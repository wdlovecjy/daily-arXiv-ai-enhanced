{"id": "2511.02373", "categories": ["stat.ML", "cs.LG", "eess.SP", "stat.CO"], "pdf": "https://arxiv.org/pdf/2511.02373", "abs": "https://arxiv.org/abs/2511.02373", "authors": ["Jean-Baptiste Courbot", "Hugo Gangloff", "Bruno Colicchio"], "title": "A new class of Markov random fields enabling lightweight sampling", "comment": null, "summary": "This work addresses the problem of efficient sampling of Markov random fields\n(MRF). The sampling of Potts or Ising MRF is most often based on Gibbs\nsampling, and is thus computationally expensive. We consider in this work how\nto circumvent this bottleneck through a link with Gaussian Markov Random\nfields. The latter can be sampled in several cost-effective ways, and we\nintroduce a mapping from real-valued GMRF to discrete-valued MRF. The resulting\nnew class of MRF benefits from a few theoretical properties that validate the\nnew model. Numerical results show the drastic performance gain in terms of\ncomputational efficiency, as we sample at least 35x faster than Gibbs sampling\nusing at least 37x less energy, all the while exhibiting empirical properties\nclose to classical MRFs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u9ad8\u65af\u9a6c\u5c14\u53ef\u592b\u968f\u673a\u573a(GMRF)\u9ad8\u6548\u91c7\u6837\u9a6c\u5c14\u53ef\u592b\u968f\u673a\u573a(MRF)\u7684\u65b0\u65b9\u6cd5\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684Gibbs\u91c7\u6837\uff0c\u8ba1\u7b97\u6548\u7387\u63d0\u5347\u81f3\u5c1135\u500d\uff0c\u80fd\u8017\u964d\u4f4e\u81f3\u5c1137\u500d\u3002", "motivation": "\u4f20\u7edfPotts\u6216Ising MRF\u7684\u91c7\u6837\u4e3b\u8981\u57fa\u4e8eGibbs\u91c7\u6837\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u5bfb\u627e\u66f4\u9ad8\u6548\u7684\u91c7\u6837\u65b9\u6cd5\u3002", "method": "\u5229\u7528GMRF\u4e0eMRF\u7684\u8054\u7cfb\uff0c\u5efa\u7acb\u4ece\u5b9e\u503cGMRF\u5230\u79bb\u6563\u503cMRF\u7684\u6620\u5c04\uff0c\u901a\u8fc7GMRF\u7684\u9ad8\u6548\u91c7\u6837\u65b9\u6cd5\u6765\u91c7\u6837MRF\u3002", "result": "\u65b0\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u6bd4Gibbs\u91c7\u6837\u5feb\u81f3\u5c1135\u500d\uff0c\u80fd\u8017\u964d\u4f4e\u81f3\u5c1137\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u7ecf\u5178MRF\u76f8\u4f3c\u7684\u5b9e\u8bc1\u7279\u6027\u3002", "conclusion": "\u901a\u8fc7GMRF\u6620\u5c04\u7684\u65b9\u6cd5\u4e3aMRF\u91c7\u6837\u63d0\u4f9b\u4e86\u4e00\u79cd\u8ba1\u7b97\u9ad8\u6548\u4e14\u8282\u80fd\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2511.01879", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01879", "abs": "https://arxiv.org/abs/2511.01879", "authors": ["HM Shadman Tabib", "Md. Hasnaen Adil", "Ayesha Rahman", "Ahmmad Nur Swapnil", "Maoyejatun Hasana", "Ahmed Hossain Chowdhury", "A. B. M. Alim Al Islam"], "title": "Affordable EEG, Actionable Insights: An Open Dataset and Evaluation Framework for Epilepsy Patient Stratification", "comment": null, "summary": "Access to clinical multi-channel EEG remains limited in many regions\nworldwide. We present NEUROSKY-EPI, the first open dataset of single-channel,\nconsumer-grade EEG for epilepsy, collected in a South Asian clinical setting\nalong with rich contextual metadata. To explore its utility, we introduce\nEmbedCluster, a patient-stratification pipeline that transfers representations\nfrom EEGNet models trained on clinical data and enriches them with contextual\nautoencoder embeddings, followed by unsupervised clustering of patients based\non EEG patterns. Results show that low-cost, single-channel data can support\nmeaningful stratification. Beyond algorithmic performance, we emphasize\nhuman-centered concerns such as deployability in resource-constrained\nenvironments, interpretability for non-specialists, and safeguards for privacy,\ninclusivity, and bias. By releasing the dataset and code, we aim to catalyze\ninterdisciplinary research across health technology, human-computer\ninteraction, and machine learning, advancing the goal of affordable and\nactionable EEG-based epilepsy care.", "AI": {"tldr": "NEUROSKY-EPI\u662f\u9996\u4e2a\u9762\u5411\u766b\u75eb\u7684\u5355\u901a\u9053\u6d88\u8d39\u7ea7EEG\u5f00\u653e\u6570\u636e\u96c6\uff0c\u7ed3\u5408EmbedCluster\u60a3\u8005\u5206\u5c42\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u4f4e\u6210\u672cEEG\u6570\u636e\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u5168\u7403\u8bb8\u591a\u5730\u533a\u96be\u4ee5\u83b7\u53d6\u4e34\u5e8a\u591a\u901a\u9053EEG\u6570\u636e\uff0c\u9700\u8981\u5f00\u53d1\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u53ef\u90e8\u7f72\u7684\u766b\u75eb\u8bca\u65ad\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faEmbedCluster\u60a3\u8005\u5206\u5c42\u6d41\u7a0b\uff1a\u4ece\u4e34\u5e8a\u6570\u636e\u8bad\u7ec3\u7684EEGNet\u6a21\u578b\u8fc1\u79fb\u8868\u5f81\uff0c\u7528\u4e0a\u4e0b\u6587\u81ea\u7f16\u7801\u5668\u5d4c\u5165\u4e30\u5bcc\u8868\u5f81\uff0c\u7136\u540e\u57fa\u4e8eEEG\u6a21\u5f0f\u8fdb\u884c\u65e0\u76d1\u7763\u805a\u7c7b\u3002", "result": "\u7ed3\u679c\u8868\u660e\u4f4e\u6210\u672c\u5355\u901a\u9053\u6570\u636e\u80fd\u591f\u652f\u6301\u6709\u610f\u4e49\u7684\u60a3\u8005\u5206\u5c42\u3002", "conclusion": "\u901a\u8fc7\u53d1\u5e03\u6570\u636e\u96c6\u548c\u4ee3\u7801\uff0c\u65e8\u5728\u4fc3\u8fdb\u8de8\u5b66\u79d1\u7814\u7a76\uff0c\u63a8\u8fdb\u53ef\u8d1f\u62c5\u4e14\u53ef\u64cd\u4f5c\u7684\u57fa\u4e8eEEG\u7684\u766b\u75eb\u62a4\u7406\u3002"}}
{"id": "2511.02452", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02452", "abs": "https://arxiv.org/abs/2511.02452", "authors": ["Junghee Pyeon", "Davide Cacciarelli", "Kamran Paynabar"], "title": "An Adaptive Sampling Framework for Detecting Localized Concept Drift under Label Scarcity", "comment": null, "summary": "Concept drift and label scarcity are two critical challenges limiting the\nrobustness of predictive models in dynamic industrial environments. Existing\ndrift detection methods often assume global shifts and rely on dense\nsupervision, making them ill-suited for regression tasks with local drifts and\nlimited labels. This paper proposes an adaptive sampling framework that\ncombines residual-based exploration and exploitation with EWMA monitoring to\nefficiently detect local concept drift under labeling budget constraints.\nEmpirical results on synthetic benchmarks and a case study on electricity\nmarket demonstrate superior performance in label efficiency and drift detection\naccuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u6b8b\u5dee\u63a2\u7d22\u5f00\u53d1\u548cEWMA\u76d1\u63a7\u7684\u81ea\u9002\u5e94\u91c7\u6837\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u6807\u7b7e\u9884\u7b97\u7ea6\u675f\u4e0b\u9ad8\u6548\u68c0\u6d4b\u5c40\u90e8\u6982\u5ff5\u6f02\u79fb\u3002", "motivation": "\u6982\u5ff5\u6f02\u79fb\u548c\u6807\u7b7e\u7a00\u7f3a\u662f\u52a8\u6001\u5de5\u4e1a\u73af\u5883\u4e2d\u9884\u6d4b\u6a21\u578b\u9762\u4e34\u7684\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff0c\u73b0\u6709\u6f02\u79fb\u68c0\u6d4b\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u5168\u5c40\u6f02\u79fb\u5e76\u4f9d\u8d56\u5bc6\u96c6\u76d1\u7763\uff0c\u4e0d\u9002\u7528\u4e8e\u5c40\u90e8\u6f02\u79fb\u548c\u6709\u9650\u6807\u7b7e\u7684\u56de\u5f52\u4efb\u52a1\u3002", "method": "\u7ed3\u5408\u6b8b\u5dee\u63a2\u7d22\u5f00\u53d1\u548cEWMA\u76d1\u63a7\u7684\u81ea\u9002\u5e94\u91c7\u6837\u6846\u67b6\uff0c\u5728\u6807\u7b7e\u9884\u7b97\u7ea6\u675f\u4e0b\u68c0\u6d4b\u5c40\u90e8\u6982\u5ff5\u6f02\u79fb\u3002", "result": "\u5728\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\u548c\u7535\u529b\u5e02\u573a\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u5728\u6807\u7b7e\u6548\u7387\u548c\u6f02\u79fb\u68c0\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u8be5\u81ea\u9002\u5e94\u91c7\u6837\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u5c40\u90e8\u6982\u5ff5\u6f02\u79fb\u68c0\u6d4b\u95ee\u9898\uff0c\u5728\u6807\u7b7e\u9884\u7b97\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\u5177\u6709\u826f\u597d\u8868\u73b0\u3002"}}
{"id": "2511.02130", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02130", "abs": "https://arxiv.org/abs/2511.02130", "authors": ["Renos Zabounidis", "Aditya Golatkar", "Michael Kleinman", "Alessandro Achille", "Wei Xia", "Stefano Soatto"], "title": "Re-FORC: Adaptive Reward Prediction for Efficient Chain-of-Thought Reasoning", "comment": "Accepted at Efficient Reasoning Workshop at NeurIPS 2025", "summary": "We propose Re-FORC, an adaptive reward prediction method that, given a\ncontext, enables prediction of the expected future rewards as a function of the\nnumber of future thinking tokens. Re-FORC trains a lightweight adapter on\nreasoning models, demonstrating improved prediction with longer reasoning and\nlarger models. Re-FORC enables: 1) early stopping of unpromising reasoning\nchains, reducing compute by 26% while maintaining accuracy, 2) optimized model\nand thinking length selection that achieves 4% higher accuracy at equal compute\nand 55% less compute at equal accuracy compared to the largest model, 3)\nadaptive test-time scaling, which increases accuracy by 11% in high compute\nregime, and 7% in low compute regime. Re-FORC allows dynamic reasoning with\nlength control via cost-per-token thresholds while estimating computation time\nupfront.", "AI": {"tldr": "Re-FORC\u662f\u4e00\u79cd\u81ea\u9002\u5e94\u5956\u52b1\u9884\u6d4b\u65b9\u6cd5\uff0c\u80fd\u591f\u6839\u636e\u4e0a\u4e0b\u6587\u9884\u6d4b\u672a\u6765\u5956\u52b1\u671f\u671b\u503c\uff0c\u4f5c\u4e3a\u672a\u6765\u601d\u8003token\u6570\u91cf\u7684\u51fd\u6570\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5728\u63a8\u7406\u6a21\u578b\u4e0a\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\uff0c\u5b9e\u73b0\u4e86\u66f4\u957f\u7684\u63a8\u7406\u548c\u66f4\u5927\u6a21\u578b\u5e26\u6765\u7684\u6539\u8fdb\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u63a8\u7406\u8fc7\u7a0b\u4e2d\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u63a8\u7406\u6548\u7387\uff0c\u540c\u65f6\u4f18\u5316\u6a21\u578b\u548c\u63a8\u7406\u957f\u5ea6\u7684\u9009\u62e9\uff0c\u5b9e\u73b0\u66f4\u597d\u7684\u6027\u80fd\u4e0e\u8ba1\u7b97\u6210\u672c\u5e73\u8861\u3002", "method": "\u5728\u63a8\u7406\u6a21\u578b\u4e0a\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\uff0c\u5b9e\u73b0\u81ea\u9002\u5e94\u5956\u52b1\u9884\u6d4b\uff0c\u80fd\u591f\u6839\u636e\u4e0a\u4e0b\u6587\u9884\u6d4b\u672a\u6765\u5956\u52b1\u671f\u671b\u503c\u3002", "result": "1) \u63d0\u524d\u505c\u6b62\u65e0\u524d\u666f\u7684\u63a8\u7406\u94fe\uff0c\u51cf\u5c1126%\u8ba1\u7b97\u91cf\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\uff1b2) \u4f18\u5316\u6a21\u578b\u548c\u601d\u8003\u957f\u5ea6\u9009\u62e9\uff0c\u5728\u76f8\u540c\u8ba1\u7b97\u91cf\u4e0b\u5b9e\u73b04%\u66f4\u9ad8\u51c6\u786e\u7387\uff0c\u5728\u76f8\u540c\u51c6\u786e\u7387\u4e0b\u51cf\u5c1155%\u8ba1\u7b97\u91cf\uff1b3) \u81ea\u9002\u5e94\u6d4b\u8bd5\u65f6\u6269\u5c55\uff0c\u5728\u9ad8\u8ba1\u7b97\u6a21\u5f0f\u4e0b\u63d0\u9ad811%\u51c6\u786e\u7387\uff0c\u5728\u4f4e\u8ba1\u7b97\u6a21\u5f0f\u4e0b\u63d0\u9ad87%\u51c6\u786e\u7387\u3002", "conclusion": "Re-FORC\u5141\u8bb8\u901a\u8fc7\u6bcftoken\u6210\u672c\u9608\u503c\u8fdb\u884c\u52a8\u6001\u63a8\u7406\u957f\u5ea6\u63a7\u5236\uff0c\u540c\u65f6\u9884\u5148\u4f30\u8ba1\u8ba1\u7b97\u65f6\u95f4\uff0c\u4e3a\u9ad8\u6548\u63a8\u7406\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.02006", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.02006", "abs": "https://arxiv.org/abs/2511.02006", "authors": ["Logan Schexnaydre", "Aman Poovalappil", "Darrell Robinette", "Jeremy Bos"], "title": "A Comparison of Road Grade Preview Signals from Lidar and Maps", "comment": "8 pages, 10 figures, submitted to SAE WCX 2026", "summary": "Road grade can impact the energy efficiency, safety, and comfort associated\nwith automated vehicle control systems. Currently, control systems that attempt\nto compensate for road grade are designed with one of two assumptions. Either\nthe grade is only known once the vehicle is driving over the road segment\nthrough proprioception, or complete knowledge of the oncoming road grade is\nknown from a pre-made map. Both assumptions limit the performance of a control\nsystem, as not having a preview signal prevents proactive grade compensation,\nwhereas relying only on map data potentially subjects the control system to\nmissing or outdated information. These limits can be avoided by measuring the\noncoming grade in real-time using on-board lidar sensors. In this work, we use\npoint returns accumulated during travel to estimate the grade at each waypoint\nalong a path. The estimated grade is defined as the difference in height\nbetween the front and rear wheelbase at a given waypoint. Kalman filtering\ntechniques are used to mitigate the effects of odometry and motion uncertainty\non the grade estimates. This estimator's performance is compared to the\nmeasurements of a map created with a GNSS/INS system via a field experiment.\nWhen compared to the map-based system, the lidar-based estimator produces an\nunbiased error with a standard deviation of 0.6 degrees at an average range of\n52.7 meters. By having similar precision to map-based systems, automotive\nlidar-based grade estimation systems are shown to be a valid approach for\nmeasuring road grade when a map is unavailable or inaccurate. In using lidar as\nan input signal for grade-based control system tasks, autonomous vehicles\nachieve higher redundancy and independence in contrast to existing methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u8f66\u8f7d\u6fc0\u5149\u96f7\u8fbe\u5b9e\u65f6\u4f30\u8ba1\u9053\u8def\u5761\u5ea6\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5361\u5c14\u66fc\u6ee4\u6ce2\u6280\u672f\u5904\u7406\u91cc\u7a0b\u8ba1\u548c\u8fd0\u52a8\u4e0d\u786e\u5b9a\u6027\uff0c\u4e0e\u57fa\u4e8e\u5730\u56fe\u7684\u7cfb\u7edf\u76f8\u6bd4\u5177\u67090.6\u5ea6\u6807\u51c6\u504f\u5dee\u7684\u7cbe\u5ea6\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u63d0\u4f9b\u72ec\u7acb\u4e8e\u5730\u56fe\u7684\u5761\u5ea6\u6d4b\u91cf\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u63a7\u5236\u7cfb\u7edf\u8981\u4e48\u4f9d\u8d56\u8f66\u8f86\u884c\u9a76\u65f6\u7684\u5b9e\u65f6\u611f\u77e5\uff08\u7f3a\u4e4f\u9884\u89c8\u4fe1\u53f7\uff09\uff0c\u8981\u4e48\u5b8c\u5168\u4f9d\u8d56\u9884\u8bbe\u5730\u56fe\u6570\u636e\uff08\u53ef\u80fd\u4fe1\u606f\u7f3a\u5931\u6216\u8fc7\u65f6\uff09\uff0c\u8fd9\u4e24\u79cd\u65b9\u6cd5\u90fd\u9650\u5236\u4e86\u63a7\u5236\u7cfb\u7edf\u7684\u6027\u80fd\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5b9e\u65f6\u6d4b\u91cf\u524d\u65b9\u9053\u8def\u5761\u5ea6\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u8f66\u8f7d\u6fc0\u5149\u96f7\u8fbe\u91c7\u96c6\u7684\u70b9\u4e91\u6570\u636e\uff0c\u901a\u8fc7\u7d2f\u79ef\u884c\u9a76\u8fc7\u7a0b\u4e2d\u7684\u70b9\u8fd4\u56de\u6765\u4f30\u8ba1\u8def\u5f84\u4e0a\u6bcf\u4e2a\u822a\u70b9\u7684\u5761\u5ea6\u3002\u5761\u5ea6\u5b9a\u4e49\u4e3a\u7ed9\u5b9a\u822a\u70b9\u5904\u524d\u540e\u8f6e\u8f74\u4e4b\u95f4\u7684\u9ad8\u5ea6\u5dee\uff0c\u91c7\u7528\u5361\u5c14\u66fc\u6ee4\u6ce2\u6280\u672f\u6765\u51cf\u8f7b\u91cc\u7a0b\u8ba1\u548c\u8fd0\u52a8\u4e0d\u786e\u5b9a\u6027\u5bf9\u5761\u5ea6\u4f30\u8ba1\u7684\u5f71\u54cd\u3002", "result": "\u4e0e\u57fa\u4e8eGNSS/INS\u7cfb\u7edf\u521b\u5efa\u7684\u5730\u56fe\u6d4b\u91cf\u76f8\u6bd4\uff0c\u6fc0\u5149\u96f7\u8fbe\u4f30\u8ba1\u5668\u4ea7\u751f\u65e0\u504f\u8bef\u5dee\uff0c\u6807\u51c6\u504f\u5dee\u4e3a0.6\u5ea6\uff0c\u5e73\u5747\u8303\u56f4\u4e3a52.7\u7c73\u3002\u7cbe\u5ea6\u4e0e\u57fa\u4e8e\u5730\u56fe\u7684\u7cfb\u7edf\u76f8\u5f53\u3002", "conclusion": "\u6fc0\u5149\u96f7\u8fbe\u5761\u5ea6\u4f30\u8ba1\u7cfb\u7edf\u5728\u65e0\u6cd5\u83b7\u53d6\u6216\u5730\u56fe\u4e0d\u51c6\u786e\u65f6\u662f\u6709\u6548\u7684\u9053\u8def\u5761\u5ea6\u6d4b\u91cf\u65b9\u6cd5\uff0c\u4e3a\u57fa\u4e8e\u5761\u5ea6\u7684\u63a7\u5236\u7cfb\u7edf\u4efb\u52a1\u63d0\u4f9b\u8f93\u5165\u4fe1\u53f7\uff0c\u4f7f\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5177\u6709\u66f4\u9ad8\u7684\u5197\u4f59\u6027\u548c\u72ec\u7acb\u6027\u3002"}}
{"id": "2511.02174", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.02174", "abs": "https://arxiv.org/abs/2511.02174", "authors": ["Jack Kissell", "Vijini Lakmini", "Brani Vidakovic"], "title": "Wavelet Based Cross Correlations with Applications", "comment": null, "summary": "Wavelet Transforms are a widely used technique for decomposing a signal into\ncoefficient vectors that correspond to distinct frequency/scale bands while\nretaining time localization. This property enables an adaptive analysis of\nsignals at different scales, capturing both temporal and spectral patterns. By\nexamining how correlations between two signals vary across these scales, we\nobtain a more nuanced understanding of their relationship than what is possible\nfrom a single global correlation measure. In this work, we expand on the theory\nof wavelet-based correlations already used in the literature and elaborate on\nwavelet correlograms, partial wavelet correlations, and additive wavelet\ncorrelations using the Pearson and Kendall definitions. We use both Orthogonal\nand Non-decimated discrete Wavelet Transforms, and assess the robustness of\nthese correlations under different wavelet bases. Simulation studies are\nconducted to illustrate these methods, and we conclude with applications to\nreal-world datasets.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u57fa\u4e8e\u5c0f\u6ce2\u53d8\u6362\u7684\u76f8\u5173\u6027\u5206\u6790\u7406\u8bba\uff0c\u8be6\u7ec6\u9610\u8ff0\u4e86\u5c0f\u6ce2\u76f8\u5173\u56fe\u3001\u504f\u5c0f\u6ce2\u76f8\u5173\u6027\u548c\u52a0\u6027\u5c0f\u6ce2\u76f8\u5173\u6027\uff0c\u4f7f\u7528Pearson\u548cKendall\u5b9a\u4e49\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e0d\u540c\u5c0f\u6ce2\u57fa\u4e0b\u8fd9\u4e9b\u76f8\u5173\u6027\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u5c0f\u6ce2\u53d8\u6362\u80fd\u591f\u5c06\u4fe1\u53f7\u5206\u89e3\u4e3a\u5bf9\u5e94\u4e0d\u540c\u9891\u7387/\u5c3a\u5ea6\u5e26\u7684\u7cfb\u6570\u5411\u91cf\uff0c\u540c\u65f6\u4fdd\u7559\u65f6\u95f4\u5c40\u90e8\u5316\u7279\u6027\uff0c\u8fd9\u4f7f\u5f97\u80fd\u591f\u5728\u4e0d\u540c\u5c3a\u5ea6\u4e0a\u81ea\u9002\u5e94\u5206\u6790\u4fe1\u53f7\uff0c\u6355\u6349\u65f6\u95f4\u548c\u9891\u8c31\u6a21\u5f0f\u3002\u901a\u8fc7\u7814\u7a76\u4e24\u4e2a\u4fe1\u53f7\u5728\u8fd9\u4e9b\u5c3a\u5ea6\u4e0a\u7684\u76f8\u5173\u6027\u53d8\u5316\uff0c\u53ef\u4ee5\u83b7\u5f97\u6bd4\u5355\u4e00\u5168\u5c40\u76f8\u5173\u6027\u5ea6\u91cf\u66f4\u7ec6\u81f4\u7684\u7406\u89e3\u3002", "method": "\u4f7f\u7528\u6b63\u4ea4\u548c\u975e\u62bd\u53d6\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\uff0c\u6269\u5c55\u4e86\u5c0f\u6ce2\u76f8\u5173\u6027\u7406\u8bba\uff0c\u5305\u62ec\u5c0f\u6ce2\u76f8\u5173\u56fe\u3001\u504f\u5c0f\u6ce2\u76f8\u5173\u6027\u548c\u52a0\u6027\u5c0f\u6ce2\u76f8\u5173\u6027\uff0c\u91c7\u7528Pearson\u548cKendall\u76f8\u5173\u6027\u5b9a\u4e49\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u8bc4\u4f30\u4e0d\u540c\u5c0f\u6ce2\u57fa\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e94\u7528\uff0c\u5c55\u793a\u4e86\u5c0f\u6ce2\u76f8\u5173\u6027\u5206\u6790\u5728\u4e0d\u540c\u5c3a\u5ea6\u4e0a\u63ed\u793a\u4fe1\u53f7\u5173\u7cfb\u7684\u4f18\u52bf\u3002", "conclusion": "\u5c0f\u6ce2\u76f8\u5173\u6027\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u79cd\u591a\u5c3a\u5ea6\u7684\u65b9\u6cd5\u6765\u7406\u89e3\u4fe1\u53f7\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u6bd4\u4f20\u7edf\u7684\u5168\u5c40\u76f8\u5173\u6027\u5ea6\u91cf\u80fd\u591f\u63d0\u4f9b\u66f4\u4e30\u5bcc\u7684\u4fe1\u606f\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2511.01904", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01904", "abs": "https://arxiv.org/abs/2511.01904", "authors": ["Doulaye Demb\u00e9l\u00e9"], "title": "The Eigenvalues Entropy as a Classifier Evaluation Measure", "comment": null, "summary": "Classification is a machine learning method used in many practical\napplications: text mining, handwritten character recognition, face recognition,\npattern classification, scene labeling, computer vision, natural langage\nprocessing. A classifier prediction results and training set information are\noften used to get a contingency table which is used to quantify the method\nquality through an evaluation measure. Such measure, typically a numerical\nvalue, allows to choose a suitable method among several. Many evaluation\nmeasures available in the literature are less accurate for a dataset with\nimbalanced classes. In this paper, the eigenvalues entropy is used as an\nevaluation measure for a binary or a multi-class problem. For a binary problem,\nrelations are given between the eigenvalues and some commonly used measures,\nthe sensitivity, the specificity, the area under the operating receiver\ncharacteristic curve and the Gini index. A by-product result of this paper is\nan estimate of the confusion matrix to deal with the curse of the imbalanced\nclasses. Various data examples are used to show the better performance of the\nproposed evaluation measure over the gold standard measures available in the\nliterature.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u7279\u5f81\u503c\u71b5\u4f5c\u4e3a\u8bc4\u4f30\u5206\u7c7b\u5668\u6027\u80fd\u7684\u65b0\u6307\u6807\uff0c\u7279\u522b\u9002\u7528\u4e8e\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u6570\u636e\u96c6\u3002\u8be5\u6307\u6807\u4e0e\u5e38\u7528\u7684\u8bc4\u4f30\u6307\u6807\uff08\u5982\u7075\u654f\u5ea6\u3001\u7279\u5f02\u6027\u3001AUC\u548c\u57fa\u5c3c\u6307\u6570\uff09\u5b58\u5728\u6570\u5b66\u5173\u7cfb\uff0c\u5e76\u80fd\u4f30\u8ba1\u6df7\u6dc6\u77e9\u9635\u4ee5\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u6307\u6807\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u4e0a\u51c6\u786e\u6027\u4e0d\u8db3\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u6709\u6548\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u6bd4\u8f83\u4e0d\u540c\u5206\u7c7b\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u7279\u5f81\u503c\u71b5\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\uff0c\u5efa\u7acb\u7279\u5f81\u503c\u4e0e\u5e38\u7528\u8bc4\u4f30\u6307\u6807\u4e4b\u95f4\u7684\u6570\u5b66\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u4f30\u8ba1\u6df7\u6dc6\u77e9\u9635\u7684\u65b9\u6cd5\u6765\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "\u901a\u8fc7\u591a\u4e2a\u6570\u636e\u793a\u4f8b\u9a8c\u8bc1\uff0c\u6240\u63d0\u51fa\u7684\u7279\u5f81\u503c\u71b5\u8bc4\u4f30\u6307\u6807\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u6587\u732e\u4e2d\u7684\u6807\u51c6\u8bc4\u4f30\u6307\u6807\u3002", "conclusion": "\u7279\u5f81\u503c\u71b5\u662f\u4e00\u79cd\u6709\u6548\u7684\u5206\u7c7b\u5668\u8bc4\u4f30\u6307\u6807\uff0c\u7279\u522b\u9002\u7528\u4e8e\u7c7b\u522b\u4e0d\u5e73\u8861\u60c5\u51b5\uff0c\u80fd\u591f\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u6027\u80fd\u8bc4\u4f30\u3002"}}
{"id": "2511.02194", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02194", "abs": "https://arxiv.org/abs/2511.02194", "authors": ["Yibo Zhao", "Yang Zhao", "Hongru Du", "Hao Frank Yang"], "title": "Personalized Decision Modeling: Utility Optimization or Textualized-Symbolic Reasoning", "comment": null, "summary": "Decision-making models for individuals, particularly in high-stakes scenarios\nlike vaccine uptake, often diverge from population optimal predictions. This\ngap arises from the uniqueness of the individual decision-making process,\nshaped by numerical attributes (e.g., cost, time) and linguistic influences\n(e.g., personal preferences and constraints). Developing upon Utility Theory\nand leveraging the textual-reasoning capabilities of Large Language Models\n(LLMs), this paper proposes an Adaptive Textual-symbolic Human-centric\nReasoning framework (ATHENA) to address the optimal information integration.\nATHENA uniquely integrates two stages: First, it discovers robust, group-level\nsymbolic utility functions via LLM-augmented symbolic discovery; Second, it\nimplements individual-level semantic adaptation, creating personalized semantic\ntemplates guided by the optimal utility to model personalized choices.\nValidated on real-world travel mode and vaccine choice tasks, ATHENA\nconsistently outperforms utility-based, machine learning, and other LLM-based\nmodels, lifting F1 score by at least 6.5% over the strongest cutting-edge\nmodels. Further, ablation studies confirm that both stages of ATHENA are\ncritical and complementary, as removing either clearly degrades overall\npredictive performance. By organically integrating symbolic utility modeling\nand semantic adaptation, ATHENA provides a new scheme for modeling\nhuman-centric decisions. The project page can be found at\nhttps://yibozh.github.io/Athena.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ATHENA\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u7b26\u53f7\u6548\u7528\u5efa\u6a21\u548c\u8bed\u4e49\u9002\u5e94\uff0c\u5728\u75ab\u82d7\u9009\u62e9\u548c\u51fa\u884c\u65b9\u5f0f\u7b49\u9ad8\u98ce\u9669\u51b3\u7b56\u573a\u666f\u4e2d\uff0c\u6bd4\u73b0\u6709\u6a21\u578b\u63d0\u5347\u4e86\u81f3\u5c116.5%\u7684F1\u5206\u6570\u3002", "motivation": "\u4e2a\u4f53\u51b3\u7b56\u6a21\u578b\u4e0e\u7fa4\u4f53\u6700\u4f18\u9884\u6d4b\u5b58\u5728\u5dee\u8ddd\uff0c\u8fd9\u79cd\u5dee\u8ddd\u6e90\u4e8e\u4e2a\u4f53\u51b3\u7b56\u8fc7\u7a0b\u7684\u72ec\u7279\u6027\uff0c\u5305\u62ec\u6570\u503c\u5c5e\u6027\uff08\u5982\u6210\u672c\u3001\u65f6\u95f4\uff09\u548c\u8bed\u8a00\u5f71\u54cd\uff08\u5982\u4e2a\u4eba\u504f\u597d\u548c\u7ea6\u675f\uff09\u3002", "method": "ATHENA\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a1\uff09\u901a\u8fc7LLM\u589e\u5f3a\u7684\u7b26\u53f7\u53d1\u73b0\u53d1\u73b0\u7a33\u5065\u7684\u7fa4\u4f53\u7ea7\u7b26\u53f7\u6548\u7528\u51fd\u6570\uff1b2\uff09\u5b9e\u73b0\u4e2a\u4f53\u7ea7\u8bed\u4e49\u9002\u5e94\uff0c\u521b\u5efa\u7531\u6700\u4f18\u6548\u7528\u6307\u5bfc\u7684\u4e2a\u6027\u5316\u8bed\u4e49\u6a21\u677f\u6765\u5efa\u6a21\u4e2a\u6027\u5316\u9009\u62e9\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u7684\u51fa\u884c\u65b9\u5f0f\u548c\u75ab\u82d7\u9009\u62e9\u4efb\u52a1\u4e0a\u9a8c\u8bc1\uff0cATHENA\u59cb\u7ec8\u4f18\u4e8e\u57fa\u4e8e\u6548\u7528\u7684\u6a21\u578b\u3001\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u5176\u4ed6\u57fa\u4e8eLLM\u7684\u6a21\u578b\uff0cF1\u5206\u6570\u6bd4\u6700\u5f3a\u524d\u6cbf\u6a21\u578b\u63d0\u5347\u4e86\u81f3\u5c116.5%\u3002", "conclusion": "\u901a\u8fc7\u6709\u673a\u6574\u5408\u7b26\u53f7\u6548\u7528\u5efa\u6a21\u548c\u8bed\u4e49\u9002\u5e94\uff0cATHENA\u4e3a\u5efa\u6a21\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u51b3\u7b56\u63d0\u4f9b\u4e86\u65b0\u65b9\u6848\uff0c\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u4e24\u4e2a\u9636\u6bb5\u90fd\u81f3\u5173\u91cd\u8981\u4e14\u4e92\u8865\u3002"}}
{"id": "2511.02509", "categories": ["stat.AP", "stat.CO"], "pdf": "https://arxiv.org/pdf/2511.02509", "abs": "https://arxiv.org/abs/2511.02509", "authors": ["R. Alberich", "N. A. Cruz", "R. Fern\u00e1ndez", "I. Garc\u00eda Mosquera", "A. Mir", "F. Rosell\u00f3"], "title": "Identification of Separable OTUs for Multinomial Classification in Compositional Data Analysis", "comment": null, "summary": "High-throughput sequencing has transformed microbiome research, but it also\nproduces inherently compositional data that challenge standard statistical and\nmachine learning methods. In this work, we propose a multinomial classification\nframework for compositional microbiome data based on penalized log-ratio\nregression and pairwise separability screening. The method quantifies the\ndiscriminative ability of each OTU through the area under the receiver\noperating characteristic curve ($AUC$) for all pairwise log-ratios and\naggregates these values into a global separability index $S_k$, yielding\ninterpretable rankings of taxa together with confidence intervals. We\nillustrate the approach by reanalyzing the Baxter colorectal adenoma dataset\nand comparing our results with Greenacre's ordination-based analysis using\nCorrespondence Analysis and Canonical Correspondence Analysis. Our models\nconsistently recover a core subset of taxa previously identified as\ndiscriminant, thereby corroborating Greenacre's main findings, while also\nrevealing additional OTUs that become important once demographic covariates are\ntaken into account. In particular, adjustment for age, gender, and diabetes\nmedication improves the precision of the separation index and highlights new,\npotentially relevant taxa, suggesting that part of the original signal may have\nbeen influenced by confounding. Overall, the integration of log-ratio modeling,\ncovariate adjustment, and uncertainty estimation provides a robust and\ninterpretable framework for OTU selection in compositional microbiome data. The\nproposed method complements existing ordination-based approaches by adding a\nprobabilistic and inferential perspective, strengthening the identification of\nbiologically meaningful microbial signatures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u60e9\u7f5a\u5bf9\u6570\u6bd4\u56de\u5f52\u548c\u6210\u5bf9\u53ef\u5206\u79bb\u6027\u7b5b\u9009\u7684\u591a\u5143\u5206\u7c7b\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u7ec4\u6210\u6027\u5fae\u751f\u7269\u7ec4\u6570\u636e\uff0c\u901a\u8fc7AUC\u8bc4\u4f30OTU\u7684\u5224\u522b\u80fd\u529b\uff0c\u5e76\u6574\u5408\u6210\u5168\u5c40\u53ef\u5206\u79bb\u6027\u6307\u6570Sk\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u7269\u79cd\u6392\u540d\u548c\u7f6e\u4fe1\u533a\u95f4\u3002", "motivation": "\u9ad8\u901a\u91cf\u6d4b\u5e8f\u4ea7\u751f\u7ec4\u6210\u6027\u6570\u636e\uff0c\u6311\u6218\u6807\u51c6\u7edf\u8ba1\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u5904\u7406\u7ec4\u6210\u6027\u5fae\u751f\u7269\u7ec4\u6570\u636e\u7684\u7a33\u5065\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u60e9\u7f5a\u5bf9\u6570\u6bd4\u56de\u5f52\u548c\u6210\u5bf9\u53ef\u5206\u79bb\u6027\u7b5b\u9009\uff0c\u901a\u8fc7\u8ba1\u7b97\u6240\u6709\u6210\u5bf9\u5bf9\u6570\u6bd4\u7684AUC\u503c\uff0c\u805a\u5408\u4e3a\u5168\u5c40\u53ef\u5206\u79bb\u6027\u6307\u6570Sk\uff0c\u5e76\u7ed3\u5408\u534f\u53d8\u91cf\u8c03\u6574\u548c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "result": "\u5728Baxter\u7ed3\u76f4\u80a0\u817a\u7624\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u4e00\u81f4\u6062\u590d\u5148\u524d\u8bc6\u522b\u7684\u6838\u5fc3\u7269\u79cd\u5b50\u96c6\uff0c\u540c\u65f6\u53d1\u73b0\u8003\u8651\u4eba\u53e3\u7edf\u8ba1\u5b66\u534f\u53d8\u91cf\u540e\u65b0\u7684\u91cd\u8981OTU\uff0c\u63d0\u9ad8\u5206\u79bb\u6307\u6570\u7684\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u6574\u5408\u5bf9\u6570\u6bd4\u5efa\u6a21\u3001\u534f\u53d8\u91cf\u8c03\u6574\u548c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u4e3a\u7ec4\u6210\u6027\u5fae\u751f\u7269\u7ec4\u6570\u636e\u4e2d\u7684OTU\u9009\u62e9\u63d0\u4f9b\u4e86\u7a33\u5065\u4e14\u53ef\u89e3\u91ca\u7684\u6846\u67b6\uff0c\u8865\u5145\u4e86\u73b0\u6709\u57fa\u4e8e\u6392\u5e8f\u7684\u65b9\u6cd5\uff0c\u589e\u5f3a\u4e86\u751f\u7269\u5b66\u610f\u4e49\u5fae\u751f\u7269\u7279\u5f81\u7684\u8bc6\u522b\u3002"}}
{"id": "2511.02345", "categories": ["cs.LG", "stat.CO", "stat.ML", "62-08", "G.3; I.5.1"], "pdf": "https://arxiv.org/pdf/2511.02345", "abs": "https://arxiv.org/abs/2511.02345", "authors": ["David Nabergoj", "Erik \u0160trumbelj"], "title": "Reducing normalizing flow complexity for MCMC preconditioning", "comment": "22 pages, 6 figures", "summary": "Preconditioning is a key component of MCMC algorithms that improves sampling\nefficiency by facilitating exploration of geometrically complex target\ndistributions through an invertible map. While linear preconditioners are often\nsufficient for moderately complex target distributions, recent work has\nexplored nonlinear preconditioning with invertible neural networks as\ncomponents of normalizing flows (NFs). However, empirical and theoretical\nstudies show that overparameterized NF preconditioners can degrade sampling\nefficiency and fit quality. Moreover, existing NF-based approaches do not adapt\ntheir architectures to the target distribution. Related work outside of MCMC\nsimilarly finds that suitably parameterized NFs can achieve comparable or\nsuperior performance with substantially less training time or data. We propose\na factorized preconditioning architecture that reduces NF complexity by\ncombining a linear component with a conditional NF, improving adaptability to\ntarget geometry. The linear preconditioner is applied to dimensions that are\napproximately Gaussian, as estimated from warmup samples, while the conditional\nNF models more complex dimensions. Our method yields significantly better tail\nsamples on two complex synthetic distributions and consistently better\nperformance on a sparse logistic regression posterior across varying likelihood\nand prior strengths. It also achieves higher effective sample sizes on\nhierarchical Bayesian model posteriors with weak likelihoods and strong funnel\ngeometries. This approach is particularly relevant for hierarchical Bayesian\nmodel analyses with limited data and could inform current theoretical and\nsoftware strides in neural MCMC design.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u56e0\u5b50\u5316\u9884\u5904\u7406\u67b6\u6784\uff0c\u901a\u8fc7\u7ed3\u5408\u7ebf\u6027\u7ec4\u4ef6\u548c\u6761\u4ef6\u5f52\u4e00\u5316\u6d41\u6765\u964d\u4f4e\u5f52\u4e00\u5316\u6d41\u590d\u6742\u5ea6\uff0c\u63d0\u9ad8\u5bf9\u76ee\u6807\u51e0\u4f55\u5f62\u72b6\u7684\u9002\u5e94\u6027\u3002", "motivation": "\u73b0\u6709\u975e\u7ebf\u6027\u9884\u5904\u7406\u65b9\u6cd5\u4f7f\u7528\u8fc7\u53c2\u6570\u5316\u7684\u5f52\u4e00\u5316\u6d41\uff0c\u8fd9\u4f1a\u964d\u4f4e\u91c7\u6837\u6548\u7387\u548c\u62df\u5408\u8d28\u91cf\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6839\u636e\u76ee\u6807\u5206\u5e03\u81ea\u9002\u5e94\u8c03\u6574\u67b6\u6784\u3002", "method": "\u63d0\u51fa\u56e0\u5b50\u5316\u9884\u5904\u7406\u67b6\u6784\uff0c\u4f7f\u7528\u7ebf\u6027\u9884\u5904\u7406\u5668\u5904\u7406\u8fd1\u4f3c\u9ad8\u65af\u5206\u5e03\u7684\u7ef4\u5ea6\uff0c\u6761\u4ef6\u5f52\u4e00\u5316\u6d41\u5904\u7406\u590d\u6742\u7ef4\u5ea6\uff0c\u57fa\u4e8e\u9884\u70ed\u6837\u672c\u4f30\u8ba1\u5206\u5e03\u7279\u6027\u3002", "result": "\u5728\u590d\u6742\u5408\u6210\u5206\u5e03\u4e0a\u83b7\u5f97\u66f4\u597d\u7684\u5c3e\u90e8\u6837\u672c\uff0c\u5728\u7a00\u758f\u903b\u8f91\u56de\u5f52\u540e\u9a8c\u4e0a\u8868\u73b0\u4e00\u81f4\u66f4\u597d\uff0c\u5728\u5f31\u4f3c\u7136\u548c\u5f3a\u6f0f\u6597\u51e0\u4f55\u7684\u5206\u5c42\u8d1d\u53f6\u65af\u6a21\u578b\u540e\u9a8c\u4e0a\u83b7\u5f97\u66f4\u9ad8\u7684\u6709\u6548\u6837\u672c\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7279\u522b\u9002\u7528\u4e8e\u6570\u636e\u6709\u9650\u7684\u5206\u5c42\u8d1d\u53f6\u65af\u6a21\u578b\u5206\u6790\uff0c\u53ef\u4e3a\u795e\u7ecfMCMC\u8bbe\u8ba1\u7684\u7406\u8bba\u548c\u8f6f\u4ef6\u8fdb\u5c55\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2511.02243", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02243", "abs": "https://arxiv.org/abs/2511.02243", "authors": ["Zhuoran Zhang", "Tengyue Wang", "Xilin Gong", "Yang Shi", "Haotian Wang", "Di Wang", "Lijie Hu"], "title": "When Modalities Conflict: How Unimodal Reasoning Uncertainty Governs Preference Dynamics in MLLMs", "comment": "19 pages", "summary": "Multimodal large language models (MLLMs) must resolve conflicts when\ndifferent modalities provide contradictory information, a process we term\nmodality following. Prior work measured this behavior only with coarse\ndataset-level statistics, overlooking the influence of model's confidence in\nunimodal reasoning. In this paper, we introduce a new framework that decomposes\nmodality following into two fundamental factors: relative reasoning uncertainty\n(the case-specific confidence gap between unimodal predictions) and inherent\nmodality preference( a model's stable bias when uncertainties are balanced). To\nvalidate this framework, we construct a controllable dataset that\nsystematically varies the reasoning difficulty of visual and textual inputs.\nUsing entropy as a fine-grained uncertainty metric, we uncover a universal law:\nthe probability of following a modality decreases monotonically as its relative\nuncertainty increases. At the relative difficulty level where the model tends\nto follow both modalities with comparable probability what we call the balance\npoint, a practical indicator of the model's inherent preference. Unlike\ntraditional macro-level ratios, this measure offers a more principled and less\nconfounded way to characterize modality bias, disentangling it from unimodal\ncapabilities and dataset artifacts. Further, by probing layer-wise predictions,\nwe reveal the internal mechanism of oscillation: in ambiguous regions near the\nbalance point, models vacillate between modalities across layers, explaining\nexternally observed indecision. Together, these findings establish relative\nuncertainty and inherent preference as the two governing principles of modality\nfollowing, offering both a quantitative framework and mechanistic insight into\nhow MLLMs resolve conflicting information.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\uff0c\u5c06\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6a21\u6001\u8ddf\u968f\u884c\u4e3a\u5206\u89e3\u4e3a\u4e24\u4e2a\u57fa\u672c\u56e0\u7d20\uff1a\u76f8\u5bf9\u63a8\u7406\u4e0d\u786e\u5b9a\u6027\u548c\u56fa\u6709\u6a21\u6001\u504f\u597d\uff0c\u5e76\u901a\u8fc7\u53ef\u63a7\u6570\u636e\u96c6\u9a8c\u8bc1\u4e86\u76f8\u5bf9\u4e0d\u786e\u5b9a\u6027\u589e\u52a0\u65f6\u8ddf\u968f\u6982\u7387\u5355\u8c03\u4e0b\u964d\u7684\u666e\u904d\u89c4\u5f8b\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4ec5\u4f7f\u7528\u7c97\u7c92\u5ea6\u7684\u6570\u636e\u96c6\u7ea7\u7edf\u8ba1\u6765\u6d4b\u91cf\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u51b2\u7a81\u4fe1\u606f\u4e0b\u7684\u6a21\u6001\u8ddf\u968f\u884c\u4e3a\uff0c\u5ffd\u7565\u4e86\u6a21\u578b\u5728\u5355\u6a21\u6001\u63a8\u7406\u4e2d\u7684\u7f6e\u4fe1\u5ea6\u5f71\u54cd\u3002", "method": "\u6784\u5efa\u53ef\u63a7\u6570\u636e\u96c6\u7cfb\u7edf\u6027\u5730\u6539\u53d8\u89c6\u89c9\u548c\u6587\u672c\u8f93\u5165\u7684\u63a8\u7406\u96be\u5ea6\uff0c\u4f7f\u7528\u71b5\u4f5c\u4e3a\u7ec6\u7c92\u5ea6\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\uff0c\u901a\u8fc7\u5c42\u95f4\u9884\u6d4b\u63a2\u6d4b\u63ed\u793a\u5185\u90e8\u673a\u5236\u3002", "result": "\u53d1\u73b0\u4e86\u4e00\u4e2a\u666e\u904d\u89c4\u5f8b\uff1a\u8ddf\u968f\u67d0\u4e2a\u6a21\u6001\u7684\u6982\u7387\u968f\u7740\u5176\u76f8\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u589e\u52a0\u800c\u5355\u8c03\u4e0b\u964d\uff1b\u5728\u5e73\u8861\u70b9\u9644\u8fd1\uff0c\u6a21\u578b\u4f1a\u5728\u4e0d\u540c\u6a21\u6001\u95f4\u632f\u8361\uff1b\u76f8\u5bf9\u4e0d\u786e\u5b9a\u6027\u548c\u56fa\u6709\u504f\u597d\u662f\u6a21\u6001\u8ddf\u968f\u7684\u4e24\u4e2a\u63a7\u5236\u539f\u5219\u3002", "conclusion": "\u5efa\u7acb\u4e86\u76f8\u5bf9\u4e0d\u786e\u5b9a\u6027\u548c\u56fa\u6709\u504f\u597d\u4f5c\u4e3a\u6a21\u6001\u8ddf\u968f\u7684\u4e24\u4e2a\u63a7\u5236\u539f\u5219\uff0c\u4e3a\u7406\u89e3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u89e3\u51b3\u51b2\u7a81\u4fe1\u606f\u63d0\u4f9b\u4e86\u5b9a\u91cf\u6846\u67b6\u548c\u673a\u5236\u6027\u89c1\u89e3\u3002"}}
{"id": "2511.02757", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.02757", "abs": "https://arxiv.org/abs/2511.02757", "authors": ["Lejs Deen Behric", "Liang Zhang", "Bingcong Li", "Kiran Koshy Thekumparampil"], "title": "ConMeZO: Adaptive Descent-Direction Sampling for Gradient-Free Finetuning of Large Language Models", "comment": null, "summary": "Zeroth-order or derivative-free optimization (MeZO) is an attractive strategy\nfor finetuning large language models (LLMs) because it eliminates the memory\noverhead of backpropagation. However, it converges slowly due to the inherent\ncurse of dimensionality when searching for descent directions in the\nhigh-dimensional parameter space of billion-scale LLMs. We propose ConMeZO, a\nnovel zeroth-order optimizer that accelerates convergence by adaptive\ndirectional sampling. Instead of drawing the direction uniformly at random,\nConMeZO restricts the sampling to a cone centered around a momentum estimate.\nThis concentrates the search in directions where the true gradient is more\nlikely to lie and thus reduces the effect of high dimensions. We prove that\nConMeZO achieves the same worst-case convergence rate as MeZO. Empirically,\nwhen finetuning LLMs on natural language tasks, ConMeZO is up to 2X faster than\nMeZO while retaining the low-memory footprint of zeroth-order methods.", "AI": {"tldr": "ConMeZO\u662f\u4e00\u79cd\u65b0\u9896\u7684\u96f6\u9636\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u65b9\u5411\u91c7\u6837\u52a0\u901f\u6536\u655b\uff0c\u5728\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u6bd4MeZO\u5feb2\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u96f6\u9636\u65b9\u6cd5\u7684\u5185\u5b58\u4f18\u52bf\u3002", "motivation": "\u96f6\u9636\u4f18\u5316\uff08MeZO\uff09\u5728\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u5177\u6709\u5185\u5b58\u4f18\u52bf\uff0c\u4f46\u7531\u4e8e\u5728\u9ad8\u7ef4\u53c2\u6570\u7a7a\u95f4\u4e2d\u641c\u7d22\u4e0b\u964d\u65b9\u5411\uff0c\u6536\u655b\u901f\u5ea6\u7f13\u6162\u3002", "method": "ConMeZO\u901a\u8fc7\u5c06\u91c7\u6837\u9650\u5236\u5728\u4ee5\u52a8\u91cf\u4f30\u8ba1\u4e3a\u4e2d\u5fc3\u7684\u5706\u9525\u5185\uff0c\u800c\u4e0d\u662f\u5747\u5300\u968f\u673a\u91c7\u6837\u65b9\u5411\uff0c\u5c06\u641c\u7d22\u96c6\u4e2d\u5728\u771f\u5b9e\u68af\u5ea6\u66f4\u53ef\u80fd\u5b58\u5728\u7684\u65b9\u5411\u4e0a\u3002", "result": "ConMeZO\u5728\u7406\u8bba\u4e0a\u8fbe\u5230\u4e0eMeZO\u76f8\u540c\u7684\u6700\u574f\u60c5\u51b5\u6536\u655b\u7387\uff0c\u5728\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u4e0a\u5fae\u8c03LLMs\u65f6\uff0c\u6bd4MeZO\u5feb2\u500d\u3002", "conclusion": "ConMeZO\u5728\u4fdd\u6301\u96f6\u9636\u65b9\u6cd5\u4f4e\u5185\u5b58\u5360\u7528\u7684\u540c\u65f6\uff0c\u663e\u8457\u52a0\u901f\u4e86\u6536\u655b\u901f\u5ea6\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u5fae\u8c03\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.02303", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.02303", "abs": "https://arxiv.org/abs/2511.02303", "authors": ["Zhiwei Zhang", "Xiaomin Li", "Yudi Lin", "Hui Liu", "Ramraj Chandradevan", "Linlin Wu", "Minhua Lin", "Fali Wang", "Xianfeng Tang", "Qi He", "Suhang Wang"], "title": "Unlocking the Power of Multi-Agent LLM for Reasoning: From Lazy Agents to Deliberation", "comment": null, "summary": "Large Language Models (LLMs) trained with reinforcement learning and\nverifiable rewards have achieved strong results on complex reasoning tasks.\nRecent work extends this paradigm to a multi-agent setting, where a\nmeta-thinking agent proposes plans and monitors progress while a reasoning\nagent executes subtasks through sequential conversational turns. Despite\npromising performance, we identify a critical limitation: lazy agent behavior,\nin which one agent dominates while the other contributes little, undermining\ncollaboration and collapsing the setup to an ineffective single agent. In this\npaper, we first provide a theoretical analysis showing why lazy behavior\nnaturally arises in multi-agent reasoning. We then introduce a stable and\nefficient method for measuring causal influence, helping mitigate this issue.\nFinally, as collaboration intensifies, the reasoning agent risks getting lost\nin multi-turn interactions and trapped by previous noisy responses. To counter\nthis, we propose a verifiable reward mechanism that encourages deliberation by\nallowing the reasoning agent to discard noisy outputs, consolidate\ninstructions, and restart its reasoning process when necessary. Extensive\nexperiments demonstrate that our framework alleviates lazy agent behavior and\nunlocks the full potential of multi-agent framework for complex reasoning\ntasks.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u591a\u667a\u80fd\u4f53\u63a8\u7406\u4e2d\u7684\u61d2\u60f0\u884c\u4e3a\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u56e0\u679c\u5f71\u54cd\u529b\u6d4b\u91cf\u65b9\u6cd5\u548c\u53ef\u9a8c\u8bc1\u5956\u52b1\u673a\u5236\u6765\u7f13\u89e3\u8be5\u95ee\u9898\uff0c\u4ece\u800c\u5145\u5206\u53d1\u6325\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u5728\u591a\u667a\u80fd\u4f53\u63a8\u7406\u4e2d\uff0c\u5b58\u5728\u61d2\u60f0\u884c\u4e3a\u95ee\u9898\u2014\u2014\u4e00\u4e2a\u667a\u80fd\u4f53\u4e3b\u5bfc\u800c\u53e6\u4e00\u4e2a\u8d21\u732e\u5f88\u5c11\uff0c\u524a\u5f31\u4e86\u534f\u4f5c\u6548\u679c\uff0c\u4f7f\u591a\u667a\u80fd\u4f53\u8bbe\u7f6e\u9000\u5316\u4e3a\u65e0\u6548\u7684\u5355\u667a\u80fd\u4f53\u3002", "method": "1) \u7406\u8bba\u5206\u6790\u61d2\u60f0\u884c\u4e3a\u7684\u4ea7\u751f\u539f\u56e0\uff1b2) \u5f15\u5165\u7a33\u5b9a\u9ad8\u6548\u7684\u56e0\u679c\u5f71\u54cd\u529b\u6d4b\u91cf\u65b9\u6cd5\uff1b3) \u63d0\u51fa\u53ef\u9a8c\u8bc1\u5956\u52b1\u673a\u5236\uff0c\u5141\u8bb8\u63a8\u7406\u667a\u80fd\u4f53\u4e22\u5f03\u566a\u58f0\u8f93\u51fa\u3001\u6574\u5408\u6307\u4ee4\u5e76\u5728\u5fc5\u8981\u65f6\u91cd\u65b0\u542f\u52a8\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u6709\u6548\u7f13\u89e3\u4e86\u61d2\u60f0\u667a\u80fd\u4f53\u884c\u4e3a\uff0c\u91ca\u653e\u4e86\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5168\u90e8\u6f5c\u529b\u3002", "conclusion": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u63a8\u7406\u4e2d\u7684\u534f\u4f5c\u95ee\u9898\uff0c\u4e3a\u590d\u6742\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u3002"}}
{"id": "2511.02426", "categories": ["eess.SP", "cs.AI", "cs.CV", "cs.IT", "cs.SY", "eess.SY", "math.IT", "68T05 (Learning and adaptive systems)", "I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2511.02426", "abs": "https://arxiv.org/abs/2511.02426", "authors": ["Marios Impraimakis"], "title": "A Kullback-Leibler divergence method for input-system-state identification", "comment": "32 pages, 17 figures, published in Journal of Sound and Vibration", "summary": "The capability of a novel Kullback-Leibler divergence method is examined\nherein within the Kalman filter framework to select the input-parameter-state\nestimation execution with the most plausible results. This identification\nsuffers from the uncertainty related to obtaining different results from\ndifferent initial parameter set guesses, and the examined approach uses the\ninformation gained from the data in going from the prior to the posterior\ndistribution to address the issue. Firstly, the Kalman filter is performed for\na number of different initial parameter sets providing the system\ninput-parameter-state estimation. Secondly, the resulting posterior\ndistributions are compared simultaneously to the initial prior distributions\nusing the Kullback-Leibler divergence. Finally, the identification with the\nleast Kullback-Leibler divergence is selected as the one with the most\nplausible results. Importantly, the method is shown to select the better\nperformed identification in linear, nonlinear, and limited information\napplications, providing a powerful tool for system monitoring.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eKullback-Leibler\u6563\u5ea6\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u5361\u5c14\u66fc\u6ee4\u6ce2\u6846\u67b6\u4e2d\u9009\u62e9\u6700\u5408\u7406\u7684\u8f93\u5165-\u53c2\u6570-\u72b6\u6001\u4f30\u8ba1\u7ed3\u679c\uff0c\u901a\u8fc7\u6bd4\u8f83\u5148\u9a8c\u5206\u5e03\u548c\u540e\u9a8c\u5206\u5e03\u7684\u4fe1\u606f\u589e\u76ca\u6765\u89e3\u51b3\u521d\u59cb\u53c2\u6570\u96c6\u4e0d\u786e\u5b9a\u6027\u5e26\u6765\u7684\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u7cfb\u7edf\u8bc6\u522b\u4e2d\u7531\u4e8e\u4e0d\u540c\u521d\u59cb\u53c2\u6570\u96c6\u731c\u6d4b\u5bfc\u81f4\u7ed3\u679c\u4e0d\u786e\u5b9a\u6027\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u9009\u62e9\u6700\u5408\u7406\u7684\u4f30\u8ba1\u7ed3\u679c\u3002", "method": "1. \u5bf9\u591a\u4e2a\u4e0d\u540c\u521d\u59cb\u53c2\u6570\u96c6\u6267\u884c\u5361\u5c14\u66fc\u6ee4\u6ce2\uff1b2. \u4f7f\u7528Kullback-Leibler\u6563\u5ea6\u540c\u65f6\u6bd4\u8f83\u540e\u9a8c\u5206\u5e03\u4e0e\u5148\u9a8c\u5206\u5e03\uff1b3. \u9009\u62e9\u5177\u6709\u6700\u5c0fKullback-Leibler\u6563\u5ea6\u7684\u8bc6\u522b\u7ed3\u679c\u4f5c\u4e3a\u6700\u5408\u7406\u7684\u7ed3\u679c\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u7ebf\u6027\u3001\u975e\u7ebf\u6027\u548c\u6709\u9650\u4fe1\u606f\u5e94\u7528\u4e2d\u90fd\u80fd\u9009\u62e9\u6027\u80fd\u66f4\u597d\u7684\u8bc6\u522b\u7ed3\u679c\uff0c\u4e3a\u7cfb\u7edf\u76d1\u63a7\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u5de5\u5177\u3002", "conclusion": "\u57fa\u4e8eKullback-Leibler\u6563\u5ea6\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u521d\u59cb\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u5e26\u6765\u7684\u95ee\u9898\uff0c\u5728\u5404\u79cd\u5e94\u7528\u573a\u666f\u4e0b\u90fd\u80fd\u53ef\u9760\u5730\u9009\u62e9\u6700\u5408\u7406\u7684\u7cfb\u7edf\u8bc6\u522b\u7ed3\u679c\u3002"}}
{"id": "2511.02340", "categories": ["cs.AI", "q-bio.OT"], "pdf": "https://arxiv.org/pdf/2511.02340", "abs": "https://arxiv.org/abs/2511.02340", "authors": ["Yohan Lee", "DongGyun Kang", "SeHoon Park", "Sa-Yoon Park", "Kwangsoo Kim"], "title": "Chronic Kidney Disease Prognosis Prediction Using Transformer", "comment": "5 pages, 2 figures, 2 tables", "summary": "Chronic Kidney Disease (CKD) affects nearly 10\\% of the global population and\noften progresses to end-stage renal failure. Accurate prognosis prediction is\nvital for timely interventions and resource optimization. We present a\ntransformer-based framework for predicting CKD progression using multi-modal\nelectronic health records (EHR) from the Seoul National University Hospital\nOMOP Common Data Model. Our approach (\\textbf{ProQ-BERT}) integrates\ndemographic, clinical, and laboratory data, employing quantization-based\ntokenization for continuous lab values and attention mechanisms for\ninterpretability. The model was pretrained with masked language modeling and\nfine-tuned for binary classification tasks predicting progression from stage 3a\nto stage 5 across varying follow-up and assessment periods. Evaluated on a\ncohort of 91,816 patients, our model consistently outperformed CEHR-BERT,\nachieving ROC-AUC up to 0.995 and PR-AUC up to 0.989 for short-term prediction.\nThese results highlight the effectiveness of transformer architectures and\ntemporal design choices in clinical prognosis modeling, offering a promising\ndirection for personalized CKD care.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eTransformer\u7684ProQ-BERT\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u6162\u6027\u80be\u75c5\u8fdb\u5c55\uff0c\u6574\u5408\u591a\u6a21\u6001\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6570\u636e\uff0c\u572891,816\u60a3\u8005\u961f\u5217\u4e2d\u8868\u73b0\u4f18\u5f02\uff0cROC-AUC\u6700\u9ad8\u8fbe0.995\u3002", "motivation": "\u6162\u6027\u80be\u75c5\u5f71\u54cd\u5168\u7403\u8fd110%\u4eba\u53e3\uff0c\u51c6\u786e\u9884\u6d4b\u75be\u75c5\u8fdb\u5c55\u5bf9\u4e8e\u53ca\u65f6\u5e72\u9884\u548c\u8d44\u6e90\u4f18\u5316\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eTransformer\u7684\u6846\u67b6\uff0c\u6574\u5408\u4eba\u53e3\u7edf\u8ba1\u3001\u4e34\u5e8a\u548c\u5b9e\u9a8c\u5ba4\u6570\u636e\uff0c\u91c7\u7528\u91cf\u5316\u5206\u8bcd\u5904\u7406\u8fde\u7eed\u5b9e\u9a8c\u5ba4\u503c\uff0c\u4f7f\u7528\u6ce8\u610f\u529b\u673a\u5236\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\uff0c\u901a\u8fc7\u63a9\u7801\u8bed\u8a00\u5efa\u6a21\u9884\u8bad\u7ec3\u548c\u4e8c\u5143\u5206\u7c7b\u5fae\u8c03\u3002", "result": "\u572891,816\u60a3\u8005\u961f\u5217\u8bc4\u4f30\u4e2d\uff0c\u6a21\u578b\u6301\u7eed\u4f18\u4e8eCEHR-BERT\uff0c\u77ed\u671f\u9884\u6d4bROC-AUC\u8fbe0.995\uff0cPR-AUC\u8fbe0.989\u3002", "conclusion": "\u7ed3\u679c\u8868\u660eTransformer\u67b6\u6784\u548c\u65f6\u95f4\u8bbe\u8ba1\u9009\u62e9\u5728\u4e34\u5e8a\u9884\u540e\u5efa\u6a21\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u4e2a\u6027\u5316\u6162\u6027\u80be\u75c5\u62a4\u7406\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2511.02444", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.02444", "abs": "https://arxiv.org/abs/2511.02444", "authors": ["Vered Karp", "Aseel Omar", "Alejandro Cohen"], "title": "Adaptive Compressed Integrate-and-Fire Time Encoding Machine", "comment": null, "summary": "Integrate-and-Fire Time Encoding Machine (IF-TEM) is a power-efficient\nasynchronous sampler that converts analog signals into non-uniform time-domain\nsamples. Adaptive IF-TEM (AIF-TEM) improves this machine by adapting its\nprocess to the characteristics of the input signal, thereby reducing the\nsampling rate. Compressed IF-TEM (CIF-TEM) reduces bit usage by performing\nanalog compression before quantization. In this paper, we introduce a combined\nAdaptive Compressed IF-TEM (ACIF-TEM) -- a new sampler that leverages the two\nmachines, AIF-TEM and CIF-TEM, where each reinforces the effectiveness of the\nother. We propose an efficient adaptive clockless time-to-digital converter\n(TDC) architecture for the novel sampler that integrates the compression stage\nwithin the TDC, facilitating the realization of the intended integrated system.\n\\ifconf \\else We analyze the total bit usage, and contrast its performance with\nthat of IF-TEM, AIF-TEM, and CIF-TEM.\\fi Via an evaluation study, we\ndemonstrate that the proposed ACIF-TEM sampler achieves lower Mean Square Error\n(MSE) with fewer bits, offering compression gains of at least 3-bit out of\n9-bits over AIF-TEM and 60\\% compression over IF-TEM, for fixed recovery MSE\nwith real audio signals.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u81ea\u9002\u5e94\u548c\u538b\u7f29\u6280\u672f\u7684ACIF-TEM\u91c7\u6837\u5668\uff0c\u901a\u8fc7\u96c6\u6210AIF-TEM\u548cCIF-TEM\u7684\u4f18\u52bf\uff0c\u5728\u964d\u4f4e\u91c7\u6837\u7387\u548c\u6bd4\u7279\u4f7f\u7528\u7684\u540c\u65f6\u63d0\u9ad8\u4fe1\u53f7\u6062\u590d\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709IF-TEM\u91c7\u6837\u5668\u5b58\u5728\u91c7\u6837\u7387\u8f83\u9ad8\u548c\u6bd4\u7279\u4f7f\u7528\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u9700\u8981\u7ed3\u5408\u81ea\u9002\u5e94\u548c\u538b\u7f29\u6280\u672f\u6765\u4f18\u5316\u6027\u80fd\u3002", "method": "\u8bbe\u8ba1ACIF-TEM\u91c7\u6837\u5668\uff0c\u96c6\u6210\u81ea\u9002\u5e94IF-TEM\u548c\u538b\u7f29IF-TEM\uff0c\u5e76\u63d0\u51fa\u9ad8\u6548\u7684\u65e0\u65f6\u949f\u65f6\u95f4\u6570\u5b57\u8f6c\u6362\u5668\u67b6\u6784\uff0c\u5c06\u538b\u7f29\u9636\u6bb5\u96c6\u6210\u5230TDC\u4e2d\u3002", "result": "ACIF-TEM\u5728\u771f\u5b9e\u97f3\u9891\u4fe1\u53f7\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4AIF-TEM\u5b9e\u73b0\u81f3\u5c113\u4f4d\uff08\u51719\u4f4d\uff09\u7684\u538b\u7f29\u589e\u76ca\uff0c\u76f8\u6bd4IF-TEM\u5b9e\u73b060%\u7684\u538b\u7f29\uff0c\u5728\u56fa\u5b9a\u6062\u590dMSE\u4e0b\u4f7f\u7528\u66f4\u5c11\u6bd4\u7279\u3002", "conclusion": "ACIF-TEM\u91c7\u6837\u5668\u901a\u8fc7\u7ed3\u5408\u81ea\u9002\u5e94\u548c\u538b\u7f29\u6280\u672f\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u6bd4\u7279\u4f7f\u7528\u5e76\u63d0\u9ad8\u4e86\u4fe1\u53f7\u6062\u590d\u7cbe\u5ea6\uff0c\u4e3a\u9ad8\u6548\u4fe1\u53f7\u91c7\u6837\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.02392", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02392", "abs": "https://arxiv.org/abs/2511.02392", "authors": ["Muhammad Sheharyar Liaqat"], "title": "Fuzzy Soft Set Theory based Expert System for the Risk Assessment in Breast Cancer Patients", "comment": null, "summary": "Breast cancer remains one of the leading causes of mortality among women\nworldwide, with early diagnosis being critical for effective treatment and\nimproved survival rates. However, timely detection continues to be a challenge\ndue to the complex nature of the disease and variability in patient risk\nfactors. This study presents a fuzzy soft set theory-based expert system\ndesigned to assess the risk of breast cancer in patients using measurable\nclinical and physiological parameters. The proposed system integrates Body Mass\nIndex, Insulin Level, Leptin Level, Adiponectin Level, and age as input\nvariables to estimate breast cancer risk through a set of fuzzy inference rules\nand soft set computations. These parameters can be obtained from routine blood\nanalyses, enabling a non-invasive and accessible method for preliminary\nassessment. The dataset used for model development and validation was obtained\nfrom the UCI Machine Learning Repository. The proposed expert system aims to\nsupport healthcare professionals in identifying high-risk patients and\ndetermining the necessity of further diagnostic procedures such as biopsies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u7cca\u8f6f\u96c6\u7406\u8bba\u7684\u4e13\u5bb6\u7cfb\u7edf\uff0c\u4f7f\u7528BMI\u3001\u80f0\u5c9b\u7d20\u6c34\u5e73\u3001\u7626\u7d20\u6c34\u5e73\u3001\u8102\u8054\u7d20\u6c34\u5e73\u548c\u5e74\u9f84\u7b49\u4e34\u5e8a\u53c2\u6570\u6765\u8bc4\u4f30\u4e73\u817a\u764c\u98ce\u9669\u3002", "motivation": "\u4e73\u817a\u764c\u662f\u5168\u7403\u5973\u6027\u6b7b\u4ea1\u7684\u4e3b\u8981\u539f\u56e0\u4e4b\u4e00\uff0c\u65e9\u671f\u8bca\u65ad\u5bf9\u6709\u6548\u6cbb\u7597\u548c\u63d0\u9ad8\u751f\u5b58\u7387\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u75be\u75c5\u590d\u6742\u6027\u548c\u60a3\u8005\u98ce\u9669\u56e0\u7d20\u7684\u53d8\u5f02\u6027\uff0c\u53ca\u65f6\u68c0\u6d4b\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6a21\u7cca\u8f6f\u96c6\u7406\u8bba\u7684\u4e13\u5bb6\u7cfb\u7edf\uff0c\u6574\u5408BMI\u3001\u80f0\u5c9b\u7d20\u6c34\u5e73\u3001\u7626\u7d20\u6c34\u5e73\u3001\u8102\u8054\u7d20\u6c34\u5e73\u548c\u5e74\u9f84\u4f5c\u4e3a\u8f93\u5165\u53d8\u91cf\uff0c\u901a\u8fc7\u6a21\u7cca\u63a8\u7406\u89c4\u5219\u548c\u8f6f\u96c6\u8ba1\u7b97\u6765\u4f30\u8ba1\u4e73\u817a\u764c\u98ce\u9669\u3002", "result": "\u8be5\u7cfb\u7edf\u4f7f\u7528UCI\u673a\u5668\u5b66\u4e60\u5b58\u50a8\u5e93\u7684\u6570\u636e\u96c6\u8fdb\u884c\u5f00\u53d1\u548c\u9a8c\u8bc1\uff0c\u80fd\u591f\u901a\u8fc7\u5e38\u89c4\u8840\u6db2\u5206\u6790\u83b7\u5f97\u53c2\u6570\uff0c\u63d0\u4f9b\u65e0\u521b\u4e14\u6613\u4e8e\u83b7\u53d6\u7684\u521d\u6b65\u8bc4\u4f30\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u4e13\u5bb6\u7cfb\u7edf\u65e8\u5728\u5e2e\u52a9\u533b\u7597\u4e13\u4e1a\u4eba\u5458\u8bc6\u522b\u9ad8\u98ce\u9669\u60a3\u8005\uff0c\u5e76\u786e\u5b9a\u662f\u5426\u9700\u8981\u8fdb\u884c\u8fdb\u4e00\u6b65\u7684\u8bca\u65ad\u7a0b\u5e8f\uff08\u5982\u6d3b\u68c0\uff09\u3002"}}
{"id": "2511.02493", "categories": ["eess.SP", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.02493", "abs": "https://arxiv.org/abs/2511.02493", "authors": ["Ana P\u00e9rez-Neira", "Marc Martinez-Gost", "Miguel \u00c1ngel Lagunas"], "title": "Before AI Takes Over: Rethinking Nonlinear Signal Processing in Communications", "comment": "Submitted to npj Wireless Technology", "summary": "There is an urgent reflection on traditional nonlinear signal processing\nmethods in communications before Artificial Intelligence (AI) dominates the\nfield. It implies a need to reassess or reinterpret established theories and\ntools, highlighting the tension between data-driven and model-based approaches.\nThis paper calls for preserving valuable insights from classical signal\nprocessing while exploring how they can coexist or integrate with emerging AI\nmethods.", "AI": {"tldr": "\u672c\u6587\u547c\u5401\u5728AI\u4e3b\u5bfc\u901a\u4fe1\u9886\u57df\u4e4b\u524d\uff0c\u91cd\u65b0\u8bc4\u4f30\u4f20\u7edf\u975e\u7ebf\u6027\u4fe1\u53f7\u5904\u7406\u65b9\u6cd5\uff0c\u5f3a\u8c03\u6570\u636e\u9a71\u52a8\u4e0e\u6a21\u578b\u9a71\u52a8\u65b9\u6cd5\u4e4b\u95f4\u7684\u5f20\u529b\uff0c\u5e76\u63a2\u7d22\u7ecf\u5178\u4fe1\u53f7\u5904\u7406\u4e0e\u65b0\u5174AI\u65b9\u6cd5\u7684\u5171\u5b58\u4e0e\u6574\u5408\u3002", "motivation": "\u5728AI\u6280\u672f\u4e3b\u5bfc\u901a\u4fe1\u9886\u57df\u4e4b\u524d\uff0c\u8feb\u5207\u9700\u8981\u53cd\u601d\u4f20\u7edf\u7684\u975e\u7ebf\u6027\u4fe1\u53f7\u5904\u7406\u65b9\u6cd5\uff0c\u91cd\u65b0\u8bc4\u4f30\u6216\u91cd\u65b0\u89e3\u91ca\u5df2\u5efa\u7acb\u7684\u7406\u8bba\u548c\u5de5\u5177\uff0c\u7a81\u663e\u6570\u636e\u9a71\u52a8\u4e0e\u6a21\u578b\u9a71\u52a8\u65b9\u6cd5\u4e4b\u95f4\u7684\u5f20\u529b\u3002", "method": "\u901a\u8fc7\u53cd\u601d\u548c\u91cd\u65b0\u8bc4\u4f30\u4f20\u7edf\u975e\u7ebf\u6027\u4fe1\u53f7\u5904\u7406\u7406\u8bba\uff0c\u63a2\u7d22\u7ecf\u5178\u4fe1\u53f7\u5904\u7406\u4e0e\u65b0\u5174AI\u65b9\u6cd5\u7684\u5171\u5b58\u4e0e\u6574\u5408\u65b9\u5f0f\u3002", "result": "\u63d0\u51fa\u4e86\u5728AI\u65f6\u4ee3\u4fdd\u7559\u7ecf\u5178\u4fe1\u53f7\u5904\u7406\u5b9d\u8d35\u89c1\u89e3\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u63a2\u8ba8\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e0eAI\u65b9\u6cd5\u5982\u4f55\u534f\u540c\u5de5\u4f5c\u7684\u53ef\u80fd\u6027\u3002", "conclusion": "\u9700\u8981\u5728AI\u4e3b\u5bfc\u7684\u901a\u4fe1\u9886\u57df\u53d1\u5c55\u4e2d\uff0c\u65e2\u4fdd\u7559\u7ecf\u5178\u4fe1\u53f7\u5904\u7406\u7684\u5b9d\u8d35\u89c1\u89e3\uff0c\u53c8\u79ef\u6781\u63a2\u7d22\u5176\u4e0e\u65b0\u5174AI\u65b9\u6cd5\u7684\u6574\u5408\u8def\u5f84\uff0c\u5b9e\u73b0\u4f20\u7edf\u4e0e\u73b0\u4ee3\u65b9\u6cd5\u7684\u548c\u8c10\u5171\u5b58\u3002"}}
{"id": "2511.02573", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02573", "abs": "https://arxiv.org/abs/2511.02573", "authors": ["Anastasios T. Sotiropoulos", "Stavros Tsimpoukis", "Dimitrios Tyrovolas", "Sotiris Ioannidis", "George K. Karagiannidis", "Christos K. Liaskos"], "title": "RIS-Assisted 3D Spherical Splatting for Object Composition Visualization using Detection Transformers", "comment": "Submitted to IEEE ICC 2026", "summary": "The pursuit of immersive and structurally aware multimedia experiences has\nintensified interest in sensing modalities that reconstruct objects beyond the\nlimits of visible light. Conventional optical pipelines degrade under occlusion\nor low illumination, motivating the use of radio-frequency (RF) sensing, whose\nelectromagnetic waves penetrate materials and encode both geometric and\ncompositional information. Yet, uncontrolled multipath propagation restricts\nreconstruction accuracy. Recent advances in Programmable Wireless Environments\n(PWEs) mitigate this limitation by enabling software-defined manipulation of\npropagation through Reconfigurable Intelligent Surfaces (RISs), thereby\nproviding controllable illumination diversity. Building on this capability,\nthis work introduces a PWE-driven RF framework for three-dimensional object\nreconstruction using material-aware spherical primitives. The proposed approach\ncombines RIS-enabled field synthesis with a Detection Transformer (DETR) that\ninfers spatial and material parameters directly from extracted RF features.\nSimulation results confirm the framework's ability to approximate object\ngeometries and classify material composition with an overall accuracy of\n79.35%, marking an initial step toward programmable and physically grounded\nRF-based 3D object composition visualization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u7f16\u7a0b\u65e0\u7ebf\u73af\u5883(PWE)\u7684\u5c04\u9891\u6846\u67b6\uff0c\u4f7f\u7528\u6750\u6599\u611f\u77e5\u7403\u5f62\u57fa\u5143\u8fdb\u884c\u4e09\u7ef4\u7269\u4f53\u91cd\u5efa\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408RIS\u652f\u6301\u7684\u573a\u5408\u6210\u4e0e\u68c0\u6d4b\u53d8\u6362\u5668(DETR)\uff0c\u76f4\u63a5\u4ece\u63d0\u53d6\u7684RF\u7279\u5f81\u63a8\u65ad\u7a7a\u95f4\u548c\u6750\u6599\u53c2\u6570\u3002", "motivation": "\u4f20\u7edf\u5149\u5b66\u7ba1\u9053\u5728\u906e\u6321\u6216\u4f4e\u5149\u7167\u6761\u4ef6\u4e0b\u6027\u80fd\u4e0b\u964d\uff0c\u800c\u5c04\u9891\u4f20\u611f\u7684\u7535\u78c1\u6ce2\u80fd\u7a7f\u900f\u6750\u6599\u5e76\u7f16\u7801\u51e0\u4f55\u548c\u6210\u5206\u4fe1\u606f\u3002\u7136\u800c\uff0c\u4e0d\u53d7\u63a7\u5236\u7684\u591a\u5f84\u4f20\u64ad\u9650\u5236\u4e86\u91cd\u5efa\u7cbe\u5ea6\u3002\u53ef\u7f16\u7a0b\u65e0\u7ebf\u73af\u5883\u901a\u8fc7\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u5b9e\u73b0\u4f20\u64ad\u7684\u8f6f\u4ef6\u5b9a\u4e49\u64cd\u4f5c\uff0c\u63d0\u4f9b\u4e86\u53ef\u63a7\u7684\u7167\u660e\u591a\u6837\u6027\u3002", "method": "\u7ed3\u5408RIS\u652f\u6301\u7684\u573a\u5408\u6210\u4e0e\u68c0\u6d4b\u53d8\u6362\u5668(DETR)\uff0c\u76f4\u63a5\u4ece\u63d0\u53d6\u7684RF\u7279\u5f81\u63a8\u65ad\u7a7a\u95f4\u548c\u6750\u6599\u53c2\u6570\u3002\u4f7f\u7528\u6750\u6599\u611f\u77e5\u7403\u5f62\u57fa\u5143\u8fdb\u884c\u4e09\u7ef4\u7269\u4f53\u91cd\u5efa\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8bc1\u5b9e\u8be5\u6846\u67b6\u80fd\u591f\u8fd1\u4f3c\u7269\u4f53\u51e0\u4f55\u5f62\u72b6\u5e76\u4ee579.35%\u7684\u603b\u4f53\u51c6\u786e\u7387\u5206\u7c7b\u6750\u6599\u6210\u5206\u3002", "conclusion": "\u8fd9\u662f\u8fc8\u5411\u53ef\u7f16\u7a0b\u548c\u57fa\u4e8e\u7269\u7406\u7684\u5c04\u9891\u4e09\u7ef4\u7269\u4f53\u6210\u5206\u53ef\u89c6\u5316\u7684\u521d\u6b65\u6b65\u9aa4\u3002"}}
{"id": "2511.02463", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02463", "abs": "https://arxiv.org/abs/2511.02463", "authors": ["Mengyu Zhang", "Xubo Liu", "Siyu Ding", "Weichong Yin", "Yu Sun", "Hua Wu", "Wenya Guo", "Ying Zhang"], "title": "Auditable-choice reframing unlocks RL-based verification for open-ended tasks", "comment": "9 pages", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated great\npotential in enhancing the reasoning capabilities of large language models\n(LLMs), achieving remarkable progress in domains such as mathematics and\nprogramming where standard answers are available. However, for open-ended tasks\nlacking ground-truth solutions (e.g., creative writing and instruction\nfollowing), existing studies typically regard them as non-reasoning scenarios,\nthereby overlooking the latent value of reasoning capabilities. This raises a\nkey question: Can strengthening reasoning improve performance in open-ended\ntasks? To address this, we explore the transfer of the RLVR paradigm to the\nopen domain. Yet, since RLVR fundamentally relies on verifiers that presuppose\nthe existence of standard answers, it cannot be directly applied to open-ended\ntasks. To overcome this challenge, we introduce Verifiable Multiple-Choice\nReformulation (VMR), a novel training strategy that restructures open-ended\ndata into verifiable multiple-choice formats, enabling effective training even\nin the absence of explicit ground truth. Experimental results on multiple\nbenchmarks validate the effectiveness of our method in improving LLM\nperformance on open-ended tasks. Notably, across eight open-ended benchmarks,\nour VMR-based training delivers an average gain of 5.99 points over the\nbaseline. Code will be released upon acceptance to facilitate reproducibility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u9a8c\u8bc1\u591a\u9009\u62e9\u91cd\u6784\uff08VMR\uff09\u65b9\u6cd5\uff0c\u5c06\u5f3a\u5316\u5b66\u4e60\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u8303\u5f0f\u6269\u5c55\u5230\u5f00\u653e\u57df\u4efb\u52a1\uff0c\u901a\u8fc7\u5c06\u5f00\u653e\u6570\u636e\u91cd\u6784\u4e3a\u53ef\u9a8c\u8bc1\u7684\u591a\u9009\u62e9\u683c\u5f0f\u6765\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65e0\u6807\u51c6\u7b54\u6848\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709RLVR\u65b9\u6cd5\u5728\u6570\u5b66\u548c\u7f16\u7a0b\u7b49\u6709\u6807\u51c6\u7b54\u6848\u7684\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u7f3a\u4e4f\u6807\u51c6\u7b54\u6848\u7684\u5f00\u653e\u4efb\u52a1\uff08\u5982\u521b\u610f\u5199\u4f5c\u548c\u6307\u4ee4\u9075\u5faa\uff09\u4e2d\u88ab\u89c6\u4e3a\u975e\u63a8\u7406\u573a\u666f\uff0c\u5ffd\u7565\u4e86\u63a8\u7406\u80fd\u529b\u7684\u6f5c\u5728\u4ef7\u503c\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u63a8\u7406\u80fd\u529b\u662f\u5426\u80fd\u63d0\u5347\u5f00\u653e\u4efb\u52a1\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u53ef\u9a8c\u8bc1\u591a\u9009\u62e9\u91cd\u6784\uff08VMR\uff09\u8bad\u7ec3\u7b56\u7565\uff0c\u5c06\u5f00\u653e\u6570\u636e\u91cd\u6784\u4e3a\u53ef\u9a8c\u8bc1\u7684\u591a\u9009\u62e9\u683c\u5f0f\uff0c\u4ece\u800c\u5728\u7f3a\u4e4f\u660e\u786e\u6807\u51c6\u7b54\u6848\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6709\u6548\u8bad\u7ec3\uff0c\u4f7fRLVR\u8303\u5f0f\u80fd\u591f\u5e94\u7528\u4e8e\u5f00\u653e\u57df\u4efb\u52a1\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5f00\u653e\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002\u5728\u516b\u4e2a\u5f00\u653e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u57fa\u4e8eVMR\u7684\u8bad\u7ec3\u76f8\u6bd4\u57fa\u7ebf\u5e73\u5747\u63d0\u5347\u4e865.99\u5206\u3002", "conclusion": "VMR\u65b9\u6cd5\u6210\u529f\u5c06RLVR\u8303\u5f0f\u6269\u5c55\u5230\u5f00\u653e\u57df\uff0c\u8bc1\u660e\u4e86\u5f3a\u5316\u63a8\u7406\u80fd\u529b\u786e\u5b9e\u80fd\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5f00\u653e\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4e3a\u7f3a\u4e4f\u6807\u51c6\u7b54\u6848\u7684\u4efb\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8bad\u7ec3\u7b56\u7565\u3002"}}
{"id": "2511.01946", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2511.01946", "abs": "https://arxiv.org/abs/2511.01946", "authors": ["Zihan Li", "Mingyang Wan", "Mingyu Gao", "Zhongshan Chen", "Xiangke Wang", "Feifan Zhang"], "title": "COFAP: A Universal Framework for COFs Adsorption Prediction through Designed Multi-Modal Extraction and Cross-Modal Synergy", "comment": null, "summary": "Covalent organic frameworks (COFs) are promising adsorbents for gas\nadsorption and separation, while identifying the optimal structures among their\nvast design space requires efficient high-throughput screening. Conventional\nmachine-learning predictors rely heavily on specific gas-related features.\nHowever, these features are time-consuming and limit scalability, leading to\ninefficiency and labor-intensive processes. Herein, a universal COFs adsorption\nprediction framework (COFAP) is proposed, which can extract multi-modal\nstructural and chemical features through deep learning, and fuse these\ncomplementary features via cross-modal attention mechanism. Without Henry\ncoefficients or adsorption heat, COFAP sets a new SOTA by outperforming\nprevious approaches on hypoCOFs dataset. Based on COFAP, we also found that\nhigh-performing COFs for separation concentrate within a narrow range of pore\nsize and surface area. A weight-adjustable prioritization scheme is also\ndeveloped to enable flexible, application-specific ranking of candidate COFs\nfor researchers. Superior efficiency and accuracy render COFAP directly\ndeployable in crystalline porous materials.", "AI": {"tldr": "\u63d0\u51fa\u4e86COFAP\u6846\u67b6\uff0c\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u63d0\u53d6\u591a\u6a21\u6001\u7ed3\u6784\u5316\u5b66\u7279\u5f81\uff0c\u4f7f\u7528\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\u878d\u5408\u7279\u5f81\uff0c\u65e0\u9700\u4f20\u7edf\u6c14\u4f53\u76f8\u5173\u7279\u5f81\u5373\u53ef\u5b9e\u73b0COFs\u5438\u9644\u6027\u80fd\u7684\u9ad8\u6548\u9884\u6d4b\u3002", "motivation": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u5668\u4f9d\u8d56\u7279\u5b9a\u6c14\u4f53\u76f8\u5173\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u8ba1\u7b97\u8017\u65f6\u4e14\u9650\u5236\u53ef\u6269\u5c55\u6027\uff0c\u5bfc\u81f4\u7b5b\u9009COFs\u6700\u4f18\u7ed3\u6784\u6548\u7387\u4f4e\u4e0b\u4e14\u52b3\u52a8\u5bc6\u96c6\u3002", "method": "\u5f00\u53d1COFAP\u6846\u67b6\uff0c\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u63d0\u53d6\u591a\u6a21\u6001\u7ed3\u6784\u5316\u5b66\u7279\u5f81\uff0c\u4f7f\u7528\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\u878d\u5408\u4e92\u8865\u7279\u5f81\uff0c\u65e0\u9700Henry\u7cfb\u6570\u6216\u5438\u9644\u70ed\u7b49\u4f20\u7edf\u7279\u5f81\u3002", "result": "\u5728hypoCOFs\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u5148\u524d\u65b9\u6cd5\uff0c\u8fbe\u5230\u65b0\u7684SOTA\u6027\u80fd\uff1b\u53d1\u73b0\u9ad8\u6027\u80fd\u5206\u79bbCOFs\u96c6\u4e2d\u5728\u72ed\u7a84\u7684\u5b54\u5f84\u548c\u8868\u9762\u79ef\u8303\u56f4\u5185\uff1b\u5f00\u53d1\u4e86\u6743\u91cd\u53ef\u8c03\u4f18\u5148\u6392\u5e8f\u65b9\u6848\u3002", "conclusion": "COFAP\u5177\u6709\u5353\u8d8a\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u53ef\u76f4\u63a5\u5e94\u7528\u4e8e\u6676\u4f53\u591a\u5b54\u6750\u6599\u7684\u9ad8\u901a\u91cf\u7b5b\u9009\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u7075\u6d3b\u7684\u5e94\u7528\u7279\u5b9a\u5019\u9009COFs\u6392\u5e8f\u3002"}}
{"id": "2511.02689", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.02689", "abs": "https://arxiv.org/abs/2511.02689", "authors": ["Smilja Stokanovi\u0107", "Jaka Sodnik", "Nadica Miljkovi\u0107"], "title": "Eye Movement Analysis in Simulated Driving Scenarios", "comment": "29 pages, 6 figures, and 6 tables", "summary": "This study investigates eye movement behaviour during three conditions:\nBaseline, Ride (simulated drive under normal visibility), and Fog (simulated\ndrive under reduced visibility). Eye tracking data are analyzed using 31\nparameters, organized into three groups: (1) saccade features, (2) Bivariate\nContour Ellipse Area (BCEA), and (3) blinking features. Specifically, the\nanalysis includes 13 saccade, 13 BCEA, and 5 blinking variables. Across all\nfeature groups, numerous statistically significant differences emerge between\nBaseline and the driving conditions, particularly between Baseline and Ride or\nFog. Between Ride and Fog, saccade features show minimal changes (one out of\n13), whereas BCEA (9 of 13) and blink features (four of 5) exhibit pronounced\ndifferences, highlighting the strong impact of reduced visibility on gaze\nstability and blinking behaviour. In addition to conventional measures such as\nMean Squared Error (MSE) and entropy metrics, a new parameter, Guzik's Index\n(GI), is introduced to quantify fixation asymmetry along the major axis of the\nBCEA. This index utilizes eye tracking data to enhance the understanding of eye\nmovement dynamics during driving conditions. Separately from GI, other\nparameters elicit the largest deviations compared to Ride (e.g., number of\nsaccades: Cliff's $\\delta$ = 0.96, BCEA: Cohen's $\\textit{d}$ = 0.89, and\nstandard deviation of blink duration: Cliff's $\\delta$ = 0.80), underscoring\nthe influence of reduced visibility on visual attention. Overall, these\nfindings demonstrate that combining BCEA with saccade and blink parameters\nprovides a comprehensive understanding of visual attention and gaze stability,\nwhile GI offers additional insights into fixation asymmetry under varying\nvisibility conditions.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc731\u4e2a\u773c\u52a8\u53c2\u6570\u5206\u6790\u4e0d\u540c\u9a7e\u9a76\u6761\u4ef6\u4e0b\u7684\u773c\u52a8\u884c\u4e3a\uff0c\u53d1\u73b0\u96fe\u5929\u4f4e\u80fd\u89c1\u5ea6\u5bf9\u6ce8\u89c6\u7a33\u5b9a\u6027\u548c\u7728\u773c\u884c\u4e3a\u6709\u663e\u8457\u5f71\u54cd\uff0c\u5e76\u5f15\u5165Guzik\u6307\u6570\u91cf\u5316\u6ce8\u89c6\u4e0d\u5bf9\u79f0\u6027\u3002", "motivation": "\u7814\u7a76\u4e0d\u540c\u80fd\u89c1\u5ea6\u6761\u4ef6\u4e0b\uff08\u6b63\u5e38\u9a7e\u9a76\u548c\u96fe\u5929\u9a7e\u9a76\uff09\u7684\u773c\u52a8\u884c\u4e3a\u5dee\u5f02\uff0c\u7279\u522b\u662f\u5173\u6ce8\u4f4e\u80fd\u89c1\u5ea6\u5982\u4f55\u5f71\u54cd\u9a7e\u9a76\u5458\u7684\u89c6\u89c9\u6ce8\u610f\u529b\u548c\u6ce8\u89c6\u7a33\u5b9a\u6027\u3002", "method": "\u4f7f\u7528\u773c\u52a8\u8ffd\u8e2a\u6280\u672f\uff0c\u5728\u4e09\u79cd\u6761\u4ef6\u4e0b\uff08\u57fa\u7ebf\u3001\u6b63\u5e38\u9a7e\u9a76\u6a21\u62df\u3001\u96fe\u5929\u9a7e\u9a76\u6a21\u62df\uff09\u6536\u96c6\u6570\u636e\uff0c\u5206\u679013\u4e2a\u626b\u89c6\u7279\u5f81\u300113\u4e2aBCEA\uff08\u53cc\u53d8\u91cf\u8f6e\u5ed3\u692d\u5706\u9762\u79ef\uff09\u53c2\u6570\u548c5\u4e2a\u7728\u773c\u7279\u5f81\u3002", "result": "\u57fa\u7ebf\u4e0e\u9a7e\u9a76\u6761\u4ef6\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u96fe\u5929\u4e0e\u6b63\u5e38\u9a7e\u9a76\u76f8\u6bd4\uff0cBCEA\u53c2\u6570\uff089/13\uff09\u548c\u7728\u773c\u7279\u5f81\uff084/5\uff09\u53d8\u5316\u660e\u663e\uff0c\u626b\u89c6\u7279\u5f81\u53d8\u5316\u8f83\u5c0f\uff081/13\uff09\u3002\u5f15\u5165\u7684Guzik\u6307\u6570\u80fd\u6709\u6548\u91cf\u5316\u6ce8\u89c6\u4e0d\u5bf9\u79f0\u6027\u3002", "conclusion": "\u7ed3\u5408BCEA\u3001\u626b\u89c6\u548c\u7728\u773c\u53c2\u6570\u80fd\u5168\u9762\u7406\u89e3\u89c6\u89c9\u6ce8\u610f\u529b\u548c\u6ce8\u89c6\u7a33\u5b9a\u6027\uff0cGuzik\u6307\u6570\u4e3a\u4e0d\u540c\u80fd\u89c1\u5ea6\u6761\u4ef6\u4e0b\u7684\u6ce8\u89c6\u4e0d\u5bf9\u79f0\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u5206\u6790\u89c6\u89d2\u3002"}}
{"id": "2511.01950", "categories": ["cs.LG", "68T07, 68T05", "I.2.6; I.5.1; I.5.2; G.3"], "pdf": "https://arxiv.org/pdf/2511.01950", "abs": "https://arxiv.org/abs/2511.01950", "authors": ["Prasanth K K", "Shubham Sharma"], "title": "EchoLSTM: A Self-Reflective Recurrent Network for Stabilizing Long-Range Memory", "comment": "11 pages, 4 figures, 5 tables", "summary": "Standard Recurrent Neural Networks, including LSTMs, struggle to model\nlong-range dependencies, particularly in sequences containing noisy or\nmisleading information. We propose a new architectural principle,\nOutput-Conditioned Gating, which enables a model to perform self-reflection by\nmodulating its internal memory gates based on its own past inferences. This\ncreates a stabilizing feedback loop that enhances memory retention. Our final\nmodel, the EchoLSTM, integrates this principle with an attention mechanism. We\nevaluate the EchoLSTM on a series of challenging benchmarks. On a\ncustom-designed Distractor Signal Task, the EchoLSTM achieves 69.0% accuracy,\ndecisively outperforming a standard LSTM baseline by 33 percentage points.\nFurthermore, on the standard ListOps benchmark, the EchoLSTM achieves\nperformance competitive with a modern Transformer model, 69.8% vs. 71.8%, while\nbeing over 5 times more parameter-efficient. A final Trigger Sensitivity Test\nprovides qualitative evidence that our model's self-reflective mechanism leads\nto a fundamentally more robust memory system.", "AI": {"tldr": "\u63d0\u51fa\u8f93\u51fa\u6761\u4ef6\u95e8\u63a7\u65b0\u67b6\u6784\uff0c\u901a\u8fc7\u57fa\u4e8e\u8fc7\u53bb\u63a8\u7406\u8c03\u8282\u5185\u90e8\u8bb0\u5fc6\u95e8\u5b9e\u73b0\u81ea\u53cd\u601d\u7ef4\uff0c\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236\u5f62\u6210EchoLSTM\u6a21\u578b\uff0c\u5728\u957f\u5e8f\u5217\u4f9d\u8d56\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u6807\u51c6LSTM\uff0c\u4e14\u53c2\u6570\u6548\u7387\u9ad8\u4e8eTransformer", "motivation": "\u6807\u51c6RNN\u548cLSTM\u96be\u4ee5\u5efa\u6a21\u957f\u8ddd\u79bb\u4f9d\u8d56\u5173\u7cfb\uff0c\u7279\u522b\u662f\u5728\u5305\u542b\u566a\u58f0\u6216\u8bef\u5bfc\u4fe1\u606f\u7684\u5e8f\u5217\u4e2d\uff0c\u9700\u8981\u66f4\u7a33\u5065\u7684\u8bb0\u5fc6\u7cfb\u7edf", "method": "\u63d0\u51fa\u8f93\u51fa\u6761\u4ef6\u95e8\u63a7\u67b6\u6784\u539f\u5219\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u57fa\u4e8e\u81ea\u8eab\u8fc7\u53bb\u63a8\u7406\u8fdb\u884c\u81ea\u53cd\u601d\u7ef4\u8c03\u8282\u5185\u90e8\u8bb0\u5fc6\u95e8\uff0c\u5f62\u6210\u7a33\u5b9a\u53cd\u9988\u5faa\u73af\u589e\u5f3a\u8bb0\u5fc6\u4fdd\u6301\uff0c\u6700\u7ec8\u6a21\u578bEchoLSTM\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236", "result": "\u5728Distractor Signal Task\u4e0a\u8fbe\u523069.0%\u51c6\u786e\u7387\uff0c\u6bd4\u6807\u51c6LSTM\u57fa\u7ebf\u63d0\u9ad833\u4e2a\u767e\u5206\u70b9\uff1b\u5728ListOps\u57fa\u51c6\u4e0a\u8fbe\u523069.8%\u6027\u80fd\uff0c\u4e0eTransformer\u768471.8%\u76f8\u5f53\uff0c\u4f46\u53c2\u6570\u6548\u7387\u9ad85\u500d\u4ee5\u4e0a", "conclusion": "\u81ea\u53cd\u601d\u7ef4\u673a\u5236\u4f7f\u6a21\u578b\u5177\u6709\u66f4\u7a33\u5065\u7684\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u8f93\u51fa\u6761\u4ef6\u95e8\u63a7\u662f\u5904\u7406\u957f\u5e8f\u5217\u4f9d\u8d56\u7684\u6709\u6548\u65b9\u6cd5"}}
{"id": "2511.02717", "categories": ["eess.SP", "cs.AI", "cs.CV", "cs.SY", "eess.AS", "eess.SY", "68T05 (Learning and adaptive systems)", "I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2511.02717", "abs": "https://arxiv.org/abs/2511.02717", "authors": ["Marios Impraimakis", "Andrew W. Smyth"], "title": "An unscented Kalman filter method for real time input-parameter-state estimation", "comment": "author-accepted manuscript (AAM) published in Mechanical Systems and\n  Signal Processing", "summary": "The input-parameter-state estimation capabilities of a novel unscented Kalman\nfilter is examined herein on both linear and nonlinear systems. The unknown\ninput is estimated in two stages within each time step. Firstly, the predicted\ndynamic states and the system parameters provide an estimation of the input.\nSecondly, the corrected with measurements states and parameters provide a final\nestimation. Importantly, it is demonstrated using the perturbation analysis\nthat, a system with at least a zero or a non-zero known input can potentially\nbe uniquely identified. This output-only methodology allows for a better\nunderstanding of the system compared to classical output-only parameter\nidentification strategies, given that all the dynamic states, the parameters,\nand the input are estimated jointly and in real-time.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e00\u79cd\u65b0\u578b\u65e0\u8ff9\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u5728\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u7cfb\u7edf\u4e2d\u7684\u8f93\u5165-\u53c2\u6570-\u72b6\u6001\u4f30\u8ba1\u80fd\u529b\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u65b9\u6cd5\u5728\u5355\u4e2a\u65f6\u95f4\u6b65\u5185\u4f30\u8ba1\u672a\u77e5\u8f93\u5165\uff0c\u5e76\u8bc1\u660e\u5177\u6709\u5df2\u77e5\u96f6\u6216\u975e\u96f6\u8f93\u5165\u7684\u7cfb\u7edf\u53ef\u88ab\u552f\u4e00\u8bc6\u522b\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u4f30\u8ba1\u52a8\u6001\u72b6\u6001\u3001\u53c2\u6570\u548c\u8f93\u5165\u7684\u8f93\u51fa\u4e13\u7528\u65b9\u6cd5\uff0c\u4ee5\u63d0\u4f9b\u6bd4\u4f20\u7edf\u8f93\u51fa\u4e13\u7528\u53c2\u6570\u8bc6\u522b\u7b56\u7565\u66f4\u597d\u7684\u7cfb\u7edf\u7406\u89e3\u3002", "method": "\u4f7f\u7528\u65b0\u578b\u65e0\u8ff9\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\uff0c\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u5185\u5206\u4e24\u9636\u6bb5\u4f30\u8ba1\u672a\u77e5\u8f93\u5165\uff1a\u9996\u5148\u57fa\u4e8e\u9884\u6d4b\u7684\u52a8\u6001\u72b6\u6001\u548c\u7cfb\u7edf\u53c2\u6570\u4f30\u8ba1\u8f93\u5165\uff0c\u7136\u540e\u57fa\u4e8e\u6d4b\u91cf\u6821\u6b63\u540e\u7684\u72b6\u6001\u548c\u53c2\u6570\u63d0\u4f9b\u6700\u7ec8\u4f30\u8ba1\u3002", "result": "\u901a\u8fc7\u6270\u52a8\u5206\u6790\u8bc1\u660e\uff0c\u5177\u6709\u81f3\u5c11\u4e00\u4e2a\u96f6\u6216\u975e\u96f6\u5df2\u77e5\u8f93\u5165\u7684\u7cfb\u7edf\u53ef\u80fd\u88ab\u552f\u4e00\u8bc6\u522b\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u65f6\u8054\u5408\u4f30\u8ba1\u6240\u6709\u52a8\u6001\u72b6\u6001\u3001\u53c2\u6570\u548c\u8f93\u5165\u3002", "conclusion": "\u8be5\u8f93\u51fa\u4e13\u7528\u65b9\u6cd5\u76f8\u6bd4\u4f20\u7edf\u7b56\u7565\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u7cfb\u7edf\u7406\u89e3\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u52a8\u6001\u72b6\u6001\u3001\u53c2\u6570\u548c\u8f93\u5165\u7684\u5b9e\u65f6\u8054\u5408\u4f30\u8ba1\u3002"}}
{"id": "2511.02728", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.02728", "abs": "https://arxiv.org/abs/2511.02728", "authors": ["Kaluguri Yashaswini", "Anshu Arora", "Satish Mulleti"], "title": "A Non-Uniform Quantization Framework for Time-Encoding Machines", "comment": "5 pages", "summary": "Time encoding machines (TEMs) provide an event-driven alternative to\nclassical uniform sampling, enabling power-efficient representations without a\nglobal clock. While prior work analyzed uniform quantization (UQ) of firing\nintervals, we show that these intervals are inherently non-uniformly\ndistributed, motivating the use of non-uniform quantization (NUQ). We derive\nthe probability distribution of firing intervals for a class of bandlimited\nsignals and design a power-law-based NUQ scheme tailored to this distribution.\nSimulations demonstrate that NUQ significantly outperforms UQ under the same\nbit budget. We also compare TEMs with non-uniform sampling (NUS), where both\namplitudes and timings require quantization, and show that TEM--NUQ achieves\nlower error at half the transmission cost. These results highlight the\nadvantages of distribution-aware quantization and establish TEM--NUQ as an\nefficient alternative to conventional UQ and NUS schemes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u65f6\u95f4\u7f16\u7801\u673a\u5668(TEMs)\u7684\u975e\u5747\u5300\u91cf\u5316\u65b9\u6848(NUQ)\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684\u5747\u5300\u91cf\u5316(UQ)\u548c\u975e\u5747\u5300\u91c7\u6837(NUS)\uff0c\u5728\u76f8\u540c\u6bd4\u7279\u9884\u7b97\u4e0b\u663e\u8457\u964d\u4f4e\u4e86\u91cf\u5316\u8bef\u5dee\uff0c\u4f20\u8f93\u6210\u672c\u51cf\u534a\u3002", "motivation": "\u4f20\u7edf\u7684\u65f6\u95f4\u7f16\u7801\u673a\u5668\u4f7f\u7528\u5747\u5300\u91cf\u5316\u5904\u7406\u89e6\u53d1\u95f4\u9694\uff0c\u4f46\u7814\u7a76\u53d1\u73b0\u8fd9\u4e9b\u95f4\u9694\u672c\u8d28\u4e0a\u662f\u975e\u5747\u5300\u5206\u5e03\u7684\uff0c\u56e0\u6b64\u9700\u8981\u8bbe\u8ba1\u66f4\u9002\u5408\u7684\u975e\u5747\u5300\u91cf\u5316\u65b9\u6848\u3002", "method": "\u63a8\u5bfc\u4e86\u5e26\u9650\u4fe1\u53f7\u7c7b\u4e2d\u89e6\u53d1\u95f4\u9694\u7684\u6982\u7387\u5206\u5e03\uff0c\u5e76\u57fa\u4e8e\u6b64\u5206\u5e03\u8bbe\u8ba1\u4e86\u5e42\u5f8b\u975e\u5747\u5300\u91cf\u5316\u65b9\u6848\u3002", "result": "\u4eff\u771f\u8868\u660e\uff0c\u5728\u76f8\u540c\u6bd4\u7279\u9884\u7b97\u4e0b\uff0cNUQ\u663e\u8457\u4f18\u4e8eUQ\u3002\u4e0e\u9700\u8981\u91cf\u5316\u5e45\u5ea6\u548c\u65f6\u95f4\u7684NUS\u76f8\u6bd4\uff0cTEM-NUQ\u4ee5\u4e00\u534a\u7684\u4f20\u8f93\u6210\u672c\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u8bef\u5dee\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u51f8\u663e\u4e86\u5206\u5e03\u611f\u77e5\u91cf\u5316\u7684\u4f18\u52bf\uff0c\u786e\u7acb\u4e86TEM-NUQ\u4f5c\u4e3a\u4f20\u7edfUQ\u548cNUS\u65b9\u6848\u7684\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2511.02823", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02823", "abs": "https://arxiv.org/abs/2511.02823", "authors": ["Chloe Loughridge", "Paul Colognese", "Avery Griffin", "Tyler Tracy", "Jon Kutasov", "Joe Benton"], "title": "Optimizing AI Agent Attacks With Synthetic Data", "comment": null, "summary": "As AI deployments become more complex and high-stakes, it becomes\nincreasingly important to be able to estimate their risk. AI control is one\nframework for doing so. However, good control evaluations require eliciting\nstrong attack policies. This can be challenging in complex agentic environments\nwhere compute constraints leave us data-poor. In this work, we show how to\noptimize attack policies in SHADE-Arena, a dataset of diverse realistic control\nenvironments. We do this by decomposing attack capability into five constituent\nskills -- suspicion modeling, attack selection, plan synthesis, execution and\nsubtlety -- and optimizing each component individually. To get around the\nconstraint of limited data, we develop a probabilistic model of attack\ndynamics, optimize our attack hyperparameters using this simulation, and then\nshow that the results transfer to SHADE-Arena. This results in a substantial\nimprovement in attack strength, reducing safety score from a baseline of 0.87\nto 0.41 using our scaffold.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u590d\u6742AI\u73af\u5883\u4e2d\u4f18\u5316\u653b\u51fb\u7b56\u7565\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u653b\u51fb\u80fd\u529b\u5206\u89e3\u4e3a\u4e94\u4e2a\u6838\u5fc3\u6280\u80fd\u5e76\u5206\u522b\u4f18\u5316\uff0c\u5728\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u653b\u51fb\u5f3a\u5ea6\u3002", "motivation": "\u968f\u7740AI\u90e8\u7f72\u53d8\u5f97\u66f4\u52a0\u590d\u6742\u548c\u9ad8\u98ce\u9669\uff0c\u51c6\u786e\u8bc4\u4f30\u5176\u98ce\u9669\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002AI\u63a7\u5236\u6846\u67b6\u9700\u8981\u5f3a\u5927\u7684\u653b\u51fb\u7b56\u7565\uff0c\u4f46\u5728\u590d\u6742\u667a\u80fd\u4f53\u73af\u5883\u4e2d\uff0c\u8ba1\u7b97\u7ea6\u675f\u5bfc\u81f4\u6570\u636e\u4e0d\u8db3\uff0c\u8fd9\u7ed9\u653b\u51fb\u7b56\u7565\u7684\u4f18\u5316\u5e26\u6765\u4e86\u6311\u6218\u3002", "method": "\u5c06\u653b\u51fb\u80fd\u529b\u5206\u89e3\u4e3a\u4e94\u4e2a\u7ec4\u6210\u6280\u80fd\uff1a\u6000\u7591\u5efa\u6a21\u3001\u653b\u51fb\u9009\u62e9\u3001\u8ba1\u5212\u5408\u6210\u3001\u6267\u884c\u548c\u9690\u853d\u6027\uff0c\u5e76\u5206\u522b\u4f18\u5316\u6bcf\u4e2a\u7ec4\u4ef6\u3002\u4e3a\u4e86\u89e3\u51b3\u6570\u636e\u6709\u9650\u7684\u95ee\u9898\uff0c\u5f00\u53d1\u4e86\u653b\u51fb\u52a8\u6001\u7684\u6982\u7387\u6a21\u578b\uff0c\u5728\u6a21\u62df\u4e2d\u4f18\u5316\u653b\u51fb\u8d85\u53c2\u6570\uff0c\u7136\u540e\u5c06\u7ed3\u679c\u8fc1\u79fb\u5230SHADE-Arena\u73af\u5883\u4e2d\u3002", "result": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u653b\u51fb\u5f3a\u5ea6\uff0c\u5c06\u5b89\u5168\u5206\u6570\u4ece\u57fa\u7ebf0.87\u964d\u4f4e\u52300.41\uff0c\u8868\u660e\u653b\u51fb\u6548\u679c\u5f97\u5230\u4e86\u5b9e\u8d28\u6027\u6539\u5584\u3002", "conclusion": "\u901a\u8fc7\u6280\u80fd\u5206\u89e3\u548c\u6982\u7387\u5efa\u6a21\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u6570\u636e\u6709\u9650\u7684\u590d\u6742\u73af\u5883\u4e2d\u6709\u6548\u4f18\u5316\u653b\u51fb\u7b56\u7565\uff0c\u4e3aAI\u98ce\u9669\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u5de5\u5177\u3002"}}
{"id": "2511.02047", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02047", "abs": "https://arxiv.org/abs/2511.02047", "authors": ["Hamidreza Sadeghsalehi"], "title": "A Dual-Use Framework for Clinical Gait Analysis: Attention-Based Sensor Optimization and Automated Dataset Auditing", "comment": null, "summary": "Objective gait analysis using wearable sensors and AI is critical for\nmanaging neurological and orthopedic conditions. However, models are vulnerable\nto hidden dataset biases, and task-specific sensor optimization remains a\nchallenge. We propose a multi-stream attention-based deep learning framework\nthat functions as both a sensor optimizer and an automated data auditor.\nApplied to the Voisard et al. (2025) multi-cohort gait dataset on four clinical\ntasks (PD, OA, CVA screening; PD vs CVA differential), the model's attention\nmechanism quantitatively discovered a severe dataset confound. For OA and CVA\nscreening, tasks where bilateral assessment is clinically essential, the model\nassigned more than 70 percent attention to the Right Foot while statistically\nignoring the Left Foot (less than 0.1 percent attention, 95 percent CI\n[0.0-0.1]). This was not a clinical finding but a direct reflection of a severe\nlaterality bias (for example, 15 of 15 right-sided OA) in the public dataset.\nThe primary contribution of this work is methodological, demonstrating that an\ninterpretable framework can automatically audit dataset integrity. As a\nsecondary finding, the model proposes novel, data-driven sensor synergies (for\nexample, Head plus Foot for PD screening) as hypotheses for future optimized\nprotocols.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6d41\u6ce8\u610f\u529b\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u65e2\u80fd\u4f18\u5316\u4f20\u611f\u5668\u914d\u7f6e\uff0c\u53c8\u80fd\u81ea\u52a8\u5ba1\u8ba1\u6570\u636e\u8d28\u91cf\u3002\u5728\u6b65\u6001\u5206\u6790\u6570\u636e\u4e2d\u53d1\u73b0\u4e25\u91cd\u7684\u4fa7\u5411\u6027\u504f\u5dee\u95ee\u9898\u3002", "motivation": "\u53ef\u7a7f\u6234\u4f20\u611f\u5668\u548cAI\u5728\u5ba2\u89c2\u6b65\u6001\u5206\u6790\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u6a21\u578b\u5bb9\u6613\u53d7\u5230\u9690\u85cf\u6570\u636e\u96c6\u504f\u5dee\u7684\u5f71\u54cd\uff0c\u4e14\u4efb\u52a1\u7279\u5b9a\u7684\u4f20\u611f\u5668\u4f18\u5316\u4ecd\u5177\u6311\u6218\u6027\u3002", "method": "\u4f7f\u7528\u591a\u6d41\u6ce8\u610f\u529b\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236\u6765\u53d1\u73b0\u6570\u636e\u96c6\u504f\u5dee\u5e76\u4f18\u5316\u4f20\u611f\u5668\u914d\u7f6e\u3002", "result": "\u6a21\u578b\u6ce8\u610f\u529b\u673a\u5236\u5b9a\u91cf\u53d1\u73b0\u4e86\u4e25\u91cd\u7684\u6570\u636e\u96c6\u6df7\u6dc6\u95ee\u9898\uff0c\u4f8b\u5982\u5728OA\u548cCVA\u7b5b\u67e5\u4efb\u52a1\u4e2d\uff0c\u8d85\u8fc770%\u7684\u6ce8\u610f\u529b\u5206\u914d\u7ed9\u53f3\u811a\uff0c\u800c\u5de6\u811a\u51e0\u4e4e\u88ab\u5ffd\u7565\uff08<0.1%\uff09\uff0c\u8fd9\u53cd\u6620\u4e86\u516c\u5171\u6570\u636e\u96c6\u4e2d\u4e25\u91cd\u7684\u4fa7\u5411\u6027\u504f\u5dee\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u7684\u4e3b\u8981\u8d21\u732e\u662f\u65b9\u6cd5\u5b66\u4e0a\u7684\uff0c\u8bc1\u660e\u53ef\u89e3\u91ca\u6846\u67b6\u53ef\u4ee5\u81ea\u52a8\u5ba1\u8ba1\u6570\u636e\u96c6\u5b8c\u6574\u6027\u3002\u4f5c\u4e3a\u6b21\u8981\u53d1\u73b0\uff0c\u6a21\u578b\u63d0\u51fa\u4e86\u65b0\u9896\u7684\u6570\u636e\u9a71\u52a8\u4f20\u611f\u5668\u534f\u540c\u4f5c\u7528\uff0c\u4e3a\u672a\u6765\u4f18\u5316\u534f\u8bae\u63d0\u4f9b\u5047\u8bbe\u3002"}}
{"id": "2511.02089", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.02089", "abs": "https://arxiv.org/abs/2511.02089", "authors": ["Stefan F. Schouten", "Peter Bloem"], "title": "LLM Probing with Contrastive Eigenproblems: Improving Understanding and Applicability of CCS", "comment": "Accepted to the Mechanistic Interpretability Workshop at NeurIPS 2025", "summary": "Contrast-Consistent Search (CCS) is an unsupervised probing method able to\ntest whether large language models represent binary features, such as sentence\ntruth, in their internal activations. While CCS has shown promise, its two-term\nobjective has been only partially understood. In this work, we revisit CCS with\nthe aim of clarifying its mechanisms and extending its applicability. We argue\nthat what should be optimized for, is relative contrast consistency. Building\non this insight, we reformulate CCS as an eigenproblem, yielding closed-form\nsolutions with interpretable eigenvalues and natural extensions to multiple\nvariables. We evaluate these approaches across a range of datasets, finding\nthat they recover similar performance to CCS, while avoiding problems around\nsensitivity to random initialization. Our results suggest that relativizing\ncontrast consistency not only improves our understanding of CCS but also opens\npathways for broader probing and mechanistic interpretability methods.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u5ba1\u89c6\u4e86\u5bf9\u6bd4\u4e00\u81f4\u6027\u641c\u7d22(CCS)\u65b9\u6cd5\uff0c\u5c06\u5176\u91cd\u65b0\u8868\u8ff0\u4e3a\u7279\u5f81\u503c\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u95ed\u5f0f\u89e3\u548c\u53ef\u89e3\u91ca\u7684\u7279\u5f81\u503c\uff0c\u5e76\u6269\u5c55\u5230\u591a\u53d8\u91cf\u60c5\u51b5\uff0c\u907f\u514d\u4e86\u968f\u673a\u521d\u59cb\u5316\u7684\u654f\u611f\u6027\u95ee\u9898\u3002", "motivation": "CCS\u662f\u4e00\u79cd\u65e0\u76d1\u7763\u63a2\u6d4b\u65b9\u6cd5\uff0c\u7528\u4e8e\u6d4b\u8bd5\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u5728\u5176\u5185\u90e8\u6fc0\u6d3b\u4e2d\u8868\u793a\u4e8c\u5143\u7279\u5f81\u3002\u867d\u7136CCS\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5176\u53cc\u9879\u76ee\u6807\u51fd\u6570\u4ec5\u88ab\u90e8\u5206\u7406\u89e3\u3002\u672c\u6587\u65e8\u5728\u6f84\u6e05\u5176\u673a\u5236\u5e76\u6269\u5c55\u5176\u9002\u7528\u6027\u3002", "method": "\u57fa\u4e8e\u76f8\u5bf9\u5bf9\u6bd4\u4e00\u81f4\u6027\u7684\u6d1e\u5bdf\uff0c\u5c06CCS\u91cd\u65b0\u8868\u8ff0\u4e3a\u7279\u5f81\u503c\u95ee\u9898\uff0c\u83b7\u5f97\u5177\u6709\u53ef\u89e3\u91ca\u7279\u5f81\u503c\u7684\u95ed\u5f0f\u89e3\uff0c\u5e76\u81ea\u7136\u6269\u5c55\u5230\u591a\u53d8\u91cf\u60c5\u51b5\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u8fd9\u4e9b\u65b9\u6cd5\uff0c\u53d1\u73b0\u5b83\u4eec\u6062\u590d\u4e86\u4e0eCCS\u76f8\u4f3c\u7684\u6027\u80fd\uff0c\u540c\u65f6\u907f\u514d\u4e86\u968f\u673a\u521d\u59cb\u5316\u7684\u654f\u611f\u6027\u95ee\u9898\u3002", "conclusion": "\u76f8\u5bf9\u5316\u5bf9\u6bd4\u4e00\u81f4\u6027\u4e0d\u4ec5\u6539\u8fdb\u4e86\u5bf9CCS\u7684\u7406\u89e3\uff0c\u8fd8\u4e3a\u66f4\u5e7f\u6cdb\u7684\u63a2\u6d4b\u548c\u673a\u68b0\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u5f00\u8f9f\u4e86\u9014\u5f84\u3002"}}
{"id": "2511.02100", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.02100", "abs": "https://arxiv.org/abs/2511.02100", "authors": ["Rodrigo Mendoza-Smith"], "title": "Geometric Data Valuation via Leverage Scores", "comment": "MLxOR: Mathematical Foundations and Operational Integration of\n  Machine Learning for Uncertainty-Aware Decision-Making (NeurIPS 2025)", "summary": "Shapley data valuation provides a principled, axiomatic framework for\nassigning importance to individual datapoints, and has gained traction in\ndataset curation, pruning, and pricing. However, it is a combinatorial measure\nthat requires evaluating marginal utility across all subsets of the data,\nmaking it computationally infeasible at scale. We propose a geometric\nalternative based on statistical leverage scores, which quantify each\ndatapoint's structural influence in the representation space by measuring how\nmuch it extends the span of the dataset and contributes to the effective\ndimensionality of the training problem. We show that our scores satisfy the\ndummy, efficiency, and symmetry axioms of Shapley valuation and that extending\nthem to \\emph{ridge leverage scores} yields strictly positive marginal gains\nthat connect naturally to classical A- and D-optimal design criteria. We\nfurther show that training on a leverage-sampled subset produces a model whose\nparameters and predictive risk are within $O(\\varepsilon)$ of the full-data\noptimum, thereby providing a rigorous link between data valuation and\ndownstream decision quality. Finally, we conduct an active learning experiment\nin which we empirically demonstrate that ridge-leverage sampling outperforms\nstandard baselines without requiring access gradients or backward passes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7edf\u8ba1\u6760\u6746\u5f97\u5206\u7684\u51e0\u4f55\u66ff\u4ee3\u65b9\u6cd5\uff0c\u7528\u4e8e\u6570\u636e\u4f30\u503c\uff0c\u89e3\u51b3\u4e86Shapley\u503c\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u7684\u95ee\u9898\uff0c\u5e76\u5728\u4e3b\u52a8\u5b66\u4e60\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "Shapley\u6570\u636e\u4f30\u503c\u867d\u7136\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u7684\u6570\u636e\u91cd\u8981\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u4f46\u7531\u4e8e\u9700\u8981\u8bc4\u4f30\u6240\u6709\u6570\u636e\u5b50\u96c6\u7684\u8fb9\u9645\u6548\u7528\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u96be\u4ee5\u5728\u5927\u89c4\u6a21\u6570\u636e\u4e0a\u5e94\u7528\u3002", "method": "\u91c7\u7528\u7edf\u8ba1\u6760\u6746\u5f97\u5206\u4f5c\u4e3a\u51e0\u4f55\u66ff\u4ee3\u65b9\u6cd5\uff0c\u91cf\u5316\u6bcf\u4e2a\u6570\u636e\u70b9\u5728\u8868\u793a\u7a7a\u95f4\u4e2d\u7684\u7ed3\u6784\u5f71\u54cd\uff0c\u901a\u8fc7\u6d4b\u91cf\u5176\u5bf9\u6570\u636e\u96c6\u8de8\u5ea6\u6269\u5c55\u548c\u8bad\u7ec3\u95ee\u9898\u6709\u6548\u7ef4\u5ea6\u7684\u8d21\u732e\u3002", "result": "\u6760\u6746\u5f97\u5206\u6ee1\u8db3Shapley\u4f30\u503c\u7684\u865a\u62df\u6027\u3001\u6548\u7387\u548c\u5bf9\u79f0\u6027\u516c\u7406\uff0c\u5cad\u6760\u6746\u5f97\u5206\u5177\u6709\u4e25\u683c\u6b63\u7684\u8fb9\u9645\u589e\u76ca\uff0c\u4e0e\u7ecf\u5178A-\u548cD-\u6700\u4f18\u8bbe\u8ba1\u51c6\u5219\u81ea\u7136\u8fde\u63a5\u3002\u8bad\u7ec3\u6760\u6746\u91c7\u6837\u5b50\u96c6\u5f97\u5230\u7684\u6a21\u578b\u53c2\u6570\u548c\u9884\u6d4b\u98ce\u9669\u4e0e\u5168\u6570\u636e\u6700\u4f18\u89e3\u76f8\u5deeO(\u03b5)\u3002", "conclusion": "\u57fa\u4e8e\u6760\u6746\u5f97\u5206\u7684\u6570\u636e\u4f30\u503c\u65b9\u6cd5\u4e0d\u4ec5\u8ba1\u7b97\u9ad8\u6548\uff0c\u800c\u4e14\u4e0e\u4e0b\u6e38\u51b3\u7b56\u8d28\u91cf\u6709\u4e25\u683c\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u5728\u4e3b\u52a8\u5b66\u4e60\u4e2d\u4f18\u4e8e\u6807\u51c6\u57fa\u7ebf\u65b9\u6cd5\uff0c\u65e0\u9700\u68af\u5ea6\u6216\u53cd\u5411\u4f20\u64ad\u3002"}}
{"id": "2511.02101", "categories": ["cs.LG", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.02101", "abs": "https://arxiv.org/abs/2511.02101", "authors": ["Arjun Rao", "Marc Ru\u00dfwurm", "Konstantin Klemmer", "Esther Rolf"], "title": "Measuring the Intrinsic Dimension of Earth Representations", "comment": "Pre-print. 27 pages, 11 figures, 6 tables", "summary": "Within the context of representation learning for Earth observation,\ngeographic Implicit Neural Representations (INRs) embed low-dimensional\nlocation inputs (longitude, latitude) into high-dimensional embeddings, through\nmodels trained on geo-referenced satellite, image or text data. Despite the\ncommon aim of geographic INRs to distill Earth's data into compact,\nlearning-friendly representations, we lack an understanding of how much\ninformation is contained in these Earth representations, and where that\ninformation is concentrated. The intrinsic dimension of a dataset measures the\nnumber of degrees of freedom required to capture its local variability,\nregardless of the ambient high-dimensional space in which it is embedded. This\nwork provides the first study of the intrinsic dimensionality of geographic\nINRs. Analyzing INRs with ambient dimension between 256 and 512, we find that\ntheir intrinsic dimensions fall roughly between 2 and 10 and are sensitive to\nchanging spatial resolution and input modalities during INR pre-training.\nFurthermore, we show that the intrinsic dimension of a geographic INR\ncorrelates with downstream task performance and can capture spatial artifacts,\nfacilitating model evaluation and diagnostics. More broadly, our work offers an\narchitecture-agnostic, label-free metric of information content that can enable\nunsupervised evaluation, model selection, and pre-training design across INRs.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7814\u7a76\u4e86\u5730\u7406\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff08INRs\uff09\u7684\u5185\u5728\u7ef4\u5ea6\uff0c\u53d1\u73b0\u5176\u7ef4\u5ea6\u57282\u523010\u4e4b\u95f4\uff0c\u4e0e\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u76f8\u5173\uff0c\u53ef\u4f5c\u4e3a\u65e0\u76d1\u7763\u8bc4\u4f30\u548c\u6a21\u578b\u9009\u62e9\u7684\u6307\u6807\u3002", "motivation": "\u5730\u7406INRs\u65e8\u5728\u5c06\u5730\u7403\u6570\u636e\u538b\u7f29\u4e3a\u7d27\u51d1\u7684\u8868\u793a\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u5176\u4fe1\u606f\u542b\u91cf\u548c\u5206\u5e03\u7684\u7406\u89e3\uff0c\u9700\u8981\u91cf\u5316\u8fd9\u4e9b\u8868\u793a\u7684\u4fe1\u606f\u5bb9\u91cf\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5185\u5728\u7ef4\u5ea6\u6765\u6d4b\u91cf\u5730\u7406INRs\u7684\u4fe1\u606f\u542b\u91cf\uff0c\u7814\u7a76\u4e0d\u540c\u7a7a\u95f4\u5206\u8fa8\u7387\u548c\u8f93\u5165\u6a21\u6001\u5bf9\u5185\u5728\u7ef4\u5ea6\u7684\u5f71\u54cd\uff0c\u5e76\u9a8c\u8bc1\u5176\u4e0e\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u7684\u76f8\u5173\u6027\u3002", "result": "\u5730\u7406INRs\u7684\u5185\u5728\u7ef4\u5ea6\u57282\u523010\u4e4b\u95f4\uff0c\u5bf9\u7a7a\u95f4\u5206\u8fa8\u7387\u548c\u8f93\u5165\u6a21\u6001\u654f\u611f\uff0c\u4e14\u4e0e\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u5448\u6b63\u76f8\u5173\uff0c\u80fd\u6355\u6349\u7a7a\u95f4\u4f2a\u5f71\u3002", "conclusion": "\u5185\u5728\u7ef4\u5ea6\u4e3a\u5730\u7406INRs\u63d0\u4f9b\u4e86\u67b6\u6784\u65e0\u5173\u3001\u65e0\u6807\u7b7e\u7684\u4fe1\u606f\u542b\u91cf\u5ea6\u91cf\uff0c\u652f\u6301\u65e0\u76d1\u7763\u8bc4\u4f30\u3001\u6a21\u578b\u9009\u62e9\u548c\u9884\u8bad\u7ec3\u8bbe\u8ba1\u3002"}}
{"id": "2511.02148", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02148", "abs": "https://arxiv.org/abs/2511.02148", "authors": ["Abdullah Almansour", "Ozan Tonguz"], "title": "CFL: On the Use of Characteristic Function Loss for Domain Alignment in Machine Learning", "comment": null, "summary": "Machine Learning (ML) models are extensively used in various applications due\nto their significant advantages over traditional learning methods. However, the\ndeveloped ML models often underperform when deployed in the real world due to\nthe well-known distribution shift problem. This problem can lead to a\ncatastrophic outcomes when these decision-making systems have to operate in\nhigh-risk applications. Many researchers have previously studied this problem\nin ML, known as distribution shift problem, using statistical techniques (such\nas Kullback-Leibler, Kolmogorov-Smirnov Test, Wasserstein distance, etc.) to\nquantify the distribution shift. In this letter, we show that using\nCharacteristic Function (CF) as a frequency domain approach is a powerful\nalternative for measuring the distribution shift in high-dimensional space and\nfor domain adaptation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u7279\u5f81\u51fd\u6570\u4f5c\u4e3a\u9891\u57df\u65b9\u6cd5\u6765\u8861\u91cf\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u7684\u5206\u5e03\u504f\u79fb\uff0c\u4e3a\u9886\u57df\u81ea\u9002\u5e94\u63d0\u4f9b\u4e86\u4e00\u79cd\u5f3a\u5927\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u90e8\u7f72\u65f6\u7531\u4e8e\u5206\u5e03\u504f\u79fb\u95ee\u9898\u800c\u8868\u73b0\u4e0d\u4f73\uff0c\u7279\u522b\u662f\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u53ef\u80fd\u5bfc\u81f4\u707e\u96be\u6027\u540e\u679c\u3002\u4f20\u7edf\u7edf\u8ba1\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u5206\u5e03\u504f\u79fb\u5ea6\u91cf\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u7279\u5f81\u51fd\u6570\u4f5c\u4e3a\u9891\u57df\u65b9\u6cd5\u6765\u91cf\u5316\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u7684\u5206\u5e03\u504f\u79fb\uff0c\u4e3a\u9886\u57df\u81ea\u9002\u5e94\u63d0\u4f9b\u65b0\u7684\u6d4b\u91cf\u5de5\u5177\u3002", "result": "\u7279\u5f81\u51fd\u6570\u65b9\u6cd5\u88ab\u8bc1\u660e\u662f\u8861\u91cf\u5206\u5e03\u504f\u79fb\u7684\u5f3a\u5927\u66ff\u4ee3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9ad8\u7ef4\u7a7a\u95f4\u548c\u9886\u57df\u81ea\u9002\u5e94\u573a\u666f\u3002", "conclusion": "\u7279\u5f81\u51fd\u6570\u4f5c\u4e3a\u4e00\u79cd\u9891\u57df\u65b9\u6cd5\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u662f\u4f20\u7edf\u7edf\u8ba1\u65b9\u6cd5\u7684\u6709\u529b\u66ff\u4ee3\u3002"}}
{"id": "2511.02152", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02152", "abs": "https://arxiv.org/abs/2511.02152", "authors": ["Bart\u0142omiej Ma\u0142kus", "Szymon Bobek", "Grzegorz J. Nalepa"], "title": "ProtoTSNet: Interpretable Multivariate Time Series Classification With Prototypical Parts", "comment": "30 pages, 10 figures", "summary": "Time series data is one of the most popular data modalities in critical\ndomains such as industry and medicine. The demand for algorithms that not only\nexhibit high accuracy but also offer interpretability is crucial in such\nfields, as decisions made there bear significant consequences. In this paper,\nwe present ProtoTSNet, a novel approach to interpretable classification of\nmultivariate time series data, through substantial enhancements to the\nProtoPNet architecture. Our method is tailored to overcome the unique\nchallenges of time series analysis, including capturing dynamic patterns and\nhandling varying feature significance. Central to our innovation is a modified\nconvolutional encoder utilizing group convolutions, pre-trainable as part of an\nautoencoder and designed to preserve and quantify feature importance. We\nevaluated our model on 30 multivariate time series datasets from the UEA\narchive, comparing our approach with existing explainable methods as well as\nnon-explainable baselines. Through comprehensive evaluation and ablation\nstudies, we demonstrate that our approach achieves the best performance among\nante-hoc explainable methods while maintaining competitive performance with\nnon-explainable and post-hoc explainable approaches, providing interpretable\nresults accessible to domain experts.", "AI": {"tldr": "ProtoTSNet\u662f\u4e00\u79cd\u7528\u4e8e\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u53ef\u89e3\u91ca\u5206\u7c7b\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6539\u8fdbProtoPNet\u67b6\u6784\u6765\u6355\u83b7\u52a8\u6001\u6a21\u5f0f\u5e76\u5904\u7406\u7279\u5f81\u91cd\u8981\u6027\u53d8\u5316\uff0c\u5728UEA\u6863\u6848\u768430\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u53ef\u89e3\u91ca\u65b9\u6cd5\u3002", "motivation": "\u5728\u5de5\u4e1a\u548c\u533b\u5b66\u7b49\u5173\u952e\u9886\u57df\uff0c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5e94\u7528\u5e7f\u6cdb\uff0c\u9700\u8981\u65e2\u9ad8\u7cbe\u5ea6\u53c8\u53ef\u89e3\u91ca\u7684\u7b97\u6cd5\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u9886\u57df\u7684\u51b3\u7b56\u5177\u6709\u91cd\u5927\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u6539\u8fdb\u7684\u5377\u79ef\u7f16\u7801\u5668\uff0c\u91c7\u7528\u5206\u7ec4\u5377\u79ef\uff0c\u53ef\u4f5c\u4e3a\u81ea\u7f16\u7801\u5668\u9884\u8bad\u7ec3\uff0c\u65e8\u5728\u4fdd\u7559\u548c\u91cf\u5316\u7279\u5f81\u91cd\u8981\u6027\uff0c\u4e13\u95e8\u89e3\u51b3\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u7684\u72ec\u7279\u6311\u6218\u3002", "result": "\u5728UEA\u6863\u6848\u768430\u4e2a\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u8be5\u65b9\u6cd5\u5728\u53ef\u89e3\u91ca\u65b9\u6cd5\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u4e0e\u975e\u53ef\u89e3\u91ca\u548c\u540e\u5904\u7406\u53ef\u89e3\u91ca\u65b9\u6cd5\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "ProtoTSNet\u4e3a\u9886\u57df\u4e13\u5bb6\u63d0\u4f9b\u4e86\u53ef\u8bbf\u95ee\u7684\u53ef\u89e3\u91ca\u7ed3\u679c\uff0c\u5728\u4fdd\u6301\u4e0e\u4e0d\u53ef\u89e3\u91ca\u65b9\u6cd5\u7ade\u4e89\u529b\u7684\u540c\u65f6\uff0c\u63d0\u4f9b\u4e86\u4f18\u4e8e\u5176\u4ed6\u53ef\u89e3\u91ca\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2511.02175", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02175", "abs": "https://arxiv.org/abs/2511.02175", "authors": ["Yuzhuang Pian", "Taiyu Wang", "Shiqi Zhang", "Rui Xu", "Yonghong Liu"], "title": "Tackling Incomplete Data in Air Quality Prediction: A Bayesian Deep Learning Framework for Uncertainty Quantification", "comment": null, "summary": "Accurate air quality forecasts are vital for public health alerts, exposure\nassessment, and emissions control. In practice, observational data are often\nmissing in varying proportions and patterns due to collection and transmission\nissues. These incomplete spatiotemporal records impede reliable inference and\nrisk assessment and can lead to overconfident extrapolation. To address these\nchallenges, we propose an end to end framework, the channel gated learning unit\nbased spatiotemporal bayesian neural field (CGLUBNF). It uses Fourier features\nwith a graph attention encoder to capture multiscale spatial dependencies and\nseasonal temporal dynamics. A channel gated learning unit, equipped with\nlearnable activations and gated residual connections, adaptively filters and\namplifies informative features. Bayesian inference jointly optimizes predictive\ndistributions and parameter uncertainty, producing point estimates and\ncalibrated prediction intervals. We conduct a systematic evaluation on two real\nworld datasets, covering four typical missing data patterns and comparing\nagainst five state of the art baselines. CGLUBNF achieves superior prediction\naccuracy and sharper confidence intervals. In addition, we further validate\nrobustness across multiple prediction horizons and analysis the contribution of\nextraneous variables. This research lays a foundation for reliable deep\nlearning based spatio-temporal forecasting with incomplete observations in\nemerging sensing paradigms, such as real world vehicle borne mobile monitoring.", "AI": {"tldr": "\u63d0\u51faCGLUBNF\u6846\u67b6\uff0c\u901a\u8fc7\u5085\u91cc\u53f6\u7279\u5f81\u548c\u56fe\u6ce8\u610f\u529b\u7f16\u7801\u5668\u6355\u6349\u591a\u5c3a\u5ea6\u7a7a\u95f4\u4f9d\u8d56\u6027\u548c\u5b63\u8282\u6027\u65f6\u95f4\u52a8\u6001\uff0c\u4f7f\u7528\u901a\u9053\u95e8\u63a7\u5b66\u4e60\u5355\u5143\u81ea\u9002\u5e94\u8fc7\u6ee4\u548c\u653e\u5927\u4fe1\u606f\u7279\u5f81\uff0c\u8d1d\u53f6\u65af\u63a8\u7406\u8054\u5408\u4f18\u5316\u9884\u6d4b\u5206\u5e03\u548c\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u7a7a\u6c14\u8d28\u91cf\u9884\u6d4b\u4e2d\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u9884\u6d4b\u548c\u66f4\u5c16\u9510\u7684\u7f6e\u4fe1\u533a\u95f4\u3002", "motivation": "\u7a7a\u6c14\u8d28\u91cf\u9884\u6d4b\u5bf9\u516c\u5171\u536b\u751f\u8b66\u62a5\u3001\u66b4\u9732\u8bc4\u4f30\u548c\u6392\u653e\u63a7\u5236\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u89c2\u6d4b\u6570\u636e\u5e38\u56e0\u6536\u96c6\u548c\u4f20\u8f93\u95ee\u9898\u800c\u5b58\u5728\u4e0d\u540c\u7a0b\u5ea6\u7684\u7f3a\u5931\uff0c\u8fd9\u4e9b\u4e0d\u5b8c\u6574\u7684\u65f6\u7a7a\u8bb0\u5f55\u4f1a\u963b\u788d\u53ef\u9760\u63a8\u65ad\u548c\u98ce\u9669\u8bc4\u4f30\uff0c\u5e76\u53ef\u80fd\u5bfc\u81f4\u8fc7\u5ea6\u81ea\u4fe1\u7684\u5916\u63a8\u3002", "method": "\u63d0\u51fa\u7aef\u5230\u7aef\u6846\u67b6CGLUBNF\uff0c\u4f7f\u7528\u5085\u91cc\u53f6\u7279\u5f81\u548c\u56fe\u6ce8\u610f\u529b\u7f16\u7801\u5668\u6355\u6349\u591a\u5c3a\u5ea6\u7a7a\u95f4\u4f9d\u8d56\u6027\u548c\u5b63\u8282\u6027\u65f6\u95f4\u52a8\u6001\uff0c\u901a\u9053\u95e8\u63a7\u5b66\u4e60\u5355\u5143\u914d\u5907\u53ef\u5b66\u4e60\u6fc0\u6d3b\u548c\u95e8\u63a7\u6b8b\u5dee\u8fde\u63a5\uff0c\u81ea\u9002\u5e94\u8fc7\u6ee4\u548c\u653e\u5927\u4fe1\u606f\u7279\u5f81\uff0c\u8d1d\u53f6\u65af\u63a8\u7406\u8054\u5408\u4f18\u5316\u9884\u6d4b\u5206\u5e03\u548c\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u7cfb\u7edf\u8bc4\u4f30\uff0c\u6db5\u76d6\u56db\u79cd\u5178\u578b\u7f3a\u5931\u6570\u636e\u6a21\u5f0f\uff0c\u5e76\u4e0e\u4e94\u4e2a\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83\u3002CGLUBNF\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u9884\u6d4b\u7cbe\u5ea6\u548c\u66f4\u5c16\u9510\u7684\u7f6e\u4fe1\u533a\u95f4\uff0c\u5728\u591a\u4e2a\u9884\u6d4b\u65f6\u95f4\u8303\u56f4\u5185\u9a8c\u8bc1\u4e86\u9c81\u68d2\u6027\uff0c\u5e76\u5206\u6790\u4e86\u5916\u90e8\u53d8\u91cf\u7684\u8d21\u732e\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u4e3a\u5728\u65b0\u5174\u611f\u77e5\u8303\u5f0f\uff08\u5982\u771f\u5b9e\u4e16\u754c\u8f66\u8f7d\u79fb\u52a8\u76d1\u6d4b\uff09\u4e2d\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u65f6\u7a7a\u9884\u6d4b\u63d0\u4f9b\u4e86\u53ef\u9760\u57fa\u7840\uff0c\u80fd\u591f\u5904\u7406\u4e0d\u5b8c\u6574\u89c2\u6d4b\u6570\u636e\u3002"}}
{"id": "2511.02205", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.02205", "abs": "https://arxiv.org/abs/2511.02205", "authors": ["Kevin Valencia", "Thilina Balasooriya", "Xihaier Luo", "Shinjae Yoo", "David Keetae Park"], "title": "OmniField: Conditioned Neural Fields for Robust Multimodal Spatiotemporal Learning", "comment": "25 pages, 12 figures, 8 tables", "summary": "Multimodal spatiotemporal learning on real-world experimental data is\nconstrained by two challenges: within-modality measurements are sparse,\nirregular, and noisy (QA/QC artifacts) but cross-modally correlated; the set of\navailable modalities varies across space and time, shrinking the usable record\nunless models can adapt to arbitrary subsets at train and test time. We propose\nOmniField, a continuity-aware framework that learns a continuous neural field\nconditioned on available modalities and iteratively fuses cross-modal context.\nA multimodal crosstalk block architecture paired with iterative cross-modal\nrefinement aligns signals prior to the decoder, enabling unified\nreconstruction, interpolation, forecasting, and cross-modal prediction without\ngridding or surrogate preprocessing. Extensive evaluations show that OmniField\nconsistently outperforms eight strong multimodal spatiotemporal baselines.\nUnder heavy simulated sensor noise, performance remains close to clean-input\nlevels, highlighting robustness to corrupted measurements.", "AI": {"tldr": "OmniField\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u65f6\u7a7a\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8fde\u7eed\u795e\u7ecf\u573a\u548c\u8de8\u6a21\u6001\u4ea4\u4e92\u5757\u5904\u7406\u7a00\u758f\u3001\u4e0d\u89c4\u5219\u3001\u566a\u58f0\u6570\u636e\uff0c\u652f\u6301\u7edf\u4e00\u7684\u91cd\u5efa\u3001\u63d2\u503c\u3001\u9884\u6d4b\u548c\u8de8\u6a21\u6001\u9884\u6d4b\u3002", "motivation": "\u89e3\u51b3\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u6570\u636e\u4e2d\u6a21\u6001\u5185\u6d4b\u91cf\u7a00\u758f\u3001\u4e0d\u89c4\u5219\u3001\u566a\u58f0\u4ee5\u53ca\u8de8\u6a21\u6001\u53ef\u7528\u6027\u53d8\u5316\u7684\u95ee\u9898\uff0c\u907f\u514d\u7f51\u683c\u5316\u6216\u66ff\u4ee3\u9884\u5904\u7406\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528\u8fde\u7eed\u795e\u7ecf\u573a\u6761\u4ef6\u5316\u53ef\u7528\u6a21\u6001\uff0c\u7ed3\u5408\u591a\u6a21\u6001\u4ea4\u4e92\u5757\u67b6\u6784\u548c\u8fed\u4ee3\u8de8\u6a21\u6001\u7ec6\u5316\uff0c\u5728\u89e3\u7801\u5668\u524d\u5bf9\u9f50\u4fe1\u53f7\u3002", "result": "\u5728\u5e7f\u6cdb\u8bc4\u4f30\u4e2d\uff0cOmniField\u6301\u7eed\u4f18\u4e8e\u516b\u4e2a\u5f3a\u5927\u7684\u591a\u6a21\u6001\u65f6\u7a7a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u91cd\u5ea6\u6a21\u62df\u4f20\u611f\u5668\u566a\u58f0\u4e0b\u6027\u80fd\u4ecd\u63a5\u8fd1\u6e05\u6d01\u8f93\u5165\u6c34\u5e73\u3002", "conclusion": "OmniField\u5c55\u793a\u4e86\u5728\u591a\u6a21\u6001\u65f6\u7a7a\u5b66\u4e60\u4e2d\u7684\u5353\u8d8a\u6027\u80fd\u548c\u9c81\u68d2\u6027\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u771f\u5b9e\u4e16\u754c\u6570\u636e\u7684\u6311\u6218\u3002"}}
{"id": "2511.02302", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02302", "abs": "https://arxiv.org/abs/2511.02302", "authors": ["Fengjuan Wang", "Zhiyi Su", "Xingzhu Hu", "Cheng Wang", "Mou Sun"], "title": "FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error", "comment": null, "summary": "Training large Mixture-of-Experts (MoE) models remains computationally\nprohibitive due to their extreme compute and memory demands. Although\nlow-precision training promises to accelerate computation and reduce memory\nfootprint, existing implementations still rely on BF16-dominated dataflows with\nfrequent quantize-dequantize (Q/DQ) conversions. These redundant casts erode\nmuch of FP8's theoretical efficiency. However, naively removing these casts by\nkeeping dataflows entirely in FP8 introduces double quantization error: tensors\nquantized along different dimensions accumulate inconsistent scaling factors,\ndegrading numerical stability.\n  We propose FP8-Flow-MoE, an FP8 training recipe featuring a\nquantization-consistent FP8-centric dataflow with a scaling-aware transpose and\nfused FP8 operators that streamline computation and eliminate explicit cast\noperations from 12 to 2. Evaluations on a 671B-parameter MoE model demonstrate\nup to 21\\% higher throughput and 16.5 GB lower memory usage per GPU compared to\nBF16 and na\\\"ive FP8 baselines, while maintaining stable convergence. We\nprovide a plug-and-play FP8 recipe compatible with TransformerEngine and\nMegatron-LM, which will be open-sourced soon.", "AI": {"tldr": "FP8-Flow-MoE\u662f\u4e00\u79cd\u7528\u4e8e\u8bad\u7ec3\u5927\u578bMoE\u6a21\u578b\u7684FP8\u8bad\u7ec3\u65b9\u6848\uff0c\u901a\u8fc7\u91cf\u5316\u4e00\u81f4\u7684FP8\u4e2d\u5fc3\u6570\u636e\u6d41\u548c\u878d\u5408\u7b97\u5b50\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u663e\u5b58\u4f7f\u7528\u5e76\u63d0\u9ad8\u4e86\u8bad\u7ec3\u541e\u5410\u91cf\u3002", "motivation": "\u5f53\u524dMoE\u6a21\u578b\u8bad\u7ec3\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\u5de8\u5927\uff0c\u73b0\u6709FP8\u5b9e\u73b0\u4ecd\u4f9d\u8d56BF16\u6570\u636e\u6d41\u548c\u9891\u7e41\u7684\u91cf\u5316-\u53cd\u91cf\u5316\u8f6c\u6362\uff0c\u8fd9\u4e9b\u5197\u4f59\u64cd\u4f5c\u524a\u5f31\u4e86FP8\u7684\u7406\u8bba\u6548\u7387\u3002", "method": "\u63d0\u51fa\u91cf\u5316\u4e00\u81f4\u7684FP8\u4e2d\u5fc3\u6570\u636e\u6d41\uff0c\u5305\u542b\u7f29\u653e\u611f\u77e5\u8f6c\u7f6e\u548c\u878d\u5408FP8\u7b97\u5b50\uff0c\u5c06\u663e\u5f0f\u8f6c\u6362\u64cd\u4f5c\u4ece12\u4e2a\u51cf\u5c11\u52302\u4e2a\uff0c\u6d88\u9664\u53cc\u91cf\u5316\u8bef\u5dee\u3002", "result": "\u5728671B\u53c2\u6570MoE\u6a21\u578b\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4BF16\u548c\u6734\u7d20FP8\u57fa\u7ebf\uff0c\u541e\u5410\u91cf\u63d0\u9ad821%\uff0c\u6bcf\u4e2aGPU\u5185\u5b58\u4f7f\u7528\u51cf\u5c1116.5GB\uff0c\u540c\u65f6\u4fdd\u6301\u7a33\u5b9a\u6536\u655b\u3002", "conclusion": "FP8-Flow-MoE\u63d0\u4f9b\u4e86\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684FP8\u8bad\u7ec3\u65b9\u6848\uff0c\u4e0eTransformerEngine\u548cMegatron-LM\u517c\u5bb9\uff0c\u5373\u5c06\u5f00\u6e90\u3002"}}
{"id": "2511.02309", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02309", "abs": "https://arxiv.org/abs/2511.02309", "authors": ["Aman Sharma", "Paras Chopra"], "title": "The Sequential Edge: Inverse-Entropy Voting Beats Parallel Self-Consistency at Matched Compute", "comment": null, "summary": "We revisit test-time scaling for language model reasoning and ask a\nfundamental question: at equal token budget and compute, is it better to run\nmultiple independent chains in parallel, or to run fewer chains that\niteratively refine through sequential steps? Through comprehensive evaluation\nacross 5 state-of-the-art open source models and 3 challenging reasoning\nbenchmarks, we find that sequential scaling where chains explicitly build upon\nprevious attempts consistently outperforms the dominant parallel\nself-consistency paradigm in 95.6% of configurations with gains in accuracy\nupto 46.7%. Further, we introduce inverse-entropy weighted voting, a novel\ntraining-free method to further boost the accuracy of sequential scaling. By\nweighing answers in proportion to the inverse entropy of their reasoning\nchains, we increase our success rate over parallel majority and establish it as\nthe optimal test-time scaling strategy. Our findings fundamentally challenge\nthe parallel reasoning orthodoxy that has dominated test-time scaling since\nWang et al.'s self-consistency decoding (Wang et al., 2022), positioning\nsequential refinement as the robust default for modern LLM reasoning and\nnecessitating a paradigm shift in how we approach inference-time optimization.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u5ba1\u89c6\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u7b56\u7565\uff0c\u53d1\u73b0\u5728\u540c\u7b49\u8ba1\u7b97\u8d44\u6e90\u4e0b\uff0c\u987a\u5e8f\u6269\u5c55\uff08\u94fe\u5f0f\u8fed\u4ee3\u7cbe\u70bc\uff09\u6bd4\u5e76\u884c\u81ea\u4e00\u81f4\u6027\u8303\u5f0f\u8868\u73b0\u66f4\u597d\uff0c\u572895.6%\u7684\u914d\u7f6e\u4e2d\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe46.7%\u3002", "motivation": "\u6311\u6218\u5f53\u524d\u4e3b\u5bfc\u7684\u5e76\u884c\u81ea\u4e00\u81f4\u6027\u63a8\u7406\u8303\u5f0f\uff0c\u63a2\u7d22\u5728\u540c\u7b49\u8ba1\u7b97\u9884\u7b97\u4e0b\uff0c\u987a\u5e8f\u6269\u5c55\u662f\u5426\u6bd4\u5e76\u884c\u6269\u5c55\u66f4\u6709\u6548\u3002", "method": "\u57285\u4e2a\u6700\u5148\u8fdb\u5f00\u6e90\u6a21\u578b\u548c3\u4e2a\u6311\u6218\u6027\u63a8\u7406\u57fa\u51c6\u4e0a\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\uff0c\u6bd4\u8f83\u5e76\u884c\u81ea\u4e00\u81f4\u6027\u4e0e\u987a\u5e8f\u6269\u5c55\u7b56\u7565\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u9006\u71b5\u52a0\u6743\u6295\u7968\u7684\u65b0\u65b9\u6cd5\u3002", "result": "\u987a\u5e8f\u6269\u5c55\u572895.6%\u7684\u914d\u7f6e\u4e2d\u4f18\u4e8e\u5e76\u884c\u81ea\u4e00\u81f4\u6027\uff0c\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe46.7%\uff1b\u9006\u71b5\u52a0\u6743\u6295\u7968\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u987a\u5e8f\u6269\u5c55\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u987a\u5e8f\u7cbe\u70bc\u5e94\u6210\u4e3a\u73b0\u4ee3LLM\u63a8\u7406\u7684\u7a33\u5065\u9ed8\u8ba4\u7b56\u7565\uff0c\u8fd9\u9700\u8981\u5bf9\u63a8\u7406\u65f6\u4f18\u5316\u65b9\u6cd5\u8fdb\u884c\u8303\u5f0f\u8f6c\u53d8\u3002"}}
{"id": "2511.02351", "categories": ["cs.LG", "cs.AI", "cs.HC", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.02351", "abs": "https://arxiv.org/abs/2511.02351", "authors": ["Zhuodi Cai", "Ziyu Xu", "Juan Pampin"], "title": "Human-Machine Ritual: Synergic Performance through Real-Time Motion Recognition", "comment": "8 pages, 5 figures. Camera-ready manuscript for the Creative AI Track\n  of NeurIPS 2025", "summary": "We introduce a lightweight, real-time motion recognition system that enables\nsynergic human-machine performance through wearable IMU sensor data, MiniRocket\ntime-series classification, and responsive multimedia control. By mapping\ndancer-specific movement to sound through somatic memory and association, we\npropose an alternative approach to human-machine collaboration, one that\npreserves the expressive depth of the performing body while leveraging machine\nlearning for attentive observation and responsiveness. We demonstrate that this\nhuman-centered design reliably supports high accuracy classification (<50 ms\nlatency), offering a replicable framework to integrate dance-literate machines\ninto creative, educational, and live performance contexts.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8f7b\u91cf\u7ea7\u5b9e\u65f6\u8fd0\u52a8\u8bc6\u522b\u7cfb\u7edf\uff0c\u901a\u8fc7\u53ef\u7a7f\u6234IMU\u4f20\u611f\u5668\u6570\u636e\u3001MiniRocket\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u548c\u54cd\u5e94\u5f0f\u591a\u5a92\u4f53\u63a7\u5236\uff0c\u5b9e\u73b0\u4eba\u673a\u534f\u540c\u8868\u6f14\u3002", "motivation": "\u63a2\u7d22\u4e00\u79cd\u66ff\u4ee3\u6027\u7684\u4eba\u673a\u534f\u4f5c\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u821e\u8005\u7279\u5b9a\u52a8\u4f5c\u6620\u5c04\u5230\u58f0\u97f3\uff0c\u4fdd\u7559\u8868\u6f14\u8eab\u4f53\u7684\u8868\u8fbe\u6df1\u5ea6\uff0c\u540c\u65f6\u5229\u7528\u673a\u5668\u5b66\u4e60\u5b9e\u73b0\u4e13\u6ce8\u89c2\u5bdf\u548c\u54cd\u5e94\u3002", "method": "\u4f7f\u7528\u53ef\u7a7f\u6234IMU\u4f20\u611f\u5668\u6536\u96c6\u6570\u636e\uff0c\u91c7\u7528MiniRocket\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u7b97\u6cd5\uff0c\u7ed3\u5408\u4f53\u611f\u8bb0\u5fc6\u548c\u5173\u8054\u673a\u5236\u5c06\u821e\u8e48\u52a8\u4f5c\u6620\u5c04\u5230\u58f0\u97f3\u63a7\u5236\u3002", "result": "\u7cfb\u7edf\u53ef\u9760\u652f\u6301\u9ad8\u7cbe\u5ea6\u5206\u7c7b\uff08\u5ef6\u8fdf<50\u6beb\u79d2\uff09\uff0c\u63d0\u4f9b\u4e86\u53ef\u590d\u5236\u7684\u6846\u67b6\uff0c\u53ef\u5c06\u5177\u5907\u821e\u8e48\u7406\u89e3\u80fd\u529b\u7684\u673a\u5668\u96c6\u6210\u5230\u521b\u610f\u3001\u6559\u80b2\u548c\u73b0\u573a\u8868\u6f14\u573a\u666f\u4e2d\u3002", "conclusion": "\u8be5\u4eba\u672c\u8bbe\u8ba1\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u7cbe\u5ea6\u7684\u5b9e\u65f6\u8fd0\u52a8\u8bc6\u522b\uff0c\u4e3a\u4eba\u673a\u534f\u540c\u8868\u6f14\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u6846\u67b6\u3002"}}
{"id": "2511.02453", "categories": ["cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.02453", "abs": "https://arxiv.org/abs/2511.02453", "authors": ["Thomas Sanchez", "Pedro M. Gordaliza", "Meritxell Bach Cuadra"], "title": "Accounting for Underspecification in Statistical Claims of Model Superiority", "comment": "Medical Imaging meets EurIPS Workshop: MedEurIPS 2025", "summary": "Machine learning methods are increasingly applied in medical imaging, yet\nmany reported improvements lack statistical robustness: recent works have\nhighlighted that small but significant performance gains are highly likely to\nbe false positives. However, these analyses do not take\n\\emph{underspecification} into account -- the fact that models achieving\nsimilar validation scores may behave differently on unseen data due to random\ninitialization or training dynamics. Here, we extend a recent statistical\nframework modeling false outperformance claims to include underspecification as\nan additional variance component. Our simulations demonstrate that even modest\nseed variability ($\\sim1\\%$) substantially increases the evidence required to\nsupport superiority claims. Our findings underscore the need for explicit\nmodeling of training variance when validating medical imaging systems.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u7edf\u8ba1\u6846\u67b6\u4ee5\u8003\u8651\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u53d1\u73b0\u5373\u4f7f\u5f88\u5c0f\u7684\u968f\u673a\u79cd\u5b50\u53d8\u5f02\u6027\u4e5f\u4f1a\u663e\u8457\u589e\u52a0\u652f\u6301\u4f18\u8d8a\u6027\u58f0\u660e\u6240\u9700\u7684\u8bc1\u636e\uff0c\u5f3a\u8c03\u4e86\u5728\u9a8c\u8bc1\u533b\u5b66\u6210\u50cf\u7cfb\u7edf\u65f6\u9700\u8981\u660e\u786e\u5efa\u6a21\u8bad\u7ec3\u65b9\u5dee\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u533b\u5b66\u6210\u50cf\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u8bb8\u591a\u62a5\u544a\u7684\u6539\u8fdb\u7f3a\u4e4f\u7edf\u8ba1\u7a33\u5065\u6027\u3002\u73b0\u6709\u5206\u6790\u672a\u8003\u8651\u4e0d\u786e\u5b9a\u6027\u2014\u2014\u5373\u7531\u4e8e\u968f\u673a\u521d\u59cb\u5316\u6216\u8bad\u7ec3\u52a8\u6001\uff0c\u83b7\u5f97\u76f8\u4f3c\u9a8c\u8bc1\u5206\u6570\u7684\u6a21\u578b\u53ef\u80fd\u5728\u672a\u89c1\u6570\u636e\u4e0a\u8868\u73b0\u4e0d\u540c\u3002", "method": "\u6269\u5c55\u4e86\u6700\u8fd1\u7684\u7edf\u8ba1\u6846\u67b6\uff0c\u5c06\u4e0d\u786e\u5b9a\u6027\u4f5c\u4e3a\u989d\u5916\u7684\u65b9\u5dee\u5206\u91cf\u8fdb\u884c\u5efa\u6a21\uff0c\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u8bc4\u4f30\u968f\u673a\u79cd\u5b50\u53d8\u5f02\u6027\u5bf9\u4f18\u8d8a\u6027\u58f0\u660e\u8bc1\u636e\u8981\u6c42\u7684\u5f71\u54cd\u3002", "result": "\u6a21\u62df\u663e\u793a\u5373\u4f7f\u9002\u5ea6\u7684\u79cd\u5b50\u53d8\u5f02\u6027\uff08\u7ea61%\uff09\u4e5f\u4f1a\u663e\u8457\u589e\u52a0\u652f\u6301\u4f18\u8d8a\u6027\u58f0\u660e\u6240\u9700\u7684\u8bc1\u636e\uff0c\u4e0d\u786e\u5b9a\u6027\u8fdb\u4e00\u6b65\u52a0\u5267\u4e86\u5047\u9633\u6027\u58f0\u660e\u7684\u98ce\u9669\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5728\u9a8c\u8bc1\u533b\u5b66\u6210\u50cf\u7cfb\u7edf\u65f6\u660e\u786e\u5efa\u6a21\u8bad\u7ec3\u65b9\u5dee\u7684\u5fc5\u8981\u6027\uff0c\u4ee5\u786e\u4fdd\u7edf\u8ba1\u7a33\u5065\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2511.02481", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02481", "abs": "https://arxiv.org/abs/2511.02481", "authors": ["Mohammad Sadegh Eshaghi", "Cosmin Anitescu", "Navid Valizadeh", "Yizheng Wang", "Xiaoying Zhuang", "Timon Rabczuk"], "title": "NOWS: Neural Operator Warm Starts for Accelerating Iterative Solvers", "comment": null, "summary": "Partial differential equations (PDEs) underpin quantitative descriptions\nacross the physical sciences and engineering, yet high-fidelity simulation\nremains a major computational bottleneck for many-query, real-time, and design\ntasks. Data-driven surrogates can be strikingly fast but are often unreliable\nwhen applied outside their training distribution. Here we introduce Neural\nOperator Warm Starts (NOWS), a hybrid strategy that harnesses learned solution\noperators to accelerate classical iterative solvers by producing high-quality\ninitial guesses for Krylov methods such as conjugate gradient and GMRES. NOWS\nleaves existing discretizations and solver infrastructures intact, integrating\nseamlessly with finite-difference, finite-element, isogeometric analysis,\nfinite volume method, etc. Across our benchmarks, the learned initialization\nconsistently reduces iteration counts and end-to-end runtime, resulting in a\nreduction of the computational time of up to 90 %, while preserving the\nstability and convergence guarantees of the underlying numerical algorithms. By\ncombining the rapid inference of neural operators with the rigor of traditional\nsolvers, NOWS provides a practical and trustworthy approach to accelerate\nhigh-fidelity PDE simulations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u7b56\u7565NOWS\uff0c\u5229\u7528\u5b66\u4e60\u5230\u7684\u89e3\u7b97\u5b50\u4e3aKrylov\u65b9\u6cd5\u751f\u6210\u9ad8\u8d28\u91cf\u521d\u59cb\u731c\u6d4b\uff0c\u4ece\u800c\u52a0\u901f\u4f20\u7edf\u8fed\u4ee3\u6c42\u89e3\u5668\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u503c\u7b97\u6cd5\u7684\u7a33\u5b9a\u6027\u548c\u6536\u655b\u4fdd\u8bc1\u3002", "motivation": "\u9ad8\u4fdd\u771fPDE\u6a21\u62df\u5728\u8ba1\u7b97\u4e0a\u4ecd\u7136\u662f\u4e00\u4e2a\u4e3b\u8981\u74f6\u9888\uff0c\u800c\u6570\u636e\u9a71\u52a8\u7684\u66ff\u4ee3\u65b9\u6cd5\u867d\u7136\u901f\u5ea6\u5feb\uff0c\u4f46\u5728\u8bad\u7ec3\u5206\u5e03\u4e4b\u5916\u5e94\u7528\u65f6\u5f80\u5f80\u4e0d\u53ef\u9760\u3002", "method": "NOWS\u7b56\u7565\u5229\u7528\u5b66\u4e60\u5230\u7684\u89e3\u7b97\u5b50\u4e3a\u5171\u8f6d\u68af\u5ea6\u548cGMRES\u7b49Krylov\u65b9\u6cd5\u751f\u6210\u9ad8\u8d28\u91cf\u521d\u59cb\u731c\u6d4b\uff0c\u4e0e\u73b0\u6709\u79bb\u6563\u5316\u548c\u6c42\u89e3\u5668\u57fa\u7840\u8bbe\u65bd\u65e0\u7f1d\u96c6\u6210\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5b66\u4e60\u5230\u7684\u521d\u59cb\u5316\u4e00\u81f4\u51cf\u5c11\u4e86\u8fed\u4ee3\u6b21\u6570\u548c\u7aef\u5230\u7aef\u8fd0\u884c\u65f6\u95f4\uff0c\u8ba1\u7b97\u65f6\u95f4\u6700\u591a\u51cf\u5c1190%\u3002", "conclusion": "NOWS\u901a\u8fc7\u5c06\u795e\u7ecf\u7b97\u5b50\u7684\u5feb\u901f\u63a8\u7406\u4e0e\u4f20\u7edf\u6c42\u89e3\u5668\u7684\u4e25\u8c28\u6027\u76f8\u7ed3\u5408\uff0c\u4e3a\u52a0\u901f\u9ad8\u4fdd\u771fPDE\u6a21\u62df\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u4fe1\u8d56\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.02567", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02567", "abs": "https://arxiv.org/abs/2511.02567", "authors": ["Yixiu Mao", "Yun Qu", "Qi Wang", "Xiangyang Ji"], "title": "Adaptive Neighborhood-Constrained Q Learning for Offline Reinforcement Learning", "comment": "Accepted to NeurIPS 2025 (Spotlight)", "summary": "Offline reinforcement learning (RL) suffers from extrapolation errors induced\nby out-of-distribution (OOD) actions. To address this, offline RL algorithms\ntypically impose constraints on action selection, which can be systematically\ncategorized into density, support, and sample constraints. However, we show\nthat each category has inherent limitations: density and sample constraints\ntend to be overly conservative in many scenarios, while the support constraint,\nthough least restrictive, faces challenges in accurately modeling the behavior\npolicy. To overcome these limitations, we propose a new neighborhood constraint\nthat restricts action selection in the Bellman target to the union of\nneighborhoods of dataset actions. Theoretically, the constraint not only bounds\nextrapolation errors and distribution shift under certain conditions, but also\napproximates the support constraint without requiring behavior policy modeling.\nMoreover, it retains substantial flexibility and enables pointwise conservatism\nby adapting the neighborhood radius for each data point. In practice, we employ\ndata quality as the adaptation criterion and design an adaptive neighborhood\nconstraint. Building on an efficient bilevel optimization framework, we develop\na simple yet effective algorithm, Adaptive Neighborhood-constrained Q learning\n(ANQ), to perform Q learning with target actions satisfying this constraint.\nEmpirically, ANQ achieves state-of-the-art performance on standard offline RL\nbenchmarks and exhibits strong robustness in scenarios with noisy or limited\ndata.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u90bb\u57df\u7ea6\u675f\u65b9\u6cd5\u6765\u89e3\u51b3\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5916\u63a8\u8bef\u5dee\u95ee\u9898\uff0c\u8be5\u65b9\u6cd5\u5c06\u8d1d\u5c14\u66fc\u76ee\u6807\u4e2d\u7684\u52a8\u4f5c\u9009\u62e9\u9650\u5236\u5728\u6570\u636e\u96c6\u52a8\u4f5c\u90bb\u57df\u7684\u5e76\u96c6\u4e0a\uff0c\u5e76\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u6846\u67b6\u5b9e\u73b0\u81ea\u9002\u5e94\u7684\u90bb\u57df\u7ea6\u675f\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u9762\u4e34\u7531\u5206\u5e03\u5916\u52a8\u4f5c\u5f15\u8d77\u7684\u5916\u63a8\u8bef\u5dee\u95ee\u9898\uff0c\u73b0\u6709\u7684\u5bc6\u5ea6\u7ea6\u675f\u3001\u652f\u6301\u7ea6\u675f\u548c\u6837\u672c\u7ea6\u675f\u65b9\u6cd5\u5404\u6709\u5c40\u9650\uff1a\u5bc6\u5ea6\u548c\u6837\u672c\u7ea6\u675f\u8fc7\u4e8e\u4fdd\u5b88\uff0c\u800c\u652f\u6301\u7ea6\u675f\u5728\u51c6\u786e\u5efa\u6a21\u884c\u4e3a\u7b56\u7565\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u90bb\u57df\u7ea6\u675f\u65b9\u6cd5\uff0c\u5c06\u8d1d\u5c14\u66fc\u76ee\u6807\u4e2d\u7684\u52a8\u4f5c\u9009\u62e9\u9650\u5236\u5728\u6570\u636e\u96c6\u52a8\u4f5c\u90bb\u57df\u7684\u5e76\u96c6\u4e0a\uff1b\u4f7f\u7528\u6570\u636e\u8d28\u91cf\u4f5c\u4e3a\u9002\u5e94\u51c6\u5219\u8bbe\u8ba1\u81ea\u9002\u5e94\u90bb\u57df\u7ea6\u675f\uff1b\u57fa\u4e8e\u9ad8\u6548\u7684\u53cc\u5c42\u4f18\u5316\u6846\u67b6\u5f00\u53d1ANQ\u7b97\u6cd5\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u8be5\u7ea6\u675f\u80fd\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u9650\u5236\u5916\u63a8\u8bef\u5dee\u548c\u5206\u5e03\u504f\u79fb\uff0c\u4e14\u65e0\u9700\u884c\u4e3a\u7b56\u7565\u5efa\u6a21\u5373\u53ef\u8fd1\u4f3c\u652f\u6301\u7ea6\u675f\uff1b\u5b9e\u8bc1\u8868\u660eANQ\u5728\u6807\u51c6\u79bb\u7ebfRL\u57fa\u51c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u566a\u58f0\u6216\u6709\u9650\u6570\u636e\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "\u90bb\u57df\u7ea6\u675f\u65b9\u6cd5\u514b\u670d\u4e86\u73b0\u6709\u7ea6\u675f\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e86\u7075\u6d3b\u4e14\u70b9\u5f0f\u4fdd\u5b88\u7684\u89e3\u51b3\u65b9\u6848\uff0cANQ\u7b97\u6cd5\u5728\u6027\u80fd\u548c\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2511.02646", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.SY", "econ.GN", "eess.SY", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2511.02646", "abs": "https://arxiv.org/abs/2511.02646", "authors": ["Tiziano Balaconi", "Aldo Glielmo", "Marco Taboga"], "title": "Natural-gas storage modelling by deep reinforcement learning", "comment": "8 pages, 5 figures, published on", "summary": "We introduce GasRL, a simulator that couples a calibrated representation of\nthe natural gas market with a model of storage-operator policies trained with\ndeep reinforcement learning (RL). We use it to analyse how optimal stockpile\nmanagement affects equilibrium prices and the dynamics of demand and supply. We\ntest various RL algorithms and find that Soft Actor Critic (SAC) exhibits\nsuperior performance in the GasRL environment: multiple objectives of storage\noperators - including profitability, robust market clearing and price\nstabilisation - are successfully achieved. Moreover, the equilibrium price\ndynamics induced by SAC-derived optimal policies have characteristics, such as\nvolatility and seasonality, that closely match those of real-world prices.\nRemarkably, this adherence to the historical distribution of prices is obtained\nwithout explicitly calibrating the model to price data. We show how the\nsimulator can be used to assess the effects of EU-mandated minimum storage\nthresholds. We find that such thresholds have a positive effect on market\nresilience against unanticipated shifts in the distribution of supply shocks.\nFor example, with unusually large shocks, market disruptions are averted more\noften if a threshold is in place.", "AI": {"tldr": "GasRL\u662f\u4e00\u4e2a\u7ed3\u5408\u5929\u7136\u6c14\u5e02\u573a\u6821\u51c6\u6a21\u578b\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5b58\u50a8\u7ba1\u7406\u7b56\u7565\u7684\u6a21\u62df\u5668\uff0c\u7528\u4e8e\u5206\u6790\u6700\u4f18\u5e93\u5b58\u7ba1\u7406\u5bf9\u5747\u8861\u4ef7\u683c\u53ca\u4f9b\u9700\u52a8\u6001\u7684\u5f71\u54cd\u3002\u7814\u7a76\u53d1\u73b0SAC\u7b97\u6cd5\u8868\u73b0\u6700\u4f73\uff0c\u80fd\u5b9e\u73b0\u76c8\u5229\u6027\u3001\u5e02\u573a\u6e05\u7b97\u7a33\u5065\u6027\u548c\u4ef7\u683c\u7a33\u5b9a\u7b49\u591a\u91cd\u76ee\u6807\uff0c\u4e14\u5176\u4ea7\u751f\u7684\u4ef7\u683c\u52a8\u6001\u4e0e\u5b9e\u9645\u5e02\u573a\u7279\u5f81\u9ad8\u5ea6\u5339\u914d\u3002\u6a21\u62df\u5668\u8fd8\u53ef\u7528\u4e8e\u8bc4\u4f30\u6b27\u76df\u6700\u4f4e\u5b58\u50a8\u9608\u503c\u653f\u7b56\uff0c\u53d1\u73b0\u8be5\u653f\u7b56\u80fd\u589e\u5f3a\u5e02\u573a\u5bf9\u4f9b\u5e94\u51b2\u51fb\u7684\u97e7\u6027\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u5206\u6790\u5929\u7136\u6c14\u5e02\u573a\u4e2d\u5b58\u50a8\u8fd0\u8425\u5546\u7684\u6700\u4f18\u5e93\u5b58\u7ba1\u7406\u7b56\u7565\u5982\u4f55\u5f71\u54cd\u5e02\u573a\u5747\u8861\u4ef7\u683c\u548c\u4f9b\u9700\u52a8\u6001\uff0c\u5e76\u8bc4\u4f30\u653f\u7b56\u5e72\u9884\uff08\u5982\u6b27\u76df\u6700\u4f4e\u5b58\u50a8\u9608\u503c\uff09\u5bf9\u5e02\u573a\u7a33\u5b9a\u6027\u7684\u5f71\u54cd\u3002", "method": "\u5f00\u53d1GasRL\u6a21\u62df\u5668\uff0c\u5c06\u5929\u7136\u6c14\u5e02\u573a\u6821\u51c6\u6a21\u578b\u4e0e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08\u7279\u522b\u662fSoft Actor Critic\u7b97\u6cd5\uff09\u8bad\u7ec3\u7684\u5b58\u50a8\u8fd0\u8425\u5546\u7b56\u7565\u76f8\u7ed3\u5408\uff0c\u6d4b\u8bd5\u591a\u79cdRL\u7b97\u6cd5\u6027\u80fd\u3002", "result": "SAC\u7b97\u6cd5\u5728GasRL\u73af\u5883\u4e2d\u8868\u73b0\u6700\u4f18\uff0c\u6210\u529f\u5b9e\u73b0\u5b58\u50a8\u8fd0\u8425\u5546\u7684\u591a\u91cd\u76ee\u6807\uff1bSAC\u7b56\u7565\u4ea7\u751f\u7684\u5747\u8861\u4ef7\u683c\u52a8\u6001\u4e0e\u5b9e\u9645\u5e02\u573a\u4ef7\u683c\u7279\u5f81\u9ad8\u5ea6\u4e00\u81f4\uff1b\u6b27\u76df\u6700\u4f4e\u5b58\u50a8\u9608\u503c\u653f\u7b56\u80fd\u6709\u6548\u589e\u5f3a\u5e02\u573a\u5bf9\u4f9b\u5e94\u51b2\u51fb\u7684\u97e7\u6027\uff0c\u51cf\u5c11\u5e02\u573a\u4e2d\u65ad\u98ce\u9669\u3002", "conclusion": "GasRL\u6a21\u62df\u5668\u4e3a\u5206\u6790\u5929\u7136\u6c14\u5e02\u573a\u52a8\u6001\u548c\u653f\u7b56\u5f71\u54cd\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0cSAC\u7b97\u6cd5\u80fd\u4ea7\u751f\u7b26\u5408\u5b9e\u9645\u5e02\u573a\u7279\u5f81\u7684\u6700\u4f18\u5b58\u50a8\u7ba1\u7406\u7b56\u7565\uff0c\u6b27\u76df\u6700\u4f4e\u5b58\u50a8\u9608\u503c\u653f\u7b56\u6709\u52a9\u4e8e\u63d0\u5347\u5e02\u573a\u7a33\u5b9a\u6027\u3002"}}
{"id": "2511.02659", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.02659", "abs": "https://arxiv.org/abs/2511.02659", "authors": ["Cooper Simpson", "Stephen Becker", "Alireza Doostan"], "title": "In Situ Training of Implicit Neural Compressors for Scientific Simulations via Sketch-Based Regularization", "comment": "17 pages, 8 figures, 4 tables", "summary": "Focusing on implicit neural representations, we present a novel in situ\ntraining protocol that employs limited memory buffers of full and sketched data\nsamples, where the sketched data are leveraged to prevent catastrophic\nforgetting. The theoretical motivation for our use of sketching as a\nregularizer is presented via a simple Johnson-Lindenstrauss-informed result.\nWhile our methods may be of wider interest in the field of continual learning,\nwe specifically target in situ neural compression using implicit neural\nrepresentation-based hypernetworks. We evaluate our method on a variety of\ncomplex simulation data in two and three dimensions, over long time horizons,\nand across unstructured grids and non-Cartesian geometries. On these tasks, we\nshow strong reconstruction performance at high compression rates. Most\nimportantly, we demonstrate that sketching enables the presented in situ scheme\nto approximately match the performance of the equivalent offline method.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u5728\u7ebf\u8bad\u7ec3\u534f\u8bae\uff0c\u4f7f\u7528\u5b8c\u6574\u6570\u636e\u548c\u8349\u56fe\u6570\u636e\u7684\u6709\u9650\u5185\u5b58\u7f13\u51b2\u533a\uff0c\u901a\u8fc7\u8349\u56fe\u6570\u636e\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8\uff0c\u7279\u522b\u9488\u5bf9\u57fa\u4e8e\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u7684\u795e\u7ecf\u538b\u7f29\u5e94\u7528\u3002", "motivation": "\u89e3\u51b3\u5728\u7ebf\u5b66\u4e60\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u548c\u795e\u7ecf\u538b\u7f29\u9886\u57df\uff0c\u901a\u8fc7\u8349\u56fe\u6570\u636e\u4f5c\u4e3a\u6b63\u5219\u5316\u5668\u6765\u7ef4\u6301\u6a21\u578b\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u6709\u9650\u5185\u5b58\u7f13\u51b2\u533a\u5b58\u50a8\u5b8c\u6574\u548c\u8349\u56fe\u6570\u636e\u6837\u672c\uff0c\u57fa\u4e8eJohnson-Lindenstrauss\u7406\u8bba\u5c06\u8349\u56fe\u4f5c\u4e3a\u6b63\u5219\u5316\u5668\uff0c\u5e94\u7528\u4e8e\u57fa\u4e8e\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u7684hypernetworks\u8fdb\u884c\u5728\u7ebf\u795e\u7ecf\u538b\u7f29\u3002", "result": "\u5728\u590d\u6742\u4eff\u771f\u6570\u636e\u4e0a\uff082D/3D\u3001\u957f\u65f6\u95f4\u5e8f\u5217\u3001\u975e\u7ed3\u6784\u5316\u7f51\u683c\u548c\u975e\u7b1b\u5361\u5c14\u51e0\u4f55\uff09\u5c55\u793a\u4e86\u9ad8\u538b\u7f29\u7387\u4e0b\u7684\u5f3a\u91cd\u5efa\u6027\u80fd\uff0c\u8349\u56fe\u65b9\u6cd5\u4f7f\u5728\u7ebf\u65b9\u6848\u6027\u80fd\u63a5\u8fd1\u7b49\u6548\u79bb\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8349\u56fe\u6280\u672f\u80fd\u591f\u6709\u6548\u9632\u6b62\u5728\u7ebf\u5b66\u4e60\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\uff0c\u4f7f\u5728\u7ebf\u8bad\u7ec3\u65b9\u6848\u5728\u795e\u7ecf\u538b\u7f29\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e0e\u79bb\u7ebf\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u6c34\u5e73\u3002"}}
{"id": "2511.02533", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02533", "abs": "https://arxiv.org/abs/2511.02533", "authors": ["Hortence Nana", "Andreas Athanasopoulos", "Christos Dimitrakakis"], "title": "Rawlsian many-to-one matching with non-linear utility", "comment": "17 pages, 7 figures", "summary": "We study a many-to-one matching problem, such as the college admission\nproblem, where each college can admit multiple students. Unlike classical\nmodels, colleges evaluate sets of students through non-linear utility functions\nthat capture diversity between them. In this setting, we show that classical\nstable matchings may fail to exist. To address this, we propose alternative\nsolution concepts based on Rawlsian fairness, aiming to maximize the minimum\nutility across colleges. We design both deterministic and stochastic algorithms\nthat iteratively improve the outcome of the worst-off college, offering a\npractical approach to fair allocation when stability cannot be guaranteed.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5177\u6709\u975e\u7ebf\u6027\u6548\u7528\u51fd\u6570\u7684\u5927\u5b66\u62db\u751f\u5339\u914d\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u7f57\u5c14\u65af\u516c\u5e73\u7684\u66ff\u4ee3\u65b9\u6848\u6765\u89e3\u51b3\u7ecf\u5178\u7a33\u5b9a\u5339\u914d\u4e0d\u5b58\u5728\u7684\u95ee\u9898\u3002", "motivation": "\u7ecf\u5178\u7a33\u5b9a\u5339\u914d\u5728\u8003\u8651\u5b66\u751f\u591a\u6837\u6027\u7684\u975e\u7ebf\u6027\u6548\u7528\u51fd\u6570\u4e0b\u53ef\u80fd\u4e0d\u5b58\u5728\uff0c\u9700\u8981\u65b0\u7684\u516c\u5e73\u5206\u914d\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u786e\u5b9a\u6027\u548c\u968f\u673a\u6027\u7b97\u6cd5\uff0c\u901a\u8fc7\u8fed\u4ee3\u6539\u5584\u6700\u5dee\u5927\u5b66\u7684\u6548\u7528\u6765\u5b9e\u73b0\u516c\u5e73\u5206\u914d\u3002", "result": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u7f57\u5c14\u65af\u516c\u5e73\u539f\u5219\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u7a33\u5b9a\u5339\u914d\u4e0d\u53ef\u5f97\u65f6\u63d0\u4f9b\u516c\u5e73\u7684\u5206\u914d\u7ed3\u679c\u3002", "conclusion": "\u5f53\u7ecf\u5178\u7a33\u5b9a\u5339\u914d\u4e0d\u5b58\u5728\u65f6\uff0c\u57fa\u4e8e\u6700\u5927\u5316\u6700\u5c0f\u6548\u7528\u7684\u7f57\u5c14\u65af\u516c\u5e73\u65b9\u6cd5\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2511.02815", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02815", "abs": "https://arxiv.org/abs/2511.02815", "authors": ["Morgan Allen", "Paul Savala"], "title": "Assessing win strength in MLB win prediction models", "comment": null, "summary": "In Major League Baseball, strategy and planning are major factors in\ndetermining the outcome of a game. Previous studies have aided this by building\nmachine learning models for predicting the winning team of any given game. We\nextend this work by training a comprehensive set of machine learning models\nusing a common dataset. In addition, we relate the win probabilities produced\nby these models to win strength as measured by score differential. In doing so\nwe show that the most common machine learning models do indeed demonstrate a\nrelationship between predicted win probability and the strength of the win.\nFinally, we analyze the results of using predicted win probabilities as a\ndecision making mechanism on run-line betting. We demonstrate positive returns\nwhen utilizing appropriate betting strategies, and show that naive use of\nmachine learning models for betting lead to significant loses.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6269\u5c55\u4e86MLB\u6bd4\u8d5b\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u8bad\u7ec3\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6765\u9884\u6d4b\u80dc\u961f\uff0c\u5e76\u5206\u6790\u9884\u6d4b\u80dc\u7387\u4e0e\u6bd4\u5206\u5dee\u5f02\u7684\u5173\u7cfb\uff0c\u6700\u540e\u63a2\u8ba8\u4e86\u5728\u8dd1\u5206\u7ebf\u6295\u6ce8\u4e2d\u7684\u5e94\u7528\u6548\u679c\u3002", "motivation": "\u6269\u5c55\u5148\u524d\u5173\u4e8eMLB\u6bd4\u8d5b\u9884\u6d4b\u7684\u7814\u7a76\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u6784\u5efa\u5168\u9762\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5e76\u9a8c\u8bc1\u9884\u6d4b\u80dc\u7387\u4e0e\u5b9e\u9645\u6bd4\u8d5b\u4f18\u52bf\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u4f7f\u7528\u7edf\u4e00\u6570\u636e\u96c6\u8bad\u7ec3\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5206\u6790\u9884\u6d4b\u80dc\u7387\u4e0e\u6bd4\u5206\u5dee\u5f02\u7684\u76f8\u5173\u6027\uff0c\u5e76\u6d4b\u8bd5\u6a21\u578b\u5728\u8dd1\u5206\u7ebf\u6295\u6ce8\u51b3\u7b56\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u5927\u591a\u6570\u673a\u5668\u5b66\u4e60\u6a21\u578b\u786e\u5b9e\u663e\u793a\u51fa\u9884\u6d4b\u80dc\u7387\u4e0e\u6bd4\u8d5b\u4f18\u52bf\u5f3a\u5ea6\u4e4b\u95f4\u7684\u5173\u7cfb\uff1b\u9002\u5f53\u7684\u6295\u6ce8\u7b56\u7565\u80fd\u4ea7\u751f\u6b63\u6536\u76ca\uff0c\u4f46\u7b80\u5355\u4f7f\u7528\u6a21\u578b\u8fdb\u884c\u6295\u6ce8\u4f1a\u5bfc\u81f4\u663e\u8457\u635f\u5931\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u80fd\u6709\u6548\u9884\u6d4bMLB\u6bd4\u8d5b\u7ed3\u679c\u5e76\u53cd\u6620\u6bd4\u8d5b\u4f18\u52bf\uff0c\u4f46\u5728\u5b9e\u9645\u6295\u6ce8\u5e94\u7528\u4e2d\u9700\u8981\u8c28\u614e\u7684\u7b56\u7565\u8bbe\u8ba1\uff0c\u4e0d\u80fd\u7b80\u5355\u4f9d\u8d56\u6a21\u578b\u9884\u6d4b\u3002"}}
{"id": "2511.02577", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02577", "abs": "https://arxiv.org/abs/2511.02577", "authors": ["Gilad Karpel", "Ruida Zhou", "Shoham Sabach", "Mohammad Ghavamzadeh"], "title": "Directional-Clamp PPO", "comment": null, "summary": "Proximal Policy Optimization (PPO) is widely regarded as one of the most\nsuccessful deep reinforcement learning algorithms, known for its robustness and\neffectiveness across a range of problems.\n  The PPO objective encourages the importance ratio between the current and\nbehavior policies to move to the \"right\" direction -- starting from importance\nsampling ratios equal to 1, increasing the ratios for actions with positive\nadvantages and decreasing those with negative advantages. A clipping function\nis introduced to prevent over-optimization when updating the importance ratio\nin these \"right\" direction regions. Many PPO variants have been proposed to\nextend its success, most of which modify the objective's behavior by altering\nthe clipping in the \"right\" direction regions. However, due to randomness in\nthe rollouts and stochasticity of the policy optimization, we observe that the\nratios frequently move to the \"wrong\" direction during the PPO optimization.\nThis is a key factor hindering the improvement of PPO, but it has been largely\noverlooked. To address this, we propose the Directional-Clamp PPO algorithm\n(DClamp-PPO), which further penalizes the actions going to the strict \"wrong\"\ndirection regions, where the advantage is positive (negative) and importance\nratio falls below (above) $1 - \\beta$ ($1+\\beta$),\n  for a tunable parameter $\\beta \\in (0, 1)$. The penalty is by enforcing a\nsteeper loss slope, i.e., a clamp, in those regions. We demonstrate that\nDClamp-PPO consistently outperforms PPO, as well as its variants, by focusing\non modifying the objective's behavior in the \"right\" direction, across various\nMuJoCo environments, using different random seeds. The proposed method is\nshown, both theoretically and empirically, to better avoid \"wrong\" direction\nupdates while keeping the importance ratio closer to 1.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684PPO\u7b97\u6cd5DClamp-PPO\uff0c\u901a\u8fc7\u5728\"\u9519\u8bef\"\u65b9\u5411\u533a\u57df\u5f15\u5165\u989d\u5916\u7684\u60e9\u7f5a\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfPPO\u7b97\u6cd5\u4e2d\u91cd\u8981\u6027\u6bd4\u7387\u7ecf\u5e38\u5411\u9519\u8bef\u65b9\u5411\u79fb\u52a8\u7684\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u5347\u4e86\u7b97\u6cd5\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfPPO\u7b97\u6cd5\u5728\u4f18\u5316\u8fc7\u7a0b\u4e2d\uff0c\u7531\u4e8erollout\u7684\u968f\u673a\u6027\u548c\u7b56\u7565\u4f18\u5316\u7684\u968f\u673a\u6027\uff0c\u91cd\u8981\u6027\u6bd4\u7387\u7ecf\u5e38\u5411\"\u9519\u8bef\"\u65b9\u5411\u79fb\u52a8\uff0c\u8fd9\u662f\u963b\u788dPPO\u6539\u8fdb\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4f46\u4e00\u76f4\u88ab\u5ffd\u89c6\u3002", "method": "\u63d0\u51faDClamp-PPO\u7b97\u6cd5\uff0c\u5728\u4e25\u683c\"\u9519\u8bef\"\u65b9\u5411\u533a\u57df\uff08\u4f18\u52bf\u4e3a\u6b63\u65f6\u91cd\u8981\u6027\u6bd4\u7387\u4f4e\u4e8e1-\u03b2\uff0c\u4f18\u52bf\u4e3a\u8d1f\u65f6\u91cd\u8981\u6027\u6bd4\u7387\u9ad8\u4e8e1+\u03b2\uff09\u5f15\u5165\u989d\u5916\u7684\u60e9\u7f5a\u673a\u5236\uff0c\u901a\u8fc7\u5f3a\u5236\u6267\u884c\u66f4\u9661\u5ced\u7684\u635f\u5931\u659c\u7387\u6765\u60e9\u7f5a\u8fd9\u4e9b\u52a8\u4f5c\u3002", "result": "\u5728\u591a\u4e2aMuJoCo\u73af\u5883\u4e2d\u4f7f\u7528\u4e0d\u540c\u968f\u673a\u79cd\u5b50\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDClamp-PPO\u59cb\u7ec8\u4f18\u4e8ePPO\u53ca\u5176\u53d8\u4f53\uff0c\u80fd\u66f4\u597d\u5730\u907f\u514d\"\u9519\u8bef\"\u65b9\u5411\u66f4\u65b0\uff0c\u540c\u65f6\u4fdd\u6301\u91cd\u8981\u6027\u6bd4\u7387\u66f4\u63a5\u8fd11\u3002", "conclusion": "DClamp-PPO\u901a\u8fc7\u5173\u6ce8\u4fee\u6539\u76ee\u6807\u51fd\u6570\u5728\"\u9519\u8bef\"\u65b9\u5411\u533a\u57df\u7684\u884c\u4e3a\uff0c\u6709\u6548\u63d0\u5347\u4e86PPO\u7b97\u6cd5\u7684\u6027\u80fd\uff0c\u7406\u8bba\u548c\u5b9e\u8bc1\u90fd\u8bc1\u660e\u4e86\u5176\u4f18\u8d8a\u6027\u3002"}}
{"id": "2511.02644", "categories": ["cs.LG", "cs.CC", "math.LO", "8T05, 03D80, 03D25 (Primary) 68Q32, 68T09, 68T27, 68Q04, 03D32\n  (Secondary)"], "pdf": "https://arxiv.org/pdf/2511.02644", "abs": "https://arxiv.org/abs/2511.02644", "authors": ["David Kattermann", "Lothar Sebastian Krapp"], "title": "Recursively Enumerably Representable Classes and Computable Versions of the Fundamental Theorem of Statistical Learning", "comment": null, "summary": "We study computable probably approximately correct (CPAC) learning, where\nlearners are required to be computable functions. It had been previously\nobserved that the Fundamental Theorem of Statistical Learning, which\ncharacterizes PAC learnability by finiteness of the Vapnik-Chervonenkis\n(VC-)dimension, no longer holds in this framework. Recent works recovered\nanalogs of the Fundamental Theorem in the computable setting, for instance by\nintroducing an effective VC-dimension. Guided by this, we investigate the\nconnection between CPAC learning and recursively enumerable representable (RER)\nclasses, whose members can be algorithmically listed. Our results show that the\neffective VC-dimensions can take arbitrary values above the traditional one,\neven for RER classes, which creates a whole family of (non-)examples for\nvarious notions of CPAC learning. Yet the two dimensions coincide for classes\nsatisfying sufficiently strong notions of CPAC learning. We then observe that\nCPAC learnability can also be characterized via containment of RER classes that\nrealize the same samples. Furthermore, it is shown that CPAC learnable classes\nsatisfying a unique identification property are necessarily RER. Finally, we\nestablish that agnostic learnability can be guaranteed for RER classes, by\nconsidering the relaxed notion of nonuniform CPAC learning.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u53ef\u8ba1\u7b97PAC\u5b66\u4e60\uff0c\u63a2\u8ba8\u4e86\u4f20\u7edf\u7edf\u8ba1\u5b66\u4e60\u57fa\u672c\u5b9a\u7406\u5728\u53ef\u8ba1\u7b97\u6846\u67b6\u4e0b\u7684\u5931\u6548\u60c5\u51b5\uff0c\u5f15\u5165\u4e86\u6709\u6548VC\u7ef4\u5ea6\u7684\u6982\u5ff5\uff0c\u5e76\u5206\u6790\u4e86\u53ef\u8ba1\u7b97PAC\u5b66\u4e60\u4e0e\u9012\u5f52\u53ef\u679a\u4e3e\u53ef\u8868\u793a\u7c7b\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "motivation": "\u4f20\u7edf\u7edf\u8ba1\u5b66\u4e60\u57fa\u672c\u5b9a\u7406\u5728\u53ef\u8ba1\u7b97\u5b66\u4e60\u6846\u67b6\u4e0b\u4e0d\u518d\u6210\u7acb\uff0c\u9700\u8981\u5bfb\u627e\u65b0\u7684\u7406\u8bba\u6846\u67b6\u6765\u523b\u753b\u53ef\u8ba1\u7b97PAC\u5b66\u4e60\u3002", "method": "\u5f15\u5165\u6709\u6548VC\u7ef4\u5ea6\u6982\u5ff5\uff0c\u7814\u7a76\u53ef\u8ba1\u7b97PAC\u5b66\u4e60\u4e0e\u9012\u5f52\u53ef\u679a\u4e3e\u53ef\u8868\u793a\u7c7b\u4e4b\u95f4\u7684\u8fde\u63a5\u5173\u7cfb\uff0c\u5206\u6790\u4e0d\u540c\u7ef4\u5ea6\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "result": "\u53d1\u73b0\u6709\u6548VC\u7ef4\u5ea6\u53ef\u4ee5\u53d6\u4efb\u610f\u9ad8\u4e8e\u4f20\u7edfVC\u7ef4\u5ea6\u7684\u503c\uff0c\u4f46\u5bf9\u4e8e\u6ee1\u8db3\u5f3a\u53ef\u8ba1\u7b97PAC\u5b66\u4e60\u6982\u5ff5\u7684\u7c7b\u522b\uff0c\u4e24\u4e2a\u7ef4\u5ea6\u4f1a\u91cd\u5408\u3002\u540c\u65f6\u8bc1\u660e\u4e86\u53ef\u8ba1\u7b97PAC\u5b66\u4e60\u53ef\u4ee5\u901a\u8fc7\u5305\u542b\u5b9e\u73b0\u76f8\u540c\u6837\u672c\u7684\u9012\u5f52\u53ef\u679a\u4e3e\u53ef\u8868\u793a\u7c7b\u6765\u523b\u753b\u3002", "conclusion": "\u53ef\u8ba1\u7b97PAC\u5b66\u4e60\u53ef\u4ee5\u901a\u8fc7\u9012\u5f52\u53ef\u679a\u4e3e\u53ef\u8868\u793a\u7c7b\u6765\u8868\u5f81\uff0c\u6ee1\u8db3\u552f\u4e00\u8bc6\u522b\u6027\u8d28\u7684\u53ef\u8ba1\u7b97PAC\u5b66\u4e60\u7c7b\u5fc5\u7136\u662f\u9012\u5f52\u53ef\u679a\u4e3e\u53ef\u8868\u793a\u7684\uff0c\u4e14\u5bf9\u4e8e\u9012\u5f52\u53ef\u679a\u4e3e\u53ef\u8868\u793a\u7c7b\uff0c\u53ef\u4ee5\u901a\u8fc7\u8003\u8651\u975e\u5747\u5300\u53ef\u8ba1\u7b97PAC\u5b66\u4e60\u6765\u4fdd\u8bc1\u4e0d\u53ef\u77e5\u5b66\u4e60\u6027\u3002"}}
{"id": "2511.02657", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02657", "abs": "https://arxiv.org/abs/2511.02657", "authors": ["Lihan Xu", "Yanjie Dong", "Gang Wang", "Runhao Zeng", "Xiaoyi Fan", "Xiping Hu"], "title": "Nesterov-Accelerated Robust Federated Learning Over Byzantine Adversaries", "comment": null, "summary": "We investigate robust federated learning, where a group of workers\ncollaboratively train a shared model under the orchestration of a central\nserver in the presence of Byzantine adversaries capable of arbitrary and\npotentially malicious behaviors. To simultaneously enhance communication\nefficiency and robustness against such adversaries, we propose a\nByzantine-resilient Nesterov-Accelerated Federated Learning (Byrd-NAFL)\nalgorithm. Byrd-NAFL seamlessly integrates Nesterov's momentum into the\nfederated learning process alongside Byzantine-resilient aggregation rules to\nachieve fast and safeguarding convergence against gradient corruption. We\nestablish a finite-time convergence guarantee for Byrd-NAFL under non-convex\nand smooth loss functions with relaxed assumption on the aggregated gradients.\nExtensive numerical experiments validate the effectiveness of Byrd-NAFL and\ndemonstrate the superiority over existing benchmarks in terms of convergence\nspeed, accuracy, and resilience to diverse Byzantine attack strategies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6297\u62dc\u5360\u5ead\u653b\u51fb\u7684Nesterov\u52a0\u901f\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5(Byrd-NAFL)\uff0c\u5728\u5b58\u5728\u6076\u610f\u653b\u51fb\u8005\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5feb\u901f\u4e14\u5b89\u5168\u7684\u6536\u655b\u3002", "motivation": "\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\uff0c\u591a\u4e2a\u5de5\u4f5c\u8282\u70b9\u5728\u4e2d\u592e\u670d\u52a1\u5668\u534f\u8c03\u4e0b\u534f\u4f5c\u8bad\u7ec3\u5171\u4eab\u6a21\u578b\u65f6\uff0c\u9762\u4e34\u62dc\u5360\u5ead\u5bf9\u624b\u7684\u4efb\u610f\u6076\u610f\u884c\u4e3a\u5a01\u80c1\uff0c\u9700\u8981\u540c\u65f6\u63d0\u5347\u901a\u4fe1\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002", "method": "\u5c06Nesterov\u52a8\u91cf\u4e0e\u6297\u62dc\u5360\u5ead\u805a\u5408\u89c4\u5219\u76f8\u7ed3\u5408\uff0c\u5728\u975e\u51f8\u5e73\u6ed1\u635f\u5931\u51fd\u6570\u4e0b\u5b9e\u73b0\u5feb\u901f\u6536\u655b\uff0c\u5e76\u5bf9\u805a\u5408\u68af\u5ea6\u5047\u8bbe\u8fdb\u884c\u4e86\u653e\u5bbd\u3002", "result": "\u5efa\u7acb\u4e86Byrd-NAFL\u7684\u6709\u9650\u65f6\u95f4\u6536\u655b\u4fdd\u8bc1\uff0c\u5e76\u901a\u8fc7\u5927\u91cf\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u6536\u655b\u901f\u5ea6\u3001\u51c6\u786e\u6027\u548c\u5bf9\u591a\u79cd\u62dc\u5360\u5ead\u653b\u51fb\u7b56\u7565\u7684\u97e7\u6027\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "Byrd-NAFL\u7b97\u6cd5\u5728\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\u6709\u6548\u5e73\u8861\u4e86\u901a\u4fe1\u6548\u7387\u4e0e\u9c81\u68d2\u6027\u9700\u6c42\uff0c\u80fd\u591f\u62b5\u5fa1\u5404\u79cd\u62dc\u5360\u5ead\u653b\u51fb\u7b56\u7565\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u65b9\u6cd5\u3002"}}
{"id": "2511.02718", "categories": ["cs.LG", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.02718", "abs": "https://arxiv.org/abs/2511.02718", "authors": ["Adia Khalid", "Alina Deriyeva", "Benjamin Paassen"], "title": "Does Interpretability of Knowledge Tracing Models Support Teacher Decision Making?", "comment": "in press at the Workshop on Epistemics and Decision-Making in\n  AI-Supported Education, AIED 2025", "summary": "Knowledge tracing (KT) models are a crucial basis for pedagogical\ndecision-making, namely which task to select next for a learner and when to\nstop teaching a particular skill. Given the high stakes of pedagogical\ndecisions, KT models are typically required to be interpretable, in the sense\nthat they should implement an explicit model of human learning and provide\nexplicit estimates of learners' abilities. However, to our knowledge, no study\nto date has investigated whether the interpretability of KT models actually\nhelps human teachers to make teaching decisions. We address this gap. First, we\nperform a simulation study to show that, indeed, decisions based on\ninterpretable KT models achieve mastery faster compared to decisions based on a\nnon-interpretable model. Second, we repeat the study but ask $N=12$ human\nteachers to make the teaching decisions based on the information provided by KT\nmodels. As expected, teachers rate interpretable KT models higher in terms of\nusability and trustworthiness. However, the number of tasks needed until\nmastery hardly differs between KT models. This suggests that the relationship\nbetween model interpretability and teacher decisions is not straightforward:\nteachers do not solely rely on KT models to make decisions and further research\nis needed to investigate how learners and teachers actually understand and use\nKT models.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u77e5\u8bc6\u8ffd\u8e2a(KT)\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u662f\u5426\u771f\u6b63\u5e2e\u52a9\u4eba\u7c7b\u6559\u5e08\u505a\u51fa\u6559\u5b66\u51b3\u7b56\u3002\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u548c\u4eba\u7c7b\u6559\u5e08\u5b9e\u9a8c\u53d1\u73b0\uff0c\u867d\u7136\u53ef\u89e3\u91ca\u6a21\u578b\u5728\u6a21\u62df\u4e2d\u80fd\u66f4\u5feb\u8fbe\u5230\u638c\u63e1\u6c34\u5e73\uff0c\u4e14\u6559\u5e08\u5bf9\u5176\u53ef\u7528\u6027\u548c\u53ef\u4fe1\u5ea6\u8bc4\u4ef7\u66f4\u9ad8\uff0c\u4f46\u5b9e\u9645\u6559\u5b66\u4e2d\u6559\u5e08\u4f7f\u7528\u4e0d\u540c\u6a21\u578b\u65f6\u5b66\u751f\u8fbe\u5230\u638c\u63e1\u6240\u9700\u7684\u4efb\u52a1\u6570\u91cf\u5dee\u5f02\u4e0d\u5927\u3002", "motivation": "\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\u5bf9\u6559\u5b66\u51b3\u7b56\u81f3\u5173\u91cd\u8981\uff0c\u867d\u7136\u901a\u5e38\u8981\u6c42\u5177\u6709\u53ef\u89e3\u91ca\u6027\uff0c\u4f46\u4e4b\u524d\u6ca1\u6709\u7814\u7a76\u9a8c\u8bc1\u8fd9\u79cd\u53ef\u89e3\u91ca\u6027\u662f\u5426\u771f\u6b63\u5e2e\u52a9\u4eba\u7c7b\u6559\u5e08\u505a\u51fa\u66f4\u597d\u7684\u6559\u5b66\u51b3\u7b56\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u9996\u5148\u8fdb\u884c\u6a21\u62df\u7814\u7a76\uff0c\u6bd4\u8f83\u57fa\u4e8e\u53ef\u89e3\u91caKT\u6a21\u578b\u548c\u975e\u53ef\u89e3\u91ca\u6a21\u578b\u7684\u6559\u5b66\u51b3\u7b56\u6548\u679c\uff1b\u7136\u540e\u9080\u8bf712\u540d\u4eba\u7c7b\u6559\u5e08\u53c2\u4e0e\u5b9e\u9a8c\uff0c\u8ba9\u4ed6\u4eec\u57fa\u4e8eKT\u6a21\u578b\u63d0\u4f9b\u7684\u4fe1\u606f\u505a\u51fa\u6559\u5b66\u51b3\u7b56\uff0c\u5e76\u8bc4\u4f30\u6a21\u578b\u7684\u53ef\u7528\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "result": "\u6a21\u62df\u7814\u7a76\u663e\u793a\u57fa\u4e8e\u53ef\u89e3\u91caKT\u6a21\u578b\u7684\u51b3\u7b56\u80fd\u66f4\u5feb\u8fbe\u5230\u638c\u63e1\u6c34\u5e73\uff1b\u4eba\u7c7b\u6559\u5e08\u5b9e\u9a8c\u8868\u660e\u6559\u5e08\u5bf9\u53ef\u89e3\u91caKT\u6a21\u578b\u7684\u53ef\u7528\u6027\u548c\u53ef\u4fe1\u5ea6\u8bc4\u4ef7\u66f4\u9ad8\uff0c\u4f46\u5b9e\u9645\u6559\u5b66\u4e2d\u5b66\u751f\u8fbe\u5230\u638c\u63e1\u6240\u9700\u7684\u4efb\u52a1\u6570\u91cf\u5728\u4e0d\u540c\u6a21\u578b\u95f4\u5dee\u5f02\u4e0d\u5927\u3002", "conclusion": "\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u4e0e\u6559\u5e08\u51b3\u7b56\u4e4b\u95f4\u7684\u5173\u7cfb\u5e76\u4e0d\u76f4\u63a5\uff1a\u6559\u5e08\u4e0d\u5b8c\u5168\u4f9d\u8d56KT\u6a21\u578b\u505a\u51b3\u7b56\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5b66\u4e60\u8005\u548c\u6559\u5e08\u5982\u4f55\u5b9e\u9645\u7406\u89e3\u548c\u4f7f\u7528KT\u6a21\u578b\u3002"}}
{"id": "2511.02738", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02738", "abs": "https://arxiv.org/abs/2511.02738", "authors": ["Ilies Chibane", "Thomas George", "Pierre Nodet", "Vincent Lemaire"], "title": "Calibration improves detection of mislabeled examples", "comment": null, "summary": "Mislabeled data is a pervasive issue that undermines the performance of\nmachine learning systems in real-world applications. An effective approach to\nmitigate this problem is to detect mislabeled instances and subject them to\nspecial treatment, such as filtering or relabeling. Automatic mislabeling\ndetection methods typically rely on training a base machine learning model and\nthen probing it for each instance to obtain a trust score that each provided\nlabel is genuine or incorrect. The properties of this base model are thus of\nparamount importance. In this paper, we investigate the impact of calibrating\nthis model. Our empirical results show that using calibration methods improves\nthe accuracy and robustness of mislabeled instance detection, providing a\npractical and effective solution for industrial applications.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6821\u51c6\u57fa\u7840\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5bf9\u9519\u8bef\u6807\u7b7e\u68c0\u6d4b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u4f7f\u7528\u6821\u51c6\u65b9\u6cd5\u53ef\u4ee5\u63d0\u9ad8\u9519\u8bef\u6807\u7b7e\u5b9e\u4f8b\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u5b9e\u5e94\u7528\u4e2d\u9519\u8bef\u6807\u7b7e\u6570\u636e\u666e\u904d\u5b58\u5728\uff0c\u4f1a\u964d\u4f4e\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u6027\u80fd\u3002\u9700\u8981\u6709\u6548\u68c0\u6d4b\u9519\u8bef\u6807\u7b7e\u5b9e\u4f8b\u5e76\u8fdb\u884c\u8fc7\u6ee4\u6216\u91cd\u65b0\u6807\u8bb0\u3002", "method": "\u8bad\u7ec3\u57fa\u7840\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7136\u540e\u5bf9\u6bcf\u4e2a\u5b9e\u4f8b\u8fdb\u884c\u63a2\u6d4b\u4ee5\u83b7\u5f97\u6807\u7b7e\u53ef\u4fe1\u5ea6\u5206\u6570\uff0c\u91cd\u70b9\u7814\u7a76\u6821\u51c6\u8be5\u57fa\u7840\u6a21\u578b\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528\u6821\u51c6\u65b9\u6cd5\u80fd\u591f\u63d0\u9ad8\u9519\u8bef\u6807\u7b7e\u5b9e\u4f8b\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u6a21\u578b\u6821\u51c6\u4e3a\u5de5\u4e1a\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u6709\u6548\u7684\u9519\u8bef\u6807\u7b7e\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.02762", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.02762", "abs": "https://arxiv.org/abs/2511.02762", "authors": ["Xun Wang", "Zhuoran Li", "Yanshan Lin", "Hai Zhong", "Longbo Huang"], "title": "From Solo to Symphony: Orchestrating Multi-Agent Collaboration with Single-Agent Demos", "comment": null, "summary": "Training a team of agents from scratch in multi-agent reinforcement learning\n(MARL) is highly inefficient, much like asking beginners to play a symphony\ntogether without first practicing solo. Existing methods, such as offline or\ntransferable MARL, can ease this burden, but they still rely on costly\nmulti-agent data, which often becomes the bottleneck. In contrast, solo\nexperiences are far easier to obtain in many important scenarios, e.g.,\ncollaborative coding, household cooperation, and search-and-rescue. To unlock\ntheir potential, we propose Solo-to-Collaborative RL (SoCo), a framework that\ntransfers solo knowledge into cooperative learning. SoCo first pretrains a\nshared solo policy from solo demonstrations, then adapts it for cooperation\nduring multi-agent training through a policy fusion mechanism that combines an\nMoE-like gating selector and an action editor. Experiments across diverse\ncooperative tasks show that SoCo significantly boosts the training efficiency\nand performance of backbone algorithms. These results demonstrate that solo\ndemonstrations provide a scalable and effective complement to multi-agent data,\nmaking cooperative learning more practical and broadly applicable.", "AI": {"tldr": "SoCo\u6846\u67b6\u901a\u8fc7\u5c06\u5355\u667a\u80fd\u4f53\u77e5\u8bc6\u8fc1\u79fb\u5230\u534f\u4f5c\u5b66\u4e60\u4e2d\uff0c\u5229\u7528\u5355\u667a\u80fd\u4f53\u6f14\u793a\u6765\u63d0\u5347\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4ece\u5934\u8bad\u7ec3\u56e2\u961f\u6548\u7387\u4f4e\u4e0b\uff0c\u800c\u73b0\u6709\u7684\u79bb\u7ebf\u6216\u53ef\u8fc1\u79fb\u65b9\u6cd5\u4ecd\u4f9d\u8d56\u6602\u8d35\u7684\u591a\u667a\u80fd\u4f53\u6570\u636e\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u5355\u667a\u80fd\u4f53\u7ecf\u9a8c\u5728\u8bb8\u591a\u91cd\u8981\u573a\u666f\u4e2d\u66f4\u5bb9\u6613\u83b7\u5f97\u3002", "method": "SoCo\u9996\u5148\u4ece\u5355\u667a\u80fd\u4f53\u6f14\u793a\u4e2d\u9884\u8bad\u7ec3\u5171\u4eab\u7684\u5355\u667a\u80fd\u4f53\u7b56\u7565\uff0c\u7136\u540e\u901a\u8fc7\u7b56\u7565\u878d\u5408\u673a\u5236\uff08\u5305\u542bMoE-like\u95e8\u63a7\u9009\u62e9\u5668\u548c\u52a8\u4f5c\u7f16\u8f91\u5668\uff09\u5728\u591a\u667a\u80fd\u4f53\u8bad\u7ec3\u671f\u95f4\u5c06\u5176\u9002\u5e94\u4e8e\u534f\u4f5c\u3002", "result": "\u5728\u591a\u6837\u5316\u534f\u4f5c\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSoCo\u663e\u8457\u63d0\u5347\u4e86\u9aa8\u5e72\u7b97\u6cd5\u7684\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd\u3002", "conclusion": "\u5355\u667a\u80fd\u4f53\u6f14\u793a\u4e3a\u591a\u667a\u80fd\u4f53\u6570\u636e\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u6709\u6548\u7684\u8865\u5145\uff0c\u4f7f\u534f\u4f5c\u5b66\u4e60\u66f4\u52a0\u5b9e\u7528\u548c\u5e7f\u6cdb\u9002\u7528\u3002"}}
{"id": "2511.02797", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02797", "abs": "https://arxiv.org/abs/2511.02797", "authors": ["Nicolas Riccieri Gardin Assumpcao", "Leandro Villas"], "title": "Fast, Private, and Protected: Safeguarding Data Privacy and Defending Against Model Poisoning Attacks in Federated Learning", "comment": null, "summary": "Federated Learning (FL) is a distributed training paradigm wherein\nparticipants collaborate to build a global model while ensuring the privacy of\nthe involved data, which remains stored on participant devices. However,\nproposals aiming to ensure such privacy also make it challenging to protect\nagainst potential attackers seeking to compromise the training outcome. In this\ncontext, we present Fast, Private, and Protected (FPP), a novel approach that\naims to safeguard federated training while enabling secure aggregation to\npreserve data privacy. This is accomplished by evaluating rounds using\nparticipants' assessments and enabling training recovery after an attack. FPP\nalso employs a reputation-based mechanism to mitigate the participation of\nattackers. We created a dockerized environment to validate the performance of\nFPP compared to other approaches in the literature (FedAvg, Power-of-Choice,\nand aggregation via Trimmed Mean and Median). Our experiments demonstrate that\nFPP achieves a rapid convergence rate and can converge even in the presence of\nmalicious participants performing model poisoning attacks.", "AI": {"tldr": "FPP\u662f\u4e00\u79cd\u8054\u90a6\u5b66\u4e60\u4fdd\u62a4\u65b9\u6cd5\uff0c\u901a\u8fc7\u53c2\u4e0e\u8005\u8bc4\u4f30\u3001\u8bad\u7ec3\u6062\u590d\u548c\u4fe1\u8a89\u673a\u5236\u6765\u9632\u5fa1\u6076\u610f\u653b\u51fb\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u636e\u9690\u79c1\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u5728\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\uff0c\u96be\u4ee5\u9632\u8303\u6076\u610f\u53c2\u4e0e\u8005\u5bf9\u8bad\u7ec3\u7ed3\u679c\u7684\u653b\u51fb\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u62a4\u9690\u79c1\u53c8\u80fd\u9632\u5fa1\u653b\u51fb\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "FPP\u91c7\u7528\u5b89\u5168\u805a\u5408\u4fdd\u62a4\u6570\u636e\u9690\u79c1\uff0c\u901a\u8fc7\u53c2\u4e0e\u8005\u8bc4\u4f30\u8f6e\u6b21\u3001\u8bad\u7ec3\u6062\u590d\u673a\u5236\u548c\u57fa\u4e8e\u4fe1\u8a89\u7684\u53c2\u4e0e\u63a7\u5236\u6765\u9632\u5fa1\u6a21\u578b\u6295\u6bd2\u653b\u51fb\u3002", "result": "\u5b9e\u9a8c\u8868\u660eFPP\u5728\u6076\u610f\u53c2\u4e0e\u8005\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u5feb\u901f\u6536\u655b\uff0c\u6536\u655b\u901f\u5ea6\u4f18\u4e8eFedAvg\u3001Power-of-Choice\u3001Trimmed Mean\u548cMedian\u7b49\u65b9\u6cd5\u3002", "conclusion": "FPP\u5728\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u7684\u540c\u65f6\u6709\u6548\u9632\u5fa1\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6076\u610f\u653b\u51fb\uff0c\u5b9e\u73b0\u4e86\u5feb\u901f\u6536\u655b\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002"}}
