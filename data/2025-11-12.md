<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 17]
- [eess.SP](#eess.SP) [Total: 6]
- [stat.ML](#stat.ML) [Total: 2]
- [cs.LG](#cs.LG) [Total: 31]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Beyond Correctness: Confidence-Aware Reward Modeling for Enhancing Large Language Model Reasoning](https://arxiv.org/abs/2511.07483)
*Qianxi He,Qingyu Ren,Shanzhe Lei,Xuhong Wang,Yingchun Wang*

Main category: cs.AI

TL;DR: 本文提出了一种基于置信度的奖励模型，专门用于增强STEM推理能力，通过惩罚低置信度的正确回答来促进更稳健和逻辑一致的推理。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的强化学习奖励机制在推理能力训练中经常导致推理链质量差或推理过程与最终答案不一致的问题，特别是对于较小规模的模型。这限制了资源有限的组织在小规模模型上进行直接强化学习训练的能力。

Method: 提出了一种新颖的基于置信度的奖励模型，不仅惩罚错误答案，还惩罚低置信度的正确回答。通过静态评估、Best-of-N推理测试和基于PPO的强化学习训练来验证方法的有效性。

Result: 该方法在多个STEM基准测试中优于几种最先进的开源奖励模型。

Conclusion: 基于置信度的奖励模型能够有效提升STEM推理能力，促进更稳健和逻辑一致的推理过程，为小规模模型的强化学习训练提供了可行方案。

Abstract: Recent advancements in large language models (LLMs) have shifted the post-training paradigm from traditional instruction tuning and human preference alignment toward reinforcement learning (RL) focused on reasoning capabilities. However, numerous technical reports indicate that purely rule-based reward RL frequently results in poor-quality reasoning chains or inconsistencies between reasoning processes and final answers, particularly when the base model is of smaller scale. During the RL exploration process, models might employ low-quality reasoning chains due to the lack of knowledge, occasionally producing correct answers randomly and receiving rewards based on established rule-based judges. This constrains the potential for resource-limited organizations to conduct direct reinforcement learning training on smaller-scale models. We propose a novel confidence-based reward model tailored for enhancing STEM reasoning capabilities. Unlike conventional approaches, our model penalizes not only incorrect answers but also low-confidence correct responses, thereby promoting more robust and logically consistent reasoning. We validate the effectiveness of our approach through static evaluations, Best-of-N inference tests, and PPO-based RL training. Our method outperforms several state-of-the-art open-source reward models across diverse STEM benchmarks. We release our codes and model in https://github.com/qianxiHe147/C2RM.

</details>


### [2] [Making LLMs Reliable When It Matters Most: A Five-Layer Architecture for High-Stakes Decisions](https://arxiv.org/abs/2511.07669)
*Alejandro R. Jadad*

Main category: cs.AI

TL;DR: 该研究提出了一个框架，通过7阶段校准序列和5层保护架构，使人类-AI团队在高风险战略决策中实现认知伙伴关系，避免可预防的认知陷阱和遗憾。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在可验证领域表现出色，但在具有不确定结果的高风险战略决策中可靠性不足，这威胁到估值辩护和投资可持续性。

Method: 通过对7个前沿级LLM和3个市场风险案例进行系统定性评估，开发了包含7阶段校准序列、4阶段初始化过程和5层保护架构的框架。

Result: 研究发现：伙伴关系状态可通过有序校准实现但需要新兴维护协议；当架构漂移和上下文耗尽同时发生时可靠性会下降；解散纪律可防止追求根本错误方向。

Conclusion: 人类-AI团队可以实现认知伙伴关系，在高风险决策中预防可避免的遗憾，满足依赖AI系统支持关键决策而不引入可预防认知陷阱的投资回报期望。

Abstract: Current large language models (LLMs) excel in verifiable domains where outputs can be checked before action but prove less reliable for high-stakes strategic decisions with uncertain outcomes. This gap, driven by mutually reinforcing cognitive biases in both humans and artificial intelligence (AI) systems, threatens the defensibility of valuations and sustainability of investments in the sector.
  This report describes a framework emerging from systematic qualitative assessment across 7 frontier-grade LLMs and 3 market-facing venture vignettes under time pressure. Detailed prompting specifying decision partnership and explicitly instructing avoidance of sycophancy, confabulation, solution drift, and nihilism achieved initial partnership state but failed to maintain it under operational pressure. Sustaining protective partnership state required an emergent 7-stage calibration sequence, built upon a 4-stage initialization process, within a 5-layer protection architecture enabling bias self-monitoring, human-AI adversarial challenge, partnership state verification, performance degradation detection, and stakeholder protection.
  Three discoveries resulted: partnership state is achievable through ordered calibration but requires emergent maintenance protocols; reliability degrades when architectural drift and context exhaustion align; and dissolution discipline prevents costly pursuit of fundamentally wrong directions. Cross-model validation revealed systematic performance differences across LLM architectures.
  This approach demonstrates that human-AI teams can achieve cognitive partnership capable of preventing avoidable regret in high-stakes decisions, addressing return-on-investment expectations that depend on AI systems supporting consequential decision-making without introducing preventable cognitive traps when verification arrives too late.

</details>


### [3] [Toward Robust EEG-based Intention Decoding during Misarticulated Speech in Aphasia](https://arxiv.org/abs/2511.07895)
*Ha-Na Jo,Jung-Sun Lee,Eunyeong Ko*

Main category: cs.AI

TL;DR: 该研究针对失语症患者开发了基于EEG的通信支持系统，通过分析正确和错误发音试验的神经活动差异，构建了多任务学习框架来解码患者意图，即使在发音错误时也能有效识别。


<details>
  <summary>Details</summary>
Motivation: 失语症严重影响语言表达能力，导致频繁发音错误，但目前针对失语症患者的EEG通信支持系统研究较少。研究旨在开发能够适应实际不完美发音条件的辅助系统。

Method: 招募一名表达性失语症患者进行韩语自动语音任务，记录EEG信号并根据发音正确性标记试验。使用频谱分析识别神经活动模式差异，开发基于最大均值差异正则化的软多任务学习框架，重点关注delta特征。

Result: 正确试验准确率58.6%，错误发音试验准确率45.5%，后者比基线提高超过45%。频谱分析显示错误发音试验在广泛通道上表现出过度的delta功率，前额区域theta-alpha活动增加。

Conclusion: 研究证明了基于EEG的辅助系统在失语症患者实际不完美发音条件下的可行性，能够稳健地解码意图，即使在发音错误时也能有效工作。

Abstract: Aphasia severely limits verbal communication due to impaired language production, often leading to frequent misarticulations during speech attempts. Despite growing interest in brain-computer interface technologies, relatively little attention has been paid to developing EEG-based communication support systems tailored for aphasic patients. To address this gap, we recruited a single participant with expressive aphasia and conducted an Korean-based automatic speech task. EEG signals were recorded during task performance, and each trial was labeled as either correct or incorrect depending on whether the intended word was successfully spoken. Spectral analysis revealed distinct neural activation patterns between the two trial types: misarticulated trials exhibited excessive delta power across widespread channels and increased theta-alpha activity in frontal regions. Building upon these findings, we developed a soft multitask learning framework with maximum mean discrepancy regularization that focus on delta features to jointly optimize class discrimination while aligning the EEG feature distributions of correct and misarticulated trials. The proposed model achieved 58.6 % accuracy for correct and 45.5 % for misarticulated trials-outperforming the baseline by over 45 % on the latter-demonstrating robust intention decoding even under articulation errors. These results highlight the feasibility of EEG-based assistive systems capable of supporting real-world, imperfect speech conditions in aphasia patients.

</details>


### [4] [SparseRM: A Lightweight Preference Modeling with Sparse Autoencoder](https://arxiv.org/abs/2511.07896)
*Dengcan Liu,Jiahao Li,Zheren Fu,Yi Tu,Jiajun Li,Zhendong Mao,Yongdong Zhang*

Main category: cs.AI

TL;DR: SparseRM利用稀疏自编码器从大语言模型表示中提取偏好相关特征，构建轻量级、可解释的奖励模型，在仅使用不到1%可训练参数的情况下优于主流奖励模型。


<details>
  <summary>Details</summary>
Motivation: 解决在有限资源下训练可靠奖励模型的挑战，因为传统方法依赖大规模偏好标注和昂贵的LLM微调成本。

Method: 使用稀疏自编码器分解LLM表示为可解释的偏好相关特征方向，通过投影计算对齐分数，然后用简单奖励头聚合这些分数预测偏好得分。

Result: 在三个偏好建模任务上的实验表明，SparseRM在仅使用不到1%可训练参数的情况下，性能优于大多数主流奖励模型。

Conclusion: SparseRM能够无缝集成到下游对齐流程中，展示了其在高效对齐方面的潜力。

Abstract: Reward models (RMs) are a core component in the post-training of large language models (LLMs), serving as proxies for human preference evaluation and guiding model alignment. However, training reliable RMs under limited resources remains challenging due to the reliance on large-scale preference annotations and the high cost of fine-tuning LLMs. To address this, we propose SparseRM, which leverages Sparse Autoencoder (SAE) to extract preference-relevant information encoded in model representations, enabling the construction of a lightweight and interpretable reward model. SparseRM first employs SAE to decompose LLM representations into interpretable directions that capture preference-relevant features. The representations are then projected onto these directions to compute alignment scores, which quantify the strength of each preference feature in the representations. A simple reward head aggregates these scores to predict preference scores. Experiments on three preference modeling tasks show that SparseRM achieves superior performance over most mainstream RMs while using less than 1% of trainable parameters. Moreover, it integrates seamlessly into downstream alignment pipelines, highlighting its potential for efficient alignment.

</details>


### [5] [Neurophysiological Characteristics of Adaptive Reasoning for Creative Problem-Solving Strategy](https://arxiv.org/abs/2511.07912)
*Jun-Young Kim,Young-Seok Kweon,Gi-Hwan Shin,Seong-Whan Lee*

Main category: cs.AI

TL;DR: 本研究通过脑电图和卡片分类任务探索人类适应性推理的神经机制，发现人类在规则变化时表现出协调的delta-theta-alpha振荡动态，而多模态大语言模型仅能进行短期反馈驱动调整，缺乏真正的适应性推理能力。


<details>
  <summary>Details</summary>
Motivation: 适应性推理使人类能够在环境规则或情境变化时灵活调整推理策略，但其潜在的神经动力学机制尚不清楚。本研究旨在揭示适应性推理的神经生理机制，并与多模态大语言模型的性能进行比较。

Method: 使用卡片分类范式结合脑电图技术，分析刺激锁定和反馈锁定的神经活动，并与多模态大语言模型的推理表现进行对比。

Result: 发现人类在适应性推理中表现出协调的delta-theta-alpha动态：早期delta-theta活动反映探索性监测和规则推断，而枕叶alpha参与表明成功规则识别后的注意力确认稳定化。多模态大语言模型仅表现出短期反馈驱动调整，缺乏层次规则抽象或真正的适应性推理。

Conclusion: 这些发现识别了人类适应性推理的神经特征，并强调了需要开发包含振荡反馈协调的脑启发人工智能，以实现真正的上下文敏感适应。

Abstract: Adaptive reasoning enables humans to flexibly adjust inference strategies when environmental rules or contexts change, yet its underlying neural dynamics remain unclear. This study investigated the neurophysiological mechanisms of adaptive reasoning using a card-sorting paradigm combined with electroencephalography and compared human performance with that of a multimodal large language model. Stimulus- and feedback-locked analyses revealed coordinated delta-theta-alpha dynamics: early delta-theta activity reflected exploratory monitoring and rule inference, whereas occipital alpha engagement indicated confirmatory stabilization of attention after successful rule identification. In contrast, the multimodal large language model exhibited only short-term feedback-driven adjustments without hierarchical rule abstraction or genuine adaptive reasoning. These findings identify the neural signatures of human adaptive reasoning and highlight the need for brain-inspired artificial intelligence that incorporates oscillatory feedback coordination for true context-sensitive adaptation.

</details>


### [6] [Toward Practical BCI: A Real-time Wireless Imagined Speech EEG Decoding System](https://arxiv.org/abs/2511.07936)
*Ji-Ha Park,Heon-Gyu Kwak,Gi-Hwan Shin,Yoo-In Jeon,Sun-Min Park,Ji-Yeon Hwang,Seong-Whan Lee*

Main category: cs.AI

TL;DR: 本文介绍了一种实时无线想象语音脑电图解码系统，旨在实现灵活和日常使用的脑机接口技术，在有限环境下取得了4类分类62.00%和46.67%的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统脑机接口研究主要局限于静态和固定环境，限制了实际应用。为了推进实用脑机接口技术，需要开发能够在日常环境中使用的灵活系统。

Method: 采用实时无线想象语音脑电图解码系统，使用实验室流层管理连续实时脑电信号流，集成用户识别模块提供个性化服务，并扩展到便携无线硬件设备。

Result: 该系统在有线设备上实现了4类分类62.00%的准确率，在便携无线头戴设备上达到46.67%的准确率，能够实时分类用户命令。

Conclusion: 这项研究向真正实用和可访问的脑机接口技术迈出了重要一步，为未来稳健、实用和个性化神经接口研究确立了明确方向。

Abstract: Brain-computer interface (BCI) research, while promising, has largely been confined to static and fixed environments, limiting real-world applicability. To move towards practical BCI, we introduce a real-time wireless imagined speech electroencephalogram (EEG) decoding system designed for flexibility and everyday use. Our framework focuses on practicality, demonstrating extensibility beyond wired EEG devices to portable, wireless hardware. A user identification module recognizes the operator and provides a personalized, user-specific service. To achieve seamless, real-time operation, we utilize the lab streaming layer to manage the continuous streaming of live EEG signals to the personalized decoder. This end-to-end pipeline enables a functional real-time application capable of classifying user commands from imagined speech EEG signals, achieving an overall 4-class accuracy of 62.00 % on a wired device and 46.67 % on a portable wireless headset. This paper demonstrates a significant step towards truly practical and accessible BCI technology, establishing a clear direction for future research in robust, practical, and personalized neural interfaces.

</details>


### [7] [Thinker: Training LLMs in Hierarchical Thinking for Deep Search via Multi-Turn Interaction](https://arxiv.org/abs/2511.07943)
*Jun Xu,Xinkai Du,Yu Ao,Peilong Zhao,Yang Li,Ling Zhong,Lin Yuan,Zhongpu Bo,Xiaorui Wang,Mengshu Sun,Zhengke Gui,Dalong Zhang,Zhaoyang Wang,Qiwei Wang,Yangyang Hou,Zhiying Yin,Haofen Wang,Huajun Chen,Lei Liang,Jun Zhou*

Main category: cs.AI

TL;DR: 提出了Thinker模型，通过多轮交互进行深度搜索，将复杂问题分解为可独立解决的子问题，并使用自然语言和逻辑函数双重表示来支持知识库和网页搜索，同时通过逻辑函数传递子问题间的依赖关系以增强逻辑一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要使用端到端强化学习训练LLMs利用外部检索器解决复杂问题，但忽视了推理过程的监督，难以保证逻辑一致性和严谨性。

Method: 提出Thinker分层思维模型，将复杂问题分解为子问题，每个子问题用自然语言和逻辑函数双重表示，通过逻辑函数传递依赖关系，并进行知识边界确定以避免不必要的外部搜索。

Result: 实验结果表明，仅用数百个训练样本，Thinker的性能就与现有基线方法相当；当扩展到完整训练集时，Thinker在各种数据集和模型大小上显著优于这些方法。

Conclusion: Thinker通过分层思维和多轮交互使推理过程可监督和可验证，有效提升了LLMs利用外部知识解决复杂问题的能力。

Abstract: Efficient retrieval of external knowledge bases and web pages is crucial for enhancing the reasoning abilities of LLMs. Previous works on training LLMs to leverage external retrievers for solving complex problems have predominantly employed end-to-end reinforcement learning. However, these approaches neglect supervision over the reasoning process, making it difficult to guarantee logical coherence and rigor. To address these limitations, we propose Thinker, a hierarchical thinking model for deep search through multi-turn interaction, making the reasoning process supervisable and verifiable. It decomposes complex problems into independently solvable sub-problems, each dually represented in both natural language and an equivalent logical function to support knowledge base and web searches. Concurrently, dependencies between sub-problems are passed as parameters via these logical functions, enhancing the logical coherence of the problem-solving process. To avoid unnecessary external searches, we perform knowledge boundary determination to check if a sub-problem is within the LLM's intrinsic knowledge, allowing it to answer directly. Experimental results indicate that with as few as several hundred training samples, the performance of Thinker is competitive with established baselines. Furthermore, when scaled to the full training set, Thinker significantly outperforms these methods across various datasets and model sizes. The source code is available at https://github.com/OpenSPG/KAG-Thinker.

</details>


### [8] [Capturing Complex Spatial-Temporal Dependencies in Traffic Forecasting: A Self-Attention Approach](https://arxiv.org/abs/2511.07980)
*Zheng Chenghong,Zongyin Deng,Liu Cheng,Xiong Simin,Di Deshi,Li Guanyao*

Main category: cs.AI

TL;DR: 提出ST-SAM模型，通过自注意力机制联合学习时空依赖关系，用于交通流量预测，相比现有方法在准确性和效率上都有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法将空间和时间依赖性分开研究，无法捕捉它们的联合效应，导致交通预测效果受限。

Method: 使用区域嵌入层学习时间特定嵌入，然后基于自注意力机制的空间-时间依赖学习模块来捕获附近和远处区域的联合时空依赖。

Result: 在两个真实数据集上的实验表明，ST-SAM在RMSE上平均提升15%，MAPE提升17%，训练时间快32倍。

Conclusion: ST-SAM完全依赖自注意力机制捕获局部和全局时空相关性，使其在交通预测任务中既有效又高效。

Abstract: We study the problem of traffic forecasting, aiming to predict the inflow and outflow of a region in the subsequent time slot. The problem is complex due to the intricate spatial and temporal interdependence among regions. Prior works study the spatial and temporal dependency in a decouple manner, failing to capture their joint effect. In this work, we propose ST-SAM, a novel and efficient Spatial-Temporal Self-Attention Model for traffic forecasting. ST-SAM uses a region embedding layer to learn time-specific embedding from traffic data for regions. Then, it employs a spatial-temporal dependency learning module based on self-attention mechanism to capture the joint spatial-temporal dependency for both nearby and faraway regions. ST-SAM entirely relies on self-attention to capture both local and global spatial-temporal correlations, which make it effective and efficient. Extensive experiments on two real world datasets show that ST-SAM is substantially more accurate and efficient than the state-of-the-art approaches (with an average improvement of up to 15% on RMSE, 17% on MAPE, and 32 times on training time in our experiments).

</details>


### [9] [The One Where They Brain-Tune for Social Cognition: Multi-Modal Brain-Tuning on Friends](https://arxiv.org/abs/2511.07988)
*Nico Policzer,Cameron Braunstein,Mariya Toneva*

Main category: cs.AI

TL;DR: 本研究将脑调谐方法扩展到多模态音频-视频模型，通过针对社交处理关键区域STS进行微调，提高了脑对齐性并改善了社交认知任务（情景喜剧中的讽刺检测）性能。


<details>
  <summary>Details</summary>
Motivation: 扩展脑调谐方法到多模态领域，通过增强模型与大脑社交处理区域的对齐性来改善社交认知能力。

Method: 使用多模态音频-视频模型，针对社交处理关键区域STS进行脑调谐，让模型更好地预测观看《老友记》时的fMRI活动。

Result: 显著提高了与STS及邻近ROI的脑对齐性，并在与训练数据相关的社交认知任务（情景喜剧讽刺检测）上表现更好。

Conclusion: 成功将脑调谐扩展到多模态领域，证明通过调谐相关功能区域可以改善下游任务性能。

Abstract: Recent studies on audio models show brain-tuning - fine-tuning models to better predict corresponding fMRI activity - improves brain alignment and increases performance on downstream semantic and audio tasks. We extend this approach to a multimodal audio-video model to enhance social cognition, targeting the Superior Temporal Sulcus (STS), a key region for social processing, while subjects watch Friends. We find significant increases in brain alignment to the STS and an adjacent ROI, as well as improvements to a social cognition task related to the training data - sarcasm detection in sitcoms. In summary, our study extends brain-tuning to the multi-modal domain, demonstrating improvements to a downstream task after tuning to a relevant functional region.

</details>


### [10] [Multivariate Time series Anomaly Detection:A Framework of Hidden Markov Models](https://arxiv.org/abs/2511.07995)
*Jinbo Li,Witold Pedrycz,Iqbal Jamal*

Main category: cs.AI

TL;DR: 本文提出了一种将多元时间序列转换为单变量时间序列的异常检测方法，结合FCM聚类、模糊积分和隐马尔可夫模型进行异常检测。


<details>
  <summary>Details</summary>
Motivation: 针对多元时间序列异常检测的复杂性，研究旨在通过降维转换技术简化问题，提高检测效率和准确性。

Method: 使用FCM聚类和模糊积分将多元时间序列转换为单变量时间序列，然后应用隐马尔可夫模型构建异常检测器，并比较不同转换方法的性能。

Result: 通过一系列实验研究和对比分析，验证了所提方法的有效性，并比较了不同转换技术在异常检测中的表现。

Conclusion: 基于多元到单变量转换的隐马尔可夫模型方法在时间序列异常检测中表现良好，为复杂多元时间序列分析提供了有效解决方案。

Abstract: In this study, we develop an approach to multivariate time series anomaly detection focused on the transformation of multivariate time series to univariate time series. Several transformation techniques involving Fuzzy C-Means (FCM) clustering and fuzzy integral are studied. In the sequel, a Hidden Markov Model (HMM), one of the commonly encountered statistical methods, is engaged here to detect anomalies in multivariate time series. We construct HMM-based anomaly detectors and in this context compare several transformation methods. A suite of experimental studies along with some comparative analysis is reported.

</details>


### [11] [Dual-Process Scaffold Reasoning for Enhancing LLM Code Debugging](https://arxiv.org/abs/2511.08052)
*Po-Chung Hsieh,Chin-Po Chen,Jeng-Lin Li,Ming-Ching Chang*

Main category: cs.AI

TL;DR: 提出了一种基于心理学理论的Scaffold Reasoning框架用于代码调试，通过三个流（Scaffold流、分析流和集成流）来优化LLM的推理过程，在DebugBench上达到了88.91%的通过率和5.36秒的平均推理时间。


<details>
  <summary>Details</summary>
Motivation: 当前LLM虽然具备复杂问题解决能力，但如何在推理步骤的复杂性和计算效率之间找到平衡仍是一个未解决的问题。缺乏对System 2推理的深入探索，需要基于心理学理论优化认知路径。

Method: 提出Scaffold Reasoning框架，包含三个流：Scaffold流构建参考代码，分析流分析错误代码，集成流将两者整合。该框架结合心理学理论，优化LLM的推理过程。

Result: 在DebugBench基准测试中，框架达到了88.91%的通过率，平均每个问题的推理时间为5.36秒，在推理准确性和效率方面均优于其他推理方法。

Conclusion: 该框架与人类认知过程对齐，在不同问题难度和错误类型下展现了各种认知路径的优势和局限性，为LLM推理优化提供了心理学基础。

Abstract: Recent LLMs have demonstrated sophisticated problem-solving capabilities on various benchmarks through advanced reasoning algorithms. However, the key research question of identifying reasoning steps that balance complexity and computational efficiency remains unsolved. Recent research has increasingly drawn upon psychological theories to explore strategies for optimizing cognitive pathways. The LLM's final outputs and intermediate steps are regarded as System 1 and System 2, respectively. However, an in-depth exploration of the System 2 reasoning is still lacking. Therefore, we propose a novel psychologically backed Scaffold Reasoning framework for code debugging, which encompasses the Scaffold Stream, Analytic Stream, and Integration Stream. The construction of reference code within the Scaffold Stream is integrated with the buggy code analysis results produced by the Analytic Stream through the Integration Stream. Our framework achieves an 88.91% pass rate and an average inference time of 5.36 seconds per-problem on DebugBench, outperforming other reasoning approaches across various LLMs in both reasoning accuracy and efficiency. Further analyses elucidate the advantages and limitations of various cognitive pathways across varying problem difficulties and bug types. Our findings also corroborate the alignment of the proposed Scaffold Reasoning framework with human cognitive processes.

</details>


### [12] [Prudential Reliability of Large Language Models in Reinsurance: Governance, Assurance, and Capital Efficiency](https://arxiv.org/abs/2511.08082)
*Stella C. Dong*

Main category: cs.AI

TL;DR: 本文开发了一个评估再保险中大型语言模型可靠性的审慎框架，通过五支柱架构将监管期望转化为可衡量的生命周期控制，并在RAIRAB基准测试中验证了该框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在再保险领域的应用日益增多，需要建立一个审慎框架来评估其可靠性，确保符合现有监管标准如Solvency II、SR 11-7等的要求。

Method: 提出了五支柱架构（治理、数据溯源、保证、韧性和监管对齐），并将其实现为再保险AI可靠性和保证基准(RAIRAB)，通过检索接地配置在六个任务系列中评估LLM的接地准确性、幻觉减少和透明度提升。

Result: 检索接地配置实现了更高的接地准确性(0.90)，幻觉和解释漂移减少了约40%，透明度几乎翻倍，有效降低了风险转移和资本配置中的信息摩擦。

Conclusion: 现有审慎原则已经能够容纳可靠的AI，前提是治理明确、数据可追溯且保证可验证，该框架为再保险领域的AI应用提供了实用的监管合规路径。

Abstract: This paper develops a prudential framework for assessing the reliability of large language models (LLMs) in reinsurance. A five-pillar architecture--governance, data lineage, assurance, resilience, and regulatory alignment--translates supervisory expectations from Solvency II, SR 11-7, and guidance from EIOPA (2025), NAIC (2023), and IAIS (2024) into measurable lifecycle controls. The framework is implemented through the Reinsurance AI Reliability and Assurance Benchmark (RAIRAB), which evaluates whether governance-embedded LLMs meet prudential standards for grounding, transparency, and accountability. Across six task families, retrieval-grounded configurations achieved higher grounding accuracy (0.90), reduced hallucination and interpretive drift by roughly 40%, and nearly doubled transparency. These mechanisms lower informational frictions in risk transfer and capital allocation, showing that existing prudential doctrines already accommodate reliable AI when governance is explicit, data are traceable, and assurance is verifiable.

</details>


### [13] [Gateways to Tractability for Satisfiability in Pearl's Causal Hierarchy](https://arxiv.org/abs/2511.08091)
*Robert Ganian,Marlene Gründel,Simon Wietheger*

Main category: cs.AI

TL;DR: 本文通过参数化复杂性理论重新审视Pearl因果层次(PCH)的可满足性问题，发现了首个可处理性路径，提出了基于原始树宽和变量数量的固定参数和XP算法，并建立了匹配的硬度结果来界定可处理性边界。


<details>
  <summary>Details</summary>
Motivation: Pearl因果层次(PCH)是推理概率、干预和反事实陈述的核心框架，但其可满足性问题在几乎所有经典设置中都是计算难解的。本文旨在通过参数化复杂性理论来应对这一挑战。

Method: 采用参数化复杂性方法，使用原始树宽和变量数量作为参数，开发了固定参数和XP算法。技术上突破了典型的树宽动态规划范式，利用结构良好的因果模型的特征化，为因果推理提供了新的算法工具包。

Result: 为关键的概率和反事实片段提供了可满足性的固定参数和XP算法，并建立了匹配的硬度结果，精确刻画了可处理性的边界。

Conclusion: 通过参数化复杂性理论成功识别了PCH可满足性问题的首个可处理性路径，为因果推理提供了新的算法工具包，并明确了可处理性的理论边界。

Abstract: Pearl's Causal Hierarchy (PCH) is a central framework for reasoning about probabilistic, interventional, and counterfactual statements, yet the satisfiability problem for PCH formulas is computationally intractable in almost all classical settings. We revisit this challenge through the lens of parameterized complexity and identify the first gateways to tractability. Our results include fixed-parameter and XP-algorithms for satisfiability in key probabilistic and counterfactual fragments, using parameters such as primal treewidth and the number of variables, together with matching hardness results that map the limits of tractability. Technically, we depart from the dynamic programming paradigm typically employed for treewidth-based algorithms and instead exploit structural characterizations of well-formed causal models, providing a new algorithmic toolkit for causal reasoning.

</details>


### [14] [Towards Provably Unlearnable Examples via Bayes Error Optimisation](https://arxiv.org/abs/2511.08191)
*Ruihan Zhang,Jun Sun,Ee-Peng Lim,Peixin Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种基于最大化贝叶斯误差的新方法来构建不可学习样本，这些样本看起来自然但能阻止机器学习模型从中有效学习，解决了现有方法缺乏理论保证和在混合干净数据时失效的问题。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型依赖大规模数据训练，用户数据保护成为重要问题。现有不可学习样本方法依赖启发式试验且缺乏理论保证，在混合干净数据时效果消失。

Method: 提出基于最大化贝叶斯误差的优化方法，使用投影梯度上升进行高效求解，系统性地增加分类的不可约误差。

Result: 实验结果表明该方法能有效限制数据可学习性，在多个数据集和模型架构上保持有效性，即使与干净样本混合时仍能发挥作用。

Conclusion: 该方法提供了理论保证的不可学习样本构建方案，能有效保护用户数据隐私，在混合数据场景下仍保持鲁棒性。

Abstract: The recent success of machine learning models, especially large-scale classifiers and language models, relies heavily on training with massive data. These data are often collected from online sources. This raises serious concerns about the protection of user data, as individuals may not have given consent for their data to be used in training. To address this concern, recent studies introduce the concept of unlearnable examples, i.e., data instances that appear natural but are intentionally altered to prevent models from effectively learning from them. While existing methods demonstrate empirical effectiveness, they typically rely on heuristic trials and lack formal guarantees. Besides, when unlearnable examples are mixed with clean data, as is often the case in practice, their unlearnability disappears. In this work, we propose a novel approach to constructing unlearnable examples by systematically maximising the Bayes error, a measurement of irreducible classification error. We develop an optimisation-based approach and provide an efficient solution using projected gradient ascent. Our method provably increases the Bayes error and remains effective when the unlearning examples are mixed with clean samples. Experimental results across multiple datasets and model architectures are consistent with our theoretical analysis and show that our approach can restrict data learnability, effectively in practice.

</details>


### [15] [FaithAct: Faithfulness Planning and Acting in MLLMs](https://arxiv.org/abs/2511.08409)
*Junxian Li,Xinyue Xu,Sai Ma,Sichao Li*

Main category: cs.AI

TL;DR: 该论文提出了FaithEval评估框架和FaithAct规划框架，用于解决多模态推理中的不忠实问题，通过强制每个推理步骤的证据基础来提高感知忠实度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多模态推理中经常产生看似合理但缺乏依据的推理链，这些推理链可能与感知证据或最终结论不符，存在行为忠实度和感知忠实度的问题。

Method: 区分行为忠实度和感知忠实度，引入FaithEval量化步骤级和链级忠实度，提出FaithAct框架在每一步推理中强制证据基础。

Result: 在多个推理基准测试中，FaithAct相比基于提示和工具增强的基线方法，将感知忠实度提高了26%，且不降低任务准确性。

Conclusion: 将忠实度作为指导原则不仅能减轻幻觉问题，还能产生更稳定的推理轨迹，为多模态推理中的忠实度评估和执行建立了统一框架。

Abstract: Unfaithfulness remains a persistent challenge for large language models (LLMs), which often produce plausible yet ungrounded reasoning chains that diverge from perceptual evidence or final conclusions. We distinguish between behavioral faithfulness (alignment between reasoning and output) and perceptual faithfulness (alignment between reasoning and input), and introduce FaithEval for quantifying step-level and chain-level faithfulness by evaluating whether each claimed object is visually supported by the image. Building on these insights, we propose FaithAct, a faithfulness-first planning and acting framework that enforces evidential grounding at every reasoning step. Experiments across multiple reasoning benchmarks demonstrate that FaithAct improves perceptual faithfulness by up to 26% without degrading task accuracy compared to prompt-based and tool-augmented baselines. Our analysis shows that treating faithfulness as a guiding principle not only mitigates hallucination but also leads to more stable reasoning trajectories. This work thereby establishes a unified framework for both evaluating and enforcing faithfulness in multimodal reasoning.

</details>


### [16] [Dataset Safety in Autonomous Driving: Requirements, Risks, and Assurance](https://arxiv.org/abs/2511.08439)
*Alireza Abbaspour,Tejaskumar Balgonda Patil,B Ravi Kiran,Russel Mohr,Senthil Yogamani*

Main category: cs.AI

TL;DR: 本文提出了一个基于ISO/PAS 8800指南的结构化框架，用于开发安全的自动驾驶数据集，涵盖数据收集、标注、管理和维护的全生命周期，并整合了严格的安全分析来识别和减轻数据集不足带来的风险。


<details>
  <summary>Details</summary>
Motivation: 数据集完整性对AI系统的安全性和可靠性至关重要，特别是在自动驾驶领域。当前缺乏系统化的数据集安全开发框架，需要确保数据集符合安全标准并能够支撑可靠的AI系统。

Method: 提出了AI数据飞轮和数据集生命周期框架，包括数据收集、标注、管理和维护等阶段。整合了严格的安全分析来识别危险源和风险，定义了数据集安全要求的建立过程，并提出了验证和验证策略。

Result: 开发了一个结构化的数据集安全框架，能够识别和减轻数据集不足带来的风险，确保数据集符合ISO/PAS 8800安全标准，为自动驾驶AI系统提供安全保证。

Conclusion: 通过整合数据集安全框架、安全分析和验证策略，本文旨在推进自动驾驶应用中稳健、安全保证的AI系统发展，为当前挑战和未来方向提供见解。

Abstract: Dataset integrity is fundamental to the safety and reliability of AI systems, especially in autonomous driving. This paper presents a structured framework for developing safe datasets aligned with ISO/PAS 8800 guidelines. Using AI-based perception systems as the primary use case, it introduces the AI Data Flywheel and the dataset lifecycle, covering data collection, annotation, curation, and maintenance. The framework incorporates rigorous safety analyses to identify hazards and mitigate risks caused by dataset insufficiencies. It also defines processes for establishing dataset safety requirements and proposes verification and validation strategies to ensure compliance with safety standards. In addition to outlining best practices, the paper reviews recent research and emerging trends in dataset safety and autonomous vehicle development, providing insights into current challenges and future directions. By integrating these perspectives, the paper aims to advance robust, safety-assured AI systems for autonomous driving applications.

</details>


### [17] [A Matter of Interest: Understanding Interestingness of Math Problems in Humans and Language Models](https://arxiv.org/abs/2511.08548)
*Shubhra Mishra,Yuka Machino,Gabriel Poesia,Albert Jiang,Joy Hsu,Adrian Weller,Challenger Mishra,David Broman,Joshua B. Tenenbaum,Mateja Jamnik,Cedegao E. Zhang,Katherine M. Collins*

Main category: cs.AI

TL;DR: 本研究通过两项实证研究探讨了人类与LLM在数学趣味性和难度评估上的一致性，发现LLM虽然大致认同人类的趣味性概念，但无法准确捕捉人类判断的分布特征，且与人类选择趣味性理由的相关性较弱。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统（如LLM）越来越多地参与数学研究和教育，理解它们与人类在数学问题趣味性和难度判断上的一致性变得重要。

Method: 通过两项实证研究，分别对众包平台参与者和国际数学奥林匹克竞赛选手进行调查，比较人类与多种LLM对数学问题趣味性和难度的评估。

Result: LLM在趣味性判断上大致与人类一致，但无法准确反映人类判断的分布模式；大多数LLM与人类选择趣味性理由的相关性较弱。

Conclusion: 当前LLM在捕捉人类数学趣味性判断方面既有潜力也有局限，对于数学AI思维伙伴关系的发展具有重要意义。

Abstract: The evolution of mathematics has been guided in part by interestingness. From researchers choosing which problems to tackle next, to students deciding which ones to engage with, people's choices are often guided by judgments about how interesting or challenging problems are likely to be. As AI systems, such as LLMs, increasingly participate in mathematics with people -- whether for advanced research or education -- it becomes important to understand how well their judgments align with human ones. Our work examines this alignment through two empirical studies of human and LLM assessment of mathematical interestingness and difficulty, spanning a range of mathematical experience. We study two groups: participants from a crowdsourcing platform and International Math Olympiad competitors. We show that while many LLMs appear to broadly agree with human notions of interestingness, they mostly do not capture the distribution observed in human judgments. Moreover, most LLMs only somewhat align with why humans find certain math problems interesting, showing weak correlation with human-selected interestingness rationales. Together, our findings highlight both the promises and limitations of current LLMs in capturing human interestingness judgments for mathematical AI thought partnerships.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [18] [Fractional Programming and Manifold Optimization for Reciprocal BD-RIS Scattering Matrix Design](https://arxiv.org/abs/2511.07683)
*Marko Fidanovski,Iván Alexander Morales Sandoval,Kuranage Roche Rayan Ranasinghe,Giuseppe Thadeu Freitas de Abreu,Emil Björnson,Bruno Clerckx*

Main category: eess.SP

TL;DR: 本文研究了使用分数规划技术最大化超对角可重构智能表面辅助多用户多输入单输出系统的和速率性能问题。


<details>
  <summary>Details</summary>
Motivation: 提高BD-RIS辅助MU-MISO系统的和速率性能，通过更有效的优化方法降低复杂度并超越现有技术水平。

Method: 利用拉格朗日对偶变换和二次变换推导等效目标函数，然后通过流形优化框架进行迭代求解。

Result: 这些技术降低了散射矩阵优化问题的复杂度，并在相同系统条件下相比现有方法提供了显著的性能增益。

Conclusion: 仿真结果证实了所提方法在改善和速率性能方面的有效性。

Abstract: We investigate the problem of maximizing the sum-rate performance of a beyond-diagonal reconfigurable intelligent surface (BD-RIS)-aided multi-user (MU)-multiple-input single-output (MISO) system using fractional programming (FP) techniques. More specifically, we leverage the Lagrangian Dual Transform (LDT) and Quadratic Transform (QT) to derive an equivalent objective function which is then solved iteratively via a manifold optimization framework. It is shown that these techniques reduce the complexity of the optimization problem for the scattering matrix solution, while also providing notable performance gains compared to state-of-the-art (SotA) methods under the same system conditions. Simulation results confirm the effectiveness of the proposed method in improving sum-rate performance.

</details>


### [19] [DMA-aided MU-MISO Systems for Power Splitting SWIPT via Lorentzian-Constrained Holography](https://arxiv.org/abs/2511.08125)
*Askin Altinoklu,Leila Musavian*

Main category: eess.SP

TL;DR: 本文提出了一种用于DMA辅助多用户MISO系统中SWIPT用户的最优功率分配和波束成形设计，通过交替优化框架最小化发射功率，同时满足用户的SINR和能量收集要求。


<details>
  <summary>Details</summary>
Motivation: 传统波束成形架构需要大量RF链和移相器，而DMA辅助架构能减少这些需求，但需要在洛伦兹约束下进行优化，限制了幅度和相位优化。

Method: 采用基于半定规划的交替优化框架，集成多种洛伦兹约束全息方案（包括自适应半径LCH），并评估非线性EH模型和电路噪声效应。

Result: 仿真结果表明，与基线方法相比，所提出的设计显著降低了发射功率，突出了ARLCH和最优功率分配在DMA辅助SWIPT系统中的效率。

Conclusion: DMA辅助架构结合ARLCH方案和最优功率分配策略，能够有效降低系统发射功率，提高SWIPT系统性能。

Abstract: This paper presents an optimal power splitting and beamforming design for co-located simultaneous wireless information and power transfer (SWIPT) users in Dynamic Metasurface Antenna (DMA)-aided multiuser multiple-input single-output (MISO) systems. The objective is to minimize transmit power while meeting users signal-to-interference-plus-noise ratio (SINR) and energy harvesting (EH) requirements. The problem is solved via an alternating optimization framework based on semidefinite programming (SDP), where metasurface tunability follows Lorentzian-constrained holography (LCH). In contrast to traditional beamforming architectures, DMA-assisted architectures reduce the need for RF chains and phase shifters but require optimization under the Lorentzian constraint limiting the amplitude and phase optimizations. Hence, the proposed method integrates several LCH schemes, including the recently proposed adaptive-radius LCH (ARLCH), and evaluates nonlinear EH models and circuit noise effects. Simulation results show that the proposed design significantly reduces transmit power compared with baseline methods, highlighting the efficiency of ARLCH and optimal power splitting in DMA-assisted SWIPT systems.

</details>


### [20] [Waveform-domain NOMA: An Enabler for ISAC in Uplink Transmission](https://arxiv.org/abs/2511.08474)
*Jialiang Zhu,Hamza Haif,Abdelali Arous,Huseyin Arslan,Arman Farhang*

Main category: eess.SP

TL;DR: 本文研究了在6G集成感知与通信系统中，使用AFDM或OTFS作为上行波形、OFDM用于下行传输和感知的波形域非正交多址系统，相比功率域NOMA系统具有更好的误码率性能。


<details>
  <summary>Details</summary>
Motivation: 根据3GPP对6G空口的决策，OFDM波形是未来集成感知与通信系统的主要候选方案。当OFDM用于下行传输和感知，而不同波形用于上行时，会产生功率域或波形域的非正交多址场景。

Method: 采用AFDM或OTFS作为上行波形，OFDM用于下行传输和感知。开发了AFDM帧设计和噪声功率估计方法，并应用二维正交匹配追踪算法进行感知，迭代识别每个目标的时延-多普勒分量。

Result: 仿真结果表明，使用AFDM或OTFS的WD-NOMA ISAC系统在误码率性能上优于仅使用OFDM波形的PD-NOMA系统。提出的噪声功率估计方法进一步改善了误码率性能。

Conclusion: 波形域NOMA ISAC系统在集成感知与通信应用中具有显著优势，AFDM和OTFS作为上行波形能够有效提升系统性能。

Abstract: According to the recent 3GPP decisions on 6G air interface, orthogonal frequency-division multiplexing (OFDM)-based waveforms are the primary candidates for future integrated sensing and communication (ISAC) systems. In this paper, we consider a monostatic sensing scenario in which OFDM is used for the downlink and its reflected echo signal is used for sensing. OFDM and discrete Fourier transform-spread OFDM (DFT-s-OFDM) are the options for uplink transmission. When OFDM is used in the uplink, the power difference between this signal and the echo signal leads to a power-domain non-orthogonal multiple access (PD-NOMA) scenario. In contrast, adopting DFT-s-OFDM as uplink signal enables a waveform-domain NOMA(WD-NOMA). Affine frequency-division multiplexing (AFDM) and orthogonal time frequency space (OTFS) have been proven to be DFT-s-OFDM based waveforms. This work focuses on such a WD-NOMA system, where AFDM or OTFS is used as uplink waveform and OFDM is employed for downlink transmission and sensing. We show that the OFDM signal exhibits additive white Gaussian noise (AWGN)-like behavior in the affine domain, allowing it to be modeled as white noise in uplink symbol detection. To enable accurate data detection performance, an AFDM frame design and a noise power estimation (NPE) method are developed. Furthermore, a two-dimensional orthogonal matching pursuit (2D-OMP) algorithm is applied for sensing by iteratively identifying delay-Doppler components of each target. Simulation results demonstrate that the WD-NOMA ISAC system, employing either AFDM or OTFS, outperforms the PD-NOMA ISAC system that uses only the OFDM waveform in terms of bit error rate (BER) performance. Furthermore, the proposed NPE method yields additional improvements in BER.

</details>


### [21] [Low Overhead Channel Estimation in MIMO OTFS Wireless Communication Systems](https://arxiv.org/abs/2511.08504)
*Kailong Wang,Athina Petropulu*

Main category: eess.SP

TL;DR: 提出了一种用于MIMO OTFS系统的低开销信道估计方法，通过在时频域嵌入导频并使用虚拟阵列构建稀疏信号恢复问题，实现高性能信道参数估计。


<details>
  <summary>Details</summary>
Motivation: 现有OTFS信道估计技术要么需要非重叠的DD域导频和防护区域导致通信速率下降，要么需要复杂算法处理重叠导频增加接收机成本和复杂度。

Method: 在时频域嵌入导频，使用TF和DD防护单元保持波形正交性和数据完整性，通过构建虚拟阵列和稀疏信号恢复问题获得高分辨率信道参数估计。

Result: 仿真结果表明该方法仅需少量导频和防护单元即可获得良好性能，所需开销与发射天线数量无关，具有良好的可扩展性。

Conclusion: 该方法考虑了实际矩形发射脉冲成形和接收机匹配滤波，同时考虑了分数多普勒效应，为大规模MIMO阵列提供了有效的信道估计解决方案。

Abstract: Orthogonal Time Frequency Space (OTFS) modulation has recently garnered attention due to its robustness in high-mobility wireless communication environments. In OTFS, the data symbols are mapped to the Doppler-Delay (DD) domain. In this paper, we address bandwidth-efficient estimation of channel state information (CSI) for MIMO OTFS systems. Existing channel estimation techniques either require non-overlapped DD-domain pilots and associated guard regions across multiple antennas, sacrificing significant communication rate as the number of transmit antennas increases, or sophisticated algorithms to handle overlapped pilots, escalating the cost and complexity of receivers. We introduce a novel pilot-aided channel estimation method that enjoys low overhead while achieving high performance. Our approach embeds pilots within each OTFS burst in the Time-Frequency (TF) domain. We propose a novel use of TF and DD guard bins, aiming to preserve waveform orthogonality on the pilot bins and DD data integrity, respectively. The receiver first obtains low-complexity coarse estimates of the channel parameters. Leveraging the orthogonality, a virtual array (VA) is constructed. This enables the formulation of a sparse signal recovery (SSR) problem, in which the coarse estimates are used to build a low-dimensional dictionary matrix. The SSR solution yields high-resolution estimates of channel parameters. Simulation results show that the proposed approach achieves good performance with only a small number of pilots and guard bins. Furthermore, the required overhead is independent of the number of transmit antennas, ensuring good scalability of the proposed method for large MIMO arrays. The proposed approach considers practical rectangular transmit pulse-shaping and receiver matched filtering, and also accounts for fractional Doppler effects.

</details>


### [22] [Hybrid Bit and Semantic Communications](https://arxiv.org/abs/2404.19477)
*Kaiwen Yu,Renhe Fan,Gang Wu,Zhijin Qin*

Main category: eess.SP

TL;DR: 提出了一种名为HybridBSC的混合比特和语义通信系统，通过在传统数字通信系统中将编码的语义信息插入比特信息进行传输，实现了语义和比特信息的并行传输。


<details>
  <summary>Details</summary>
Motivation: 当前直接将内容映射到传输符号的语义通信方法难以实际部署，限制了语义通信的发展。

Method: 设计了语义插入和提取方案，在传统数字通信系统中利用相同频谱资源将编码的语义信息插入比特信息进行传输。

Result: 基于Pluto软件定义无线电平台在真实无线信道中的实验验证表明，该策略能够同时传输语义和比特信息。

Conclusion: HybridBSC系统可以利用现有通信架构轻松部署，实现比特和语义信息的传输。

Abstract: Semantic communication technology is regarded as a method surpassing the Shannon limit of bit transmission, capable of effectively enhancing transmission efficiency. However, current approaches that directly map content to transmission symbols are challenging to deploy in practice, imposing significant limitations on the development of semantic communication. To address this challenge, we propose a hybrid bit and semantic communication system, named HybridBSC, in which encoded semantic information is inserted into bit information for transmission via conventional digital communication systems utilizing same spectrum resources. The system can be easily deployed using existing communication architecture to achieve bit and semantic information transmission. Particularly, we design a semantic insertion and extraction scheme to implement this strategy. Furthermore, we conduct experimental validation based on the pluto-based software defined radio (SDR) platform in a real wireless channel, demonstrating that the proposed strategy can simultaneously transmit semantic and bit information.

</details>


### [23] [Toward Adaptive BCIs: Enhancing Decoding Stability via User State-Aware EEG Filtering](https://arxiv.org/abs/2511.07891)
*Yeon-Woo Choi,Hye-Bin Shin,Dan Li*

Main category: eess.SP

TL;DR: 本文提出了一种用户状态感知的EEG过滤框架，通过估计用户的认知状态来过滤不可靠的EEG片段，从而提高脑机接口的鲁棒性和长期适应性。


<details>
  <summary>Details</summary>
Motivation: 脑机接口在用户注意力波动、大脑状态随时间变化或存在不规则伪影时性能会迅速下降，需要提高其鲁棒性和长期适应性。

Method: 引入用户状态感知的EEG过滤框架，通过EEG特征连续估计用户的认知状态，并基于估计的注意力水平应用自适应加权来过滤不可靠片段。

Result: 在多个模拟真实BCI场景的EEG数据集上的实验表明，与传统的预处理流程相比，所提出的状态感知过滤提高了分类准确性和稳定性。

Conclusion: 利用大脑衍生的状态信息（即使没有额外的用户标签）可以显著提高基于EEG的实用脑机接口的可靠性。

Abstract: Brain-computer interfaces (BCIs) often suffer from limited robustness and poor long-term adaptability. Model performance rapidly degrades when user attention fluctuates, brain states shift over time, or irregular artifacts appear during interaction. To mitigate these issues, we introduce a user state-aware electroencephalogram (EEG) filtering framework that refines neural representations before decoding user intentions. The proposed method continuously estimates the user's cognitive state (e.g., focus or distraction) from EEG features and filters unreliable segments by applying adaptive weighting based on the estimated attention level. This filtering stage suppresses noisy or out-of-focus epochs, thereby reducing distributional drift and improving the consistency of subsequent decoding. Experiments on multiple EEG datasets that emulate real BCI scenarios demonstrate that the proposed state-aware filtering enhances classification accuracy and stability across different user states and sessions compared with conventional preprocessing pipelines. These findings highlight that leveraging brain-derived state information--even without additional user labels--can substantially improve the reliability of practical EEG-based BCIs.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [24] [Tractable Instances of Bilinear Maximization: Implementing LinUCB on Ellipsoids](https://arxiv.org/abs/2511.07504)
*Raymond Zhang,Hédi Hadiji,Richard Combes*

Main category: stat.ML

TL;DR: 该论文研究了在凸集X和椭球集Θ上最大化x⊤θ的问题，这是线性bandits中的基本问题。作者首先证明对于某些集合（如ℓp球，p>2），除非P=NP，否则不存在高效算法。然后提出了两种新算法，当X是中心椭球时能高效解决该问题。


<details>
  <summary>Details</summary>
Motivation: 线性bandits中的乐观算法需要在每个时间步解决最大化x⊤θ的问题，但现有方法在高维情况下效率低下或无法实现。

Method: 首先证明了某些集合下该问题的计算复杂性（除非P=NP无高效算法），然后提出了两种专门针对中心椭球集X的新算法。

Result: 提供了首个已知的方法来实现高维线性bandits中的乐观算法，当X是中心椭球时能高效求解。

Conclusion: 该研究为高维线性bandits中的乐观算法实现提供了理论基础和实用方法，填补了该领域的重要空白。

Abstract: We consider the maximization of $x^\top θ$ over $(x,θ) \in \mathcal{X} \times Θ$, with $\mathcal{X} \subset \mathbb{R}^d$ convex and $Θ\subset \mathbb{R}^d$ an ellipsoid. This problem is fundamental in linear bandits, as the learner must solve it at every time step using optimistic algorithms. We first show that for some sets $\mathcal{X}$ e.g. $\ell_p$ balls with $p>2$, no efficient algorithms exist unless $\mathcal{P} = \mathcal{NP}$. We then provide two novel algorithms solving this problem efficiently when $\mathcal{X}$ is a centered ellipsoid. Our findings provide the first known method to implement optimistic algorithms for linear bandits in high dimensions.

</details>


### [25] [Distributionally Robust Online Markov Game with Linear Function Approximation](https://arxiv.org/abs/2511.07831)
*Zewu Zheng,Yuanyuan Lin*

Main category: stat.ML

TL;DR: 本文提出了一种名为DR-CCE-LSI的样本高效算法，用于解决多智能体强化学习中的sim-to-real差距问题，能够在环境动态变化的情况下找到ε-近似鲁棒粗相关均衡。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习中sim-to-real差距问题，即智能体在模拟器中训练后在真实环境中性能显著下降的挑战，特别是在多智能体设置下学习鲁棒策略。

Method: 采用分布鲁棒RL框架，假设环境动态变化满足d-矩形性，提出DR-CCE-LSI算法——一种带有探索奖励的最小二乘值迭代算法，专门为多智能体设计。

Result: 当特征映射函数满足特定性质时，DR-CCE-LSI算法能够以O{dHmin{H,1/min{σ_i}}√K}的遗憾界实现ε-近似粗相关均衡，在特征维度d上达到极小极大最优样本复杂度。

Conclusion: 本文提出了首个在该设置下的样本高效算法，在单智能体设置下匹配了最佳结果，并通过仿真研究验证了算法在鲁棒均衡学习中的有效性。

Abstract: The sim-to-real gap, where agents trained in a simulator face significant performance degradation during testing, is a fundamental challenge in reinforcement learning. Extansive works adopt the framework of distributionally robust RL, to learn a policy that acts robustly under worst case environment shift. Within this framework, our objective is to devise algorithms that are sample efficient with interactive data collection and large state spaces. By assuming d-rectangularity of environment dynamic shift, we identify a fundamental hardness result for learning in online Markov game, and address it by adopting minimum value assumption. Then, a novel least square value iteration type algorithm, DR-CCE-LSI, with exploration bonus devised specifically for multiple agents, is proposed to find an \episilon-approximate robust Coarse Correlated Equilibrium(CCE). To obtain sample efficient learning, we find that: when the feature mapping function satisfies certain properties, our algorithm, DR-CCE-LSI, is able to achieve ε-approximate CCE with a regret bound of O{dHmin{H,1/min{σ_i}}\sqrt{K}}, where K is the number of interacting episodes, H is the horizon length, d is the feature dimension, and \simga_i represents the uncertainty level of player i. Our work introduces the first sample-efficient algorithm for this setting, matches the best result so far in single agent setting, and achieves minimax optimalsample complexity in terms of the feature dimension d. Meanwhile, we also conduct simulation study to validate the efficacy of our algorithm in learning a robust equilibrium.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [26] [Optimizing Classification of Infrequent Labels by Reducing Variability in Label Distribution](https://arxiv.org/abs/2511.07459)
*Ashutosh Agarwal*

Main category: cs.LG

TL;DR: LEVER提出了一种新颖的解决方案，通过Siamese风格架构和知识转移来改善极端分类任务中低频类别的性能，显著减少了标签不一致性问题。


<details>
  <summary>Details</summary>
Motivation: 极端分类任务中的低频类别由于样本稀疏导致标签不一致性高，严重影响分类性能，需要专门的方法来解决这一问题。

Method: 采用鲁棒的Siamese风格架构，利用知识转移技术来降低标签不一致性，并增强One-vs-All分类器的性能。

Result: 在多个极端分类数据集上的综合测试显示，该方法在处理低频类别方面取得了显著改进，为该领域设立了新的基准。

Conclusion: LEVER有效解决了极端分类中低频类别的性能问题，同时提供了两个新创建的多意图数据集，为未来研究提供了重要资源。

Abstract: This paper presents a novel solution, LEVER, designed to address the challenges posed by underperforming infrequent categories in Extreme Classification (XC) tasks. Infrequent categories, often characterized by sparse samples, suffer from high label inconsistency, which undermines classification performance. LEVER mitigates this problem by adopting a robust Siamese-style architecture, leveraging knowledge transfer to reduce label inconsistency and enhance the performance of One-vs-All classifiers. Comprehensive testing across multiple XC datasets reveals substantial improvements in the handling of infrequent categories, setting a new benchmark for the field. Additionally, the paper introduces two newly created multi-intent datasets, offering essential resources for future XC research.

</details>


### [27] [Slimmable NAM: Neural Amp Models with adjustable runtime computational cost](https://arxiv.org/abs/2511.07470)
*Steven Atkinson*

Main category: cs.LG

TL;DR: 提出了可调整大小的神经放大器模型，无需额外训练即可改变模型大小和计算成本，让音乐家能够在模型精度和计算资源之间灵活权衡。


<details>
  <summary>Details</summary>
Motivation: 让音乐家能够根据实际需求在模型精度和计算成本之间进行灵活权衡，无需为不同规模的模型进行额外训练。

Method: 开发可调整大小的神经放大器模型架构，支持在推理时动态调整模型大小，同时保持可忽略的计算开销。

Result: 与常用基线方法相比量化了性能表现，并开发了实时音频效果插件的实际演示。

Conclusion: 该方法成功实现了无需额外训练即可调整模型规模的目标，为音乐应用提供了灵活的精度-计算权衡方案。

Abstract: This work demonstrates "slimmable Neural Amp Models", whose size and computational cost can be changed without additional training and with negligible computational overhead, enabling musicians to easily trade off between the accuracy and compute of the models they are using. The method's performance is quantified against commonly-used baselines, and a real-time demonstration of the model in an audio effect plug-in is developed.

</details>


### [28] [Multivariate Variational Autoencoder](https://arxiv.org/abs/2511.07472)
*Mehmet Can Yavuz*

Main category: cs.LG

TL;DR: 提出了多元变分自编码器（MVAE），一种保留高斯可处理性同时解除对角后验限制的VAE变体，通过全局耦合矩阵和每样本对角尺度实现全协方差建模。


<details>
  <summary>Details</summary>
Motivation: 传统VAE使用对角协方差后验限制了建模能力，MVAE旨在保持高斯可处理性的同时实现更灵活的全协方差建模。

Method: MVAE将每个后验协方差分解为全局耦合矩阵C（诱导数据集范围的潜在相关性）和每样本对角尺度（调制局部不确定性），通过L=Cdiag(σ)实现高效重参数化。

Result: 在多个数据集上，MVAE在重建误差、校准指标和无监督结构发现方面均优于对角协方差VAE，特别是在中等潜在维度下表现更佳。

Conclusion: MVAE提供了一种在保持高斯可处理性的同时实现全协方差建模的有效方法，在多个评估维度上均优于传统对角协方差VAE。

Abstract: We present the Multivariate Variational Autoencoder (MVAE), a VAE variant that preserves Gaussian tractability while lifting the diagonal posterior restriction. MVAE factorizes each posterior covariance, where a \emph{global} coupling matrix $\mathbf{C}$ induces dataset-wide latent correlations and \emph{per-sample} diagonal scales modulate local uncertainty. This yields a full-covariance family with analytic KL and an efficient reparameterization via $\mathbf{L}=\mathbf{C}\mathrm{diag}(\boldsymbolσ)$. Across Larochelle-style MNIST variants, Fashion-MNIST, CIFAR-10, and CIFAR-100, MVAE consistently matches or improves reconstruction (MSE~$\downarrow$) and delivers robust gains in calibration (NLL/Brier/ECE~$\downarrow$) and unsupervised structure (NMI/ARI~$\uparrow$) relative to diagonal-covariance VAEs with matched capacity, especially at mid-range latent sizes. Latent-plane visualizations further indicate smoother, more coherent factor traversals and sharper local detail. We release a fully reproducible implementation with training/evaluation scripts and sweep utilities to facilitate fair comparison and reuse.

</details>


### [29] [Comparing Reconstruction Attacks on Pretrained Versus Full Fine-tuned Large Language Model Embeddings on Homo Sapiens Splice Sites Genomic Data](https://arxiv.org/abs/2511.07481)
*Reem Al-Saidi,Erman Ayday,Ziad Kobti*

Main category: cs.LG

TL;DR: 该研究探讨了在应用于基因组序列的大型语言模型中嵌入重建攻击的问题，特别关注微调如何影响对这些攻击的脆弱性。研究发现微调可以增强模型对重建攻击的抵抗力，特别是在XLNet、GPT-2和BERT等架构中。


<details>
  <summary>Details</summary>
Motivation: 基于Pan等人的开创性工作，该研究旨在确定任务特定的优化是增强还是削弱隐私保护，特别是在处理敏感的基因组数据时。

Method: 研究扩展了Pan等人的工作，在三个重要维度上进行了改进：将重建攻击管道应用于预训练和微调模型嵌入；为DNA序列实现专门的标记化机制；进行详细的比较分析，检查位置特定、核苷酸类型和隐私变化。

Result: 研究结果显示预训练和微调嵌入在重建脆弱性方面存在明显区别。微调增强了多种架构对重建攻击的抵抗力：XLNet (+19.8%)、GPT-2 (+9.8%) 和 BERT (+7.8%)。

Conclusion: 这些结果强调了为处理敏感基因组数据的语言模型开发高级保护机制的必要性，同时指出微调作为一种潜在的隐私增强技术值得进一步探索。

Abstract: This study investigates embedding reconstruction attacks in large language models (LLMs) applied to genomic sequences, with a specific focus on how fine-tuning affects vulnerability to these attacks. Building upon Pan et al.'s seminal work demonstrating that embeddings from pretrained language models can leak sensitive information, we conduct a comprehensive analysis using the HS3D genomic dataset to determine whether task-specific optimization strengthens or weakens privacy protections. Our research extends Pan et al.'s work in three significant dimensions. First, we apply their reconstruction attack pipeline to pretrained and fine-tuned model embeddings, addressing a critical gap in their methodology that did not specify embedding types. Second, we implement specialized tokenization mechanisms tailored specifically for DNA sequences, enhancing the model's ability to process genomic data, as these models are pretrained on natural language and not DNA. Third, we perform a detailed comparative analysis examining position-specific, nucleotide-type, and privacy changes between pretrained and fine-tuned embeddings. We assess embeddings vulnerabilities across different types and dimensions, providing deeper insights into how task adaptation shifts privacy risks throughout genomic sequences. Our findings show a clear distinction in reconstruction vulnerability between pretrained and fine-tuned embeddings. Notably, fine-tuning strengthens resistance to reconstruction attacks in multiple architectures -- XLNet (+19.8\%), GPT-2 (+9.8\%), and BERT (+7.8\%) -- pointing to task-specific optimization as a potential privacy enhancement mechanism. These results highlight the need for advanced protective mechanisms for language models processing sensitive genomic data, while highlighting fine-tuning as a potential privacy-enhancing technique worth further exploration.

</details>


### [30] [Alignment-Constrained Dynamic Pruning for LLMs: Identifying and Preserving Alignment-Critical Circuits](https://arxiv.org/abs/2511.07482)
*Dev Patel,Gabrielle Gervacio,Diekola Raimi,Kevin Zhu,Ryan Lagasse,Gabriel Grand,Ashwinee Panda,Maheep Chaudhary*

Main category: cs.LG

TL;DR: AAPP是一种动态结构化剪枝方法，通过自适应保留对齐相关电路来提高LLM推理效率，同时保持安全性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型推理需要大量计算资源，动态剪枝虽然比静态方法更高效，但会加剧对齐退化问题，需要解决这些对齐漏洞。

Method: 基于Probe Pruning，提出对齐感知探针剪枝(AAPP)，在推理过程中自适应保留对齐相关电路。

Result: 在LLaMA 2-7B、Qwen2.5-14B-Instruct和Gemma-3-12B-IT上的实验显示，AAPP在相同计算量下将拒绝率提高了50%。

Conclusion: AAPP能够实现高效且保持安全性的LLM部署。

Abstract: Large Language Models require substantial computational resources for inference, posing deployment challenges. While dynamic pruning offers superior efficiency over static methods through adaptive circuit selection, it exacerbates alignment degradation by retaining only input-dependent safety-critical circuit preservation across diverse inputs. As a result, addressing these heightened alignment vulnerabilities remains critical. We introduce Alignment-Aware Probe Pruning (AAPP), a dynamic structured pruning method that adaptively preserves alignment-relevant circuits during inference, building upon Probe Pruning. Experiments on LLaMA 2-7B, Qwen2.5-14B-Instruct, and Gemma-3-12B-IT show AAPP improves refusal rates by 50\% at matched compute, enabling efficient yet safety-preserving LLM deployment.

</details>


### [31] [When Are Learning Biases Equivalent? A Unifying Framework for Fairness, Robustness, and Distribution Shift](https://arxiv.org/abs/2511.07485)
*Sushant Mehta*

Main category: cs.LG

TL;DR: 该论文提出了一个统一的理论框架，证明不同偏差机制（如虚假相关性、子群体偏移、类别不平衡和公平性违规）在模型性能上会产生定量等效的影响。通过信息论方法将偏差形式化为条件独立性的违反，建立了这些偏差机制之间的等价关系，并进行了实证验证。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统存在多种失败模式，如对受保护群体的不公平性、对虚假相关性的脆弱性、在少数子群体上的性能差等，这些问题通常由不同的研究社区孤立研究。作者希望建立一个统一的理论框架来理解这些偏差机制之间的内在联系。

Method: 通过信息论度量将偏差形式化为条件独立性的违反，建立了不同偏差机制之间的正式等价条件。理论预测了虚假相关性强度与子群体不平衡比率之间的定量关系，并在六个数据集和三种架构上进行了实证验证。

Result: 实证验证表明，预测的等价关系在最差群体准确度3%的范围内成立。虚假相关性强度α与子群体不平衡比率r≈(1+α)/(1-α)之间存在定量等价关系，这允许在不同问题领域间有原则地转移去偏差方法。

Conclusion: 这项工作在公平性、鲁棒性和分布偏移的文献之间建立了桥梁，提供了一个共同的视角来理解机器学习中的各种偏差机制。

Abstract: Machine learning systems exhibit diverse failure modes: unfairness toward protected groups, brittleness to spurious correlations, poor performance on minority sub-populations, which are typically studied in isolation by distinct research communities. We propose a unifying theoretical framework that characterizes when different bias mechanisms produce quantitatively equivalent effects on model performance. By formalizing biases as violations of conditional independence through information-theoretic measures, we prove formal equivalence conditions relating spurious correlations, subpopulation shift, class imbalance, and fairness violations. Our theory predicts that a spurious correlation of strength $α$ produces equivalent worst-group accuracy degradation as a sub-population imbalance ratio $r \approx (1+α)/(1-α)$ under feature overlap assumptions. Empirical validation in six datasets and three architectures confirms that predicted equivalences hold within the accuracy of the worst group 3\%, enabling the principled transfer of debiasing methods across problem domains. This work bridges the literature on fairness, robustness, and distribution shifts under a common perspective.

</details>


### [32] [Methodological Precedence in Health Tech: Why ML/Big Data Analysis Must Follow Basic Epidemiological Consistency. A Case Study](https://arxiv.org/abs/2511.07500)
*Marco Roccetti*

Main category: cs.LG

TL;DR: 该研究通过一个疫苗与精神事件关系的队列研究案例，证明即使使用机器学习和大数据等先进分析方法，如果基础研究设计存在严重方法学缺陷，复杂分析反而会放大这些错误，导致误导性结论。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习和海量数据处理在健康研究中的广泛应用，研究者需要警惕这些复杂方法对基础方法学严谨性的依赖。本文旨在强调，在应用先进分析之前，必须首先验证基础方法学的一致性。

Method: 通过对一项已发表的疫苗结果与精神事件队列研究，应用标准描述性统计方法和国家流行病学基准，识别出统计上不可调和的矛盾，揭示研究设计中的选择偏倚问题。

Result: 研究发现该队列研究存在多个统计悖论，包括高风险人群中慢性疾病风险降低的不可信结果、矛盾的发病率比较等，证明报告的风险比是数学伪象，源于队列构建中未校正的选择偏倚。

Conclusion: 复杂健康研究在应用机器学习或统计建模之前，必须首先通过基础流行病学一致性检验。对于非随机化的行政数据，倾向评分匹配等稳健方法是实现有效因果推断的关键。

Abstract: The integration of advanced analytical tools, including Machine Learning (ML) and massive data processing, has revolutionized health research, promising unprecedented accuracy in diagnosis and risk prediction. However, the rigor of these complex methods is fundamentally dependent on the quality and integrity of the underlying datasets and the validity of their statistical design. We propose an emblematic case where advanced analysis (ML/Big Data) must necessarily be subsequent to the verification of basic methodological coherence. This study highlights a crucial cautionary principle: sophisticated analyses amplify, rather than correct, severe methodological flaws rooted in basic design choices, leading to misleading or contradictory findings. By applying simple, standard descriptive statistical methods and established national epidemiological benchmarks to a recently published cohort study on vaccine outcomes and psychiatric events, we expose multiple, statistically irreconcilable paradoxes. These paradoxes, including an implausible risk reduction for a chronic disorder in a high-risk group and contradictory incidence rate comparisons, definitively invalidate the reported hazard ratios (HRs). We demonstrate that the observed effects are mathematical artifacts stemming from an uncorrected selection bias in the cohort construction. This analysis serves as a robust reminder that even the most complex health studies must first pass the test of basic epidemiological consistency before any conclusion drawn from subsequent advanced ML or statistical modeling can be considered valid or publishable. We conclude that robust methods, such as Propensity Score Matching, are essential for achieving valid causal inference from administrative data in the absence of randomization

</details>


### [33] [Partial Action Replacement: Tackling Distribution Shift in Offline MARL](https://arxiv.org/abs/2511.07629)
*Yue Jin,Giovanni Montana*

Main category: cs.LG

TL;DR: 本文提出了一种名为SPaCQL的离线多智能体强化学习方法，通过部分动作替换策略缓解分布外联合动作评估问题，在因子化行为策略下显著降低分布偏移。


<details>
  <summary>Details</summary>
Motivation: 离线多智能体强化学习面临分布外联合动作评估的严重挑战，特别是在行为策略因子化的常见场景下。

Method: 开发了Soft-Partial Conservative Q-Learning方法，使用部分动作替换策略缓解OOD问题，并根据价值估计的不确定性动态加权不同的PAR策略。

Result: 理论证明在因子化行为策略下，分布偏移与偏离智能体数量呈线性关系而非指数关系，实验结果显示SPaCQL在具有独立性结构的离线数据集上显著优于基线算法。

Conclusion: SPaCQL方法通过部分动作替换和不确定性加权，有效解决了离线MARL中的分布偏移问题，在因子化行为策略场景下表现优异。

Abstract: Offline multi-agent reinforcement learning (MARL) is severely hampered by the challenge of evaluating out-of-distribution (OOD) joint actions. Our core finding is that when the behavior policy is factorized - a common scenario where agents act fully or partially independently during data collection - a strategy of partial action replacement (PAR) can significantly mitigate this challenge. PAR updates a single or part of agents' actions while the others remain fixed to the behavioral data, reducing distribution shift compared to full joint-action updates. Based on this insight, we develop Soft-Partial Conservative Q-Learning (SPaCQL), using PAR to mitigate OOD issue and dynamically weighting different PAR strategies based on the uncertainty of value estimation. We provide a rigorous theoretical foundation for this approach, proving that under factorized behavior policies, the induced distribution shift scales linearly with the number of deviating agents rather than exponentially with the joint-action space. This yields a provably tighter value error bound for this important class of offline MARL problems. Our theoretical results also indicate that SPaCQL adaptively addresses distribution shift using uncertainty-informed weights. Our empirical results demonstrate SPaCQL enables more effective policy learning, and manifest its remarkable superiority over baseline algorithms when the offline dataset exhibits the independence structure.

</details>


### [34] [Adaptive Graph Learning with Transformer for Multi-Reservoir Inflow Prediction](https://arxiv.org/abs/2511.07649)
*Pengfei Hu,Ming Fan,Xiaoxue Han,Chang Lu,Wei Zhang,Hyun Kang,Yue Ning,Dan Lu*

Main category: cs.LG

TL;DR: AdaTrip是一个自适应时变图学习框架，用于多水库入流预测，通过动态图结构和注意力机制捕捉水库间的时空依赖关系，在科罗拉多河上游流域30个水库上表现优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有水库入流预测方法主要关注单一水库模型，忽略了相互连接水库之间的空间依赖性，需要开发能够捕捉水库间时空依赖关系的多水库预测框架。

Method: AdaTrip构建动态图结构，将水库作为节点，有向边反映水文连接，使用注意力机制自动识别关键的时空依赖关系，并通过参数共享提升数据有限水库的预测性能。

Result: 在科罗拉多河上游流域30个水库上的评估显示，AdaTrip优于现有基线方法，对记录有限的水库通过参数共享实现了性能提升，并提供可解释的注意力图谱。

Conclusion: AdaTrip为多水库入流预测提供了有效的自适应图学习框架，不仅能准确预测，还能提供对水文控制因素的可解释洞察，支持运营决策。

Abstract: Reservoir inflow prediction is crucial for water resource management, yet existing approaches mainly focus on single-reservoir models that ignore spatial dependencies among interconnected reservoirs. We introduce AdaTrip as an adaptive, time-varying graph learning framework for multi-reservoir inflow forecasting. AdaTrip constructs dynamic graphs where reservoirs are nodes with directed edges reflecting hydrological connections, employing attention mechanisms to automatically identify crucial spatial and temporal dependencies. Evaluation on thirty reservoirs in the Upper Colorado River Basin demonstrates superiority over existing baselines, with improved performance for reservoirs with limited records through parameter sharing. Additionally, AdaTrip provides interpretable attention maps at edge and time-step levels, offering insights into hydrological controls to support operational decision-making. Our code is available at https://github.com/humphreyhuu/AdaTrip.

</details>


### [35] [CAE: Character-Level Autoencoder for Non-Semantic Relational Data Grouping](https://arxiv.org/abs/2511.07657)
*Veera V S Bhargav Nunna,Shinae Kang,Zheyuan Zhou,Virginia Wang,Sucharitha Boinapally,Michael Foley*

Main category: cs.LG

TL;DR: 本文提出了一种字符级自编码器(CAE)方法，用于自动识别和分组非语义关系数据集中的语义相同列，通过检测数据模式和结构的列相似性，显著优于传统NLP方法。


<details>
  <summary>Details</summary>
Motivation: 企业关系数据库包含大量非语义数据（IP地址、产品标识符、编码键和时间戳），这些数据挑战了传统的语义分析，需要新的方法来处理非语义关系数据集的列相似性检测。

Method: 采用字符级自编码器(CAE)架构，在字符级别操作并保持固定字典约束，编码非语义关系表列的文本表示，提取高维特征嵌入进行数据分组，显著降低内存需求和训练时间。

Result: 实验评估显示，CAE方法在关系数据集的前5列匹配任务中达到80.95%的准确率，显著优于传统NLP方法如词袋模型(47.62%)。

Conclusion: 该工作弥合了字符级神经架构的理论进展与企业数据管理实践挑战之间的差距，为非语义工业数据集的大规模模式理解和数据剖析提供了自动化解决方案。

Abstract: Enterprise relational databases increasingly contain vast amounts of non-semantic data - IP addresses, product identifiers, encoded keys, and timestamps - that challenge traditional semantic analysis. This paper introduces a novel Character-Level Autoencoder (CAE) approach that automatically identifies and groups semantically identical columns in non-semantic relational datasets by detecting column similarities based on data patterns and structures. Unlike conventional Natural Language Processing (NLP) models that struggle with limitations in semantic interpretability and out-of-vocabulary tokens, our approach operates at the character level with fixed dictionary constraints, enabling scalable processing of large-scale data lakes and warehouses. The CAE architecture encodes text representations of non-semantic relational table columns and extracts high-dimensional feature embeddings for data grouping. By maintaining a fixed dictionary size, our method significantly reduces both memory requirements and training time, enabling efficient processing of large-scale industrial data environments. Experimental evaluation demonstrates substantial performance gains: our CAE approach achieved 80.95% accuracy in top 5 column matching tasks across relational datasets, substantially outperforming traditional NLP approaches such as Bag of Words (47.62%). These results demonstrate its effectiveness for identifying and clustering identical columns in relational datasets. This work bridges the gap between theoretical advances in character-level neural architectures and practical enterprise data management challenges, providing an automated solution for schema understanding and data profiling of non-semantic industrial datasets at scale.

</details>


### [36] [On the Role of Calibration in Benchmarking Algorithmic Fairness for Skin Cancer Detection](https://arxiv.org/abs/2511.07700)
*Brandon Dominique,Prudence Lam,Nicholas Kurtansky,Jochen Weber,Kivanc Kose,Veronica Rotemberg,Jennifer Dy*

Main category: cs.LG

TL;DR: 该论文指出AI模型在黑色素瘤检测中存在跨人口亚组（性别、种族、年龄）的性能差异，提出将校准作为AUROC公平性指标的补充基准指标，评估了ISIC 2020挑战赛领先模型在新数据集上的表现，发现模型存在过度诊断风险和校准问题。


<details>
  <summary>Details</summary>
Motivation: AI模型在黑色素瘤检测中表现出专家级性能，但临床采用受到跨人口亚组性能差异的阻碍。现有基准主要依赖AUROC群体公平性指标，无法提供模型准确估计能力的信息。

Method: 将校准作为AUROC公平性指标的补充基准指标，评估ISIC 2020挑战赛领先模型在ISIC 2020挑战赛数据集和PROVE-AI数据集上的表现，重点关注性别、种族（Fitzpatrick皮肤类型）和年龄定义的亚组。

Result: 研究发现现有模型提高了判别准确性，但在应用于新数据集时经常过度诊断风险并表现出校准问题。

Conclusion: 研究强调了实现公平AI驱动医疗解决方案需要全面的模型审计策略和广泛的元数据收集。

Abstract: Artificial Intelligence (AI) models have demonstrated expert-level performance in melanoma detection, yet their clinical adoption is hindered by performance disparities across demographic subgroups such as gender, race, and age. Previous efforts to benchmark the performance of AI models have primarily focused on assessing model performance using group fairness metrics that rely on the Area Under the Receiver Operating Characteristic curve (AUROC), which does not provide insights into a model's ability to provide accurate estimates. In line with clinical assessments, this paper addresses this gap by incorporating calibration as a complementary benchmarking metric to AUROC-based fairness metrics. Calibration evaluates the alignment between predicted probabilities and observed event rates, offering deeper insights into subgroup biases. We assess the performance of the leading skin cancer detection algorithm of the ISIC 2020 Challenge on the ISIC 2020 Challenge dataset and the PROVE-AI dataset, and compare it with the second and third place models, focusing on subgroups defined by sex, race (Fitzpatrick Skin Tone), and age. Our findings reveal that while existing models enhance discriminative accuracy, they often over-diagnose risk and exhibit calibration issues when applied to new datasets. This study underscores the necessity for comprehensive model auditing strategies and extensive metadata collection to achieve equitable AI-driven healthcare solutions. All code is publicly available at https://github.com/bdominique/testing_strong_calibration.

</details>


### [37] [A Ranking-Based Optimization Algorithm for the Vehicle Relocation Problem in Car Sharing Services](https://arxiv.org/abs/2511.07724)
*Piotr Szwed,Paweł Skrzynski,Jarosław Wąs*

Main category: cs.LG

TL;DR: 本文提出了一种针对自由浮动汽车共享服务中车辆重新定位问题的解决方案，通过使用滑板车重新定位车辆和转移人员。该方法将服务区域划分为具有相似车辆存在和服务需求时间模式的区域，并采用基于排名的快速算法进行决策。


<details>
  <summary>Details</summary>
Motivation: 解决自由浮动汽车共享服务中的车辆重新定位问题，提高服务效率，减少总旅行时间。

Method: 1. 将服务区域划分为具有相似时间模式的区域；2. 提出基于排名的快速算法，考虑每个区域的可用车辆数量、需求概率密度和预计行程持续时间；3. 使用真实世界数据进行实验验证。

Result: 与无优化基线相比，提出的算法平均改进8.44%，MIP求解器改进19.6%。根据工作人员规模，性能指标可提高约3%-10%。

Conclusion: 提出的解决方案能有效改善车辆重新定位性能，但MIP模型包含当前业务规则排除的行程选择决策，实际应用中需考虑这一差异。

Abstract: The paper addresses the Vehicle Relocation Problem in free-floating car-sharing services by presenting a solution focused on strategies for repositioning vehicles and transferring personnel with the use of scooters. Our method begins by dividing the service area into zones that group regions with similar temporal patterns of vehicle presence and service demand, allowing the application of discrete optimization methods. In the next stage, we propose a fast ranking-based algorithm that makes its decisions on the basis of the number of cars available in each zone, the projected probability density of demand, and estimated trip durations. The experiments were carried out on the basis of real-world data originating from a major car-sharing service operator in Poland. The results of this algorithm are evaluated against scenarios without optimization that constitute a baseline and compared with the results of an exact algorithm to solve the Mixed Integer Programming (MIP) model. As performance metrics, the total travel time was used. Under identical conditions (number of vehicles, staff, and demand distribution), the average improvements with respect to the baseline of our algorithm and MIP solver were equal to 8.44\% and 19.6\% correspondingly. However, it should be noted that the MIP model also mimicked decisions on trip selection, which are excluded by current services business rules. The analysis of results suggests that, depending on the size of the workforce, the application of the proposed solution allows for improving performance metrics by roughly 3%-10%.

</details>


### [38] [Multistep Quasimetric Learning for Scalable Goal-conditioned Reinforcement Learning](https://arxiv.org/abs/2511.07730)
*Bill Chunyuan Zheng,Vivek Myers,Benjamin Eysenbach,Sergey Levine*

Main category: cs.LG

TL;DR: 该论文提出了一种结合局部更新和全局更新的目标条件强化学习方法，通过多步蒙特卡洛回报拟合准度量距离，在长时程任务中表现出色，并在真实机器人操作领域实现多步拼接。


<details>
  <summary>Details</summary>
Motivation: 解决AI中长时程目标达成的问题，特别是如何准确估计观测对之间的时间距离，整合具有最优性保证的局部更新方法和性能更好的全局更新方法。

Method: 提出一种实用的GCRL方法，使用多步蒙特卡洛回报拟合准度量距离，将时间差分方法和蒙特卡洛方法的优势结合起来。

Result: 在长达4000步的长时程模拟任务中表现优于现有GCRL方法，即使使用视觉观测；在真实世界机器人操作领域（Bridge设置）实现了多步拼接，是首个在该领域从无标签离线视觉观测数据集实现端到端多步拼接的GCRL方法。

Conclusion: 该方法成功整合了局部和全局更新的优势，在长时程任务和真实世界机器人操作中表现出卓越性能，为GCRL领域提供了新的解决方案。

Abstract: Learning how to reach goals in an environment is a longstanding challenge in AI, yet reasoning over long horizons remains a challenge for modern methods. The key question is how to estimate the temporal distance between pairs of observations. While temporal difference methods leverage local updates to provide optimality guarantees, they often perform worse than Monte Carlo methods that perform global updates (e.g., with multi-step returns), which lack such guarantees. We show how these approaches can be integrated into a practical GCRL method that fits a quasimetric distance using a multistep Monte-Carlo return. We show our method outperforms existing GCRL methods on long-horizon simulated tasks with up to 4000 steps, even with visual observations. We also demonstrate that our method can enable stitching in the real-world robotic manipulation domain (Bridge setup). Our approach is the first end-to-end GCRL method that enables multistep stitching in this real-world manipulation domain from an unlabeled offline dataset of visual observations.

</details>


### [39] [Schedulers for Schedule-free: Theoretically inspired hyperparameters](https://arxiv.org/abs/2511.07767)
*Yuen-Man Pun,Matthew Buchholz,Robert M. Gower*

Main category: cs.LG

TL;DR: 本文扩展了schedule-free方法的收敛理论，支持任意学习率调度器，并提出了新的自适应Polyak学习率调度，在理论和实验中都表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的schedule-free理论只支持恒定学习率，但实际实现使用了warm-up调度。需要扩展理论以支持任意调度器，并改进实际性能。

Method: 扩展schedule-free的收敛理论以允许任意学习率调度，更新平均参数作为学习率的函数，并基于凸性设计新的自适应Polyak学习率调度。

Result: 理论证明了在wsd调度下达到O(1/√T)的最优收敛率，新Polyak调度在模型蒸馏任务中表现优于多个基线方法。

Conclusion: 扩展的schedule-free理论具有实际预测能力，新提出的自适应Polyak调度在理论和实验中均表现出最优性能。

Abstract: The recently proposed schedule-free method has been shown to achieve strong performance when hyperparameter tuning is limited. The current theory for schedule-free only supports a constant learning rate, where-as the implementation used in practice uses a warm-up schedule. We show how to extend the last-iterate convergence theory of schedule-free to allow for any scheduler, and how the averaging parameter has to be updated as a function of the learning rate. We then perform experiments showing how our convergence theory has some predictive power with regards to practical executions on deep neural networks, despite that this theory relies on assuming convexity. When applied to the warmup-stable-decay (wsd) schedule, our theory shows the optimal convergence rate of $\mathcal{O}(1/\sqrt{T})$. We then use convexity to design a new adaptive Polyak learning rate schedule for schedule-free. We prove an optimal anytime last-iterate convergence for our new Polyak schedule, and show that it performs well compared to a number of baselines on a black-box model distillation task.

</details>


### [40] [Analyzing Political Text at Scale with Online Tensor LDA](https://arxiv.org/abs/2511.07809)
*Sara Kangaslahti,Danny Ebanks,Jean Kossaifi,Anqi Liu,R. Michael Alvarez,Animashree Anandkumar*

Main category: cs.LG

TL;DR: 本文提出了一种可扩展到数十亿文档的主题建模方法TLDA，具有线性扩展性、计算效率高（比现有并行LDA方法快3-4倍），并提供了开源GPU实现。


<details>
  <summary>Details</summary>
Motivation: 现有主题建模方法难以处理超大规模文本数据，限制了社会科学研究对海量语料的分析能力。

Method: 提出Tensor Latent Dirichlet Allocation (TLDA)方法，具有可识别和可恢复参数保证，以及大数据的样本复杂度保证。

Result: 该方法在包含超过10亿文档的文本数据集上实现线性扩展，并成功应用于#MeToo运动演化和2020年总统选举欺诈社交媒体对话的大规模分析。

Conclusion: TLDA方法为社会科学研究者提供了研究超大规模语料库的能力，能够近乎实时地分析重要理论相关问题。

Abstract: This paper proposes a topic modeling method that scales linearly to billions of documents. We make three core contributions: i) we present a topic modeling method, Tensor Latent Dirichlet Allocation (TLDA), that has identifiable and recoverable parameter guarantees and sample complexity guarantees for large data; ii) we show that this method is computationally and memory efficient (achieving speeds over 3-4x those of prior parallelized Latent Dirichlet Allocation (LDA) methods), and that it scales linearly to text datasets with over a billion documents; iii) we provide an open-source, GPU-based implementation, of this method. This scaling enables previously prohibitive analyses, and we perform two real-world, large-scale new studies of interest to political scientists: we provide the first thorough analysis of the evolution of the #MeToo movement through the lens of over two years of Twitter conversation and a detailed study of social media conversations about election fraud in the 2020 presidential election. Thus this method provides social scientists with the ability to study very large corpora at scale and to answer important theoretically-relevant questions about salient issues in near real-time.

</details>


### [41] [Multi-Objective Bilevel Learning](https://arxiv.org/abs/2511.07824)
*Zhiyao Zhang,Zhuqing Liu,Xin Zhang,Wen-Yen Chen,Jiyan Yang,Jia Liu*

Main category: cs.LG

TL;DR: 本文提出了一个统一的多目标双层学习（MOBL）算法框架WC-MHGD，用于解决机器学习中多个冲突目标的优化问题，具有低oracle复杂度和系统化Pareto前沿探索能力。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习应用日益复杂，现代ML框架需要处理多个可能冲突的目标和不同层间的耦合决策变量，这产生了对多目标双层学习的迫切需求。但目前MOBL领域仍处于起步阶段，许多重要问题尚未充分探索。

Method: 提出了加权Chebyshev多超梯度下降（WC-MHGD）算法框架，适用于确定性和随机设置，通过偏好引导识别Pareto稳态解，并实现系统化的Pareto前沿探索。

Result: 理论分析表明WC-MHGD具有有限时间Pareto稳态收敛率保证，不仅意味着低oracle复杂度，还能诱导系统化的Pareto前沿探索。实验验证了理论结果。

Conclusion: WC-MHGD为多目标双层学习提供了一个有效的理论算法框架，填补了该领域的研究空白，为复杂ML应用中的多目标优化问题提供了系统解决方案。

Abstract: As machine learning (ML) applications grow increasingly complex in recent years, modern ML frameworks often need to address multiple potentially conflicting objectives with coupled decision variables across different layers. This creates a compelling need for multi-objective bilevel learning (MOBL). So far, however, the field of MOBL remains in its infancy and many important problems remain under-explored. This motivates us to fill this gap and systematically investigate the theoretical and algorithmic foundation of MOBL. Specifically, we consider MOBL problems with multiple conflicting objectives guided by preferences at the upper-level subproblem, where part of the inputs depend on the optimal solution of the lower-level subproblem. Our goal is to develop efficient MOBL optimization algorithms to (1) identify a preference-guided Pareto-stationary solution with low oracle complexity; and (2) enable systematic Pareto front exploration. To this end, we propose a unifying algorithmic framework called weighted-Chebyshev multi-hyper-gradient-descent (WC-MHGD) for both deterministic and stochastic settings with finite-time Pareto-stationarity convergence rate guarantees, which not only implies low oracle complexity but also induces systematic Pareto front exploration. We further conduct extensive experiments to confirm our theoretical results.

</details>


### [42] [DP-AdamW: Investigating Decoupled Weight Decay and Bias Correction in Private Deep Learning](https://arxiv.org/abs/2511.07843)
*Jay Chooi,Kevin Cong,Russell Li,Lillian Sun*

Main category: cs.LG

TL;DR: 本文研究了差分隐私AdamW优化器（DP-AdamW）及其带偏置校正的版本（DP-AdamW-BC），在多个隐私预算下进行实证分析，发现DP-AdamW在文本分类、图像分类和图节点分类任务上均优于现有DP优化器。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习广泛使用敏感数据，差分隐私提供正式保护以防止训练过程中的信息泄露。现有挑战在于实现既保持强性能又保护隐私的DP优化器，而AdamW因其强大经验性能成为流行选择。

Method: 提出了DP-AdamW及其带偏置校正的版本DP-AdamW-BC，提供了隐私和收敛保证的理论结果，并在多个隐私预算（ε=1,3,7）下对两种优化器进行实证分析。

Result: DP-AdamW在文本分类上比现有DP优化器高出15%以上，图像分类高出5%，图节点分类一致高出1%。但DP-AdamW-BC的偏置校正反而降低了准确率，与DP-AdamBC改善DP-Adam的情况相反。

Conclusion: DP-AdamW在保护隐私的同时显著优于现有DP优化器，但偏置校正在该设置下未能带来性能提升，反而降低了准确性。

Abstract: As deep learning methods increasingly utilize sensitive data on a widespread scale, differential privacy (DP) offers formal guarantees to protect against information leakage during model training. A significant challenge remains in implementing DP optimizers that retain strong performance while preserving privacy. Recent advances introduced ever more efficient optimizers, with AdamW being a popular choice for training deep learning models because of strong empirical performance. We study \emph{DP-AdamW} and introduce \emph{DP-AdamW-BC}, a differentially private variant of the AdamW optimizer with DP bias correction for the second moment estimator. We start by showing theoretical results for privacy and convergence guarantees of DP-AdamW and DP-AdamW-BC. Then, we empirically analyze the behavior of both optimizers across multiple privacy budgets ($ε= 1, 3, 7$). We find that DP-AdamW outperforms existing state-of-the-art differentially private optimizers like DP-SGD, DP-Adam, and DP-AdamBC, scoring over 15\% higher on text classification, up to 5\% higher on image classification, and consistently 1\% higher on graph node classification. Moreover, we empirically show that incorporating bias correction in DP-AdamW (DP-AdamW-BC) consistently decreases accuracy, in contrast to the improvement of DP-AdamBC improvement over DP-Adam.

</details>


### [43] [Test-driven Reinforcement Learning](https://arxiv.org/abs/2511.07904)
*Zhao Yu,Xiuping Wu,Liangjun Ke*

Main category: cs.LG

TL;DR: 提出测试驱动的强化学习框架，用多个测试函数替代单一奖励函数来定义任务目标，解决强化学习中奖励函数设计困难的问题。


<details>
  <summary>Details</summary>
Motivation: 强化学习中的奖励函数既要定义最优目标又要指导学习过程，手动设计困难且容易导致次优任务表示。受满意理论启发，希望找到更简单的任务定义方法。

Method: 使用通过-失败测试和指示性测试两类测试函数分别定义最优目标和指导学习过程；提出基于轨迹返回函数的策略优化方法，并引入词典序启发式方法学习轨迹返回函数。

Result: 在DeepMind Control Suite基准测试中，TdRL方法在策略训练上达到或优于手工设计奖励的方法，且具有更大的设计简单性和对多目标优化的内在支持。

Conclusion: TdRL为表示任务目标提供了新的视角，有助于解决强化学习应用中的奖励设计挑战。

Abstract: Reinforcement learning (RL) has been recognized as a powerful tool for robot control tasks. RL typically employs reward functions to define task objectives and guide agent learning. However, since the reward function serves the dual purpose of defining the optimal goal and guiding learning, it is challenging to design the reward function manually, which often results in a suboptimal task representation. To tackle the reward design challenge in RL, inspired by the satisficing theory, we propose a Test-driven Reinforcement Learning (TdRL) framework. In the TdRL framework, multiple test functions are used to represent the task objective rather than a single reward function. Test functions can be categorized as pass-fail tests and indicative tests, each dedicated to defining the optimal objective and guiding the learning process, respectively, thereby making defining tasks easier. Building upon such a task definition, we first prove that if a trajectory return function assigns higher returns to trajectories closer to the optimal trajectory set, maximum entropy policy optimization based on this return function will yield a policy that is closer to the optimal policy set. Then, we introduce a lexicographic heuristic approach to compare the relative distance relationship between trajectories and the optimal trajectory set for learning the trajectory return function. Furthermore, we develop an algorithm implementation of TdRL. Experimental results on the DeepMind Control Suite benchmark demonstrate that TdRL matches or outperforms handcrafted reward methods in policy training, with greater design simplicity and inherent support for multi-objective optimization. We argue that TdRL offers a novel perspective for representing task objectives, which could be helpful in addressing the reward design challenges in RL applications.

</details>


### [44] [Low-Rank Curvature for Zeroth-Order Optimization in LLM Fine-Tuning](https://arxiv.org/abs/2511.07971)
*Hyunseok Seung,Jaewoo Lee,Hyunsuk Ko*

Main category: cs.LG

TL;DR: LOREN是一种曲率感知的零阶优化方法，用于微调大语言模型，通过自适应估计各向异性扰动分布、低秩块对角预处理器和REINFORCE留一法梯度估计器，实现了更高的准确性和更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 现有的零阶方法使用随机扰动通过有限差分估计梯度，存在高方差和次优搜索方向的问题，需要改进梯度估计的效率和准确性。

Method: LOREN通过以下方式解决挑战：(i)将梯度预条件问题重新表述为自适应估计各向异性扰动分布；(ii)使用自然进化策略框架通过低秩块对角预处理器捕获曲率；(iii)应用REINFORCE留一法梯度估计器减少方差。

Result: 在标准LLM基准测试中，LOREN优于最先进的零阶方法，实现了更高的准确性和更快的收敛速度，同时与MeZO-Adam相比，峰值内存使用量减少了高达27.3%。

Conclusion: LOREN通过曲率感知的零阶优化方法，在微调大语言模型时显著提高了性能，同时降低了内存使用，为资源受限环境下的模型优化提供了有效解决方案。

Abstract: We introduce LOREN, a curvature-aware zeroth-order (ZO) optimization method for fine-tuning large language models (LLMs). Existing ZO methods, which estimate gradients via finite differences using random perturbations, often suffer from high variance and suboptimal search directions. Our approach addresses these challenges by: (i) reformulating the problem of gradient preconditioning as that of adaptively estimating an anisotropic perturbation distribution for gradient estimation, (ii) capturing curvature through a low-rank block diagonal preconditioner using the framework of natural evolution strategies, and (iii) applying a REINFORCE leave-one-out (RLOO) gradient estimator to reduce variance. Experiments on standard LLM benchmarks show that our method outperforms state-of-the-art ZO methods by achieving higher accuracy and faster convergence, while cutting peak memory usage by up to 27.3% compared with MeZO-Adam.

</details>


### [45] [From Sequential to Recursive: Enhancing Decision-Focused Learning with Bidirectional Feedback](https://arxiv.org/abs/2511.08035)
*Xinyu Wang,Jinxiao Du,Yiyang Peng,Wei Ma*

Main category: cs.LG

TL;DR: 本文提出了递归决策聚焦学习（R-DFL）框架，通过在下游优化和上游预测之间引入双向反馈，克服了传统顺序决策聚焦学习（S-DFL）的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有DFL框架受限于严格的顺序结构（S-DFL），无法捕捉复杂交互场景中预测与优化之间的双向反馈。

Method: 提出了R-DFL框架，并扩展了两种微分方法：基于自动微分的显式展开和基于定点方法的隐式微分，以促进R-DFL中的高效梯度传播。

Result: 在报童问题和二分匹配问题等合成和真实数据集上的实验表明，R-DFL显著提高了最终决策质量，并在闭环决策问题中展现出强大的跨场景适应性。

Conclusion: R-DFL不仅超越了顺序基线方法，还证明了在复杂决策场景中双向反馈机制的有效性。

Abstract: Decision-focused learning (DFL) has emerged as a powerful end-to-end alternative to conventional predict-then-optimize (PTO) pipelines by directly optimizing predictive models through downstream decision losses. Existing DFL frameworks are limited by their strictly sequential structure, referred to as sequential DFL (S-DFL). However, S-DFL fails to capture the bidirectional feedback between prediction and optimization in complex interaction scenarios. In view of this, we first time propose recursive decision-focused learning (R-DFL), a novel framework that introduces bidirectional feedback between downstream optimization and upstream prediction. We further extend two distinct differentiation methods: explicit unrolling via automatic differentiation and implicit differentiation based on fixed-point methods, to facilitate efficient gradient propagation in R-DFL. We rigorously prove that both methods achieve comparable gradient accuracy, with the implicit method offering superior computational efficiency. Extensive experiments on both synthetic and real-world datasets, including the newsvendor problem and the bipartite matching problem, demonstrate that R-DFL not only substantially enhances the final decision quality over sequential baselines but also exhibits robust adaptability across diverse scenarios in closed-loop decision-making problems.

</details>


### [46] [An Integrated Fusion Framework for Ensemble Learning Leveraging Gradient Boosting and Fuzzy Rule-Based Models](https://arxiv.org/abs/2511.08077)
*Jinbo Li,Peng Liu,Long Chen,Witold Pedrycz,Weiping Ding*

Main category: cs.LG

TL;DR: 本文提出了一种集成融合框架，将模糊规则模型与梯度提升相结合，通过动态控制因子和样本校正机制来提升性能、防止过拟合并保持可解释性。


<details>
  <summary>Details</summary>
Motivation: 模糊规则模型具有良好的可解释性但面临设计复杂和大数据集扩展性问题。融合梯度提升技术可以克服这些限制，结合两种范式的优势。

Method: 提出集成融合框架，在每次迭代中构建模糊规则模型，通过动态控制因子优化其在整体集成中的贡献，并包含基于样本的校正机制进行自适应调整。

Result: 实验结果表明该框架有效提升了性能，特别是在减轻过拟合和规则复杂性方面，同时保持了模型的可解释性。

Conclusion: 通过优化控制因子来管理每个模型的贡献，该框架实现了性能提升、可解释性保持以及模型维护和更新的简化。

Abstract: The integration of different learning paradigms has long been a focus of machine learning research, aimed at overcoming the inherent limitations of individual methods. Fuzzy rule-based models excel in interpretability and have seen widespread application across diverse fields. However, they face challenges such as complex design specifications and scalability issues with large datasets. The fusion of different techniques and strategies, particularly Gradient Boosting, with Fuzzy Rule-Based Models offers a robust solution to these challenges. This paper proposes an Integrated Fusion Framework that merges the strengths of both paradigms to enhance model performance and interpretability. At each iteration, a Fuzzy Rule-Based Model is constructed and controlled by a dynamic factor to optimize its contribution to the overall ensemble. This control factor serves multiple purposes: it prevents model dominance, encourages diversity, acts as a regularization parameter, and provides a mechanism for dynamic tuning based on model performance, thus mitigating the risk of overfitting. Additionally, the framework incorporates a sample-based correction mechanism that allows for adaptive adjustments based on feedback from a validation set. Experimental results substantiate the efficacy of the presented gradient boosting framework for fuzzy rule-based models, demonstrating performance enhancement, especially in terms of mitigating overfitting and complexity typically associated with many rules. By leveraging an optimal factor to govern the contribution of each model, the framework improves performance, maintains interpretability, and simplifies the maintenance and update of the models.

</details>


### [47] [Dynamic Sparsity: Challenging Common Sparsity Assumptions for Learning World Models in Robotic Reinforcement Learning Benchmarks](https://arxiv.org/abs/2511.08086)
*Muthukumar Pandaram,Jakob Hollenstein,David Drexel,Samuele Tosatto,Antonio Rodríguez-Sánchez,Justus Piater*

Main category: cs.LG

TL;DR: 本文批判性地检验了强化学习中动态模型的稀疏性假设，通过分析MuJoCo Playground基准套件中的真实动态，发现全局稀疏性很少见，但存在局部、状态依赖的稀疏性，且这种稀疏性呈现特定的时间聚类模式。


<details>
  <summary>Details</summary>
Motivation: 检验强化学习中动态模型的两个常见假设：因果图稀疏性和时间稀疏性是否在实际任务中成立，为学习动态模型提供更准确的归纳偏置。

Method: 分析MuJoCo Playground基准套件中机器人强化学习环境的真实动态，研究三个问题：(i)环境动态的因果图是否稀疏，(ii)这种稀疏性是否状态依赖，(iii)局部系统动态是否稀疏变化。

Result: 全局稀疏性很少见，但任务在其动态中表现出局部、状态依赖的稀疏性，这种稀疏性呈现特定的结构，出现在时间局部化的聚类中（如接触事件期间）并影响特定的状态维度子集。

Conclusion: 研究结果挑战了动态学习中常见的稀疏性先验假设，强调需要反映真实世界动态状态依赖稀疏性结构的接地归纳偏置。

Abstract: The use of learned dynamics models, also known as world models, can improve the sample efficiency of reinforcement learning. Recent work suggests that the underlying causal graphs of such dynamics models are sparsely connected, with each of the future state variables depending only on a small subset of the current state variables, and that learning may therefore benefit from sparsity priors. Similarly, temporal sparsity, i.e. sparsely and abruptly changing local dynamics, has also been proposed as a useful inductive bias.
  In this work, we critically examine these assumptions by analyzing ground-truth dynamics from a set of robotic reinforcement learning environments in the MuJoCo Playground benchmark suite, aiming to determine whether the proposed notions of state and temporal sparsity actually tend to hold in typical reinforcement learning tasks.
  We study (i) whether the causal graphs of environment dynamics are sparse, (ii) whether such sparsity is state-dependent, and (iii) whether local system dynamics change sparsely.
  Our results indicate that global sparsity is rare, but instead the tasks show local, state-dependent sparsity in their dynamics and this sparsity exhibits distinct structures, appearing in temporally localized clusters (e.g., during contact events) and affecting specific subsets of state dimensions. These findings challenge common sparsity prior assumptions in dynamics learning, emphasizing the need for grounded inductive biases that reflect the state-dependent sparsity structure of real-world dynamics.

</details>


### [48] [A robust methodology for long-term sustainability evaluation of Machine Learning models](https://arxiv.org/abs/2511.08120)
*Jorge Paz-Ruza,João Gama,Amparo Alonso-Betanzos,Bertha Guijarro-Berdiñas*

Main category: cs.LG

TL;DR: 提出一个评估机器学习模型长期可持续性的综合协议，适用于批处理和流式学习场景，发现传统静态评估无法可靠反映真实世界长期AI生命周期中的可持续性。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统监管和报告实践缺乏标准化、模型无关的评估协议，当前评估仅测量短期实验资源使用，过度强调批学习设置，无法反映真实世界长期AI生命周期。

Method: 提出综合评估协议，适用于批处理和流式学习场景，通过多样化分类任务和多种模型类型的实验来验证。

Result: 实验表明传统静态训练-测试评估无法可靠捕捉数据演变和重复模型更新下的可持续性，长期可持续性在不同模型间差异显著，且在许多情况下更高的环境成本带来的性能收益很小。

Conclusion: 需要新的评估标准来准确衡量AI系统的长期可持续性，当前评估方法不足以反映真实部署环境中的资源消耗和效率。

Abstract: Sustainability and efficiency have become essential considerations in the development and deployment of Artificial Intelligence systems, yet existing regulatory and reporting practices lack standardized, model-agnostic evaluation protocols. Current assessments often measure only short-term experimental resource usage and disproportionately emphasize batch learning settings, failing to reflect real-world, long-term AI lifecycles. In this work, we propose a comprehensive evaluation protocol for assessing the long-term sustainability of ML models, applicable to both batch and streaming learning scenarios. Through experiments on diverse classification tasks using a range of model types, we demonstrate that traditional static train-test evaluations do not reliably capture sustainability under evolving data and repeated model updates. Our results show that long-term sustainability varies significantly across models, and in many cases, higher environmental cost yields little performance benefit.

</details>


### [49] [A Unified Geometric Field Theory Framework for Transformers: From Manifold Embeddings to Kernel Modulation](https://arxiv.org/abs/2511.08243)
*Xianshuai Shi,Jianfeng Zhu,Leibo Liu*

Main category: cs.LG

TL;DR: 本文提出了一个统一的理论框架，将Transformer中的位置编码、核积分算子和注意力机制整合起来进行理论研究。


<details>
  <summary>Details</summary>
Motivation: Transformer架构在自然语言处理、计算机视觉和科学计算中取得了巨大成功，但其核心组件（位置编码和注意力机制）缺乏统一的物理或数学解释。

Method: 将离散位置映射到连续流形上的空间函数，将Transformer层解释为在嵌入流形上作用的核调制算子。

Result: 建立了一个场论解释框架，为Transformer架构提供了统一的数学基础。

Conclusion: 该框架为理解Transformer的核心组件提供了新的理论视角，有助于推动Transformer架构的进一步发展。

Abstract: The Transformer architecture has achieved tremendous success in natural language processing, computer vision, and scientific computing through its self-attention mechanism. However, its core components-positional encoding and attention mechanisms-have lacked a unified physical or mathematical interpretation. This paper proposes a structural theoretical framework that integrates positional encoding, kernel integral operators, and attention mechanisms for in-depth theoretical investigation. We map discrete positions (such as text token indices and image pixel coordinates) to spatial functions on continuous manifolds, enabling a field-theoretic interpretation of Transformer layers as kernel-modulated operators acting over embedded manifolds.

</details>


### [50] [Rethinking Explanation Evaluation under the Retraining Scheme](https://arxiv.org/abs/2511.08281)
*Yi Cai,Thibaud Ardoin,Mayank Gulati,Gerhard Wunder*

Main category: cs.LG

TL;DR: 本文研究了基于重训练的归因方法评估方案ROAR中理论与实证结果不一致的问题，识别出符号问题是导致评估失真的关键因素，并提出改进方案来提高评估效率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有基于推理的归因评估方法存在分布偏移问题，而基于重训练的ROAR方案虽然解决了分布偏移，但其评估结果与理论预期存在矛盾，需要深入分析这种不一致的原因。

Method: 识别了符号问题作为关键因素，提出了简单的评估过程重构方案，并基于现有框架开发了新的变体，共同构建了全面的归因评估视角。

Result: 提出的改进方案显著提高了评估效率，在不同数据规模下的实证结果为精心选择的归因方法提供了更深入的性能洞察。

Conclusion: 研究揭示了可解释性研究中存在的开放挑战和未来方向，提出的评估方案增强了归因方法选择和基准测试的实用性。

Abstract: Feature attribution has gained prominence as a tool for explaining model decisions, yet evaluating explanation quality remains challenging due to the absence of ground-truth explanations. To circumvent this, explanation-guided input manipulation has emerged as an indirect evaluation strategy, measuring explanation effectiveness through the impact of input modifications on model outcomes during inference. Despite the widespread use, a major concern with inference-based schemes is the distribution shift caused by such manipulations, which undermines the reliability of their assessments. The retraining-based scheme ROAR overcomes this issue by adapting the model to the altered data distribution. However, its evaluation results often contradict the theoretical foundations of widely accepted explainers. This work investigates this misalignment between empirical observations and theoretical expectations. In particular, we identify the sign issue as a key factor responsible for residual information that ultimately distorts retraining-based evaluation. Based on the analysis, we show that a straightforward reframing of the evaluation process can effectively resolve the identified issue. Building on the existing framework, we further propose novel variants that jointly structure a comprehensive perspective on explanation evaluation. These variants largely improve evaluation efficiency over the standard retraining protocol, thereby enhancing practical applicability for explainer selection and benchmarking. Following our proposed schemes, empirical results across various data scales provide deeper insights into the performance of carefully selected explainers, revealing open challenges and future directions in explainability research.

</details>


### [51] [Multi-objective Hyperparameter Optimization in the Age of Deep Learning](https://arxiv.org/abs/2511.08371)
*Soham Basu,Frank Hutter,Danny Stoll*

Main category: cs.LG

TL;DR: PriMO是首个能够整合多目标用户信念的超参数优化算法，在8个深度学习基准测试中实现了最先进的性能，成为深度学习从业者的首选HPO算法。


<details>
  <summary>Details</summary>
Motivation: 深度学习专家通常具有关于哪些超参数设置能获得强性能的先验知识，但现有的HPO算法很少能利用这种先验知识，且没有算法能整合多目标的先验知识。

Method: 提出了PriMO算法，这是首个能够整合多目标用户信念的HPO算法。

Result: 在8个深度学习基准测试中，PriMO在多目标和单目标设置下都实现了最先进的性能。

Conclusion: PriMO明确地将自己定位为深度学习从业者的新首选HPO算法。

Abstract: While Deep Learning (DL) experts often have prior knowledge about which hyperparameter settings yield strong performance, only few Hyperparameter Optimization (HPO) algorithms can leverage such prior knowledge and none incorporate priors over multiple objectives. As DL practitioners often need to optimize not just one but many objectives, this is a blind spot in the algorithmic landscape of HPO. To address this shortcoming, we introduce PriMO, the first HPO algorithm that can integrate multi-objective user beliefs. We show PriMO achieves state-of-the-art performance across 8 DL benchmarks in the multi-objective and single-objective setting, clearly positioning itself as the new go-to HPO algorithm for DL practitioners.

</details>


### [52] [EMAformer: Enhancing Transformer through Embedding Armor for Time Series Forecasting](https://arxiv.org/abs/2511.08396)
*Zhiwei Zhang,Xinyi Du,Xuanchi Guo,Weihao Wang,Wenjuan Han*

Main category: cs.LG

TL;DR: EMAformer是一种增强Transformer架构的多元时间序列预测模型，通过引入全局稳定性、相位敏感性和跨轴特异性三个关键归纳偏置，在12个真实世界基准测试中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer架构在多元时间序列预测方面取得了显著进展，但其性能仍落后于最新的基于MLP的模型，作者将这种性能差距归因于不稳定的通道间关系。

Method: 提出EMAformer模型，通过辅助嵌入套件增强Transformer，引入三个关键归纳偏置：全局稳定性、相位敏感性和跨轴特异性。

Result: 在12个真实世界基准测试中实现了最先进的性能，MSE平均减少2.73%，MAE平均减少5.15%。

Conclusion: EMAformer显著提升了基于Transformer的方法在多元时间序列预测中的实际适用性。

Abstract: Multivariate time series forecasting is crucial across a wide range of domains. While presenting notable progress for the Transformer architecture, iTransformer still lags behind the latest MLP-based models. We attribute this performance gap to unstable inter-channel relationships. To bridge this gap, we propose EMAformer, a simple yet effective model that enhances the Transformer with an auxiliary embedding suite, akin to armor that reinforces its ability. By introducing three key inductive biases, i.e., \textit{global stability}, \textit{phase sensitivity}, and \textit{cross-axis specificity}, EMAformer unlocks the further potential of the Transformer architecture, achieving state-of-the-art performance on 12 real-world benchmarks and reducing forecasting errors by an average of 2.73\% in MSE and 5.15\% in MAE. This significantly advances the practical applicability of Transformer-based approaches for multivariate time series forecasting. The code is available on https://github.com/PlanckChang/EMAformer.

</details>


### [53] [Aligning by Misaligning: Boundary-aware Curriculum Learning for Multimodal Alignment](https://arxiv.org/abs/2511.08399)
*Hua Ye,Hang Ding,Siyuan Chen,Yiyang Jiang,Changyuan Zhang,Xuan Zhang*

Main category: cs.LG

TL;DR: BACL是一个轻量级的多模态模型增强模块，通过边界感知负采样和对比局部注意力损失，将模糊的负样本转化为课程学习信号，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型对所有负样本一视同仁，忽略了与正样本仅存在细微差异的模糊负样本，这些边界情况蕴含着重要的学习信号。

Method: 提出边界感知课程学习方法，包含边界感知负采样器（逐步增加难度）和对比局部注意力损失（定位不匹配区域），这两个模块完全可微分且可与任何现成的双编码器配合使用。

Result: 理论预测误差率为O(1/n)；实验显示在四个大规模基准测试中，相比CLIP提升高达32%的R@1，达到新的SOTA水平，且无需额外标签。

Conclusion: BACL通过有效利用边界负样本作为课程学习信号，显著提升了多模态模型的性能，证明了边界情况在模型训练中的重要性。

Abstract: Most multimodal models treat every negative pair alike, ignoring the ambiguous negatives that differ from the positive by only a small detail. We propose Boundary-Aware Curriculum with Local Attention (BACL), a lightweight add-on that turns these borderline cases into a curriculum signal. A Boundary-aware Negative Sampler gradually raises difficulty, while a Contrastive Local Attention loss highlights where the mismatch occurs. The two modules are fully differentiable and work with any off-the-shelf dual encoder. Theory predicts a fast O(1/n) error rate; practice shows up to +32% R@1 over CLIP and new SOTA on four large-scale benchmarks, all without extra labels.

</details>


### [54] [Binary Split Categorical feature with Mean Absolute Error Criteria in CART](https://arxiv.org/abs/2511.08470)
*Peng Yu,Yike Chen,Chao Xu,Albert Bifet,Jesse Read*

Main category: cs.LG

TL;DR: 本文证明了无监督数值编码方法不适用于MAE准则，并提出了一种新的高效分裂算法来处理CART算法中分类特征与MAE准则的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统上使用MAE准则处理分类特征时依赖各种数值编码方法，但现有方法存在局限性，需要更有效的解决方案。

Method: 提出了一种新颖高效的分裂算法，专门针对CART算法中分类特征与MAE准则的挑战。

Result: 研究发现无监督数值编码方法不适用于MAE准则，新算法能够有效解决这一问题。

Conclusion: 现有方法在处理分类特征与MAE准则时存在局限，新算法为增强CART算法中分类数据处理提供了有前景的解决方案。

Abstract: In the context of the Classification and Regression Trees (CART) algorithm, the efficient splitting of categorical features using standard criteria like GINI and Entropy is well-established. However, using the Mean Absolute Error (MAE) criterion for categorical features has traditionally relied on various numerical encoding methods. This paper demonstrates that unsupervised numerical encoding methods are not viable for the MAE criteria. Furthermore, we present a novel and efficient splitting algorithm that addresses the challenges of handling categorical features with the MAE criterion. Our findings underscore the limitations of existing approaches and offer a promising solution to enhance the handling of categorical data in CART algorithms.

</details>


### [55] [FMMI: Flow Matching Mutual Information Estimation](https://arxiv.org/abs/2511.08552)
*Ivan Butakov,Alexander Semenenko,Alexey Frolov,Ivan Oseledets*

Main category: cs.LG

TL;DR: 提出了一种新的互信息估计器，通过使用归一化流将一个分布转换为另一个分布，而不是训练分类器来区分联合分布和边缘分布。


<details>
  <summary>Details</summary>
Motivation: 传统的互信息估计方法使用分类器来区分联合分布和边缘分布，存在计算效率低和在高维情况下性能不佳的问题。

Method: 学习一个归一化流，将联合分布转换为边缘分布，从而直接估计互信息。

Result: 该方法计算效率高、估计精度好，能够很好地扩展到高维情况，并在广泛的真实互信息值范围内表现良好。

Conclusion: 通过重新构建互信息估计问题，使用归一化流方法提供了一种高效且精确的互信息估计解决方案。

Abstract: We introduce a novel Mutual Information (MI) estimator that fundamentally reframes the discriminative approach. Instead of training a classifier to discriminate between joint and marginal distributions, we learn a normalizing flow that transforms one into the other. This technique produces a computationally efficient and precise MI estimate that scales well to high dimensions and across a wide range of ground-truth MI values.

</details>


### [56] [The Path Not Taken: RLVR Provably Learns Off the Principals](https://arxiv.org/abs/2511.08567)
*Hanqing Zhu,Zhenyu Zhang,Hanxian Huang,DiJia Su,Zechun Liu,Jiawei Zhao,Igor Fedorov,Hamed Pirsiavash,Zhizhou Sha,Jinwon Lee,David Z. Pan,Zhangyang Wang,Yuandong Tian,Kai Sheng Tai*

Main category: cs.LG

TL;DR: RLVR在强化学习中表现出参数稀疏性，但这实际上是模型条件优化偏差的表面现象。研究发现RLVR在权重空间中沿非主方向学习，通过最小化谱漂移和减少主空间旋转来获得性能提升，而SFT则针对主权重并扭曲谱结构。


<details>
  <summary>Details</summary>
Motivation: 解决RLVR中看似参数稀疏但实际上存在系统性优化偏差的悖论，揭示RLVR与SFT在优化机制上的根本差异。

Method: 提出三闸门理论：闸门I（KL锚）施加KL约束更新；闸门II（模型几何）将步长引导至低曲率、保谱子空间；闸门III（精度）在非偏好区域隐藏微更新。通过参数级分析验证理论。

Result: 首次提供了RLVR学习动态的参数级表征：RLVR在权重空间的非主方向学习，实现最小谱漂移、减少主空间旋转和离主更新对齐。相比SFT，RLVR在保持谱结构方面更优。

Conclusion: RLVR与SFT处于不同的优化机制，直接适配SFT时代的参数高效微调方法存在缺陷。研究为理解RLVR提供了白盒视角，并为设计几何感知的RLVR原生学习算法指明了方向。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) reliably improves the reasoning performance of large language models, yet it appears to modify only a small fraction of parameters. We revisit this paradox and show that sparsity is a surface artifact of a model-conditioned optimization bias: for a fixed pretrained model, updates consistently localize to preferred parameter regions, highly consistent across runs and largely invariant to datasets and RL recipes. We mechanistically explain these dynamics with a Three-Gate Theory: Gate I (KL Anchor) imposes a KL-constrained update; Gate II (Model Geometry) steers the step off principal directions into low-curvature, spectrum-preserving subspaces; and Gate III (Precision) hides micro-updates in non-preferred regions, making the off-principal bias appear as sparsity. We then validate this theory and, for the first time, provide a parameter-level characterization of RLVR's learning dynamics: RLVR learns off principal directions in weight space, achieving gains via minimal spectral drift, reduced principal-subspace rotation, and off-principal update alignment. In contrast, SFT targets principal weights, distorts the spectrum, and even lags RLVR.
  Together, these results provide the first parameter-space account of RLVR's training dynamics, revealing clear regularities in how parameters evolve. Crucially, we show that RL operates in a distinct optimization regime from SFT, so directly adapting SFT-era parameter-efficient fine-tuning (PEFT) methods can be flawed, as evidenced by our case studies on advanced sparse fine-tuning and LoRA variants. We hope this work charts a path toward a white-box understanding of RLVR and the design of geometry-aware, RLVR-native learning algorithms, rather than repurposed SFT-era heuristics.

</details>
