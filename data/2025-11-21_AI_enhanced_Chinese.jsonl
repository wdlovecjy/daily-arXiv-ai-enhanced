{"id": "2511.15714", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15714", "abs": "https://arxiv.org/abs/2511.15714", "authors": ["Ariel Kamen", "Yakov Kamen"], "title": "Majority Rules: LLM Ensemble is a Winning Approach for Content Categorization", "comment": "17 pages, 7 figures", "summary": "This study introduces an ensemble framework for unstructured text categorization using large language models (LLMs). By integrating multiple models, the ensemble large language model (eLLM) framework addresses common weaknesses of individual systems, including inconsistency, hallucination, category inflation, and misclassification. The eLLM approach yields a substantial performance improvement of up to 65\\% in F1-score over the strongest single model. We formalize the ensemble process through a mathematical model of collective decision-making and establish principled aggregation criteria. Using the Interactive Advertising Bureau (IAB) hierarchical taxonomy, we evaluate ten state-of-the-art LLMs under identical zero-shot conditions on a human-annotated corpus of 8{,}660 samples. Results show that individual models plateau in performance due to the compression of semantically rich text into sparse categorical representations, while eLLM improves both robustness and accuracy. With a diverse consortium of models, eLLM achieves near human-expert-level performance, offering a scalable and reliable solution for taxonomy-based classification that may significantly reduce dependence on human expert labeling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u975e\u7ed3\u6784\u5316\u6587\u672c\u5206\u7c7b\u96c6\u6210\u6846\u67b6(eLLM)\uff0c\u901a\u8fc7\u6574\u5408\u591a\u4e2a\u6a21\u578b\u89e3\u51b3\u4e86\u5355\u4e2a\u7cfb\u7edf\u7684\u5e38\u89c1\u5f31\u70b9\uff0c\u5728IAB\u5206\u5c42\u5206\u7c7b\u6cd5\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe65%\u7684F1\u5206\u6570\u63d0\u5347\u3002", "motivation": "\u89e3\u51b3\u5355\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u5206\u7c7b\u4e2d\u7684\u4e0d\u4e00\u81f4\u6027\u3001\u5e7b\u89c9\u3001\u7c7b\u522b\u81a8\u80c0\u548c\u8bef\u5206\u7c7b\u7b49\u95ee\u9898\uff0c\u63d0\u9ad8\u5206\u7c7b\u7684\u53ef\u9760\u6027\u548c\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u96c6\u6210\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u5b66\u5efa\u6a21\u96c6\u4f53\u51b3\u7b56\u8fc7\u7a0b\u5e76\u5efa\u7acb\u539f\u5219\u6027\u805a\u5408\u51c6\u5219\uff0c\u5728IAB\u5206\u5c42\u5206\u7c7b\u6cd5\u4e0a\u8bc4\u4f30\u4e8610\u4e2a\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u75288,660\u4e2a\u4eba\u5de5\u6807\u6ce8\u6837\u672c\u8fdb\u884c\u96f6\u6837\u672c\u6d4b\u8bd5\u3002", "result": "eLLM\u6846\u67b6\u76f8\u6bd4\u6700\u5f3a\u5355\u6a21\u578b\u5b9e\u73b0\u4e86\u9ad8\u8fbe65%\u7684F1\u5206\u6570\u63d0\u5347\uff0c\u8fbe\u5230\u63a5\u8fd1\u4eba\u7c7b\u4e13\u5bb6\u6c34\u5e73\u7684\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\u3002", "conclusion": "eLLM\u4e3a\u57fa\u4e8e\u5206\u7c7b\u6cd5\u7684\u5206\u7c7b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u80fd\u663e\u8457\u51cf\u5c11\u5bf9\u4eba\u7c7b\u4e13\u5bb6\u6807\u6ce8\u7684\u4f9d\u8d56\u3002"}}
{"id": "2511.15716", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15716", "abs": "https://arxiv.org/abs/2511.15716", "authors": ["Abraham Itzhak Weinberg"], "title": "MACIE: Multi-Agent Causal Intelligence Explainer for Collective Behavior Understanding", "comment": null, "summary": "As Multi Agent Reinforcement Learning systems are used in safety critical applications. Understanding why agents make decisions and how they achieve collective behavior is crucial. Existing explainable AI methods struggle in multi agent settings. They fail to attribute collective outcomes to individuals, quantify emergent behaviors, or capture complex interactions. We present MACIE Multi Agent Causal Intelligence Explainer, a framework combining structural causal models, interventional counterfactuals, and Shapley values to provide comprehensive explanations. MACIE addresses three questions. First, each agent's causal contribution using interventional attribution scores. Second, system level emergent intelligence through synergy metrics separating collective effects from individual contributions. Third, actionable explanations using natural language narratives synthesizing causal insights. We evaluate MACIE across four MARL scenarios: cooperative, competitive, and mixed motive. Results show accurate outcome attribution, mean phi_i equals 5.07, standard deviation less than 0.05, detection of positive emergence in cooperative tasks, synergy index up to 0.461, and efficient computation, 0.79 seconds per dataset on CPU. MACIE uniquely combines causal rigor, emergence quantification, and multi agent support while remaining practical for real time use. This represents a step toward interpretable, trustworthy, and accountable multi agent AI.", "AI": {"tldr": "MACIE\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u56e0\u679c\u667a\u80fd\u89e3\u91ca\u6846\u67b6\uff0c\u7ed3\u5408\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u3001\u5e72\u9884\u53cd\u4e8b\u5b9e\u548cShapley\u503c\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u5168\u9762\u89e3\u91ca\uff0c\u89e3\u51b3\u4e2a\u4f53\u56e0\u679c\u8d21\u732e\u3001\u7cfb\u7edf\u7ea7\u6d8c\u73b0\u667a\u80fd\u548c\u53ef\u64cd\u4f5c\u89e3\u91ca\u4e09\u4e2a\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u4f7f\u7528\uff0c\u7406\u89e3\u667a\u80fd\u4f53\u51b3\u7b56\u539f\u56e0\u548c\u96c6\u4f53\u884c\u4e3a\u5b9e\u73b0\u65b9\u5f0f\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u53ef\u89e3\u91caAI\u65b9\u6cd5\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u65e0\u6cd5\u5c06\u96c6\u4f53\u7ed3\u679c\u5f52\u56e0\u4e8e\u4e2a\u4f53\u3001\u91cf\u5316\u6d8c\u73b0\u884c\u4e3a\u6216\u6355\u6349\u590d\u6742\u4ea4\u4e92\u3002", "method": "MACIE\u6846\u67b6\u7ed3\u5408\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u3001\u5e72\u9884\u53cd\u4e8b\u5b9e\u548cShapley\u503c\uff0c\u901a\u8fc7\u5e72\u9884\u5f52\u56e0\u5206\u6570\u8bc4\u4f30\u6bcf\u4e2a\u667a\u80fd\u4f53\u7684\u56e0\u679c\u8d21\u732e\uff0c\u4f7f\u7528\u534f\u540c\u6307\u6807\u5206\u79bb\u96c6\u4f53\u6548\u5e94\u4e0e\u4e2a\u4f53\u8d21\u732e\u6765\u91cf\u5316\u7cfb\u7edf\u7ea7\u6d8c\u73b0\u667a\u80fd\uff0c\u5e76\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u53d9\u8ff0\u5408\u6210\u56e0\u679c\u6d1e\u5bdf\u63d0\u4f9b\u53ef\u64cd\u4f5c\u89e3\u91ca\u3002", "result": "\u5728\u56db\u79cdMARL\u573a\u666f\uff08\u5408\u4f5c\u3001\u7ade\u4e89\u548c\u6df7\u5408\u52a8\u673a\uff09\u4e2d\u8bc4\u4f30\u663e\u793a\uff1a\u51c6\u786e\u7684\u7ed3\u679c\u5f52\u56e0\uff08\u5e73\u5747\u03c6_i=5.07\uff0c\u6807\u51c6\u5dee<0.05\uff09\uff0c\u5728\u5408\u4f5c\u4efb\u52a1\u4e2d\u68c0\u6d4b\u5230\u6b63\u5411\u6d8c\u73b0\uff08\u534f\u540c\u6307\u6570\u9ad8\u8fbe0.461\uff09\uff0c\u8ba1\u7b97\u6548\u7387\u9ad8\uff08CPU\u4e0a\u6bcf\u4e2a\u6570\u636e\u96c60.79\u79d2\uff09\u3002", "conclusion": "MACIE\u72ec\u7279\u5730\u7ed3\u5408\u4e86\u56e0\u679c\u4e25\u8c28\u6027\u3001\u6d8c\u73b0\u91cf\u5316\u548c\u591a\u667a\u80fd\u4f53\u652f\u6301\uff0c\u540c\u65f6\u4fdd\u6301\u5b9e\u65f6\u4f7f\u7528\u7684\u5b9e\u7528\u6027\uff0c\u4ee3\u8868\u4e86\u5411\u53ef\u89e3\u91ca\u3001\u53ef\u4fe1\u8d56\u548c\u8d1f\u8d23\u4efb\u7684\u591a\u667a\u80fd\u4f53AI\u8fc8\u51fa\u7684\u4e00\u6b65\u3002"}}
{"id": "2511.15812", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.15812", "abs": "https://arxiv.org/abs/2511.15812", "authors": ["Luke Dosiek", "Akaash Karn", "Frank Liu"], "title": "Rapid and Accurate Changepoint Detection of Power System Forced Oscillations", "comment": "Currently under review for the proceedings of the 2026 IEEE Power and Energy Society General Meeting (PESGM26)", "summary": "This paper describes a new approach for using changepoint detection (CPD) to estimate the starting and stopping times of a forced oscillation (FO) in measured power system data. As with a previous application of CPD to this problem, the pruned exact linear time (PELT) algorithm is used. However, instead of allowing PELT to automatically tune its penalty parameter, a method of manually providing it is presented that dramatically reduces computation time without sacrificing accuracy. Additionally, the new algorithm requires fewer input parameters and provides a formal, data-driven approach to setting the minimum FO segment length to consider as troublesome for an electromechanical mode meter. A low-order ARMAX representation of the minniWECC model is used to test the approach, where a 98\\% reduction in computation time is enjoyed with high estimation accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u53d8\u70b9\u68c0\u6d4b(CPD)\u6765\u4f30\u8ba1\u7535\u529b\u7cfb\u7edf\u6570\u636e\u4e2d\u5f3a\u5236\u632f\u8361\u8d77\u6b62\u65f6\u95f4\u7684\u65b0\u65b9\u6cd5\uff0c\u91c7\u7528PELT\u7b97\u6cd5\u4f46\u901a\u8fc7\u624b\u52a8\u8bbe\u7f6e\u60e9\u7f5a\u53c2\u6570\uff0c\u5927\u5e45\u51cf\u5c11\u8ba1\u7b97\u65f6\u95f4\u800c\u4e0d\u635f\u5931\u7cbe\u5ea6\u3002", "motivation": "\u6539\u8fdb\u73b0\u6709CPD\u65b9\u6cd5\u5728\u5f3a\u5236\u632f\u8361\u68c0\u6d4b\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u51cf\u5c11\u8f93\u5165\u53c2\u6570\u9700\u6c42\uff0c\u5e76\u63d0\u4f9b\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u6765\u8bbe\u7f6e\u6700\u5c0fFO\u6bb5\u957f\u5ea6\u3002", "method": "\u4f7f\u7528PELT\u7b97\u6cd5\u8fdb\u884c\u53d8\u70b9\u68c0\u6d4b\uff0c\u4f46\u624b\u52a8\u63d0\u4f9b\u60e9\u7f5a\u53c2\u6570\u800c\u975e\u81ea\u52a8\u8c03\u53c2\uff0c\u7ed3\u5408\u4f4e\u9636ARMAX\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\u9a8c\u8bc1\u3002", "result": "\u5728minniWECC\u6a21\u578b\u6d4b\u8bd5\u4e2d\uff0c\u8ba1\u7b97\u65f6\u95f4\u51cf\u5c11\u4e8698%\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u4f30\u8ba1\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5f3a\u5236\u632f\u8361\u68c0\u6d4b\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u51cf\u5c11\u4e86\u53c2\u6570\u9700\u6c42\uff0c\u4e3a\u673a\u7535\u6a21\u5f0f\u4eea\u8868\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.16164", "categories": ["cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.16164", "abs": "https://arxiv.org/abs/2511.16164", "authors": ["Eloi Lindas", "Yannig Goude", "Philippe Ciais"], "title": "Achieving Skilled and Reliable Daily Probabilistic Forecasts of Wind Power at Subseasonal-to-Seasonal Timescales over France", "comment": null, "summary": "Accurate and reliable wind power forecasts are crucial for grid stability, balancing supply and demand, and market risk management. Even though short-term weather forecasts have been thoroughly used to provide short-term renewable power predictions, forecasts involving longer prediction horizons still need investigations. Despite the recent progress in subseasonal-to-seasonal weather probabilistic forecasting, their use for wind power prediction usually involves both temporal and spatial aggregation achieve reasonable skill. In this study, we present a forecasting pipeline enabling to transform ECMWF subseasonal-to-seasonal weather forecasts into wind power forecasts for lead times ranging from 1 day to 46 days at daily resolution. This framework also include post-processing of the resulting power ensembles to account for the biases and lack of dispersion of the weather forecasts. We show that our method is able to outperform a climatological baseline by 50 % in terms of both Continuous Ranked Probability Skill Score and Ensemble Mean Squared Error while also providing near perfect calibration of the forecasts for lead times ranging from 15 to 46 days.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5c06ECMWF\u6b21\u5b63\u8282\u5230\u5b63\u8282\u5929\u6c14\u9884\u62a5\u8f6c\u5316\u4e3a\u98ce\u529f\u7387\u9884\u6d4b\u7684\u6846\u67b6\uff0c\u9884\u6d4b\u8303\u56f4\u4ece1\u5929\u523046\u5929\uff0c\u901a\u8fc7\u540e\u5904\u7406\u6539\u5584\u9884\u62a5\u504f\u5dee\u548c\u79bb\u6563\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u51c6\u786e\u53ef\u9760\u7684\u98ce\u529f\u7387\u9884\u6d4b\u5bf9\u7535\u7f51\u7a33\u5b9a\u3001\u4f9b\u9700\u5e73\u8861\u548c\u5e02\u573a\u98ce\u9669\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6d89\u53ca\u8f83\u957f\u9884\u6d4b\u5468\u671f\u7684\u98ce\u529f\u7387\u9884\u6d4b\u4ecd\u9700\u6df1\u5165\u7814\u7a76\uff0c\u5c3d\u7ba1\u6b21\u5b63\u8282\u5230\u5b63\u8282\u5929\u6c14\u6982\u7387\u9884\u62a5\u5df2\u6709\u8fdb\u5c55\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u9884\u6d4b\u6d41\u7a0b\uff0c\u5c06ECMWF\u6b21\u5b63\u8282\u5230\u5b63\u8282\u5929\u6c14\u9884\u62a5\u8f6c\u6362\u4e3a\u98ce\u529f\u7387\u9884\u6d4b\uff0c\u5305\u62ec\u5bf9\u7ed3\u679c\u529f\u7387\u96c6\u5408\u8fdb\u884c\u540e\u5904\u7406\u4ee5\u89e3\u51b3\u5929\u6c14\u9884\u62a5\u7684\u504f\u5dee\u548c\u79bb\u6563\u5ea6\u4e0d\u8db3\u95ee\u9898\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u8fde\u7eed\u6392\u540d\u6982\u7387\u6280\u80fd\u8bc4\u5206\u548c\u96c6\u5408\u5747\u65b9\u8bef\u5dee\u65b9\u9762\u6bd4\u6c14\u5019\u5b66\u57fa\u51c6\u63d0\u9ad8\u4e8650%\uff0c\u572815\u523046\u5929\u7684\u9884\u6d4b\u8303\u56f4\u5185\u63d0\u4f9b\u4e86\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u6821\u51c6\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u5c06\u6b21\u5b63\u8282\u5230\u5b63\u8282\u5929\u6c14\u9884\u62a5\u8f6c\u5316\u4e3a\u98ce\u529f\u7387\u9884\u6d4b\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\uff0c\u5e76\u4e3a\u4e2d\u957f\u671f\u98ce\u529f\u7387\u9884\u6d4b\u63d0\u4f9b\u4e86\u53ef\u9760\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.15822", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.15822", "abs": "https://arxiv.org/abs/2511.15822", "authors": ["Mu Niu", "Yue Zhang", "Ke Ye", "Pokman Cheung", "Yizhu Wang", "Xiaochen Yang"], "title": "Atlas Gaussian processes on restricted domains and point clouds", "comment": null, "summary": "In real-world applications, data often reside in restricted domains with unknown boundaries, or as high-dimensional point clouds lying on a lower-dimensional, nontrivial, unknown manifold. Traditional Gaussian Processes (GPs) struggle to capture the underlying geometry in such settings. Some existing methods assume a flat space embedded in a point cloud, which can be represented by a single latent chart (latent space), while others exhibit weak performance when the point cloud is sparse or irregularly sampled. The goal of this work is to address these challenges. The main contributions are twofold: (1) We establish the Atlas Brownian Motion (BM) framework for estimating the heat kernel on point clouds with unknown geometries and nontrivial topological structures; (2) Instead of directly using the heat kernel estimates, we construct a Riemannian corrected kernel by combining the global heat kernel with local RBF kernel and leading to the formulation of Riemannian-corrected Atlas Gaussian Processes (RC-AGPs). The resulting RC-AGPs are applied to regression tasks across synthetic and real-world datasets. These examples demonstrate that our method outperforms existing approaches in both heat kernel estimation and regression accuracy. It improves statistical inference by effectively bridging the gap between complex, high-dimensional observations and manifold-based inferences.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Atlas\u5e03\u6717\u8fd0\u52a8\u6846\u67b6\u6765\u4f30\u8ba1\u672a\u77e5\u51e0\u4f55\u548c\u62d3\u6251\u7ed3\u6784\u70b9\u4e91\u4e0a\u7684\u70ed\u6838\uff0c\u5e76\u6784\u5efa\u4e86Riemannian\u6821\u6b63\u6838\uff0c\u5f62\u6210\u4e86Riemannian\u6821\u6b63Atlas\u9ad8\u65af\u8fc7\u7a0b(RC-AGPs)\uff0c\u5728\u56de\u5f52\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u5b9e\u5e94\u7528\u4e2d\u6570\u636e\u5e38\u4f4d\u4e8e\u8fb9\u754c\u672a\u77e5\u7684\u53d7\u9650\u57df\u4e2d\uff0c\u6216\u4f5c\u4e3a\u9ad8\u7ef4\u70b9\u4e91\u4f4d\u4e8e\u4f4e\u7ef4\u672a\u77e5\u6d41\u5f62\u4e0a\u3002\u4f20\u7edf\u9ad8\u65af\u8fc7\u7a0b\u96be\u4ee5\u6355\u6349\u6b64\u7c7b\u51e0\u4f55\u7ed3\u6784\uff0c\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u5047\u8bbe\u5e73\u5766\u7a7a\u95f4\u5d4c\u5165\u70b9\u4e91\uff0c\u8981\u4e48\u5728\u7a00\u758f\u6216\u4e0d\u89c4\u5219\u91c7\u6837\u70b9\u4e91\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u5efa\u7acbAtlas\u5e03\u6717\u8fd0\u52a8\u6846\u67b6\u4f30\u8ba1\u672a\u77e5\u51e0\u4f55\u70b9\u4e91\u4e0a\u7684\u70ed\u6838\uff1b\u6784\u5efaRiemannian\u6821\u6b63\u6838\uff0c\u5c06\u5168\u5c40\u70ed\u6838\u4e0e\u5c40\u90e8RBF\u6838\u7ed3\u5408\uff0c\u5f62\u6210Riemannian\u6821\u6b63Atlas\u9ad8\u65af\u8fc7\u7a0b(RC-AGPs)\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u56de\u5f52\u4efb\u52a1\u4e2d\uff0cRC-AGPs\u5728\u70ed\u6838\u4f30\u8ba1\u548c\u56de\u5f52\u7cbe\u5ea6\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6709\u6548\u5f25\u5408\u4e86\u590d\u6742\u9ad8\u7ef4\u89c2\u6d4b\u4e0e\u57fa\u4e8e\u6d41\u5f62\u63a8\u65ad\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "RC-AGPs\u901a\u8fc7\u7ed3\u5408\u5168\u5c40\u70ed\u6838\u548c\u5c40\u90e8RBF\u6838\uff0c\u5728\u672a\u77e5\u51e0\u4f55\u7ed3\u6784\u7684\u70b9\u4e91\u4e0a\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u7684\u7edf\u8ba1\u63a8\u65ad\uff0c\u63d0\u5347\u4e86\u56de\u5f52\u6027\u80fd\u3002"}}
{"id": "2511.15738", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15738", "abs": "https://arxiv.org/abs/2511.15738", "authors": ["Chao Yu", "Qixin Tan", "Jiaxuan Gao", "Shi Yu", "Hong Lu", "Xinting Yang", "Zelai Xu", "Yu Wang", "Yi Wu", "Eugene Vinitsky"], "title": "Extending Test-Time Scaling: A 3D Perspective with Context, Batch, and Turn", "comment": "44 pages, 12 figures", "summary": "Reasoning reinforcement learning (RL) has recently revealed a new scaling effect: test-time scaling. Thinking models such as R1 and o1 improve their reasoning accuracy at test time as the length of the reasoning context increases. However, compared with training-time scaling, test-time scaling is fundamentally limited by the limited context length of base models, which remains orders of magnitude smaller than the amount of tokens consumed during training. We revisit test-time enhancement techniques through the lens of scaling effect and introduce a unified framework of multi-dimensional test-time scaling to extend the capacity of test-time reasoning. Beyond conventional context-length scaling, we consider two additional dimensions: batch scaling, where accuracy improves with parallel sampling, and turn scaling, where iterative self-refinement enhances reasoning quality. Building on this perspective, we propose 3D test-time scaling, which integrates context, batch, and turn scaling. We show that: (1) each dimension demonstrates a test-time scaling effect, but with a bounded capacity; (2) combining all three dimensions substantially improves the reasoning performance of challenging testbeds, including IOI, IMO, and CPHO, and further benefits from human preference feedback; and (3) the human-in-the-loop framework naturally extends to a more open-ended domain, i.e., embodied learning, which enables the design of humanoid control behaviors.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e09\u7ef4\u6d4b\u8bd5\u65f6\u6269\u5c55\u6846\u67b6\uff0c\u5c06\u4e0a\u4e0b\u6587\u957f\u5ea6\u3001\u6279\u91cf\u91c7\u6837\u548c\u8fed\u4ee3\u8f6e\u6b21\u4e09\u4e2a\u7ef4\u5ea6\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u6548\u5e94\u7ed3\u5408\u8d77\u6765\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u5177\u8eab\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u53d7\u9650\u4e8e\u57fa\u7840\u6a21\u578b\u7684\u6709\u9650\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u8fdc\u5c0f\u4e8e\u8bad\u7ec3\u65f6\u6d88\u8017\u7684token\u6570\u91cf\u3002\u9700\u8981\u63a2\u7d22\u66f4\u591a\u7ef4\u5ea6\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u65b9\u6cd5\u6765\u7a81\u7834\u8fd9\u4e00\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u7ef4\u6d4b\u8bd5\u65f6\u6269\u5c55\u6846\u67b6\uff0c\u5305\u62ec\uff1a\u4e0a\u4e0b\u6587\u957f\u5ea6\u6269\u5c55\uff08\u589e\u52a0\u63a8\u7406\u4e0a\u4e0b\u6587\uff09\u3001\u6279\u91cf\u6269\u5c55\uff08\u5e76\u884c\u91c7\u6837\u63d0\u5347\u51c6\u786e\u7387\uff09\u3001\u8f6e\u6b21\u6269\u5c55\uff08\u8fed\u4ee3\u81ea\u6211\u4f18\u5316\u63d0\u5347\u63a8\u7406\u8d28\u91cf\uff09\u3002", "result": "\u6bcf\u4e2a\u7ef4\u5ea6\u90fd\u8868\u73b0\u51fa\u6d4b\u8bd5\u65f6\u6269\u5c55\u6548\u5e94\u4f46\u5bb9\u91cf\u6709\u9650\uff1b\u4e09\u4e2a\u7ef4\u5ea6\u7ed3\u5408\u663e\u8457\u63d0\u5347\u4e86IOI\u3001IMO\u3001CPHO\u7b49\u6311\u6218\u6027\u6d4b\u8bd5\u96c6\u7684\u63a8\u7406\u6027\u80fd\uff1b\u4eba\u7c7b\u53cd\u9988\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6548\u679c\uff1b\u6846\u67b6\u53ef\u6269\u5c55\u5230\u5177\u8eab\u5b66\u4e60\u9886\u57df\u3002", "conclusion": "\u4e09\u7ef4\u6d4b\u8bd5\u65f6\u6269\u5c55\u6846\u67b6\u6709\u6548\u7a81\u7834\u4e86\u5355\u4e00\u4e0a\u4e0b\u6587\u6269\u5c55\u7684\u9650\u5236\uff0c\u4e3a\u63a8\u7406\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u65b0\u7684\u6269\u5c55\u7ef4\u5ea6\uff0c\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u548c\u5f00\u653e\u9886\u57df\u5e94\u7528\u4e2d\u5c55\u73b0\u51fa\u826f\u597d\u6f5c\u529b\u3002"}}
{"id": "2511.15902", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.15902", "abs": "https://arxiv.org/abs/2511.15902", "authors": ["Roman Dolgopolyi", "Antonis Chatzipanagiotou"], "title": "EEG Emotion Recognition Through Deep Learning", "comment": "This version corresponds to the original manuscript submitted to the 22nd EMCIS conference prior to peer review. The peer-reviewed and accepted version will appear in the Springer conference proceedings", "summary": "An advanced emotion classification model was developed using a CNN-Transformer architecture for emotion recognition from EEG brain wave signals, effectively distinguishing among three emotional states, positive, neutral and negative. The model achieved a testing accuracy of 91%, outperforming traditional models such as SVM, DNN, and Logistic Regression. Training was conducted on a custom dataset created by merging data from SEED, SEED-FRA, and SEED-GER repositories, comprising 1,455 samples with EEG recordings labeled according to emotional states. The combined dataset represents one of the largest and most culturally diverse collections available. Additionally, the model allows for the reduction of the requirements of the EEG apparatus, by leveraging only 5 electrodes of the 62. This reduction demonstrates the feasibility of deploying a more affordable consumer-grade EEG headset, thereby enabling accessible, at-home use, while also requiring less computational power. This advancement sets the groundwork for future exploration into mood changes induced by media content consumption, an area that remains underresearched. Integration into medical, wellness, and home-health platforms could enable continuous, passive emotional monitoring, particularly beneficial in clinical or caregiving settings where traditional behavioral cues, such as facial expressions or vocal tone, are diminished, restricted, or difficult to interpret, thus potentially transforming mental health diagnostics and interventions...", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eCNN-Transformer\u67b6\u6784\u7684\u8111\u7535\u6ce2\u60c5\u7eea\u5206\u7c7b\u6a21\u578b\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u79ef\u6781\u3001\u4e2d\u6027\u548c\u6d88\u6781\u4e09\u79cd\u60c5\u7eea\u72b6\u6001\uff0c\u6d4b\u8bd5\u51c6\u786e\u7387\u8fbe\u523091%\uff0c\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u60c5\u7eea\u8bc6\u522b\u65b9\u6cd5\u5728\u9762\u90e8\u8868\u60c5\u6216\u8bed\u97f3\u7ebf\u7d22\u53d7\u9650\u573a\u666f\u4e0b\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u533b\u7597\u3001\u5065\u5eb7\u76d1\u6d4b\u7b49\u5e94\u7528\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u60c5\u7eea\u8bc6\u522b\u6280\u672f\u3002", "method": "\u4f7f\u7528CNN-Transformer\u6df7\u5408\u67b6\u6784\u5904\u7406EEG\u4fe1\u53f7\uff0c\u5728\u5408\u5e76SEED\u3001SEED-FRA\u548cSEED-GER\u6570\u636e\u96c6\u7684\u57fa\u7840\u4e0a\u8bad\u7ec3\u6a21\u578b\uff0c\u4ec5\u97005\u4e2a\u7535\u6781\u800c\u975e\u4f20\u7edf\u768462\u4e2a\u3002", "result": "\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u523091%\u7684\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8eSVM\u3001DNN\u548c\u903b\u8f91\u56de\u5f52\u7b49\u4f20\u7edf\u65b9\u6cd5\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u786c\u4ef6\u8981\u6c42\u548c\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5f00\u53d1\u7ecf\u6d4e\u5b9e\u60e0\u7684\u6d88\u8d39\u7ea7EEG\u8bbe\u5907\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u6709\u671b\u5728\u533b\u7597\u5065\u5eb7\u3001\u5bb6\u5ead\u76d1\u6d4b\u7b49\u9886\u57df\u5b9e\u73b0\u8fde\u7eed\u88ab\u52a8\u7684\u60c5\u7eea\u76d1\u6d4b\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4f20\u7edf\u884c\u4e3a\u7ebf\u7d22\u53d7\u9650\u7684\u4e34\u5e8a\u6216\u62a4\u7406\u573a\u666f\u3002"}}
{"id": "2511.15720", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15720", "abs": "https://arxiv.org/abs/2511.15720", "authors": ["Islem Sahraoui"], "title": "Automated Hazard Detection in Construction Sites Using Large Language and Vision-Language Models", "comment": "Master thesis, University of Houton", "summary": "This thesis explores a multimodal AI framework for enhancing construction safety through the combined analysis of textual and visual data. In safety-critical environments such as construction sites, accident data often exists in multiple formats, such as written reports, inspection records, and site imagery, making it challenging to synthesize hazards using traditional approaches. To address this, this thesis proposed a multimodal AI framework that combines text and image analysis to assist in identifying safety hazards on construction sites. Two case studies were consucted to evaluate the capabilities of large language models (LLMs) and vision-language models (VLMs) for automated hazard identification.The first case study introduces a hybrid pipeline that utilizes GPT 4o and GPT 4o mini to extract structured insights from a dataset of 28,000 OSHA accident reports (2000-2025). The second case study extends this investigation using Molmo 7B and Qwen2 VL 2B, lightweight, open-source VLMs. Using the public ConstructionSite10k dataset, the performance of the two models was evaluated on rule-level safety violation detection using natural language prompts. This experiment served as a cost-aware benchmark against proprietary models and allowed testing at scale with ground-truth labels. Despite their smaller size, Molmo 7B and Quen2 VL 2B showed competitive performance in certain prompt configurations, reinforcing the feasibility of low-resource multimodal systems for rule-aware safety monitoring.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001AI\u6846\u67b6\uff0c\u7ed3\u5408\u6587\u672c\u548c\u56fe\u50cf\u5206\u6790\u6765\u8bc6\u522b\u5efa\u7b51\u5de5\u5730\u7684\u5b89\u5168\u9690\u60a3\uff0c\u901a\u8fc7\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u5371\u9669\u8bc6\u522b\u4e2d\u7684\u80fd\u529b\u3002", "motivation": "\u5728\u5efa\u7b51\u5de5\u5730\u7b49\u5b89\u5168\u5173\u952e\u73af\u5883\u4e2d\uff0c\u4e8b\u6545\u6570\u636e\u901a\u5e38\u4ee5\u591a\u79cd\u683c\u5f0f\u5b58\u5728\uff08\u5982\u4e66\u9762\u62a5\u544a\u3001\u68c0\u67e5\u8bb0\u5f55\u548c\u73b0\u573a\u56fe\u50cf\uff09\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u7efc\u5408\u8bc6\u522b\u5371\u9669\u6e90\u3002", "method": "\u5f00\u53d1\u4e86\u591a\u6a21\u6001AI\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\uff1a1\uff09\u4f7f\u7528GPT-4o\u548cGPT-4o mini\u4ece28,000\u4efdOSHA\u4e8b\u6545\u62a5\u544a\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u89c1\u89e3\uff1b2\uff09\u4f7f\u7528\u8f7b\u91cf\u7ea7\u5f00\u6e90\u89c6\u89c9\u8bed\u8a00\u6a21\u578bMolmo 7B\u548cQwen2 VL 2B\u5728ConstructionSite10k\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u89c4\u5219\u7ea7\u5b89\u5168\u8fdd\u89c4\u68c0\u6d4b\u3002", "result": "\u5c3d\u7ba1\u6a21\u578b\u89c4\u6a21\u8f83\u5c0f\uff0cMolmo 7B\u548cQwen2 VL 2B\u5728\u67d0\u4e9b\u63d0\u793a\u914d\u7f6e\u4e0b\u8868\u73b0\u51fa\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u4f4e\u8d44\u6e90\u591a\u6a21\u6001\u7cfb\u7edf\u7528\u4e8e\u89c4\u5219\u611f\u77e5\u5b89\u5168\u76d1\u63a7\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u591a\u6a21\u6001AI\u6846\u67b6\u80fd\u591f\u6709\u6548\u7ed3\u5408\u6587\u672c\u548c\u89c6\u89c9\u6570\u636e\u5206\u6790\uff0c\u4e3a\u5efa\u7b51\u5b89\u5168\u76d1\u63a7\u63d0\u4f9b\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u8f7b\u91cf\u7ea7\u5f00\u6e90\u6a21\u578b\u5728\u6210\u672c\u654f\u611f\u573a\u666f\u4e2d\u5177\u6709\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.15722", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15722", "abs": "https://arxiv.org/abs/2511.15722", "authors": ["Weichen Liu", "Qiyao Xue", "Haoming Wang", "Xiangyu Yin", "Boyuan Yang", "Wei Gao"], "title": "Spatial Reasoning in Multimodal Large Language Models: A Survey of Tasks, Benchmarks and Methods", "comment": null, "summary": "Spatial reasoning, which requires ability to perceive and manipulate spatial relationships in the 3D world, is a fundamental aspect of human intelligence, yet remains a persistent challenge for Multimodal large language models (MLLMs). While existing surveys often categorize recent progress based on input modality (e.g., text, image, video, or 3D), we argue that spatial ability is not solely determined by the input format. Instead, our survey introduces a taxonomy that organizes spatial intelligence from cognitive aspect and divides tasks in terms of reasoning complexity, linking them to several cognitive functions. We map existing benchmarks across text only, vision language, and embodied settings onto this taxonomy, and review evaluation metrics and methodologies for assessing spatial reasoning ability. This cognitive perspective enables more principled cross-task comparisons and reveals critical gaps between current model capabilities and human-like reasoning. In addition, we analyze methods for improving spatial ability, spanning both training-based and reasoning-based approaches. This dual perspective analysis clarifies their respective strengths, uncovers complementary mechanisms. By surveying tasks, benchmarks, and recent advances, we aim to provide new researchers with a comprehensive understanding of the field and actionable directions for future research.", "AI": {"tldr": "\u672c\u6587\u4ece\u8ba4\u77e5\u89d2\u5ea6\u6784\u5efa\u7a7a\u95f4\u667a\u80fd\u5206\u7c7b\u6cd5\uff0c\u6309\u63a8\u7406\u590d\u6742\u5ea6\u7ec4\u7ec7\u4efb\u52a1\uff0c\u5c06\u73b0\u6709\u57fa\u51c6\u6620\u5c04\u5230\u8be5\u5206\u7c7b\u4e2d\uff0c\u5206\u6790\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u6bd4\u8f83\u8bad\u7ec3\u5f0f\u548c\u63a8\u7406\u5f0f\u63d0\u5347\u7a7a\u95f4\u80fd\u529b\u7684\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8c03\u67e5\u591a\u57fa\u4e8e\u8f93\u5165\u6a21\u6001\u5206\u7c7b\uff0c\u4f46\u7a7a\u95f4\u80fd\u529b\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u8f93\u5165\u683c\u5f0f\u3002\u672c\u6587\u4ece\u8ba4\u77e5\u89d2\u5ea6\u51fa\u53d1\uff0c\u65e8\u5728\u63d0\u4f9b\u66f4\u539f\u5219\u6027\u7684\u8de8\u4efb\u52a1\u6bd4\u8f83\uff0c\u63ed\u793a\u5f53\u524d\u6a21\u578b\u80fd\u529b\u4e0e\u4eba\u7c7b\u63a8\u7406\u4e4b\u95f4\u7684\u5173\u952e\u5dee\u8ddd\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u8ba4\u77e5\u89c6\u89d2\u7684\u5206\u7c7b\u6cd5\uff0c\u6309\u63a8\u7406\u590d\u6742\u5ea6\u5212\u5206\u4efb\u52a1\u5e76\u5173\u8054\u8ba4\u77e5\u529f\u80fd\uff1b\u5c06\u6587\u672c\u3001\u89c6\u89c9\u8bed\u8a00\u548c\u5177\u8eab\u73af\u5883\u4e0b\u7684\u73b0\u6709\u57fa\u51c6\u6620\u5c04\u5230\u8be5\u5206\u7c7b\u4e2d\uff1b\u5206\u6790\u8bc4\u4f30\u6307\u6807\u548c\u65b9\u6cd5\uff1b\u6bd4\u8f83\u8bad\u7ec3\u5f0f\u548c\u63a8\u7406\u5f0f\u63d0\u5347\u7a7a\u95f4\u80fd\u529b\u7684\u65b9\u6cd5\u3002", "result": "\u6784\u5efa\u4e86\u4ece\u8ba4\u77e5\u89d2\u5ea6\u7ec4\u7ec7\u7a7a\u95f4\u667a\u80fd\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u5b9e\u73b0\u4e86\u73b0\u6709\u57fa\u51c6\u7684\u6620\u5c04\u5206\u6790\uff0c\u660e\u786e\u4e86\u8bc4\u4f30\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u8bad\u7ec3\u5f0f\u548c\u63a8\u7406\u5f0f\u65b9\u6cd5\u7684\u4e92\u8865\u673a\u5236\u3002", "conclusion": "\u8ba4\u77e5\u89c6\u89d2\u4e3a\u7a7a\u95f4\u63a8\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u539f\u5219\u6027\u7684\u5206\u6790\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u65b0\u7814\u7a76\u8005\u5168\u9762\u7406\u89e3\u8be5\u9886\u57df\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u53ef\u884c\u65b9\u5411\u3002"}}
{"id": "2511.16169", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.16169", "abs": "https://arxiv.org/abs/2511.16169", "authors": ["Zijian Wang", "Xiaoyu Bao", "Chenhao Zhao", "Jihui Zhang", "Sizhi Ai", "Yuanqing Li"], "title": "UT-OSANet: A Multimodal Deep Learning model for Evaluating and Classifying Obstructive Sleep Apnea", "comment": "12 pages,8 figures", "summary": "Obstructive sleep apnea (OSA) is a highly prevalent sleep disorder that is associated with increased risks of cardiovascular morbidity and all-cause mortality. While existing diagnostic approaches can roughly classify OSA severity or detect isolated respiratory events, they lack the precision and comprehensiveness required for high resolution, event level diagnosis. Here, we present UT OSANet, a deep learning based model designed as a event level, multi scenario diagnostic tool for OSA. This model facilitates detailed identification of events associated with OSA, including apnea, hypopnea, oxygen desaturation, and arousal. Moreover, the model employs flexibly adjustable input modalities such as electroencephalography (EEG), airflow, and SpO 2. It utilizes a random masked modality combination training strategy, allowing it to comprehend cross-modal relationships while sustaining consistent performance across varying modality conditions. This model was trained and evaluated utilizing 9,021 polysomnography (PSG) recordings from five independent datasets. achieving sensitivities up to 0.93 and macro F1 scores of 0.84, 0.85 across home, clinical, and research scenarios. This model serves as an event-level, multi-scenario diagnostic instrument for real-world applications of OSA, while also establishing itself as a means to deepen the mechanistic comprehension of respiratory processes in sleep disorders and their extensive health implications.", "AI": {"tldr": "UT OSANet\u662f\u4e00\u4e2a\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u963b\u585e\u6027\u7761\u7720\u547c\u5438\u6682\u505c(OSA)\u4e8b\u4ef6\u7ea7\u8bca\u65ad\u6a21\u578b\uff0c\u652f\u6301\u591a\u6a21\u6001\u8f93\u5165\u548c\u591a\u79cd\u5e94\u7528\u573a\u666f\uff0c\u57289,021\u4e2a\u591a\u5bfc\u7761\u7720\u56fe\u8bb0\u5f55\u4e0a\u8bad\u7ec3\uff0c\u6027\u80fd\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709OSA\u8bca\u65ad\u65b9\u6cd5\u53ea\u80fd\u7c97\u7565\u5206\u7c7b\u4e25\u91cd\u7a0b\u5ea6\u6216\u68c0\u6d4b\u5b64\u7acb\u547c\u5438\u4e8b\u4ef6\uff0c\u7f3a\u4e4f\u9ad8\u5206\u8fa8\u7387\u7684\u4e8b\u4ef6\u7ea7\u8bca\u65ad\u7cbe\u5ea6\u548c\u5168\u9762\u6027\u3002", "method": "\u5f00\u53d1\u4e86UT OSANet\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u91c7\u7528\u968f\u673a\u63a9\u7801\u6a21\u6001\u7ec4\u5408\u8bad\u7ec3\u7b56\u7565\uff0c\u652f\u6301\u7075\u6d3b\u8c03\u6574\u7684\u8f93\u5165\u6a21\u6001(EEG\u3001\u6c14\u6d41\u3001SpO2)\uff0c\u80fd\u591f\u7406\u89e3\u8de8\u6a21\u6001\u5173\u7cfb\u5e76\u5728\u4e0d\u540c\u6a21\u6001\u6761\u4ef6\u4e0b\u4fdd\u6301\u7a33\u5b9a\u6027\u80fd\u3002", "result": "\u5728\u4e94\u4e2a\u72ec\u7acb\u6570\u636e\u96c6\u76849,021\u4e2aPSG\u8bb0\u5f55\u4e0a\u8bad\u7ec3\u8bc4\u4f30\uff0c\u5728\u5bb6\u5ead\u3001\u4e34\u5e8a\u548c\u7814\u7a76\u573a\u666f\u4e2d\u8fbe\u5230\u6700\u9ad80.93\u7684\u654f\u611f\u5ea6\u548c0.84\u30010.85\u7684\u5b8fF1\u5206\u6570\u3002", "conclusion": "\u8be5\u6a21\u578b\u53ef\u4f5c\u4e3aOSA\u4e8b\u4ef6\u7ea7\u3001\u591a\u573a\u666f\u8bca\u65ad\u5de5\u5177\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\uff0c\u540c\u65f6\u4e3a\u6df1\u5165\u7406\u89e3\u7761\u7720\u969c\u788d\u4e2d\u547c\u5438\u8fc7\u7a0b\u7684\u673a\u5236\u53ca\u5176\u5e7f\u6cdb\u5065\u5eb7\u5f71\u54cd\u63d0\u4f9b\u4e86\u624b\u6bb5\u3002"}}
{"id": "2511.16613", "categories": ["stat.ML", "cs.CC", "cs.DS", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.16613", "abs": "https://arxiv.org/abs/2511.16613", "authors": ["Jingqiu Ding", "Yiding Hua", "Kasper Lindberg", "David Steurer", "Aleksandr Storozhenko"], "title": "Rate-optimal community detection near the KS threshold via node-robust algorithms", "comment": null, "summary": "We study community detection in the \\emph{symmetric $k$-stochastic block model}, where $n$ nodes are evenly partitioned into $k$ clusters with intra- and inter-cluster connection probabilities $p$ and $q$, respectively.\n  Our main result is a polynomial-time algorithm that achieves the minimax-optimal misclassification rate\n  \\begin{equation*}\n  \\exp \\Bigl(-\\bigl(1 \\pm o(1)\\bigr) \\tfrac{C}{k}\\Bigr),\n  \\quad \\text{where } C = (\\sqrt{pn} - \\sqrt{qn})^2,\n  \\end{equation*}\n  whenever $C \\ge K\\,k^2\\,\\log k$ for some universal constant $K$, matching the Kesten--Stigum (KS) threshold up to a $\\log k$ factor.\n  Notably, this rate holds even when an adversary corrupts an $\u03b7\\le \\exp\\bigl(- (1 \\pm o(1)) \\tfrac{C}{k}\\bigr)$ fraction of the nodes.\n  To the best of our knowledge, the minimax rate was previously only attainable either via computationally inefficient procedures [ZZ15] or via polynomial-time algorithms that require strictly stronger assumptions such as $C \\ge K k^3$ [GMZZ17].\n  In the node-robust setting, the best known algorithm requires the substantially stronger condition $C \\ge K k^{102}$ [LM22].\n  Our results close this gap by providing the first polynomial-time algorithm that achieves the minimax rate near the KS threshold in both settings.\n  Our work has two key technical contributions:\n  (1) we robustify majority voting via the Sum-of-Squares framework,\n  (2) we develop a novel graph bisection algorithm via robust majority voting, which allows us to significantly improve the misclassification rate to $1/\\mathrm{poly}(k)$ for the initial estimation near the KS threshold.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u5728\u5bf9\u79f0k-\u968f\u673a\u5757\u6a21\u578b\u4e2d\u5b9e\u73b0\u4e86\u6700\u5c0f\u6700\u5927\u6700\u4f18\u7684\u8bef\u5206\u7c7b\u7387\uff0c\u8be5\u7b97\u6cd5\u5728Kesten-Stigum\u9608\u503c\u9644\u8fd1\u5de5\u4f5c\uff0c\u5e76\u4e14\u80fd\u591f\u62b5\u6297\u8282\u70b9\u635f\u574f\u653b\u51fb\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u8981\u4e48\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\uff0c\u8981\u4e48\u9700\u8981\u66f4\u5f3a\u7684\u5047\u8bbe\u6761\u4ef6\uff08\u5982C \u2265 Kk\u00b3\uff09\uff0c\u7279\u522b\u662f\u5728\u8282\u70b9\u9c81\u68d2\u6027\u8bbe\u7f6e\u4e2d\uff0c\u5df2\u77e5\u6700\u4f73\u7b97\u6cd5\u9700\u8981C \u2265 Kk\u00b9\u2070\u00b2\u7684\u5f3a\u6761\u4ef6\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u7ed3\u5408\u4e24\u4e2a\u5173\u952e\u6280\u672f\u8d21\u732e\uff1a(1) \u901a\u8fc7Sum-of-Squares\u6846\u67b6\u9c81\u68d2\u5316\u591a\u6570\u6295\u7968\uff1b(2) \u5f00\u53d1\u57fa\u4e8e\u9c81\u68d2\u591a\u6570\u6295\u7968\u7684\u65b0\u578b\u56fe\u4e8c\u5206\u7b97\u6cd5\uff0c\u663e\u8457\u6539\u5584\u4e86\u521d\u59cb\u4f30\u8ba1\u7684\u8bef\u5206\u7c7b\u7387\u3002", "result": "\u7b97\u6cd5\u5728C \u2265 Kk\u00b2logk\u7684\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u6700\u5c0f\u6700\u5927\u6700\u4f18\u8bef\u5206\u7c7b\u7387exp(-(1\u00b1o(1))C/k)\uff0c\u5373\u4f7f\u5f53\u5bf9\u624b\u635f\u574f\u03b7 \u2264 exp(-(1\u00b1o(1))C/k)\u6bd4\u4f8b\u7684\u8282\u70b9\u65f6\u4ecd\u7136\u6709\u6548\u3002", "conclusion": "\u8fd9\u662f\u7b2c\u4e00\u4e2a\u5728Kesten-Stigum\u9608\u503c\u9644\u8fd1\u5b9e\u73b0\u6700\u5c0f\u6700\u5927\u6700\u4f18\u8bef\u5206\u7c7b\u7387\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u540c\u65f6\u5728\u6807\u51c6\u8bbe\u7f6e\u548c\u8282\u70b9\u9c81\u68d2\u8bbe\u7f6e\u4e2d\u90fd\u6709\u6548\uff0c\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002"}}
{"id": "2511.16340", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.16340", "abs": "https://arxiv.org/abs/2511.16340", "authors": ["Alan Yufei Dong", "Jihao Andreas Lin", "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"], "title": "Improving Iterative Gaussian Processes via Warm Starting Sequential Posteriors", "comment": null, "summary": "Scalable Gaussian process (GP) inference is essential for sequential decision-making tasks, yet improving GP scalability remains a challenging problem with many open avenues of research. This paper focuses on iterative GPs, where iterative linear solvers, such as conjugate gradients, stochastic gradient descent or alternative projections, are used to approximate the GP posterior. We propose a new method which improves solver convergence of a large linear system by leveraging the known solution to a smaller system contained within. This is significant for tasks with incremental data additions, and we show that our technique achieves speed-ups when solving to tolerance, as well as improved Bayesian optimisation performance under a fixed compute budget.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u9ad8\u65af\u8fc7\u7a0b\u53ef\u6269\u5c55\u6027\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u5c0f\u7ebf\u6027\u7cfb\u7edf\u7684\u5df2\u77e5\u89e3\u6765\u52a0\u901f\u5927\u7ebf\u6027\u7cfb\u7edf\u7684\u6c42\u89e3\u5668\u6536\u655b\uff0c\u7279\u522b\u9002\u7528\u4e8e\u589e\u91cf\u6570\u636e\u6dfb\u52a0\u4efb\u52a1\u3002", "motivation": "\u9ad8\u65af\u8fc7\u7a0b\u63a8\u7406\u7684\u53ef\u6269\u5c55\u6027\u5bf9\u4e8e\u5e8f\u5217\u51b3\u7b56\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6539\u8fdb\u9ad8\u65af\u8fc7\u7a0b\u53ef\u6269\u5c55\u6027\u4ecd\u7136\u662f\u4e00\u4e2a\u5177\u6709\u8bb8\u591a\u5f00\u653e\u7814\u7a76\u65b9\u5411\u7684\u6311\u6218\u6027\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u8fed\u4ee3\u7ebf\u6027\u6c42\u89e3\u5668\uff08\u5982\u5171\u8f6d\u68af\u5ea6\u3001\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6216\u4ea4\u66ff\u6295\u5f71\uff09\u6765\u8fd1\u4f3c\u9ad8\u65af\u8fc7\u7a0b\u540e\u9a8c\uff0c\u901a\u8fc7\u5229\u7528\u5305\u542b\u5728\u5176\u4e2d\u7684\u8f83\u5c0f\u7cfb\u7edf\u7684\u5df2\u77e5\u89e3\u6765\u6539\u8fdb\u5927\u7ebf\u6027\u7cfb\u7edf\u7684\u6c42\u89e3\u5668\u6536\u655b\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5bb9\u5dee\u6c42\u89e3\u65f6\u5b9e\u73b0\u4e86\u52a0\u901f\uff0c\u5e76\u5728\u56fa\u5b9a\u8ba1\u7b97\u9884\u7b97\u4e0b\u6539\u5584\u4e86\u8d1d\u53f6\u65af\u4f18\u5316\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6280\u672f\u5bf9\u4e8e\u589e\u91cf\u6570\u636e\u6dfb\u52a0\u4efb\u52a1\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u9ad8\u65af\u8fc7\u7a0b\u63a8\u7406\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2511.15847", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.15847", "abs": "https://arxiv.org/abs/2511.15847", "authors": ["Alexander Bakumenko", "Janine Hoelscher", "Hudson Smith"], "title": "Transparent Early ICU Mortality Prediction with Clinical Transformer and Per-Case Modality Attribution", "comment": null, "summary": "Early identification of intensive care patients at risk of in-hospital mortality enables timely intervention and efficient resource allocation. Despite high predictive performance, existing machine learning approaches lack transparency and robustness, limiting clinical adoption. We present a lightweight, transparent multimodal ensemble that fuses physiological time-series measurements with unstructured clinical notes from the first 48 hours of an ICU stay. A logistic regression model combines predictions from two modality-specific models: a bidirectional LSTM for vitals and a finetuned ClinicalModernBERT transformer for notes. This traceable architecture allows for multilevel interpretability: feature attributions within each modality and direct per-case modality attributions quantifying how vitals and notes influence each decision. On the MIMIC-III benchmark, our late-fusion ensemble improves discrimination over the best single model (AUPRC 0.565 vs. 0.526; AUROC 0.891 vs. 0.876) while maintaining well-calibrated predictions. The system remains robust through a calibrated fallback when a modality is missing. These results demonstrate competitive performance with reliable, auditable risk estimates and transparent, predictable operation, which together are crucial for clinical use.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u900f\u660e\u7684\u591a\u6a21\u6001\u96c6\u6210\u65b9\u6cd5\uff0c\u7ed3\u5408ICU\u60a3\u8005\u524d48\u5c0f\u65f6\u7684\u751f\u7406\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u548c\u4e34\u5e8a\u7b14\u8bb0\uff0c\u901a\u8fc7\u903b\u8f91\u56de\u5f52\u878d\u5408\u53cc\u5411LSTM\u548cClinicalModernBERT\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u5b9e\u73b0\u591a\u7ea7\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u867d\u7136\u9884\u6d4b\u6027\u80fd\u9ad8\uff0c\u4f46\u7f3a\u4e4f\u900f\u660e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u9650\u5236\u4e86\u4e34\u5e8a\u91c7\u7528\u3002\u9700\u8981\u5f00\u53d1\u65e2\u51c6\u786e\u53c8\u53ef\u89e3\u91ca\u7684ICU\u6b7b\u4ea1\u7387\u9884\u6d4b\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u903b\u8f91\u56de\u5f52\u6a21\u578b\u878d\u5408\u4e24\u4e2a\u6a21\u6001\u7279\u5b9a\u6a21\u578b\u7684\u9884\u6d4b\uff1a\u53cc\u5411LSTM\u5904\u7406\u751f\u547d\u4f53\u5f81\u6570\u636e\uff0c\u5fae\u8c03\u7684ClinicalModernBERT\u5904\u7406\u4e34\u5e8a\u7b14\u8bb0\u3002\u91c7\u7528\u53ef\u8ffd\u6eaf\u67b6\u6784\u5b9e\u73b0\u591a\u7ea7\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5728MIMIC-III\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u665a\u671f\u878d\u5408\u96c6\u6210\u6bd4\u6700\u4f73\u5355\u4e00\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff08AUPRC 0.565 vs. 0.526\uff1bAUROC 0.891 vs. 0.876\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u597d\u6821\u51c6\u7684\u9884\u6d4b\u3002\u7cfb\u7edf\u5728\u6a21\u6001\u7f3a\u5931\u65f6\u4ecd\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u63d0\u4f9b\u53ef\u9760\u3001\u53ef\u5ba1\u8ba1\u7684\u98ce\u9669\u4f30\u8ba1\u548c\u900f\u660e\u3001\u53ef\u9884\u6d4b\u7684\u64cd\u4f5c\uff0c\u8fd9\u5bf9\u4e34\u5e8a\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2511.16377", "categories": ["cs.LG", "cs.CR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.16377", "abs": "https://arxiv.org/abs/2511.16377", "authors": ["Hrad Ghoukasian", "Shahab Asoodeh"], "title": "Optimal Fairness under Local Differential Privacy", "comment": "21 pages, 6 figures, 2 tables", "summary": "We investigate how to optimally design local differential privacy (LDP) mechanisms that reduce data unfairness and thereby improve fairness in downstream classification. We first derive a closed-form optimal mechanism for binary sensitive attributes and then develop a tractable optimization framework that yields the corresponding optimal mechanism for multi-valued attributes. As a theoretical contribution, we establish that for discrimination-accuracy optimal classifiers, reducing data unfairness necessarily leads to lower classification unfairness, thus providing a direct link between privacy-aware pre-processing and classification fairness. Empirically, we demonstrate that our approach consistently outperforms existing LDP mechanisms in reducing data unfairness across diverse datasets and fairness metrics, while maintaining accuracy close to that of non-private models. Moreover, compared with leading pre-processing and post-processing fairness methods, our mechanism achieves a more favorable accuracy-fairness trade-off while simultaneously preserving the privacy of sensitive attributes. Taken together, these results highlight LDP as a principled and effective pre-processing fairness intervention technique.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5982\u4f55\u8bbe\u8ba1\u6700\u4f18\u7684\u672c\u5730\u5dee\u5206\u9690\u79c1\u673a\u5236\u6765\u51cf\u5c11\u6570\u636e\u4e0d\u516c\u5e73\u6027\uff0c\u4ece\u800c\u6539\u5584\u4e0b\u6e38\u5206\u7c7b\u7684\u516c\u5e73\u6027\u3002\u63d0\u51fa\u4e86\u9488\u5bf9\u4e8c\u5143\u548c\u591a\u503c\u654f\u611f\u5c5e\u6027\u7684\u4f18\u5316\u673a\u5236\uff0c\u5e76\u8bc1\u660e\u4e86\u51cf\u5c11\u6570\u636e\u4e0d\u516c\u5e73\u6027\u5fc5\u7136\u964d\u4f4e\u5206\u7c7b\u4e0d\u516c\u5e73\u6027\u3002", "motivation": "\u5f53\u524d\u672c\u5730\u5dee\u5206\u9690\u79c1\u673a\u5236\u5728\u4fdd\u62a4\u654f\u611f\u5c5e\u6027\u9690\u79c1\u7684\u540c\u65f6\uff0c\u53ef\u80fd\u52a0\u5267\u6570\u636e\u4e0d\u516c\u5e73\u6027\uff0c\u5f71\u54cd\u4e0b\u6e38\u5206\u7c7b\u7684\u516c\u5e73\u6027\u3002\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u4fdd\u62a4\u9690\u79c1\u53c8\u80fd\u6539\u5584\u516c\u5e73\u6027\u7684\u673a\u5236\u3002", "method": "\u9996\u5148\u63a8\u5bfc\u4e86\u4e8c\u5143\u654f\u611f\u5c5e\u6027\u7684\u95ed\u5f0f\u6700\u4f18\u673a\u5236\uff0c\u7136\u540e\u5f00\u53d1\u4e86\u53ef\u5904\u7406\u7684\u4f18\u5316\u6846\u67b6\u6765\u5904\u7406\u591a\u503c\u5c5e\u6027\u3002\u5efa\u7acb\u4e86\u9690\u79c1\u611f\u77e5\u9884\u5904\u7406\u4e0e\u5206\u7c7b\u516c\u5e73\u6027\u4e4b\u95f4\u7684\u7406\u8bba\u8054\u7cfb\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u6570\u636e\u96c6\u548c\u516c\u5e73\u6027\u6307\u6807\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709LDP\u673a\u5236\uff0c\u5728\u51cf\u5c11\u6570\u636e\u4e0d\u516c\u5e73\u6027\u7684\u540c\u65f6\u4fdd\u6301\u63a5\u8fd1\u975e\u79c1\u6709\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002\u76f8\u6bd4\u9886\u5148\u7684\u9884\u5904\u7406\u548c\u540e\u5904\u7406\u516c\u5e73\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u51c6\u786e\u6027-\u516c\u5e73\u6027\u6743\u8861\u3002", "conclusion": "\u672c\u5730\u5dee\u5206\u9690\u79c1\u662f\u4e00\u79cd\u539f\u5219\u6027\u4e14\u6709\u6548\u7684\u9884\u5904\u7406\u516c\u5e73\u5e72\u9884\u6280\u672f\uff0c\u80fd\u591f\u5728\u4fdd\u62a4\u654f\u611f\u5c5e\u6027\u9690\u79c1\u7684\u540c\u65f6\u663e\u8457\u6539\u5584\u5206\u7c7b\u516c\u5e73\u6027\u3002"}}
{"id": "2511.15763", "categories": ["cs.AI", "cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15763", "abs": "https://arxiv.org/abs/2511.15763", "authors": ["Raymond K. Sheh", "Karen Geappen"], "title": "Identifying the Supply Chain of AI for Trustworthiness and Risk Management in Critical Applications", "comment": "Presented at the 2025 AAAI Fall Symposium - AI Trustworthiness and Risk Assessment for Challenged Contexts (ATRACC)", "summary": "Risks associated with the use of AI, ranging from algorithmic bias to model hallucinations, have received much attention and extensive research across the AI community, from researchers to end-users. However, a gap exists in the systematic assessment of supply chain risks associated with the complex web of data sources, pre-trained models, agents, services, and other systems that contribute to the output of modern AI systems. This gap is particularly problematic when AI systems are used in critical applications, such as the food supply, healthcare, utilities, law, insurance, and transport.\n  We survey the current state of AI risk assessment and management, with a focus on the supply chain of AI and risks relating to the behavior and outputs of the AI system. We then present a proposed taxonomy specifically for categorizing AI supply chain entities. This taxonomy helps stakeholders, especially those without extensive AI expertise, to \"consider the right questions\" and systematically inventory dependencies across their organization's AI systems. Our contribution bridges a gap between the current state of AI governance and the urgent need for actionable risk assessment and management of AI use in critical applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cdAI\u4f9b\u5e94\u94fe\u98ce\u9669\u5206\u7c7b\u6cd5\uff0c\u586b\u8865\u4e86\u5f53\u524dAI\u98ce\u9669\u8bc4\u4f30\u5728\u4f9b\u5e94\u94fe\u73af\u8282\u7684\u7a7a\u767d\uff0c\u5e2e\u52a9\u975e\u6280\u672f\u80cc\u666f\u7684\u5229\u76ca\u76f8\u5173\u8005\u7cfb\u7edf\u8bc6\u522bAI\u7cfb\u7edf\u4f9d\u8d56\u5173\u7cfb\u3002", "motivation": "\u5f53\u524dAI\u98ce\u9669\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u7b97\u6cd5\u504f\u89c1\u548c\u6a21\u578b\u5e7b\u89c9\u7b49\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u5bf9AI\u4f9b\u5e94\u94fe\uff08\u6570\u636e\u6e90\u3001\u9884\u8bad\u7ec3\u6a21\u578b\u3001\u670d\u52a1\u7b49\uff09\u7684\u7cfb\u7edf\u98ce\u9669\u8bc4\u4f30\uff0c\u8fd9\u5728\u5173\u952e\u5e94\u7528\u4e2d\u5c24\u4e3a\u5371\u9669\u3002", "method": "\u8c03\u7814\u5f53\u524dAI\u98ce\u9669\u8bc4\u4f30\u548c\u7ba1\u7406\u73b0\u72b6\uff0c\u91cd\u70b9\u5173\u6ce8AI\u4f9b\u5e94\u94fe\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u4e13\u95e8\u7528\u4e8e\u5206\u7c7bAI\u4f9b\u5e94\u94fe\u5b9e\u4f53\u7684\u5206\u7c7b\u6cd5\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2aAI\u4f9b\u5e94\u94fe\u5b9e\u4f53\u5206\u7c7b\u6cd5\uff0c\u5e2e\u52a9\u5229\u76ca\u76f8\u5173\u8005\u7cfb\u7edf\u6027\u5730\u8bc6\u522b\u548c\u76d8\u70b9\u7ec4\u7ec7AI\u7cfb\u7edf\u7684\u4f9d\u8d56\u5173\u7cfb\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u5f53\u524dAI\u6cbb\u7406\u4e0e\u5173\u952e\u5e94\u7528\u4e2dAI\u4f7f\u7528\u98ce\u9669\u8bc4\u4f30\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u98ce\u9669\u8bc4\u4f30\u548c\u7ba1\u7406\u65b9\u6cd5\u3002"}}
{"id": "2511.15778", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15778", "abs": "https://arxiv.org/abs/2511.15778", "authors": ["Paulina Tworek", "Mi\u0142osz Bargie\u0142", "Yousef Khan", "Tomasz Pe\u0142ech-Pilichowski", "Marek Miko\u0142ajczyk", "Roman Lewandowski", "Jose Sousa"], "title": "Balancing Natural Language Processing Accuracy and Normalisation in Extracting Medical Insights", "comment": "20 pages, 5 figures", "summary": "Extracting structured medical insights from unstructured clinical text using Natural Language Processing (NLP) remains an open challenge in healthcare, particularly in non-English contexts where resources are scarce. This study presents a comparative analysis of NLP low-compute rule-based methods and Large Language Models (LLMs) for information extraction from electronic health records (EHR) obtained from the Voivodeship Rehabilitation Hospital for Children in Ameryka, Poland. We evaluate both approaches by extracting patient demographics, clinical findings, and prescribed medications while examining the effects of lack of text normalisation and translation-induced information loss. Results demonstrate that rule-based methods provide higher accuracy in information retrieval tasks, particularly for age and sex extraction. However, LLMs offer greater adaptability and scalability, excelling in drug name recognition. The effectiveness of the LLMs was compared with texts originally in Polish and those translated into English, assessing the impact of translation. These findings highlight the trade-offs between accuracy, normalisation, and computational cost when deploying NLP in healthcare settings. We argue for hybrid approaches that combine the precision of rule-based systems with the adaptability of LLMs, offering a practical path toward more reliable and resource-efficient clinical NLP in real-world hospitals.", "AI": {"tldr": "\u6bd4\u8f83\u57fa\u4e8e\u89c4\u5219\u7684NLP\u65b9\u6cd5\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ece\u6ce2\u5170\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u63d0\u53d6\u533b\u7597\u4fe1\u606f\u7684\u6027\u80fd\uff0c\u5206\u6790\u6587\u672c\u6807\u51c6\u5316\u548c\u7ffb\u8bd1\u5bf9\u4fe1\u606f\u63d0\u53d6\u7684\u5f71\u54cd\u3002", "motivation": "\u89e3\u51b3\u975e\u82f1\u8bed\u73af\u5883\u4e0b\u4ece\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u6587\u672c\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u533b\u7597\u4fe1\u606f\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u4f4e\u8ba1\u7b97NLP\u65b9\u6cd5\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u6ce2\u5170\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u63d0\u53d6\u60a3\u8005\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u3001\u4e34\u5e8a\u53d1\u73b0\u548c\u5904\u65b9\u836f\u7269\uff0c\u8bc4\u4f30\u6587\u672c\u6807\u51c6\u5316\u7f3a\u5931\u548c\u7ffb\u8bd1\u5bfc\u81f4\u7684\u4fe1\u606f\u635f\u5931\u5f71\u54cd\u3002", "result": "\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u5728\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u4e2d\u51c6\u786e\u7387\u66f4\u9ad8\uff0c\u7279\u522b\u662f\u5728\u5e74\u9f84\u548c\u6027\u522b\u63d0\u53d6\u65b9\u9762\uff1b\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u836f\u7269\u540d\u79f0\u8bc6\u522b\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u5177\u6709\u66f4\u5f3a\u7684\u9002\u5e94\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u5efa\u8bae\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u57fa\u4e8e\u89c4\u5219\u7cfb\u7edf\u7684\u7cbe\u786e\u6027\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9002\u5e94\u6027\uff0c\u4e3a\u73b0\u5b9e\u533b\u9662\u73af\u5883\u63d0\u4f9b\u66f4\u53ef\u9760\u548c\u8d44\u6e90\u9ad8\u6548\u7684\u4e34\u5e8aNLP\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.16575", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.16575", "abs": "https://arxiv.org/abs/2511.16575", "authors": ["Fares Fourati", "Mohamed-Slim Alouini", "Vaneet Aggarwal"], "title": "ECPv2: Fast, Efficient, and Scalable Global Optimization of Lipschitz Functions", "comment": "Accepted at AAAI 2026 (main technical track), extended version", "summary": "We propose ECPv2, a scalable and theoretically grounded algorithm for global optimization of Lipschitz-continuous functions with unknown Lipschitz constants. Building on the Every Call is Precious (ECP) framework, which ensures that each accepted function evaluation is potentially informative, ECPv2 addresses key limitations of ECP, including high computational cost and overly conservative early behavior. ECPv2 introduces three innovations: (i) an adaptive lower bound to avoid vacuous acceptance regions, (ii) a Worst-m memory mechanism that restricts comparisons to a fixed-size subset of past evaluations, and (iii) a fixed random projection to accelerate distance computations in high dimensions. We theoretically show that ECPv2 retains ECP's no-regret guarantees with optimal finite-time bounds and expands the acceptance region with high probability. We further empirically validate these findings through extensive experiments and ablation studies. Using principled hyperparameter settings, we evaluate ECPv2 across a wide range of high-dimensional, non-convex optimization problems. Across benchmarks, ECPv2 consistently matches or outperforms state-of-the-art optimizers, while significantly reducing wall-clock time.", "AI": {"tldr": "ECPv2\u662f\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u5168\u5c40\u4f18\u5316\u7b97\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316Lipschitz\u8fde\u7eed\u51fd\u6570\uff0c\u89e3\u51b3\u4e86ECP\u7b97\u6cd5\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u4fdd\u5b88\u884c\u4e3a\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u4e0b\u754c\u3001Worst-m\u8bb0\u5fc6\u673a\u5236\u548c\u56fa\u5b9a\u968f\u673a\u6295\u5f71\u7b49\u521b\u65b0\uff0c\u5728\u4fdd\u6301\u7406\u8bba\u4fdd\u8bc1\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3ECP\u7b97\u6cd5\u5728\u5168\u5c40\u4f18\u5316\u4e2d\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u3001\u65e9\u671f\u884c\u4e3a\u8fc7\u4e8e\u4fdd\u5b88\u4ee5\u53ca\u672a\u77e5Lipschitz\u5e38\u6570\u7b49\u5173\u952e\u9650\u5236\uff0c\u5f00\u53d1\u4e86ECPv2\u7b97\u6cd5\u3002", "method": "ECPv2\u5f15\u5165\u4e86\u4e09\u4e2a\u521b\u65b0\uff1a(1)\u81ea\u9002\u5e94\u4e0b\u754c\u907f\u514d\u65e0\u6548\u63a5\u53d7\u533a\u57df\uff1b(2)Worst-m\u8bb0\u5fc6\u673a\u5236\u9650\u5236\u4e0e\u56fa\u5b9a\u5927\u5c0f\u5386\u53f2\u8bc4\u4f30\u5b50\u96c6\u7684\u6bd4\u8f83\uff1b(3)\u56fa\u5b9a\u968f\u673a\u6295\u5f71\u52a0\u901f\u9ad8\u7ef4\u8ddd\u79bb\u8ba1\u7b97\u3002", "result": "\u7406\u8bba\u8bc1\u660eECPv2\u4fdd\u6301ECP\u7684\u65e0\u6094\u4fdd\u8bc1\u548c\u6700\u4f18\u6709\u9650\u65f6\u95f4\u754c\u9650\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5728\u5e7f\u6cdb\u7684\u9ad8\u7ef4\u975e\u51f8\u4f18\u5316\u95ee\u9898\u4e2d\uff0cECPv2\u59cb\u7ec8\u5339\u914d\u6216\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u4f18\u5316\u5668\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8fd0\u884c\u65f6\u95f4\u3002", "conclusion": "ECPv2\u662f\u4e00\u4e2a\u7406\u8bba\u4e0a\u6709\u4fdd\u8bc1\u4e14\u5b9e\u7528\u7684\u5168\u5c40\u4f18\u5316\u7b97\u6cd5\uff0c\u901a\u8fc7\u5173\u952e\u521b\u65b0\u89e3\u51b3\u4e86ECP\u7684\u5c40\u9650\u6027\uff0c\u5728\u4fdd\u6301\u7406\u8bba\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2511.15830", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15830", "abs": "https://arxiv.org/abs/2511.15830", "authors": ["St\u00e9phane Aroca-Ouellette", "Ian Berlot-Attwell", "Panagiotis Lymperopoulos", "Abhiramon Rajasekharan", "Tongqi Zhu", "Herin Kang", "Kaheer Suleman", "Sam Pasupalak"], "title": "Mini Amusement Parks (MAPs): A Testbed for Modelling Business Decisions", "comment": "8 pages (main paper)", "summary": "Despite rapid progress in artificial intelligence, current systems struggle with the interconnected challenges that define real-world decision making. Practical domains, such as business management, require optimizing an open-ended and multi-faceted objective, actively learning environment dynamics from sparse experience, planning over long horizons in stochastic settings, and reasoning over spatial information. Yet existing human--AI benchmarks isolate subsets of these capabilities, limiting our ability to assess holistic decision-making competence. We introduce Mini Amusement Parks (MAPs), an amusement-park simulator designed to evaluate an agent's ability to model its environment, anticipate long-term consequences under uncertainty, and strategically operate a complex business. We provide human baselines and a comprehensive evaluation of state-of-the-art LLM agents, finding that humans outperform these systems by 6.5x on easy mode and 9.8x on medium mode. Our analysis reveals persistent weaknesses in long-horizon optimization, sample-efficient learning, spatial reasoning, and world modelling. By unifying these challenges within a single environment, MAPs offers a new foundation for benchmarking agents capable of adaptable decision making. Code: https://github.com/Skyfall-Research/MAPs", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86Mini Amusement Parks (MAPs)\u6a21\u62df\u5668\uff0c\u7528\u4e8e\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u590d\u6742\u5546\u4e1a\u73af\u5883\u4e2d\u7684\u51b3\u7b56\u80fd\u529b\uff0c\u53d1\u73b0\u4eba\u7c7b\u8868\u73b0\u8fdc\u8d85\u73b0\u6709LLM\u667a\u80fd\u4f53\u3002", "motivation": "\u73b0\u6709AI\u7cfb\u7edf\u5728\u73b0\u5b9e\u4e16\u754c\u51b3\u7b56\u4e2d\u9762\u4e34\u6311\u6218\uff0c\u4f46\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u5b64\u7acb\u8bc4\u4f30\u5404\u9879\u80fd\u529b\uff0c\u65e0\u6cd5\u5168\u9762\u8bc4\u4f30\u6574\u4f53\u51b3\u7b56\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u4e86MAPs\u6e38\u4e50\u56ed\u6a21\u62df\u5668\uff0c\u7edf\u4e00\u8bc4\u4f30\u73af\u5883\u5efa\u6a21\u3001\u957f\u671f\u89c4\u5212\u3001\u7a7a\u95f4\u63a8\u7406\u7b49\u80fd\u529b\uff0c\u5e76\u63d0\u4f9b\u4eba\u7c7b\u57fa\u51c6\u548c\u6700\u65b0LLM\u667a\u80fd\u4f53\u7684\u5168\u9762\u8bc4\u4f30\u3002", "result": "\u4eba\u7c7b\u5728\u7b80\u5355\u6a21\u5f0f\u4e0b\u8868\u73b0\u4f18\u4e8eAI\u7cfb\u7edf6.5\u500d\uff0c\u4e2d\u7b49\u6a21\u5f0f\u4e0b\u4f18\u4e8e9.8\u500d\uff0c\u63ed\u793a\u4e86AI\u5728\u957f\u671f\u4f18\u5316\u3001\u6837\u672c\u6548\u7387\u5b66\u4e60\u7b49\u65b9\u9762\u7684\u6301\u7eed\u5f31\u70b9\u3002", "conclusion": "MAPs\u4e3a\u8bc4\u4f30\u9002\u5e94\u6027\u51b3\u7b56\u80fd\u529b\u7684\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u65b0\u7684\u57fa\u51c6\u57fa\u7840\uff0c\u7edf\u4e00\u4e86\u73b0\u5b9e\u51b3\u7b56\u4e2d\u7684\u591a\u79cd\u6311\u6218\u3002"}}
{"id": "2511.16472", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.16472", "abs": "https://arxiv.org/abs/2511.16472", "authors": ["Niko Lindvall", "Mikko Heino", "Mikko Valkama"], "title": "3-20 GHz Wideband Tightly-Coupled Dual-Polarized Vivaldi Antenna Array", "comment": null, "summary": "Very wideband apertures are needed in positioning, sensing, spectrum monitoring, and modern spread spectrum, e.g., frequency hopping systems. Vivaldi antennas are one of the prominent choices for the aforementioned systems due to their natural wideband characteristics. Furthermore, tightly-coupled antenna arrays have been researched in the recent years to extend the lower band edge of compact arrays by taking advantage of the strong mutual coupling between the elements especially with dipole elements, but not with dual-polarized Vivaldi antennas. This paper presents a novel tightly-coupled dual-polarized antipodal Vivaldi antenna (TC-AVA) with -6 dB impedance bandwidth of 3 to 20 GHz. The tight coupling by overlapping the Vivaldi leaves is shown to extend the lower band edge from 3.75 to 3 GHz and 2.75 GHz, an improvement of 20% to 25% for both polarizations, compared with an isolated antipodal Vivaldi element.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7d27\u5bc6\u8026\u5408\u53cc\u6781\u5316\u5bf9\u8dd6\u7ef4\u74e6\u5c14\u7b2c\u5929\u7ebf\uff0c\u901a\u8fc7\u91cd\u53e0\u7ef4\u74e6\u5c14\u7b2c\u53f6\u7247\u5b9e\u73b0\u7d27\u5bc6\u8026\u5408\uff0c\u5c06-6dB\u963b\u6297\u5e26\u5bbd\u6269\u5c55\u52303-20GHz\uff0c\u76f8\u6bd4\u5b64\u7acb\u5929\u7ebf\u5c06\u4e0b\u8fb9\u5e26\u4ece3.75GHz\u6269\u5c55\u52303GHz\u548c2.75GHz\uff0c\u6539\u8fdb\u5e45\u5ea6\u8fbe20-25%\u3002", "motivation": "\u5728\u5b9a\u4f4d\u3001\u4f20\u611f\u3001\u9891\u8c31\u76d1\u6d4b\u548c\u73b0\u4ee3\u6269\u9891\u7cfb\u7edf\uff08\u5982\u8df3\u9891\u7cfb\u7edf\uff09\u4e2d\u9700\u8981\u975e\u5e38\u5bbd\u5e26\u7684\u5b54\u5f84\u3002\u7ef4\u74e6\u5c14\u7b2c\u5929\u7ebf\u56e0\u5176\u5929\u7136\u7684\u5bbd\u5e26\u7279\u6027\u6210\u4e3a\u8fd9\u4e9b\u7cfb\u7edf\u7684\u7a81\u51fa\u9009\u62e9\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u5076\u6781\u5b50\u5143\u4ef6\u7684\u7d27\u5bc6\u8026\u5408\u9635\u5217\uff0c\u5c1a\u672a\u6d89\u53ca\u53cc\u6781\u5316\u7ef4\u74e6\u5c14\u7b2c\u5929\u7ebf\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7d27\u5bc6\u8026\u5408\u53cc\u6781\u5316\u5bf9\u8dd6\u7ef4\u74e6\u5c14\u7b2c\u5929\u7ebf\uff0c\u901a\u8fc7\u91cd\u53e0\u7ef4\u74e6\u5c14\u7b2c\u53f6\u7247\u5b9e\u73b0\u5143\u4ef6\u95f4\u7684\u7d27\u5bc6\u8026\u5408\uff0c\u4ece\u800c\u6269\u5c55\u5929\u7ebf\u7684\u4f4e\u9891\u6027\u80fd\u3002", "result": "\u8be5\u5929\u7ebf\u5b9e\u73b0\u4e863-20GHz\u7684-6dB\u963b\u6297\u5e26\u5bbd\uff0c\u76f8\u6bd4\u5b64\u7acb\u7ef4\u74e6\u5c14\u7b2c\u5929\u7ebf\u5143\u4ef6\uff0c\u5c06\u4e0b\u8fb9\u5e26\u4ece3.75GHz\u6269\u5c55\u52303GHz\u548c2.75GHz\uff0c\u5bf9\u4e24\u79cd\u6781\u5316\u5206\u522b\u5b9e\u73b0\u4e8620%\u548c25%\u7684\u6539\u8fdb\u3002", "conclusion": "\u7d27\u5bc6\u8026\u5408\u6280\u672f\u53ef\u6709\u6548\u6269\u5c55\u53cc\u6781\u5316\u7ef4\u74e6\u5c14\u7b2c\u5929\u7ebf\u7684\u4f4e\u9891\u6027\u80fd\uff0c\u4e3a\u5bbd\u5e26\u5929\u7ebf\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u8bbe\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2511.15895", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15895", "abs": "https://arxiv.org/abs/2511.15895", "authors": ["Ivan Chulo", "Ananya Joshi"], "title": "Decomposing Theory of Mind: How Emotional Processing Mediates ToM Abilities in LLMs", "comment": "Published at ToM4AI workshop@AAAI2026", "summary": "Recent work shows activation steering substantially improves language models' Theory of Mind (ToM) (Bortoletto et al. 2024), yet the mechanisms of what changes occur internally that leads to different outputs remains unclear. We propose decomposing ToM in LLMs by comparing steered versus baseline LLMs' activations using linear probes trained on 45 cognitive actions. We applied Contrastive Activation Addition (CAA) steering to Gemma-3-4B and evaluated it on 1,000 BigToM forward belief scenarios (Gandhi et al. 2023), we find improved performance on belief attribution tasks (32.5\\% to 46.7\\% accuracy) is mediated by activations processing emotional content : emotion perception (+2.23), emotion valuing (+2.20), while suppressing analytical processes: questioning (-0.78), convergent thinking (-1.59). This suggests that successful ToM abilities in LLMs are mediated by emotional understanding, not analytical reasoning.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5bf9\u6bd4\u6fc0\u6d3b\u5f15\u5bfc\u4e0e\u57fa\u7ebfLLMs\u7684\u6fc0\u6d3b\uff0c\u4f7f\u7528\u7ebf\u6027\u63a2\u9488\u5206\u679045\u79cd\u8ba4\u77e5\u884c\u4e3a\uff0c\u53d1\u73b0\u60c5\u611f\u7406\u89e3\u800c\u975e\u5206\u6790\u63a8\u7406\u662fLLMs\u6210\u529f\u5fc3\u667a\u7406\u8bba\u80fd\u529b\u7684\u5173\u952e\u673a\u5236\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8868\u660e\u6fc0\u6d3b\u5f15\u5bfc\u80fd\u663e\u8457\u6539\u5584\u8bed\u8a00\u6a21\u578b\u7684\u5fc3\u667a\u7406\u8bba\u80fd\u529b\uff0c\u4f46\u5176\u5185\u90e8\u673a\u5236\u5bfc\u81f4\u4e0d\u540c\u8f93\u51fa\u7684\u5177\u4f53\u53d8\u5316\u4ecd\u4e0d\u6e05\u695a\u3002", "method": "\u5e94\u7528\u5bf9\u6bd4\u6fc0\u6d3b\u52a0\u6cd5\u5f15\u5bfcGemma-3-4B\u6a21\u578b\uff0c\u57281000\u4e2aBigToM\u524d\u5411\u4fe1\u5ff5\u573a\u666f\u4e0a\u8bc4\u4f30\uff0c\u4f7f\u7528\u7ebf\u6027\u63a2\u9488\u5206\u679045\u79cd\u8ba4\u77e5\u884c\u4e3a\u3002", "result": "\u4fe1\u5ff5\u5f52\u56e0\u4efb\u52a1\u51c6\u786e\u7387\u4ece32.5%\u63d0\u5347\u81f346.7%\uff0c\u8fd9\u79cd\u6539\u5584\u7531\u60c5\u611f\u5185\u5bb9\u5904\u7406\uff08\u60c5\u611f\u611f\u77e5+2.23\uff0c\u60c5\u611f\u8bc4\u4ef7+2.20\uff09\u4ecb\u5bfc\uff0c\u540c\u65f6\u6291\u5236\u5206\u6790\u8fc7\u7a0b\uff08\u8d28\u7591-0.78\uff0c\u6536\u655b\u601d\u7ef4-1.59\uff09\u3002", "conclusion": "LLMs\u4e2d\u6210\u529f\u7684\u5fc3\u667a\u7406\u8bba\u80fd\u529b\u7531\u60c5\u611f\u7406\u89e3\u4ecb\u5bfc\uff0c\u800c\u975e\u5206\u6790\u63a8\u7406\u3002"}}
{"id": "2511.15958", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15958", "abs": "https://arxiv.org/abs/2511.15958", "authors": ["Zhenyu Bi", "Gaurav Srivastava", "Yang Li", "Meng Lu", "Swastik Roy", "Morteza Ziyadi", "Xuan Wang"], "title": "JudgeBoard: Benchmarking and Enhancing Small Language Models for Reasoning Evaluation", "comment": "23 pages, 4 figures", "summary": "While small language models (SLMs) have shown promise on various reasoning tasks, their ability to judge the correctness of answers remains unclear compared to large language models (LLMs). Prior work on LLM-as-a-judge frameworks typically relies on comparing candidate answers against ground-truth labels or other candidate answers using predefined metrics like entailment. However, this approach is inherently indirect and difficult to fully automate, offering limited support for fine-grained and scalable evaluation of reasoning outputs. In this work, we propose JudgeBoard, a novel evaluation pipeline that directly queries models to assess the correctness of candidate answers without requiring extra answer comparisons. We focus on two core reasoning domains: mathematical reasoning and science/commonsense reasoning, and construct task-specific evaluation leaderboards using both accuracy-based ranking and an Elo-based rating system across five benchmark datasets, enabling consistent model comparison as judges rather than comparators. To improve judgment performance in lightweight models, we propose MAJ (Multi-Agent Judging), a novel multi-agent evaluation framework that leverages multiple interacting SLMs with distinct reasoning profiles to approximate LLM-level judgment accuracy through collaborative deliberation. Experimental results reveal a significant performance gap between SLMs and LLMs in isolated judging tasks. However, our MAJ framework substantially improves the reliability and consistency of SLMs. On the MATH dataset, MAJ using smaller-sized models as backbones performs comparatively well or even better than their larger-sized counterparts. Our findings highlight that multi-agent SLM systems can potentially match or exceed LLM performance in judgment tasks, with implications for scalable and efficient assessment.", "AI": {"tldr": "JudgeBoard\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u76f4\u63a5\u67e5\u8be2\u6a21\u578b\u6765\u8bc4\u4f30\u5019\u9009\u7b54\u6848\u7684\u6b63\u786e\u6027\uff0c\u65e0\u9700\u989d\u5916\u7b54\u6848\u6bd4\u8f83\u3002\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u8bc4\u5224(MAJ)\u6846\u67b6\uff0c\u4f7f\u7528\u591a\u4e2a\u4ea4\u4e92\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u6765\u8fd1\u4f3c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5224\u65ad\u51c6\u786e\u6027\u3002", "motivation": "\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5224\u65ad\u7b54\u6848\u6b63\u786e\u6027\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u4e0d\u660e\u786e\uff0c\u73b0\u6709\u57fa\u4e8e\u6bd4\u8f83\u7684\u8bc4\u4f30\u65b9\u6cd5\u95f4\u63a5\u4e14\u96be\u4ee5\u5b8c\u5168\u81ea\u52a8\u5316\uff0c\u65e0\u6cd5\u652f\u6301\u7ec6\u7c92\u5ea6\u548c\u53ef\u6269\u5c55\u7684\u63a8\u7406\u8f93\u51fa\u8bc4\u4f30\u3002", "method": "\u63d0\u51faJudgeBoard\u8bc4\u4f30\u7ba1\u9053\uff0c\u76f4\u63a5\u8bc4\u4f30\u5019\u9009\u7b54\u6848\u6b63\u786e\u6027\uff1b\u5f00\u53d1MAJ\u591a\u667a\u80fd\u4f53\u8bc4\u4f30\u6846\u67b6\uff0c\u5229\u7528\u591a\u4e2a\u5177\u6709\u4e0d\u540c\u63a8\u7406\u7279\u5f81\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u534f\u4f5c\u5ba1\u8bae\u6765\u63d0\u5347\u5224\u65ad\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u72ec\u7acb\u5224\u65ad\u4efb\u52a1\u4e2d\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\uff0c\u4f46MAJ\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u9760\u6027\u548c\u4e00\u81f4\u6027\u3002\u5728MATH\u6570\u636e\u96c6\u4e0a\uff0c\u57fa\u4e8e\u5c0f\u578b\u6a21\u578b\u7684MAJ\u8868\u73b0\u4e0e\u5927\u578b\u6a21\u578b\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u5728\u5224\u65ad\u4efb\u52a1\u4e2d\u53ef\u80fd\u5339\u914d\u6216\u8d85\u8d8a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4e3a\u53ef\u6269\u5c55\u548c\u9ad8\u6548\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.15983", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.15983", "abs": "https://arxiv.org/abs/2511.15983", "authors": ["Siqiao Mu", "Diego Klabjan"], "title": "Descend or Rewind? Stochastic Gradient Descent Unlearning", "comment": null, "summary": "Machine unlearning algorithms aim to remove the impact of selected training data from a model without the computational expenses of retraining from scratch. Two such algorithms are ``Descent-to-Delete\" (D2D) and ``Rewind-to-Delete\" (R2D), full-batch gradient descent algorithms that are easy to implement and satisfy provable unlearning guarantees. In particular, the stochastic version of D2D is widely implemented as the ``finetuning\" unlearning baseline, despite lacking theoretical backing on nonconvex functions. In this work, we prove $(\u03b5, \u03b4)$ certified unlearning guarantees for stochastic R2D and D2D for strongly convex, convex, and nonconvex loss functions, by analyzing unlearning through the lens of disturbed or biased gradient systems, which may be contracting, semi-contracting, or expansive respectively. Our argument relies on optimally coupling the random behavior of the unlearning and retraining trajectories, resulting in a probabilistic sensitivity bound that can be combined with a novel relaxed Gaussian mechanism to achieve $(\u03b5, \u03b4)$ unlearning. We determine that D2D can yield tighter guarantees for strongly convex functions compared to R2D by relying on contraction to a unique global minimum. However, unlike D2D, R2D can achieve unlearning in the convex and nonconvex setting because it draws the unlearned model closer to the retrained model by reversing the accumulated disturbances.", "AI": {"tldr": "\u672c\u6587\u4e3a\u968f\u673a\u7248\u672c\u7684R2D\u548cD2D\u673a\u5668\u9057\u5fd8\u7b97\u6cd5\u63d0\u4f9b\u4e86(\u03b5, \u03b4)\u8ba4\u8bc1\u9057\u5fd8\u4fdd\u8bc1\uff0c\u6db5\u76d6\u5f3a\u51f8\u3001\u51f8\u548c\u975e\u51f8\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u5206\u6790\u53d7\u6270\u68af\u5ea6\u7cfb\u7edf\u7684\u6536\u7f29\u7279\u6027\u6765\u5b9e\u73b0\u7406\u8bba\u4fdd\u8bc1\u3002", "motivation": "\u673a\u5668\u9057\u5fd8\u7b97\u6cd5\u65e8\u5728\u65e0\u9700\u4ece\u5934\u91cd\u65b0\u8bad\u7ec3\u5c31\u80fd\u4ece\u6a21\u578b\u4e2d\u79fb\u9664\u9009\u5b9a\u8bad\u7ec3\u6570\u636e\u7684\u5f71\u54cd\uff0c\u4f46\u73b0\u6709\u7684\u968f\u673aD2D\u7b97\u6cd5\u867d\u88ab\u5e7f\u6cdb\u7528\u4f5c\u57fa\u51c6\u5374\u7f3a\u4e4f\u975e\u51f8\u51fd\u6570\u4e0a\u7684\u7406\u8bba\u652f\u6301\u3002", "method": "\u901a\u8fc7\u5206\u6790\u53d7\u6270\u6216\u6709\u504f\u68af\u5ea6\u7cfb\u7edf\uff08\u5206\u522b\u5bf9\u5e94\u6536\u7f29\u3001\u534a\u6536\u7f29\u6216\u6269\u5f20\u7279\u6027\uff09\uff0c\u91c7\u7528\u6700\u4f18\u8026\u5408\u968f\u673a\u9057\u5fd8\u548c\u91cd\u65b0\u8bad\u7ec3\u8f68\u8ff9\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u65b0\u578b\u677e\u5f1b\u9ad8\u65af\u673a\u5236\u5b9e\u73b0(\u03b5, \u03b4)\u9057\u5fd8\u3002", "result": "\u8bc1\u660e\u4e86D2D\u5728\u5f3a\u51f8\u51fd\u6570\u4e0a\u6bd4R2D\u6709\u66f4\u7d27\u7684\u4fdd\u8bc1\uff0c\u800cR2D\u5728\u51f8\u548c\u975e\u51f8\u8bbe\u7f6e\u4e0b\u4e5f\u80fd\u5b9e\u73b0\u9057\u5fd8\uff0c\u56e0\u4e3a\u5b83\u901a\u8fc7\u9006\u8f6c\u7d2f\u79ef\u6270\u52a8\u5c06\u9057\u5fd8\u6a21\u578b\u62c9\u8fd1\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u3002", "conclusion": "\u4e3a\u968f\u673aR2D\u548cD2D\u7b97\u6cd5\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u7406\u8bba\u9057\u5fd8\u4fdd\u8bc1\uff0c\u586b\u8865\u4e86\u73b0\u6709\u57fa\u51c6\u7b97\u6cd5\u7f3a\u4e4f\u7406\u8bba\u652f\u6301\u7684\u7a7a\u767d\uff0c\u5e76\u9610\u660e\u4e86\u4e0d\u540c\u7b97\u6cd5\u5728\u4e0d\u540c\u51fd\u6570\u7c7b\u578b\u4e0b\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2511.16045", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16045", "abs": "https://arxiv.org/abs/2511.16045", "authors": ["Jorge A. Huertas", "Pascal Van Hentenryck"], "title": "An Aligned Constraint Programming Model For Serial Batch Scheduling With Minimum Batch Size", "comment": "14 pages, 12 figures", "summary": "In serial batch (s-batch) scheduling, jobs from similar families are grouped into batches and processed sequentially to avoid repetitive setups that are required when processing consecutive jobs of different families. Despite its large success in scheduling, only three Constraint Programming (CP) models have been proposed for this problem considering minimum batch sizes, which is a common requirement in many practical settings, including the ion implantation area in semiconductor manufacturing. These existing CP models rely on a predefined virtual set of possible batches that suffers from the curse of dimensionality and adds complexity to the problem. This paper proposes a novel CP model that does not rely on this virtual set. Instead, it uses key alignment parameters that allow it to reason directly on the sequences of same-family jobs scheduled on the machines, resulting in a more compact formulation. This new model is further improved by exploiting the problem's structure with tailored search phases and strengthened inference levels of the constraint propagators. The extensive computational experiments on nearly five thousand instances compare the proposed models against existing methods in the literature, including mixed-integer programming formulations, tabu search meta-heuristics, and CP approaches. The results demonstrate the superiority of the proposed models on small-to-medium instances with up to 100 jobs, and their ability to find solutions up to 25\\% better than the ones produces by existing methods on large-scale instances with up to 500 jobs, 10 families, and 10 machines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ea6\u675f\u89c4\u5212\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3\u8003\u8651\u6700\u5c0f\u6279\u6b21\u5927\u5c0f\u7684\u4e32\u884c\u6279\u6b21\u8c03\u5ea6\u95ee\u9898\uff0c\u907f\u514d\u4e86\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9884\u5b9a\u4e49\u865a\u62df\u6279\u6b21\u96c6\u5408\u7684\u7f3a\u9677\u3002", "motivation": "\u73b0\u6709\u7ea6\u675f\u89c4\u5212\u6a21\u578b\u4f9d\u8d56\u9884\u5b9a\u4e49\u7684\u865a\u62df\u6279\u6b21\u96c6\u5408\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u7ef4\u5ea6\u707e\u96be\u5e76\u589e\u52a0\u95ee\u9898\u590d\u6742\u6027\u3002\u5728\u534a\u5bfc\u4f53\u5236\u9020\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u6700\u5c0f\u6279\u6b21\u5927\u5c0f\u662f\u5e38\u89c1\u8981\u6c42\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e0d\u4f9d\u8d56\u865a\u62df\u6279\u6b21\u96c6\u5408\u7684\u65b0\u7ea6\u675f\u89c4\u5212\u6a21\u578b\uff0c\u4f7f\u7528\u5173\u952e\u5bf9\u9f50\u53c2\u6570\u76f4\u63a5\u5728\u673a\u5668\u4e0a\u8c03\u5ea6\u540c\u65cf\u4f5c\u4e1a\u5e8f\u5217\uff0c\u5f62\u6210\u66f4\u7d27\u51d1\u7684\u8868\u8ff0\u3002\u901a\u8fc7\u5b9a\u5236\u641c\u7d22\u9636\u6bb5\u548c\u52a0\u5f3a\u7ea6\u675f\u4f20\u64ad\u5668\u7684\u63a8\u7406\u7ea7\u522b\u6765\u6539\u8fdb\u6a21\u578b\u3002", "result": "\u5728\u8fd15000\u4e2a\u5b9e\u4f8b\u4e0a\u7684\u8ba1\u7b97\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u6a21\u578b\u5728\u6700\u591a100\u4e2a\u4f5c\u4e1a\u7684\u5c0f\u5230\u4e2d\u578b\u5b9e\u4f8b\u4e0a\u8868\u73b0\u4f18\u8d8a\uff0c\u5728\u6700\u591a500\u4e2a\u4f5c\u4e1a\u300110\u4e2a\u5bb6\u65cf\u548c10\u53f0\u673a\u5668\u7684\u5927\u89c4\u6a21\u5b9e\u4f8b\u4e0a\uff0c\u80fd\u627e\u5230\u6bd4\u73b0\u6709\u65b9\u6cd5\u4f1825%\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u65b0\u7ea6\u675f\u89c4\u5212\u6a21\u578b\u5728\u4e32\u884c\u6279\u6b21\u8c03\u5ea6\u95ee\u9898\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5305\u62ec\u6df7\u5408\u6574\u6570\u89c4\u5212\u3001\u7981\u5fcc\u641c\u7d22\u5143\u542f\u53d1\u5f0f\u548c\u4f20\u7edf\u7ea6\u675f\u89c4\u5212\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u5b9e\u4f8b\u4e0a\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2511.16075", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16075", "abs": "https://arxiv.org/abs/2511.16075", "authors": ["Hrikshesh Kumar", "Anika Garg", "Anshul Gupta", "Yashika Agarwal"], "title": "A Hybrid Proactive And Predictive Framework For Edge Cloud Resource Management", "comment": null, "summary": "Old cloud edge workload resource management is too reactive. The problem with relying on static thresholds is that we are either overspending for more resources than needed or have reduced performance because of their lack. This is why we work on proactive solutions. A framework developed for it stops reacting to the problems but starts expecting them. We design a hybrid architecture, combining two powerful tools: the CNN LSTM model for time series forecasting and an orchestrator based on multi agent Deep Reinforcement Learning In fact the novelty is in how we combine them as we embed the predictive forecast from the CNN LSTM directly into the DRL agent state space. That is what makes the AI manager smarter it sees the future, which allows it to make better decisions about a long term plan for where to run tasks That means finding that sweet spot between how much money is saved while keeping the system healthy and apps fast for users That is we have given it eyes in order to see down the road so that it does not have to lurch from one problem to another it finds a smooth path forward Our tests show our system easily beats the old methods It is great at solving tough problems like making complex decisions and juggling multiple goals at once like being cheap fast and reliable", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408CNN-LSTM\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u548c\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u6df7\u5408\u67b6\u6784\uff0c\u7528\u4e8e\u4e91\u8fb9\u5de5\u4f5c\u8d1f\u8f7d\u8d44\u6e90\u7ba1\u7406\uff0c\u5b9e\u73b0\u4ece\u88ab\u52a8\u54cd\u5e94\u5230\u4e3b\u52a8\u9884\u6d4b\u7684\u8f6c\u53d8\u3002", "motivation": "\u4f20\u7edf\u4e91\u8fb9\u5de5\u4f5c\u8d1f\u8f7d\u8d44\u6e90\u7ba1\u7406\u8fc7\u4e8e\u88ab\u52a8\uff0c\u4f9d\u8d56\u9759\u6001\u9608\u503c\u5bfc\u81f4\u8d44\u6e90\u8fc7\u5ea6\u914d\u7f6e\u6216\u6027\u80fd\u4e0b\u964d\uff0c\u9700\u8981\u8f6c\u5411\u4e3b\u52a8\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u6df7\u5408\u67b6\u6784\uff0c\u5c06CNN-LSTM\u6a21\u578b\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u5d4c\u5165\u5230\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u7f16\u6392\u5668\u72b6\u6001\u7a7a\u95f4\u4e2d\uff0c\u4f7fAI\u7ba1\u7406\u5668\u80fd\u591f\u9884\u89c1\u672a\u6765\u5e76\u505a\u51fa\u957f\u671f\u89c4\u5212\u51b3\u7b56\u3002", "result": "\u6d4b\u8bd5\u8868\u660e\u8be5\u7cfb\u7edf\u660e\u663e\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u590d\u6742\u51b3\u7b56\u95ee\u9898\uff0c\u540c\u65f6\u5e73\u8861\u6210\u672c\u8282\u7ea6\u3001\u7cfb\u7edf\u5065\u5eb7\u548c\u7528\u6237\u4f53\u9a8c\u7b49\u591a\u4e2a\u76ee\u6807\u3002", "conclusion": "\u901a\u8fc7\u5c06\u9884\u6d4b\u80fd\u529b\u5d4c\u5165\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\uff0c\u7cfb\u7edf\u80fd\u591f\u9884\u89c1\u672a\u6765\u5e76\u627e\u5230\u8d44\u6e90\u7ba1\u7406\u7684\u6700\u4f18\u5e73\u8861\u70b9\uff0c\u5b9e\u73b0\u4ece\u88ab\u52a8\u54cd\u5e94\u5230\u4e3b\u52a8\u89c4\u5212\u7684\u8f6c\u53d8\u3002"}}
{"id": "2511.16073", "categories": ["cs.LG", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.16073", "abs": "https://arxiv.org/abs/2511.16073", "authors": ["Shreyansh Jain", "Madhav Singhvi", "Shreya Rahul Jain", "Pranav S", "Dishaa Lokesh", "Naren Chittibabu", "Akash Anandhan"], "title": "A Mathematical Framework for Custom Reward Functions in Job Application Evaluation using Reinforcement Learning", "comment": "13 pages, 4 figures, 2 equations, 3 Tables", "summary": "Conventional Applicant Tracking Systems (ATS) tend to be inflexible keyword-matchers, and deny gifted candidates a role due to a few minor semantic mismatches. This article describes a new two-step process to design a more refined resume evaluation model based on a small language model (<600M parameters) that is finetuned using GRPO on a custom reward function. To begin with, Supervised Fine-Tuning (SFT) was used to build a solid baseline model. Second, this SFT model was also optimized with the help of Reinforcement Learning (RL) through GRPO under the guidance of a new, multi-component reward function that can holistically assess candidates beyond simple keyword matching. We indicate that the RL application presents a critical problem of reward hacking due to the initial experiments of aggressive penalties, which produces faulty, excessively negative model behaviors. We have overcome this challenge by refining the reward function repeatedly and training hyperparameters into a stable \"gentle polishing process\" of the reward function. Our resulting GRPO-polished model demonstrates significant real-world efficacy, achieving a final accuracy of 91% on unseen test data. The model shows a strong ability to correctly identify qualified candidates (recall of 0.85 for the 'SELECTED' class) while also showing exceptional precision (1.0), confirming its reliability. These results indicate that a properly executed, two-step fine-tuning procedure can indeed effectively refine a small language model to be able to conduct fine-tuned and human-like candidate scoring, overcoming the drawbacks of both traditional ATS and naive RL usage.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08<600M\u53c2\u6570\uff09\u7684\u4e24\u6b65\u7b80\u5386\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u548cGRPO\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfATS\u7cfb\u7edf\u8fc7\u4e8e\u4f9d\u8d56\u5173\u952e\u8bcd\u5339\u914d\u7684\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfATS\u7cfb\u7edf\u8fc7\u4e8e\u50f5\u5316\uff0c\u4ec5\u4f9d\u8d56\u5173\u952e\u8bcd\u5339\u914d\uff0c\u5bfc\u81f4\u6709\u624d\u534e\u7684\u5019\u9009\u4eba\u56e0\u5fae\u5c0f\u8bed\u4e49\u4e0d\u5339\u914d\u800c\u88ab\u62d2\u7edd\u3002\u9700\u8981\u5f00\u53d1\u66f4\u7cbe\u7ec6\u7684\u7b80\u5386\u8bc4\u4f30\u6a21\u578b\u3002", "method": "\u91c7\u7528\u4e24\u6b65\u6cd5\uff1a\u9996\u5148\u4f7f\u7528\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u5efa\u7acb\u57fa\u7ebf\u6a21\u578b\uff0c\u7136\u540e\u901a\u8fc7GRPO\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u4f7f\u7528\u591a\u7ec4\u4ef6\u5956\u52b1\u51fd\u6570\u5168\u9762\u8bc4\u4f30\u5019\u9009\u4eba\u3002", "result": "\u6700\u7ec8\u6a21\u578b\u5728\u672a\u89c1\u6d4b\u8bd5\u6570\u636e\u4e0a\u8fbe\u523091%\u51c6\u786e\u7387\uff0c\u5bf9'SELECTED'\u7c7b\u522b\u7684\u53ec\u56de\u7387\u4e3a0.85\uff0c\u7cbe\u786e\u5ea6\u4e3a1.0\uff0c\u663e\u793a\u51fa\u5f3a\u5927\u7684\u5019\u9009\u8bc6\u522b\u80fd\u529b\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u7ecf\u8fc7\u9002\u5f53\u6267\u884c\u7684\u4e24\u6b65\u5fae\u8c03\u7a0b\u5e8f\u53ef\u4ee5\u6709\u6548\u4f18\u5316\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u5176\u80fd\u591f\u8fdb\u884c\u7cbe\u7ec6\u4e14\u7c7b\u4f3c\u4eba\u7c7b\u7684\u5019\u9009\u4eba\u8bc4\u5206\uff0c\u514b\u670d\u4f20\u7edfATS\u548c\u7b80\u5355RL\u4f7f\u7528\u7684\u7f3a\u70b9\u3002"}}
{"id": "2511.16202", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16202", "abs": "https://arxiv.org/abs/2511.16202", "authors": ["Pei Yang", "Ke Zhang", "Ji Wang", "Xiao Chen", "Yuxin Tang", "Eric Yang", "Lynn Ai", "Bill Shi"], "title": "Multi-Agent Collaborative Reward Design for Enhancing Reasoning in Reinforcement Learning", "comment": null, "summary": "We present CRM (Multi-Agent Collaborative Reward Model), a framework that replaces a single black-box reward model with a coordinated team of specialist evaluators to improve robustness and interpretability in RLHF. Conventional reward models struggle to jointly optimize multiple, sometimes conflicting, preference dimensions (e.g., factuality, helpfulness, safety) and offer limited transparency into why a score is assigned. CRM addresses these issues by decomposing preference evaluation into domain-specific agents that each produce partial signals, alongside global evaluators such as ranker-based and embedding-similarity rewards. A centralized aggregator fuses these signals at each timestep, balancing factors like step-wise correctness, multi-agent agreement, and repetition penalties, yielding a single training reward compatible with standard RL pipelines. The policy is optimized with advantage-based updates (e.g., GAE), while a value model regresses to the aggregated reward, enabling multi-perspective reward shaping without requiring additional human annotations beyond those used to train the evaluators. To support training and assessment, we introduce rewardBench, a benchmark and training suite aligned with the collaborative structure of CRM. Together, CRM and rewardBench provide a practical, modular path to more transparent reward modeling and more stable optimization.", "AI": {"tldr": "CRM\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5956\u52b1\u6a21\u578b\u6846\u67b6\uff0c\u7528\u4e13\u5bb6\u8bc4\u4f30\u5668\u56e2\u961f\u66ff\u4ee3\u5355\u4e00\u9ed1\u76d2\u5956\u52b1\u6a21\u578b\uff0c\u63d0\u9ad8RLHF\u7684\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edf\u5956\u52b1\u6a21\u578b\u96be\u4ee5\u540c\u65f6\u4f18\u5316\u591a\u4e2a\u53ef\u80fd\u51b2\u7a81\u7684\u504f\u597d\u7ef4\u5ea6\uff08\u5982\u4e8b\u5b9e\u6027\u3001\u5e2e\u52a9\u6027\u3001\u5b89\u5168\u6027\uff09\uff0c\u4e14\u8bc4\u5206\u900f\u660e\u5ea6\u6709\u9650\u3002", "method": "\u5c06\u504f\u597d\u8bc4\u4f30\u5206\u89e3\u4e3a\u9886\u57df\u7279\u5b9a\u7684\u667a\u80fd\u4f53\u751f\u6210\u90e8\u5206\u4fe1\u53f7\uff0c\u7ed3\u5408\u5168\u5c40\u8bc4\u4f30\u5668\uff0c\u901a\u8fc7\u4e2d\u592e\u805a\u5408\u5668\u878d\u5408\u4fe1\u53f7\uff0c\u5e73\u8861\u9010\u6b65\u6b63\u786e\u6027\u3001\u591a\u667a\u80fd\u4f53\u4e00\u81f4\u6027\u548c\u91cd\u590d\u60e9\u7f5a\u7b49\u56e0\u7d20\u3002", "result": "CRM\u4e0erewardBench\u57fa\u51c6\u5957\u4ef6\u4e00\u8d77\u63d0\u4f9b\u4e86\u66f4\u900f\u660e\u7684\u5956\u52b1\u5efa\u6a21\u548c\u66f4\u7a33\u5b9a\u4f18\u5316\u7684\u5b9e\u7528\u6a21\u5757\u5316\u8def\u5f84\u3002", "conclusion": "\u8be5\u6846\u67b6\u65e0\u9700\u989d\u5916\u4eba\u5de5\u6807\u6ce8\u5373\u53ef\u5b9e\u73b0\u591a\u89c6\u89d2\u5956\u52b1\u5851\u9020\uff0c\u4e0e\u6807\u51c6RL\u6d41\u7a0b\u517c\u5bb9\u3002"}}
{"id": "2511.16145", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16145", "abs": "https://arxiv.org/abs/2511.16145", "authors": ["Zhijie Zhong", "Zhiwen Yu", "Kaixiang Yang", "C. L. Philip Chen"], "title": "Labels Matter More Than Models: Quantifying the Benefit of Supervised Time Series Anomaly Detection", "comment": "16 pages, 14 figures, 7 tables. Under review", "summary": "Time series anomaly detection (TSAD) is a critical data mining task often constrained by label scarcity. Consequently, current research predominantly focuses on Unsupervised Time-series Anomaly Detection (UTAD), relying on complex architectures to model normal data distributions. However, this approach often overlooks the significant performance gains available from limited anomaly labels achievable in practical scenarios. This paper challenges the premise that architectural complexity is the optimal path for TSAD. We conduct the first methodical comparison between supervised and unsupervised paradigms and introduce STAND, a streamlined supervised baseline. Extensive experiments on five public datasets demonstrate that: (1) Labels matter more than models: under a limited labeling budget, simple supervised models significantly outperform complex state-of-the-art unsupervised methods; (2) Supervision yields higher returns: the performance gain from minimal supervision far exceeds that from architectural innovations; and (3) Practicality: STAND exhibits superior prediction consistency and anomaly localization compared to unsupervised counterparts. These findings advocate for a data-centric shift in TSAD research, emphasizing label utilization over purely algorithmic complexity. The code is publicly available at https://github.com/EmorZz1G/STAND.", "AI": {"tldr": "\u672c\u6587\u6311\u6218\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4e2d\u67b6\u6784\u590d\u6742\u6027\u7684\u5fc5\u8981\u6027\uff0c\u901a\u8fc7\u7cfb\u7edf\u6bd4\u8f83\u76d1\u7763\u4e0e\u65e0\u76d1\u7763\u65b9\u6cd5\uff0c\u63d0\u51fa\u7b80\u5355\u76d1\u7763\u57fa\u7ebfSTAND\uff0c\u8bc1\u660e\u5728\u6709\u9650\u6807\u7b7e\u4e0b\u76d1\u7763\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u590d\u6742\u65e0\u76d1\u7763\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u7814\u7a76\u8fc7\u5ea6\u4f9d\u8d56\u590d\u6742\u67b6\u6784\u5efa\u6a21\u6b63\u5e38\u6570\u636e\u5206\u5e03\uff0c\u5ffd\u89c6\u4e86\u5b9e\u9645\u573a\u666f\u4e2d\u6709\u9650\u5f02\u5e38\u6807\u7b7e\u5e26\u6765\u7684\u6027\u80fd\u63d0\u5347\u6f5c\u529b\u3002", "method": "\u63d0\u51faSTAND\u4f5c\u4e3a\u6d41\u7ebf\u578b\u76d1\u7763\u57fa\u7ebf\uff0c\u5e76\u8fdb\u884c\u76d1\u7763\u4e0e\u65e0\u76d1\u7763\u8303\u5f0f\u7684\u9996\u6b21\u7cfb\u7edf\u6027\u6bd4\u8f83\u3002", "result": "\u5728\u4e94\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff1a(1)\u6807\u7b7e\u6bd4\u6a21\u578b\u66f4\u91cd\u8981\uff1b(2)\u76d1\u7763\u5e26\u6765\u66f4\u9ad8\u56de\u62a5\uff1b(3)STAND\u5177\u6709\u66f4\u4f18\u7684\u9884\u6d4b\u4e00\u81f4\u6027\u548c\u5f02\u5e38\u5b9a\u4f4d\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u5021\u5bfc\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u5411\u4ee5\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u8f6c\u53d8\uff0c\u5f3a\u8c03\u6807\u7b7e\u5229\u7528\u800c\u975e\u7eaf\u7cb9\u7b97\u6cd5\u590d\u6742\u6027\u3002"}}
{"id": "2511.16231", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.16231", "abs": "https://arxiv.org/abs/2511.16231", "authors": ["Yang Yu"], "title": "Pass@k Metric for RLVR: A Diagnostic Tool of Exploration, But Not an Objective", "comment": null, "summary": "The ability of Large Language Models (LLMs) to perform complex, multi-step reasoning is a central focus of modern AI research. To evaluate and enhance this capability, the pass@k metric, which measures the probability of obtaining at least one correct solution in k independent samples, has received significant attention. Its intuitive appeal has led to its adoption not only as an evaluation standard but also as a direct optimization objective in reinforcement learning. In this paper, we analyze the pass@k objective, derive its gradient, and demonstrate that it is fundamentally a per-example positive reweighting of the simpler pass@1 objective. Our analysis reveals that the pass@k objective provides a vanishing learning signal in regimes where exploration is most critical. We further analyze the dynamics of \"exploration collapse\", showing that as the policy concentrates probability mass, the gap between pass@k and pass@1 diminishes. We conclude that while pass@k is a useful diagnostic tool, it may be an unsuitable direct objective for optimization. Instead, mechanisms explicitly encouraging efficient exploration could offer a more effective path forward for reinforcement learning in reasoning tasks.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86pass@k\u6307\u6807\u4f5c\u4e3a\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u76ee\u6807\u7684\u5c40\u9650\u6027\uff0c\u6307\u51fa\u5b83\u672c\u8d28\u4e0a\u662fpass@1\u76ee\u6807\u7684\u6b63\u5411\u91cd\u52a0\u6743\uff0c\u5728\u9700\u8981\u63a2\u7d22\u7684\u5173\u952e\u533a\u57df\u63d0\u4f9b\u6d88\u5931\u7684\u5b66\u4e60\u4fe1\u53f7\uff0c\u53ef\u80fd\u5bfc\u81f4\u63a2\u7d22\u5d29\u6e83\u3002", "motivation": "\u8bc4\u4f30\u548c\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6b65\u63a8\u7406\u80fd\u529b\u662fAI\u7814\u7a76\u7684\u6838\u5fc3\u7126\u70b9\uff0cpass@k\u6307\u6807\u5df2\u88ab\u5e7f\u6cdb\u91c7\u7528\u4f5c\u4e3a\u8bc4\u4f30\u6807\u51c6\u548c\u4f18\u5316\u76ee\u6807\uff0c\u4f46\u5176\u4f5c\u4e3a\u76f4\u63a5\u4f18\u5316\u76ee\u6807\u7684\u9002\u7528\u6027\u9700\u8981\u6df1\u5165\u5206\u6790\u3002", "method": "\u5206\u6790pass@k\u76ee\u6807\u51fd\u6570\uff0c\u63a8\u5bfc\u5176\u68af\u5ea6\uff0c\u8bc1\u660e\u5176\u672c\u8d28\u4e0a\u662fpass@1\u76ee\u6807\u7684\u9010\u6837\u672c\u6b63\u5411\u91cd\u52a0\u6743\uff0c\u5e76\u5206\u6790\u63a2\u7d22\u5d29\u6e83\u7684\u52a8\u6001\u8fc7\u7a0b\u3002", "result": "\u53d1\u73b0pass@k\u76ee\u6807\u5728\u63a2\u7d22\u6700\u5173\u952e\u7684\u673a\u5236\u4e2d\u63d0\u4f9b\u6d88\u5931\u7684\u5b66\u4e60\u4fe1\u53f7\uff0c\u968f\u7740\u7b56\u7565\u6982\u7387\u8d28\u91cf\u96c6\u4e2d\uff0cpass@k\u4e0epass@1\u4e4b\u95f4\u7684\u5dee\u8ddd\u4f1a\u51cf\u5c0f\u3002", "conclusion": "pass@k\u4f5c\u4e3a\u8bca\u65ad\u5de5\u5177\u6709\u7528\uff0c\u4f46\u4e0d\u9002\u5408\u4f5c\u4e3a\u76f4\u63a5\u4f18\u5316\u76ee\u6807\uff0c\u5e94\u4f7f\u7528\u660e\u786e\u9f13\u52b1\u9ad8\u6548\u63a2\u7d22\u7684\u673a\u5236\u6765\u63a8\u8fdb\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\u3002"}}
{"id": "2511.16548", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16548", "abs": "https://arxiv.org/abs/2511.16548", "authors": ["Guanchen Wu", "Yuzhang Xie", "Huanwei Wu", "Zhe He", "Hui Shao", "Xiao Hu", "Carl Yang"], "title": "Utilizing Large Language Models for Zero-Shot Medical Ontology Extension from Clinical Notes", "comment": "BIBM 2025 (WS#44: Biological ontologies and knowledge bases (BiOK) in the LLM era)", "summary": "Integrating novel medical concepts and relationships into existing ontologies can significantly enhance their coverage and utility for both biomedical research and clinical applications. Clinical notes, as unstructured documents rich with detailed patient observations, offer valuable context-specific insights and represent a promising yet underutilized source for ontology extension. Despite this potential, directly leveraging clinical notes for ontology extension remains largely unexplored. To address this gap, we propose CLOZE, a novel framework that uses large language models (LLMs) to automatically extract medical entities from clinical notes and integrate them into hierarchical medical ontologies. By capitalizing on the strong language understanding and extensive biomedical knowledge of pre-trained LLMs, CLOZE effectively identifies disease-related concepts and captures complex hierarchical relationships. The zero-shot framework requires no additional training or labeled data, making it a cost-efficient solution. Furthermore, CLOZE ensures patient privacy through automated removal of protected health information (PHI). Experimental results demonstrate that CLOZE provides an accurate, scalable, and privacy-preserving ontology extension framework, with strong potential to support a wide range of downstream applications in biomedical research and clinical informatics.", "AI": {"tldr": "CLOZE\u662f\u4e00\u4e2a\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u4e34\u5e8a\u7b14\u8bb0\u4e2d\u81ea\u52a8\u63d0\u53d6\u533b\u5b66\u5b9e\u4f53\u5e76\u6574\u5408\u5230\u5c42\u6b21\u5316\u533b\u5b66\u672c\u4f53\u4e2d\u7684\u96f6\u6837\u672c\u6846\u67b6\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u6807\u6ce8\u6570\u636e\uff0c\u4fdd\u62a4\u60a3\u8005\u9690\u79c1\uff0c\u5177\u6709\u51c6\u786e\u3001\u53ef\u6269\u5c55\u7684\u7279\u70b9\u3002", "motivation": "\u4e34\u5e8a\u7b14\u8bb0\u4f5c\u4e3a\u5bcc\u542b\u8be6\u7ec6\u60a3\u8005\u89c2\u5bdf\u7684\u975e\u7ed3\u6784\u5316\u6587\u6863\uff0c\u4e3a\u533b\u5b66\u672c\u4f53\u6269\u5c55\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u4f46\u672a\u88ab\u5145\u5206\u5229\u7528\u7684\u8d44\u6e90\uff0c\u76f4\u63a5\u5229\u7528\u4e34\u5e8a\u7b14\u8bb0\u8fdb\u884c\u672c\u4f53\u6269\u5c55\u7684\u7814\u7a76\u5c1a\u4e0d\u5145\u5206\u3002", "method": "\u5229\u7528\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5927\u8bed\u8a00\u7406\u89e3\u548c\u5e7f\u6cdb\u751f\u7269\u533b\u5b66\u77e5\u8bc6\uff0cCLOZE\u6846\u67b6\u81ea\u52a8\u8bc6\u522b\u75be\u75c5\u76f8\u5173\u6982\u5ff5\u5e76\u6355\u83b7\u590d\u6742\u7684\u5c42\u6b21\u5173\u7cfb\uff0c\u91c7\u7528\u96f6\u6837\u672c\u65b9\u6cd5\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u79fb\u9664\u53d7\u4fdd\u62a4\u5065\u5eb7\u4fe1\u606f\u786e\u4fdd\u60a3\u8005\u9690\u79c1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eCLOZE\u63d0\u4f9b\u4e86\u4e00\u4e2a\u51c6\u786e\u3001\u53ef\u6269\u5c55\u4e14\u4fdd\u62a4\u9690\u79c1\u7684\u672c\u4f53\u6269\u5c55\u6846\u67b6\uff0c\u5728\u751f\u7269\u533b\u5b66\u7814\u7a76\u548c\u4e34\u5e8a\u4fe1\u606f\u5b66\u4e2d\u5177\u6709\u5e7f\u6cdb\u4e0b\u6e38\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "CLOZE\u6846\u67b6\u6210\u529f\u5c55\u793a\u4e86\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u4e34\u5e8a\u7b14\u8bb0\u4e2d\u81ea\u52a8\u6269\u5c55\u533b\u5b66\u672c\u4f53\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u96f6\u6837\u672c\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u751f\u7269\u533b\u5b66\u672c\u4f53\u6784\u5efa\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.16318", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.16318", "abs": "https://arxiv.org/abs/2511.16318", "authors": ["Hao Shu"], "title": "Learning-Enhanced Observer for Linear Time-Invariant Systems with Parametric Uncertainty", "comment": "6 pages, ordinary version", "summary": "This work introduces a learning-enhanced observer (LEO) for linear time-invariant systems with uncertain dynamics. Rather than relying solely on nominal models, the proposed framework treats the system matrices as optimizable variables and refines them through gradient-based minimization of a steady-state output discrepancy loss. The resulting data-informed surrogate model enables the construction of an improved observer that effectively compensates for moderate parameter uncertainty while preserving the structure of classical designs. Extensive Monte Carlo studies across diverse system dimensions show systematic and statistically significant reductions, typically exceeding 15\\%, in normalized estimation error for both open-loop and Luenberger observers. These results demonstrate that modern learning mechanisms can serve as a powerful complement to traditional observer design, yielding more accurate and robust state estimation in uncertain systems. Codes are available at https://github.com/Hao-B-Shu/LTI_LEO.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u7ebf\u6027\u65f6\u4e0d\u53d8\u7cfb\u7edf\u7684\u5b66\u4e60\u589e\u5f3a\u89c2\u6d4b\u5668(LEO)\uff0c\u901a\u8fc7\u68af\u5ea6\u4f18\u5316\u7cfb\u7edf\u77e9\u9635\u6765\u6539\u8fdb\u4f20\u7edf\u89c2\u6d4b\u5668\u8bbe\u8ba1\uff0c\u5728\u53c2\u6570\u4e0d\u786e\u5b9a\u6027\u60c5\u51b5\u4e0b\u663e\u8457\u964d\u4f4e\u4f30\u8ba1\u8bef\u5dee\u3002", "motivation": "\u4f20\u7edf\u89c2\u6d4b\u5668\u8bbe\u8ba1\u4f9d\u8d56\u6807\u79f0\u6a21\u578b\uff0c\u5728\u7cfb\u7edf\u53c2\u6570\u4e0d\u786e\u5b9a\u65f6\u6027\u80fd\u4e0b\u964d\u3002\u9700\u8981\u7ed3\u5408\u73b0\u4ee3\u5b66\u4e60\u673a\u5236\u6765\u589e\u5f3a\u89c2\u6d4b\u5668\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\u3002", "method": "\u5c06\u7cfb\u7edf\u77e9\u9635\u4f5c\u4e3a\u53ef\u4f18\u5316\u53d8\u91cf\uff0c\u901a\u8fc7\u68af\u5ea6\u6700\u5c0f\u5316\u7a33\u6001\u8f93\u51fa\u5dee\u5f02\u635f\u5931\u6765\u7cbe\u70bc\u6a21\u578b\uff0c\u6784\u5efa\u6570\u636e\u9a71\u52a8\u7684\u66ff\u4ee3\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u7559\u7ecf\u5178\u89c2\u6d4b\u5668\u7ed3\u6784\u3002", "result": "\u8499\u7279\u5361\u6d1b\u7814\u7a76\u8868\u660e\uff0c\u5728\u591a\u79cd\u7cfb\u7edf\u7ef4\u5ea6\u4e0b\uff0c\u5f00\u73af\u548cLuenberger\u89c2\u6d4b\u5668\u7684\u5f52\u4e00\u5316\u4f30\u8ba1\u8bef\u5dee\u5747\u663e\u8457\u964d\u4f4e\uff0c\u901a\u5e38\u8d85\u8fc715%\u3002", "conclusion": "\u73b0\u4ee3\u5b66\u4e60\u673a\u5236\u53ef\u4ee5\u4f5c\u4e3a\u4f20\u7edf\u89c2\u6d4b\u5668\u8bbe\u8ba1\u7684\u5f3a\u5927\u8865\u5145\uff0c\u5728\u4e0d\u786e\u5b9a\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u66f4\u51c6\u786e\u548c\u9c81\u68d2\u7684\u72b6\u6001\u4f30\u8ba1\u3002"}}
{"id": "2511.16602", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16602", "abs": "https://arxiv.org/abs/2511.16602", "authors": ["Yi Zhang", "Che Liu", "Xiancong Ren", "Hanchu Ni", "Yingji Zhang", "Shuai Zhang", "Zeyuan Ding", "Jiayu Hu", "Haozhe Shan", "Junbo Qi", "Yan Bai", "Dengjie Li", "Jiachen Luo", "Yidong Wang", "Yong Dai", "Zenglin Xu", "Bin Shen", "Qifan Wang", "Jian Tang", "Xiaozhu Ju"], "title": "Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization", "comment": null, "summary": "Developing a universal and versatile embodied intelligence system presents two primary challenges: the critical embodied data bottleneck, where real-world data is scarce and expensive, and the algorithmic inefficiency of existing methods, which are resource-prohibitive. To address these limitations, we introduce Deliberate Practice Policy Optimization (DPPO), a metacognitive ``Metaloop'' training framework that dynamically alternates between supervised fine-tuning (competence expansion) and reinforcement learning (skill refinement). This enables automatic weakness identification and targeted resource allocation, specifically designed to maximize learning efficiency from sparse, finite data. Theoretically, DPPO can be formalised as a unified preference-learning framework. Empirically, training a vision-language embodied model with DPPO, referred to as Pelican-VL 1.0, yields a 20.3% performance improvement over the base model and surpasses open-source models at the 100B-parameter scale by 10.6%. We are open-sourcing both the models and code, providing the first systematic framework that alleviates the data and resource bottleneck and enables the community to build versatile embodied agents efficiently.", "AI": {"tldr": "DPPO\u662f\u4e00\u4e2a\u5143\u8ba4\u77e5\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u4ea4\u66ff\u76d1\u7763\u5fae\u8c03\uff08\u80fd\u529b\u6269\u5c55\uff09\u548c\u5f3a\u5316\u5b66\u4e60\uff08\u6280\u80fd\u7cbe\u70bc\uff09\u6765\u89e3\u51b3\u5177\u8eab\u667a\u80fd\u4e2d\u7684\u6570\u636e\u74f6\u9888\u548c\u7b97\u6cd5\u6548\u7387\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5177\u8eab\u667a\u80fd\u7cfb\u7edf\u7684\u4e24\u5927\u6311\u6218\uff1a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u7a00\u7f3a\u6602\u8d35\u7684\u6570\u636e\u74f6\u9888\uff0c\u4ee5\u53ca\u73b0\u6709\u65b9\u6cd5\u8d44\u6e90\u6d88\u8017\u5927\u7684\u7b97\u6cd5\u6548\u7387\u95ee\u9898\u3002", "method": "\u63d0\u51faDeliberate Practice Policy Optimization (DPPO)\u6846\u67b6\uff0c\u91c7\u7528\u5143\u8ba4\u77e5\"Metaloop\"\u8bad\u7ec3\u65b9\u6cd5\uff0c\u52a8\u6001\u4ea4\u66ff\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u5b9e\u73b0\u81ea\u52a8\u5f31\u70b9\u8bc6\u522b\u548c\u9488\u5bf9\u6027\u8d44\u6e90\u5206\u914d\u3002", "result": "\u8bad\u7ec3\u51fa\u7684Pelican-VL 1.0\u6a21\u578b\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u6027\u80fd\u63d0\u534720.3%\uff0c\u5728100B\u53c2\u6570\u89c4\u6a21\u4e0a\u8d85\u8d8a\u5f00\u6e90\u6a21\u578b10.6%\u3002", "conclusion": "DPPO\u662f\u9996\u4e2a\u7cfb\u7edf\u6027\u89e3\u51b3\u6570\u636e\u548c\u8d44\u6e90\u74f6\u9888\u7684\u6846\u67b6\uff0c\u80fd\u591f\u9ad8\u6548\u6784\u5efa\u591a\u529f\u80fd\u5177\u8eab\u667a\u80fd\u4f53\uff0c\u76f8\u5173\u6a21\u578b\u548c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2511.16625", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16625", "abs": "https://arxiv.org/abs/2511.16625", "authors": ["Elias Hossain", "Md Mehedi Hasan Nipu", "Maleeha Sheikh", "Rajib Rana", "Subash Neupane", "Niloofar Yousefi"], "title": "MedBayes-Lite: Bayesian Uncertainty Quantification for Safe Clinical Decision Support", "comment": null, "summary": "We propose MedBayes-Lite, a lightweight Bayesian enhancement for transformer-based clinical language models designed to produce reliable, uncertainty-aware predictions. Although transformers show strong potential for clinical decision support, they remain prone to overconfidence, especially in ambiguous medical cases where calibrated uncertainty is critical. MedBayes-Lite embeds uncertainty quantification directly into existing transformer pipelines without any retraining or architectural rewiring, adding no new trainable layers and keeping parameter overhead under 3 percent. The framework integrates three components: (i) Bayesian Embedding Calibration using Monte Carlo dropout for epistemic uncertainty, (ii) Uncertainty-Weighted Attention that marginalizes over token reliability, and (iii) Confidence-Guided Decision Shaping inspired by clinical risk minimization. Across biomedical QA and clinical prediction benchmarks (MedQA, PubMedQA, MIMIC-III), MedBayes-Lite consistently improves calibration and trustworthiness, reducing overconfidence by 32 to 48 percent. In simulated clinical settings, it can prevent up to 41 percent of diagnostic errors by flagging uncertain predictions for human review. These results demonstrate its effectiveness in enabling reliable uncertainty propagation and improving interpretability in medical AI systems.", "AI": {"tldr": "MedBayes-Lite\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u8d1d\u53f6\u65af\u589e\u5f3a\u6846\u67b6\uff0c\u7528\u4e8e\u57fa\u4e8etransformer\u7684\u4e34\u5e8a\u8bed\u8a00\u6a21\u578b\uff0c\u65e8\u5728\u4ea7\u751f\u53ef\u9760\u3001\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u9884\u6d4b\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u67b6\u6784\u4fee\u6539\u3002", "motivation": "transformer\u6a21\u578b\u5728\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u4e2d\u663e\u793a\u51fa\u5f3a\u5927\u6f5c\u529b\uff0c\u4f46\u5728\u6a21\u7cca\u533b\u7597\u6848\u4f8b\u4e2d\u5bb9\u6613\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u800c\u6821\u51c6\u7684\u4e0d\u786e\u5b9a\u6027\u5bf9\u533b\u7597\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6846\u67b6\u96c6\u6210\u4e09\u4e2a\u7ec4\u4ef6\uff1a(i)\u4f7f\u7528\u8499\u7279\u5361\u6d1bdropout\u8fdb\u884c\u8d1d\u53f6\u65af\u5d4c\u5165\u6821\u51c6\u4ee5\u83b7\u53d6\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c(ii)\u4e0d\u786e\u5b9a\u6027\u52a0\u6743\u6ce8\u610f\u529b\u673a\u5236\u5bf9token\u53ef\u9760\u6027\u8fdb\u884c\u8fb9\u9645\u5316\uff0c(iii)\u53d7\u4e34\u5e8a\u98ce\u9669\u6700\u5c0f\u5316\u542f\u53d1\u7684\u7f6e\u4fe1\u5ea6\u5f15\u5bfc\u51b3\u7b56\u5851\u9020\u3002", "result": "\u5728\u751f\u7269\u533b\u5b66QA\u548c\u4e34\u5e8a\u9884\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMedBayes-Lite\u6301\u7eed\u6539\u5584\u6821\u51c6\u548c\u53ef\u4fe1\u5ea6\uff0c\u5c06\u8fc7\u5ea6\u81ea\u4fe1\u51cf\u5c1132-48%\u3002\u5728\u6a21\u62df\u4e34\u5e8a\u8bbe\u7f6e\u4e2d\uff0c\u901a\u8fc7\u6807\u8bb0\u4e0d\u786e\u5b9a\u9884\u6d4b\u4f9b\u4eba\u5de5\u5ba1\u67e5\uff0c\u53ef\u4ee5\u9884\u9632\u9ad8\u8fbe41%\u7684\u8bca\u65ad\u9519\u8bef\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u533b\u7597AI\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u4e86\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4f20\u64ad\uff0c\u5e76\u63d0\u9ad8\u4e86\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2511.16660", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16660", "abs": "https://arxiv.org/abs/2511.16660", "authors": ["Priyanka Kargupta", "Shuyue Stella Li", "Haocheng Wang", "Jinu Lee", "Shan Chen", "Orevaoghene Ahia", "Dean Light", "Thomas L. Griffiths", "Max Kleiman-Weiner", "Jiawei Han", "Asli Celikyilmaz", "Yulia Tsvetkov"], "title": "Cognitive Foundations for Reasoning and Their Manifestation in LLMs", "comment": "40 pages, 4 tables, 6 figures", "summary": "Large language models solve complex problems yet fail on simpler variants, suggesting they achieve correct outputs through mechanisms fundamentally different from human reasoning. We synthesize cognitive science research into a taxonomy of 28 cognitive elements spanning computational constraints, meta-cognitive controls, knowledge representations, and transformation operations, then analyze their behavioral manifestations in reasoning traces. We propose a fine-grained cognitive evaluation framework and conduct the first large-scale analysis of 170K traces from 17 models across text, vision, and audio modalities, alongside 54 human think-aloud traces, which we make publicly available. Our analysis reveals systematic structural differences: humans employ hierarchical nesting and meta-cognitive monitoring while models rely on shallow forward chaining, with divergence most pronounced on ill-structured problems. Meta-analysis of 1,598 LLM reasoning papers reveals the research community concentrates on easily quantifiable behaviors (sequential organization: 55%, decomposition: 60%) while neglecting meta-cognitive controls (self-awareness: 16%, evaluation: 8%) that correlate with success. Models possess behavioral repertoires associated with success but fail to deploy them spontaneously. Leveraging these patterns, we develop test-time reasoning guidance that automatically scaffold successful structures, improving performance by up to 60% on complex problems. By bridging cognitive science and LLM research, we establish a foundation for developing models that reason through principled cognitive mechanisms rather than brittle spurious reasoning shortcuts or memorization, opening new directions for both improving model capabilities and testing theories of human cognition at scale.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b28\u4e2a\u8ba4\u77e5\u5143\u7d20\u7684\u5206\u7c7b\u6cd5\uff0c\u5206\u6790\u4e8617\u4e2a\u6a21\u578b\u548c\u4eba\u7c7b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u884c\u4e3a\u5dee\u5f02\uff0c\u53d1\u73b0\u4eba\u7c7b\u4f7f\u7528\u5c42\u6b21\u5d4c\u5957\u548c\u5143\u8ba4\u77e5\u76d1\u63a7\uff0c\u800c\u6a21\u578b\u4f9d\u8d56\u6d45\u5c42\u524d\u5411\u94fe\u5f0f\u63a8\u7406\u3002\u7814\u7a76\u5f00\u53d1\u4e86\u6d4b\u8bd5\u65f6\u63a8\u7406\u6307\u5bfc\u65b9\u6cd5\uff0c\u53ef\u5c06\u590d\u6742\u95ee\u9898\u6027\u80fd\u63d0\u534760%\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u95ee\u9898\u4e0a\u8868\u73b0\u826f\u597d\u4f46\u5728\u7b80\u5355\u53d8\u4f53\u4e0a\u5931\u8d25\uff0c\u8868\u660e\u5b83\u4eec\u901a\u8fc7\u4e0d\u540c\u4e8e\u4eba\u7c7b\u63a8\u7406\u7684\u673a\u5236\u83b7\u5f97\u6b63\u786e\u8f93\u51fa\u3002\u7814\u7a76\u65e8\u5728\u5f25\u5408\u8ba4\u77e5\u79d1\u5b66\u4e0eLLM\u7814\u7a76\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5efa\u7acb\u57fa\u4e8e\u8ba4\u77e5\u673a\u5236\u800c\u975e\u8bb0\u5fc6\u6216\u865a\u5047\u63a8\u7406\u6377\u5f84\u7684\u6a21\u578b\u5f00\u53d1\u57fa\u7840\u3002", "method": "\u7efc\u5408\u8ba4\u77e5\u79d1\u5b66\u7814\u7a76\u6784\u5efa28\u4e2a\u8ba4\u77e5\u5143\u7d20\u7684\u5206\u7c7b\u6cd5\uff0c\u5206\u679017\u4e2a\u6a21\u578b\u7684170K\u63a8\u7406\u8f68\u8ff9\u548c54\u4e2a\u4eba\u7c7b\u601d\u7ef4\u8f68\u8ff9\uff0c\u5e76\u8fdb\u884c1,598\u7bc7LLM\u63a8\u7406\u8bba\u6587\u7684\u5143\u5206\u6790\u3002\u5f00\u53d1\u6d4b\u8bd5\u65f6\u63a8\u7406\u6307\u5bfc\u65b9\u6cd5\u6765\u81ea\u52a8\u6784\u5efa\u6210\u529f\u63a8\u7406\u7ed3\u6784\u3002", "result": "\u53d1\u73b0\u4eba\u7c7b\u548c\u6a21\u578b\u5728\u63a8\u7406\u7ed3\u6784\u4e0a\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff1a\u4eba\u7c7b\u4f7f\u7528\u5c42\u6b21\u5d4c\u5957\u548c\u5143\u8ba4\u77e5\u76d1\u63a7\uff0c\u6a21\u578b\u4f9d\u8d56\u6d45\u5c42\u524d\u5411\u94fe\u5f0f\u63a8\u7406\u3002\u5143\u5206\u6790\u663e\u793a\u7814\u7a76\u793e\u533a\u5173\u6ce8\u53ef\u91cf\u5316\u884c\u4e3a\u800c\u5ffd\u89c6\u5143\u8ba4\u77e5\u63a7\u5236\u3002\u63a8\u7406\u6307\u5bfc\u65b9\u6cd5\u53ef\u5c06\u590d\u6742\u95ee\u9898\u6027\u80fd\u63d0\u534760%\u3002", "conclusion": "\u901a\u8fc7\u8fde\u63a5\u8ba4\u77e5\u79d1\u5b66\u548cLLM\u7814\u7a76\uff0c\u4e3a\u5f00\u53d1\u57fa\u4e8e\u539f\u5219\u6027\u8ba4\u77e5\u673a\u5236\u800c\u975e\u8106\u5f31\u865a\u5047\u63a8\u7406\u6377\u5f84\u6216\u8bb0\u5fc6\u7684\u6a21\u578b\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u4e3a\u6539\u8fdb\u6a21\u578b\u80fd\u529b\u548c\u5927\u89c4\u6a21\u6d4b\u8bd5\u4eba\u7c7b\u8ba4\u77e5\u7406\u8bba\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2511.16512", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.16512", "abs": "https://arxiv.org/abs/2511.16512", "authors": ["Nicholas Pellegrino", "David Szczecina", "Paul Fieguth"], "title": "Loss Functions Robust to the Presence of Label Errors", "comment": "6 pages, 6 figures, Presented at the 10th Annual Conference on Vision and Intelligent Systems (2024)", "summary": "Methods for detecting label errors in training data require models that are robust to label errors (i.e., not fit to erroneously labelled data points). However, acquiring such models often involves training on corrupted data, which presents a challenge. Adjustments to the loss function present an opportunity for improvement. Motivated by Focal Loss (which emphasizes difficult-to-classify samples), two novel, yet simple, loss functions are proposed that de-weight or ignore these difficult samples (i.e., those likely to have label errors). Results on artificially corrupted data show promise, such that F1 scores for detecting errors are improved from the baselines of conventional categorical Cross Entropy and Focal Loss.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u964d\u4f4e\u6216\u5ffd\u7565\u53ef\u80fd\u542b\u6709\u6807\u7b7e\u9519\u8bef\u7684\u56f0\u96be\u6837\u672c\u6743\u91cd\uff0c\u6765\u6539\u8fdb\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u6807\u7b7e\u9519\u8bef\u68c0\u6d4b\u3002", "motivation": "\u68c0\u6d4b\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u6807\u7b7e\u9519\u8bef\u9700\u8981\u80fd\u591f\u62b5\u6297\u6807\u7b7e\u9519\u8bef\u7684\u6a21\u578b\uff0c\u4f46\u83b7\u53d6\u8fd9\u79cd\u6a21\u578b\u901a\u5e38\u9700\u8981\u5728\u88ab\u6c61\u67d3\u7684\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u8fd9\u5e26\u6765\u4e86\u6311\u6218\u3002\u53d7Focal Loss\u542f\u53d1\uff0c\u5e0c\u671b\u901a\u8fc7\u8c03\u6574\u635f\u5931\u51fd\u6570\u6765\u6539\u8fdb\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u9896\u800c\u7b80\u5355\u7684\u635f\u5931\u51fd\u6570\uff0c\u8fd9\u4e9b\u51fd\u6570\u5bf9\u53ef\u80fd\u542b\u6709\u6807\u7b7e\u9519\u8bef\u7684\u56f0\u96be\u6837\u672c\u8fdb\u884c\u964d\u6743\u6216\u5ffd\u7565\u5904\u7406\u3002", "result": "\u5728\u4eba\u5de5\u6c61\u67d3\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u4f20\u7edf\u7684\u5206\u7c7b\u4ea4\u53c9\u71b5\u548cFocal Loss\u57fa\u7ebf\u76f8\u6bd4\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u68c0\u6d4b\u6807\u7b7e\u9519\u8bef\u65b9\u9762\u7684F1\u5206\u6570\u6709\u6240\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u8c03\u6574\u635f\u5931\u51fd\u6570\u6765\u5904\u7406\u56f0\u96be\u6837\u672c\uff08\u53ef\u80fd\u542b\u6709\u6807\u7b7e\u9519\u8bef\uff09\uff0c\u53ef\u4ee5\u6709\u6548\u6539\u8fdb\u6807\u7b7e\u9519\u8bef\u68c0\u6d4b\u7684\u6027\u80fd\u3002"}}
{"id": "2511.16520", "categories": ["cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.16520", "abs": "https://arxiv.org/abs/2511.16520", "authors": ["Yuxiang Wan", "Ryan Devera", "Wenjie Zhang", "Ju Sun"], "title": "Saving Foundation Flow-Matching Priors for Inverse Problems", "comment": null, "summary": "Foundation flow-matching (FM) models promise a universal prior for solving inverse problems (IPs), yet today they trail behind domain-specific or even untrained priors. How can we unlock their potential? We introduce FMPlug, a plug-in framework that redefines how foundation FMs are used in IPs. FMPlug combines an instance-guided, time-dependent warm-start strategy with a sharp Gaussianity regularization, adding problem-specific guidance while preserving the Gaussian structures. This leads to a significant performance boost across image restoration and scientific IPs. Our results point to a path for making foundation FM models practical, reusable priors for IP solving.", "AI": {"tldr": "FMPlug\u662f\u4e00\u4e2a\u63d2\u4ef6\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u4f8b\u5f15\u5bfc\u7684\u65f6\u95f4\u76f8\u5173\u9884\u70ed\u542f\u52a8\u7b56\u7565\u548c\u9510\u5229\u9ad8\u65af\u6b63\u5219\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u7840\u6d41\u5339\u914d\u6a21\u578b\u5728\u9006\u95ee\u9898\u6c42\u89e3\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u57fa\u7840\u6d41\u5339\u914d\u6a21\u578b\u5728\u89e3\u51b3\u9006\u95ee\u9898\u65f6\u8868\u73b0\u4e0d\u5982\u9886\u57df\u7279\u5b9a\u751a\u81f3\u65e0\u8bad\u7ec3\u5148\u9a8c\uff0c\u9700\u8981\u89e3\u9501\u5176\u6f5c\u529b\u4ee5\u6210\u4e3a\u5b9e\u7528\u7684\u901a\u7528\u5148\u9a8c\u3002", "method": "\u7ed3\u5408\u5b9e\u4f8b\u5f15\u5bfc\u7684\u65f6\u95f4\u76f8\u5173\u9884\u70ed\u542f\u52a8\u7b56\u7565\u548c\u9510\u5229\u9ad8\u65af\u6b63\u5219\u5316\uff0c\u5728\u4fdd\u6301\u9ad8\u65af\u7ed3\u6784\u7684\u540c\u65f6\u6dfb\u52a0\u95ee\u9898\u7279\u5b9a\u6307\u5bfc\u3002", "result": "\u5728\u56fe\u50cf\u6062\u590d\u548c\u79d1\u5b66\u9006\u95ee\u9898\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "FMPlug\u4e3a\u5c06\u57fa\u7840\u6d41\u5339\u914d\u6a21\u578b\u8f6c\u5316\u4e3a\u5b9e\u7528\u7684\u3001\u53ef\u91cd\u7528\u7684\u9006\u95ee\u9898\u6c42\u89e3\u5148\u9a8c\u6307\u660e\u4e86\u8def\u5f84\u3002"}}
{"id": "2511.16549", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.16549", "abs": "https://arxiv.org/abs/2511.16549", "authors": ["Yuanbo Guo", "Jun Xia", "Yiyu Shi"], "title": "FairLRF: Achieving Fairness through Sparse Low Rank Factorization", "comment": null, "summary": "As deep learning (DL) techniques become integral to various applications, ensuring model fairness while maintaining high performance has become increasingly critical, particularly in sensitive fields such as medical diagnosis. Although a variety of bias-mitigation methods have been proposed, many rely on computationally expensive debiasing strategies or suffer substantial drops in model accuracy, which limits their practicality in real-world, resource-constrained settings. To address this issue, we propose a fairness-oriented low rank factorization (LRF) framework that leverages singular value decomposition (SVD) to improve DL model fairness. Unlike traditional SVD, which is mainly used for model compression by decomposing and reducing weight matrices, our work shows that SVD can also serve as an effective tool for fairness enhancement. Specifically, we observed that elements in the unitary matrices obtained from SVD contribute unequally to model bias across groups defined by sensitive attributes. Motivated by this observation, we propose a method, named FairLRF, that selectively removes bias-inducing elements from unitary matrices to reduce group disparities, thus enhancing model fairness. Extensive experiments show that our method outperforms conventional LRF methods as well as state-of-the-art fairness-enhancing techniques. Additionally, an ablation study examines how major hyper-parameters may influence the performance of processed models. To the best of our knowledge, this is the first work utilizing SVD not primarily for compression but for fairness enhancement.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f4e\u79e9\u5206\u89e3\u7684\u516c\u5e73\u6027\u589e\u5f3a\u6846\u67b6FairLRF\uff0c\u5229\u7528SVD\u5206\u89e3\u9009\u62e9\u6027\u79fb\u9664\u5bfc\u81f4\u504f\u5dee\u7684\u77e9\u9635\u5143\u7d20\u6765\u63d0\u5347\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u516c\u5e73\u6027\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c11\u7fa4\u4f53\u5dee\u5f02\u3002", "motivation": "\u73b0\u6709\u504f\u5dee\u7f13\u89e3\u65b9\u6cd5\u901a\u5e38\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u6216\u5bfc\u81f4\u6a21\u578b\u51c6\u786e\u7387\u663e\u8457\u4e0b\u964d\uff0c\u9650\u5236\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5b9e\u7528\u6027\u3002\u4f5c\u8005\u53d1\u73b0SVD\u5206\u89e3\u5f97\u5230\u7684\u9149\u77e9\u9635\u5143\u7d20\u5bf9\u654f\u611f\u5c5e\u6027\u5b9a\u4e49\u7684\u7fa4\u4f53\u504f\u5dee\u8d21\u732e\u4e0d\u5747\u7b49\uff0c\u8fd9\u542f\u53d1\u4e86\u5229\u7528SVD\u8fdb\u884c\u516c\u5e73\u6027\u589e\u5f3a\u7684\u65b0\u601d\u8def\u3002", "method": "\u63d0\u51faFairLRF\u65b9\u6cd5\uff0c\u901a\u8fc7SVD\u5206\u89e3\u6a21\u578b\u6743\u91cd\u77e9\u9635\uff0c\u8bc6\u522b\u5e76\u9009\u62e9\u6027\u79fb\u9664\u5bfc\u81f4\u7fa4\u4f53\u504f\u5dee\u7684\u9149\u77e9\u9635\u5143\u7d20\uff0c\u4ece\u800c\u51cf\u5c11\u6a21\u578b\u5bf9\u4e0d\u540c\u654f\u611f\u5c5e\u6027\u7fa4\u4f53\u7684\u9884\u6d4b\u5dee\u5f02\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u4f4e\u79e9\u5206\u89e3\u65b9\u6cd5\u548c\u6700\u5148\u8fdb\u7684\u516c\u5e73\u6027\u589e\u5f3a\u6280\u672f\uff0c\u540c\u65f6\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u5206\u6790\u4e86\u4e3b\u8981\u8d85\u53c2\u6570\u5bf9\u5904\u7406\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u4e3b\u8981\u5229\u7528SVD\u8fdb\u884c\u516c\u5e73\u6027\u589e\u5f3a\u800c\u975e\u538b\u7f29\u7684\u7814\u7a76\uff0c\u8bc1\u660e\u4e86SVD\u5728\u63d0\u5347\u6a21\u578b\u516c\u5e73\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u516c\u5e73AI\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.16587", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.16587", "abs": "https://arxiv.org/abs/2511.16587", "authors": ["Amartya Mukherjee", "Jun Liu"], "title": "Almost Sure Convergence Analysis of Differentially Private Stochastic Gradient Methods", "comment": "6 pages", "summary": "Differentially private stochastic gradient descent (DP-SGD) has become the standard algorithm for training machine learning models with rigorous privacy guarantees. Despite its widespread use, the theoretical understanding of its long-run behavior remains limited: existing analyses typically establish convergence in expectation or with high probability, but do not address the almost sure convergence of single trajectories. In this work, we prove that DP-SGD converges almost surely under standard smoothness assumptions, both in nonconvex and strongly convex settings, provided the step sizes satisfy some standard decaying conditions. Our analysis extends to momentum variants such as the stochastic heavy ball (DP-SHB) and Nesterov's accelerated gradient (DP-NAG), where we show that careful energy constructions yield similar guarantees. These results provide stronger theoretical foundations for differentially private optimization and suggest that, despite privacy-induced distortions, the algorithm remains pathwise stable in both convex and nonconvex regimes.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u5dee\u5206\u9690\u79c1\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08DP-SGD\uff09\u53ca\u5176\u52a8\u91cf\u53d8\u4f53\u5728\u6807\u51c6\u5e73\u6ed1\u6027\u5047\u8bbe\u4e0b\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\uff0c\u4e3a\u5dee\u5206\u9690\u79c1\u4f18\u5316\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u5c3d\u7ba1DP-SGD\u5df2\u6210\u4e3a\u8bad\u7ec3\u5177\u6709\u4e25\u683c\u9690\u79c1\u4fdd\u8bc1\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6807\u51c6\u7b97\u6cd5\uff0c\u4f46\u5176\u957f\u671f\u884c\u4e3a\u7684\u7406\u8bba\u7406\u89e3\u4ecd\u7136\u6709\u9650\u3002\u73b0\u6709\u5206\u6790\u901a\u5e38\u53ea\u5efa\u7acb\u671f\u671b\u6536\u655b\u6216\u9ad8\u6982\u7387\u6536\u655b\uff0c\u672a\u80fd\u89e3\u51b3\u5355\u6761\u8f68\u8ff9\u7684\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\u95ee\u9898\u3002", "method": "\u5728\u6807\u51c6\u5e73\u6ed1\u6027\u5047\u8bbe\u4e0b\uff0c\u901a\u8fc7\u6ee1\u8db3\u6807\u51c6\u8870\u51cf\u6761\u4ef6\u7684\u6b65\u957f\uff0c\u8bc1\u660e\u4e86DP-SGD\u5728\u975e\u51f8\u548c\u5f3a\u51f8\u8bbe\u7f6e\u4e0b\u7684\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\u3002\u5206\u6790\u6269\u5c55\u5230\u52a8\u91cf\u53d8\u4f53\u5982\u968f\u673a\u91cd\u7403\u6cd5\uff08DP-SHB\uff09\u548cNesterov\u52a0\u901f\u68af\u5ea6\uff08DP-NAG\uff09\uff0c\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u80fd\u91cf\u6784\u9020\u83b7\u5f97\u7c7b\u4f3c\u4fdd\u8bc1\u3002", "result": "\u8bc1\u660e\u4e86DP-SGD\u53ca\u5176\u52a8\u91cf\u53d8\u4f53\u5728\u975e\u51f8\u548c\u5f3a\u51f8\u8bbe\u7f6e\u4e0b\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\uff0c\u8868\u660e\u5c3d\u7ba1\u5b58\u5728\u9690\u79c1\u5f15\u8d77\u7684\u5931\u771f\uff0c\u7b97\u6cd5\u5728\u51f8\u548c\u975e\u51f8\u533a\u57df\u90fd\u4fdd\u6301\u8def\u5f84\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u5dee\u5206\u9690\u79c1\u4f18\u5316\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u7406\u8bba\u57fa\u7840\uff0c\u8868\u660e\u5c3d\u7ba1\u6709\u9690\u79c1\u5f15\u8d77\u7684\u626d\u66f2\uff0cDP-SGD\u7b97\u6cd5\u5728\u51f8\u548c\u975e\u51f8\u60c5\u51b5\u4e0b\u90fd\u4fdd\u6301\u8def\u5f84\u7a33\u5b9a\u6027\u3002"}}
{"id": "2511.16596", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.16596", "abs": "https://arxiv.org/abs/2511.16596", "authors": ["Zohar Rimon", "Elisei Shafer", "Tal Tepper", "Efrat Shimron", "Aviv Tamar"], "title": "Toward Artificial Palpation: Representation Learning of Touch on Soft Bodies", "comment": null, "summary": "Palpation, the use of touch in medical examination, is almost exclusively performed by humans. We investigate a proof of concept for an artificial palpation method based on self-supervised learning. Our key idea is that an encoder-decoder framework can learn a $\\textit{representation}$ from a sequence of tactile measurements that contains all the relevant information about the palpated object. We conjecture that such a representation can be used for downstream tasks such as tactile imaging and change detection. With enough training data, it should capture intricate patterns in the tactile measurements that go beyond a simple map of forces -- the current state of the art. To validate our approach, we both develop a simulation environment and collect a real-world dataset of soft objects and corresponding ground truth images obtained by magnetic resonance imaging (MRI). We collect palpation sequences using a robot equipped with a tactile sensor, and train a model that predicts sensory readings at different positions on the object. We investigate the representation learned in this process, and demonstrate its use in imaging and change detection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u4eba\u5de5\u89e6\u8bca\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6846\u67b6\u4ece\u89e6\u89c9\u6d4b\u91cf\u5e8f\u5217\u4e2d\u5b66\u4e60\u5305\u542b\u88ab\u89e6\u8bca\u7269\u4f53\u6240\u6709\u76f8\u5173\u4fe1\u606f\u7684\u8868\u793a\uff0c\u7528\u4e8e\u89e6\u89c9\u6210\u50cf\u548c\u53d8\u5316\u68c0\u6d4b\u7b49\u4e0b\u6e38\u4efb\u52a1\u3002", "motivation": "\u5f53\u524d\u89e6\u8bca\u51e0\u4e4e\u5b8c\u5168\u7531\u4eba\u7c7b\u6267\u884c\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6355\u6349\u89e6\u89c9\u6d4b\u91cf\u4e2d\u590d\u6742\u6a21\u5f0f\u7684\u4eba\u5de5\u89e6\u8bca\u65b9\u6cd5\uff0c\u8d85\u8d8a\u7b80\u5355\u7684\u529b\u6620\u5c04\u56fe\u3002", "method": "\u5f00\u53d1\u6a21\u62df\u73af\u5883\u5e76\u6536\u96c6\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u914d\u5907\u89e6\u89c9\u4f20\u611f\u5668\u7684\u673a\u5668\u4eba\u6536\u96c6\u89e6\u8bca\u5e8f\u5217\uff0c\u8bad\u7ec3\u6a21\u578b\u9884\u6d4b\u7269\u4f53\u4e0d\u540c\u4f4d\u7f6e\u7684\u611f\u5b98\u8bfb\u6570\uff0c\u7814\u7a76\u5b66\u4e60\u5230\u7684\u8868\u793a\u3002", "result": "\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u80fd\u591f\u5b66\u4e60\u5230\u6709\u6548\u7684\u8868\u793a\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u6210\u50cf\u548c\u53d8\u5316\u68c0\u6d4b\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u4ece\u89e6\u89c9\u6d4b\u91cf\u4e2d\u5b66\u4e60\u5230\u5305\u542b\u4e30\u5bcc\u4fe1\u606f\u7684\u8868\u793a\uff0c\u4e3a\u4eba\u5de5\u89e6\u8bca\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u6982\u5ff5\u9a8c\u8bc1\u3002"}}
