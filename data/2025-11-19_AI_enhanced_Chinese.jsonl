{"id": "2511.13729", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13729", "abs": "https://arxiv.org/abs/2511.13729", "authors": ["Huseyin Goksu"], "title": "DualLaguerreNet: A Decoupled Spectral Filter GNN and the Uncovering of the Flexibility-Stability Trade-off", "comment": null, "summary": "Graph Neural Networks (GNNs) based on spectral filters, such as the Adaptive Orthogonal Polynomial Filter (AOPF) class (e.g., LaguerreNet), have shown promise in unifying the solutions for heterophily and over-smoothing. However, these single-filter models suffer from a \"compromise\" problem, as their single adaptive parameter (e.g., alpha) must learn a suboptimal, averaged response across the entire graph spectrum. In this paper, we propose DualLaguerreNet, a novel GNN architecture that solves this by introducing \"Decoupled Spectral Flexibility.\" DualLaguerreNet splits the graph Laplacian into two operators, L_low (low-frequency) and L_high (high-frequency), and learns two independent, adaptive Laguerre polynomial filters, parameterized by alpha_1 and alpha_2, respectively. This work, however, uncovers a deeper finding. While our experiments show DualLaguerreNet's flexibility allows it to achieve state-of-the-art results on complex heterophilic tasks (outperforming LaguerreNet), it simultaneously underperforms on simpler, homophilic tasks. We identify this as a fundamental \"Flexibility-Stability Trade-off\". The increased parameterization (2x filter parameters and 2x model parameters) leads to overfitting on simple tasks, demonstrating that the \"compromise\" of simpler models acts as a crucial regularizer. This paper presents a new SOTA architecture for heterophily while providing a critical analysis of the bias-variance trade-off inherent in adaptive GNN filter design.", "AI": {"tldr": "DualLaguerreNet\u901a\u8fc7\u5f15\u5165\u89e3\u8026\u8c31\u7075\u6d3b\u6027\uff0c\u5c06\u56fe\u62c9\u666e\u62c9\u65af\u7b97\u5b50\u5206\u89e3\u4e3a\u4f4e\u9891\u548c\u9ad8\u9891\u4e24\u4e2a\u7b97\u5b50\uff0c\u5206\u522b\u5b66\u4e60\u72ec\u7acb\u7684Laguerre\u591a\u9879\u5f0f\u6ee4\u6ce2\u5668\uff0c\u89e3\u51b3\u4e86\u5355\u6ee4\u6ce2\u5668\u6a21\u578b\u7684\u6298\u4e2d\u95ee\u9898\uff0c\u5728\u590d\u6742\u5f02\u8d28\u4efb\u52a1\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u4f46\u63ed\u793a\u4e86\u7075\u6d3b\u6027-\u7a33\u5b9a\u6027\u6743\u8861\u3002", "motivation": "\u89e3\u51b3\u57fa\u4e8e\u8c31\u6ee4\u6ce2\u5668\u7684GNNs\uff08\u5982LaguerreNet\uff09\u4e2d\u5355\u6ee4\u6ce2\u5668\u6a21\u578b\u7684\u6298\u4e2d\u95ee\u9898\uff0c\u5373\u5355\u4e2a\u81ea\u9002\u5e94\u53c2\u6570\u5fc5\u987b\u5728\u6574\u4e2a\u56fe\u8c31\u4e0a\u5b66\u4e60\u6b21\u4f18\u7684\u5e73\u5747\u54cd\u5e94\u3002", "method": "\u63d0\u51faDualLaguerreNet\u67b6\u6784\uff0c\u5c06\u56fe\u62c9\u666e\u62c9\u65af\u7b97\u5b50\u5206\u89e3\u4e3aL_low\uff08\u4f4e\u9891\uff09\u548cL_high\uff08\u9ad8\u9891\uff09\u4e24\u4e2a\u7b97\u5b50\uff0c\u5206\u522b\u5b66\u4e60\u7531alpha_1\u548calpha_2\u53c2\u6570\u5316\u7684\u72ec\u7acb\u81ea\u9002\u5e94Laguerre\u591a\u9879\u5f0f\u6ee4\u6ce2\u5668\u3002", "result": "\u5728\u590d\u6742\u5f02\u8d28\u4efb\u52a1\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff08\u4f18\u4e8eLaguerreNet\uff09\uff0c\u4f46\u5728\u7b80\u5355\u540c\u8d28\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u63ed\u793a\u4e86\u7075\u6d3b\u6027-\u7a33\u5b9a\u6027\u6743\u8861\u3002\u589e\u52a0\u7684\u53c2\u6570\u5316\u5bfc\u81f4\u5728\u7b80\u5355\u4efb\u52a1\u4e0a\u8fc7\u62df\u5408\u3002", "conclusion": "\u63d0\u51fa\u4e86\u7528\u4e8e\u5f02\u8d28\u6027\u7684\u65b0SOTA\u67b6\u6784\uff0c\u540c\u65f6\u6279\u5224\u6027\u5206\u6790\u4e86\u81ea\u9002\u5e94GNN\u6ee4\u6ce2\u5668\u8bbe\u8ba1\u4e2d\u56fa\u6709\u7684\u504f\u5dee-\u65b9\u5dee\u6743\u8861\uff0c\u8868\u660e\u7b80\u5355\u6a21\u578b\u7684\u6298\u4e2d\u8d77\u5230\u4e86\u5173\u952e\u7684\u6b63\u5219\u5316\u4f5c\u7528\u3002"}}
{"id": "2511.13763", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13763", "abs": "https://arxiv.org/abs/2511.13763", "authors": ["Anthony Kiggundu", "Bin Han", "Hans D. Schotten"], "title": "Knowledge vs. Experience: Asymptotic Limits of Impatience in Edge Tenants", "comment": "Submitted to IEEE ICC 2026", "summary": "We study how two information feeds, a closed-form Markov estimator of residual sojourn and an online trained actor-critic, affect reneging and jockeying in a dual M/M/1 system. Analytically, for unequal service rates and total-time patience, we show that total wait grows linearly so abandonment is inevitable and the probability of a successful jockey vanishes as the backlog approaches towards infinity. Furthermore, under a mild sub-linear error condition both information models yield the same asymptotic limits (robustness). We empirically validate these limits and quantify finite backlog differences. Our findings show that learned and analytic feeds produce different delays, reneging rates and transient jockeying behavior at practical sizes, but converge to the same asymptotic outcome implied by our theory. The results characterize when value-of-information matters (finite regimes) and when it does not (asymptotics), informing lightweight telemetry and decision-logic design for low-cost, jockeying-aware systems.", "AI": {"tldr": "\u7814\u7a76\u4e24\u79cd\u4fe1\u606f\u53cd\u9988\uff08\u9a6c\u5c14\u53ef\u592b\u4f30\u8ba1\u5668\u548c\u5728\u7ebf\u8bad\u7ec3\u7684\u6f14\u5458-\u8bc4\u8bba\u5bb6\uff09\u5982\u4f55\u5f71\u54cd\u53ccM/M/1\u7cfb\u7edf\u4e2d\u7684\u653e\u5f03\u548c\u8df3\u69fd\u884c\u4e3a\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u670d\u52a1\u7387\u548c\u603b\u65f6\u95f4\u8010\u5fc3\u4e0b\u7684\u6e10\u8fd1\u7279\u6027\u3002", "motivation": "\u63a2\u8ba8\u4fe1\u606f\u53cd\u9988\u5bf9\u6392\u961f\u7cfb\u7edf\u4e2d\u7528\u6237\u884c\u4e3a\uff08\u653e\u5f03\u548c\u8df3\u69fd\uff09\u7684\u5f71\u54cd\uff0c\u4e3a\u4f4e\u6210\u672c\u3001\u652f\u6301\u8df3\u69fd\u7684\u7cfb\u7edf\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u9065\u6d4b\u548c\u51b3\u7b56\u903b\u8f91\u63d0\u4f9b\u7406\u8bba\u6307\u5bfc\u3002", "method": "\u7ed3\u5408\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u4f7f\u7528\u9a6c\u5c14\u53ef\u592b\u4f30\u8ba1\u5668\u548c\u5728\u7ebf\u8bad\u7ec3\u7684\u6f14\u5458-\u8bc4\u8bba\u5bb6\u4e24\u79cd\u4fe1\u606f\u6a21\u578b\uff0c\u7814\u7a76\u53ccM/M/1\u7cfb\u7edf\u5728\u4e0d\u540c\u670d\u52a1\u7387\u548c\u603b\u65f6\u95f4\u8010\u5fc3\u4e0b\u7684\u884c\u4e3a\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u603b\u7b49\u5f85\u65f6\u95f4\u7ebf\u6027\u589e\u957f\u5bfc\u81f4\u653e\u5f03\u4e0d\u53ef\u907f\u514d\uff0c\u6210\u529f\u8df3\u69fd\u6982\u7387\u5728\u79ef\u538b\u8d8b\u4e8e\u65e0\u7a77\u65f6\u6d88\u5931\uff1b\u4e24\u79cd\u4fe1\u606f\u6a21\u578b\u5728\u6ee1\u8db3\u6e29\u548c\u6b21\u7ebf\u6027\u8bef\u5dee\u6761\u4ef6\u4e0b\u5177\u6709\u76f8\u540c\u7684\u6e10\u8fd1\u6781\u9650\uff1b\u5b9e\u8bc1\u9a8c\u8bc1\u4e86\u6709\u9650\u79ef\u538b\u4e0b\u7684\u5dee\u5f02\u548c\u6e10\u8fd1\u6536\u655b\u3002", "conclusion": "\u4fe1\u606f\u4ef7\u503c\u5728\u6709\u9650\u89c4\u6a21\u4e0b\u91cd\u8981\uff08\u4ea7\u751f\u4e0d\u540c\u7684\u5ef6\u8fdf\u3001\u653e\u5f03\u7387\u548c\u77ac\u6001\u8df3\u69fd\u884c\u4e3a\uff09\uff0c\u4f46\u5728\u6e10\u8fd1\u60c5\u51b5\u4e0b\u4e0d\u91cd\u8981\uff0c\u4e3a\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2511.13782", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13782", "abs": "https://arxiv.org/abs/2511.13782", "authors": ["Xiaoxing Lian", "Aidong Yang", "Jun Zhu", "Peng Wang", "Yue Zhang"], "title": "Imagine in Space: Exploring the Frontier of Spatial Intelligence and Reasoning Efficiency in Vision Language Models", "comment": "10 pages,a detail and effective benchmark for spatial reasoning", "summary": "Large language models (LLMs) and vision language models (VLMs), such as DeepSeek R1,OpenAI o3, and Gemini 2.5 Pro, have demonstrated remarkable reasoning capabilities across logical inference, problem solving, and decision making. However, spatial reasoning:a fundamental component of human cognition that includes mental rotation, navigation, and spatial relationship comprehension remains a significant challenge for current advanced VLMs. We hypothesize that imagination, the internal simulation of spatial states, is the dominant reasoning mechanism within a spatial world model. To test this hypothesis and systematically probe current VLM spatial reasoning mechanisms, we introduce SpatiaLite, a fully synthetic benchmark that jointly measures spatial reasoning accuracy and reasoning efficiency. Comprehensive experiments reveal three key findings. First, advanced VLMs predominantly rely on linguistic representations for reasoning and imagination, resulting in significant deficiencies on visual centric tasks that demand perceptual spatial relations and 3D geometry transformations such as mental rotation or projection prediction. Second, advanced VLMs exhibit severe inefficiency in their current spatial reasoning mechanisms, with token usage growing rapidly as transformation complexity increases. Third, we propose an Imagery Driven Framework (IDF) for data synthesis and training, which can implicitly construct an internal world model that is critical for spatial reasoning in VLMs. Building on SpatiaLite, this work delineates the spatial reasoning limits and patterns of advanced VLMs, identifies key shortcomings, and informs future advances", "AI": {"tldr": "SpatiaLite\u662f\u4e00\u4e2a\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524d\u5148\u8fdbVLMs\u4e3b\u8981\u4f9d\u8d56\u8bed\u8a00\u8868\u793a\uff0c\u5728\u89c6\u89c9\u4e2d\u5fc3\u4efb\u52a1\u4e0a\u5b58\u5728\u663e\u8457\u7f3a\u9677\uff0c\u4e14\u63a8\u7406\u6548\u7387\u4f4e\u4e0b\u3002", "motivation": "\u5f53\u524d\u5148\u8fdb\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u7a7a\u95f4\u63a8\u7406\uff08\u5982\u5fc3\u7406\u65cb\u8f6c\u3001\u5bfc\u822a\u548c\u7a7a\u95f4\u5173\u7cfb\u7406\u89e3\uff09\u65b9\u9762\u5b58\u5728\u663e\u8457\u6311\u6218\uff0c\u4f5c\u8005\u5047\u8bbe\u60f3\u8c61\u529b\uff08\u7a7a\u95f4\u72b6\u6001\u7684\u5185\u90e8\u6a21\u62df\uff09\u662f\u7a7a\u95f4\u4e16\u754c\u6a21\u578b\u4e2d\u7684\u4e3b\u5bfc\u63a8\u7406\u673a\u5236\u3002", "method": "\u5f15\u5165SpatiaLite\u5408\u6210\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8054\u5408\u6d4b\u91cf\u7a7a\u95f4\u63a8\u7406\u51c6\u786e\u6027\u548c\u6548\u7387\uff1b\u63d0\u51fa\u56fe\u50cf\u9a71\u52a8\u6846\u67b6\uff08IDF\uff09\u8fdb\u884c\u6570\u636e\u5408\u6210\u548c\u8bad\u7ec3\uff0c\u9690\u5f0f\u6784\u5efa\u5185\u90e8\u4e16\u754c\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff1a1\uff09\u5148\u8fdbVLMs\u4e3b\u8981\u4f9d\u8d56\u8bed\u8a00\u8868\u793a\uff0c\u5728\u9700\u8981\u611f\u77e5\u7a7a\u95f4\u5173\u7cfb\u548c3D\u51e0\u4f55\u53d8\u6362\u7684\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff1b2\uff09\u5f53\u524d\u7a7a\u95f4\u63a8\u7406\u673a\u5236\u6548\u7387\u4f4e\u4e0b\uff0ctoken\u4f7f\u7528\u968f\u590d\u6742\u5ea6\u5feb\u901f\u589e\u52a0\uff1b3\uff09IDF\u6846\u67b6\u80fd\u6709\u6548\u6784\u5efa\u5185\u90e8\u4e16\u754c\u6a21\u578b\u3002", "conclusion": "\u672c\u7814\u7a76\u660e\u786e\u4e86\u5148\u8fdbVLMs\u7684\u7a7a\u95f4\u63a8\u7406\u5c40\u9650\u6027\u548c\u6a21\u5f0f\uff0c\u8bc6\u522b\u4e86\u5173\u952e\u7f3a\u9677\uff0c\u5e76\u4e3a\u672a\u6765\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b9\u5411\uff0c\u5f3a\u8c03\u4e86\u6784\u5efa\u5185\u90e8\u4e16\u754c\u6a21\u578b\u5bf9\u7a7a\u95f4\u63a8\u7406\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.13741", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13741", "abs": "https://arxiv.org/abs/2511.13741", "authors": ["Silin Zhou", "Yao Chen", "Shuo Shang", "Lisi Chen", "Bingsheng He", "Ryosuke Shibasaki"], "title": "Blurred Encoding for Trajectory Representation Learning", "comment": "This paper is accepted by KDD2025(Feb. Cycle)", "summary": "Trajectory representation learning (TRL) maps trajectories to vector embeddings and facilitates tasks such as trajectory classification and similarity search. State-of-the-art (SOTA) TRL methods transform raw GPS trajectories to grid or road trajectories to capture high-level travel semantics, i.e., regions and roads. However, they lose fine-grained spatial-temporal details as multiple GPS points are grouped into a single grid cell or road segment. To tackle this problem, we propose the BLUrred Encoding method, dubbed BLUE, which gradually reduces the precision of GPS coordinates to create hierarchical patches with multiple levels. The low-level patches are small and preserve fine-grained spatial-temporal details, while the high-level patches are large and capture overall travel patterns. To complement different patch levels with each other, our BLUE is an encoder-decoder model with a pyramid structure. At each patch level, a Transformer is used to learn the trajectory embedding at the current level, while pooling prepares inputs for the higher level in the encoder, and up-resolution provides guidance for the lower level in the decoder. BLUE is trained using the trajectory reconstruction task with the MSE loss. We compare BLUE with 8 SOTA TRL methods for 3 downstream tasks, the results show that BLUE consistently achieves higher accuracy than all baselines, outperforming the best-performing baselines by an average of 30.90%. Our code is available at https://github.com/slzhou-xy/BLUE.", "AI": {"tldr": "BLUE\u662f\u4e00\u79cd\u8f68\u8ff9\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u9010\u6e10\u964d\u4f4eGPS\u5750\u6807\u7cbe\u5ea6\u521b\u5efa\u591a\u7ea7\u5206\u5c42\u8865\u4e01\uff0c\u5728\u4fdd\u6301\u7ec6\u7c92\u5ea6\u65f6\u7a7a\u7ec6\u8282\u7684\u540c\u65f6\u6355\u83b7\u6574\u4f53\u51fa\u884c\u6a21\u5f0f\uff0c\u5728\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u5e73\u5747\u6bd4\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5\u63d0\u534730.90%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u6700\u5148\u8fdb\u7684\u8f68\u8ff9\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u5c06\u539f\u59cbGPS\u8f68\u8ff9\u8f6c\u6362\u4e3a\u7f51\u683c\u6216\u9053\u8def\u8f68\u8ff9\u6765\u6355\u83b7\u9ad8\u7ea7\u51fa\u884c\u8bed\u4e49\uff0c\u4f46\u4f1a\u4e22\u5931\u7ec6\u7c92\u5ea6\u7684\u65f6\u7a7a\u7ec6\u8282\uff0c\u56e0\u4e3a\u591a\u4e2aGPS\u70b9\u88ab\u5206\u7ec4\u5230\u5355\u4e2a\u7f51\u683c\u5355\u5143\u6216\u9053\u8def\u6bb5\u4e2d\u3002", "method": "\u63d0\u51faBLUrred Encoding\u65b9\u6cd5(BLUE)\uff0c\u901a\u8fc7\u9010\u6e10\u964d\u4f4eGPS\u5750\u6807\u7cbe\u5ea6\u521b\u5efa\u5206\u5c42\u8865\u4e01\uff0c\u4f7f\u7528\u5177\u6709\u91d1\u5b57\u5854\u7ed3\u6784\u7684\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6a21\u578b\uff0c\u5728\u6bcf\u4e2a\u8865\u4e01\u7ea7\u522b\u4f7f\u7528Transformer\u5b66\u4e60\u8f68\u8ff9\u5d4c\u5165\uff0c\u901a\u8fc7\u6c60\u5316\u51c6\u5907\u66f4\u9ad8\u7ea7\u522b\u7684\u8f93\u5165\uff0c\u901a\u8fc7\u4e0a\u5206\u8fa8\u7387\u63d0\u4f9b\u66f4\u4f4e\u7ea7\u522b\u7684\u6307\u5bfc\uff0c\u4f7f\u7528\u8f68\u8ff9\u91cd\u5efa\u4efb\u52a1\u548cMSE\u635f\u5931\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u4e0e8\u79cd\u6700\u5148\u8fdb\u7684\u8f68\u8ff9\u8868\u793a\u5b66\u4e60\u65b9\u6cd5\u57283\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e0a\u8fdb\u884c\u6bd4\u8f83\uff0cBLUE\u59cb\u7ec8\u6bd4\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u66f4\u9ad8\u7684\u51c6\u786e\u7387\uff0c\u5e73\u5747\u6bd4\u6700\u4f73\u57fa\u7ebf\u65b9\u6cd5\u9ad8\u51fa30.90%\u3002", "conclusion": "BLUE\u65b9\u6cd5\u901a\u8fc7\u5206\u5c42\u8865\u4e01\u673a\u5236\u6709\u6548\u5e73\u8861\u4e86\u7ec6\u7c92\u5ea6\u65f6\u7a7a\u7ec6\u8282\u548c\u6574\u4f53\u51fa\u884c\u6a21\u5f0f\u7684\u6355\u83b7\uff0c\u5728\u8f68\u8ff9\u8868\u793a\u5b66\u4e60\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2511.14051", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.14051", "abs": "https://arxiv.org/abs/2511.14051", "authors": ["Xiang Chen", "Ming-Min Zhao", "An Liu", "Min Li", "Qingjiang Shi", "Min-Jian Zhao"], "title": "Cross-Sparsity-Enabled Multipath Perception via Structured Bayesian Inference for Multi-Target Estimation", "comment": "13 pages, 9 figures", "summary": "In this paper, we investigate a multi-target sensing system in multipath environment, where inter-target scattering gives rise to first-order reflected paths whose angles of departure (AoDs) and angles of arrival (AoAs) coincide with the direct-path angles of different targets. Unlike other multipath components, these first-order paths carry structural information that can be exploited as additional prior knowledge for target direction estimation. To exploit this property, we construct a sparse representation of the multi-target sensing channel and propose a novel cross sparsity structure under a three-layer hierarchical structured (3LHS) prior model, which leverages the first-order paths to enhance the prior probability of the direct paths and thereby improve the estimation accuracy. Building on this model, we propose a structured fast turbo variational Bayesian inference (SF-TVBI) algorithm, which integrates an efficient message-passing strategy to enable tractable probabilistic exchange within the cross sparsity, and a two-timescale update scheme to reduce the update frequency of the high-dimensional sparse vector. Simulation results demonstrate that leveraging the proposed cross sparsity structure is able to improve the target angle estimation accuracy substantially, and the SF-TVBI algorithm achieves estimation performance comparable to that of the Turbo-VBI, but with lower computational complexity.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u591a\u5f84\u73af\u5883\u4e2d\u76ee\u6807\u95f4\u6563\u5c04\u4ea7\u751f\u7684\u4e00\u9636\u53cd\u5c04\u8def\u5f84\u6765\u589e\u5f3a\u76ee\u6807\u65b9\u5411\u4f30\u8ba1\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efa\u4ea4\u53c9\u7a00\u758f\u7ed3\u6784\u548c\u5206\u5c42\u5148\u9a8c\u6a21\u578b\uff0c\u7ed3\u5408\u9ad8\u6548\u7684\u53d8\u5206\u8d1d\u53f6\u65af\u63a8\u7406\u7b97\u6cd5\uff0c\u5728\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u540c\u65f6\u63d0\u9ad8\u4f30\u8ba1\u7cbe\u5ea6\u3002", "motivation": "\u5728\u591a\u76ee\u6807\u611f\u77e5\u7cfb\u7edf\u4e2d\uff0c\u591a\u5f84\u73af\u5883\u4e0b\u7684\u76ee\u6807\u95f4\u6563\u5c04\u4f1a\u4ea7\u751f\u4e00\u9636\u53cd\u5c04\u8def\u5f84\uff0c\u8fd9\u4e9b\u8def\u5f84\u7684\u89d2\u5ea6\u4fe1\u606f\u4e0e\u4e0d\u540c\u76ee\u6807\u7684\u76f4\u63a5\u8def\u5f84\u89d2\u5ea6\u91cd\u5408\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u989d\u5916\u7684\u5148\u9a8c\u77e5\u8bc6\u6765\u6539\u8fdb\u76ee\u6807\u65b9\u5411\u4f30\u8ba1\u3002", "method": "\u6784\u5efa\u591a\u76ee\u6807\u611f\u77e5\u4fe1\u9053\u7684\u7a00\u758f\u8868\u793a\uff0c\u63d0\u51fa\u4e09\u5c42\u5206\u5c42\u7ed3\u6784\u5316\u5148\u9a8c\u6a21\u578b\u4e0b\u7684\u4ea4\u53c9\u7a00\u758f\u7ed3\u6784\uff0c\u5e76\u5f00\u53d1\u7ed3\u6784\u5316\u5feb\u901f\u6da1\u8f6e\u53d8\u5206\u8d1d\u53f6\u65af\u63a8\u7406\u7b97\u6cd5\uff0c\u7ed3\u5408\u9ad8\u6548\u6d88\u606f\u4f20\u9012\u7b56\u7565\u548c\u53cc\u65f6\u95f4\u5c3a\u5ea6\u66f4\u65b0\u65b9\u6848\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u5229\u7528\u6240\u63d0\u51fa\u7684\u4ea4\u53c9\u7a00\u758f\u7ed3\u6784\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u76ee\u6807\u89d2\u5ea6\u4f30\u8ba1\u7cbe\u5ea6\uff0cSF-TVBI\u7b97\u6cd5\u5728\u8fbe\u5230\u4e0eTurbo-VBI\u76f8\u5f53\u4f30\u8ba1\u6027\u80fd\u7684\u540c\u65f6\uff0c\u5177\u6709\u66f4\u4f4e\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u591a\u5f84\u73af\u5883\u4e2d\u7684\u4e00\u9636\u53cd\u5c04\u8def\u5f84\u6784\u5efa\u4ea4\u53c9\u7a00\u758f\u7ed3\u6784\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u591a\u76ee\u6807\u65b9\u5411\u4f30\u8ba1\u6027\u80fd\uff0c\u6240\u63d0\u51fa\u7684SF-TVBI\u7b97\u6cd5\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u8d1f\u62c5\u3002"}}
{"id": "2511.13934", "categories": ["stat.ML", "cs.LG", "econ.EM", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.13934", "abs": "https://arxiv.org/abs/2511.13934", "authors": ["Harold D. Chiang", "Yukitoshi Matsushita", "Taisuke Otsu"], "title": "Empirical Likelihood for Random Forests and Ensembles", "comment": "34 pages, 1 figure", "summary": "We develop an empirical likelihood (EL) framework for random forests and related ensemble methods, providing a likelihood-based approach to quantify their statistical uncertainty. Exploiting the incomplete $U$-statistic structure inherent in ensemble predictions, we construct an EL statistic that is asymptotically chi-squared when subsampling induced by incompleteness is not overly sparse. Under sparser subsampling regimes, the EL statistic tends to over-cover due to loss of pivotality; we therefore propose a modified EL that restores pivotality through a simple adjustment. Our method retains key properties of EL while remaining computationally efficient. Theory for honest random forests and simulations demonstrate that modified EL achieves accurate coverage and practical reliability relative to existing inference methods.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u7528\u4e8e\u968f\u673a\u68ee\u6797\u548c\u76f8\u5173\u96c6\u6210\u65b9\u6cd5\u7684\u7ecf\u9a8c\u4f3c\u7136\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u96c6\u6210\u9884\u6d4b\u4e2d\u56fa\u6709\u7684\u4e0d\u5b8c\u5168U\u7edf\u8ba1\u91cf\u7ed3\u6784\uff0c\u6784\u5efa\u4e86\u6e10\u8fd1\u5361\u65b9\u5206\u5e03\u7684\u7ecf\u9a8c\u4f3c\u7136\u7edf\u8ba1\u91cf\uff0c\u5e76\u63d0\u51fa\u4fee\u6b63\u7248\u672c\u4ee5\u5728\u7a00\u758f\u5b50\u91c7\u6837\u60c5\u51b5\u4e0b\u6062\u590d\u67a2\u8f74\u6027\u3002", "motivation": "\u4e3a\u968f\u673a\u68ee\u6797\u548c\u96c6\u6210\u65b9\u6cd5\u63d0\u4f9b\u57fa\u4e8e\u4f3c\u7136\u7684\u7edf\u8ba1\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u89e3\u51b3\u73b0\u6709\u63a8\u7406\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "method": "\u5229\u7528\u96c6\u6210\u9884\u6d4b\u7684\u4e0d\u5b8c\u5168U\u7edf\u8ba1\u91cf\u7ed3\u6784\u6784\u5efa\u7ecf\u9a8c\u4f3c\u7136\u7edf\u8ba1\u91cf\uff0c\u5728\u7a00\u758f\u5b50\u91c7\u6837\u60c5\u51b5\u4e0b\u901a\u8fc7\u7b80\u5355\u8c03\u6574\u63d0\u51fa\u4fee\u6b63\u7ecf\u9a8c\u4f3c\u7136\u4ee5\u6062\u590d\u67a2\u8f74\u6027\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u6a21\u62df\u8868\u660e\uff0c\u4fee\u6b63\u7ecf\u9a8c\u4f3c\u7136\u76f8\u5bf9\u4e8e\u73b0\u6709\u63a8\u7406\u65b9\u6cd5\u5b9e\u73b0\u4e86\u51c6\u786e\u7684\u8986\u76d6\u7387\u548c\u5b9e\u9645\u53ef\u9760\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4fdd\u7559\u4e86\u7ecf\u9a8c\u4f3c\u7136\u7684\u5173\u952e\u7279\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u968f\u673a\u68ee\u6797\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7edf\u8ba1\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6846\u67b6\u3002"}}
{"id": "2511.14146", "categories": ["stat.ML", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.14146", "abs": "https://arxiv.org/abs/2511.14146", "authors": ["Renjie Chen", "Viet Anh Nguyen", "Huifu Xu"], "title": "SCOPE: Spectral Concentration by Distributionally Robust Joint Covariance-Precision Estimation", "comment": null, "summary": "We propose a distributionally robust formulation for simultaneously estimating the covariance matrix and the precision matrix of a random vector.The proposed model minimizes the worst-case weighted sum of the Frobenius loss of the covariance estimator and Stein's loss of the precision matrix estimator against all distributions from an ambiguity set centered at the nominal distribution. The radius of the ambiguity set is measured via convex spectral divergence. We demonstrate that the proposed distributionally robust estimation model can be reduced to a convex optimization problem, thereby yielding quasi-analytical estimators. The joint estimators are shown to be nonlinear shrinkage estimators. The eigenvalues of the estimators are shrunk nonlinearly towards a positive scalar, where the scalar is determined by the weight coefficient of the loss terms. By tuning the coefficient carefully, the shrinkage corrects the spectral bias of the empirical covariance/precision matrix estimator. By this property, we call the proposed joint estimator the Spectral concentrated COvariance and Precision matrix Estimator (SCOPE). We demonstrate that the shrinkage effect improves the condition number of the estimator. We provide a parameter-tuning scheme that adjusts the shrinkage target and intensity that is asymptotically optimal. Numerical experiments on synthetic and real data show that our shrinkage estimators perform competitively against state-of-the-art estimators in practical applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5206\u5e03\u9c81\u68d2\u8054\u5408\u4f30\u8ba1\u65b9\u6cd5\uff0c\u540c\u65f6\u4f30\u8ba1\u968f\u673a\u5411\u91cf\u7684\u534f\u65b9\u5dee\u77e9\u9635\u548c\u7cbe\u5ea6\u77e9\u9635\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u52a0\u6743\u635f\u5931\u51fd\u6570\u6765\u83b7\u5f97\u975e\u7ebf\u6027\u6536\u7f29\u4f30\u8ba1\u5668\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u7ecf\u9a8c\u534f\u65b9\u5dee/\u7cbe\u5ea6\u77e9\u9635\u4f30\u8ba1\u5668\u7684\u8c31\u504f\u5dee\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u4f18\u5316\u534f\u65b9\u5dee\u548c\u7cbe\u5ea6\u77e9\u9635\u4f30\u8ba1\u7684\u9c81\u68d2\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u6846\u67b6\uff0c\u6784\u5efa\u4ee5\u540d\u4e49\u5206\u5e03\u4e3a\u4e2d\u5fc3\u7684\u6a21\u7cca\u96c6\uff0c\u6700\u5c0f\u5316Frobenius\u635f\u5931\u548cStein\u635f\u5931\u7684\u6700\u574f\u60c5\u51b5\u52a0\u6743\u548c\uff0c\u901a\u8fc7\u51f8\u8c31\u6563\u5ea6\u8861\u91cf\u6a21\u7cca\u96c6\u534a\u5f84\u3002", "result": "\u63d0\u51fa\u7684SCOPE\u4f30\u8ba1\u5668\u80fd\u591f\u5c06\u7279\u5f81\u503c\u975e\u7ebf\u6027\u6536\u7f29\u5230\u6b63\u6807\u91cf\uff0c\u6539\u5584\u4f30\u8ba1\u5668\u7684\u6761\u4ef6\u6570\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u7cbe\u5fc3\u8c03\u6574\u6743\u91cd\u7cfb\u6570\uff0c\u6709\u6548\u6821\u6b63\u8c31\u504f\u5dee\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u53c2\u6570\u8c03\u6574\u65b9\u6848\uff0c\u5728\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u7ade\u4e89\u4f18\u52bf\u3002"}}
{"id": "2511.14206", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14206", "abs": "https://arxiv.org/abs/2511.14206", "authors": ["Alessio Zanga", "Marco Scutari", "Fabio Stella"], "title": "Causal Discovery on Higher-Order Interactions", "comment": "16 pages, 2 figures", "summary": "Causal discovery combines data with knowledge provided by experts to learn the DAG representing the causal relationships between a given set of variables. When data are scarce, bagging is used to measure our confidence in an average DAG obtained by aggregating bootstrapped DAGs. However, the aggregation step has received little attention from the specialized literature: the average DAG is constructed using only the confidence in the individual edges of the bootstrapped DAGs, thus disregarding complex higher-order edge structures. In this paper, we introduce a novel theoretical framework based on higher-order structures and describe a new DAG aggregation algorithm. We perform a simulation study, discussing the advantages and limitations of the proposed approach. Our proposal is both computationally efficient and effective, outperforming state-of-the-art solutions, especially in low sample size regimes and under high dimensionality settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9ad8\u9636\u7ed3\u6784\u7684\u56e0\u679c\u53d1\u73b0\u65b0\u6846\u67b6\u548cDAG\u805a\u5408\u7b97\u6cd5\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u60c5\u51b5\u4e0b\u901a\u8fc7bagging\u65b9\u6cd5\u63d0\u5347\u56e0\u679c\u56fe\u6784\u5efa\u7684\u7f6e\u4fe1\u5ea6\uff0c\u7279\u522b\u5728\u4f4e\u6837\u672c\u91cf\u548c\u9ad8\u7ef4\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u5728\u6570\u636e\u7a00\u7f3a\u65f6\u4f7f\u7528bagging\u6280\u672f\uff0c\u4f46\u805a\u5408\u6b65\u9aa4\u4ec5\u8003\u8651\u5355\u4e2a\u8fb9\u7684\u7f6e\u4fe1\u5ea6\uff0c\u5ffd\u7565\u4e86\u590d\u6742\u7684\u9ad8\u9636\u8fb9\u7ed3\u6784\uff0c\u5bfc\u81f4\u805a\u5408\u6548\u679c\u53d7\u9650\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u9ad8\u9636\u7ed3\u6784\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5f00\u53d1\u65b0\u7684DAG\u805a\u5408\u7b97\u6cd5\uff0c\u901a\u8fc7\u8003\u8651\u590d\u6742\u7684\u9ad8\u9636\u8fb9\u7ed3\u6784\u6765\u6539\u8fdb\u56e0\u679c\u56fe\u7684\u805a\u5408\u8fc7\u7a0b\u3002", "result": "\u6a21\u62df\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u9ad8\u4e14\u6548\u679c\u663e\u8457\uff0c\u5728\u4f4e\u6837\u672c\u91cf\u548c\u9ad8\u7ef4\u8bbe\u7f6e\u4e0b\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u7684\u9ad8\u9636\u7ed3\u6784\u6846\u67b6\u548cDAG\u805a\u5408\u7b97\u6cd5\u4e3a\u56e0\u679c\u53d1\u73b0\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u5de5\u5177\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u7a00\u7f3a\u60c5\u51b5\u4e0b\u80fd\u591f\u66f4\u51c6\u786e\u5730\u6784\u5efa\u56e0\u679c\u56fe\u3002"}}
{"id": "2511.13753", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.13753", "abs": "https://arxiv.org/abs/2511.13753", "authors": ["Feilong Wang", "Fuqiang Liu"], "title": "Robustness of LLM-enabled vehicle trajectory prediction under data security threats", "comment": "20 pages, 2 figures, 11 tables, working paper", "summary": "The integration of large language models (LLMs) into automated driving systems has opened new possibilities for reasoning and decision-making by transforming complex driving contexts into language-understandable representations. Recent studies demonstrate that fine-tuned LLMs can accurately predict vehicle trajectories and lane-change intentions by gathering and transforming data from surrounding vehicles. However, the robustness of such LLM-based prediction models for safety-critical driving systems remains unexplored, despite the increasing concerns about the trustworthiness of LLMs. This study addresses this gap by conducting a systematic vulnerability analysis of LLM-enabled vehicle trajectory prediction. We propose a one-feature differential evolution attack that perturbs a single kinematic feature of surrounding vehicles within the LLM's input prompts under a black-box setting. Experiments on the highD dataset reveal that even minor, physically plausible perturbations can significantly disrupt model outputs, underscoring the susceptibility of LLM-based predictors to adversarial manipulation. Further analyses reveal a trade-off between accuracy and robustness, examine the failure mechanism, and explore potential mitigation solutions. The findings provide the very first insights into adversarial vulnerabilities of LLM-driven automated vehicle models in the context of vehicular interactions and highlight the need for robustness-oriented design in future LLM-based intelligent transportation systems.", "AI": {"tldr": "\u672c\u6587\u5bf9\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u7cfb\u7edf\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u6f0f\u6d1e\u5206\u6790\uff0c\u63d0\u51fa\u5355\u7279\u5f81\u5dee\u5206\u8fdb\u5316\u653b\u51fb\u65b9\u6cd5\uff0c\u53d1\u73b0\u5728\u9ed1\u76d2\u8bbe\u7f6e\u4e0b\u5373\u4f7f\u5fae\u5c0f\u6270\u52a8\u4e5f\u80fd\u663e\u8457\u7834\u574f\u6a21\u578b\u8f93\u51fa\uff0c\u63ed\u793a\u4e86LLM\u9a71\u52a8\u81ea\u52a8\u9a7e\u9a76\u6a21\u578b\u7684\u5b89\u5168\u8106\u5f31\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5fae\u8c03\u540e\u7684LLM\u5728\u9884\u6d4b\u8f66\u8f86\u8f68\u8ff9\u548c\u53d8\u9053\u610f\u56fe\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5728\u5b89\u5168\u5173\u952e\u9a7e\u9a76\u7cfb\u7edf\u4e2d\u7684\u9c81\u68d2\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u7279\u522b\u662f\u8003\u8651\u5230LLM\u53ef\u4fe1\u5ea6\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5355\u7279\u5f81\u5dee\u5206\u8fdb\u5316\u653b\u51fb\u65b9\u6cd5\uff0c\u5728LLM\u8f93\u5165\u63d0\u793a\u4e2d\u6270\u52a8\u5468\u56f4\u8f66\u8f86\u7684\u5355\u4e2a\u8fd0\u52a8\u5b66\u7279\u5f81\uff0c\u91c7\u7528\u9ed1\u76d2\u8bbe\u7f6e\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5728\u9ad8D\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u5fae\u5c0f\u4e14\u7269\u7406\u4e0a\u5408\u7406\u7684\u6270\u52a8\u4e5f\u80fd\u663e\u8457\u7834\u574f\u6a21\u578b\u8f93\u51fa\uff0c\u63ed\u793a\u4e86LLM\u9884\u6d4b\u5668\u5bf9\u5bf9\u6297\u6027\u64cd\u7eb5\u7684\u6613\u611f\u6027\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u63ed\u793a\u4e86\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u63ed\u793aLLM\u9a71\u52a8\u81ea\u52a8\u9a7e\u9a76\u6a21\u578b\u5728\u8f66\u8f86\u4ea4\u4e92\u80cc\u666f\u4e0b\u7684\u5bf9\u6297\u6027\u6f0f\u6d1e\uff0c\u5f3a\u8c03\u4e86\u672a\u6765\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u9700\u8981\u91c7\u7528\u9762\u5411\u9c81\u68d2\u6027\u7684\u8bbe\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2511.13755", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13755", "abs": "https://arxiv.org/abs/2511.13755", "authors": ["Zhe Yang", "Wenrui Li", "Hongtao Chen", "Penghong Wang", "Ruiqin Xiong", "Xiaopeng Fan"], "title": "Adaptive Redundancy Regulation for Balanced Multimodal Information Refinement", "comment": null, "summary": "Multimodal learning aims to improve performance by leveraging data from multiple sources. During joint multimodal training, due to modality bias, the advantaged modality often dominates backpropagation, leading to imbalanced optimization. Existing methods still face two problems: First, the long-term dominance of the dominant modality weakens representation-output coupling in the late stages of training, resulting in the accumulation of redundant information. Second, previous methods often directly and uniformly adjust the gradients of the advantaged modality, ignoring the semantics and directionality between modalities. To address these limitations, we propose Adaptive Redundancy Regulation for Balanced Multimodal Information Refinement (RedReg), which is inspired by information bottleneck principle. Specifically, we construct a redundancy phase monitor that uses a joint criterion of effective gain growth rate and redundancy to trigger intervention only when redundancy is high. Furthermore, we design a co-information gating mechanism to estimate the contribution of the current dominant modality based on cross-modal semantics. When the task primarily relies on a single modality, the suppression term is automatically disabled to preserve modality-specific information. Finally, we project the gradient of the dominant modality onto the orthogonal complement of the joint multimodal gradient subspace and suppress the gradient according to redundancy. Experiments show that our method demonstrates superiority among current major methods in most scenarios. Ablation experiments verify the effectiveness of our method. The code is available at https://github.com/xia-zhe/RedReg.git", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRedReg\u65b9\u6cd5\u89e3\u51b3\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u4f18\u52bf\u6a21\u6001\u4e3b\u5bfc\u5bfc\u81f4\u7684\u4f18\u5316\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u5197\u4f59\u9636\u6bb5\u76d1\u63a7\u548c\u5171\u4fe1\u606f\u95e8\u63a7\u673a\u5236\u81ea\u9002\u5e94\u8c03\u8282\u68af\u5ea6\uff0c\u5728\u591a\u6570\u573a\u666f\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u7531\u4e8e\u6a21\u6001\u504f\u5dee\uff0c\u4f18\u52bf\u6a21\u6001\u5728\u53cd\u5411\u4f20\u64ad\u4e2d\u5360\u636e\u4e3b\u5bfc\u5730\u4f4d\uff0c\u5bfc\u81f4\u4f18\u5316\u4e0d\u5e73\u8861\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a1\uff09\u4f18\u52bf\u6a21\u6001\u957f\u671f\u4e3b\u5bfc\u524a\u5f31\u4e86\u8868\u793a-\u8f93\u51fa\u8026\u5408\uff0c\u5bfc\u81f4\u5197\u4f59\u4fe1\u606f\u79ef\u7d2f\uff1b2\uff09\u76f4\u63a5\u5747\u5300\u8c03\u6574\u4f18\u52bf\u6a21\u6001\u68af\u5ea6\uff0c\u5ffd\u7565\u6a21\u6001\u95f4\u7684\u8bed\u4e49\u548c\u65b9\u5411\u6027\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u5197\u4f59\u8c03\u8282\u65b9\u6cd5RedReg\uff0c\u57fa\u4e8e\u4fe1\u606f\u74f6\u9888\u539f\u7406\uff1a1\uff09\u6784\u5efa\u5197\u4f59\u9636\u6bb5\u76d1\u63a7\u5668\uff0c\u4f7f\u7528\u6709\u6548\u589e\u76ca\u589e\u957f\u7387\u548c\u5197\u4f59\u8054\u5408\u6807\u51c6\u89e6\u53d1\u5e72\u9884\uff1b2\uff09\u8bbe\u8ba1\u5171\u4fe1\u606f\u95e8\u63a7\u673a\u5236\uff0c\u57fa\u4e8e\u8de8\u6a21\u6001\u8bed\u4e49\u4f30\u8ba1\u4f18\u52bf\u6a21\u6001\u8d21\u732e\uff1b3\uff09\u5c06\u4f18\u52bf\u6a21\u6001\u68af\u5ea6\u6295\u5f71\u5230\u8054\u5408\u591a\u6a21\u6001\u68af\u5ea6\u5b50\u7a7a\u95f4\u7684\u6b63\u4ea4\u8865\u7a7a\u95f4\uff0c\u6839\u636e\u5197\u4f59\u5ea6\u6291\u5236\u68af\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5927\u591a\u6570\u573a\u666f\u4e0b\u4f18\u4e8e\u5f53\u524d\u4e3b\u6d41\u65b9\u6cd5\uff0c\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "RedReg\u65b9\u6cd5\u901a\u8fc7\u81ea\u9002\u5e94\u5197\u4f59\u8c03\u8282\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u7684\u4f18\u5316\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6a21\u6001\u7279\u5b9a\u4fe1\u606f\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2511.14537", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.14537", "abs": "https://arxiv.org/abs/2511.14537", "authors": ["Ayham Makhamra", "Yelyzaveta Satynska", "Michael Weselcouch"], "title": "Darts Analysis", "comment": "16 pages, 8 figures", "summary": "In this paper we examine the effectiveness of five mathematical models used to predict the outcomes of amateur darts games. These models not only predict the outcomes at the start of the game, but also update their estimations as the game score changes. The models were trained and tested on a dataset consisting of games played by amateur players involving students, faculty, and staff at Roanoke College. The five models are: the null model, which is based only on the live scores, a logistic regression model, a basic simulation model, a time-adjusted simulation model, and a new variation of the Massey model which updates based on the current score. We evaluate these models using two approaches. First, we compare their Brier scores. Second, we conduct head-to-head comparisons in a betting game in which one model sets the betting odds while the other places bets. In both cases, model performance is assessed not only at the start of the game but also at the start of each round. Across both evaluation methods, the score-dependent Massey model performs the best. We conclude by illustrating how this score-dependent Massey model framework can be adapted to other competitive settings beyond darts.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u4e94\u79cd\u9884\u6d4b\u4e1a\u4f59\u98de\u9556\u6bd4\u8d5b\u7ed3\u679c\u7684\u6570\u5b66\u6a21\u578b\uff0c\u5305\u62ec\u7a7a\u6a21\u578b\u3001\u903b\u8f91\u56de\u5f52\u6a21\u578b\u3001\u57fa\u7840\u6a21\u62df\u6a21\u578b\u3001\u65f6\u95f4\u8c03\u6574\u6a21\u62df\u6a21\u578b\u548c\u57fa\u4e8e\u5f53\u524d\u6bd4\u5206\u66f4\u65b0\u7684Massey\u6a21\u578b\u53d8\u4f53\u3002\u901a\u8fc7Brier\u8bc4\u5206\u548c\u6295\u6ce8\u6e38\u620f\u4e24\u79cd\u65b9\u6cd5\u8bc4\u4f30\uff0c\u5f97\u5206\u4f9d\u8d56\u7684Massey\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u4e0d\u540c\u6570\u5b66\u6a21\u578b\u5728\u9884\u6d4b\u4e1a\u4f59\u98de\u9556\u6bd4\u8d5b\u7ed3\u679c\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u8fd9\u4e9b\u6a21\u578b\u5982\u4f55\u968f\u7740\u6bd4\u8d5b\u6bd4\u5206\u53d8\u5316\u800c\u66f4\u65b0\u9884\u6d4b\u3002", "method": "\u4f7f\u7528\u4e94\u79cd\u6a21\u578b\uff1a\u7a7a\u6a21\u578b\u3001\u903b\u8f91\u56de\u5f52\u6a21\u578b\u3001\u57fa\u7840\u6a21\u62df\u6a21\u578b\u3001\u65f6\u95f4\u8c03\u6574\u6a21\u62df\u6a21\u578b\u548c\u5f97\u5206\u4f9d\u8d56\u7684Massey\u6a21\u578b\u3002\u901a\u8fc7Brier\u8bc4\u5206\u548c\u6295\u6ce8\u6e38\u620f\u4e24\u79cd\u65b9\u6cd5\u8fdb\u884c\u8bc4\u4f30\uff0c\u4e0d\u4ec5\u8bc4\u4f30\u6bd4\u8d5b\u5f00\u59cb\u65f6\u7684\u9884\u6d4b\uff0c\u8fd8\u8bc4\u4f30\u6bcf\u8f6e\u5f00\u59cb\u65f6\u7684\u9884\u6d4b\u3002", "result": "\u5728\u4e24\u79cd\u8bc4\u4f30\u65b9\u6cd5\u4e2d\uff0c\u5f97\u5206\u4f9d\u8d56\u7684Massey\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u5f97\u5206\u4f9d\u8d56\u7684Massey\u6a21\u578b\u6846\u67b6\u53ef\u4ee5\u9002\u5e94\u98de\u9556\u4ee5\u5916\u7684\u5176\u4ed6\u7ade\u4e89\u73af\u5883\u3002"}}
{"id": "2511.14018", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14018", "abs": "https://arxiv.org/abs/2511.14018", "authors": ["Minghu Wang", "Shuliang Zhao", "Yuanyuan Zhao", "Hongxia Xu"], "title": "ALEX:A Light Editing-knowledge Extractor", "comment": null, "summary": "The static nature of knowledge within Large Language Models (LLMs) makes it difficult for them to adapt to evolving information, rendering knowledge editing a critical task. However, existing methods struggle with challenges of scalability and retrieval efficiency, particularly when handling complex, multi-hop questions that require multi-step reasoning. To address these challenges, this paper introduces ALEX (A Light Editing-knowledge Extractor), a lightweight knowledge editing framework. The core innovation of ALEX is its hierarchical memory architecture, which organizes knowledge updates (edits) into semantic clusters. This design fundamentally reduces retrieval complexity from a linear O(N) to a highly scalable O(K+N/C). Furthermore, the framework integrates an Inferential Query Synthesis (IQS) module to bridge the semantic gap between queries and facts , and a Dynamic Evidence Adjudication (DEA) engine that executes an efficient two-stage retrieval process. Experiments on the MQUAKE benchmark demonstrate that ALEX significantly improves both the accuracy of multi-hop answers (MultiHop-ACC) and the reliability of reasoning paths (HopWise-ACC). It also reduces the required search space by over 80% , presenting a promising path toward building scalable, efficient, and accurate knowledge editing systems.", "AI": {"tldr": "ALEX\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u77e5\u8bc6\u7f16\u8f91\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u5185\u5b58\u67b6\u6784\u5c06\u77e5\u8bc6\u66f4\u65b0\u7ec4\u7ec7\u6210\u8bed\u4e49\u7c07\uff0c\u5c06\u68c0\u7d22\u590d\u6742\u5ea6\u4eceO(N)\u964d\u4f4e\u5230O(K+N/C)\uff0c\u5e76\u96c6\u6210\u63a8\u7406\u67e5\u8be2\u5408\u6210\u6a21\u5757\u548c\u52a8\u6001\u8bc1\u636e\u88c1\u51b3\u5f15\u64ce\uff0c\u663e\u8457\u63d0\u9ad8\u591a\u8df3\u95ee\u7b54\u51c6\u786e\u6027\u548c\u63a8\u7406\u8def\u5f84\u53ef\u9760\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u77e5\u8bc6\u662f\u9759\u6001\u7684\uff0c\u96be\u4ee5\u9002\u5e94\u4e0d\u65ad\u53d8\u5316\u7684\u4fe1\u606f\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u9700\u8981\u591a\u6b65\u63a8\u7406\u7684\u590d\u6742\u591a\u8df3\u95ee\u9898\u65f6\u9762\u4e34\u53ef\u6269\u5c55\u6027\u548c\u68c0\u7d22\u6548\u7387\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faALEX\u6846\u67b6\uff0c\u91c7\u7528\u5206\u5c42\u5185\u5b58\u67b6\u6784\u7ec4\u7ec7\u77e5\u8bc6\u7f16\u8f91\uff0c\u96c6\u6210\u63a8\u7406\u67e5\u8be2\u5408\u6210\u6a21\u5757\u5f25\u5408\u67e5\u8be2\u4e0e\u4e8b\u5b9e\u4e4b\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\uff0c\u4ee5\u53ca\u52a8\u6001\u8bc1\u636e\u88c1\u51b3\u5f15\u64ce\u6267\u884c\u4e24\u9636\u6bb5\u68c0\u7d22\u8fc7\u7a0b\u3002", "result": "\u5728MQUAKE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cALEX\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u8df3\u7b54\u6848\u7684\u51c6\u786e\u6027\u548c\u63a8\u7406\u8def\u5f84\u7684\u53ef\u9760\u6027\uff0c\u540c\u65f6\u5c06\u6240\u9700\u641c\u7d22\u7a7a\u95f4\u51cf\u5c11\u4e8680%\u4ee5\u4e0a\u3002", "conclusion": "ALEX\u4e3a\u6784\u5efa\u53ef\u6269\u5c55\u3001\u9ad8\u6548\u548c\u51c6\u786e\u7684\u77e5\u8bc6\u7f16\u8f91\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u6761\u6709\u524d\u666f\u7684\u8def\u5f84\u3002"}}
{"id": "2511.13759", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13759", "abs": "https://arxiv.org/abs/2511.13759", "authors": ["Han Wang", "Deyi Ji", "Junyu Lu", "Lanyun Zhu", "Hailong Zhang", "Haiyang Wu", "Liqun Liu", "Peng Shu", "Roy Ka-Wei Lee"], "title": "Multi-Agent VLMs Guided Self-Training with PNU Loss for Low-Resource Offensive Content Detection", "comment": "8 pages, 4 figures, Fortieth AAAI Conference on Artificial Intelligence (AAAI-26)", "summary": "Accurate detection of offensive content on social media demands high-quality labeled data; however, such data is often scarce due to the low prevalence of offensive instances and the high cost of manual annotation. To address this low-resource challenge, we propose a self-training framework that leverages abundant unlabeled data through collaborative pseudo-labeling. Starting with a lightweight classifier trained on limited labeled data, our method iteratively assigns pseudo-labels to unlabeled instances with the support of Multi-Agent Vision-Language Models (MA-VLMs). Un-labeled data on which the classifier and MA-VLMs agree are designated as the Agreed-Unknown set, while conflicting samples form the Disagreed-Unknown set. To enhance label reliability, MA-VLMs simulate dual perspectives, moderator and user, capturing both regulatory and subjective viewpoints. The classifier is optimized using a novel Positive-Negative-Unlabeled (PNU) loss, which jointly exploits labeled, Agreed-Unknown, and Disagreed-Unknown data while mitigating pseudo-label noise. Experiments on benchmark datasets demonstrate that our framework substantially outperforms baselines under limited supervision and approaches the performance of large-scale models", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u8bad\u7ec3\u6846\u67b6\uff0c\u5229\u7528\u591a\u667a\u80fd\u4f53\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u534f\u4f5c\u4f2a\u6807\u6ce8\uff0c\u901a\u8fc7PNU\u635f\u5931\u51fd\u6570\u4f18\u5316\u5206\u7c7b\u5668\uff0c\u5728\u6709\u9650\u76d1\u7763\u4e0b\u663e\u8457\u63d0\u5347\u793e\u4ea4\u5a92\u4f53\u5192\u72af\u6027\u5185\u5bb9\u68c0\u6d4b\u6027\u80fd", "motivation": "\u793e\u4ea4\u5a92\u4f53\u5192\u72af\u6027\u5185\u5bb9\u68c0\u6d4b\u9700\u8981\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u4f46\u7531\u4e8e\u5192\u72af\u6027\u5b9e\u4f8b\u7a00\u5c11\u4e14\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u9ad8\uff0c\u6807\u6ce8\u6570\u636e\u5f80\u5f80\u7a00\u7f3a\uff0c\u9700\u8981\u89e3\u51b3\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\u7684\u68c0\u6d4b\u6311\u6218", "method": "\u4f7f\u7528\u8f7b\u91cf\u7ea7\u5206\u7c7b\u5668\u548c\u591a\u667a\u80fd\u4f53\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8fed\u4ee3\u4f2a\u6807\u6ce8\uff0c\u5f62\u6210\u4e00\u81f4\u672a\u77e5\u96c6\u548c\u5206\u6b67\u672a\u77e5\u96c6\uff0c\u901a\u8fc7\u6a21\u62df\u76d1\u7ba1\u8005\u548c\u7528\u6237\u53cc\u89c6\u89d2\u589e\u5f3a\u6807\u7b7e\u53ef\u9760\u6027\uff0c\u91c7\u7528PNU\u635f\u5931\u51fd\u6570\u8054\u5408\u4f18\u5316", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u6709\u9650\u76d1\u7763\u4e0b\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63a5\u8fd1\u5927\u89c4\u6a21\u6a21\u578b\u7684\u6027\u80fd", "conclusion": "\u6240\u63d0\u51fa\u7684\u81ea\u8bad\u7ec3\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\u7684\u5192\u72af\u6027\u5185\u5bb9\u68c0\u6d4b\u95ee\u9898\uff0c\u901a\u8fc7\u534f\u4f5c\u4f2a\u6807\u6ce8\u548c\u566a\u58f0\u6291\u5236\u5b9e\u73b0\u4e86\u4f18\u8d8a\u6027\u80fd"}}
{"id": "2511.14052", "categories": ["cs.AI", "cs.CE", "stat.AP", "stat.OT"], "pdf": "https://arxiv.org/pdf/2511.14052", "abs": "https://arxiv.org/abs/2511.14052", "authors": ["Amirreza Mehrabi", "Jason W. Morphew", "Breejha Quezada", "N. Sanjay Rebello"], "title": "Making Evidence Actionable in Adaptive Learning", "comment": null, "summary": "Adaptive learning often diagnoses precisely yet intervenes weakly, yielding help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted micro-interventions. The adaptive learning algorithm contains three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted constraint for time and redundancy, and diversity as protection against overfitting to a single resource. We formalize intervention assignment as a binary integer program with constraints for coverage, time, difficulty windows informed by ability estimates, prerequisites encoded by a concept matrix, and anti-redundancy enforced through diversity. Greedy selection serves low-richness and tight-latency regimes, gradient-based relaxation serves rich repositories, and a hybrid method transitions along a richness-latency frontier. In simulation and in an introductory physics deployment with one thousand two hundred four students, both solvers achieved full skill coverage for essentially all learners within bounded watch time. The gradient-based method reduced redundant coverage by approximately twelve percentage points relative to greedy and harmonized difficulty across slates, while greedy delivered comparable adequacy with lower computational cost in scarce settings. Slack variables localized missing content and supported targeted curation, sustaining sufficiency across subgroups. The result is a tractable and auditable controller that closes the diagnostic-pedagogical loop and delivers equitable, load-aware personalization at classroom scale.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7531\u6559\u5e08\u4e3b\u5bfc\u7684\u53cd\u9988\u5faa\u73af\u7cfb\u7edf\uff0c\u5c06\u6982\u5ff5\u7ea7\u8bc4\u4f30\u8bc1\u636e\u8f6c\u5316\u4e3a\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u5fae\u5e72\u9884\u63aa\u65bd\uff0c\u901a\u8fc7\u4e09\u4e2a\u4fdd\u969c\u673a\u5236\uff08\u5145\u5206\u6027\u3001\u6ce8\u610f\u529b\u9884\u7b97\u3001\u591a\u6837\u6027\uff09\u5b9e\u73b0\u81ea\u9002\u5e94\u5b66\u4e60\u3002", "motivation": "\u81ea\u9002\u5e94\u5b66\u4e60\u7cfb\u7edf\u901a\u5e38\u8bca\u65ad\u51c6\u786e\u4f46\u5e72\u9884\u6548\u679c\u5f31\uff0c\u5bfc\u81f4\u5e2e\u52a9\u65f6\u673a\u4e0d\u5f53\u6216\u5185\u5bb9\u4e0d\u5339\u914d\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6709\u6548\u95ed\u5408\u8bca\u65ad\u4e0e\u6559\u5b66\u5faa\u73af\u7684\u7cfb\u7edf\u3002", "method": "\u5c06\u5e72\u9884\u5206\u914d\u5f62\u5f0f\u5316\u4e3a\u4e8c\u5143\u6574\u6570\u89c4\u5212\uff0c\u5305\u542b\u8986\u76d6\u5ea6\u3001\u65f6\u95f4\u3001\u96be\u5ea6\u7a97\u53e3\u3001\u5148\u51b3\u6761\u4ef6\u6982\u5ff5\u77e9\u9635\u548c\u53cd\u5197\u4f59\u7ea6\u675f\u3002\u91c7\u7528\u8d2a\u5fc3\u9009\u62e9\u3001\u57fa\u4e8e\u68af\u5ea6\u7684\u677e\u5f1b\u65b9\u6cd5\u548c\u6df7\u5408\u65b9\u6cd5\u6765\u89e3\u51b3\u4e0d\u540c\u8d44\u6e90\u4e30\u5bcc\u5ea6\u548c\u5ef6\u8fdf\u8981\u6c42\u3002", "result": "\u5728\u6a21\u62df\u548c1204\u540d\u5b66\u751f\u7684\u7269\u7406\u8bfe\u7a0b\u90e8\u7f72\u4e2d\uff0c\u4e24\u79cd\u6c42\u89e3\u5668\u90fd\u80fd\u5728\u6709\u9650\u89c2\u770b\u65f6\u95f4\u5185\u4e3a\u51e0\u4e4e\u6240\u6709\u5b66\u4e60\u8005\u5b9e\u73b0\u5b8c\u6574\u7684\u6280\u80fd\u8986\u76d6\u3002\u57fa\u4e8e\u68af\u5ea6\u7684\u65b9\u6cd5\u6bd4\u8d2a\u5fc3\u65b9\u6cd5\u51cf\u5c11\u7ea612%\u7684\u5197\u4f59\u8986\u76d6\uff0c\u5e76\u5728\u8d44\u6e90\u7a00\u7f3a\u73af\u5883\u4e0b\u4ee5\u8f83\u4f4e\u8ba1\u7b97\u6210\u672c\u5b9e\u73b0\u76f8\u5f53\u7684\u5145\u5206\u6027\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u8ffd\u8e2a\u548c\u53ef\u5ba1\u8ba1\u7684\u63a7\u5236\u5668\uff0c\u80fd\u591f\u95ed\u5408\u8bca\u65ad-\u6559\u5b66\u5faa\u73af\uff0c\u5728\u8bfe\u5802\u89c4\u6a21\u4e0a\u5b9e\u73b0\u516c\u5e73\u3001\u8d1f\u8f7d\u611f\u77e5\u7684\u4e2a\u6027\u5316\u6559\u5b66\u3002"}}
{"id": "2511.13766", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13766", "abs": "https://arxiv.org/abs/2511.13766", "authors": ["Kaizheng Wang", "Fabio Cuzzolin", "David Moens", "Hans Hallez"], "title": "Credal Ensemble Distillation for Uncertainty Quantification", "comment": "An extended version for Credal Ensemble Distillation for Uncertainty Quantification, which has been accepted for publication at AAAI 2026", "summary": "Deep ensembles (DE) have emerged as a powerful approach for quantifying predictive uncertainty and distinguishing its aleatoric and epistemic components, thereby enhancing model robustness and reliability. However, their high computational and memory costs during inference pose significant challenges for wide practical deployment. To overcome this issue, we propose credal ensemble distillation (CED), a novel framework that compresses a DE into a single model, CREDIT, for classification tasks. Instead of a single softmax probability distribution, CREDIT predicts class-wise probability intervals that define a credal set, a convex set of probability distributions, for uncertainty quantification. Empirical results on out-of-distribution detection benchmarks demonstrate that CED achieves superior or comparable uncertainty estimation compared to several existing baselines, while substantially reducing inference overhead compared to DE.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86credal ensemble distillation (CED)\u6846\u67b6\uff0c\u5c06\u6df1\u5ea6\u96c6\u6210\u538b\u7f29\u4e3a\u5355\u4e2a\u6a21\u578bCREDIT\uff0c\u901a\u8fc7\u9884\u6d4b\u7c7b\u522b\u6982\u7387\u533a\u95f4\u6765\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u663e\u8457\u964d\u4f4e\u63a8\u7406\u5f00\u9500\u3002", "motivation": "\u6df1\u5ea6\u96c6\u6210\u867d\u7136\u80fd\u6709\u6548\u91cf\u5316\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u5176\u9ad8\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u9650\u5236\u4e86\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u63d0\u51facredal ensemble distillation (CED)\u6846\u67b6\uff0c\u5c06\u6df1\u5ea6\u96c6\u6210\u538b\u7f29\u4e3a\u5355\u4e2a\u6a21\u578bCREDIT\uff0c\u9884\u6d4b\u7c7b\u522b\u6982\u7387\u533a\u95f4\u800c\u975e\u5355\u4e00\u6982\u7387\u5206\u5e03\u3002", "result": "\u5728\u5206\u5e03\u5916\u68c0\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCED\u5b9e\u73b0\u4e86\u4f18\u4e8e\u6216\u53ef\u6bd4\u73b0\u6709\u57fa\u7ebf\u7684uncertainty\u4f30\u8ba1\u6027\u80fd\uff0c\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u63a8\u7406\u5f00\u9500\u3002", "conclusion": "CED\u6846\u67b6\u80fd\u6709\u6548\u538b\u7f29\u6df1\u5ea6\u96c6\u6210\uff0c\u5728\u4fdd\u6301uncertainty\u4f30\u8ba1\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u4ef7\u503c\u3002"}}
{"id": "2511.14214", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14214", "abs": "https://arxiv.org/abs/2511.14214", "authors": ["Pattaraphon Kenny Wongchamcharoen", "Paul Glasserman"], "title": "Do Large Language Models (LLMs) Understand Chronology?", "comment": "47 pages", "summary": "Large language models (LLMs) are increasingly used in finance and economics, where prompt-based attempts against look-ahead bias implicitly assume that models understand chronology. We test this fundamental question with a series of chronological ordering tasks with increasing complexities over facts the model already knows from pre-training. Our tasks cover (1) chronological ordering, (2) conditional sorting (filter, then order), and (3) anachronism detection. We evaluate GPT-4.1, Claude-3.7 Sonnet, with and without Extended Thinking (ET), and GPT-5 across multiple reasoning-effort settings. Across models, Exact match rate drops sharply as sequences lengthen even while rank correlations stay high as LLMs largely preserve local order but struggle to maintain a single globally consistent timeline. In conditional sorting, most failures stem from the filtering step rather than the ordering step, but GPT-5 and Claude-3.7 Sonnet with Extended Thinking outshine normal models significantly. Lastly, anachronism detection is found to be the easiest task for the LLMs but performance still declines with increasingly overlapping timelines or entities. Overall, our main contribution is showing that allocating explicit reasoning budget helps with chronological ordering with GPT-5 at medium/high reasoning effort achieving flawless ordering at all lengths and perfect conditional sorting (both self-filtered and given-subset), whereas low/minimal effort degrades with longer lists, mirroring earlier models. Our findings delineate limits of current LLMs on chronological tasks, providing insights into task complexity, and demonstrate scenarios in which reasoning helps. These patterns are important for the real-time application of LLMs in finance. We release all code and evaluation templates to support full reproducibility.", "AI": {"tldr": "\u672c\u6587\u6d4b\u8bd5\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u95f4\u987a\u5e8f\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u7406\u89e3\u65f6\u95f4\u987a\u5e8f\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u957f\u5e8f\u5217\u65f6\u3002GPT-5\u548cClaude-3.7 Sonnet\u5728\u663e\u5f0f\u63a8\u7406\u9884\u7b97\u4e0b\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u548c\u7ecf\u6d4e\u5b66\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u6d4b\u8bd5\u6a21\u578b\u662f\u5426\u771f\u6b63\u7406\u89e3\u65f6\u95f4\u987a\u5e8f\uff0c\u4ee5\u907f\u514d\u524d\u77bb\u6027\u504f\u5dee\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u7cfb\u5217\u65f6\u95f4\u987a\u5e8f\u6392\u5e8f\u4efb\u52a1\uff0c\u5305\u62ec\u65f6\u95f4\u987a\u5e8f\u6392\u5e8f\u3001\u6761\u4ef6\u6392\u5e8f\uff08\u5148\u7b5b\u9009\u540e\u6392\u5e8f\uff09\u548c\u65f6\u4ee3\u9519\u8bef\u68c0\u6d4b\uff0c\u8bc4\u4f30\u4e86GPT-4.1\u3001Claude-3.7 Sonnet\u548cGPT-5\u5728\u4e0d\u540c\u63a8\u7406\u8bbe\u7f6e\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u968f\u7740\u5e8f\u5217\u957f\u5ea6\u589e\u52a0\uff0c\u7cbe\u786e\u5339\u914d\u7387\u663e\u8457\u4e0b\u964d\uff0c\u4f46\u7b49\u7ea7\u76f8\u5173\u6027\u4fdd\u6301\u8f83\u9ad8\u3002\u6761\u4ef6\u6392\u5e8f\u4e2d\u7684\u5931\u8d25\u4e3b\u8981\u6765\u81ea\u7b5b\u9009\u6b65\u9aa4\u3002GPT-5\u5728\u4e2d/\u9ad8\u63a8\u7406\u52aa\u529b\u4e0b\u5728\u6240\u6709\u957f\u5ea6\u4e0a\u5b9e\u73b0\u4e86\u5b8c\u7f8e\u6392\u5e8f\u548c\u6761\u4ef6\u6392\u5e8f\u3002", "conclusion": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u95f4\u987a\u5e8f\u4efb\u52a1\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u663e\u5f0f\u63a8\u7406\u9884\u7b97\u6709\u52a9\u4e8e\u6539\u5584\u6027\u80fd\uff0c\u8fd9\u5bf9\u91d1\u878d\u9886\u57df\u7684\u5b9e\u65f6\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.13780", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.13780", "abs": "https://arxiv.org/abs/2511.13780", "authors": ["Nihal Mehta"], "title": "Self-Attention as Distributional Projection: A Unified Interpretation of Transformer Architecture", "comment": "17 pages, 0 figures. This work provides a mathematical interpretation of self-attention mechanisms in Transformers through distributional semantics principles", "summary": "This paper presents a mathematical interpretation of self-attention by connecting it to distributional semantics principles. We show that self-attention emerges from projecting corpus-level co-occurrence statistics into sequence context. Starting from the co-occurrence matrix underlying GloVe embeddings, we demonstrate how the projection naturally captures contextual influence, with the query-key-value mechanism arising as the natural asymmetric extension for modeling directional relationships. Positional encodings and multi-head attention then follow as structured refinements of this same projection principle. Our analysis demonstrates that the Transformer architecture's particular algebraic form follows from these projection principles rather than being an arbitrary design choice.", "AI": {"tldr": "\u672c\u6587\u4ece\u5206\u5e03\u8bed\u4e49\u5b66\u89d2\u5ea6\u5bf9\u81ea\u6ce8\u610f\u529b\u673a\u5236\u8fdb\u884c\u6570\u5b66\u89e3\u91ca\uff0c\u8bc1\u660e\u5176\u6e90\u4e8e\u5c06\u8bed\u6599\u5e93\u7ea7\u5171\u73b0\u7edf\u8ba1\u6295\u5f71\u5230\u5e8f\u5217\u4e0a\u4e0b\u6587\u4e2d\u3002", "motivation": "\u4e3a\u81ea\u6ce8\u610f\u529b\u673a\u5236\u63d0\u4f9b\u6570\u5b66\u7406\u8bba\u57fa\u7840\uff0c\u8bc1\u660eTransformer\u67b6\u6784\u7684\u4ee3\u6570\u5f62\u5f0f\u6e90\u4e8e\u6295\u5f71\u539f\u7406\u800c\u975e\u4efb\u610f\u8bbe\u8ba1\u9009\u62e9\u3002", "method": "\u4eceGloVe\u5d4c\u5165\u7684\u5171\u73b0\u77e9\u9635\u51fa\u53d1\uff0c\u5c55\u793a\u6295\u5f71\u5982\u4f55\u81ea\u7136\u6355\u83b7\u4e0a\u4e0b\u6587\u5f71\u54cd\uff0cquery-key-value\u673a\u5236\u4f5c\u4e3a\u5efa\u6a21\u65b9\u5411\u5173\u7cfb\u7684\u81ea\u7136\u975e\u5bf9\u79f0\u6269\u5c55\u3002", "result": "\u8bc1\u660e\u4f4d\u7f6e\u7f16\u7801\u548c\u591a\u5934\u6ce8\u610f\u529b\u90fd\u662f\u540c\u4e00\u6295\u5f71\u539f\u7406\u7684\u7ed3\u6784\u5316\u6539\u8fdb\uff0c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u4ece\u8bed\u6599\u7ea7\u5171\u73b0\u7edf\u8ba1\u6295\u5f71\u5230\u5e8f\u5217\u4e0a\u4e0b\u6587\u4e2d\u81ea\u7136\u4ea7\u751f\u3002", "conclusion": "Transformer\u67b6\u6784\u7684\u7279\u5b9a\u4ee3\u6570\u5f62\u5f0f\u9075\u5faa\u8fd9\u4e9b\u6295\u5f71\u539f\u7406\uff0c\u800c\u975e\u4efb\u610f\u7684\u8bbe\u8ba1\u9009\u62e9\uff0c\u4e3a\u81ea\u6ce8\u610f\u529b\u63d0\u4f9b\u4e86\u6570\u5b66\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.14219", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2511.14219", "abs": "https://arxiv.org/abs/2511.14219", "authors": ["Kumud Tripathi", "Aditya Srinivas Menon", "Aman Gaurav", "Raj Prakash Gohil", "Pankaj Wasnik"], "title": "Listen Like a Teacher: Mitigating Whisper Hallucinations using Adaptive Layer Attention and Knowledge Distillation", "comment": "Accepted at AAAI 2026 - Main Technical Track", "summary": "The Whisper model, an open-source automatic speech recognition system, is widely adopted for its strong performance across multilingual and zero-shot settings. However, it frequently suffers from hallucination errors, especially under noisy acoustic conditions. Previous works to reduce hallucinations in Whisper-style ASR systems have primarily focused on audio preprocessing or post-processing of transcriptions to filter out erroneous content. However, modifications to the Whisper model itself remain largely unexplored to mitigate hallucinations directly. To address this challenge, we present a two-stage architecture that first enhances encoder robustness through Adaptive Layer Attention (ALA) and further suppresses hallucinations using a multi-objective knowledge distillation (KD) framework. In the first stage, ALA groups encoder layers into semantically coherent blocks via inter-layer correlation analysis. A learnable multi-head attention module then fuses these block representations, enabling the model to jointly exploit low- and high-level features for more robust encoding. In the second stage, our KD framework trains the student model on noisy audio to align its semantic and attention distributions with a teacher model processing clean inputs. Our experiments on noisy speech benchmarks show notable reductions in hallucinations and word error rates, while preserving performance on clean speech. Together, ALA and KD offer a principled strategy to improve Whisper's reliability under real-world noisy conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u67b6\u6784\u6765\u51cf\u5c11Whisper\u6a21\u578b\u5728\u566a\u58f0\u73af\u5883\u4e0b\u7684\u5e7b\u89c9\u9519\u8bef\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u81ea\u9002\u5e94\u5c42\u6ce8\u610f\u529b\u589e\u5f3a\u7f16\u7801\u5668\u9c81\u68d2\u6027\uff0c\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u591a\u76ee\u6807\u77e5\u8bc6\u84b8\u998f\u6291\u5236\u5e7b\u89c9\u3002", "motivation": "Whisper\u6a21\u578b\u5728\u566a\u58f0\u58f0\u5b66\u6761\u4ef6\u4e0b\u7ecf\u5e38\u51fa\u73b0\u5e7b\u89c9\u9519\u8bef\uff0c\u800c\u4e4b\u524d\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u97f3\u9891\u9884\u5904\u7406\u6216\u8f6c\u5f55\u540e\u5904\u7406\uff0c\u5bf9\u6a21\u578b\u672c\u8eab\u7684\u4fee\u6539\u63a2\u7d22\u4e0d\u8db3\u3002", "method": "1. \u81ea\u9002\u5e94\u5c42\u6ce8\u610f\u529b(ALA)\uff1a\u901a\u8fc7\u5c42\u95f4\u76f8\u5173\u6027\u5206\u6790\u5c06\u7f16\u7801\u5668\u5c42\u5206\u7ec4\u4e3a\u8bed\u4e49\u8fde\u8d2f\u5757\uff0c\u4f7f\u7528\u53ef\u5b66\u4e60\u591a\u5934\u6ce8\u610f\u529b\u878d\u5408\u5757\u8868\u793a\uff1b2. \u591a\u76ee\u6807\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff1a\u5728\u566a\u58f0\u97f3\u9891\u4e0a\u8bad\u7ec3\u5b66\u751f\u6a21\u578b\uff0c\u4f7f\u5176\u8bed\u4e49\u548c\u6ce8\u610f\u529b\u5206\u5e03\u4e0e\u5904\u7406\u5e72\u51c0\u8f93\u5165\u7684\u6559\u5e08\u6a21\u578b\u5bf9\u9f50\u3002", "result": "\u5728\u566a\u58f0\u8bed\u97f3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u51cf\u5c11\u4e86\u5e7b\u89c9\u548c\u8bcd\u9519\u8bef\u7387\uff0c\u540c\u65f6\u5728\u5e72\u51c0\u8bed\u97f3\u4e0a\u4fdd\u6301\u4e86\u6027\u80fd\u3002", "conclusion": "ALA\u548cKD\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7b56\u7565\u6765\u6539\u5584Whisper\u5728\u771f\u5b9e\u4e16\u754c\u566a\u58f0\u6761\u4ef6\u4e0b\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2511.14248", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14248", "abs": "https://arxiv.org/abs/2511.14248", "authors": ["Hongju Lee", "Youngjun Park", "Jisun An", "Dongman Lee"], "title": "Enhancing Regional Airbnb Trend Forecasting Using LLM-Based Embeddings of Accessibility and Human Mobility", "comment": "Accepted at ASONAM 2025", "summary": "The expansion of short-term rental platforms, such as Airbnb, has significantly disrupted local housing markets, often leading to increased rental prices and housing affordability issues. Accurately forecasting regional Airbnb market trends can thus offer critical insights for policymakers and urban planners aiming to mitigate these impacts. This study proposes a novel time-series forecasting framework to predict three key Airbnb indicators -- Revenue, Reservation Days, and Number of Reservations -- at the regional level. Using a sliding-window approach, the model forecasts trends 1 to 3 months ahead. Unlike prior studies that focus on individual listings at fixed time points, our approach constructs regional representations by integrating listing features with external contextual factors such as urban accessibility and human mobility. We convert structured tabular data into prompt-based inputs for a Large Language Model (LLM), producing comprehensive regional embeddings. These embeddings are then fed into advanced time-series models (RNN, LSTM, Transformer) to better capture complex spatio-temporal dynamics. Experiments on Seoul's Airbnb dataset show that our method reduces both average RMSE and MAE by approximately 48% compared to conventional baselines, including traditional statistical and machine learning models. Our framework not only improves forecasting accuracy but also offers practical insights for detecting oversupplied regions and supporting data-driven urban policy decisions.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u533a\u57df\u5c42\u9762\u7684Airbnb\u5173\u952e\u6307\u6807\uff08\u6536\u5165\u3001\u9884\u8ba2\u5929\u6570\u548c\u9884\u8ba2\u6570\u91cf\uff09\uff0c\u901a\u8fc7\u7ed3\u5408\u623f\u6e90\u7279\u5f81\u4e0e\u5916\u90e8\u73af\u5883\u56e0\u7d20\u751f\u6210\u533a\u57df\u5d4c\u5165\uff0c\u4f7f\u7528LLM\u548c\u5148\u8fdb\u65f6\u5e8f\u6a21\u578b\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u77ed\u671f\u79df\u8d41\u5e73\u53f0\uff08\u5982Airbnb\uff09\u7684\u6269\u5f20\u663e\u8457\u6270\u4e71\u4e86\u5f53\u5730\u4f4f\u623f\u5e02\u573a\uff0c\u5bfc\u81f4\u79df\u91d1\u4e0a\u6da8\u548c\u4f4f\u623f\u8d1f\u62c5\u80fd\u529b\u95ee\u9898\u3002\u51c6\u786e\u9884\u6d4b\u533a\u57dfAirbnb\u5e02\u573a\u8d8b\u52bf\u53ef\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u548c\u57ce\u5e02\u89c4\u5212\u8005\u63d0\u4f9b\u5173\u952e\u89c1\u89e3\u4ee5\u51cf\u8f7b\u8fd9\u4e9b\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u6ed1\u52a8\u7a97\u53e3\u65b9\u6cd5\u9884\u6d4b1-3\u4e2a\u6708\u8d8b\u52bf\uff0c\u6784\u5efa\u533a\u57df\u8868\u793a\u65f6\u6574\u5408\u623f\u6e90\u7279\u5f81\u4e0e\u5916\u90e8\u73af\u5883\u56e0\u7d20\uff08\u5982\u57ce\u5e02\u53ef\u8fbe\u6027\u548c\u4eba\u5458\u6d41\u52a8\u6027\uff09\uff0c\u5c06\u7ed3\u6784\u5316\u8868\u683c\u6570\u636e\u8f6c\u6362\u4e3a\u57fa\u4e8e\u63d0\u793a\u7684LLM\u8f93\u5165\u4ee5\u751f\u6210\u5168\u9762\u533a\u57df\u5d4c\u5165\uff0c\u7136\u540e\u8f93\u5165\u5230\u5148\u8fdb\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\uff08RNN\u3001LSTM\u3001Transformer\uff09\u4e2d\u3002", "result": "\u5728\u9996\u5c14Airbnb\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u57fa\u7ebf\uff08\u5305\u62ec\u4f20\u7edf\u7edf\u8ba1\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff09\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5c06\u5e73\u5747RMSE\u548cMAE\u964d\u4f4e\u4e86\u7ea648%\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u8fd8\u4e3a\u68c0\u6d4b\u4f9b\u5e94\u8fc7\u5269\u533a\u57df\u548c\u652f\u6301\u6570\u636e\u9a71\u52a8\u7684\u57ce\u5e02\u653f\u7b56\u51b3\u7b56\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2511.13809", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.13809", "abs": "https://arxiv.org/abs/2511.13809", "authors": ["Emanuel Covaci", "Fabian Galis", "Radu Balan", "Daniela Zaharie", "Darian Onchis"], "title": "ScoresActivation: A New Activation Function for Model Agnostic Global Explainability by Design", "comment": "Paper submitted to ECAI 2025 Conference", "summary": "Understanding the decision of large deep learning models is a critical challenge for building transparent and trustworthy systems. Although the current post hoc explanation methods offer valuable insights into feature importance, they are inherently disconnected from the model training process, limiting their faithfulness and utility. In this work, we introduce a novel differentiable approach to global explainability by design, integrating feature importance estimation directly into model training. Central to our method is the ScoresActivation function, a feature-ranking mechanism embedded within the learning pipeline. This integration enables models to prioritize features according to their contribution to predictive performance in a differentiable and end-to-end trainable manner. Evaluations across benchmark datasets show that our approach yields globally faithful, stable feature rankings aligned with SHAP values and ground-truth feature importance, while maintaining high predictive performance. Moreover, feature scoring is 150 times faster than the classical SHAP method, requiring only 2 seconds during training compared to SHAP's 300 seconds for feature ranking in the same configuration. Our method also improves classification accuracy by 11.24% with 10 features (5 relevant) and 29.33% with 16 features (5 relevant, 11 irrelevant), demonstrating robustness to irrelevant inputs. This work bridges the gap between model accuracy and interpretability, offering a scalable framework for inherently explainable machine learning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53ef\u5fae\u5206\u5168\u5c40\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u76f4\u63a5\u96c6\u6210\u7279\u5f81\u91cd\u8981\u6027\u4f30\u8ba1\u6765\u5b9e\u73b0\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528ScoresActivation\u51fd\u6570\u4f5c\u4e3a\u7279\u5f81\u6392\u5e8f\u673a\u5236\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u4ee5\u53ef\u5fae\u5206\u548c\u7aef\u5230\u7aef\u53ef\u8bad\u7ec3\u7684\u65b9\u5f0f\u6839\u636e\u7279\u5f81\u5bf9\u9884\u6d4b\u6027\u80fd\u7684\u8d21\u732e\u8fdb\u884c\u4f18\u5148\u7ea7\u6392\u5e8f\u3002", "motivation": "\u5f53\u524d\u7684\u4e8b\u540e\u89e3\u91ca\u65b9\u6cd5\u4e0e\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u8131\u8282\uff0c\u9650\u5236\u4e86\u5176\u5fe0\u5b9e\u6027\u548c\u5b9e\u7528\u6027\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u5c06\u7279\u5f81\u91cd\u8981\u6027\u4f30\u8ba1\u76f4\u63a5\u96c6\u6210\u5230\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u65b9\u6cd5\uff0c\u4ee5\u5f25\u5408\u6a21\u578b\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u63d0\u51faScoresActivation\u51fd\u6570\u4f5c\u4e3a\u7279\u5f81\u6392\u5e8f\u673a\u5236\uff0c\u5d4c\u5165\u5230\u5b66\u4e60\u6d41\u7a0b\u4e2d\u3002\u8fd9\u79cd\u65b9\u6cd5\u4f7f\u6a21\u578b\u80fd\u591f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4ee5\u53ef\u5fae\u5206\u548c\u7aef\u5230\u7aef\u53ef\u8bad\u7ec3\u7684\u65b9\u5f0f\u4f18\u5148\u8003\u8651\u5bf9\u9884\u6d4b\u6027\u80fd\u8d21\u732e\u6700\u5927\u7684\u7279\u5f81\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u4ea7\u751f\u4e86\u5168\u5c40\u5fe0\u5b9e\u3001\u7a33\u5b9a\u7684\u7279\u5f81\u6392\u5e8f\uff0c\u4e0eSHAP\u503c\u548c\u771f\u5b9e\u7279\u5f81\u91cd\u8981\u6027\u4e00\u81f4\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u9884\u6d4b\u6027\u80fd\u3002\u7279\u5f81\u8bc4\u5206\u901f\u5ea6\u6bd4\u7ecf\u5178SHAP\u65b9\u6cd5\u5feb150\u500d\uff0c\u8bad\u7ec3\u4ec5\u97002\u79d2\u3002\u572810\u4e2a\u7279\u5f81\uff085\u4e2a\u76f8\u5173\uff09\u548c16\u4e2a\u7279\u5f81\uff085\u4e2a\u76f8\u5173\uff0c11\u4e2a\u65e0\u5173\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u5206\u522b\u63d0\u9ad8\u4e8611.24%\u548c29.33%\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5f25\u5408\u4e86\u6a21\u578b\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u56fa\u6709\u53ef\u89e3\u91ca\u7684\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6846\u67b6\u3002"}}
{"id": "2511.13880", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.13880", "abs": "https://arxiv.org/abs/2511.13880", "authors": ["Saleh Momeni", "Changnan Xiao", "Bing Liu"], "title": "AnaCP: Toward Upper-Bound Continual Learning via Analytic Contrastive Projection", "comment": null, "summary": "This paper studies the problem of class-incremental learning (CIL), a core setting within continual learning where a model learns a sequence of tasks, each containing a distinct set of classes. Traditional CIL methods, which do not leverage pre-trained models (PTMs), suffer from catastrophic forgetting (CF) due to the need to incrementally learn both feature representations and the classifier. The integration of PTMs into CIL has recently led to efficient approaches that treat the PTM as a fixed feature extractor combined with analytic classifiers, achieving state-of-the-art performance. However, they still face a major limitation: the inability to continually adapt feature representations to best suit the CIL tasks, leading to suboptimal performance. To address this, we propose AnaCP (Analytic Contrastive Projection), a novel method that preserves the efficiency of analytic classifiers while enabling incremental feature adaptation without gradient-based training, thereby eliminating the CF caused by gradient updates. Our experiments show that AnaCP not only outperforms existing baselines but also achieves the accuracy level of joint training, which is regarded as the upper bound of CIL.", "AI": {"tldr": "AnaCP\u662f\u4e00\u79cd\u65b0\u9896\u7684\u7c7b\u589e\u91cf\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u5bf9\u6bd4\u6295\u5f71\u5728\u4fdd\u6301\u5206\u6790\u5206\u7c7b\u5668\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u589e\u91cf\u7279\u5f81\u9002\u5e94\uff0c\u65e0\u9700\u57fa\u4e8e\u68af\u5ea6\u7684\u8bad\u7ec3\uff0c\u4ece\u800c\u907f\u514d\u707e\u96be\u6027\u9057\u5fd8\u3002", "motivation": "\u4f20\u7edf\u7c7b\u589e\u91cf\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u800c\u73b0\u6709\u57fa\u4e8e\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5\u867d\u7136\u9ad8\u6548\uff0c\u4f46\u65e0\u6cd5\u6301\u7eed\u9002\u5e94\u7279\u5f81\u8868\u793a\uff0c\u5bfc\u81f4\u6027\u80fd\u6b21\u4f18\u3002", "method": "\u63d0\u51faAnaCP\u65b9\u6cd5\uff0c\u7ed3\u5408\u5206\u6790\u5206\u7c7b\u5668\u7684\u6548\u7387\u548c\u5bf9\u6bd4\u6295\u5f71\u6280\u672f\uff0c\u5b9e\u73b0\u65e0\u9700\u68af\u5ea6\u8bad\u7ec3\u7684\u7279\u5f81\u589e\u91cf\u9002\u5e94\u3002", "result": "\u5b9e\u9a8c\u8868\u660eAnaCP\u4e0d\u4ec5\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u800c\u4e14\u8fbe\u5230\u4e86\u8054\u5408\u8bad\u7ec3\u7684\u51c6\u786e\u7387\u6c34\u5e73\uff0c\u8fd9\u662f\u7c7b\u589e\u91cf\u5b66\u4e60\u7684\u7406\u8bba\u4e0a\u754c\u3002", "conclusion": "AnaCP\u6210\u529f\u89e3\u51b3\u4e86\u7c7b\u589e\u91cf\u5b66\u4e60\u4e2d\u7684\u7279\u5f81\u9002\u5e94\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u63a5\u8fd1\u7406\u8bba\u4e0a\u754c\u7684\u6027\u80fd\u3002"}}
{"id": "2511.14476", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14476", "abs": "https://arxiv.org/abs/2511.14476", "authors": ["Dalia Ali", "Dora Zhao", "Allison Koenecke", "Orestis Papakyriakopoulos"], "title": "Operationalizing Pluralistic Values in Large Language Model Alignment Reveals Trade-offs in Safety, Inclusivity, and Model Behavior", "comment": null, "summary": "Although large language models (LLMs) are increasingly trained using human feedback for safety and alignment with human values, alignment decisions often overlook human social diversity. This study examines how incorporating pluralistic values affects LLM behavior by systematically evaluating demographic variation and design parameters in the alignment pipeline. We collected alignment data from US and German participants (N = 1,095, 27,375 ratings) who rated LLM responses across five dimensions: Toxicity, Emotional Awareness (EA), Sensitivity, Stereotypical Bias, and Helpfulness. We fine-tuned multiple Large Language Models and Large Reasoning Models using preferences from different social groups while varying rating scales, disagreement handling methods, and optimization techniques. The results revealed systematic demographic effects: male participants rated responses 18% less toxic than female participants; conservative and Black participants rated responses 27.9% and 44% more emotionally aware than liberal and White participants, respectively. Models fine-tuned on group-specific preferences exhibited distinct behaviors. Technical design choices showed strong effects: the preservation of rater disagreement achieved roughly 53% greater toxicity reduction than majority voting, and 5-point scales yielded about 22% more reduction than binary formats; and Direct Preference Optimization (DPO) consistently outperformed Group Relative Policy Optimization (GRPO) in multi-value optimization. These findings represent a preliminary step in answering a critical question: How should alignment balance expert-driven and user-driven signals to ensure both safety and fair representation?", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5728LLM\u5bf9\u9f50\u8fc7\u7a0b\u4e2d\u878d\u5165\u591a\u5143\u793e\u4f1a\u4ef7\u503c\u89c2\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\u4eba\u53e3\u7edf\u8ba1\u5dee\u5f02\u548c\u8bbe\u8ba1\u53c2\u6570\uff0c\u53d1\u73b0\u4e0d\u540c\u793e\u4f1a\u7fa4\u4f53\u5bf9\u6a21\u578b\u54cd\u5e94\u7684\u8bc4\u4ef7\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u6280\u672f\u8bbe\u8ba1\u9009\u62e9\u5bf9\u6a21\u578b\u884c\u4e3a\u6709\u663e\u8457\u5f71\u54cd\u3002", "motivation": "\u5f53\u524dLLM\u5bf9\u9f50\u51b3\u7b56\u5f80\u5f80\u5ffd\u89c6\u4eba\u7c7b\u793e\u4f1a\u7684\u591a\u6837\u6027\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u7eb3\u5165\u591a\u5143\u4ef7\u503c\u89c2\u6765\u5f71\u54cdLLM\u884c\u4e3a\uff0c\u4ee5\u5e73\u8861\u5b89\u5168\u6027\u4e0e\u516c\u5e73\u4ee3\u8868\u6027\u3002", "method": "\u4ece\u7f8e\u56fd\u548c\u5fb7\u56fd\u6536\u96c6\u4e861,095\u540d\u53c2\u4e0e\u8005\u768427,375\u4e2a\u8bc4\u5206\uff0c\u8bc4\u4f30LLM\u54cd\u5e94\u5728\u6bd2\u6027\u3001\u60c5\u611f\u610f\u8bc6\u3001\u654f\u611f\u6027\u3001\u523b\u677f\u504f\u89c1\u548c\u5e2e\u52a9\u6027\u4e94\u4e2a\u7ef4\u5ea6\u3002\u4f7f\u7528\u4e0d\u540c\u793e\u4f1a\u7fa4\u4f53\u7684\u504f\u597d\u5fae\u8c03\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5927\u63a8\u7406\u6a21\u578b\uff0c\u540c\u65f6\u53d8\u5316\u8bc4\u5206\u5c3a\u5ea6\u3001\u5206\u6b67\u5904\u7406\u65b9\u6cd5\u548c\u4f18\u5316\u6280\u672f\u3002", "result": "\u53d1\u73b0\u7cfb\u7edf\u6027\u4eba\u53e3\u7edf\u8ba1\u6548\u5e94\uff1a\u7537\u6027\u53c2\u4e0e\u8005\u5bf9\u6bd2\u6027\u7684\u8bc4\u5206\u6bd4\u5973\u6027\u4f4e18%\uff1b\u4fdd\u5b88\u6d3e\u548c\u9ed1\u4eba\u53c2\u4e0e\u8005\u5bf9\u60c5\u611f\u610f\u8bc6\u7684\u8bc4\u5206\u5206\u522b\u6bd4\u81ea\u7531\u6d3e\u548c\u767d\u4eba\u53c2\u4e0e\u8005\u9ad827.9%\u548c44%\u3002\u6280\u672f\u8bbe\u8ba1\u9009\u62e9\u663e\u793a\u5f3a\u70c8\u5f71\u54cd\uff1a\u4fdd\u7559\u8bc4\u5206\u8005\u5206\u6b67\u6bd4\u591a\u6570\u6295\u7968\u5b9e\u73b0\u7ea653%\u66f4\u5927\u7684\u6bd2\u6027\u51cf\u5c11\uff1b5\u70b9\u91cf\u8868\u6bd4\u4e8c\u5143\u683c\u5f0f\u4ea7\u751f\u7ea622%\u66f4\u591a\u51cf\u5c11\uff1bDPO\u5728\u591a\u503c\u4f18\u5316\u4e2d\u59cb\u7ec8\u4f18\u4e8eGRPO\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u56de\u7b54\u5173\u952e\u95ee\u9898\u63d0\u4f9b\u4e86\u521d\u6b65\u6b65\u9aa4\uff1a\u5bf9\u9f50\u5e94\u5982\u4f55\u5e73\u8861\u4e13\u5bb6\u9a71\u52a8\u548c\u7528\u6237\u9a71\u52a8\u4fe1\u53f7\uff0c\u4ee5\u786e\u4fdd\u5b89\u5168\u6027\u548c\u516c\u5e73\u4ee3\u8868\u6027\u3002"}}
{"id": "2511.14057", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14057", "abs": "https://arxiv.org/abs/2511.14057", "authors": ["Xianghe Liu", "Jiajia Liu", "Chuxian Xu", "Minghan Wang", "Hongbo Peng", "Tao Sun", "Jiaqi Xu"], "title": "A Machine Learning-Based Multimodal Framework for Wearable Sensor-Based Archery Action Recognition and Stress Estimation", "comment": null, "summary": "In precision sports such as archery, athletes' performance depends on both biomechanical stability and psychological resilience. Traditional motion analysis systems are often expensive and intrusive, limiting their use in natural training environments. To address this limitation, we propose a machine learning-based multimodal framework that integrates wearable sensor data for simultaneous action recognition and stress estimation. Using a self-developed wrist-worn device equipped with an accelerometer and photoplethysmography (PPG) sensor, we collected synchronized motion and physiological data during real archery sessions. For motion recognition, we introduce a novel feature--Smoothed Differential Acceleration (SmoothDiff)--and employ a Long Short-Term Memory (LSTM) model to identify motion phases, achieving 96.8% accuracy and 95.9% F1-score. For stress estimation, we extract heart rate variability (HRV) features from PPG signals and apply a Multi-Layer Perceptron (MLP) classifier, achieving 80% accuracy in distinguishing high- and low-stress levels. The proposed framework demonstrates that integrating motion and physiological sensing can provide meaningful insights into athletes' technical and mental states. This approach offers a foundation for developing intelligent, real-time feedback systems for training optimization in archery and other precision sports.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u591a\u6a21\u6001\u6846\u67b6\uff0c\u96c6\u6210\u53ef\u7a7f\u6234\u4f20\u611f\u5668\u6570\u636e\u540c\u65f6\u8fdb\u884c\u52a8\u4f5c\u8bc6\u522b\u548c\u538b\u529b\u4f30\u8ba1\uff0c\u7528\u4e8e\u5c04\u7bad\u7b49\u7cbe\u51c6\u8fd0\u52a8\u8bad\u7ec3\u4f18\u5316\u3002", "motivation": "\u4f20\u7edf\u8fd0\u52a8\u5206\u6790\u7cfb\u7edf\u6602\u8d35\u4e14\u4fb5\u5165\u6027\u5f3a\uff0c\u9650\u5236\u4e86\u5728\u81ea\u7136\u8bad\u7ec3\u73af\u5883\u4e2d\u7684\u4f7f\u7528\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u5b9e\u7528\u7684\u8fd0\u52a8\u5458\u6280\u672f\u548c\u5fc3\u7406\u72b6\u6001\u76d1\u6d4b\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u81ea\u7814\u8155\u6234\u8bbe\u5907\u91c7\u96c6\u52a0\u901f\u5ea6\u548cPPG\u6570\u636e\uff0c\u91c7\u7528LSTM\u6a21\u578b\u8fdb\u884c\u52a8\u4f5c\u9636\u6bb5\u8bc6\u522b\uff08\u4f7f\u7528SmoothDiff\u7279\u5f81\uff09\uff0cMLP\u5206\u7c7b\u5668\u8fdb\u884c\u538b\u529b\u6c34\u5e73\u5206\u7c7b\uff08\u57fa\u4e8eHRV\u7279\u5f81\uff09\u3002", "result": "\u52a8\u4f5c\u8bc6\u522b\u51c6\u786e\u738796.8%\uff0cF1\u5206\u657095.9%\uff1b\u538b\u529b\u4f30\u8ba1\u51c6\u786e\u738780%\u3002", "conclusion": "\u96c6\u6210\u8fd0\u52a8\u548c\u751f\u7406\u611f\u77e5\u53ef\u4e3a\u8fd0\u52a8\u5458\u6280\u672f\u548c\u5fc3\u7406\u72b6\u6001\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u6d1e\u5bdf\uff0c\u4e3a\u5f00\u53d1\u667a\u80fd\u5b9e\u65f6\u53cd\u9988\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.14084", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14084", "abs": "https://arxiv.org/abs/2511.14084", "authors": ["Iden Kalemaj", "Luca Melis", "Maxime Boucher", "Ilya Mironov", "Saeed Mahloujifar"], "title": "Observational Auditing of Label Privacy", "comment": null, "summary": "Differential privacy (DP) auditing is essential for evaluating privacy guarantees in machine learning systems. Existing auditing methods, however, pose a significant challenge for large-scale systems since they require modifying the training dataset -- for instance, by injecting out-of-distribution canaries or removing samples from training. Such interventions on the training data pipeline are resource-intensive and involve considerable engineering overhead. We introduce a novel observational auditing framework that leverages the inherent randomness of data distributions, enabling privacy evaluation without altering the original dataset. Our approach extends privacy auditing beyond traditional membership inference to protected attributes, with labels as a special case, addressing a key gap in existing techniques. We provide theoretical foundations for our method and perform experiments on Criteo and CIFAR-10 datasets that demonstrate its effectiveness in auditing label privacy guarantees. This work opens new avenues for practical privacy auditing in large-scale production environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5dee\u5206\u9690\u79c1\u5ba1\u8ba1\u6846\u67b6\uff0c\u65e0\u9700\u4fee\u6539\u8bad\u7ec3\u6570\u636e\u96c6\u5373\u53ef\u8bc4\u4f30\u9690\u79c1\u4fdd\u8bc1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u7cfb\u7edf\u4e2d\u8d44\u6e90\u5bc6\u96c6\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5dee\u5206\u9690\u79c1\u5ba1\u8ba1\u65b9\u6cd5\u9700\u8981\u4fee\u6539\u8bad\u7ec3\u6570\u636e\u96c6\uff08\u5982\u6ce8\u5165\u5f02\u5e38\u6570\u636e\u6216\u79fb\u9664\u6837\u672c\uff09\uff0c\u5728\u5927\u89c4\u6a21\u7cfb\u7edf\u4e2d\u8d44\u6e90\u5bc6\u96c6\u4e14\u5de5\u7a0b\u5f00\u9500\u5927\uff0c\u9700\u8981\u4e00\u79cd\u65e0\u9700\u5e72\u9884\u6570\u636e\u7ba1\u9053\u7684\u5ba1\u8ba1\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u6570\u636e\u5206\u5e03\u7684\u56fa\u6709\u968f\u673a\u6027\uff0c\u5f00\u53d1\u89c2\u5bdf\u6027\u5ba1\u8ba1\u6846\u67b6\uff0c\u65e0\u9700\u4fee\u6539\u539f\u59cb\u6570\u636e\u96c6\uff0c\u5c06\u9690\u79c1\u5ba1\u8ba1\u6269\u5c55\u5230\u4fdd\u62a4\u5c5e\u6027\u548c\u6807\u7b7e\u9690\u79c1\u3002", "result": "\u5728Criteo\u548cCIFAR-10\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5ba1\u8ba1\u6807\u7b7e\u9690\u79c1\u4fdd\u8bc1\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5927\u89c4\u6a21\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u5b9e\u7528\u9690\u79c1\u5ba1\u8ba1\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2511.14102", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.14102", "abs": "https://arxiv.org/abs/2511.14102", "authors": ["Wenfeng Wang", "Jiacheng Liu", "Xiaofeng Hou", "Xinfeng Xia", "Peng Tang", "Mingxuan Zhang", "Chao Li", "Minyi Guo"], "title": "MoE-SpeQ: Speculative Quantized Decoding with Proactive Expert Prefetching and Offloading for Mixture-of-Experts", "comment": null, "summary": "The immense memory requirements of state-of-the-art Mixture-of-Experts (MoE) models present a significant challenge for inference, often exceeding the capacity of a single accelerator. While offloading experts to host memory is a common solution, it introduces a severe I/O bottleneck over the PCIe bus, as the data-dependent nature of expert selection places these synchronous transfers directly on the critical path of execution, crippling performance.\n  This paper argues that the I/O bottleneck can be overcome by trading a small amount of cheap, on-device computation to hide the immense cost of data movement. We present MoE-SpeQ, a new inference system built on a novel co-design of speculative execution and expert offloading. MoE-SpeQ employs a small, on-device draft model to predict the sequence of required experts for future tokens. This foresight enables a runtime orchestrator to prefetch these experts from host memory, effectively overlapping the expensive I/O with useful computation and hiding the latency from the critical path. To maximize performance, an adaptive governor, guided by an Amortization Roofline Model, dynamically tunes the speculation strategy to the underlying hardware. Our evaluation on memory-constrained devices shows that for the Phi-MoE model, MoE-SpeQ achieves at most 2.34x speedup over the state-of-the-art offloading framework. Our work establishes a new, principled approach for managing data-dependent memory access in resource-limited environments, making MoE inference more accessible on commodity hardware.", "AI": {"tldr": "MoE-SpeQ\u901a\u8fc7\u63a8\u6d4b\u6267\u884c\u548c\u4e13\u5bb6\u5378\u8f7d\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u4f7f\u7528\u5c0f\u578b\u8349\u7a3f\u6a21\u578b\u9884\u6d4b\u672a\u6765token\u6240\u9700\u7684\u4e13\u5bb6\u5e8f\u5217\uff0c\u901a\u8fc7\u9884\u53d6\u4e13\u5bb6\u6765\u9690\u85cfI/O\u5ef6\u8fdf\uff0c\u5728\u5185\u5b58\u53d7\u9650\u8bbe\u5907\u4e0a\u5b9e\u73b0\u6700\u9ad82.34\u500d\u52a0\u901f\u3002", "motivation": "\u89e3\u51b3MoE\u6a21\u578b\u63a8\u7406\u65f6\u56e0\u4e13\u5bb6\u9009\u62e9\u7684\u6570\u636e\u4f9d\u8d56\u6027\u5bfc\u81f4\u7684PCIe\u603b\u7ebfI/O\u74f6\u9888\u95ee\u9898\uff0c\u4f7fMoE\u63a8\u7406\u5728\u5546\u54c1\u786c\u4ef6\u4e0a\u66f4\u52a0\u53ef\u884c\u3002", "method": "\u91c7\u7528\u63a8\u6d4b\u6267\u884c\u548c\u4e13\u5bb6\u5378\u8f7d\u534f\u540c\u8bbe\u8ba1\uff0c\u4f7f\u7528\u5c0f\u578b\u8349\u7a3f\u6a21\u578b\u9884\u6d4b\u672a\u6765token\u7684\u4e13\u5bb6\u9700\u6c42\uff0c\u8fd0\u884c\u65f6\u7f16\u6392\u5668\u9884\u53d6\u4e13\u5bb6\uff0c\u81ea\u9002\u5e94\u8c03\u8282\u5668\u6839\u636e\u644a\u9500\u5c4b\u9876\u6a21\u578b\u52a8\u6001\u8c03\u6574\u63a8\u6d4b\u7b56\u7565\u3002", "result": "\u5728\u5185\u5b58\u53d7\u9650\u8bbe\u5907\u4e0a\uff0c\u5bf9Phi-MoE\u6a21\u578b\u5b9e\u73b0\u4e86\u6700\u9ad82.34\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u5378\u8f7d\u6846\u67b6\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "MoE-SpeQ\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7ba1\u7406\u6570\u636e\u4f9d\u8d56\u6027\u5185\u5b58\u8bbf\u95ee\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u4f7fMoE\u63a8\u7406\u5728\u5546\u54c1\u786c\u4ef6\u4e0a\u66f4\u52a0\u53ef\u884c\u3002"}}
{"id": "2511.14117", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14117", "abs": "https://arxiv.org/abs/2511.14117", "authors": ["Agamdeep Singh", "Ashish Tiwari", "Hosein Hasanbeig", "Priyanshu Gupta"], "title": "Soft-Label Training Preserves Epistemic Uncertainty", "comment": null, "summary": "Many machine learning tasks involve inherent subjectivity, where annotators naturally provide varied labels. Standard practice collapses these label distributions into single labels, aggregating diverse human judgments into point estimates. We argue that this approach is epistemically misaligned for ambiguous data--the annotation distribution itself should be regarded as the ground truth. Training on collapsed single labels forces models to express false confidence on fundamentally ambiguous cases, creating a misalignment between model certainty and the diversity of human perception. We demonstrate empirically that soft-label training, which treats annotation distributions as ground truth, preserves epistemic uncertainty. Across both vision and NLP tasks, soft-label training achieves 32% lower KL divergence from human annotations and 61% stronger correlation between model and annotation entropy, while matching the accuracy of hard-label training. Our work repositions annotation distributions from noisy signals to be aggregated away, to faithful representations of epistemic uncertainty that models should learn to reproduce.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3b\u5f20\u5728\u4e3b\u89c2\u6027\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u4e2d\uff0c\u5e94\u5c06\u6807\u6ce8\u5206\u5e03\u89c6\u4e3a\u771f\u5b9e\u6807\u7b7e\u800c\u975e\u805a\u5408\u4e3a\u5355\u4e00\u6807\u7b7e\uff0c\u901a\u8fc7\u8f6f\u6807\u7b7e\u8bad\u7ec3\u4fdd\u7559\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u89c6\u89c9\u548cNLP\u4efb\u52a1\u4e2d\u663e\u8457\u6539\u5584\u4e86\u6a21\u578b\u4e0e\u4eba\u7c7b\u6807\u6ce8\u7684\u4e00\u81f4\u6027\u3002", "motivation": "\u6807\u51c6\u5b9e\u8df5\u5c06\u591a\u6837\u7684\u4eba\u7c7b\u6807\u6ce8\u805a\u5408\u4e3a\u5355\u4e00\u6807\u7b7e\uff0c\u8fd9\u5728\u6a21\u7cca\u6570\u636e\u4e0a\u5b58\u5728\u8ba4\u77e5\u504f\u5dee\uff0c\u8feb\u4f7f\u6a21\u578b\u5728\u672c\u8d28\u4e0a\u6a21\u7cca\u7684\u60c5\u51b5\u4e0b\u8868\u8fbe\u865a\u5047\u7684\u7f6e\u4fe1\u5ea6\uff0c\u9020\u6210\u6a21\u578b\u786e\u5b9a\u6027\u4e0e\u4eba\u7c7b\u611f\u77e5\u591a\u6837\u6027\u4e4b\u95f4\u7684\u9519\u4f4d\u3002", "method": "\u91c7\u7528\u8f6f\u6807\u7b7e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5c06\u6807\u6ce8\u5206\u5e03\u89c6\u4e3a\u771f\u5b9e\u6807\u7b7e\u8fdb\u884c\u8bad\u7ec3\uff0c\u800c\u4e0d\u662f\u5c06\u591a\u6837\u7684\u4eba\u7c7b\u5224\u65ad\u805a\u5408\u4e3a\u70b9\u4f30\u8ba1\u3002", "result": "\u5728\u89c6\u89c9\u548cNLP\u4efb\u52a1\u4e2d\uff0c\u8f6f\u6807\u7b7e\u8bad\u7ec3\u5b9e\u73b0\u4e8632%\u66f4\u4f4e\u7684KL\u6563\u5ea6\uff08\u4e0e\u4eba\u7c7b\u6807\u6ce8\u76f8\u6bd4\uff09\u548c61%\u66f4\u5f3a\u7684\u6a21\u578b\u4e0e\u6807\u6ce8\u71b5\u76f8\u5173\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u786c\u6807\u7b7e\u8bad\u7ec3\u76f8\u5f53\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u6807\u6ce8\u5206\u5e03\u5e94\u91cd\u65b0\u5b9a\u4f4d\u4e3a\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u7684\u5fe0\u5b9e\u8868\u793a\uff0c\u6a21\u578b\u5e94\u5b66\u4e60\u91cd\u73b0\u8fd9\u79cd\u4e0d\u786e\u5b9a\u6027\uff0c\u800c\u4e0d\u662f\u5c06\u5176\u4f5c\u4e3a\u9700\u8981\u805a\u5408\u7684\u566a\u58f0\u4fe1\u53f7\u3002"}}
{"id": "2511.14218", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14218", "abs": "https://arxiv.org/abs/2511.14218", "authors": ["Xinlei Xiong", "Wenbo Hu", "Shuxun Zhou", "Kaifeng Bi", "Lingxi Xie", "Ying Liu", "Richang Hong", "Qi Tian"], "title": "Bridging the Gap Between Bayesian Deep Learning and Ensemble Weather Forecasts", "comment": null, "summary": "Weather forecasting is fundamentally challenged by the chaotic nature of the atmosphere, necessitating probabilistic approaches to quantify uncertainty. While traditional ensemble prediction (EPS) addresses this through computationally intensive simulations, recent advances in Bayesian Deep Learning (BDL) offer a promising but often disconnected alternative. We bridge these paradigms through a unified hybrid Bayesian Deep Learning framework for ensemble weather forecasting that explicitly decomposes predictive uncertainty into epistemic and aleatoric components, learned via variational inference and a physics-informed stochastic perturbation scheme modeling flow-dependent atmospheric dynamics, respectively. We further establish a unified theoretical framework that rigorously connects BDL and EPS, providing formal theorems that decompose total predictive uncertainty into epistemic and aleatoric components under the hybrid BDL framework. We validate our framework on the large-scale 40-year ERA5 reanalysis dataset (1979-2019) with 0.25\u00b0 spatial resolution. Experimental results show that our method not only improves forecast accuracy and yields better-calibrated uncertainty quantification but also achieves superior computational efficiency compared to state-of-the-art probabilistic diffusion models. We commit to making our code open-source upon acceptance of this paper.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u7684\u6df7\u5408\u8d1d\u53f6\u65af\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u5929\u6c14\u9884\u62a5\u4e0d\u786e\u5b9a\u6027\u5206\u89e3\u4e3a\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u548c\u5076\u7136\u4e0d\u786e\u5b9a\u6027\uff0c\u901a\u8fc7\u53d8\u5206\u63a8\u7406\u548c\u7269\u7406\u4fe1\u606f\u968f\u673a\u6270\u52a8\u65b9\u6848\u5206\u522b\u5b66\u4e60\uff0c\u5728ERA5\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u5929\u6c14\u9884\u62a5\u9762\u4e34\u5927\u6c14\u6df7\u6c8c\u7279\u6027\u7684\u6311\u6218\uff0c\u4f20\u7edf\u96c6\u5408\u9884\u62a5\u65b9\u6cd5\u8ba1\u7b97\u5bc6\u96c6\uff0c\u800c\u8d1d\u53f6\u65af\u6df1\u5ea6\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u4f46\u5f80\u5f80\u8131\u8282\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u9700\u8981\u6865\u63a5\u8fd9\u4e24\u79cd\u8303\u5f0f\u3002", "method": "\u901a\u8fc7\u6df7\u5408\u8d1d\u53f6\u65af\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u7528\u53d8\u5206\u63a8\u7406\u5b66\u4e60\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u7269\u7406\u4fe1\u606f\u968f\u673a\u6270\u52a8\u65b9\u6848\u5efa\u6a21\u6d41\u4f9d\u8d56\u7684\u5927\u6c14\u52a8\u529b\u5b66\u6765\u5b66\u4e60\u5076\u7136\u4e0d\u786e\u5b9a\u6027\uff0c\u5efa\u7acb\u4e86BDL\u4e0eEPS\u7684\u7edf\u4e00\u7406\u8bba\u6846\u67b6\u3002", "result": "\u5728ERA5\u518d\u5206\u6790\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9884\u62a5\u51c6\u786e\u6027\uff0c\u63d0\u4f9b\u4e86\u66f4\u597d\u6821\u51c6\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u800c\u4e14\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6982\u7387\u6269\u6563\u6a21\u578b\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u8d1d\u53f6\u65af\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u6210\u529f\u6865\u63a5\u4e86\u4f20\u7edf\u96c6\u5408\u9884\u62a5\u548c\u8d1d\u53f6\u65af\u6df1\u5ea6\u5b66\u4e60\uff0c\u4e3a\u5929\u6c14\u9884\u62a5\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u3001\u66f4\u9ad8\u6548\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u3002"}}
{"id": "2511.14229", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14229", "abs": "https://arxiv.org/abs/2511.14229", "authors": ["Jim Broadbent", "Felix Cohen", "Frederik Hvilsh\u00f8j", "Eric Landau", "Eren Sasoglu"], "title": "EBind: a practical approach to space binding", "comment": null, "summary": "We simplify space binding by focusing on two core components, a single encoder per modality and high-quality data; enabling training state-of-the-art models on a single GPU in a few hours as opposed to multiple days. We present EBind, an Easy, data-centric, and parameter-efficient method to Bind the embedding spaces of multiple contrastive models. We demonstrate that a simple 1.8B-parameter image-text-video-audio-3D model can outperform models 4 to 17x the size. The key to achieving this is a carefully curated dataset of three complementary data sources: i) 6.7M fully-automated multimodal quintuples sourced via SOTA retrieval models, ii) 1M diverse, semi-automated triples annotated by humans as negative, partial, or positive matches, and iii) 3.4M pre-existing captioned data items. We use 13 different evaluations to demonstrate the value of each data source. Due to limitations with existing benchmarks, we further introduce the first high-quality, consensus-annotated zero-shot classification benchmark between audio and PCs. In contrast to related work, we will open-source our code, model weights, and datasets.", "AI": {"tldr": "EBind\u662f\u4e00\u79cd\u7b80\u5355\u3001\u6570\u636e\u9a71\u52a8\u4e14\u53c2\u6570\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u7ed1\u5b9a\u591a\u6a21\u6001\u5bf9\u6bd4\u6a21\u578b\u7684\u5d4c\u5165\u7a7a\u95f4\uff0c\u4ec5\u9700\u5355\u4e2aGPU\u5728\u51e0\u5c0f\u65f6\u5185\u8bad\u7ec3\u51fa\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u800c\u975e\u4f20\u7edf\u9700\u8981\u7684\u6570\u5929\u3002", "motivation": "\u7b80\u5316\u7a7a\u95f4\u7ed1\u5b9a\u8fc7\u7a0b\uff0c\u901a\u8fc7\u4e13\u6ce8\u4e8e\u5355\u4e00\u7f16\u7801\u5668\u548c\u9ad8\u8d28\u91cf\u6570\u636e\uff0c\u5b9e\u73b0\u53c2\u6570\u6548\u7387\u548c\u591a\u6a21\u6001\u878d\u5408\u3002", "method": "\u4f7f\u75281.8B\u53c2\u6570\u7684\u591a\u6a21\u6001\u6a21\u578b\uff08\u56fe\u50cf-\u6587\u672c-\u89c6\u9891-\u97f3\u9891-3D\uff09\uff0c\u7ed3\u5408\u4e09\u4e2a\u4e92\u8865\u6570\u636e\u6e90\uff1a670\u4e07\u5168\u81ea\u52a8\u591a\u6a21\u6001\u4e94\u5143\u7ec4\u3001100\u4e07\u4eba\u5de5\u6807\u6ce8\u4e09\u5143\u7ec4\u548c340\u4e07\u73b0\u6709\u6807\u6ce8\u6570\u636e\u9879\u3002", "result": "\u8be5\u6a21\u578b\u572813\u4e2a\u4e0d\u540c\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u53c2\u6570\u89c4\u6a21\u59274-17\u500d\u7684\u6a21\u578b\uff0c\u5e76\u5f15\u5165\u4e86\u9996\u4e2a\u9ad8\u8d28\u91cf\u3001\u5171\u8bc6\u6807\u6ce8\u7684\u97f3\u9891\u4e0e\u70b9\u4e91\u96f6\u6837\u672c\u5206\u7c7b\u57fa\u51c6\u3002", "conclusion": "EBind\u65b9\u6cd5\u8bc1\u660e\u4e86\u901a\u8fc7\u7cbe\u5fc3\u7b56\u5212\u7684\u6570\u636e\u96c6\u548c\u53c2\u6570\u6548\u7387\u8bbe\u8ba1\uff0c\u53ef\u4ee5\u5728\u8f83\u5c0f\u6a21\u578b\u89c4\u6a21\u4e0b\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u5c06\u5f00\u6e90\u4ee3\u7801\u3001\u6a21\u578b\u6743\u91cd\u548c\u6570\u636e\u96c6\u3002"}}
{"id": "2511.14265", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14265", "abs": "https://arxiv.org/abs/2511.14265", "authors": ["Rui Zhang", "Chao Li", "Kezhong Liu", "Chen Wang", "Bolong Zheng", "Hongbo Jiang"], "title": "Unified Multimodal Vessel Trajectory Prediction with Explainable Navigation Intention", "comment": null, "summary": "Vessel trajectory prediction is fundamental to intelligent maritime systems. Within this domain, short-term prediction of rapid behavioral changes in complex maritime environments has established multimodal trajectory prediction (MTP) as a promising research area. However, existing vessel MTP methods suffer from limited scenario applicability and insufficient explainability. To address these challenges, we propose a unified MTP framework incorporating explainable navigation intentions, which we classify into sustained and transient categories. Our method constructs sustained intention trees from historical trajectories and models dynamic transient intentions using a Conditional Variational Autoencoder (CVAE), while using a non-local attention mechanism to maintain global scenario consistency. Experiments on real Automatic Identification System (AIS) datasets demonstrates our method's broad applicability across diverse scenarios, achieving significant improvements in both ADE and FDE. Furthermore, our method improves explainability by explicitly revealing the navigational intentions underlying each predicted trajectory.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u53ef\u89e3\u91ca\u5bfc\u822a\u610f\u56fe\u7684\u7edf\u4e00\u591a\u6a21\u6001\u8f68\u8ff9\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u6301\u7eed\u610f\u56fe\u6811\u548c\u77ac\u6001\u610f\u56fe\u5efa\u6a21\uff0c\u5728\u590d\u6742\u6d77\u4e8b\u73af\u5883\u4e2d\u5b9e\u73b0\u66f4\u51c6\u786e\u548c\u53ef\u89e3\u91ca\u7684\u8239\u8236\u8f68\u8ff9\u9884\u6d4b\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u8239\u8236\u591a\u6a21\u6001\u8f68\u8ff9\u9884\u6d4b\u65b9\u6cd5\u5728\u573a\u666f\u9002\u7528\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u6d77\u4e8b\u73af\u5883\u4e2d\u5bf9\u5feb\u901f\u884c\u4e3a\u53d8\u5316\u7684\u77ed\u671f\u9884\u6d4b\u9700\u6c42\u3002", "method": "\u6784\u5efa\u6301\u7eed\u610f\u56fe\u6811\u4ece\u5386\u53f2\u8f68\u8ff9\u4e2d\u63d0\u53d6\u4fe1\u606f\uff0c\u4f7f\u7528\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u5efa\u6a21\u52a8\u6001\u77ac\u6001\u610f\u56fe\uff0c\u5e76\u91c7\u7528\u975e\u5c40\u90e8\u6ce8\u610f\u529b\u673a\u5236\u4fdd\u6301\u5168\u5c40\u573a\u666f\u4e00\u81f4\u6027\u3002", "result": "\u5728\u771f\u5b9eAIS\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u573a\u666f\u4e0b\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\uff0c\u5728ADE\u548cFDE\u6307\u6807\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u663e\u5f0f\u63ed\u793a\u6bcf\u4e2a\u9884\u6d4b\u8f68\u8ff9\u80cc\u540e\u7684\u5bfc\u822a\u610f\u56fe\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u8fd8\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2511.14406", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14406", "abs": "https://arxiv.org/abs/2511.14406", "authors": ["Bastien Vuillod", "Pierre-Alain Moellic", "Jean-Max Dutertre"], "title": "Watch Out for the Lifespan: Evaluating Backdoor Attacks Against Federated Model Adaptation", "comment": "Accepted at FPS 2025", "summary": "Large models adaptation through Federated Learning (FL) addresses a wide range of use cases and is enabled by Parameter-Efficient Fine-Tuning techniques such as Low-Rank Adaptation (LoRA). However, this distributed learning paradigm faces several security threats, particularly to its integrity, such as backdoor attacks that aim to inject malicious behavior during the local training steps of certain clients. We present the first analysis of the influence of LoRA on state-of-the-art backdoor attacks targeting model adaptation in FL. Specifically, we focus on backdoor lifespan, a critical characteristic in FL, that can vary depending on the attack scenario and the attacker's ability to effectively inject the backdoor. A key finding in our experiments is that for an optimally injected backdoor, the backdoor persistence after the attack is longer when the LoRA's rank is lower. Importantly, our work highlights evaluation issues of backdoor attacks against FL and contributes to the development of more robust and fair evaluations of backdoor attacks, enhancing the reliability of risk assessments for critical FL systems. Our code is publicly available.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u8054\u90a6\u5b66\u4e60\u4e2dLoRA\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6280\u672f\u5bf9\u540e\u95e8\u653b\u51fb\u7684\u5f71\u54cd\uff0c\u53d1\u73b0LoRA\u79e9\u8d8a\u4f4e\uff0c\u540e\u95e8\u6301\u4e45\u6027\u8d8a\u957f\uff0c\u5e76\u6307\u51fa\u4e86FL\u540e\u95e8\u653b\u51fb\u8bc4\u4f30\u4e2d\u7684\u95ee\u9898\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5927\u6a21\u578b\u9002\u914d\u9762\u4e34\u5b89\u5168\u5a01\u80c1\uff0c\u7279\u522b\u662f\u540e\u95e8\u653b\u51fb\uff0c\u9700\u8981\u7814\u7a76\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6280\u672f\u5982LoRA\u5bf9\u540e\u95e8\u653b\u51fb\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790LoRA\u4e0d\u540c\u79e9\u8bbe\u7f6e\u5bf9\u6700\u5148\u8fdb\u540e\u95e8\u653b\u51fb\u7684\u5f71\u54cd\uff0c\u91cd\u70b9\u5173\u6ce8\u540e\u95e8\u5bff\u547d\u8fd9\u4e00\u5173\u952e\u7279\u5f81\u3002", "result": "\u5173\u952e\u53d1\u73b0\uff1a\u5bf9\u4e8e\u6700\u4f18\u6ce8\u5165\u7684\u540e\u95e8\uff0cLoRA\u79e9\u8d8a\u4f4e\uff0c\u653b\u51fb\u505c\u6b62\u540e\u540e\u95e8\u6301\u4e45\u6027\u8d8a\u957f\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86FL\u540e\u95e8\u653b\u51fb\u8bc4\u4f30\u4e2d\u7684\u95ee\u9898\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u7a33\u5065\u516c\u5e73\u7684\u540e\u95e8\u653b\u51fb\u8bc4\u4f30\u65b9\u6cd5\uff0c\u63d0\u9ad8\u5173\u952eFL\u7cfb\u7edf\u98ce\u9669\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2511.14452", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14452", "abs": "https://arxiv.org/abs/2511.14452", "authors": ["Emanuele Palumbo", "Sorawit Saengkyongam", "Maria R. Cervera", "Jens Behrmann", "Andrew C. Miller", "Guillermo Sapiro", "Christina Heinze-Deml", "Antoine Wehenkel"], "title": "Hybrid Modeling of Photoplethysmography for Non-invasive Monitoring of Cardiovascular Parameters", "comment": null, "summary": "Continuous cardiovascular monitoring can play a key role in precision health. However, some fundamental cardiac biomarkers of interest, including stroke volume and cardiac output, require invasive measurements, e.g., arterial pressure waveforms (APW). As a non-invasive alternative, photoplethysmography (PPG) measurements are routinely collected in hospital settings. Unfortunately, the prediction of key cardiac biomarkers from PPG instead of APW remains an open challenge, further complicated by the scarcity of annotated PPG measurements. As a solution, we propose a hybrid approach that uses hemodynamic simulations and unlabeled clinical data to estimate cardiovascular biomarkers directly from PPG signals. Our hybrid model combines a conditional variational autoencoder trained on paired PPG-APW data with a conditional density estimator of cardiac biomarkers trained on labeled simulated APW segments. As a key result, our experiments demonstrate that the proposed approach can detect fluctuations of cardiac output and stroke volume and outperform a supervised baseline in monitoring temporal changes in these biomarkers.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8840\u6d41\u52a8\u529b\u5b66\u6a21\u62df\u548c\u65e0\u6807\u7b7e\u4e34\u5e8a\u6570\u636e\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u76f4\u63a5\u4ecePPG\u4fe1\u53f7\u4f30\u8ba1\u5fc3\u8840\u7ba1\u751f\u7269\u6807\u5fd7\u7269\uff0c\u89e3\u51b3\u4e86\u5173\u952e\u5fc3\u810f\u751f\u7269\u6807\u5fd7\u7269\u9884\u6d4b\u7684\u6311\u6218\u3002", "motivation": "\u8fde\u7eed\u5fc3\u8840\u7ba1\u76d1\u6d4b\u5bf9\u7cbe\u51c6\u5065\u5eb7\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5173\u952e\u5fc3\u810f\u751f\u7269\u6807\u5fd7\u7269\u5982\u6bcf\u640f\u8f93\u51fa\u91cf\u548c\u5fc3\u8f93\u51fa\u91cf\u9700\u8981\u4fb5\u5165\u6027\u6d4b\u91cf\u3002PPG\u4f5c\u4e3a\u975e\u4fb5\u5165\u6027\u66ff\u4ee3\u65b9\u6848\u5b58\u5728\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u6761\u4ef6\u53d8\u5206\u81ea\u7f16\u7801\u5668\u5728\u914d\u5bf9PPG-APW\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u7ed3\u5408\u5728\u6807\u8bb0\u6a21\u62dfAPW\u6bb5\u4e0a\u8bad\u7ec3\u7684\u6761\u4ef6\u5bc6\u5ea6\u4f30\u8ba1\u5668\uff0c\u5f62\u6210\u6df7\u5408\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u68c0\u6d4b\u5fc3\u8f93\u51fa\u91cf\u548c\u6bcf\u640f\u8f93\u51fa\u91cf\u7684\u6ce2\u52a8\uff0c\u5e76\u5728\u76d1\u6d4b\u8fd9\u4e9b\u751f\u7269\u6807\u5fd7\u7269\u7684\u65f6\u95f4\u53d8\u5316\u65b9\u9762\u4f18\u4e8e\u76d1\u7763\u57fa\u7ebf\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u4ecePPG\u4fe1\u53f7\u4f30\u8ba1\u5fc3\u8840\u7ba1\u751f\u7269\u6807\u5fd7\u7269\uff0c\u4e3a\u975e\u4fb5\u5165\u6027\u5fc3\u8840\u7ba1\u76d1\u6d4b\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.14465", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14465", "abs": "https://arxiv.org/abs/2511.14465", "authors": ["Cl\u00e9ment Dumas"], "title": "nnterp: A Standardized Interface for Mechanistic Interpretability of Transformers", "comment": "7 pages, 1 figure, accepted at the mechanistic interpretability workshop of NeurIPS 2025", "summary": "Mechanistic interpretability research requires reliable tools for analyzing transformer internals across diverse architectures. Current approaches face a fundamental tradeoff: custom implementations like TransformerLens ensure consistent interfaces but require coding a manual adaptation for each architecture, introducing numerical mismatch with the original models, while direct HuggingFace access through NNsight preserves exact behavior but lacks standardization across models. To bridge this gap, we develop nnterp, a lightweight wrapper around NNsight that provides a unified interface for transformer analysis while preserving original HuggingFace implementations. Through automatic module renaming and comprehensive validation testing, nnterp enables researchers to write intervention code once and deploy it across 50+ model variants spanning 16 architecture families. The library includes built-in implementations of common interpretability methods (logit lens, patchscope, activation steering) and provides direct access to attention probabilities for models that support it. By packaging validation tests with the library, researchers can verify compatibility with custom models locally. nnterp bridges the gap between correctness and usability in mechanistic interpretability tooling.", "AI": {"tldr": "nnterp\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5305\u88c5\u5668\uff0c\u4e3aTransformer\u5206\u6790\u63d0\u4f9b\u7edf\u4e00\u63a5\u53e3\uff0c\u540c\u65f6\u4fdd\u7559\u539f\u59cbHuggingFace\u5b9e\u73b0\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u5de5\u5177\u5728\u4e00\u81f4\u6027\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u5f53\u524dTransformer\u5206\u6790\u5de5\u5177\u9762\u4e34\u6839\u672c\u6743\u8861\uff1a\u81ea\u5b9a\u4e49\u5b9e\u73b0\u786e\u4fdd\u63a5\u53e3\u4e00\u81f4\u4f46\u9700\u8981\u624b\u52a8\u9002\u914d\u6bcf\u4e2a\u67b6\u6784\u4e14\u5b58\u5728\u6570\u503c\u4e0d\u5339\u914d\uff0c\u800c\u76f4\u63a5\u4f7f\u7528HuggingFace\u4fdd\u6301\u51c6\u786e\u884c\u4e3a\u4f46\u7f3a\u4e4f\u6807\u51c6\u5316\u3002", "method": "\u5f00\u53d1nnterp\u4f5c\u4e3aNNsight\u7684\u8f7b\u91cf\u7ea7\u5305\u88c5\u5668\uff0c\u901a\u8fc7\u81ea\u52a8\u6a21\u5757\u91cd\u547d\u540d\u548c\u5168\u9762\u9a8c\u8bc1\u6d4b\u8bd5\uff0c\u4e3a50+\u6a21\u578b\u53d8\u4f53\u63d0\u4f9b\u7edf\u4e00\u5206\u6790\u63a5\u53e3\u3002", "result": "nnterp\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u7f16\u5199\u4e00\u6b21\u5e72\u9884\u4ee3\u7801\u5e76\u572816\u4e2a\u67b6\u6784\u5bb6\u65cf\u768450\u591a\u4e2a\u6a21\u578b\u53d8\u4f53\u4e2d\u90e8\u7f72\uff0c\u5305\u542b\u5e38\u89c1\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u7684\u5b9e\u73b0\u5e76\u63d0\u4f9b\u6ce8\u610f\u529b\u6982\u7387\u7684\u76f4\u63a5\u8bbf\u95ee\u3002", "conclusion": "nnterp\u5728\u673a\u68b0\u53ef\u89e3\u91ca\u6027\u5de5\u5177\u4e2d\u5f25\u5408\u4e86\u6b63\u786e\u6027\u548c\u53ef\u7528\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2511.14485", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14485", "abs": "https://arxiv.org/abs/2511.14485", "authors": ["Diego Armando P\u00e9rez-Rosero", "Danna Valentina Salazar-Dubois", "Juan Camilo Lugo-Rojas", "Andr\u00e9s Marino \u00c1lvarez-Meza", "Germ\u00e1n Castellanos-Dominguez"], "title": "Notes on Kernel Methods in Machine Learning", "comment": null, "summary": "These notes provide a self-contained introduction to kernel methods and their geometric foundations in machine learning. Starting from the construction of Hilbert spaces, we develop the theory of positive definite kernels, reproducing kernel Hilbert spaces (RKHS), and Hilbert-Schmidt operators, emphasizing their role in statistical estimation and representation of probability measures. Classical concepts such as covariance, regression, and information measures are revisited through the lens of Hilbert space geometry. We also introduce kernel density estimation, kernel embeddings of distributions, and the Maximum Mean Discrepancy (MMD). The exposition is designed to serve as a foundation for more advanced topics, including Gaussian processes, kernel Bayesian inference, and functional analytic approaches to modern machine learning.", "AI": {"tldr": "\u672c\u6587\u63d0\u4f9b\u4e86\u5173\u4e8e\u6838\u65b9\u6cd5\u53ca\u5176\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u51e0\u4f55\u57fa\u7840\u7684\u81ea\u5305\u542b\u4ecb\u7ecd\uff0c\u6db5\u76d6\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u6784\u9020\u3001\u6b63\u5b9a\u6838\u3001\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u7b49\u6838\u5fc3\u7406\u8bba\uff0c\u5e76\u63a2\u8ba8\u4e86\u5b83\u4eec\u5728\u7edf\u8ba1\u4f30\u8ba1\u548c\u6982\u7387\u6d4b\u5ea6\u8868\u793a\u4e2d\u7684\u4f5c\u7528\u3002", "motivation": "\u4e3a\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u6838\u65b9\u6cd5\u63d0\u4f9b\u7cfb\u7edf\u7684\u51e0\u4f55\u7406\u8bba\u57fa\u7840\uff0c\u5c06\u7ecf\u5178\u7edf\u8ba1\u6982\u5ff5\u4e0e\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u51e0\u4f55\u8054\u7cfb\u8d77\u6765\uff0c\u5e76\u4e3a\u9ad8\u65af\u8fc7\u7a0b\u3001\u6838\u8d1d\u53f6\u65af\u63a8\u65ad\u7b49\u9ad8\u7ea7\u4e3b\u9898\u5960\u5b9a\u57fa\u7840\u3002", "method": "\u4ece\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u6784\u9020\u51fa\u53d1\uff0c\u7cfb\u7edf\u53d1\u5c55\u6b63\u5b9a\u6838\u3001\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u548c\u5e0c\u5c14\u4f2f\u7279-\u65bd\u5bc6\u7279\u7b97\u5b50\u7406\u8bba\uff0c\u901a\u8fc7\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u51e0\u4f55\u91cd\u65b0\u5ba1\u89c6\u534f\u65b9\u5dee\u3001\u56de\u5f52\u548c\u4fe1\u606f\u5ea6\u91cf\u7b49\u7ecf\u5178\u6982\u5ff5\u3002", "result": "\u5efa\u7acb\u4e86\u6838\u5bc6\u5ea6\u4f30\u8ba1\u3001\u5206\u5e03\u6838\u5d4c\u5165\u548c\u6700\u5927\u5747\u503c\u5dee\u5f02\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u7edf\u8ba1\u4f30\u8ba1\u548c\u6982\u7387\u6d4b\u5ea6\u8868\u793a\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u51e0\u4f55\u89c6\u89d2\u3002", "conclusion": "\u8be5\u5bfc\u8bba\u4e3a\u7406\u89e3\u6838\u65b9\u6cd5\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u4e3a\u540e\u7eed\u5b66\u4e60\u9ad8\u65af\u8fc7\u7a0b\u3001\u6838\u8d1d\u53f6\u65af\u63a8\u65ad\u7b49\u529f\u80fd\u5206\u6790\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u6570\u5b66\u51c6\u5907\u3002"}}
{"id": "2511.14510", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14510", "abs": "https://arxiv.org/abs/2511.14510", "authors": ["Jiawei Yi", "Ping Gong", "Youhui Bai", "Jiaqi Ruan", "Shengnan Wang", "Pengcheng Wang", "Haibo Wang", "Weiguang Wang", "Xia Zhu", "Feng Wu", "Cheng Li"], "title": "CLO: Efficient LLM Inference System with CPU-Light KVCache Offloading via Algorithm-System Co-Design", "comment": null, "summary": "The growth of million-token LLMs exposes the scalability limits of inference systems, where the KVCache dominates memory usage and data transfer overhead. Recent offloading systems migrate the KVCache to CPU memory and incorporate top-k attention to reduce the volume of data transferred from the CPU, while further applying system-level optimizations such as on-GPU caching and prefetching to lower transfer overhead. However, they overlook the CPU bottleneck in three aspects: (1) substantial overhead of fine-grained dynamic cache management performed on the CPU side, (2) significant transfer overhead from poor PCIe bandwidth utilization caused by heavy gathering operations at the CPU side, and (3) GPU runtime bubbles introduced by coarse-grained CPU-centric synchronization. To address these challenges, we propose CLO, a CPU-light KVCache offloading system via algorithm-system co-design. CLO features: (1) a coarse-grained head-wise approximate on-GPU caching strategy with negligible cache management cost, (2) seamless combination of data prefetching and on-GPU persistent caching for lower transfer overhead, (3) a zero-copy transfer engine to fully exploit PCIe bandwidth, and a GPU-centric synchronization method to eliminate GPU stalls. Evaluation on two widely-used LLMs demonstrates that CLO achieves comparable accuracy to state-of-the-art systems, while substantially minimizing CPU overhead, fully utilizing PCIe bandwidth, thus improving decoding throughput by 9.3%-66.6%. Our results highlight that algorithm-system co-design is essential for memory-constrained LLM inference on modern GPU platforms. We open source CLO at https://github.com/CommediaJW/CLO.", "AI": {"tldr": "CLO\u662f\u4e00\u4e2a\u901a\u8fc7\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u5b9e\u73b0\u7684CPU\u8f7b\u91cf\u7ea7KVCache\u5378\u8f7d\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7cfb\u7edf\u5728CPU\u74f6\u9888\u3001PCIe\u5e26\u5bbd\u5229\u7528\u548cGPU\u8fd0\u884c\u65f6\u6c14\u6ce1\u65b9\u9762\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u63a8\u7406\u7684\u89e3\u7801\u541e\u5410\u91cf\u3002", "motivation": "\u968f\u7740\u767e\u4e07token LLM\u7684\u53d1\u5c55\uff0c\u63a8\u7406\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027\u9762\u4e34\u6311\u6218\uff0c\u5176\u4e2dKVCache\u4e3b\u5bfc\u4e86\u5185\u5b58\u4f7f\u7528\u548c\u6570\u636e\u4f20\u8f93\u5f00\u9500\u3002\u73b0\u6709\u5378\u8f7d\u7cfb\u7edf\u867d\u7136\u5c06KVCache\u8fc1\u79fb\u5230CPU\u5185\u5b58\u5e76\u91c7\u7528top-k\u6ce8\u610f\u529b\u6765\u51cf\u5c11\u6570\u636e\u4f20\u8f93\u91cf\uff0c\u4f46\u5ffd\u89c6\u4e86CPU\u74f6\u9888\u7684\u4e09\u4e2a\u5173\u952e\u65b9\u9762\uff1a\u7ec6\u7c92\u5ea6\u52a8\u6001\u7f13\u5b58\u7ba1\u7406\u5f00\u9500\u3001PCIe\u5e26\u5bbd\u5229\u7528\u7387\u4f4e\u4ee5\u53caGPU\u8fd0\u884c\u65f6\u6c14\u6ce1\u3002", "method": "CLO\u91c7\u7528\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\uff0c\u5305\u62ec\uff1a(1)\u7c97\u7c92\u5ea6\u7684\u5934\u7ea7\u8fd1\u4f3cGPU\u7f13\u5b58\u7b56\u7565\uff0c\u7f13\u5b58\u7ba1\u7406\u6210\u672c\u53ef\u5ffd\u7565\uff1b(2)\u6570\u636e\u9884\u53d6\u548cGPU\u6301\u4e45\u7f13\u5b58\u7684\u65e0\u7f1d\u7ed3\u5408\u4ee5\u964d\u4f4e\u4f20\u8f93\u5f00\u9500\uff1b(3)\u96f6\u62f7\u8d1d\u4f20\u8f93\u5f15\u64ce\u5145\u5206\u5229\u7528PCIe\u5e26\u5bbd\uff0c\u4ee5\u53caGPU\u4e2d\u5fc3\u7684\u540c\u6b65\u65b9\u6cd5\u6d88\u9664GPU\u505c\u987f\u3002", "result": "\u5728\u4e24\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684LLM\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cCLO\u5728\u4fdd\u6301\u4e0e\u6700\u5148\u8fdb\u7cfb\u7edf\u76f8\u5f53\u51c6\u786e\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u6700\u5c0f\u5316CPU\u5f00\u9500\uff0c\u5145\u5206\u5229\u7528PCIe\u5e26\u5bbd\uff0c\u5c06\u89e3\u7801\u541e\u5410\u91cf\u63d0\u9ad8\u4e869.3%-66.6%\u3002", "conclusion": "\u7b97\u6cd5-\u7cfb\u7edf\u534f\u540c\u8bbe\u8ba1\u5bf9\u4e8e\u73b0\u4ee3GPU\u5e73\u53f0\u4e0a\u5185\u5b58\u53d7\u9650\u7684LLM\u63a8\u7406\u81f3\u5173\u91cd\u8981\u3002CLO\u5df2\u5f00\u6e90\u5728GitHub\u4e0a\u3002"}}
{"id": "2511.14619", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14619", "abs": "https://arxiv.org/abs/2511.14619", "authors": ["Marco Locatelli", "Arjen Hommersom", "Roberto Clemens Cerioli", "Daniela Besozzi", "Fabio Stella"], "title": "Expert-Guided POMDP Learning for Data-Efficient Modeling in Healthcare", "comment": null, "summary": "Learning the parameters of Partially Observable Markov Decision Processes (POMDPs) from limited data is a significant challenge. We introduce the Fuzzy MAP EM algorithm, a novel approach that incorporates expert knowledge into the parameter estimation process by enriching the Expectation Maximization (EM) framework with fuzzy pseudo-counts derived from an expert-defined fuzzy model. This integration naturally reformulates the problem as a Maximum A Posteriori (MAP) estimation, effectively guiding learning in environments with limited data. In synthetic medical simulations, our method consistently outperforms the standard EM algorithm under both low-data and high-noise conditions. Furthermore, a case study on Myasthenia Gravis illustrates the ability of the Fuzzy MAP EM algorithm to recover a clinically coherent POMDP, demonstrating its potential as a practical tool for data-efficient modeling in healthcare.", "AI": {"tldr": "\u63d0\u51faFuzzy MAP EM\u7b97\u6cd5\uff0c\u901a\u8fc7\u5c06\u4e13\u5bb6\u77e5\u8bc6\u878d\u5165\u671f\u671b\u6700\u5927\u5316\u6846\u67b6\u6765\u89e3\u51b3\u6709\u9650\u6570\u636e\u4e0b\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u7684\u53c2\u6570\u5b66\u4e60\u95ee\u9898\u3002", "motivation": "\u5728\u6709\u9650\u6570\u636e\u6761\u4ef6\u4e0b\u5b66\u4e60POMDP\u53c2\u6570\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u5229\u7528\u4e13\u5bb6\u77e5\u8bc6\u6765\u6307\u5bfc\u5b66\u4e60\u8fc7\u7a0b\u3002", "method": "\u5c06\u4e13\u5bb6\u5b9a\u4e49\u7684\u6a21\u7cca\u6a21\u578b\u751f\u6210\u7684\u6a21\u7cca\u4f2a\u8ba1\u6570\u878d\u5165EM\u6846\u67b6\uff0c\u5c06\u95ee\u9898\u91cd\u65b0\u8868\u8ff0\u4e3a\u6700\u5927\u540e\u9a8c\u4f30\u8ba1\u3002", "result": "\u5728\u5408\u6210\u533b\u7597\u6a21\u62df\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u4f4e\u6570\u636e\u548c\u9ad8\u566a\u58f0\u6761\u4ef6\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u6807\u51c6EM\u7b97\u6cd5\uff1b\u5728\u91cd\u75c7\u808c\u65e0\u529b\u6848\u4f8b\u7814\u7a76\u4e2d\u6210\u529f\u6062\u590d\u4e86\u4e34\u5e8a\u4e00\u81f4\u7684POMDP\u3002", "conclusion": "Fuzzy MAP EM\u7b97\u6cd5\u662f\u533b\u7597\u4fdd\u5065\u9886\u57df\u6570\u636e\u9ad8\u6548\u5efa\u6a21\u7684\u5b9e\u7528\u5de5\u5177\uff0c\u80fd\u591f\u6709\u6548\u5229\u7528\u4e13\u5bb6\u77e5\u8bc6\u6539\u5584\u6709\u9650\u6570\u636e\u73af\u5883\u4e0b\u7684\u5b66\u4e60\u6548\u679c\u3002"}}
{"id": "2511.14632", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14632", "abs": "https://arxiv.org/abs/2511.14632", "authors": ["Yuchen Luo", "Xinyu Li", "Liuhua Peng", "Mingming Gong"], "title": "Adapformer: Adaptive Channel Management for Multivariate Time Series Forecasting", "comment": null, "summary": "In multivariate time series forecasting (MTSF), accurately modeling the intricate dependencies among multiple variables remains a significant challenge due to the inherent limitations of traditional approaches. Most existing models adopt either \\textbf{channel-independent} (CI) or \\textbf{channel-dependent} (CD) strategies, each presenting distinct drawbacks. CI methods fail to leverage the potential insights from inter-channel interactions, resulting in models that may not fully exploit the underlying statistical dependencies present in the data. Conversely, CD approaches often incorporate too much extraneous information, risking model overfitting and predictive inefficiency. To address these issues, we introduce the Adaptive Forecasting Transformer (\\textbf{Adapformer}), an advanced Transformer-based framework that merges the benefits of CI and CD methodologies through effective channel management. The core of Adapformer lies in its dual-stage encoder-decoder architecture, which includes the \\textbf{A}daptive \\textbf{C}hannel \\textbf{E}nhancer (\\textbf{ACE}) for enriching embedding processes and the \\textbf{A}daptive \\textbf{C}hannel \\textbf{F}orecaster (\\textbf{ACF}) for refining the predictions. ACE enhances token representations by selectively incorporating essential dependencies, while ACF streamlines the decoding process by focusing on the most relevant covariates, substantially reducing noise and redundancy. Our rigorous testing on diverse datasets shows that Adapformer achieves superior performance over existing models, enhancing both predictive accuracy and computational efficiency, thus making it state-of-the-art in MTSF.", "AI": {"tldr": "Adapformer\u662f\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u901a\u9053\u7ba1\u7406\u7ed3\u5408\u4e86\u901a\u9053\u72ec\u7acb\u548c\u901a\u9053\u4f9d\u8d56\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edf\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u5b58\u5728\u901a\u9053\u72ec\u7acb\u65b9\u6cd5\u65e0\u6cd5\u5229\u7528\u901a\u9053\u95f4\u4ea4\u4e92\u4fe1\u606f\uff0c\u4ee5\u53ca\u901a\u9053\u4f9d\u8d56\u65b9\u6cd5\u5305\u542b\u8fc7\u591a\u65e0\u5173\u4fe1\u606f\u5bfc\u81f4\u8fc7\u62df\u5408\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u53cc\u9636\u6bb5\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\uff0c\u5305\u62ec\u81ea\u9002\u5e94\u901a\u9053\u589e\u5f3a\u5668(ACE)\u7528\u4e8e\u4e30\u5bcc\u5d4c\u5165\u8fc7\u7a0b\uff0c\u4ee5\u53ca\u81ea\u9002\u5e94\u901a\u9053\u9884\u6d4b\u5668(ACF)\u7528\u4e8e\u4f18\u5316\u9884\u6d4b\u7ed3\u679c\u3002ACE\u9009\u62e9\u6027\u6574\u5408\u5173\u952e\u4f9d\u8d56\u5173\u7cfb\uff0cACF\u4e13\u6ce8\u4e8e\u6700\u76f8\u5173\u7684\u534f\u53d8\u91cf\u4ee5\u51cf\u5c11\u566a\u58f0\u548c\u5197\u4f59\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u4e25\u683c\u6d4b\u8bd5\u8868\u660e\uff0cAdapformer\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u6c34\u5e73\u3002", "conclusion": "Adapformer\u901a\u8fc7\u6709\u6548\u7684\u901a\u9053\u7ba1\u7406\u7b56\u7565\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u4f9d\u8d56\u5173\u7cfb\u5efa\u6a21\u6311\u6218\uff0c\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u90fd\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.14544", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14544", "abs": "https://arxiv.org/abs/2511.14544", "authors": ["Jaume Ros", "Alessio Arleo", "Fernando Paulovich"], "title": "Mind the Gaps: Measuring Visual Artifacts in Dimensionality Reduction", "comment": null, "summary": "Dimensionality Reduction (DR) techniques are commonly used for the visual exploration and analysis of high-dimensional data due to their ability to project datasets of high-dimensional points onto the 2D plane. However, projecting datasets in lower dimensions often entails some distortion, which is not necessarily easy to recognize but can lead users to misleading conclusions. Several Projection Quality Metrics (PQMs) have been developed as tools to quantify the goodness-of-fit of a DR projection; however, they mostly focus on measuring how well the projection captures the global or local structure of the data, without taking into account the visual distortion of the resulting plots, thus often ignoring the presence of outliers or artifacts that can mislead a visual analysis of the projection. In this work, we introduce the Warping Index (WI), a new metric for measuring the quality of DR projections onto the 2D plane, based on the assumption that the correct preservation of empty regions between points is of crucial importance towards a faithful visual representation of the data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Warping Index (WI)\u8fd9\u4e00\u65b0\u7684\u7ef4\u5ea6\u7f29\u51cf\u6295\u5f71\u8d28\u91cf\u5ea6\u91cf\u6307\u6807\uff0c\u4e13\u6ce8\u4e8e\u6d4b\u91cf\u6295\u5f71\u4e2d\u7a7a\u533a\u57df\u7684\u6b63\u786e\u4fdd\u6301\uff0c\u4ee5\u907f\u514d\u89c6\u89c9\u5206\u6790\u4e2d\u7684\u8bef\u5bfc\u3002", "motivation": "\u73b0\u6709\u7684\u6295\u5f71\u8d28\u91cf\u5ea6\u91cf\u4e3b\u8981\u5173\u6ce8\u5168\u5c40\u6216\u5c40\u90e8\u7ed3\u6784\u4fdd\u6301\uff0c\u4f46\u5ffd\u7565\u4e86\u89c6\u89c9\u5931\u771f\u3001\u5f02\u5e38\u503c\u548c\u4f2a\u5f71\u5bf9\u89c6\u89c9\u5206\u6790\u7684\u5f71\u54cd\uff0c\u53ef\u80fd\u5bfc\u81f4\u7528\u6237\u5f97\u51fa\u8bef\u5bfc\u6027\u7ed3\u8bba\u3002", "method": "\u57fa\u4e8e\u7a7a\u533a\u57df\u6b63\u786e\u4fdd\u6301\u5bf9\u5fe0\u5b9e\u89c6\u89c9\u8868\u793a\u81f3\u5173\u91cd\u8981\u7684\u5047\u8bbe\uff0c\u5f00\u53d1\u4e86Warping Index (WI)\u5ea6\u91cf\u6307\u6807\u6765\u91cf\u5316\u7ef4\u5ea6\u7f29\u51cf\u6295\u5f71\u7684\u8d28\u91cf\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6295\u5f71\u8d28\u91cf\u5ea6\u91cf\u65b9\u6cd5\uff0c\u4e13\u95e8\u5173\u6ce8\u6295\u5f71\u4e2d\u7a7a\u533a\u57df\u7684\u4fdd\u6301\u60c5\u51b5\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u5ea6\u91cf\u65b9\u6cd5\u5728\u89c6\u89c9\u5931\u771f\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "conclusion": "Warping Index (WI)\u4e3a\u7ef4\u5ea6\u7f29\u51cf\u6295\u5f71\u8d28\u91cf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u7279\u522b\u5f3a\u8c03\u7a7a\u533a\u57df\u4fdd\u6301\u5bf9\u89c6\u89c9\u5206\u6790\u51c6\u786e\u6027\u7684\u91cd\u8981\u6027\u3002"}}
