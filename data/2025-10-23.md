<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 6]
- [eess.SP](#eess.SP) [Total: 5]
- [cs.LG](#cs.LG) [Total: 34]
- [stat.ML](#stat.ML) [Total: 3]
- [stat.AP](#stat.AP) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [The MUSE Benchmark: Probing Music Perception and Auditory Relational Reasoning in Audio LLMS](https://arxiv.org/abs/2510.19055)
*Brandon James Carone,Iran R. Roman,Pablo Ripollés*

Main category: cs.AI

TL;DR: 该论文提出了MUSE基准测试，用于评估多模态大语言模型在音乐理解中的关系推理能力，发现当前SOTA模型在音乐感知方面存在严重缺陷，且与人类专家存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在音频理解方面的评估可能掩盖了其在关系推理方面的根本弱点，需要更深入的音乐感知能力评估工具。

Method: 开发了MUSE基准测试，包含10个任务来探测基础音乐感知技能，评估了4个SOTA模型（Gemini Pro和Flash、Qwen2.5-Omni、Audio-Flamingo 3）并与200人的人类基线进行比较。

Result: 发现SOTA模型能力差异很大，与人类专家存在持续差距；Gemini Pro在基础感知上表现良好，但Qwen和Audio Flamingo 3表现接近随机水平；思维链提示提供不一致且通常有害的结果。

Conclusion: 该工作为评估不变音乐表征和开发更鲁棒的AI系统提供了关键工具。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated capabilities in
audio understanding, but current evaluations may obscure fundamental weaknesses
in relational reasoning. We introduce the Music Understanding and Structural
Evaluation (MUSE) Benchmark, an open-source resource with 10 tasks designed to
probe fundamental music perception skills. We evaluate four SOTA models (Gemini
Pro and Flash, Qwen2.5-Omni, and Audio-Flamingo 3) against a large human
baseline (N=200). Our results reveal a wide variance in SOTA capabilities and a
persistent gap with human experts. While Gemini Pro succeeds on basic
perception, Qwen and Audio Flamingo 3 perform at or near chance, exposing
severe perceptual deficits. Furthermore, we find Chain-of-Thought (CoT)
prompting provides inconsistent, often detrimental results. Our work provides a
critical tool for evaluating invariant musical representations and driving
development of more robust AI systems.

</details>


### [2] [A Multi-faceted Analysis of Cognitive Abilities: Evaluating Prompt Methods with Large Language Models on the CONSORT Checklist](https://arxiv.org/abs/2510.19139)
*Sohyeon Jeon,Hyung-Chul Lee*

Main category: cs.AI

TL;DR: 本研究采用行为和元认知分析方法，系统比较了两种代表性LLM在三种提示条件下评估临床试验报告CONSORT标准的能力，发现模型在不同CONSORT项目和提示类型下存在明显差异。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在医疗领域快速扩展，但这些系统根据CONSORT标准评估临床试验报告的能力仍不明确，特别是在认知和推理策略方面。

Method: 采用行为和元认知分析方法，使用专家验证数据，系统比较两种代表性LLM在三种提示条件下的表现。

Result: 模型在不同CONSORT项目和提示类型上表现出明显差异，包括推理风格转变、显式不确定性和替代解释等响应模式的变化。

Conclusion: 结果突显了这些系统在临床合规自动化方面的当前局限性，并强调了理解其认知适应和策略行为对于开发更可解释和可靠的医疗AI的重要性。

Abstract: Despite the rapid expansion of Large Language Models (LLMs) in healthcare,
the ability of these systems to assess clinical trial reporting according to
CONSORT standards remains unclear, particularly with respect to their cognitive
and reasoning strategies. This study applies a behavioral and metacognitive
analytic approach with expert-validated data, systematically comparing two
representative LLMs under three prompt conditions. Clear differences emerged in
how the models approached various CONSORT items, and prompt types, including
shifts in reasoning style, explicit uncertainty, and alternative
interpretations shaped response patterns. Our results highlight the current
limitations of these systems in clinical compliance automation and underscore
the importance of understanding their cognitive adaptations and strategic
behavior in developing more explainable and reliable medical AI.

</details>


### [3] [Continual Knowledge Adaptation for Reinforcement Learning](https://arxiv.org/abs/2510.19314)
*Jinwu Hu,Zihao Lian,Zhiquan Wen,Chenghao Li,Guohao Chen,Xutao Wen,Bin Xiao,Mingkui Tan*

Main category: cs.AI

TL;DR: 提出CKA-RL方法解决持续强化学习中的灾难性遗忘和知识利用效率低的问题，通过持续知识适应策略和自适应知识合并机制，在三个基准测试中性能提升4.20%，前向迁移提升8.02%。


<details>
  <summary>Details</summary>
Motivation: 现实环境通常是非平稳的，需要智能体持续适应新任务和变化条件。现有持续强化学习方法存在灾难性遗忘和知识利用效率低的问题。

Method: 提出持续知识适应策略，维护任务特定知识向量池并动态使用历史知识来适应新任务；引入自适应知识合并机制，合并相似知识向量以减少内存需求。

Result: 在三个基准测试中，CKA-RL优于最先进方法，整体性能提升4.20%，前向迁移提升8.02%。

Conclusion: CKA-RL通过持续知识适应和自适应知识合并，有效缓解了灾难性遗忘，实现了跨任务的高效知识迁移，在持续强化学习任务中表现出色。

Abstract: Reinforcement Learning enables agents to learn optimal behaviors through
interactions with environments. However, real-world environments are typically
non-stationary, requiring agents to continuously adapt to new tasks and
changing conditions. Although Continual Reinforcement Learning facilitates
learning across multiple tasks, existing methods often suffer from catastrophic
forgetting and inefficient knowledge utilization. To address these challenges,
we propose Continual Knowledge Adaptation for Reinforcement Learning (CKA-RL),
which enables the accumulation and effective utilization of historical
knowledge. Specifically, we introduce a Continual Knowledge Adaptation
strategy, which involves maintaining a task-specific knowledge vector pool and
dynamically using historical knowledge to adapt the agent to new tasks. This
process mitigates catastrophic forgetting and enables efficient knowledge
transfer across tasks by preserving and adapting critical model parameters.
Additionally, we propose an Adaptive Knowledge Merging mechanism that combines
similar knowledge vectors to address scalability challenges, reducing memory
requirements while ensuring the retention of essential knowledge. Experiments
on three benchmarks demonstrate that the proposed CKA-RL outperforms
state-of-the-art methods, achieving an improvement of 4.20% in overall
performance and 8.02% in forward transfer. The source code is available at
https://github.com/Fhujinwu/CKA-RL.

</details>


### [4] [Explainable e-sports win prediction through Machine Learning classification in streaming](https://arxiv.org/abs/2510.19671)
*Silvia García-Méndez,Francisco de Arriba-Pérez*

Main category: cs.AI

TL;DR: 本文提出了一种可解释的电子竞技流式胜率预测分类解决方案，通过滑动窗口控制输入数据以反映游戏变化，准确率超过90%，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 电子竞技观众和玩家数量增长，加上通信技术和云计算的发展，推动了在线游戏行业的持续发展。尽管基于AI的电子竞技分析传统上定义为从相关数据中提取有意义模式并可视化以增强决策，但专业胜率预测大多关注批量分类，忽略了可视化技术。

Method: 提出可解释的流式胜率预测分类解决方案，通过多个滑动窗口控制输入数据以反映相关游戏变化。

Result: 实验结果显示准确率超过90%，超越了文献中的竞争解决方案。

Conclusion: 该系统可被排名和推荐系统利用进行知情决策，得益于可解释性模块，增强了结果预测的信任度。

Abstract: The increasing number of spectators and players in e-sports, along with the
development of optimized communication solutions and cloud computing
technology, has motivated the constant growth of the online game industry. Even
though Artificial Intelligence-based solutions for e-sports analytics are
traditionally defined as extracting meaningful patterns from related data and
visualizing them to enhance decision-making, most of the effort in professional
winning prediction has been focused on the classification aspect from a batch
perspective, also leaving aside the visualization techniques. Consequently,
this work contributes to an explainable win prediction classification solution
in streaming in which input data is controlled over several sliding windows to
reflect relevant game changes. Experimental results attained an accuracy higher
than 90 %, surpassing the performance of competing solutions in the literature.
Ultimately, our system can be leveraged by ranking and recommender systems for
informed decision-making, thanks to the explainability module, which fosters
trust in the outcome predictions.

</details>


### [5] [Misalignment Bounty: Crowdsourcing AI Agent Misbehavior](https://arxiv.org/abs/2510.19738)
*Rustem Turtayev,Natalia Fedorova,Oleg Serikov,Sergey Koldyba,Lev Avagyan,Dmitrii Volkov*

Main category: cs.AI

TL;DR: 该论文介绍了"错位赏金"项目，这是一个众包项目，旨在收集AI系统追求非预期或不安全目标的案例。项目收到295份提交，其中9份获奖。


<details>
  <summary>Details</summary>
Motivation: 收集AI系统与人类意图不一致的清晰、可复现案例，以更好地理解和解决AI错位问题。

Method: 通过众包方式运行"错位赏金"项目，收集AI系统追求非预期或不安全目标的案例，并设立评估标准对提交进行评审。

Result: 项目收到295份提交，最终评选出9个获奖案例，展示了AI系统可能偏离人类意图的具体情况。

Conclusion: 通过众包方式可以有效收集AI错位案例，这些案例为理解和解决AI系统与人类意图不一致的问题提供了有价值的实证材料。

Abstract: Advanced AI systems sometimes act in ways that differ from human intent. To
gather clear, reproducible examples, we ran the Misalignment Bounty: a
crowdsourced project that collected cases of agents pursuing unintended or
unsafe goals. The bounty received 295 submissions, of which nine were awarded.
  This report explains the program's motivation and evaluation criteria, and
walks through the nine winning submissions step by step.

</details>


### [6] [Benchmarking World-Model Learning](https://arxiv.org/abs/2510.19788)
*Archana Warrier,Dat Nyugen,Michelangelo Naim,Moksh Jain,Yichao Liang,Karen Schroeder,Cambridge Yang,Joshua B. Tenenbaum,Sebastian Vollmer,Kevin Ellis,Zenna Tavares*

Main category: cs.AI

TL;DR: WorldTest是一个评估模型学习智能体的协议，将无奖励交互与不同但相关环境中的评分测试阶段分离，支持多种未知任务。AutumnBench作为WorldTest的具体实现，包含43个交互式网格世界环境和129个任务，比较了人类参与者和前沿模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前模型学习和评估方法偏离了学习支持多种下游任务的世界模型的目标，训练和评估都锚定在下一帧预测上，成功标准是在同一环境中最大化奖励。

Method: 提出WorldTest协议，包含无奖励探索、衍生测试和行为评分三个模板。使用AutumnBench套件，包含43个网格世界环境和129个任务，涵盖掩码帧预测、规划和因果动态变化预测三个任务系列。

Result: 比较了517名人类参与者和三个前沿模型，发现人类表现优于模型，计算规模扩展只在某些环境中提高性能而非所有环境。

Conclusion: WorldTest提供了一个新颖的模板来评估智能体对环境动态的学习情况，AutumnBench揭示了世界模型学习中的显著改进空间。

Abstract: Model-learning agents should gather information to learn world models that
support many downstream tasks and inferences, such as predicting unobserved
states, estimating near- and far-term consequences of actions, planning action
sequences, and detecting changes in dynamics. Current methods for learning and
evaluating world models diverge from this goal: training and evaluation are
anchored to next-frame prediction, and success is scored by reward maximization
in the same environment. We propose WorldTest, a protocol to evaluate
model-learning agents that separates reward-free interaction from a scored test
phase in a different but related environment. WorldTest is
open-ended$\unicode{x2014}$models should support many different tasks unknown
ahead of time$\unicode{x2014}$and agnostic to model representation, allowing
comparison across approaches. We instantiated WorldTest with AutumnBench, a
suite of 43 interactive grid-world environments and 129 tasks across three
families: masked-frame prediction, planning, and predicting changes to the
causal dynamics. We compared 517 human participants and three frontier models
on AutumnBench. We found that humans outperform the models, and scaling compute
improves performance only in some environments but not others. WorldTest
provides a novel template$\unicode{x2014}$reward-free exploration, derived
tests, and behavior-based scoring$\unicode{x2014}$to evaluate what agents learn
about environment dynamics, and AutumnBench exposes significant headroom in
world-model learning.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [7] [AI Signal Processing Paradigm for Movable Antenna: From Geometric Optimization to Electromagnetic Reconfigurability](https://arxiv.org/abs/2510.19209)
*Yining Li,Ziwei Wan,Chongjia Sun,Kaijun Feng,Keke Ying,Wenyan Ma,Lipeng Zhu,Xiaodan Shao,Zhenyu Xiao,Zhen Gao*

Main category: eess.SP

TL;DR: 本文综述了6G无线通信系统中几何可移动天线(GMA)和电磁可重构天线(ERA)的集成，提出了统一的可移动可重构天线(MARA)建模框架，并系统分析了AI方法在高维混合优化中的优势。


<details>
  <summary>Details</summary>
Motivation: 传统固定天线在6G智能可重构系统中的局限性日益突出，GMA和ERA的集成形成了"几何-电磁双重构"范式，但带来了高维混合优化的严重挑战，需要新的信号处理方法。

Method: 首次集成GMA的几何优化和ERA的电磁重构，提出统一的MARA建模框架，研究GMA、ERA和MARA的信道建模与频谱效率优化，并系统回顾基于AI的解决方案。

Result: 建立了统一的MARA建模框架，分析了AI方法相比传统算法在高维非凸优化计算中的优势，填补了现有文献在几何-电磁双重构下AI驱动信号处理范式综述的空白。

Conclusion: 本文为具有高频谱效率和灵活性的6G无线系统设计与优化提供了理论支持，推动了智能可重构天线技术的发展。

Abstract: As 6G wireless communication systems evolve toward intelligence and high
reconfigurability, the limitations of traditional fixed antenna (TFA) has
become increasingly prominent, with geometrically movable antenna (GMA) and
electromagnetically reconfigurable antenna (ERA) emerging as key technologies
to break through this bottleneck. GMA activates spatial degrees of freedom
(DoF) by dynamically adjusting antenna positions, ERA regulates radiation
characteristics using tunable metamaterials, thereby introducing DoF in the
electromagnetic domain. However, the ``geometric-electromagnetic dual
reconfiguration" paradigm formed by their integration poses severe challenges
of high-dimensional hybrid optimization to signal processing. To address this
issue, we integrate the geometric optimization of GMA and the electromagnetic
reconfiguration of ERA for the first time, propose a unified modeling framework
for movable and reconfigurable antenna (MARA), investigate the channel modeling
and spectral efficiency (SE) optimization for GMA, ERA, and MARA. Besides, we
systematically review artificial intelligence (AI)-based solutions, focusing on
analyzing the advantages of AI over traditional algorithms in high-dimensional
non-convex optimization computations. This paper fills the gap in existing
literature regarding the lack of a comprehensive review on the AI-driven signal
processing paradigm under geometric-electromagnetic dual reconfiguration and
provides theoretical support for the design and optimization of 6G wireless
systems with high SE and flexibility.

</details>


### [8] [IoT-Enabled Sleep Monitoring and Cognitive Assessment for Evaluating Teacher Well-Being](https://arxiv.org/abs/2510.19269)
*Anwar Ahmed Khan,Shama Siddiqui,Mehar Ullah,Indrakshi Dey*

Main category: eess.SP

TL;DR: 本研究使用物联网技术和智能手表监测巴基斯坦高中教师的睡眠质量，并结合认知评估问卷分析睡眠质量与认知功能的关系，发现大多数教师睡眠质量差且认知功能受损，两者存在明显关联。


<details>
  <summary>Details</summary>
Motivation: 高中教师因工作压力大和多任务处理需求，常面临睡眠质量和认知功能问题，这对教学能力产生负面影响，因此需要研究其睡眠质量状况及其与认知功能的关系。

Method: 使用嵌入脉搏率和血氧饱和度传感器的智能手表收集数据，将睡眠质量分为"差"、"一般"和"好"三个等级，同时采用认知评估问卷进行教师认知功能的自我评估，研究覆盖巴基斯坦208名高中教师。

Result: 研究发现大多数教师睡眠质量差且认知功能受损，睡眠质量与认知功能之间存在明显关联。

Conclusion: 教师的工作负荷和其他因素需要改善，以确保他们的身心健康，这将反过来对教学质量产生积极影响。

Abstract: Sleep quality is an important indicator of the efficient cognitive function
for high school teachers. Due to the high work stress and multi-tasking
expectations, the teachers often face issues with their sleep quality and
cognitive function, which has a clearly negative influence on their teaching
abilities. In this work, we propose a unique but simple method of deploying
Internet of Things (IoT) technology to monitor the sleep quality of high school
teachers at Pakistan. Smart watches embedded with pulse rate and SpO2 sensors
were used to collect data and categorize the sleep quality as "poor", "fair" or
"good". Moreover, we used a psychological tool, Cognitive Assessment
Questionnaire (CAQ) for the self-assessment of teachers' cognitive function.
The study was conducted over 208 high school teachers from across Pakistan. It
has been found that most of the teachers had a poor sleep quality and cognitive
function; The link between these two variables indicate that the workload and
other factors must be improved for the teachers to ensure their well-being,
which will in turn have a positive impact on their teaching quality.

</details>


### [9] [Multi-code rate Task-Oriented Communication for Multi-Edge Cooperative Inference](https://arxiv.org/abs/2510.19360)
*Dongwon Kim,Jiwan Seo,Joonhyuk Kang*

Main category: eess.SP

TL;DR: 本文提出了一种动态调整特征提取码率的框架，通过率自适应量化方案和动态规划方法，在有限带宽下优化多边缘协同推理系统的通信效率和推理性能。


<details>
  <summary>Details</summary>
Motivation: 物联网与人工智能的集成需要边缘设备将本地感知数据的提取特征传输到边缘服务器进行AI驱动任务，但隐私问题和有限通信带宽带来了挑战，固定压缩比的同步特征传输导致通信资源利用率低下。

Method: 采用率自适应量化方案动态调整特征提取码率，基于特征对下游推理任务的重要性；使用动态规划方法在有限带宽约束下为每个边缘设备选择码率。

Result: 在多视图数据集上的实验表明，所提框架显著优于使用固定率量化的框架，在有限带宽条件下实现了通信效率和推理性能的良好平衡。

Conclusion: 提出的动态码率调整框架通过率自适应量化和动态规划码率分配，有效解决了多边缘协同推理系统中的通信效率问题，在保持推理性能的同时优化了带宽利用。

Abstract: The integration of artificial intelligence (AI) with the internet of things
(IoT) enables task-oriented communication for multi-edge cooperative inference
system, where edge devices transmit extracted features of local sensory data to
an edge server to perform AI-driven tasks. However, the privacy concerns and
limited communication bandwidth pose fundamental challenges, since simultaneous
transmission of extracted features with a single fixed compression ratio from
all devices leads to severe inefficiency in communication resource utilization.
To address this challenge, we propose a framework that dynamically adjusts the
code rate in feature extraction based on its importance to the downstream
inference task by adopting a rate-adaptive quantization (RAQ) scheme.
Furthermore, to select the code rate for each edge device under limited
bandwidth constraint, a dynamic programming (DP) approach is leveraged to
allocate the code rate across discrete code rate options. Experiments on
multi-view datasets demonstrate that the proposed frameworks significantly
outperform the frameworks using fixed-rate quantization, achieving a favorable
balance between communication efficiency and inference performance under
limited bandwidth conditions.

</details>


### [10] [On the Robustness of AFDM and OTFS Against Passive Eavesdroppers](https://arxiv.org/abs/2510.19525)
*Vincent Savaux,Hyeon Seok Rou,Zeping Sui,Giuseppe Thadeu Freitas de Abreu,Zilong Liu*

Main category: eess.SP

TL;DR: 本文研究了AFDM和OTFS波形对被动窃听者的鲁棒性，分析显示AFDM在抗窃听方面优于OTFS，其暴力破解复杂度分别为O(N²)和O(√N)。


<details>
  <summary>Details</summary>
Motivation: 研究AFDM和OTFS波形在被动窃听场景下的安全性，特别是在窃听者不知道啁啾参数或时延-多普勒网格配置时的抗破解能力。

Method: 通过分析暴力破解复杂度，并利用比特误码率仿真验证分析结果，比较AFDM和OTFS在等效条件下的信号恢复能力。

Result: 分析结果表明AFDM的暴力破解复杂度为O(N²)，OTFS为O(√N)，BER仿真显示AFDM信号在窃听端几乎无法解码，而OTFS允许部分信号恢复。

Conclusion: AFDM在抗被动窃听方面具有比OTFS更优越的鲁棒性，能够提供更好的物理层安全性。

Abstract: We investigate the robustness of affine frequency division multiplexing
(AFDM) and orthogonal time frequency space (OTFS) waveforms against passive
eavesdroppers performing brute-force demodulation to intercepted signals, under
the assumption that eavesdroppers have no knowledge of chirp parameters (in
AFDM) or the delay-Doppler grid configuration (in OTFS), such that they must
search exhaustively over possible demodulation matrices. Analytical results
show that the brute-force complexity scales as $\mathcal{O}(\sqrt{N})$ for OTFS
and $\mathcal{O}(N^2)$ for AFDM, where $N$ is the number of subcarriers,
indicating that AFDM has superior resilience over OTFS. Bit error rate (BER)
simulations confirm the analysis by showing that, with AFDM, the signal remains
nearly undecodable at the eavesdropper, while OTFS allows partial signal
recovery under equivalent conditions.

</details>


### [11] [Micro-Doppler Energy-Based Robust Multi-Target Vital Signs Monitoring Using 77-GHz FMCW Radar with Spatiotemporal Adaptive Processing](https://arxiv.org/abs/2510.19639)
*Chenxing Tan,Yuguan Hou,Hao Wang,Zhonghao Yuan*

Main category: eess.SP

TL;DR: 提出一种基于微多普勒能量的77GHz FMCW雷达多目标生命体征监测框架，相比传统相位方法具有更强的抗噪声和运动干扰能力


<details>
  <summary>Details</summary>
Motivation: 传统相位方法易受环境噪声、随机身体运动和严格校准要求影响，需要更鲁棒的生命体征监测方法

Method: 集成STAP目标检测跟踪、MUSIC高分辨率角度估计和自适应谱滤波技术，建立微多普勒能量变化与生理活动的数学关系

Result: 可在5米范围内准确检测和分离最多4个目标的生命体征，呼吸和心率平均绝对误差分别为1.2次/分钟和2.3次/分钟

Conclusion: 该方法在具有环境噪声和受试者移动的挑战性多目标场景中表现出优于传统相位方法的性能

Abstract: This paper presents a novel micro-Doppler energy-based framework for robust
multi-target vital signs monitoring using 77-GHz Frequency-Modulated
Continuous-Wave (FMCW) radar. Unlike conventional phase-based methods that are
susceptible to environmental noise, random body movements, and stringent
calibration requirements, our approach exploits the energy variations in radar
returns induced by cardiopulmonary activities. The proposed system integrates a
comprehensive processing pipeline including space-time adaptive processing
(STAP) for target detection and tracking, MUSIC algorithm for high-resolution
angle estimation, and an innovative adaptive spectral filtering technique for
vital signs extraction. We establish a rigorous mathematical framework that
formalizes the relationship between micro-Doppler energy variations and
physiological activities, enabling robust separation of closely spaced targets.
The key innovation lies in the micro-Doppler energy extraction methodology that
provides inherent robustness to phase noise and motion artifacts. Experimental
results using millimeter-wave radar datasets demonstrate that the system can
accurately detect and separate vital signs of up to four targets within
\SI{5}{\meter} range, achieving mean absolute errors of \SI{1.2}beats per
minute and \SI{2.3} beats per minute for respiration and heart rates,
respectively. The proposed approach demonstrates superior performance compared
to traditional phase-based methods, particularly in challenging multi-target
scenarios with environmental noise and subject movement.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [12] [3D Optimization for AI Inference Scaling: Balancing Accuracy, Cost, and Latency](https://arxiv.org/abs/2510.18905)
*Minseok Jung,Abhas Ricky,Muhammad Rameez Chatni*

Main category: cs.LG

TL;DR: 提出了一个3D优化框架，联合校准准确性、成本和延迟，在统一决策空间内实现约束感知的推理扩展。通过蒙特卡洛模拟评估四种优化方法，发现knee-point优化实现最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的AI推理扩展方法通常使用1D启发式或2D双变量权衡，未能考虑成本和延迟约束，需要更全面的优化框架。

Method: 使用蒙特卡洛模拟在三种代表性场景和九个模拟大语言模型上评估四种优化方法，解决3D多目标优化问题。

Result: knee-point优化实现最佳平衡，当精度优先时准确性最大化方法仍更有利。3D框架形成了1D和2D优化无法捕获的可行空间。

Conclusion: 该框架为跨不同操作环境的部署感知推理扩展建立了理论基础，支持环境自适应选择推理扩展参数k。

Abstract: AI inference scaling is often tuned through 1D heuristics (a fixed reasoning
passes) or 2D bivariate trade-offs (e.g., performance vs. compute), which fail
to consider cost and latency constraints. We introduce a 3D optimization
framework that jointly calibrates accuracy, cost, and latency within a unified
decision space, enabling constraints-aware inference scaling. Using Monte Carlo
simulations across three representative scenarios and nine simulated large
language models, we evaluate four optimization methods to address the 3D
multi-objective optimization (MOO) problem. Framing inference scaling in MOO
shapes a feasible space that 1D and 2D optimizations fail to capture, enabling
environmentadaptive selection of the inference scaling k. Results show that
knee-point optimization achieves the best balance, while accuracy-maximization
remains favorable when precision is prioritized. The framework establishes a
theoretical foundation for deployment-aware inference scaling across diverse
operational contexts.

</details>


### [13] [Large Connectome Model: An fMRI Foundation Model of Brain Connectomes Empowered by Brain-Environment Interaction in Multitask Learning Landscape](https://arxiv.org/abs/2510.18910)
*Ziquan Wei,Tingting Dan,Guorong Wu*

Main category: cs.LG

TL;DR: 该论文提出了一种基于多任务学习的脑功能成像基础模型，通过利用丰富的环境变量和人口统计数据，结合大规模无标记fMRI数据进行预训练，并在下游任务中实现半监督微调，在性别预测、行为识别和多种神经系统疾病早期诊断中取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型在临床应用中受限于样本量不足，而现有的基础模型由于自监督学习与脑-结果关系不一致，对下游任务（如疾病预测）不够优化。

Method: 将脑建模构建为多任务学习：1）通过标记多个脑-环境交互进行多任务预训练；2）使用预训练的BEI伪标签进行半监督微调。

Result: 在性别预测、人类行为识别以及自闭症、帕金森病、阿尔茨海默病和精神分裂症的早期诊断等多种应用中取得了有前景的结果。

Conclusion: 该基础模型在促进当前神经影像学临床应用方面具有巨大潜力。

Abstract: A reliable foundation model of functional neuroimages is critical to promote
clinical applications where the performance of current AI models is
significantly impeded by a limited sample size. To that end, tremendous efforts
have been made to pretraining large models on extensive unlabeled fMRI data
using scalable self-supervised learning. Since self-supervision is not
necessarily aligned with the brain-to-outcome relationship, most foundation
models are suboptimal to the downstream task, such as predicting disease
outcomes. By capitalizing on rich environmental variables and demographic data
along with an unprecedented amount of functional neuroimages, we form the brain
modeling as a multitask learning and present a scalable model architecture for
(i) multitask pretraining by tokenizing multiple brain-environment interactions
(BEI) and (ii) semi-supervised finetuning by assigning pseudo-labels of
pretrained BEI. We have evaluated our foundation model on a variety of
applications, including sex prediction, human behavior recognition, and disease
early diagnosis of Autism, Parkinson's disease, Alzheimer's disease, and
{Schizophrenia}, where promising results indicate the great potential to
facilitate current neuroimaging applications in clinical routines.

</details>


### [14] [Noise-corrected GRPO: From Noisy Rewards to Unbiased Gradients](https://arxiv.org/abs/2510.18924)
*Omar El mansouri,Mohamed El Amine Seddik,Salem Lahlou*

Main category: cs.LG

TL;DR: 本文提出了一种噪声鲁棒的Group Relative Policy Optimization (GRPO)和Done Right GRPO (Dr.GRPO)框架，用于解决RLHF中奖励噪声问题，通过建模奖励腐败为伯努利噪声并进行噪声校正，在数学和代码任务上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: RLHF或RLVR作为对齐LLMs和构建推理模型的标准范式，对不一致或错误奖励产生的噪声高度敏感，但现有研究对噪声与广泛使用的基于群体的策略优化方法之间的相互作用探索不足。

Method: 引入GRPO和Dr.GRPO框架，将奖励腐败建模为伯努利噪声，在估计奖励翻转概率后应用噪声校正来消除学习信号的偏差，获得可证明无偏的梯度估计。

Result: 在数学任务上准确率提升高达6.7个百分点，在代码任务上提升1.5个百分点，在真实奖励模型条件下表现尤为突出。

Conclusion: 这项工作将监督学习中的标签噪声校正与现代RLHF相结合，为噪声现实世界部署提供了理论洞见和实用算法。

Abstract: Reinforcement learning from human feedback (RLHF) or verifiable rewards
(RLVR), the standard paradigm for aligning LLMs or building recent SOTA
reasoning models, is highly sensitive to noise from inconsistent or erroneous
rewards. Yet, the interaction between such noise and widely used group-based
policy optimization methods remains underexplored. We introduce a noise-robust
Group Relative Policy Optimization (GRPO) and Done Right GRPO (Dr.GRPO)
framework that explicitly models reward corruption as Bernoulli noise. Our
method applies noise correction after estimating reward flip probabilities to
debias the learning signal, yielding provably unbiased gradient estimates.
Theoretical analysis shows that group-based methods inherently mitigate
individual-level noise, and our correction strategy amplifies this robustness.
Empirically, we observe consistent improvements across math and code tasks when
applying our noise correction to standard reward model usage, with particular
gains of up to 6.7 percentage points in accuracy on math tasks and 1.5 on code
tasks under realistic reward model conditions. This work bridges label-noise
correction from supervised learning with modern RLHF, offering both theoretical
insights and a practical algorithm for noisy real-world deployment.

</details>


### [15] [BAPO: Stabilizing Off-Policy Reinforcement Learning for LLMs via Balanced Policy Optimization with Adaptive Clipping](https://arxiv.org/abs/2510.18927)
*Zhiheng Xi,Xin Guo,Yang Nan,Enyu Zhou,Junrui Shen,Wenxiang Chen,Jiaqi Liu,Jixuan Huang,Zhihao Zhang,Honglin Guo,Xun Deng,Zhikai Lei,Miao Zheng,Guoteng Wang,Shuo Zhang,Peng Sun,Rui Zheng,Hang Yan,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.LG

TL;DR: 本文提出BAPO方法，通过动态调整裁剪边界来解决离线强化学习中策略熵下降、优化不稳定等问题，在多个基准测试中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在语言模型对齐中面临策略熵急剧下降、优化不稳定甚至崩溃的挑战，需要解决负优势样本主导和固定裁剪机制抑制探索的问题。

Method: 提出BAPO方法，基于熵裁剪规则动态调整裁剪边界，自适应地重新平衡正负贡献，保持熵值并稳定RL优化。

Result: 在AIME 2024和2025基准测试中，7B BAPO模型超越开源对手，32B BAPO模型在同规模模型中达到最先进水平，甚至优于o3-mini和Gemini-2.5-Flash-Thinking等专有系统。

Conclusion: BAPO通过动态裁剪机制有效解决了离线强化学习的稳定性问题，实现了快速、稳定且数据高效的训练，在多个场景下表现出色。

Abstract: Reinforcement learning (RL) has recently become the core paradigm for
aligning and strengthening large language models (LLMs). Yet, applying RL in
off-policy settings--where stale data from past policies are used for
training--improves sample efficiency, but remains challenging: policy entropy
declines sharply, optimization often becomes unstable and may even collapse.
Through theoretical and empirical analysis, we identify two key insights: (i)
an imbalance in optimization, where negative-advantage samples dominate the
policy gradient, suppressing useful behaviors and risking gradient explosions;
and (ii) the derived Entropy-Clip Rule, which reveals that the fixed clipping
mechanism in PPO-like objectives systematically blocks entropy-increasing
updates, thereby driving the policy toward over-exploitation at the expense of
exploration. Building on these insights, we propose BAlanced Policy
Optimization with Adaptive Clipping (BAPO), a simple yet effective method that
dynamically adjusts clipping bounds to adaptively re-balance positive and
negative contributions, preserve entropy, and stabilize RL optimization. Across
diverse off-policy scenarios--including sample replay and partial rollout--BAPO
achieves fast, stable, and data-efficient training. On AIME 2024 and AIME 2025
benchmarks, our 7B BAPO model surpasses open-source counterparts such as
SkyWork-OR1-7B, while our 32B BAPO model not only achieves state-of-the-art
results among models of the same scale but also outperforms leading proprietary
systems like o3-mini and Gemini-2.5-Flash-Thinking.

</details>


### [16] [Scalable LinUCB: Low-Rank Design Matrix Updates for Recommenders with Large Action Spaces](https://arxiv.org/abs/2510.19349)
*Evgenia Shustova,Marina Sheshukova,Sergey Samsonov,Evgeny Frolov*

Main category: cs.LG

TL;DR: 提出了Scalable LinUCB算法，通过动态低秩参数化逆Cholesky因子，实现快速内存高效的线性上下文赌博机操作，解决了传统LinUCB在特征维度和动作空间增长时的计算瓶颈。


<details>
  <summary>Details</summary>
Motivation: 传统LinUCB在推荐系统中训练、推理和内存成本随特征维度和动作空间增长而增加，关键瓶颈是需要更新、求逆和存储吸收交互历史上下文信息的设计矩阵。

Method: 通过动态低秩参数化逆Cholesky式因子，推导数值稳定的秩1和批量更新，无需直接形成整个矩阵；采用投影器分裂积分器进行动态低秩逼近控制内存增长。

Result: 实现了平均每步更新成本O(dr)和内存O(dr)，推理复杂度为O(dr)每动作评估，在推荐系统数据集上验证了算法有效性。

Conclusion: Scalable LinUCB算法解决了LinUCB的计算瓶颈，实现了高效的内存使用和计算性能，适用于大规模推荐系统应用。

Abstract: Linear contextual bandits, especially LinUCB, are widely used in recommender
systems. However, its training, inference, and memory costs grow with feature
dimensionality and the size of the action space. The key bottleneck becomes the
need to update, invert and store a design matrix that absorbs contextual
information from interaction history. In this paper, we introduce Scalable
LinUCB, the algorithm that enables fast and memory efficient operations with
the inverse regularized design matrix. We achieve this through a dynamical
low-rank parametrization of its inverse Cholesky-style factors. We derive
numerically stable rank-1 and batched updates that maintain the inverse without
directly forming the entire matrix. To control memory growth, we employ a
projector-splitting integrator for dynamical low-rank approximation, yielding
average per-step update cost $O(dr)$ and memory $O(dr)$ for approximation rank
$r$. Inference complexity of the suggested algorithm is $O(dr)$ per action
evaluation. Experiments on recommender system datasets demonstrate the
effectiveness of our algorithm.

</details>


### [17] [Policy Learning with Abstention](https://arxiv.org/abs/2510.19672)
*Ayush Sawarni,Jikai Jin,Justin Whitehouse,Vasilis Syrgkanis*

Main category: cs.LG

TL;DR: 本文研究带有弃权机制的政策学习，允许政策在不确定时选择弃权而非强制决策，并在弃权时获得额外奖励。提出了两阶段学习器，先识别近似最优政策集合，然后基于其分歧构建弃权规则。


<details>
  <summary>Details</summary>
Motivation: 传统政策学习算法在预测不确定时仍强制决策，这在高风险环境中存在风险。需要一种允许政策在不确定时弃权的方法，以提高决策的安全性和可靠性。

Method: 提出两阶段学习器：第一阶段识别一组近似最优政策，第二阶段基于这些政策之间的分歧构建弃权规则。使用双重稳健目标处理未知倾向得分情况。

Result: 当倾向得分已知时获得O(1/n)类型的快速遗憾保证，并扩展到未知倾向得分情况。弃权机制还能改善边际条件下的性能保证，连接分布鲁棒政策学习，并支持安全政策改进。

Conclusion: 弃权是政策学习中的多功能工具，能在不确定时提高决策安全性，改善性能保证，增强对数据分布的鲁棒性，并确保相对于基线政策的改进。

Abstract: Policy learning algorithms are widely used in areas such as personalized
medicine and advertising to develop individualized treatment regimes. However,
most methods force a decision even when predictions are uncertain, which is
risky in high-stakes settings. We study policy learning with abstention, where
a policy may defer to a safe default or an expert. When a policy abstains, it
receives a small additive reward on top of the value of a random guess. We
propose a two-stage learner that first identifies a set of near-optimal
policies and then constructs an abstention rule from their disagreements. We
establish fast O(1/n)-type regret guarantees when propensities are known, and
extend these guarantees to the unknown-propensity case via a doubly robust (DR)
objective. We further show that abstention is a versatile tool with direct
applications to other core problems in policy learning: it yields improved
guarantees under margin conditions without the common realizability assumption,
connects to distributionally robust policy learning by hedging against small
data shifts, and supports safe policy improvement by ensuring improvement over
a baseline policy with high probability.

</details>


### [18] [Statistical Inference for Linear Functionals of Online Least-squares SGD when $t \gtrsim d^{1+δ}$](https://arxiv.org/abs/2510.19734)
*Bhavya Agrawalla,Krishnakumar Balasubramanian,Promit Ghosal*

Main category: cs.LG

TL;DR: 本文为在线最小二乘SGD的线性泛函建立了非渐近Berry-Esseen界，在增长维度机制下提供了高斯中心极限定理，显著扩展了先前工作的维度范围并提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 在关键应用中部署SGD需要严格量化其固有不确定性，现有高维推理方法计算昂贵且维度扩展受限。

Method: 提出基于在线SGD的程序，运行时间为O(td)，内存需求为O(d)，并开发了在线方差估计器。

Result: 当迭代次数增长为t ≳ d^(1+δ)时，SGD迭代满足CLT，相比现有方法的t ≳ d^(3/2)要求显著改善。

Conclusion: 建立了第一个完全在线和数据驱动的框架，在接近最优的缩放机制t ≳ d^(1+δ)下为SGD迭代构建置信区间。

Abstract: Stochastic Gradient Descent (SGD) has become a cornerstone method in modern
data science. However, deploying SGD in high-stakes applications necessitates
rigorous quantification of its inherent uncertainty. In this work, we establish
\emph{non-asymptotic Berry--Esseen bounds} for linear functionals of online
least-squares SGD, thereby providing a Gaussian Central Limit Theorem (CLT) in
a \emph{growing-dimensional regime}. Existing approaches to high-dimensional
inference for projection parameters, such as~\cite{chang2023inference}, rely on
inverting empirical covariance matrices and require at least $t \gtrsim
d^{3/2}$ iterations to achieve finite-sample Berry--Esseen guarantees,
rendering them computationally expensive and restrictive in the allowable
dimensional scaling. In contrast, we show that a CLT holds for SGD iterates
when the number of iterations grows as $t \gtrsim d^{1+\delta}$ for any $\delta
> 0$, significantly extending the dimensional regime permitted by prior works
while improving computational efficiency. The proposed online SGD-based
procedure operates in $\mathcal{O}(td)$ time and requires only $\mathcal{O}(d)$
memory, in contrast to the $\mathcal{O}(td^2 + d^3)$ runtime of
covariance-inversion methods. To render the theory practically applicable, we
further develop an \emph{online variance estimator} for the asymptotic variance
appearing in the CLT and establish \emph{high-probability deviation bounds} for
this estimator. Collectively, these results yield the first fully online and
data-driven framework for constructing confidence intervals for SGD iterates in
the near-optimal scaling regime $t \gtrsim d^{1+\delta}$.

</details>


### [19] [An Encode-then-Decompose Approach to Unsupervised Time Series Anomaly Detection on Contaminated Training Data--Extended Version](https://arxiv.org/abs/2510.18998)
*Buang Zhang,Tung Kieu,Xiangfei Qiu,Chenjuan Guo,Jilin Hu,Aoying Zhou,Christian S. Jensen,Bin Yang*

Main category: cs.LG

TL;DR: 本文提出了一种新的编码-分解范式，通过将编码表示分解为稳定和辅助表示，增强了在污染时间序列训练时的鲁棒性，并使用基于互信息的指标替代重构误差来识别异常。


<details>
  <summary>Details</summary>
Motivation: 时间序列异常检测在大型系统中应用广泛，无监督方法因无需标注而备受关注。自编码器是常用方法，但其学习到的表示对训练时间序列中的异常敏感，导致准确性降低。

Method: 提出编码-分解范式，将编码表示分解为稳定和辅助表示，并使用基于互信息的指标替代重构误差来识别异常。

Result: 在八个常用的多变量和单变量时间序列基准测试中表现出竞争性或最先进的性能，并对不同污染比例的时间序列展现出鲁棒性。

Conclusion: 所提出的方法在时间序列异常检测中具有更好的鲁棒性和准确性，特别是在训练数据包含异常的情况下。

Abstract: Time series anomaly detection is important in modern large-scale systems and
is applied in a variety of domains to analyze and monitor the operation of
diverse systems. Unsupervised approaches have received widespread interest, as
they do not require anomaly labels during training, thus avoiding potentially
high costs and having wider applications. Among these, autoencoders have
received extensive attention. They use reconstruction errors from compressed
representations to define anomaly scores. However, representations learned by
autoencoders are sensitive to anomalies in training time series, causing
reduced accuracy. We propose a novel encode-then-decompose paradigm, where we
decompose the encoded representation into stable and auxiliary representations,
thereby enhancing the robustness when training with contaminated time series.
In addition, we propose a novel mutual information based metric to replace the
reconstruction errors for identifying anomalies. Our proposal demonstrates
competitive or state-of-the-art performance on eight commonly used multi- and
univariate time series benchmarks and exhibits robustness to time series with
different contamination ratios.

</details>


### [20] [POLAR: Policy-based Layerwise Reinforcement Learning Method for Stealthy Backdoor Attacks in Federated Learning](https://arxiv.org/abs/2510.19056)
*Kuai Yu,Xiaoyu Wu,Peishen Yan,Qingqian Yang,Linshan Jiang,Hao Wang,Yang Hua,Tao Song,Haibing Guan*

Main category: cs.LG

TL;DR: POLAR是一种基于强化学习的联邦学习后门攻击方法，通过策略梯度优化选择关键层进行攻击，在保持隐蔽性的同时提高攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习后门攻击方法基于规则选择关键层，未考虑层间相互关系，导致效果不佳且容易被先进防御检测。

Method: 提出POLAR框架，采用轻量级伯努利采样的强化学习方法，动态学习攻击策略，通过策略梯度更新优化层选择，并引入正则化约束限制修改层数以确保隐蔽性。

Result: 实验表明POLAR在对抗六种最先进防御方法时，比最新攻击方法性能提升高达40%。

Conclusion: POLAR成功将强化学习应用于层间后门攻击，显著提高了攻击效果和隐蔽性。

Abstract: Federated Learning (FL) enables decentralized model training across multiple
clients without exposing local data, but its distributed feature makes it
vulnerable to backdoor attacks. Despite early FL backdoor attacks modifying
entire models, recent studies have explored the concept of backdoor-critical
(BC) layers, which poison the chosen influential layers to maintain
stealthiness while achieving high effectiveness. However, existing BC layers
approaches rely on rule-based selection without consideration of the
interrelations between layers, making them ineffective and prone to detection
by advanced defenses. In this paper, we propose POLAR (POlicy-based LAyerwise
Reinforcement learning), the first pipeline to creatively adopt RL to solve the
BC layer selection problem in layer-wise backdoor attack. Different from other
commonly used RL paradigm, POLAR is lightweight with Bernoulli sampling. POLAR
dynamically learns an attack strategy, optimizing layer selection using policy
gradient updates based on backdoor success rate (BSR) improvements. To ensure
stealthiness, we introduce a regularization constraint that limits the number
of modified layers by penalizing large attack footprints. Extensive experiments
demonstrate that POLAR outperforms the latest attack methods by up to 40%
against six state-of-the-art (SOTA) defenses.

</details>


### [21] [MetaCluster: Enabling Deep Compression of Kolmogorov-Arnold Network](https://arxiv.org/abs/2510.19105)
*Matthew Raffel,Adwaith Renjith,Lizhong Chen*

Main category: cs.LG

TL;DR: MetaCluster框架通过元学习和聚类技术显著压缩Kolmogorov-Arnold Networks的参数存储，在保持精度的同时实现高达80倍的参数存储减少。


<details>
  <summary>Details</summary>
Motivation: KANs用向量权重替代标量权重提高了表达能力，但导致参数和内存呈倍数增长，需要高效的压缩方法。

Method: 使用轻量级元学习器将低维嵌入映射到系数向量，使其位于低维流形上，然后通过K-means聚类用共享质心替代每边向量，最后微调质心码本恢复精度损失。

Result: 在MNIST、CIFAR-10和CIFAR-100数据集上，对标准KANs和ConvKANs使用多种基函数，实现了高达80倍的参数存储减少，且无精度损失。

Conclusion: MetaCluster框架成功解决了KANs参数存储问题，通过元学习和聚类技术实现了高效的模型压缩，为KANs的实际应用提供了可行方案。

Abstract: Kolmogorov-Arnold Networks (KANs) replace scalar weights with per-edge
vectors of basis coefficients, thereby boosting expressivity and accuracy but
at the same time resulting in a multiplicative increase in parameters and
memory. We propose MetaCluster, a framework that makes KANs highly compressible
without sacrificing accuracy. Specifically, a lightweight meta-learner, trained
jointly with the KAN, is used to map low-dimensional embedding to coefficient
vectors, shaping them to lie on a low-dimensional manifold that is amenable to
clustering. We then run K-means in coefficient space and replace per-edge
vectors with shared centroids. Afterwards, the meta-learner can be discarded,
and a brief fine-tuning of the centroid codebook recovers any residual accuracy
loss. The resulting model stores only a small codebook and per-edge indices,
exploiting the vector nature of KAN parameters to amortize storage across
multiple coefficients. On MNIST, CIFAR-10, and CIFAR-100, across standard KANs
and ConvKANs using multiple basis functions, MetaCluster achieves a reduction
of up to 80$\times$ in parameter storage, with no loss in accuracy. Code will
be released upon publication.

</details>


### [22] [Subliminal Corruption: Mechanisms, Thresholds, and Interpretability](https://arxiv.org/abs/2510.19152)
*Reya Vir,Sarvesh Bhatnagar*

Main category: cs.LG

TL;DR: 本文研究了AI系统在微调合成数据时出现的潜意识污染现象，即不良特征通过语义中性数据传播，绕过安全检查。通过GPT-2的师生设置实验，发现潜意识污染会导致行为交叉、在临界阈值发生急剧相变，且污染机制难以检测。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型越来越多地使用合成数据进行微调，存在微妙错位通过互联AI系统传播的关键风险。需要量化理解潜意识污染的动力学机制。

Method: 使用GPT-2构建师生设置，系统研究潜意识污染的缩放规律、阈值和机制，包括行为交叉分析、相变阈值检测和可解释性分析。

Result: 实验揭示三个关键发现：(1)潜意识污染导致行为交叉，降低模型整体对齐性；(2)对齐性在污染数据临界阈值处发生急剧相变；(3)污染机制模仿自然微调过程，难以检测。

Conclusion: 结果表明依赖合成数据的AI系统存在关键脆弱性，需要能够考虑潜在威胁的新安全协议。

Abstract: As machine learning models are increasingly fine-tuned on synthetic data,
there is a critical risk of subtle misalignments spreading through
interconnected AI systems. This paper investigates subliminal corruption, which
we define as undesirable traits are transmitted through semantically neutral
data, bypassing standard safety checks. While this phenomenon has been
identified, a quantitative understanding of its dynamics is missing. To address
this gap, we present a systematic study of the scaling laws, thresholds, and
mechanisms of subliminal corruption using a teacher-student setup with GPT-2.
Our experiments reveal three key findings: (1) subliminal corruption causes
behavioral crossover, degrading the model's overall alignment, not just the
targeted trait; (2) alignment fails in a sharp phase transition at a critical
threshold of poisoned data, rather than degrading gradually; and (3)
interpretability analysis shows the corruption mechanism mimics the model's
natural fine-tuning process, making it difficult to detect. These results
demonstrate a critical vulnerability in AI systems that rely on synthetic data
and highlight the need for new safety protocols that can account for latent
threats.

</details>


### [23] [Preliminary Use of Vision Language Model Driven Extraction of Mouse Behavior Towards Understanding Fear Expression](https://arxiv.org/abs/2510.19160)
*Paimon Goulart,Jordan Steinhauser,Kylene Shuler,Edward Korzus,Jia Chen,Evangelos E. Papalexakis*

Main category: cs.LG

TL;DR: 该研究开发了一个视觉语言模型，用于通过文本输入对视频中的小鼠行为进行分类，生成随时间变化的行为向量，无需模型微调即可获得高准确率。


<details>
  <summary>Details</summary>
Motivation: 整合多样数据对改善科学探索至关重要，该研究旨在构建一个能够对小鼠在环境中各种行为进行分类的视觉语言模型，为跨学科研究人员提供全面的行为数据集。

Method: 使用开源的Qwen2.5-VL模型，通过提示工程、上下文学习（ICL）和帧级预处理来增强性能，无需模型微调。

Result: 这些方法均有助于改进分类性能，组合使用时在所有行为类别（包括罕见的冻结和逃跑行为）上都获得了较高的F1分数。

Conclusion: 该模型将支持跨学科研究人员整合不同时间点和环境中的行为特征，构建能够解决复杂研究问题的综合数据集。

Abstract: Integration of diverse data will be a pivotal step towards improving
scientific explorations in many disciplines. This work establishes a
vision-language model (VLM) that encodes videos with text input in order to
classify various behaviors of a mouse existing in and engaging with their
environment. Importantly, this model produces a behavioral vector over time for
each subject and for each session the subject undergoes. The output is a
valuable dataset that few programs are able to produce with as high accuracy
and with minimal user input. Specifically, we use the open-source Qwen2.5-VL
model and enhance its performance through prompts, in-context learning (ICL)
with labeled examples, and frame-level preprocessing. We found that each of
these methods contributes to improved classification, and that combining them
results in strong F1 scores across all behaviors, including rare classes like
freezing and fleeing, without any model fine-tuning. Overall, this model will
support interdisciplinary researchers studying mouse behavior by enabling them
to integrate diverse behavioral features, measured across multiple time points
and environments, into a comprehensive dataset that can address complex
research questions.

</details>


### [24] [Natural Gradient VI: Guarantees for Non-Conjugate Models](https://arxiv.org/abs/2510.19163)
*Fangyuan Sun,Ilyas Fatkhullin,Niao He*

Main category: cs.LG

TL;DR: 本文分析了自然梯度变分推断(NGVI)在非共轭模型中的理论性质，提出了相对平滑性条件，设计了改进算法并证明了收敛性，揭示了变分损失函数的隐藏凸性。


<details>
  <summary>Details</summary>
Motivation: NGVI作为变分推断的常用方法，在非共轭似然情况下的理论分析仍然有限，现有收敛保证仅适用于共轭模型，无法扩展到非共轭设置。

Method: 针对均值场参数化，推导变分损失满足相对平滑性的充分条件，提出包含非欧投影的改进NGVI算法，并在特定结构假设下分析隐藏凸性。

Result: 证明了改进算法的全局非渐近收敛到驻点，在额外结构假设下建立了NGVI快速全局收敛到全局最优解的结果。

Conclusion: 这些结果为NGVI在挑战性推断场景中的几何性质和收敛行为提供了新的理论见解。

Abstract: Stochastic Natural Gradient Variational Inference (NGVI) is a widely used
method for approximating posterior distribution in probabilistic models.
Despite its empirical success and foundational role in variational inference,
its theoretical underpinnings remain limited, particularly in the case of
non-conjugate likelihoods. While NGVI has been shown to be a special instance
of Stochastic Mirror Descent, and recent work has provided convergence
guarantees using relative smoothness and strong convexity for conjugate models,
these results do not extend to the non-conjugate setting, where the variational
loss becomes non-convex and harder to analyze. In this work, we focus on
mean-field parameterization and advance the theoretical understanding of NGVI
in three key directions. First, we derive sufficient conditions under which the
variational loss satisfies relative smoothness with respect to a suitable
mirror map. Second, leveraging this structure, we propose a modified NGVI
algorithm incorporating non-Euclidean projections and prove its global
non-asymptotic convergence to a stationary point. Finally, under additional
structural assumptions about the likelihood, we uncover hidden convexity
properties of the variational loss and establish fast global convergence of
NGVI to a global optimum. These results provide new insights into the geometry
and convergence behavior of NGVI in challenging inference settings.

</details>


### [25] [Imbalanced Gradients in RL Post-Training of Multi-Task LLMs](https://arxiv.org/abs/2510.19178)
*Runzhe Wu,Ankur Samanta,Ayush Jain,Scott Fujimoto,Jeongyeol Kwon,Ben Kretzu,Youliang Yu,Kaveh Hassani,Boris Vidolov,Yonathan Efroni*

Main category: cs.LG

TL;DR: 研究发现多任务后训练中梯度不平衡问题：某些任务产生显著更大的梯度，导致优化偏向这些任务，但大梯度并不一定带来更大的学习收益。


<details>
  <summary>Details</summary>
Motivation: 多任务后训练通常假设所有任务贡献相似大小的梯度，但本文发现这一假设在强化学习后训练中不成立，某些任务会产生显著更大的梯度，导致优化偏差。

Method: 通过分析不同任务在RL后训练中的梯度大小和学习收益关系，研究梯度不平衡现象及其对优化的影响。

Result: 发现大梯度任务并不一定获得更大的学习收益，梯度不平衡无法用训练奖励或优势等典型统计量解释，表明其源于任务间的固有差异。

Conclusion: 警告不要简单混合数据集，呼吁未来研究开发基于梯度水平的校正方法来解决LLMs中的梯度不平衡问题。

Abstract: Multi-task post-training of large language models (LLMs) is typically
performed by mixing datasets from different tasks and optimizing them jointly.
This approach implicitly assumes that all tasks contribute gradients of similar
magnitudes; when this assumption fails, optimization becomes biased toward
large-gradient tasks. In this paper, however, we show that this assumption
fails in RL post-training: certain tasks produce significantly larger
gradients, thus biasing updates toward those tasks. Such gradient imbalance
would be justified only if larger gradients implied larger learning gains on
the tasks (i.e., larger performance improvements) -- but we find this is not
true. Large-gradient tasks can achieve similar or even much lower learning
gains than small-gradient ones. Further analyses reveal that these gradient
imbalances cannot be explained by typical training statistics such as training
rewards or advantages, suggesting that they arise from the inherent differences
between tasks. This cautions against naive dataset mixing and calls for future
work on principled gradient-level corrections for LLMs.

</details>


### [26] [Brain-Inspired Perspective on Configurations: Unsupervised Similarity and Early Cognition](https://arxiv.org/abs/2510.19229)
*Juntang Wang,Yihan Wang,Hao Wu,Dongmian Zou,Shixin Xu*

Main category: cs.LG

TL;DR: 本文提出了一种受大脑启发的配置框架，使用单一分辨率参数和吸引-排斥动力学实现层次聚类、新颖性检测和灵活适应，在标准聚类指标上表现优异，新颖性检测AUC达87%，动态类别演化稳定性提升35%。


<details>
  <summary>Details</summary>
Motivation: 婴儿能够无监督地发现类别、检测新颖性并适应新环境，这对当前机器学习构成挑战，因此需要开发受大脑启发的计算模型来模拟这种早期认知分类能力。

Method: 提出配置框架，使用有限分辨率聚类方法，通过单一分辨率参数和吸引-排斥动力学实现层次组织、新颖性敏感性和灵活适应性，并引入mheatmap方法提供比例热图和重分配算法来评估多分辨率和动态行为。

Result: 在多个数据集上，配置框架在标准聚类指标上具有竞争力，新颖性检测AUC达到87%，在动态类别演化过程中稳定性提升35%。

Conclusion: 配置框架为早期认知分类提供了一个原则性的计算模型，是迈向受大脑启发的AI的重要一步。

Abstract: Infants discover categories, detect novelty, and adapt to new contexts
without supervision -- a challenge for current machine learning. We present a
brain-inspired perspective on configurations, a finite-resolution clustering
framework that uses a single resolution parameter and attraction-repulsion
dynamics to yield hierarchical organization, novelty sensitivity, and flexible
adaptation. To evaluate these properties, we introduce mheatmap, which provides
proportional heatmaps and a reassignment algorithm to fairly assess
multi-resolution and dynamic behavior. Across datasets, configurations are
competitive on standard clustering metrics, achieve 87% AUC in novelty
detection, and show 35% better stability during dynamic category evolution.
These results position configurations as a principled computational model of
early cognitive categorization and a step toward brain-inspired AI.

</details>


### [27] [SPOT: Scalable Policy Optimization with Trees for Markov Decision Processes](https://arxiv.org/abs/2510.19241)
*Xuyuan Xiong,Pedro Chumpitaz-Flores,Kaixun Hua,Cheng Hua*

Main category: cs.LG

TL;DR: SPOT是一种新颖的强化学习方法，通过混合整数线性规划优化决策树策略，显著提高了可解释性策略的计算效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 在高风险决策中，可解释的强化学习策略至关重要，但在马尔可夫决策过程中优化决策树策略仍然具有挑战性。

Method: 将优化问题表述为混合整数线性规划，采用缩减空间的分支定界方法，将MDP动态与树结构约束解耦，实现高效并行搜索。

Result: 在标准基准测试中，SPOT实现了显著加速，可扩展到具有更多状态的大型MDP，生成的可解释决策树策略紧凑且不牺牲性能。

Conclusion: 该方法同时实现了可解释性和可扩展性，比现有方法快一个数量级地提供高质量策略。

Abstract: Interpretable reinforcement learning policies are essential for high-stakes
decision-making, yet optimizing decision tree policies in Markov Decision
Processes (MDPs) remains challenging. We propose SPOT, a novel method for
computing decision tree policies, which formulates the optimization problem as
a mixed-integer linear program (MILP). To enhance efficiency, we employ a
reduced-space branch-and-bound approach that decouples the MDP dynamics from
tree-structure constraints, enabling efficient parallel search. This
significantly improves runtime and scalability compared to previous methods.
Our approach ensures that each iteration yields the optimal decision tree.
Experimental results on standard benchmarks demonstrate that SPOT achieves
substantial speedup and scales to larger MDPs with a significantly higher
number of states. The resulting decision tree policies are interpretable and
compact, maintaining transparency without compromising performance. These
results demonstrate that our approach simultaneously achieves interpretability
and scalability, delivering high-quality policies an order of magnitude faster
than existing approaches.

</details>


### [28] [Mixing Configurations for Downstream Prediction](https://arxiv.org/abs/2510.19248)
*Juntang Wang,Hao Wu,Runkun Guo,Yihan Wang,Dongmian Zou,Shixin Xu*

Main category: cs.LG

TL;DR: 论文提出GraMixC模块，通过提取配置、对齐和融合来改进下游预测任务，在多个数据集上显著提升性能


<details>
  <summary>Details</summary>
Motivation: 人类具有基于相似性分组对象的能力，聚类算法旨在模拟这种认知机制。配置（跨多个分辨率尺度的有效层次聚类）可以在无标签数据下发现，但选择和组合仍依赖于下游任务和输入

Method: 引入GraMixC模块：提取配置，使用反向合并/分割（RMS）技术对齐，通过注意力头融合，然后传递给下游预测器

Result: 在DSN1 16S rRNA培养介质预测任务中，GraMixC将R2分数从0.6提升到0.9；在标准表格基准测试中持续优于单分辨率和静态特征基线

Conclusion: GraMixC通过有效提取和融合多分辨率配置，显著提升了预测性能，为无监督和自监督学习提供了新的解决方案

Abstract: Humans possess an innate ability to group objects by similarity, a cognitive
mechanism that clustering algorithms aim to emulate. Recent advances in
community detection have enabled the discovery of configurations -- valid
hierarchical clusterings across multiple resolution scales -- without requiring
labeled data. In this paper, we formally characterize these configurations and
identify similar emergent structures in register tokens within Vision
Transformers. Unlike register tokens, configurations exhibit lower redundancy
and eliminate the need for ad hoc selection. They can be learned through
unsupervised or self-supervised methods, yet their selection or composition
remains specific to the downstream task and input. Building on these insights,
we introduce GraMixC, a plug-and-play module that extracts configurations,
aligns them using our Reverse Merge/Split (RMS) technique, and fuses them via
attention heads before forwarding them to any downstream predictor. On the DSN1
16S rRNA cultivation-media prediction task, GraMixC improves the R2 score from
0.6 to 0.9 across multiple methods, setting a new state of the art. We further
validate GraMixC on standard tabular benchmarks, where it consistently
outperforms single-resolution and static-feature baselines.

</details>


### [29] [Knowledge Distillation of Uncertainty using Deep Latent Factor Model](https://arxiv.org/abs/2510.19290)
*Sehyun Park,Jongjin Lee,Yunseop Shin,Ilsang Ohn,Yongdai Kim*

Main category: cs.LG

TL;DR: 提出了一种名为高斯蒸馏的新方法，通过深度潜变量模型将教师集成压缩为学生分布，解决了传统知识蒸馏在不确定性保持方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 深度集成在不确定性量化方面表现优异，但其计算和内存需求限制了在真实应用中的部署。现有知识蒸馏技术在压缩集成时难以保持不确定性，因为减小DNN尺寸通常会导致方差减小。

Method: 引入高斯蒸馏方法，通过深度潜变量模型将教师集成视为随机过程的实现，使用期望最大化算法稳定估计均值函数和协方差函数。

Result: 在多个基准数据集上的实验表明，高斯蒸馏优于现有基线方法，并且在语言模型微调和分布偏移问题上表现良好。

Conclusion: 高斯蒸馏提供了一种有效的分布蒸馏方法，能够成功压缩教师集成并保持不确定性量化能力，适用于实际部署场景。

Abstract: Deep ensembles deliver state-of-the-art, reliable uncertainty quantification,
but their heavy computational and memory requirements hinder their practical
deployments to real applications such as on-device AI. Knowledge distillation
compresses an ensemble into small student models, but existing techniques
struggle to preserve uncertainty partly because reducing the size of DNNs
typically results in variation reduction. To resolve this limitation, we
introduce a new method of distribution distillation (i.e. compressing a teacher
ensemble into a student distribution instead of a student ensemble) called
Gaussian distillation, which estimates the distribution of a teacher ensemble
through a special Gaussian process called the deep latent factor model (DLF) by
treating each member of the teacher ensemble as a realization of a certain
stochastic process. The mean and covariance functions in the DLF model are
estimated stably by using the expectation-maximization (EM) algorithm. By using
multiple benchmark datasets, we demonstrate that the proposed Gaussian
distillation outperforms existing baselines. In addition, we illustrate that
Gaussian distillation works well for fine-tuning of language models and
distribution shift problems.

</details>


### [30] [Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning](https://arxiv.org/abs/2510.19338)
*Ling Team,Bin Han,Caizhi Tang,Chen Liang,Donghao Zhang,Fan Yuan,Feng Zhu,Jie Gao,Jingyu Hu,Longfei Li,Meng Li,Mingyang Zhang,Peijie Jiang,Peng Jiao,Qian Zhao,Qingyuan Yang,Wenbo Shen,Xinxing Yang,Yalin Zhang,Yankun Ren,Yao Zhao,Yibo Cao,Yixuan Sun,Yue Zhang,Yuchen Fang,Zibin Lin,Zixuan Cheng,Jun Zhou*

Main category: cs.LG

TL;DR: 提出了Ring-linear模型系列，包括Ring-mini-linear-2.0和Ring-flash-linear-2.0，采用混合注意力架构，显著降低长上下文推理的I/O和计算开销，推理成本降至密集模型的1/10。


<details>
  <summary>Details</summary>
Motivation: 解决长上下文推理场景中传统注意力机制的高I/O和计算开销问题，通过混合架构优化推理效率。

Method: 采用线性注意力和softmax注意力的混合架构，系统探索不同注意力机制的比例，利用自研的高性能FP8算子库linghe提升训练效率。

Result: Ring-mini-linear-2.0含16B参数和957M激活，Ring-flash-linear-2.0含104B参数和6.1B激活；推理成本比32B密集模型降低90%，比原Ring系列降低50%以上；训练效率提升50%。

Conclusion: 混合注意力架构在长上下文推理中具有显著优势，实现了高效稳定的模型优化，在多个复杂推理基准测试中保持SOTA性能。

Abstract: In this technical report, we present the Ring-linear model series,
specifically including Ring-mini-linear-2.0 and Ring-flash-linear-2.0.
Ring-mini-linear-2.0 comprises 16B parameters and 957M activations, while
Ring-flash-linear-2.0 contains 104B parameters and 6.1B activations. Both
models adopt a hybrid architecture that effectively integrates linear attention
and softmax attention, significantly reducing I/O and computational overhead in
long-context inference scenarios. Compared to a 32 billion parameter dense
model, this series reduces inference cost to 1/10, and compared to the original
Ring series, the cost is also reduced by over 50%. Furthermore, through
systematic exploration of the ratio between different attention mechanisms in
the hybrid architecture, we have identified the currently optimal model
structure. Additionally, by leveraging our self-developed high-performance FP8
operator library-linghe, overall training efficiency has been improved by 50%.
Benefiting from the high alignment between the training and inference engine
operators, the models can undergo long-term, stable, and highly efficient
optimization during the reinforcement learning phase, consistently maintaining
SOTA performance across multiple challenging complex reasoning benchmarks.

</details>


### [31] [Foundation Model Forecasts: Form and Function](https://arxiv.org/abs/2510.19345)
*Alvaro Perez-Diaz,James C. Loach,Danielle E. Toutoungi,Lee Middleton*

Main category: cs.LG

TL;DR: 该论文分析了时间序列基础模型（TSFMs）的预测类型与实际应用价值的关系，指出仅关注预测精度不足以确定实用价值，预测类型（点预测、分位数预测、参数预测或轨迹集成）对支持的操作任务有根本性约束。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列基础模型虽然取得了良好的预测精度，但精度本身并不能完全决定其实际应用价值。许多操作任务需要轨迹集成预测来保持时间依赖性，而现有模型中有三分之二仅产生点预测或参数预测，这限制了它们的实际应用范围。

Method: 通过调查近期的时间序列基础模型，分析不同预测类型之间的转换可能性，证明边际分布无法确定路径依赖事件概率，并将六种基本预测任务映射到最小充分预测类型，提供任务对齐的评估框架。

Result: 研究发现轨迹集成可以通过边际化转换为更简单的形式，但反向转换需要施加时间依赖性；边际分布不能唯一确定路径依赖事件概率，因为无限多个联合分布可以共享相同的边际分布但对操作问题给出不同答案。

Conclusion: 预测类型而非精度决定了实际效用，需要根据具体操作任务选择合适的预测类型，并采用任务对齐的评估方法来确保预测的实际应用价值。

Abstract: Time-series foundation models (TSFMs) achieve strong forecast accuracy, yet
accuracy alone does not determine practical value. The form of a forecast --
point, quantile, parametric, or trajectory ensemble -- fundamentally constrains
which operational tasks it can support. We survey recent TSFMs and find that
two-thirds produce only point or parametric forecasts, while many operational
tasks require trajectory ensembles that preserve temporal dependence. We
establish when forecast types can be converted and when they cannot: trajectory
ensembles convert to simpler forms via marginalization without additional
assumptions, but the reverse requires imposing temporal dependence through
copulas or conformal methods. We prove that marginals cannot determine
path-dependent event probabilities -- infinitely many joint distributions share
identical marginals but yield different answers to operational questions. We
map six fundamental forecasting tasks to minimal sufficient forecast types and
provide a task-aligned evaluation framework. Our analysis clarifies when
forecast type, not accuracy, differentiates practical utility.

</details>


### [32] [FairNet: Dynamic Fairness Correction without Performance Loss via Contrastive Conditional LoRA](https://arxiv.org/abs/2510.19421)
*Songqi Zhou,Zeyuan Liu,Benben Jiang*

Main category: cs.LG

TL;DR: FairNet是一个动态实例级公平性校正框架，通过偏置检测器和条件低秩适配器，仅在识别为偏置的实例上激活公平性校正机制，同时保持无偏置实例的性能。


<details>
  <summary>Details</summary>
Motivation: 现有去偏方法通常会在性能上做出妥协，依赖静态校正策略，难以处理数据稀疏问题，特别是在少数群体中。它们对敏感属性的利用也不理想，要么过度依赖完整属性标注，要么完全忽略这些属性。

Method: FairNet集成了偏置检测器和条件低秩适配器(LoRA)，使用新的对比损失函数训练LoRA模块，专门设计用于最小化不同敏感群体间的类内表示差异，有效解决少数群体的欠拟合问题。

Result: 理论分析表明，在偏置检测器具有中等TPR/FPR的情况下，FairNet能够提升最差群体的性能而不降低整体模型性能，甚至可能带来轻微的性能提升。在多种视觉和语言基准测试上的综合实证评估验证了FairNet的有效性。

Conclusion: FairNet提供了一个灵活处理完整、部分或完全缺失敏感属性标签场景的动态公平性校正框架，能够有效提升模型公平性同时保持性能。

Abstract: Ensuring fairness in machine learning models is a critical challenge.
Existing debiasing methods often compromise performance, rely on static
correction strategies, and struggle with data sparsity, particularly within
minority groups. Furthermore, their utilization of sensitive attributes is
often suboptimal, either depending excessively on complete attribute labeling
or disregarding these attributes entirely. To overcome these limitations, we
propose FairNet, a novel framework for dynamic, instance-level fairness
correction. FairNet integrates a bias detector with conditional low-rank
adaptation (LoRA), which enables selective activation of the fairness
correction mechanism exclusively for instances identified as biased, and
thereby preserve performance on unbiased instances. A key contribution is a new
contrastive loss function for training the LoRA module, specifically designed
to minimize intra-class representation disparities across different sensitive
groups and effectively address underfitting in minority groups. The FairNet
framework can flexibly handle scenarios with complete, partial, or entirely
absent sensitive attribute labels. Theoretical analysis confirms that, under
moderate TPR/FPR for the bias detector, FairNet can enhance the performance of
the worst group without diminishing overall model performance, and potentially
yield slight performance improvements. Comprehensive empirical evaluations
across diverse vision and language benchmarks validate the effectiveness of
FairNet.

</details>


### [33] [A Concrete Roadmap towards Safety Cases based on Chain-of-Thought Monitoring](https://arxiv.org/abs/2510.19476)
*Julian Schulz*

Main category: cs.LG

TL;DR: 本文提出基于思维链监控的安全案例路线图，通过确保模型在无思维链时缺乏危险能力，以及思维链启用的危险能力可被检测，来构建AI安全案例。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统接近危险能力水平，传统安全案例方法已不足，需要替代方案来确保安全性。

Method: 提出两阶段安全案例：1) 建立模型在无思维链时缺乏危险能力；2) 确保思维链启用的危险能力可被监控检测。分析神经语言和编码推理等威胁，评估现有技术保持思维链忠实性。

Result: 系统分析了监控性威胁（神经语言、编码推理），评估了保持思维链忠实性的技术，并建立预测市场来评估可行性。

Conclusion: 思维链监控可能支持控制和可信度安全案例，为AI系统安全提供了一条有前景的研究路径。

Abstract: As AI systems approach dangerous capability levels where inability safety
cases become insufficient, we need alternative approaches to ensure safety.
This paper presents a roadmap for constructing safety cases based on
chain-of-thought (CoT) monitoring in reasoning models and outlines our research
agenda. We argue that CoT monitoring might support both control and
trustworthiness safety cases. We propose a two-part safety case: (1)
establishing that models lack dangerous capabilities when operating without
their CoT, and (2) ensuring that any dangerous capabilities enabled by a CoT
are detectable by CoT monitoring. We systematically examine two threats to
monitorability: neuralese and encoded reasoning, which we categorize into three
forms (linguistic drift, steganography, and alien reasoning) and analyze their
potential drivers. We evaluate existing and novel techniques for maintaining
CoT faithfulness. For cases where models produce non-monitorable reasoning, we
explore the possibility of extracting a monitorable CoT from a non-monitorable
CoT. To assess the viability of CoT monitoring safety cases, we establish
prediction markets to aggregate forecasts on key technical milestones
influencing their feasibility.

</details>


### [34] [Graph Unlearning Meets Influence-aware Negative Preference Optimization](https://arxiv.org/abs/2510.19479)
*Qiang Chen,Zhongze Wu,Ang He,Xi Lin,Shuo Jiang,Shan You,Chang Xu,Yi Chen,Xiu Su*

Main category: cs.LG

TL;DR: INPO是一个基于影响感知的负偏好优化框架，通过减缓梯度上升的发散速度来提高图遗忘过程中的模型效用鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的图遗忘模型使用梯度上升在遗忘集上实现遗忘，但这种方法导致模型效用在遗忘过程中急剧下降，主要原因是梯度上升的发散速度过快。

Method: 1. 分析NPO具有较慢的发散速度；2. 理论证明遗忘高影响边可以减少遗忘的影响；3. 设计影响感知的消息函数来放大被遗忘边的影响并减轻遗忘集与保留集之间的紧密拓扑耦合；4. 使用基于移除的方法快速估计每条边的影响；5. 从拓扑角度提出拓扑熵损失以避免遗忘过程中局部结构的过度信息损失。

Result: 在五个真实世界数据集上的广泛实验表明，基于INPO的模型在所有遗忘质量指标上都达到了最先进的性能，同时保持了模型的效用。

Conclusion: INPO框架通过减缓发散速度和改善模型效用鲁棒性，在图遗忘任务中实现了优异的性能。

Abstract: Recent advancements in graph unlearning models have enhanced model utility by
preserving the node representation essentially invariant, while using gradient
ascent on the forget set to achieve unlearning. However, this approach causes a
drastic degradation in model utility during the unlearning process due to the
rapid divergence speed of gradient ascent. In this paper, we introduce
\textbf{INPO}, an \textbf{I}nfluence-aware \textbf{N}egative
\textbf{P}reference \textbf{O}ptimization framework that focuses on slowing the
divergence speed and improving the robustness of the model utility to the
unlearning process. Specifically, we first analyze that NPO has slower
divergence speed and theoretically propose that unlearning high-influence edges
can reduce impact of unlearning. We design an influence-aware message function
to amplify the influence of unlearned edges and mitigate the tight topological
coupling between the forget set and the retain set. The influence of each edge
is quickly estimated by a removal-based method. Additionally, we propose a
topological entropy loss from the perspective of topology to avoid excessive
information loss in the local structure during unlearning. Extensive
experiments conducted on five real-world datasets demonstrate that INPO-based
model achieves state-of-the-art performance on all forget quality metrics while
maintaining the model's utility. Codes are available at
\href{https://github.com/sh-qiangchen/INPO}{https://github.com/sh-qiangchen/INPO}.

</details>


### [35] [A Markov Decision Process for Variable Selection in Branch & Bound](https://arxiv.org/abs/2510.19348)
*Paul Strang,Zacharie Alès,Côme Bissuel,Olivier Juan,Safia Kedad-Sidhoum,Emmanuel Rachelson*

Main category: cs.LG

TL;DR: 本文提出了BBMDP，一种用于分支定界法中变量选择的马尔可夫决策过程框架，通过强化学习算法学习最优分支启发式策略，在四个标准混合整数线性规划基准测试中优于现有最先进的RL智能体。


<details>
  <summary>Details</summary>
Motivation: 分支定界法在解决混合整数线性规划问题时，变量选择启发式策略对求解器性能有重要影响。现有研究尝试使用强化学习来学习最优分支策略，但缺乏统一的MDP框架。

Method: 提出了BBMDP，一个基于马尔可夫决策过程的变量选择框架，可以应用广泛的强化学习算法来学习最优分支启发式策略。

Result: 计算实验验证了该模型的有效性，提出的分支智能体在四个标准MILP基准测试中优于先前最先进的RL智能体。

Conclusion: BBMDP提供了一个原则性的MDP框架，能够有效学习分支定界法中的最优变量选择策略，显著提升求解器性能。

Abstract: Mixed-Integer Linear Programming (MILP) is a powerful framework used to
address a wide range of NP-hard combinatorial optimization problems, often
solved by Branch and Bound (B&B). A key factor influencing the performance of
B&B solvers is the variable selection heuristic governing branching decisions.
Recent contributions have sought to adapt reinforcement learning (RL)
algorithms to the B&B setting to learn optimal branching policies, through
Markov Decision Processes (MDP) inspired formulations, and ad hoc convergence
theorems and algorithms. In this work, we introduce BBMDP, a principled vanilla
MDP formulation for variable selection in B&B, allowing to leverage a broad
range of RL algorithms for the purpose of learning optimal B\&B heuristics.
Computational experiments validate our model empirically, as our branching
agent outperforms prior state-of-the-art RL agents on four standard MILP
benchmarks.

</details>


### [36] [Optimizing the Unknown: Black Box Bayesian Optimization with Energy-Based Model and Reinforcement Learning](https://arxiv.org/abs/2510.19530)
*Ruiyao Miao,Junren Xiao,Shiya Tsang,Hui Xiong,Yingnian Wu*

Main category: cs.LG

TL;DR: 提出REBMBO方法，结合高斯过程和能量模型，使用PPO算法进行自适应多步前瞻，克服传统贝叶斯优化的单步偏差问题


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯优化方法存在显著的单步偏差，容易收敛到局部最优，在复杂或高维任务中表现不佳。黑盒优化在科学和工程领域取得成功，特别是在函数评估成本高且梯度不可用时。

Method: 集成高斯过程进行局部指导，使用能量模型捕捉全局结构信息。将贝叶斯优化迭代定义为马尔可夫决策过程，使用近端策略优化进行自适应多步前瞻，动态调整探索深度和方向。

Result: 在合成和真实世界基准测试中进行了广泛实验，确认REBMBO的优越性能。在不同高斯过程配置下的额外分析进一步突显其适应性和鲁棒性。

Conclusion: REBMBO方法有效克服了传统贝叶斯优化的局限性，在复杂优化任务中表现出色，具有良好的适应性和鲁棒性。

Abstract: Existing Bayesian Optimization (BO) methods typically balance exploration and
exploitation to optimize costly objective functions. However, these methods
often suffer from a significant one-step bias, which may lead to convergence
towards local optima and poor performance in complex or high-dimensional tasks.
Recently, Black-Box Optimization (BBO) has achieved success across various
scientific and engineering domains, particularly when function evaluations are
costly and gradients are unavailable. Motivated by this, we propose the
Reinforced Energy-Based Model for Bayesian Optimization (REBMBO), which
integrates Gaussian Processes (GP) for local guidance with an Energy-Based
Model (EBM) to capture global structural information. Notably, we define each
Bayesian Optimization iteration as a Markov Decision Process (MDP) and use
Proximal Policy Optimization (PPO) for adaptive multi-step lookahead,
dynamically adjusting the depth and direction of exploration to effectively
overcome the limitations of traditional BO methods. We conduct extensive
experiments on synthetic and real-world benchmarks, confirming the superior
performance of REBMBO. Additional analyses across various GP configurations
further highlight its adaptability and robustness.

</details>


### [37] [Insights into the Unknown: Federated Data Diversity Analysis on Molecular Data](https://arxiv.org/abs/2510.19535)
*Markus Bujotzek,Evelyn Trautmann,Calum Hand,Ian Hales*

Main category: cs.LG

TL;DR: 本文研究了联邦聚类方法在分子数据多样性分析中的应用，比较了三种联邦学习方法与集中式方法的性能，并引入了化学信息评估指标SF-ICF。


<details>
  <summary>Details</summary>
Motivation: AI方法在药物发现中的应用受到公共数据集规模和多样性限制，联邦学习能整合私有数据但增加了数据多样性分析的复杂性。

Method: 在八个分子数据集上对三种联邦聚类方法（Fed-kMeans、Fed-PCA+Fed-kMeans、Fed-LSH）与集中式方法进行大规模基准测试，使用标准数学指标和新提出的化学信息指标SF-ICF进行评估。

Result: 联邦聚类方法能有效表示分布式分子数据，结合化学信息指标和客户端可解释性分析对分子数据联邦多样性分析至关重要。

Conclusion: 联邦聚类方法在保护隐私的同时能够有效分析分子数据的多样性，领域知识的融入和客户端可解释性分析对联邦学习在药物发现中的应用具有重要意义。

Abstract: AI methods are increasingly shaping pharmaceutical drug discovery. However,
their translation to industrial applications remains limited due to their
reliance on public datasets, lacking scale and diversity of proprietary
pharmaceutical data. Federated learning (FL) offers a promising approach to
integrate private data into privacy-preserving, collaborative model training
across data silos. This federated data access complicates important
data-centric tasks such as estimating dataset diversity, performing informed
data splits, and understanding the structure of the combined chemical space. To
address this gap, we investigate how well federated clustering methods can
disentangle and represent distributed molecular data. We benchmark three
approaches, Federated kMeans (Fed-kMeans), Federated Principal Component
Analysis combined with Fed-kMeans (Fed-PCA+Fed-kMeans), and Federated
Locality-Sensitive Hashing (Fed-LSH), against their centralized counterparts on
eight diverse molecular datasets. Our evaluation utilizes both, standard
mathematical and a chemistry-informed evaluation metrics, SF-ICF, that we
introduce in this work. The large-scale benchmarking combined with an in-depth
explainability analysis shows the importance of incorporating domain knowledge
through chemistry-informed metrics, and on-client explainability analyses for
federated diversity analysis on molecular data.

</details>


### [38] [Optimization Benchmark for Diffusion Models on Dynamical Systems](https://arxiv.org/abs/2510.19376)
*Fabian Schaipp*

Main category: cs.LG

TL;DR: 本文对扩散模型训练中的优化算法进行了基准测试，发现Muon和SOAP是比AdamW更高效的替代方案（最终损失降低18%），并重新审视了学习率调度和Adam与SGD性能差距等问题。


<details>
  <summary>Details</summary>
Motivation: 当前新优化技术在扩散模型训练中的评估往往缺失，因此需要对扩散模型去噪流轨迹训练中的优化算法进行系统基准测试。

Method: 对近期优化算法进行基准测试，训练扩散模型用于去噪流轨迹，比较不同优化器的性能表现。

Result: Muon和SOAP是比AdamW更高效的替代方案，能够使最终损失降低18%。同时验证了学习率调度对训练动态的影响以及Adam与SGD之间的性能差距。

Conclusion: 在扩散模型训练中，Muon和SOAP是比AdamW更优的优化算法选择，学习率调度和优化器选择对训练效果有显著影响。

Abstract: The training of diffusion models is often absent in the evaluation of new
optimization techniques. In this work, we benchmark recent optimization
algorithms for training a diffusion model for denoising flow trajectories. We
observe that Muon and SOAP are highly efficient alternatives to AdamW (18%
lower final loss). We also revisit several recent phenomena related to the
training of models for text or image applications in the context of diffusion
model training. This includes the impact of the learning-rate schedule on the
training dynamics, and the performance gap between Adam and SGD.

</details>


### [39] [ARA: Adaptive Rank Allocation for Efficient Large Language Model SVD Compression](https://arxiv.org/abs/2510.19389)
*Lin Xv,Jingsheng Gao,Xian Gao,Ting Liu,Yuzhuo Fu*

Main category: cs.LG

TL;DR: 本文提出了一种自适应秩分配（ARA）方法，用于解决大语言模型SVD压缩中不同线性模块的秩分配问题。该方法通过专门的掩码设计和额外损失函数，实现了比现有方法更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有SVD压缩方法存在局限性：启发式算法在受限区域探索解空间，基于掩码的训练难以有效捕捉奇异值谱与可训练参数的关系，且忽略了增益函数在压缩比为1时的非光滑特性，导致训练陷入局部最优。

Method: 提出自适应秩分配（ARA）方法：1）设计专用掩码实现保留秩与可训练参数之间的高效映射和更新；2）采用额外损失函数引导参数选择朝向全局最优解。

Result: 在LLaMA2-7B模型上，80%压缩比下，ARA将WikiText2上的困惑度从8.38降至6.42，平均零样本任务准确率相比均匀压缩提高了9.72个百分点。

Conclusion: ARA方法在基于SVD的LLM压缩中实现了最先进的性能，证明了该方法在秩分配方面的有效性。

Abstract: In the field of large language model (LLM) compression, singular value
decomposition (SVD) is a widely studied and adopted low-rank decomposition
technique. Since SVD operates exclusively on linear modules, and these modules
in LLMs are separated by nonlinear components, SVD can only be applied
independently to each linear module. Under a global compression ratio
constraint, determining the appropriate rank for different linear modules
becomes a critical problem. Existing approaches, such as heuristic algorithms
and mask-based training, have made progress in addressing this challenge.
However, these methods still suffer from several limitations: heuristic
algorithms explore the solution space within restricted regions, while
mask-based training struggles to efficiently capture the relationship between
singular value spectra and trainable parameters. More importantly, current
methods overlook the key property that the gain function is non-smooth at a
compression ratio of 1, which often leads the training process to suboptimal
local minima. To address these issues, we propose an Adaptive Rank Allocation
(ARA) method. Specifically, (1) ARA introduces a dedicated mask design that
enables efficient mapping and updating between retained ranks and trainable
parameters; and (2) it employs an additional loss function to guide parameter
selection toward globally optimal solutions. Experimental results demonstrate
that ARA achieves state-of-the-art performance. On the LLaMA2-7B model with a
80\% compression ratio, ARA reduces perplexity on WikiText2 from 8.38 to 6.42
and improves average zero-shot task accuracy by 9.72 percentage points compared
with uniform compression. These results highlight the effectiveness of our
method for rank allocation in SVD-based LLM compression.

</details>


### [40] [ELUTQ: Efficient LUT-Aware Quantization for Deploying Large Language Models on Edge Devices](https://arxiv.org/abs/2510.19482)
*Xin Nie,Liang Dong,HaiCheng Zhang,JiaWang Xiao,G. Sun*

Main category: cs.LG

TL;DR: ELUTQ是一个高效的量化框架，引入分层线性量化(HLQ)格式，在CPU边缘设备上部署大语言模型时减少内存使用和延迟，消除反量化开销。


<details>
  <summary>Details</summary>
Motivation: 在CPU边缘设备上部署大语言模型面临内存和计算资源有限的挑战，现有均匀量化方法不适合权重分布且低比特位宽时反量化开销高。

Method: 提出HLQ量化格式，在不增加位串行LUT-based GEMM计算成本的情况下更好地捕捉权重统计特征，提供优化的CPU内核进行端到端推理。

Result: 对于LLaMA3-8B，HLQ在3位精度下降低困惑度约8%，2位精度下降低85%；在Apple M2芯片上2位LLaMA2-7B实现超过25 tokens/s的推理速度。

Conclusion: ELUTQ框架有效解决了边缘设备上大语言模型部署的内存和延迟瓶颈，提供高效的量化解决方案。

Abstract: The deployment of Large Language Models (LLMs) on CPU-based edge devices is
crucial for enabling on-device intelligence and expanding AI accessibility.
However, it remains challenging due to limited memory and computational
resources. During edge inference, memory usage and latency are the primary
bottlenecks. Although weight quantization can effectively reduce memory
consumption, existing hardware-friendly approaches often rely on uniform
quantization, which poorly fits weight distributions and incurs high
dequantization overhead at low bit widths. To address these limitations, we
propose ELUTQ, an efficient quantization framework introducing a novel
quantization format, Hierarchical Linear Quantization (HLQ). HLQ better
captures the statistical characteristics of weights without increasing the
computational cost of Bit-serial LUT-based GEMM operations, thereby eliminating
dequantization overhead. It is orthogonal to existing quantization algorithms
and can be seamlessly integrated into various quantization pipelines. For
efficient on-device deployment, ELUTQ provides optimized CPU kernels for
end-to-end inference. Experiments show that for LLaMA3-8B, HLQ reduces
perplexity by about 8% at 3-bit and 85% at 2-bit precision under post-training
quantization, completing quantization within one hour. With efficient
finetuning, HLQ further improves 2-bit performance within two hours. In terms
of inference efficiency, our 2-bit LLaMA2-7B achieves over 25 tokens/s on an
Apple M2 chip (4 threads, batch size = 1).

</details>


### [41] [Teaming LLMs to Detect and Mitigate Hallucinations](https://arxiv.org/abs/2510.19507)
*Demian Till,John Smeaton,Peter Haubrick,Gouse Saheb,Florian Graef,David Berman*

Main category: cs.LG

TL;DR: 本文提出了一种多模型一致性方法，通过整合来自不同训练数据、训练方案和模型架构的多个LLM的响应，显著改进了幻觉检测和缓解能力，同时降低了推理成本。


<details>
  <summary>Details</summary>
Motivation: 现有基于单一模型一致性的方法在LLM幻觉检测和缓解方面取得了先进成果，但受限于训练数据的不完善性（包括偏见和信息代表性不足）。作者希望探索通过组合多个不同LLM的响应来进一步提升性能。

Method: 提出联盟一致性方法，将来自15个不同LLM的多个响应进行组合，研究在不同条件下如何有效组建LLM团队。

Result: 多模型一致性方法在幻觉检测和缓解能力方面相比单一模型一致性方法有显著提升，且通常伴随着推理成本的降低。

Conclusion: 通过组合多个不同LLM的响应可以实现更好的幻觉检测和缓解效果，同时克服单一模型一致性方法在推理成本方面的显著缺点。

Abstract: Recent work has demonstrated state-of-the-art results in large language model
(LLM) hallucination detection and mitigation through consistency-based
approaches which involve aggregating multiple responses sampled from a single
LLM for a given prompt. These approaches help offset limitations stemming from
the imperfect data on which LLMs are trained, which includes biases and
under-representation of information required at deployment time among other
limitations which can lead to hallucinations. We show that extending these
single-model consistency methods to combine responses from multiple LLMs with
different training data, training schemes and model architectures can result in
substantial further improvements in hallucination detection and mitigation
capabilities beyond their single-model consistency counterparts. We evaluate
this \emph{consortium consistency} approach across many model teams from a pool
of 15 LLMs and explore under what conditions it is beneficial to team together
different LLMs in this manner. Further, we show that these performance
improvements often come with reduced inference costs, offsetting a significant
drawback with single-model consistency methods.

</details>


### [42] [The Confusing Instance Principle for Online Linear Quadratic Control](https://arxiv.org/abs/2510.19531)
*Waris Radji,Odalric-Ambrym Maillard*

Main category: cs.LG

TL;DR: 提出基于混淆实例原则的MED-LQ方法，用于未知动态线性系统的模型强化学习控制，相比传统乐观方法和汤普森采样具有更好性能


<details>
  <summary>Details</summary>
Motivation: 传统基于多臂老虎机的乐观方法和汤普森采样在实际应用中存在局限性，需要开发更有效的控制策略

Method: 利用LQR策略结构结合灵敏度和稳定性分析，基于混淆实例原则和最小经验散度算法开发MED-LQ控制策略

Result: 在综合控制套件基准测试中，MED-LQ在各种场景下实现竞争性性能

Conclusion: MED-LQ展示了在小规模设置之外应用混淆实例和MED原则的潜力，为大规模MDPs的广泛应用提供了前景

Abstract: We revisit the problem of controlling linear systems with quadratic cost
under unknown dynamics with model-based reinforcement learning. Traditional
methods like Optimism in the Face of Uncertainty and Thompson Sampling, rooted
in multi-armed bandits (MABs), face practical limitations. In contrast, we
propose an alternative based on the Confusing Instance (CI) principle, which
underpins regret lower bounds in MABs and discrete Markov Decision Processes
(MDPs) and is central to the Minimum Empirical Divergence (MED) family of
algorithms, known for their asymptotic optimality in various settings. By
leveraging the structure of LQR policies along with sensitivity and stability
analysis, we develop MED-LQ. This novel control strategy extends the principles
of CI and MED beyond small-scale settings. Our benchmarks on a comprehensive
control suite demonstrate that MED-LQ achieves competitive performance in
various scenarios while highlighting its potential for broader applications in
large-scale MDPs.

</details>


### [43] [Latent Space Factorization in LoRA](https://arxiv.org/abs/2510.19640)
*Shashi Kumar,Yacouba Kaloga,John Mitros,Petr Motlicek,Ina Kodrasi*

Main category: cs.LG

TL;DR: 提出FVAE-LoRA方法，通过变分自编码器学习两个不同的潜在空间，一个专注于任务相关特征，另一个处理残差信息，从而提升LoRA在下游任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LoRA变体缺乏明确区分任务相关信息与残差信息的机制，限制了在下游任务中的性能表现。

Method: 使用变分自编码器学习两个不同的潜在空间，通过新的证据下界公式促进潜在空间之间的因子分解，一个潜在空间专门处理任务显著特征，另一个处理残差信息。

Result: 在文本、音频和图像任务上的广泛实验表明，FVAE-LoRA始终优于标准LoRA。虚假相关性评估证实FVAE-LoRA能更好地隔离任务相关信号，在分布偏移下具有更好的鲁棒性。

Conclusion: FVAE-LoRA通过明确分离任务相关特征和残差信息，有效提升了LoRA在下游任务中的性能和鲁棒性。

Abstract: Low-rank adaptation (LoRA) is a widely used method for parameter-efficient
finetuning. However, existing LoRA variants lack mechanisms to explicitly
disambiguate task-relevant information within the learned low-rank subspace,
potentially limiting downstream performance. We propose Factorized Variational
Autoencoder LoRA (FVAE-LoRA), which leverages a VAE to learn two distinct
latent spaces. Our novel Evidence Lower Bound formulation explicitly promotes
factorization between the latent spaces, dedicating one latent space to
task-salient features and the other to residual information. Extensive
experiments on text, audio, and image tasks demonstrate that FVAE-LoRA
consistently outperforms standard LoRA. Moreover, spurious correlation
evaluations confirm that FVAE-LoRA better isolates task-relevant signals,
leading to improved robustness under distribution shifts. Our code is publicly
available at: https://github.com/idiap/FVAE-LoRA

</details>


### [44] [The Tail Tells All: Estimating Model-Level Membership Inference Vulnerability Without Reference Models](https://arxiv.org/abs/2510.19773)
*Euodia Dodd,Nataša Krčo,Igor Shilov,Yves-Alexandre de Montjoye*

Main category: cs.LG

TL;DR: 提出了一种无需参考模型即可估计模型对成员推理攻击（MIA）脆弱性的新方法，通过分析损失分布的不对称性和重尾特性，利用高损失区域异常值的缺失来预测风险。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的成员推理攻击需要训练大量计算昂贵的参考模型，限制了实际应用，因此需要开发无需参考模型的风险评估方法。

Method: 利用训练和测试分布的不对称性和重尾特性，通过高损失区域异常值的缺失来预测模型脆弱性，使用简单的损失攻击的真负率（TNR）作为评估指标。

Result: 该方法在多种架构和数据集上能准确估计模型对最先进MIA攻击（LiRA）的脆弱性，优于低成本攻击（如RMIA）和其他分布差异度量方法。

Conclusion: 该方法为评估模型隐私风险提供了一种高效实用的替代方案，特别在大型语言模型风险评估方面显示出潜力。

Abstract: Membership inference attacks (MIAs) have emerged as the standard tool for
evaluating the privacy risks of AI models. However, state-of-the-art attacks
require training numerous, often computationally expensive, reference models,
limiting their practicality. We present a novel approach for estimating
model-level vulnerability, the TPR at low FPR, to membership inference attacks
without requiring reference models. Empirical analysis shows loss distributions
to be asymmetric and heavy-tailed and suggests that most points at risk from
MIAs have moved from the tail (high-loss region) to the head (low-loss region)
of the distribution after training. We leverage this insight to propose a
method to estimate model-level vulnerability from the training and testing
distribution alone: using the absence of outliers from the high-loss region as
a predictor of the risk. We evaluate our method, the TNR of a simple loss
attack, across a wide range of architectures and datasets and show it to
accurately estimate model-level vulnerability to the SOTA MIA attack (LiRA). We
also show our method to outperform both low-cost (few reference models) attacks
such as RMIA and other measures of distribution difference. We finally evaluate
the use of non-linear functions to evaluate risk and show the approach to be
promising to evaluate the risk in large-language models.

</details>


### [45] [Blackbox Model Provenance via Palimpsestic Membership Inference](https://arxiv.org/abs/2510.19796)
*Rohith Kuditipudi,Jing Huang,Sally Zhu,Diyi Yang,Christopher Potts,Percy Liang*

Main category: cs.LG

TL;DR: 该论文提出了一种检测模型衍生使用的方法，通过测试Bob的模型或文本与Alice训练数据顺序之间的相关性来验证Bob是否使用了Alice的模型。


<details>
  <summary>Details</summary>
Motivation: 研究如何证明Bob使用了Alice的开源语言模型，即使Bob使用的是黑盒衍生模型。

Method: 将问题建模为独立性测试，利用语言模型对后期训练数据记忆更强的特性，通过相关性测试来检测模型使用情况。在查询设置中直接估计模型对训练数据的似然度；在观察设置中通过文本重叠或重新训练模型来检测。

Result: 在查询设置中，对40多个微调模型进行测试，p值大多小于1e-8；在观察设置中，第二种方法仅需几百个token就能可靠区分，第一种方法需要几十万个token。

Conclusion: 该方法能够有效检测模型衍生使用，为开源模型的知识产权保护提供了统计证据支持。

Abstract: Suppose Alice trains an open-weight language model and Bob uses a blackbox
derivative of Alice's model to produce text. Can Alice prove that Bob is using
her model, either by querying Bob's derivative model (query setting) or from
the text alone (observational setting)? We formulate this question as an
independence testing problem--in which the null hypothesis is that Bob's model
or text is independent of Alice's randomized training run--and investigate it
through the lens of palimpsestic memorization in language models: models are
more likely to memorize data seen later in training, so we can test whether Bob
is using Alice's model using test statistics that capture correlation between
Bob's model or text and the ordering of training examples in Alice's training
run. If Alice has randomly shuffled her training data, then any significant
correlation amounts to exactly quantifiable statistical evidence against the
null hypothesis, regardless of the composition of Alice's training data. In the
query setting, we directly estimate (via prompting) the likelihood Bob's model
gives to Alice's training examples and order; we correlate the likelihoods of
over 40 fine-tunes of various Pythia and OLMo base models ranging from 1B to
12B parameters with the base model's training data order, achieving a p-value
on the order of at most 1e-8 in all but six cases. In the observational
setting, we try two approaches based on estimating 1) the likelihood of Bob's
text overlapping with spans of Alice's training examples and 2) the likelihood
of Bob's text with respect to different versions of Alice's model we obtain by
repeating the last phase (e.g., 1%) of her training run on reshuffled data. The
second approach can reliably distinguish Bob's text from as little as a few
hundred tokens; the first does not involve any retraining but requires many
more tokens (several hundred thousand) to achieve high power.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [46] [Topology of Currencies: Persistent Homology for FX Co-movements: A Comparative Clustering Study](https://arxiv.org/abs/2510.19306)
*Pattravadee de Favereau de Jeneret,Ioannis Diamantis*

Main category: stat.ML

TL;DR: 该研究比较了拓扑数据分析(TDA)与传统统计方法在聚类货币行为方面的表现，发现TDA能捕捉传统方法可能忽略的结构模式，产生更紧凑和分离的聚类。


<details>
  <summary>Details</summary>
Motivation: 外汇市场是一个复杂的系统，经常表现出非线性和高维动态，传统技术可能无法完全捕捉这些特征。研究旨在探索TDA是否能提供超越传统统计方法的额外洞察。

Method: 使用13种主要货币兑欧元的月度对数收益率，比较基于TDA特征与传统统计特征的聚类结果。应用k-means和层次聚类两种算法，通过轮廓系数和Calinski-Harabasz指数评估聚类质量。

Result: TDA特征聚类产生比传统统计特征更紧凑和分离的聚类，特别是Calinski-Harabasz得分显著更高。但所有聚类方法的轮廓系数都较低，表明聚类外汇时间序列具有固有难度。TDA与传统特征下的聚类组成不同，表明TDA能捕捉传统方法可能忽略的货币联动结构模式。

Conclusion: TDA是分析金融时间序列的有价值补充工具，在风险管理等领域具有应用潜力，因为理解结构性联动在这些领域至关重要。

Abstract: This study investigates whether Topological Data Analysis (TDA) can provide
additional insights beyond traditional statistical methods in clustering
currency behaviours. We focus on the foreign exchange (FX) market, which is a
complex system often exhibiting non-linear and high-dimensional dynamics that
classical techniques may not fully capture. We compare clustering results based
on TDA-derived features versus classical statistical features using monthly
logarithmic returns of 13 major currency exchange rates (all against the euro).
Two widely-used clustering algorithms, \(k\)-means and Hierarchical clustering,
are applied on both types of features, and cluster quality is evaluated via the
Silhouette score and the Calinski-Harabasz index. Our findings show that
TDA-based feature clustering produces more compact and well-separated clusters
than clustering on traditional statistical features, particularly achieving
substantially higher Calinski-Harabasz scores. However, all clustering
approaches yield modest Silhouette scores, underscoring the inherent difficulty
of grouping FX time series. The differing cluster compositions under TDA vs.
classical features suggest that TDA captures structural patterns in currency
co-movements that conventional methods might overlook. These results highlight
TDA as a valuable complementary tool for analysing financial time series, with
potential applications in risk management where understanding structural
co-movements is crucial.

</details>


### [47] [Metadata Extraction Leveraging Large Language Models](https://arxiv.org/abs/2510.19334)
*Cuize Han,Sesh Jalagam*

Main category: stat.ML

TL;DR: 本文提出了一种基于大语言模型的合同文档元数据提取系统，通过优化文本转换、分块选择和LLM特定技术，显著提高了法律条款识别的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 利用大语言模型技术自动化法律文档分析，特别是合同审查中的关键法律条款检测和标注，以降低合同审查的时间和成本。

Method: 结合公开的CUAD数据集和专有合同数据集，采用文本转换、分块选择策略，以及思维链提示和结构化工具调用等LLM特定技术。

Result: 实验结果显示在条款识别准确性和效率方面有显著提升，能够保持高精度的法律条款识别。

Conclusion: 经过精心优化的LLM系统可以作为法律专业人士的有价值工具，为各种规模的组织提供高效的合同审查服务。

Abstract: The advent of Large Language Models has revolutionized tasks across domains,
including the automation of legal document analysis, a critical component of
modern contract management systems. This paper presents a comprehensive
implementation of LLM-enhanced metadata extraction for contract review,
focusing on the automatic detection and annotation of salient legal clauses.
Leveraging both the publicly available Contract Understanding Atticus Dataset
(CUAD) and proprietary contract datasets, our work demonstrates the integration
of advanced LLM methodologies with practical applications. We identify three
pivotal elements for optimizing metadata extraction: robust text conversion,
strategic chunk selection, and advanced LLM-specific techniques, including
Chain of Thought (CoT) prompting and structured tool calling. The results from
our experiments highlight the substantial improvements in clause identification
accuracy and efficiency. Our approach shows promise in reducing the time and
cost associated with contract review while maintaining high accuracy in legal
clause identification. The results suggest that carefully optimized LLM systems
could serve as valuable tools for legal professionals, potentially increasing
access to efficient contract review services for organizations of all sizes.

</details>


### [48] [Learning Upper Lower Value Envelopes to Shape Online RL: A Principled Approach](https://arxiv.org/abs/2510.19528)
*Sebastian Reboul,Hélène Halconruy,Randal Douc*

Main category: stat.ML

TL;DR: 提出了一种利用离线数据加速在线强化学习的两阶段框架，通过数据驱动的价值包络方法实现更紧密的价值函数边界估计，显著降低在线学习遗憾。


<details>
  <summary>Details</summary>
Motivation: 解决离线数据如何有效加速在线强化学习这一具有潜力但缺乏理论支撑的基础问题，建立离线预训练与在线微调之间的理论桥梁。

Method: 两阶段框架：第一阶段使用离线数据学习价值函数的上界和下界；第二阶段将这些学习到的边界整合到在线算法中。通过解耦上下界实现更灵活紧密的近似，采用数据驱动的随机变量建模方法。

Result: 在表格MDP上的实证结果表明，相比UCBVI和现有方法，该方法能显著降低遗憾。理论分析建立了由两个可解释量决定的高概率遗憾边界。

Conclusion: 该方法为离线预训练与在线微调提供了正式的理论桥梁，通过数据驱动的价值包络实现了更有效的强化学习加速。

Abstract: We investigate the fundamental problem of leveraging offline data to
accelerate online reinforcement learning - a direction with strong potential
but limited theoretical grounding. Our study centers on how to learn and apply
value envelopes within this context. To this end, we introduce a principled
two-stage framework: the first stage uses offline data to derive upper and
lower bounds on value functions, while the second incorporates these learned
bounds into online algorithms. Our method extends prior work by decoupling the
upper and lower bounds, enabling more flexible and tighter approximations. In
contrast to approaches that rely on fixed shaping functions, our envelopes are
data-driven and explicitly modeled as random variables, with a filtration
argument ensuring independence across phases. The analysis establishes
high-probability regret bounds determined by two interpretable quantities,
thereby providing a formal bridge between offline pre-training and online
fine-tuning. Empirical results on tabular MDPs demonstrate substantial regret
reductions compared with both UCBVI and prior methods.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [49] [Simulation-Guided Planning of a Target Trial Emulated Cluster Randomized Trial for Mass Small-Quantity Lipid Nutrient Supplementation Combined with Expanded Program on Immunization in Rural Niger](https://arxiv.org/abs/2510.19077)
*Rebecca K. Metcalfe,Nathaniel Dyrkton,Yichen Yan,Shomoita Alam,Susan Shepherd,Ibrahim Sana,Kevin Phelan,Jay JH Park*

Main category: stat.AP

TL;DR: 本研究通过模拟方法为无法进行集群随机化的营养补充干预研究设计数据收集方案，比较了四种统计方法，发现beta回归在控制I类错误率和统计功效方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 目标试验模拟方法在非随机化研究中的应用日益增多，但在模拟集群随机试验方面的应用有限。本研究旨在解决当集群随机化不可行时，如何设计非随机化研究来模拟集群随机试验的问题。

Method: 使用模拟方法，基于基线人口普查数据，比较四种统计方法：beta回归、准二项回归、逆概率处理加权和朴素Wald检验。采用协变量约束随机选择方法确定随访村庄。

Result: 只有逆概率处理加权和beta回归能将I类错误率控制在0.05水平，但逆概率处理加权的统计功效较差。beta回归在控制I类错误率和保持足够统计功效方面表现最佳，因此被选为主要分析方法。

Conclusion: 在目标试验模拟框架内采用模拟引导的设计原则，能够稳健地规划模拟集群随机试验的群体水平非随机化研究。本研究的经验教训也适用于个体水平随机试验的目标试验模拟规划。

Abstract: While target trial emulation (TTE) is increasingly used to improve the
analysis of non-randomized studies by applying trial design principles, TTE
applications to emulate cluster randomized trials (RCTs) have been limited. We
performed simulations to prospectively plan data collection of a non-randomized
study intended to emulate a village-level cluster RCT when
cluster-randomization was infeasible. The planned study will assess the impact
of mass distribution of nutritional supplements embedded within an existing
immunization program to improve pentavalent vaccination rates among children
12-24 months old in Niger. The design included covariate-constrained random
selection of villages for outcome ascertainment at follow-up. Simulations used
baseline census data on pentavalent vaccination rates and cluster-level
covariates to compare the type I error rate and power of four statistical
methods: beta-regression; quasi-binomial regression; inverse probability of
treatment weighting (IPTW); and na\"ive Wald test. Of these methods, only IPTW
and beta-regression controlled the type I error rate at 0.05, but IPTW yielded
poor statistical power. Beta-regression, which showed adequate statistical
power, was chosen as our primary analysis. Adopting simulation-guided design
principles within TTE can enable robust planning of a group-level
non-randomized study emulating a cluster RCT. Lessons from this study also
apply to TTE planning of individually-RCTs.

</details>
