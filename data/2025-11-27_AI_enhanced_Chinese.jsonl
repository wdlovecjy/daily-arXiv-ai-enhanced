{"id": "2511.20696", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20696", "abs": "https://arxiv.org/abs/2511.20696", "authors": ["Dan Li", "Hye-Bin Shin", "Yeon-Woo Choi"], "title": "Prototype-Guided Non-Exemplar Continual Learning for Cross-subject EEG Decoding", "comment": "4 pages, 2 figures, 14th IEEE International Winter Conference on Brain-Computer Interface Conference 2026", "summary": "Due to the significant variability in electroencephalogram (EEG) signals across individuals, knowledge acquired from previous subjects is often overwritten as new subjects are introduced in continual EEG decoding task. Current works mainly rely on storing the historical data of seen subjects as a replay buffer to prevent forgetting. However, privacy concerns or memory constraints make keeping such data impractical. Instead, we propose a Prototype-guided Non-Exemplar Continual Learning (ProNECL)framework that preserves prior knowledge without accessing any historical EEG samples. ProNECL constructs class-level prototypes to summarize discriminative representations from each subject and incrementally aligns new feature spaces with the global prototype memory through cross-subject feature alignment and knowledge distillation. Validated on the BCI Competition IV 2a and 2b datasets, our framework effectively balances knowledge retention and adaptability, achieving superior performance in cross-subject continual EEG decoding tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u5386\u53f2EEG\u6837\u672c\u7684\u539f\u578b\u5f15\u5bfc\u65e0\u793a\u4f8b\u6301\u7eed\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u8de8\u4e2a\u4f53EEG\u89e3\u7801\u4e2d\u7684\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u3002", "motivation": "\u7531\u4e8eEEG\u4fe1\u53f7\u5728\u4e2a\u4f53\u95f4\u5b58\u5728\u663e\u8457\u53d8\u5f02\u6027\uff0c\u5728\u6301\u7eedEEG\u89e3\u7801\u4efb\u52a1\u4e2d\uff0c\u5f15\u5165\u65b0\u53d7\u8bd5\u8005\u65f6\u5148\u524d\u83b7\u5f97\u7684\u77e5\u8bc6\u5f80\u5f80\u4f1a\u88ab\u8986\u76d6\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5b58\u50a8\u5386\u53f2\u6570\u636e\u4f5c\u4e3a\u56de\u653e\u7f13\u51b2\u533a\u6765\u9632\u6b62\u9057\u5fd8\uff0c\u4f46\u9690\u79c1\u95ee\u9898\u6216\u5185\u5b58\u9650\u5236\u4f7f\u5f97\u4fdd\u5b58\u8fd9\u4e9b\u6570\u636e\u4e0d\u5207\u5b9e\u9645\u3002", "method": "\u63d0\u51faProNECL\u6846\u67b6\uff0c\u6784\u5efa\u7c7b\u7ea7\u539f\u578b\u6765\u603b\u7ed3\u6bcf\u4e2a\u53d7\u8bd5\u8005\u7684\u5224\u522b\u6027\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u8de8\u53d7\u8bd5\u8005\u7279\u5f81\u5bf9\u9f50\u548c\u77e5\u8bc6\u84b8\u998f\uff0c\u9010\u6b65\u5c06\u65b0\u7279\u5f81\u7a7a\u95f4\u4e0e\u5168\u5c40\u539f\u578b\u8bb0\u5fc6\u5bf9\u9f50\u3002", "result": "\u5728BCI Competition IV 2a\u548c2b\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u8be5\u6846\u67b6\u6709\u6548\u5e73\u8861\u4e86\u77e5\u8bc6\u4fdd\u7559\u548c\u9002\u5e94\u6027\uff0c\u5728\u8de8\u53d7\u8bd5\u8005\u6301\u7eedEEG\u89e3\u7801\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "ProNECL\u6846\u67b6\u80fd\u591f\u5728\u65e0\u9700\u8bbf\u95ee\u5386\u53f2EEG\u6837\u672c\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u4fdd\u7559\u5148\u9a8c\u77e5\u8bc6\uff0c\u4e3a\u6301\u7eedEEG\u89e3\u7801\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.20671", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.20671", "abs": "https://arxiv.org/abs/2511.20671", "authors": ["Zhaoxin Chang", "Shuguang Xiao", "Fusang Zhang", "Xujun Ma", "Badii Jouaber", "Qingfeng Zhang", "Daqing Zhang"], "title": "WiRainbow: Single-Antenna Direction-Aware Wi-Fi Sensing via Dispersion Effect", "comment": null, "summary": "Recently, Wi-Fi signals have emerged as a powerful tool for contactless sensing. During the sensing process, obtaining target direction information can provide valuable contextual insights for various applications. Existing direction estimation methods typically rely on antenna arrays, which are costly and complex to deploy in real-world scenarios. In this paper, we present WiRainbow, a novel approach that enables single-antenna-based direction awareness for Wi-Fi sensing by leveraging the dispersion effect of frequency-scanning antennas (FSAs), which can naturally steer Wi-Fi subcarriers toward distinct angles during signal transmission. To address key challenges in antenna design and signal processing, we propose a coupled-resonator-based antenna architecture that significantly expands the narrow Field-of-View inherent in conventional FSAs, improving sensing coverage. Additionally, we develop a sensing signal-to-noise-ratio-based signal processing framework that reliably estimates target direction in multipath-rich environments. We prototype WiRainbow and evaluate its performance through benchmark experiments and real-world case studies, demonstrating its ability to achieve accurate, robust, and cost-effective direction awareness for diverse Wi-Fi sensing applications.", "AI": {"tldr": "WiRainbow\u662f\u4e00\u79cd\u5229\u7528\u9891\u7387\u626b\u63cf\u5929\u7ebf\u5b9e\u73b0\u5355\u5929\u7ebfWi-Fi\u65b9\u5411\u611f\u77e5\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6269\u5c55\u5929\u7ebf\u89c6\u573a\u548c\u5f00\u53d1\u4fe1\u53f7\u5904\u7406\u6846\u67b6\uff0c\u5728\u590d\u6742\u73af\u5883\u4e2d\u5b9e\u73b0\u51c6\u786e\u3001\u9c81\u68d2\u4e14\u7ecf\u6d4e\u7684\u65b9\u5411\u611f\u77e5\u3002", "motivation": "\u73b0\u6709Wi-Fi\u65b9\u5411\u4f30\u8ba1\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u6602\u8d35\u590d\u6742\u7684\u5929\u7ebf\u9635\u5217\uff0c\u96be\u4ee5\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u90e8\u7f72\u3002\u9700\u8981\u4e00\u79cd\u4f4e\u6210\u672c\u3001\u6613\u90e8\u7f72\u7684\u5355\u5929\u7ebf\u65b9\u5411\u611f\u77e5\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8026\u5408\u8c10\u632f\u5668\u7684\u5929\u7ebf\u67b6\u6784\u6269\u5c55\u4f20\u7edf\u9891\u7387\u626b\u63cf\u5929\u7ebf\u7684\u7a84\u89c6\u573a\uff0c\u5f00\u53d1\u57fa\u4e8e\u611f\u77e5\u4fe1\u566a\u6bd4\u7684\u4fe1\u53f7\u5904\u7406\u6846\u67b6\uff0c\u5728\u4e30\u5bcc\u591a\u5f84\u73af\u5883\u4e2d\u53ef\u9760\u4f30\u8ba1\u76ee\u6807\u65b9\u5411\u3002", "result": "\u539f\u578b\u7cfb\u7edf\u8bc4\u4f30\u663e\u793aWiRainbow\u80fd\u591f\u5b9e\u73b0\u51c6\u786e\u3001\u9c81\u68d2\u7684\u65b9\u5411\u611f\u77e5\uff0c\u9002\u7528\u4e8e\u591a\u79cdWi-Fi\u4f20\u611f\u5e94\u7528\u573a\u666f\u3002", "conclusion": "WiRainbow\u901a\u8fc7\u521b\u65b0\u7684\u5929\u7ebf\u8bbe\u8ba1\u548c\u4fe1\u53f7\u5904\u7406\u65b9\u6cd5\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u4f4e\u6210\u672c\u3001\u9ad8\u7cbe\u5ea6\u7684\u5355\u5929\u7ebfWi-Fi\u65b9\u5411\u611f\u77e5\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2511.20679", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20679", "abs": "https://arxiv.org/abs/2511.20679", "authors": ["Melika Ayoughi", "Pascal Mettes", "Paul Groth"], "title": "Minimizing Hyperbolic Embedding Distortion with LLM-Guided Hierarchy Restructuring", "comment": null, "summary": "Hyperbolic geometry is an effective geometry for embedding hierarchical data structures. Hyperbolic learning has therefore become increasingly prominent in machine learning applications where data is hierarchically organized or governed by hierarchical semantics, ranging from recommendation systems to computer vision. The quality of hyperbolic embeddings is tightly coupled to the structure of the input hierarchy, which is often derived from knowledge graphs or ontologies. Recent work has uncovered that for an optimal hyperbolic embedding, a high branching factor and single inheritance are key, while embedding algorithms are robust to imbalance and hierarchy size. To assist knowledge engineers in reorganizing hierarchical knowledge, this paper investigates whether Large Language Models (LLMs) have the ability to automatically restructure hierarchies to meet these criteria. We propose a prompt-based approach to transform existing hierarchies using LLMs, guided by known desiderata for hyperbolic embeddings. Experiments on 16 diverse hierarchies show that LLM-restructured hierarchies consistently yield higher-quality hyperbolic embeddings across several standard embedding quality metrics. Moreover, we show how LLM-guided hierarchy restructuring enables explainable reorganizations, providing justifications to knowledge engineers.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u91cd\u6784\u5c42\u6b21\u7ed3\u6784\u4ee5\u4f18\u5316\u53cc\u66f2\u5d4c\u5165\u8d28\u91cf\uff0c\u901a\u8fc7\u63d0\u793a\u65b9\u6cd5\u5c06\u73b0\u6709\u5c42\u6b21\u7ed3\u6784\u8f6c\u5316\u4e3a\u7b26\u5408\u53cc\u66f2\u5d4c\u5165\u9700\u6c42\u7684\u5f62\u5f0f\uff0c\u5b9e\u9a8c\u8bc1\u660e\u91cd\u6784\u540e\u7684\u5c42\u6b21\u7ed3\u6784\u5728\u591a\u4e2a\u6807\u51c6\u6307\u6807\u4e0a\u90fd\u80fd\u4ea7\u751f\u66f4\u9ad8\u8d28\u91cf\u7684\u53cc\u66f2\u5d4c\u5165\u3002", "motivation": "\u53cc\u66f2\u51e0\u4f55\u80fd\u6709\u6548\u5d4c\u5165\u5c42\u6b21\u6570\u636e\uff0c\u4f46\u5d4c\u5165\u8d28\u91cf\u4e0e\u8f93\u5165\u5c42\u6b21\u7ed3\u6784\u5bc6\u5207\u76f8\u5173\u3002\u7814\u7a76\u53d1\u73b0\u6700\u4f18\u53cc\u66f2\u5d4c\u5165\u9700\u8981\u9ad8\u5206\u652f\u56e0\u5b50\u548c\u5355\u7ee7\u627f\u7ed3\u6784\u3002\u4e3a\u5e2e\u52a9\u77e5\u8bc6\u5de5\u7a0b\u5e08\u91cd\u65b0\u7ec4\u7ec7\u5c42\u6b21\u77e5\u8bc6\uff0c\u672c\u6587\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u5177\u5907\u81ea\u52a8\u91cd\u6784\u5c42\u6b21\u7ed3\u6784\u4ee5\u6ee1\u8db3\u8fd9\u4e9b\u6807\u51c6\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5df2\u77e5\u53cc\u66f2\u5d4c\u5165\u9700\u6c42\u6307\u5bfc\u4e0b\u8f6c\u6362\u73b0\u6709\u5c42\u6b21\u7ed3\u6784\u3002\u572816\u4e2a\u4e0d\u540c\u5c42\u6b21\u7ed3\u6784\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u7ecf\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u91cd\u6784\u7684\u5c42\u6b21\u7ed3\u6784\u5728\u591a\u4e2a\u6807\u51c6\u5d4c\u5165\u8d28\u91cf\u6307\u6807\u4e0a\u4e00\u81f4\u4ea7\u751f\u66f4\u9ad8\u8d28\u91cf\u7684\u53cc\u66f2\u5d4c\u5165\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u6709\u6548\u91cd\u6784\u5c42\u6b21\u7ed3\u6784\u4ee5\u4f18\u5316\u53cc\u66f2\u5d4c\u5165\u8d28\u91cf\uff0c\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u91cd\u7ec4\u8fc7\u7a0b\uff0c\u4e3a\u77e5\u8bc6\u5de5\u7a0b\u5e08\u63d0\u4f9b\u5408\u7406\u6027\u89e3\u91ca\u3002"}}
{"id": "2511.21223", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21223", "abs": "https://arxiv.org/abs/2511.21223", "authors": ["Jasraj Singh", "Shelvia Wongso", "Jeremie Houssineau", "Badr-Eddine Ch\u00e9rief-Abdellatif"], "title": "Maxitive Donsker-Varadhan Formulation for Possibilistic Variational Inference", "comment": null, "summary": "Variational inference (VI) is a cornerstone of modern Bayesian learning, enabling approximate inference in complex models that would otherwise be intractable. However, its formulation depends on expectations and divergences defined through high-dimensional integrals, often rendering analytical treatment impossible and necessitating heavy reliance on approximate learning and inference techniques. Possibility theory, an imprecise probability framework, allows to directly model epistemic uncertainty instead of leveraging subjective probabilities. While this framework provides robustness and interpretability under sparse or imprecise information, adapting VI to the possibilistic setting requires rethinking core concepts such as entropy and divergence, which presuppose additivity. In this work, we develop a principled formulation of possibilistic variational inference and apply it to a special class of exponential-family functions, highlighting parallels with their probabilistic counterparts and revealing the distinctive mathematical structures of possibility theory.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u539f\u5219\u6027\u7684\u53ef\u80fd\u6027\u53d8\u5206\u63a8\u7406\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u6307\u6570\u65cf\u51fd\u6570\uff0c\u63ed\u793a\u4e86\u53ef\u80fd\u6027\u7406\u8bba\u7684\u72ec\u7279\u6570\u5b66\u7ed3\u6784\u3002", "motivation": "\u53d8\u5206\u63a8\u7406\u662f\u73b0\u4ee3\u8d1d\u53f6\u65af\u5b66\u4e60\u7684\u57fa\u77f3\uff0c\u4f46\u5176\u5728\u9ad8\u7ef4\u79ef\u5206\u4e0b\u7684\u516c\u5f0f\u4f9d\u8d56\u671f\u671b\u548c\u6563\u5ea6\uff0c\u901a\u5e38\u9700\u8981\u8fd1\u4f3c\u6280\u672f\u3002\u53ef\u80fd\u6027\u7406\u8bba\u4f5c\u4e3a\u4e0d\u7cbe\u786e\u6982\u7387\u6846\u67b6\uff0c\u53ef\u4ee5\u76f4\u63a5\u5efa\u6a21\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u5c06\u5176\u9002\u5e94\u5230\u53d8\u5206\u63a8\u7406\u9700\u8981\u91cd\u65b0\u601d\u8003\u71b5\u548c\u6563\u5ea6\u7b49\u6838\u5fc3\u6982\u5ff5\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u539f\u5219\u6027\u7684\u53ef\u80fd\u6027\u53d8\u5206\u63a8\u7406\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u6307\u6570\u65cf\u51fd\u6570\uff0c\u4e0e\u6982\u7387\u5bf9\u5e94\u7269\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u63d0\u51fa\u4e86\u53ef\u80fd\u6027\u53d8\u5206\u63a8\u7406\u7684\u6570\u5b66\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u53ef\u80fd\u6027\u7406\u8bba\u4e0e\u6982\u7387\u7406\u8bba\u5728\u53d8\u5206\u63a8\u7406\u4e2d\u7684\u7ed3\u6784\u5dee\u5f02\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u53ef\u80fd\u6027\u7406\u8bba\u5728\u53d8\u5206\u63a8\u7406\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u53ef\u80fd\u6027\u6846\u67b6\u5728\u5efa\u6a21\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u65b9\u9762\u7684\u72ec\u7279\u4f18\u52bf\u3002"}}
{"id": "2511.21526", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.21526", "abs": "https://arxiv.org/abs/2511.21526", "authors": ["Alexandra Carpentier", "Christophe Giraud", "Nicolas Verzelen"], "title": "Phase Transition for Stochastic Block Model with more than $\\sqrt{n}$ Communities (II)", "comment": null, "summary": "A fundamental theoretical question in network analysis is to determine under which conditions community recovery is possible in polynomial time in the Stochastic Block Model (SBM). When the number $K$ of communities remains smaller than $\\sqrt{n}$ --where $n$ denotes the number of nodes--, non-trivial community recovery is possible in polynomial time above, and only above, the Kesten--Stigum (KS) threshold, originally postulated using arguments from statistical physics.\n  When $K \\geq \\sqrt{n}$, Chin, Mossel, Sohn, and Wein recently proved that, in the \\emph{sparse regime}, community recovery in polynomial time is achievable below the KS threshold by counting non-backtracking paths. This finding led them to postulate a new threshold for the many-communities regime $K \\geq \\sqrt{n}$. Subsequently, Carpentier, Giraud, and Verzelen established the failure of low-degree polynomials below this new threshold across all density regimes, and demonstrated successful recovery above the threshold in certain moderately sparse settings. While these results provide strong evidence that, in the many community setting, the computational barrier lies at the threshold proposed in~Chin et al., the question of achieving recovery above this threshold still remains open in most density regimes.\n  The present work is a follow-up to~Carpentier et al., in which we prove Conjecture~1.4 stated therein by: \\\\ 1- Constructing a family of motifs satisfying specific structural properties; and\\\\ 2- Proving that community recovery is possible above the proposed threshold by counting such motifs.\\\\ Our results complete the picture of the computational barrier for community recovery in the SBM with $K \\geq \\sqrt{n}$ communities. They also indicate that, in moderately sparse regimes, the optimal algorithms appear to be fundamentally different from spectral methods.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u4e86\u5f53\u793e\u533a\u6570\u91cfK\u2265\u221an\u65f6\uff0c\u968f\u673a\u5757\u6a21\u578b(SBM)\u4e2d\u793e\u533a\u6062\u590d\u7684\u8ba1\u7b97\u969c\u788d\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u5728Chin\u7b49\u4eba\u63d0\u51fa\u7684\u9608\u503c\u4e4b\u4e0a\u53ef\u4ee5\u5b9e\u73b0\u591a\u9879\u5f0f\u65f6\u95f4\u793e\u533a\u6062\u590d\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u8868\u660e\u5f53K\u2265\u221an\u65f6\uff0c\u793e\u533a\u6062\u590d\u5728\u7a00\u758f\u533a\u57df\u53ef\u4ee5\u5728Kesten-Stigum\u9608\u503c\u4ee5\u4e0b\u5b9e\u73b0\uff0c\u4f46\u5173\u4e8e\u5728\u5927\u591a\u6570\u5bc6\u5ea6\u533a\u57df\u4e2d\u662f\u5426\u80fd\u5728\u65b0\u63d0\u51fa\u7684\u9608\u503c\u4e4b\u4e0a\u5b9e\u73b0\u6062\u590d\u7684\u95ee\u9898\u4ecd\u7136\u5f00\u653e\u3002", "method": "\u901a\u8fc7\u6784\u9020\u6ee1\u8db3\u7279\u5b9a\u7ed3\u6784\u6027\u8d28\u7684motif\u65cf\uff0c\u5e76\u8bc1\u660e\u901a\u8fc7\u8ba1\u6570\u8fd9\u4e9bmotif\u53ef\u4ee5\u5728\u63d0\u8bae\u7684\u9608\u503c\u4e4b\u4e0a\u5b9e\u73b0\u793e\u533a\u6062\u590d\u3002", "result": "\u8bc1\u660e\u4e86\u5728K\u2265\u221an\u7684SBM\u4e2d\uff0c\u793e\u533a\u6062\u590d\u5728\u63d0\u8bae\u7684\u9608\u503c\u4e4b\u4e0a\u662f\u53ef\u80fd\u7684\uff0c\u4ece\u800c\u5b8c\u6210\u4e86\u8be5\u8bbe\u7f6e\u4e0b\u8ba1\u7b97\u969c\u788d\u7684\u5b8c\u6574\u56fe\u50cf\u3002", "conclusion": "\u5728\u4e2d\u7b49\u7a00\u758f\u533a\u57df\uff0c\u6700\u4f18\u7b97\u6cd5\u4e0e\u8c31\u65b9\u6cd5\u6709\u6839\u672c\u6027\u4e0d\u540c\uff0c\u672c\u6587\u7ed3\u679c\u5b8c\u5584\u4e86\u591a\u793e\u533a\u8bbe\u7f6e\u4e0b\u793e\u533a\u6062\u590d\u8ba1\u7b97\u969c\u788d\u7684\u7406\u8bba\u56fe\u666f\u3002"}}
{"id": "2511.20811", "categories": ["cs.LG", "cs.AI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.20811", "abs": "https://arxiv.org/abs/2511.20811", "authors": ["Aaron O. Feldman", "D. Isaiah Harp", "Joseph Duncan", "Mac Schwager"], "title": "Conformal Safety Monitoring for Flight Testing: A Case Study in Data-Driven Safety Learning", "comment": "ICRA 2025 Workshop on Robot safety under uncertainty from intangible specifications", "summary": "We develop a data-driven approach for runtime safety monitoring in flight testing, where pilots perform maneuvers on aircraft with uncertain parameters. Because safety violations can arise unexpectedly as a result of these uncertainties, pilots need clear, preemptive criteria to abort the maneuver in advance of safety violation. To solve this problem, we use offline stochastic trajectory simulation to learn a calibrated statistical model of the short-term safety risk facing pilots. We use flight testing as a motivating example for data-driven learning/monitoring of safety due to its inherent safety risk, uncertainty, and human-interaction. However, our approach consists of three broadly-applicable components: a model to predict future state from recent observations, a nearest neighbor model to classify the safety of the predicted state, and classifier calibration via conformal prediction. We evaluate our method on a flight dynamics model with uncertain parameters, demonstrating its ability to reliably identify unsafe scenarios, match theoretical guarantees, and outperform baseline approaches in preemptive classification of risk.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u98de\u884c\u6d4b\u8bd5\u8fd0\u884c\u65f6\u5b89\u5168\u76d1\u63a7\u65b9\u6cd5\uff0c\u901a\u8fc7\u79bb\u7ebf\u968f\u673a\u8f68\u8ff9\u6a21\u62df\u5b66\u4e60\u77ed\u671f\u5b89\u5168\u98ce\u9669\u7684\u6821\u51c6\u7edf\u8ba1\u6a21\u578b\uff0c\u4e3a\u98de\u884c\u5458\u63d0\u4f9b\u9884\u5148\u4e2d\u6b62\u673a\u52a8\u64cd\u4f5c\u7684\u6807\u51c6\u3002", "motivation": "\u98de\u884c\u6d4b\u8bd5\u4e2d\u98de\u884c\u5458\u5728\u53c2\u6570\u4e0d\u786e\u5b9a\u7684\u98de\u673a\u4e0a\u6267\u884c\u673a\u52a8\u64cd\u4f5c\u65f6\uff0c\u5b89\u5168\u8fdd\u89c4\u53ef\u80fd\u56e0\u4e0d\u786e\u5b9a\u6027\u800c\u610f\u5916\u53d1\u751f\uff0c\u9700\u8981\u4e3a\u98de\u884c\u5458\u63d0\u4f9b\u660e\u786e\u3001\u9884\u5148\u7684\u4e2d\u6b62\u6807\u51c6\u6765\u907f\u514d\u5b89\u5168\u8fdd\u89c4\u3002", "method": "\u65b9\u6cd5\u5305\u542b\u4e09\u4e2a\u901a\u7528\u7ec4\u4ef6\uff1a\u57fa\u4e8e\u8fd1\u671f\u89c2\u6d4b\u9884\u6d4b\u672a\u6765\u72b6\u6001\u7684\u6a21\u578b\u3001\u901a\u8fc7\u6700\u8fd1\u90bb\u6a21\u578b\u5bf9\u9884\u6d4b\u72b6\u6001\u8fdb\u884c\u5b89\u5168\u5206\u7c7b\u3001\u4ee5\u53ca\u901a\u8fc7\u4fdd\u5f62\u9884\u6d4b\u8fdb\u884c\u5206\u7c7b\u5668\u6821\u51c6\u3002", "result": "\u5728\u5177\u6709\u4e0d\u786e\u5b9a\u53c2\u6570\u7684\u98de\u884c\u52a8\u529b\u5b66\u6a21\u578b\u4e0a\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u53ef\u9760\u8bc6\u522b\u4e0d\u5b89\u5168\u573a\u666f\uff0c\u5339\u914d\u7406\u8bba\u4fdd\u8bc1\uff0c\u5e76\u5728\u98ce\u9669\u9884\u5206\u7c7b\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u98de\u884c\u6d4b\u8bd5\u4e2d\u7684\u8fd0\u884c\u65f6\u5b89\u5168\u76d1\u63a7\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6570\u636e\u9a71\u52a8\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u63d0\u524d\u8bc6\u522b\u5b89\u5168\u98ce\u9669\u5e76\u6307\u5bfc\u98de\u884c\u5458\u51b3\u7b56\u3002"}}
{"id": "2511.20694", "categories": ["cs.AI", "astro-ph.SR", "cs.LG", "physics.space-ph"], "pdf": "https://arxiv.org/pdf/2511.20694", "abs": "https://arxiv.org/abs/2511.20694", "authors": ["Kevin Lee", "Russell Spiewak", "James Walsh"], "title": "Reasoning With a Star: A Heliophysics Dataset and Benchmark for Agentic Scientific Reasoning", "comment": "Accepted at NeurIPS 2025 Machine Learning and the Physical Sciences (ML4PS) Workshop. Dataset: https://huggingface.co/datasets/SpaceML/ReasoningWithAStar", "summary": "Scientific reasoning through Large Language Models in heliophysics involves more than just recalling facts: it requires incorporating physical assumptions, maintaining consistent units, and providing clear scientific formats through coordinated approaches. To address these challenges, we present Reasoning With a Star, a newly contributed heliophysics dataset applicable to reasoning; we also provide an initial benchmarking approach. Our data are constructed from National Aeronautics and Space Administration & University Corporation for Atmospheric Research Living With a Star summer school problem sets and compiled into a readily consumable question-and-answer structure with question contexts, reasoning steps, expected answer type, ground-truth targets, format hints, and metadata. A programmatic grader checks the predictions using unit-aware numerical tolerance, symbolic equivalence, and schema validation. We benchmark a single-shot baseline and four multi-agent patterns, finding that decomposing workflows through systems engineering principles outperforms direct prompting on problems requiring deductive reasoning rather than pure inductive recall.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a\"Reasoning With a Star\"\u7684\u592a\u9633\u7269\u7406\u5b66\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u63a8\u7406\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u901a\u8fc7\u7cfb\u7edf\u5de5\u7a0b\u539f\u5219\u5206\u89e3\u5de5\u4f5c\u6d41\u7a0b\u5728\u9700\u8981\u6f14\u7ece\u63a8\u7406\u7684\u95ee\u9898\u4e0a\u4f18\u4e8e\u76f4\u63a5\u63d0\u793a\u3002", "motivation": "\u89e3\u51b3\u592a\u9633\u7269\u7406\u5b66\u4e2d\u5927\u8bed\u8a00\u6a21\u578b\u79d1\u5b66\u63a8\u7406\u7684\u6311\u6218\uff0c\u5305\u62ec\u6574\u5408\u7269\u7406\u5047\u8bbe\u3001\u4fdd\u6301\u5355\u4f4d\u4e00\u81f4\u6027\u4ee5\u53ca\u901a\u8fc7\u534f\u8c03\u65b9\u6cd5\u63d0\u4f9b\u6e05\u6670\u7684\u79d1\u5b66\u683c\u5f0f\u3002", "method": "\u6784\u5efa\u57fa\u4e8eNASA\u548cUCAR Living With a Star\u6691\u671f\u5b66\u6821\u95ee\u9898\u96c6\u7684\u6570\u636e\u96c6\uff0c\u91c7\u7528\u7a0b\u5e8f\u5316\u8bc4\u5206\u5668\u68c0\u67e5\u9884\u6d4b\u7ed3\u679c\uff0c\u5e76\u6bd4\u8f83\u5355\u6b21\u63d0\u793a\u548c\u56db\u79cd\u591a\u667a\u80fd\u4f53\u6a21\u5f0f\u7684\u6027\u80fd\u3002", "result": "\u53d1\u73b0\u901a\u8fc7\u7cfb\u7edf\u5de5\u7a0b\u539f\u5219\u5206\u89e3\u5de5\u4f5c\u6d41\u7a0b\u5728\u9700\u8981\u6f14\u7ece\u63a8\u7406\u800c\u975e\u7eaf\u5f52\u7eb3\u56de\u5fc6\u7684\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u4e8e\u76f4\u63a5\u63d0\u793a\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u4e3a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u592a\u9633\u7269\u7406\u5b66\u79d1\u5b66\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u591a\u667a\u80fd\u4f53\u5206\u89e3\u7b56\u7565\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2511.20713", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20713", "abs": "https://arxiv.org/abs/2511.20713", "authors": ["Minhui Zhang", "Prahar Ijner", "Yoav Wald", "Elliot Creager"], "title": "Active Slice Discovery in Large Language Models", "comment": "Accepted for presentation at NeurIPS 2025 - Reliable ML Workshop", "summary": "Large Language Models (LLMs) often exhibit systematic errors on specific subsets of data, known as error slices. For instance, a slice can correspond to a certain demographic, where a model does poorly in identifying toxic comments regarding that demographic. Identifying error slices is crucial to understanding and improving models, but it is also challenging. An appealing approach to reduce the amount of manual annotation required is to actively group errors that are likely to belong to the same slice, while using limited access to an annotator to verify whether the chosen samples share the same pattern of model mistake. In this paper, we formalize this approach as Active Slice Discovery and explore it empirically on a problem of discovering human-defined slices in toxicity classification. We examine the efficacy of active slice discovery under different choices of feature representations and active learning algorithms. On several slices, we find that uncertainty-based active learning algorithms are most effective, achieving competitive accuracy using 2-10% of the available slice membership information, while significantly outperforming baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e3b\u52a8\u5207\u7247\u53d1\u73b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e3b\u52a8\u5b66\u4e60\u8bc6\u522bLLM\u5728\u6bd2\u6027\u5206\u7c7b\u4e2d\u7684\u7cfb\u7edf\u6027\u9519\u8bef\u5207\u7247\uff0c\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u6807\u6ce8\u9700\u6c42\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u6570\u636e\u5b50\u96c6\u4e0a\u5b58\u5728\u7cfb\u7edf\u6027\u9519\u8bef\uff0c\u8bc6\u522b\u8fd9\u4e9b\u9519\u8bef\u5207\u7247\u5bf9\u6a21\u578b\u6539\u8fdb\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u9ad8\u6602\u3002", "method": "\u4f7f\u7528\u4e3b\u52a8\u5b66\u4e60\u7b97\u6cd5\uff0c\u7ed3\u5408\u4e0d\u540c\u7279\u5f81\u8868\u793a\uff0c\u901a\u8fc7\u6709\u9650\u7684\u4eba\u5de5\u9a8c\u8bc1\u6765\u5206\u7ec4\u53ef\u80fd\u5c5e\u4e8e\u540c\u4e00\u9519\u8bef\u5207\u7247\u7684\u6837\u672c\u3002", "result": "\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u4e3b\u52a8\u5b66\u4e60\u7b97\u6cd5\u6548\u679c\u6700\u4f73\uff0c\u4ec5\u4f7f\u75282-10%\u7684\u5207\u7247\u6210\u5458\u4fe1\u606f\u5373\u53ef\u8fbe\u5230\u7ade\u4e89\u6027\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u4e3b\u52a8\u5207\u7247\u53d1\u73b0\u662f\u8bc6\u522b\u6a21\u578b\u9519\u8bef\u5207\u7247\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u80fd\u591f\u5927\u5e45\u51cf\u5c11\u4eba\u5de5\u6807\u6ce8\u5de5\u4f5c\u91cf\uff0c\u5728\u6bd2\u6027\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.21133", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.21133", "abs": "https://arxiv.org/abs/2511.21133", "authors": ["Xi Zhang", "Miguel Bernal", "Wei-Ning Lee"], "title": "2D Sparse Array Design via Reweighted L1 Second Order Cone Programming for 3D Ultrasound Imaging", "comment": null, "summary": "Two-dimensional (2D) fully-addressed arrays can conveniently realize three-dimensional (3D) ultrasound imaging while fully controlled such arrays usually demands thousands of independent channels, which is costly. Sparse array technique using stochastic optimization methods is one of promising techniques to reduce channel counts while due to the stochastic nature of these methods, the optimized results are usually unstable. In this work, we introduce a sparse array design approach that formulates the synthesis problem of sparse arrays as second-order cone programming (SOCP) and a re-weighted L1 technique is implemented to sequentially optimize the SOCP. Based on this method, an on-grid quasi-flatten side-lobe (Q-Flats) 2D sparse array with side-lobe level (SLL) no more than -21.26 dB and 252 activated elements is designed, which aims to achieve as high contrast performance as possible under the limits of resolution and maximum number of independent channels (i.e., 256). The imaging performance of the Q-Flats array was compared with those of a corresponding dense array (Dense), a Fermat spiral array (Spiral) and a spatially 50%-Tukey tapered spiral array (Spiral-Taper) using Field II simulations in a multi-angle steered diverging wave transmission scheme. It was demonstrated that the Dense achieved the best resolution and contrast and the Spiral-Taper the worst. The Q-Flats showed better resolution (about 3%) but slightly worse contrast than the Spiral. All the results indicate the re-weighted L1 SOCP method is a promising and flexible method for seeking trade-offs among resolution, contrast, and number of activated elements.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8c\u9636\u9525\u89c4\u5212\u548c\u91cd\u52a0\u6743L1\u6280\u672f\u7684\u7a00\u758f\u9635\u5217\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u7528\u4e8e\u51cf\u5c113D\u8d85\u58f0\u6210\u50cf\u4e2d\u7684\u901a\u9053\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u5168\u5bfb\u5740\u4e8c\u7ef4\u9635\u5217\u9700\u8981\u6570\u5343\u4e2a\u72ec\u7acb\u901a\u9053\uff0c\u6210\u672c\u9ad8\u6602\u3002\u73b0\u6709\u968f\u673a\u4f18\u5316\u65b9\u6cd5\u7ed3\u679c\u4e0d\u7a33\u5b9a\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u7a00\u758f\u9635\u5217\u8bbe\u8ba1\u65b9\u6cd5\u3002", "method": "\u5c06\u7a00\u758f\u9635\u5217\u5408\u6210\u95ee\u9898\u5efa\u6a21\u4e3a\u4e8c\u9636\u9525\u89c4\u5212\uff0c\u5e76\u5b9e\u73b0\u91cd\u52a0\u6743L1\u6280\u672f\u6765\u987a\u5e8f\u4f18\u5316SOCP\uff0c\u8bbe\u8ba1\u4e86\u5177\u6709\u51c6\u5e73\u5766\u65c1\u74e3\u7684\u4e8c\u7ef4\u7a00\u758f\u9635\u5217\u3002", "result": "\u8bbe\u8ba1\u7684Q-Flats\u9635\u5217\u5177\u6709252\u4e2a\u6fc0\u6d3b\u5143\u7d20\uff0c\u65c1\u74e3\u7535\u5e73\u4e0d\u8d85\u8fc7-21.26 dB\u3002\u4e0e\u5bc6\u96c6\u9635\u5217\u3001\u8d39\u9a6c\u87ba\u65cb\u9635\u5217\u548c\u9525\u5f62\u87ba\u65cb\u9635\u5217\u76f8\u6bd4\uff0cQ-Flats\u5728\u5206\u8fa8\u7387\u4e0a\u4f18\u4e8e\u87ba\u65cb\u9635\u5217\u7ea63%\uff0c\u5bf9\u6bd4\u5ea6\u7565\u5dee\u3002", "conclusion": "\u91cd\u52a0\u6743L1 SOCP\u65b9\u6cd5\u662f\u4e00\u79cd\u6709\u524d\u666f\u4e14\u7075\u6d3b\u7684\u65b9\u6cd5\uff0c\u53ef\u5728\u5206\u8fa8\u7387\u3001\u5bf9\u6bd4\u5ea6\u548c\u6fc0\u6d3b\u5143\u7d20\u6570\u91cf\u4e4b\u95f4\u5bfb\u6c42\u5e73\u8861\u3002"}}
{"id": "2511.21274", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21274", "abs": "https://arxiv.org/abs/2511.21274", "authors": ["Junhui Rao", "Yi Liu", "Jichen Zhang", "Zhaoyang Ming", "Tianrui Qiao", "Yujie Zhang", "Chi Yuk Chiu", "Hua Wang", "Ross Murch"], "title": "Multiport Analytical Pixel Electromagnetic Simulator (MAPES) for AI-assisted RFIC and Microwave Circuit Design", "comment": null, "summary": "This paper proposes a novel analytical framework, termed the Multiport Analytical Pixel Electromagnetic Simulator (MAPES). MAPES enables efficient and accurate prediction of the electromagnetic (EM) performance of arbitrary pixel-based microwave (MW) and RFIC structures. Inspired by the Integrated Internal Multiport Method (IMPM), MAPES extends the concept to the pixel presence/absence domain used in AI-assisted EM design. By introducing virtual pixels and diagonal virtual pixels and inserting virtual ports at critical positions, MAPES captures all horizontal, vertical, and diagonal electromagnetic couplings within a single multiport impedance matrix. Only a small set of full-wave simulations (typically about 1% of the datasets required by AI-assisted EM simulators) is needed to construct this matrix. Subsequently, any arbitrary pixel configuration can be evaluated analytically using a closed-form multiport relation without additional full-wave calculations. The proposed approach eliminates data-driven overfitting and ensures accurate results across all design variations. Comprehensive examples for single- and double-layer CMOS processes (180 nm and 65 nm) and PCBs confirm that MAPES achieves high prediction accuracy with 600- 2000x speed improvement compared to CST simulations. Owing to its efficiency, scalability and reliability, MAPES provides a practical and versatile tool for AI-assisted MW circuit and RFIC design across diverse fabrication technologies.", "AI": {"tldr": "MAPES\u662f\u4e00\u79cd\u65b0\u9896\u7684\u591a\u7aef\u53e3\u5206\u6790\u50cf\u7d20\u7535\u78c1\u6a21\u62df\u5668\uff0c\u80fd\u591f\u9ad8\u6548\u51c6\u786e\u5730\u9884\u6d4b\u4efb\u610f\u57fa\u4e8e\u50cf\u7d20\u7684\u5fae\u6ce2\u548cRFIC\u7ed3\u6784\u7684\u7535\u78c1\u6027\u80fd\uff0c\u4ec5\u9700\u7ea61%\u7684\u5168\u6ce2\u4eff\u771f\u6570\u636e\u5373\u53ef\u6784\u5efa\u591a\u7aef\u53e3\u963b\u6297\u77e9\u9635\uff0c\u5b9e\u73b0600-2000\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002", "motivation": "\u4f20\u7edfAI\u8f85\u52a9\u7535\u78c1\u8bbe\u8ba1\u9700\u8981\u5927\u91cf\u5168\u6ce2\u4eff\u771f\u6570\u636e\u96c6\uff0c\u5b58\u5728\u6570\u636e\u9a71\u52a8\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u51c6\u786e\u7684\u7535\u78c1\u6027\u80fd\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u96c6\u6210\u5185\u90e8\u591a\u7aef\u53e3\u65b9\u6cd5\uff0c\u5f15\u5165\u865a\u62df\u50cf\u7d20\u548c\u5bf9\u89d2\u865a\u62df\u50cf\u7d20\uff0c\u5728\u5173\u952e\u4f4d\u7f6e\u63d2\u5165\u865a\u62df\u7aef\u53e3\uff0c\u6355\u6349\u6240\u6709\u6c34\u5e73\u3001\u5782\u76f4\u548c\u5bf9\u89d2\u7535\u78c1\u8026\u5408\uff0c\u6784\u5efa\u5355\u4e00\u591a\u7aef\u53e3\u963b\u6297\u77e9\u9635\u3002", "result": "MAPES\u5728180nm\u548c65nm CMOS\u5de5\u827a\u53caPCB\u4e0a\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u4e86\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff0c\u76f8\u6bd4CST\u4eff\u771f\u901f\u5ea6\u63d0\u5347600-2000\u500d\uff0c\u6d88\u9664\u4e86\u6570\u636e\u9a71\u52a8\u8fc7\u62df\u5408\u3002", "conclusion": "MAPES\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u5b9e\u7528\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u8de8\u591a\u79cd\u5236\u9020\u6280\u672f\u7684AI\u8f85\u52a9\u5fae\u6ce2\u7535\u8def\u548cRFIC\u8bbe\u8ba1\u3002"}}
{"id": "2511.20893", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.20893", "abs": "https://arxiv.org/abs/2511.20893", "authors": ["Aodong Li", "Abishek Sankararaman", "Balakrishnan Narayanaswamy"], "title": "Probabilistic Hash Embeddings for Online Learning of Categorical Features", "comment": "AAAI 2026 Oral", "summary": "We study streaming data with categorical features where the vocabulary of categorical feature values is changing and can even grow unboundedly over time. Feature hashing is commonly used as a pre-processing step to map these categorical values into a feature space of fixed size before learning their embeddings. While these methods have been developed and evaluated for offline or batch settings, in this paper we consider online settings. We show that deterministic embeddings are sensitive to the arrival order of categories and suffer from forgetting in online learning, leading to performance deterioration. To mitigate this issue, we propose a probabilistic hash embedding (PHE) model that treats hash embeddings as stochastic and applies Bayesian online learning to learn incrementally from data. Based on the structure of PHE, we derive a scalable inference algorithm to learn model parameters and infer/update the posteriors of hash embeddings and other latent variables. Our algorithm (i) can handle an evolving vocabulary of categorical items, (ii) is adaptive to new items without forgetting old items, (iii) is implementable with a bounded set of parameters that does not grow with the number of distinct observed values on the stream, and (iv) is invariant to the item arrival order. Experiments in classification, sequence modeling, and recommendation systems in online learning setups demonstrate the superior performance of PHE while maintaining high memory efficiency (consumes as low as 2~4 memory of a one-hot embedding table). Supplementary materials are at https://github.com/aodongli/probabilistic-hash-embeddings", "AI": {"tldr": "\u63d0\u51fa\u6982\u7387\u54c8\u5e0c\u5d4c\u5165\u6a21\u578b\u89e3\u51b3\u5728\u7ebf\u5b66\u4e60\u4e2d\u5206\u7c7b\u7279\u5f81\u8bcd\u6c47\u8868\u53d8\u5316\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u5728\u7ebf\u5b66\u4e60\u907f\u514d\u786e\u5b9a\u6027\u5d4c\u5165\u7684\u987a\u5e8f\u654f\u611f\u6027\u548c\u9057\u5fd8\u95ee\u9898", "motivation": "\u4f20\u7edf\u7279\u5f81\u54c8\u5e0c\u65b9\u6cd5\u5728\u79bb\u7ebf\u6216\u6279\u5904\u7406\u573a\u666f\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5728\u7ebf\u5b66\u4e60\u573a\u666f\u4e2d\uff0c\u786e\u5b9a\u6027\u5d4c\u5165\u5bf9\u7c7b\u522b\u5230\u8fbe\u987a\u5e8f\u654f\u611f\u4e14\u5bb9\u6613\u9057\u5fd8\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d", "method": "\u63d0\u51fa\u6982\u7387\u54c8\u5e0c\u5d4c\u5165\u6a21\u578b\uff0c\u5c06\u54c8\u5e0c\u5d4c\u5165\u89c6\u4e3a\u968f\u673a\u53d8\u91cf\uff0c\u5e94\u7528\u8d1d\u53f6\u65af\u5728\u7ebf\u5b66\u4e60\u4ece\u6570\u636e\u4e2d\u589e\u91cf\u5b66\u4e60\uff0c\u63a8\u5bfc\u51fa\u53ef\u6269\u5c55\u7684\u63a8\u7406\u7b97\u6cd5", "result": "\u5b9e\u9a8c\u5728\u5206\u7c7b\u3001\u5e8f\u5217\u5efa\u6a21\u548c\u63a8\u8350\u7cfb\u7edf\u7684\u5728\u7ebf\u5b66\u4e60\u8bbe\u7f6e\u4e2d\u5c55\u793a\u4e86PHE\u7684\u4f18\u8d8a\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u5185\u5b58\u6548\u7387\uff08\u4ec5\u6d88\u8017one-hot\u5d4c\u5165\u88682-4\u500d\u7684\u5185\u5b58\uff09", "conclusion": "PHE\u6a21\u578b\u80fd\u591f\u5904\u7406\u4e0d\u65ad\u6f14\u5316\u7684\u5206\u7c7b\u9879\u76ee\u8bcd\u6c47\u8868\uff0c\u9002\u5e94\u65b0\u9879\u76ee\u800c\u4e0d\u9057\u5fd8\u65e7\u9879\u76ee\uff0c\u53c2\u6570\u96c6\u6709\u754c\u4e0d\u968f\u6d41\u4e2d\u4e0d\u540c\u89c2\u5bdf\u503c\u6570\u91cf\u589e\u957f\uff0c\u4e14\u5bf9\u9879\u76ee\u5230\u8fbe\u987a\u5e8f\u4e0d\u53d8"}}
{"id": "2511.20725", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20725", "abs": "https://arxiv.org/abs/2511.20725", "authors": ["Deng Fucheng", "Wang Wanjie", "Gong Ao", "Wang Xiaoqi", "Wang Fan"], "title": "Gradient Descent Algorithm Survey", "comment": null, "summary": "Focusing on the practical configuration needs of optimization algorithms in deep learning, this article concentrates on five major algorithms: SGD, Mini-batch SGD, Momentum, Adam, and Lion. It systematically analyzes the core advantages, limitations, and key practical recommendations of each algorithm. The research aims to gain an in-depth understanding of these algorithms and provide a standardized reference for the reasonable selection, parameter tuning, and performance improvement of optimization algorithms in both academic research and engineering practice, helping to solve optimization challenges in different scales of models and various training scenarios.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790SGD\u3001Mini-batch SGD\u3001Momentum\u3001Adam\u548cLion\u4e94\u79cd\u6df1\u5ea6\u5b66\u4e60\u4f18\u5316\u7b97\u6cd5\u7684\u6838\u5fc3\u4f18\u52bf\u3001\u5c40\u9650\u6027\u548c\u5b9e\u8df5\u5efa\u8bae\uff0c\u4e3a\u7b97\u6cd5\u9009\u62e9\u548c\u53c2\u6570\u8c03\u4f18\u63d0\u4f9b\u6807\u51c6\u5316\u53c2\u8003\u3002", "motivation": "\u9488\u5bf9\u6df1\u5ea6\u5b66\u4e60\u4f18\u5316\u7b97\u6cd5\u7684\u5b9e\u9645\u914d\u7f6e\u9700\u6c42\uff0c\u89e3\u51b3\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u548c\u5404\u79cd\u8bad\u7ec3\u573a\u666f\u4e2d\u7684\u4f18\u5316\u6311\u6218\uff0c\u4e3a\u5b66\u672f\u7814\u7a76\u548c\u5de5\u7a0b\u5b9e\u8df5\u63d0\u4f9b\u5408\u7406\u9009\u62e9\u3001\u53c2\u6570\u8c03\u4f18\u548c\u6027\u80fd\u63d0\u5347\u7684\u53c2\u8003\u4f9d\u636e\u3002", "method": "\u7cfb\u7edf\u5206\u6790\u4e94\u79cd\u4e3b\u8981\u4f18\u5316\u7b97\u6cd5\uff08SGD\u3001Mini-batch SGD\u3001Momentum\u3001Adam\u3001Lion\uff09\u7684\u6838\u5fc3\u7279\u70b9\uff0c\u5305\u62ec\u5404\u81ea\u7684\u4f18\u52bf\u3001\u5c40\u9650\u6027\u548c\u5173\u952e\u5b9e\u8df5\u5efa\u8bae\u3002", "result": "\u6df1\u5165\u7406\u89e3\u4e86\u8fd9\u4e9b\u4f18\u5316\u7b97\u6cd5\u7684\u7279\u6027\uff0c\u5efa\u7acb\u4e86\u6807\u51c6\u5316\u7684\u7b97\u6cd5\u9009\u62e9\u53c2\u8003\u6846\u67b6\uff0c\u80fd\u591f\u6307\u5bfc\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u7b97\u6cd5\u914d\u7f6e\u548c\u53c2\u6570\u8c03\u4f18\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6df1\u5ea6\u5b66\u4e60\u4f18\u5316\u7b97\u6cd5\u7684\u5408\u7406\u9009\u62e9\u548c\u914d\u7f6e\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u7684\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u6a21\u578b\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u89c4\u6a21\u7684\u6a21\u578b\u548c\u8bad\u7ec3\u573a\u666f\u3002"}}
{"id": "2511.20927", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.20927", "abs": "https://arxiv.org/abs/2511.20927", "authors": ["Vitoria Barin-Pacela", "Kartik Ahuja", "Simon Lacoste-Julien", "Pascal Vincent"], "title": "Operationalizing Quantized Disentanglement", "comment": null, "summary": "Recent theoretical work established the unsupervised identifiability of quantized factors under any diffeomorphism. The theory assumes that quantization thresholds correspond to axis-aligned discontinuities in the probability density of the latent factors. By constraining a learned map to have a density with axis-aligned discontinuities, we can recover the quantization of the factors. However, translating this high-level principle into an effective practical criterion remains challenging, especially under nonlinear maps. Here, we develop a criterion for unsupervised disentanglement by encouraging axis-aligned discontinuities. Discontinuities manifest as sharp changes in the estimated density of factors and form what we call cliffs. Following the definition of independent discontinuities from the theory, we encourage the location of the cliffs along a factor to be independent of the values of the other factors. We show that our method, Cliff, outperforms the baselines on all disentanglement benchmarks, demonstrating its effectiveness in unsupervised disentanglement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCliff\u7684\u65e0\u76d1\u7763\u89e3\u7f20\u65b9\u6cd5\uff0c\u901a\u8fc7\u9f13\u52b1\u8f74\u5bf9\u9f50\u7684\u5bc6\u5ea6\u4e0d\u8fde\u7eed\u6027\u6765\u6062\u590d\u91cf\u5316\u56e0\u5b50\uff0c\u5728\u975e\u7ebf\u6027\u6620\u5c04\u4e0b\u5b9e\u73b0\u4e86\u4f18\u4e8e\u57fa\u51c6\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7406\u8bba\u8868\u660e\u91cf\u5316\u56e0\u5b50\u5728\u4efb\u610f\u5fae\u5206\u540c\u80da\u4e0b\u5177\u6709\u65e0\u76d1\u7763\u53ef\u8bc6\u522b\u6027\uff0c\u4f46\u5c06\u8fd9\u4e00\u7406\u8bba\u539f\u5219\u8f6c\u5316\u4e3a\u6709\u6548\u7684\u5b9e\u8df5\u6807\u51c6\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u7279\u522b\u662f\u5728\u975e\u7ebf\u6027\u6620\u5c04\u4e0b\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u9f13\u52b1\u8f74\u5bf9\u9f50\u4e0d\u8fde\u7eed\u6027\u7684\u65e0\u76d1\u7763\u89e3\u7f20\u6807\u51c6\uff0c\u901a\u8fc7\u5bc6\u5ea6\u4f30\u8ba1\u4e2d\u7684\u5c16\u9510\u53d8\u5316\uff08\u79f0\u4e3acliffs\uff09\u6765\u8bc6\u522b\u4e0d\u8fde\u7eed\u6027\uff0c\u5e76\u786e\u4fdd\u6cbf\u67d0\u4e00\u56e0\u5b50\u7684cliffs\u4f4d\u7f6e\u4e0e\u5176\u4ed6\u56e0\u5b50\u7684\u503c\u72ec\u7acb\u3002", "result": "Cliff\u65b9\u6cd5\u5728\u6240\u6709\u89e3\u7f20\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u90fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u65e0\u76d1\u7763\u89e3\u7f20\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u9f13\u52b1\u8f74\u5bf9\u9f50\u7684\u4e0d\u8fde\u7eed\u6027\uff0cCliff\u65b9\u6cd5\u6210\u529f\u5730\u5c06\u7406\u8bba\u539f\u5219\u8f6c\u5316\u4e3a\u5b9e\u7528\u7684\u65e0\u76d1\u7763\u89e3\u7f20\u6807\u51c6\uff0c\u5e76\u5728\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.21345", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.21345", "abs": "https://arxiv.org/abs/2511.21345", "authors": ["Chin-Hung Chen", "Yan Wu", "Wim van Houtum", "Alex Alvarado"], "title": "Blind Turbo Demodulation for Differentially Encoded OFDM with 2D Trellis Decomposition", "comment": "preprint", "summary": "Digital Audio Broadcasting (DAB)-like systems employ differentially encoded (DE) phase-shift keying (PSK) for transmission. While turbo-DE-PSK receivers offer substantial performance gains through iterative decoding by making the DE-PSK an inner code, they rely on accurate channel estimation without pilots, which is a key challenge in DAB-like scenarios. This paper develops a fully blind turbo-DE-PSK scheme that jointly estimates channel phase, channel gain, and noise variance directly from the received signal. The design leverages a two-dimensional (2D) trellis decomposition for blind phase estimation, complemented by power-based estimators for channel gain and noise variance. We provide a comprehensive system assessment across practical system parameters, including inner code length, phase quantization, and 2D block size. Simulation results show that the blind 2D turbo demodulator approaches the performance of receivers with perfect channel knowledge and remains robust under realistic transmission conditions.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u79cd\u5b8c\u5168\u76f2\u7684turbo-DE-PSK\u65b9\u6848\uff0c\u65e0\u9700\u5bfc\u9891\u5373\u53ef\u8054\u5408\u4f30\u8ba1\u4fe1\u9053\u76f8\u4f4d\u3001\u4fe1\u9053\u589e\u76ca\u548c\u566a\u58f0\u65b9\u5dee\uff0c\u5728DAB-like\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u63a5\u8fd1\u7406\u60f3\u4fe1\u9053\u77e5\u8bc6\u7684\u6027\u80fd\u3002", "motivation": "\u5728DAB-like\u7cfb\u7edf\u4e2d\uff0cturbo-DE-PSK\u63a5\u6536\u673a\u867d\u7136\u901a\u8fc7\u8fed\u4ee3\u89e3\u7801\u63d0\u4f9b\u663e\u8457\u6027\u80fd\u589e\u76ca\uff0c\u4f46\u4f9d\u8d56\u65e0\u5bfc\u9891\u7684\u51c6\u786e\u4fe1\u9053\u4f30\u8ba1\uff0c\u8fd9\u662f\u6b64\u7c7b\u573a\u666f\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002", "method": "\u91c7\u7528\u4e8c\u7ef4\u7f51\u683c\u5206\u89e3\u8fdb\u884c\u76f2\u76f8\u4f4d\u4f30\u8ba1\uff0c\u8f85\u4ee5\u57fa\u4e8e\u529f\u7387\u7684\u4fe1\u9053\u589e\u76ca\u548c\u566a\u58f0\u65b9\u5dee\u4f30\u8ba1\u5668\uff0c\u6784\u5efa\u5b8c\u5168\u76f2\u7684turbo-DE-PSK\u65b9\u6848\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u76f2\u4e8c\u7ef4turbo\u89e3\u8c03\u5668\u6027\u80fd\u63a5\u8fd1\u7406\u60f3\u4fe1\u9053\u77e5\u8bc6\u63a5\u6536\u673a\uff0c\u5e76\u5728\u5b9e\u9645\u4f20\u8f93\u6761\u4ef6\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u76f2turbo-DE-PSK\u65b9\u6848\u80fd\u591f\u6709\u6548\u89e3\u51b3DAB-like\u7cfb\u7edf\u4e2d\u65e0\u5bfc\u9891\u4fe1\u9053\u4f30\u8ba1\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u76f2\u63a5\u6536\u3002"}}
{"id": "2511.20779", "categories": ["cs.LG", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.20779", "abs": "https://arxiv.org/abs/2511.20779", "authors": ["Thomas Norrenbrock", "Timo Kaiser", "Sovan Biswas", "Neslihan Kose", "Ramesh Manuvinakurike", "Bodo Rosenhahn"], "title": "CHiQPM: Calibrated Hierarchical Interpretable Image Classification", "comment": "Accepted to NeurIPS 2025", "summary": "Globally interpretable models are a promising approach for trustworthy AI in safety-critical domains. Alongside global explanations, detailed local explanations are a crucial complement to effectively support human experts during inference. This work proposes the Calibrated Hierarchical QPM (CHiQPM) which offers uniquely comprehensive global and local interpretability, paving the way for human-AI complementarity. CHiQPM achieves superior global interpretability by contrastively explaining the majority of classes and offers novel hierarchical explanations that are more similar to how humans reason and can be traversed to offer a built-in interpretable Conformal prediction (CP) method. Our comprehensive evaluation shows that CHiQPM achieves state-of-the-art accuracy as a point predictor, maintaining 99% accuracy of non-interpretable models. This demonstrates a substantial improvement, where interpretability is incorporated without sacrificing overall accuracy. Furthermore, its calibrated set prediction is competitively efficient to other CP methods, while providing interpretable predictions of coherent sets along its hierarchical explanation.", "AI": {"tldr": "CHiQPM\u662f\u4e00\u4e2a\u5168\u5c40\u53ef\u89e3\u91ca\u6a21\u578b\uff0c\u901a\u8fc7\u5bf9\u6bd4\u89e3\u91ca\u591a\u6570\u7c7b\u522b\u5b9e\u73b0\u4f18\u8d8a\u7684\u5168\u5c40\u53ef\u89e3\u91ca\u6027\uff0c\u63d0\u4f9b\u7c7b\u4f3c\u4eba\u7c7b\u63a8\u7406\u7684\u5206\u5c42\u89e3\u91ca\uff0c\u5e76\u5185\u7f6e\u53ef\u89e3\u91ca\u7684Conformal\u9884\u6d4b\u65b9\u6cd5\uff0c\u5728\u4fdd\u630199%\u975e\u53ef\u89e3\u91ca\u6a21\u578b\u51c6\u786e\u7387\u7684\u540c\u65f6\u5b9e\u73b0SOTA\u6027\u80fd\u3002", "motivation": "\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\uff0c\u9664\u4e86\u5168\u5c40\u89e3\u91ca\u5916\uff0c\u8be6\u7ec6\u7684\u5c40\u90e8\u89e3\u91ca\u5bf9\u4e8e\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6709\u6548\u652f\u6301\u4eba\u7c7b\u4e13\u5bb6\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5b9e\u73b0\u4eba\u7c7b-AI\u4e92\u8865\u6027\u3002", "method": "\u63d0\u51fa\u6821\u51c6\u5206\u5c42QPM\uff08CHiQPM\uff09\uff0c\u901a\u8fc7\u5bf9\u6bd4\u89e3\u91ca\u591a\u6570\u7c7b\u522b\u5b9e\u73b0\u5168\u5c40\u53ef\u89e3\u91ca\u6027\uff0c\u63d0\u4f9b\u5206\u5c42\u89e3\u91ca\uff08\u7c7b\u4f3c\u4eba\u7c7b\u63a8\u7406\u65b9\u5f0f\uff09\uff0c\u5e76\u5185\u7f6e\u53ef\u89e3\u91ca\u7684Conformal\u9884\u6d4b\u65b9\u6cd5\u3002", "result": "CHiQPM\u4f5c\u4e3a\u70b9\u9884\u6d4b\u5668\u8fbe\u5230SOTA\u51c6\u786e\u7387\uff0c\u4fdd\u6301\u975e\u53ef\u89e3\u91ca\u6a21\u578b99%\u7684\u51c6\u786e\u7387\uff0c\u5176\u6821\u51c6\u96c6\u9884\u6d4b\u5728\u6548\u7387\u4e0a\u4e0e\u5176\u4ed6CP\u65b9\u6cd5\u7ade\u4e89\uff0c\u540c\u65f6\u63d0\u4f9b\u6cbf\u5176\u5206\u5c42\u89e3\u91ca\u7684\u8fde\u8d2f\u96c6\u7684\u53ef\u89e3\u91ca\u9884\u6d4b\u3002", "conclusion": "CHiQPM\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u5168\u9762\u7684\u5168\u5c40\u548c\u5c40\u90e8\u53ef\u89e3\u91ca\u6027\uff0c\u5c55\u793a\u4e86\u5728\u4e0d\u727a\u7272\u6574\u4f53\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u878d\u5165\u53ef\u89e3\u91ca\u6027\u7684\u663e\u8457\u6539\u8fdb\u3002"}}
{"id": "2511.20934", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20934", "abs": "https://arxiv.org/abs/2511.20934", "authors": ["Biagio La Rosa", "Leilani H. Gilpin"], "title": "Guaranteed Optimal Compositional Explanations for Neurons", "comment": "41 pages, 10 figures", "summary": "While neurons are the basic units of deep neural networks, it is still unclear what they learn and if their knowledge is aligned with that of humans. Compositional explanations aim to answer this question by describing the spatial alignment between neuron activations and concepts through logical rules. These logical descriptions are typically computed via a search over all possible concept combinations. Since computing the spatial alignment over the entire state space is computationally infeasible, the literature commonly adopts beam search to restrict the space. However, beam search cannot provide any theoretical guarantees of optimality, and it remains unclear how close current explanations are to the true optimum. In this theoretical paper, we address this gap by introducing the first framework for computing guaranteed optimal compositional explanations. Specifically, we propose: (i) a decomposition that identifies the factors influencing the spatial alignment, (ii) a heuristic to estimate the alignment at any stage of the search, and (iii) the first algorithm that can compute optimal compositional explanations within a feasible time. Using this framework, we analyze the differences between optimal and non-optimal explanations in the most popular settings for compositional explanations, the computer vision domain and Convolutional Neural Networks. In these settings, we demonstrate that 10-40 percent of explanations obtained with beam search are suboptimal when overlapping concepts are involved. Finally, we evaluate a beam-search variant guided by our proposed decomposition and heuristic, showing that it matches or improves runtime over prior methods while offering greater flexibility in hyperparameters and computational resources.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u8ba1\u7b97\u4fdd\u8bc1\u6700\u4f18\u7ec4\u5408\u89e3\u91ca\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u7a7a\u95f4\u5bf9\u9f50\u56e0\u7d20\u3001\u8bbe\u8ba1\u542f\u53d1\u5f0f\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5f00\u53d1\u51fa\u80fd\u5728\u53ef\u884c\u65f6\u95f4\u5185\u627e\u5230\u6700\u4f18\u89e3\u91ca\u7684\u7b97\u6cd5\u3002\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u548cCNN\u4e2d\uff0c\u53d1\u73b010-40%\u7684beam search\u89e3\u91ca\u662f\u6b21\u4f18\u7684\u3002", "motivation": "\u73b0\u6709\u7ec4\u5408\u89e3\u91ca\u65b9\u6cd5\u4f7f\u7528beam search\u6765\u8ba1\u7b97\u795e\u7ecf\u5143\u6fc0\u6d3b\u4e0e\u6982\u5ff5\u4e4b\u95f4\u7684\u7a7a\u95f4\u5bf9\u9f50\uff0c\u4f46\u65e0\u6cd5\u63d0\u4f9b\u6700\u4f18\u6027\u4fdd\u8bc1\uff0c\u4e0d\u6e05\u695a\u5f53\u524d\u89e3\u91ca\u4e0e\u771f\u6b63\u6700\u4f18\u89e3\u7684\u63a5\u8fd1\u7a0b\u5ea6\u3002", "method": "\u63d0\u51fa\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\u7684\u6846\u67b6\uff1a(i)\u8bc6\u522b\u5f71\u54cd\u7a7a\u95f4\u5bf9\u9f50\u56e0\u7d20\u7684\u5206\u89e3\u65b9\u6cd5\uff1b(ii)\u5728\u641c\u7d22\u4efb\u4f55\u9636\u6bb5\u4f30\u8ba1\u5bf9\u9f50\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff1b(iii)\u7b2c\u4e00\u4e2a\u80fd\u5728\u53ef\u884c\u65f6\u95f4\u5185\u8ba1\u7b97\u6700\u4f18\u7ec4\u5408\u89e3\u91ca\u7684\u7b97\u6cd5\u3002", "result": "\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u548cCNN\u7684\u6d41\u884c\u8bbe\u7f6e\u4e2d\uff0c\u5f53\u6d89\u53ca\u91cd\u53e0\u6982\u5ff5\u65f6\uff0c10-40%\u901a\u8fc7beam search\u83b7\u5f97\u7684\u89e3\u91ca\u662f\u6b21\u4f18\u7684\u3002\u57fa\u4e8e\u6240\u63d0\u5206\u89e3\u548c\u542f\u53d1\u5f0f\u7684beam search\u53d8\u4f53\u5728\u8fd0\u884c\u65f6\u5339\u914d\u6216\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u9996\u6b21\u5b9e\u73b0\u4e86\u4fdd\u8bc1\u6700\u4f18\u7684\u7ec4\u5408\u89e3\u91ca\u8ba1\u7b97\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2511.21050", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.21050", "abs": "https://arxiv.org/abs/2511.21050", "authors": ["Dongkyu Derek Cho", "Huan Song", "Arijit Ghosh Chowdhury", "Haotian An", "Yawei Wang", "Rohit Thekkanal", "Negin Sokhandan", "Sharlina Keshava", "Hannah Marlowe"], "title": "Breaking the Safety-Capability Tradeoff: Reinforcement Learning with Verifiable Rewards Maintains Safety Guardrails in LLMs", "comment": "AAAI-26 Workshop on Post-AI Formal Methods", "summary": "Fine-tuning large language models (LLMs) for downstream tasks typically exhibit a fundamental safety-capability tradeoff, where improving task performance degrades safety alignment even on benign datasets. This degradation persists across standard approaches including supervised finetuning (SFT) and reinforcement learning from human feedback (RLHF). While reinforcement learning with verifiable rewards (RLVR) has emerged as a promising alternative that optimizes models on objectively measurable tasks, its safety implications remain unexplored. We present the first comprehensive theoretical and empirical analysis of safety properties in RLVR. Theoretically, we derive upper bounds on safety drift under KL-constrained optimization and prove conditions under which safety degradation is eliminated. Empirically, we conduct extensive experiments across five adversarial safety benchmarks, demonstrating that RLVR can simultaneously enhance reasoning capabilities while maintaining or improving safety guardrails. Our comprehensive ablation studies examine the effects of optimization algorithms, model scale, and task domains. Our findings challenge the prevailing assumption of an inevitable safety capability trade-off, and establish that a specific training methodology can achieve both objectives simultaneously, providing insights for the safe deployment of reasoning-capable LLMs.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5168\u9762\u5206\u6790\u4e86RLVR\uff08\u5e26\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\uff09\u5728LLM\u5fae\u8c03\u4e2d\u7684\u5b89\u5168\u6027\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u5b89\u5168-\u80fd\u529b\u6743\u8861\u7684\u5047\u8bbe\uff0c\u8bc1\u660e\u4e86RLVR\u53ef\u4ee5\u540c\u65f6\u63d0\u5347\u63a8\u7406\u80fd\u529b\u5e76\u4fdd\u6301\u6216\u6539\u8fdb\u5b89\u5168\u9632\u62a4\u3002", "motivation": "\u4f20\u7edfLLM\u5fae\u8c03\u65b9\u6cd5\uff08\u5982SFT\u548cRLHF\uff09\u5b58\u5728\u5b89\u5168-\u80fd\u529b\u6743\u8861\u95ee\u9898\uff0c\u5373\u63d0\u5347\u4efb\u52a1\u6027\u80fd\u4f1a\u964d\u4f4e\u5b89\u5168\u5bf9\u9f50\u3002RLVR\u4f5c\u4e3a\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6cd5\uff0c\u5176\u5b89\u5168\u6027\u5f71\u54cd\u5c1a\u672a\u88ab\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u63a8\u5bfcKL\u7ea6\u675f\u4f18\u5316\u4e0b\u7684\u5b89\u5168\u6f02\u79fb\u4e0a\u754c\uff0c\u5e76\u8fdb\u884c\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u5b9e\u9a8c\uff0c\u6db5\u76d6\u4e94\u4e2a\u5bf9\u6297\u6027\u5b89\u5168\u57fa\u51c6\uff0c\u7814\u7a76\u4f18\u5316\u7b97\u6cd5\u3001\u6a21\u578b\u89c4\u6a21\u548c\u4efb\u52a1\u9886\u57df\u7684\u5f71\u54cd\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u53ef\u4ee5\u6d88\u9664\u5b89\u5168\u9000\u5316\uff0c\u5b9e\u8bc1\u7ed3\u679c\u663e\u793aRLVR\u80fd\u591f\u540c\u65f6\u589e\u5f3a\u63a8\u7406\u80fd\u529b\u5e76\u4fdd\u6301\u6216\u6539\u8fdb\u5b89\u5168\u9632\u62a4\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u6311\u6218\u4e86\u4e0d\u53ef\u907f\u514d\u7684\u5b89\u5168-\u80fd\u529b\u6743\u8861\u5047\u8bbe\uff0c\u786e\u7acb\u4e86\u7279\u5b9a\u8bad\u7ec3\u65b9\u6cd5\u53ef\u4ee5\u540c\u65f6\u5b9e\u73b0\u4e24\u4e2a\u76ee\u6807\uff0c\u4e3a\u5b89\u5168\u90e8\u7f72\u5177\u5907\u63a8\u7406\u80fd\u529b\u7684LLM\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2511.20937", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20937", "abs": "https://arxiv.org/abs/2511.20937", "authors": ["Qineng Wang", "Wenlong Huang", "Yu Zhou", "Hang Yin", "Tianwei Bao", "Jianwen Lyu", "Weiyu Liu", "Ruohan Zhang", "Jiajun Wu", "Li Fei-Fei", "Manling Li"], "title": "ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction", "comment": "Preprint version", "summary": "Embodied cognition argues that intelligence arises from sensorimotor interaction rather than passive observation. It raises an intriguing question: do modern vision-language models (VLMs), trained largely in a disembodied manner, exhibit signs of embodied cognition? We introduce ENACT, a benchmark that casts evaluation of embodied cognition as world modeling from egocentric interaction in a visual question answering (VQA) format. Framed as a partially observable Markov decision process (POMDP) whose actions are scene graph changes, ENACT comprises two complementary sequence reordering tasks: forward world modeling (reorder shuffled observations given actions) and inverse world modeling (reorder shuffled actions given observations). While conceptually simple, solving these tasks implicitly demands capabilities central to embodied cognition-affordance recognition, action-effect reasoning, embodied awareness, and interactive, long-horizon memory from partially observable egocentric input, while avoiding low-level image synthesis that could confound the evaluation. We provide a scalable pipeline that synthesizes QA pairs from robotics simulation (BEHAVIOR) and evaluates models on 8,972 QA pairs spanning long-horizon home-scale activities. Experiments reveal a performance gap between frontier VLMs and humans that widens with interaction horizon. Models consistently perform better on the inverse task than the forward one and exhibit anthropocentric biases, including a preference for right-handed actions and degradation when camera intrinsics or viewpoints deviate from human vision. Website at https://enact-embodied-cognition.github.io/.", "AI": {"tldr": "ENACT\u662f\u4e00\u4e2a\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u662f\u5426\u5c55\u73b0\u5177\u8eab\u8ba4\u77e5\u7684\u57fa\u51c6\uff0c\u901a\u8fc7\u89c6\u89c9\u95ee\u7b54\u5f62\u5f0f\u6d4b\u8bd5\u6a21\u578b\u4ece\u81ea\u6211\u4e2d\u5fc3\u4ea4\u4e92\u4e2d\u8fdb\u884c\u4e16\u754c\u5efa\u6a21\u7684\u80fd\u529b\uff0c\u5305\u542b\u524d\u5411\u4e16\u754c\u5efa\u6a21\u548c\u9006\u5411\u4e16\u754c\u5efa\u6a21\u4e24\u4e2a\u4efb\u52a1\u3002", "motivation": "\u7814\u7a76\u73b0\u4ee3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u867d\u7136\u4e3b\u8981\u4ee5\u975e\u5177\u8eab\u65b9\u5f0f\u8bad\u7ec3\uff0c\u4f46\u80fd\u5426\u8868\u73b0\u51fa\u5177\u8eab\u8ba4\u77e5\u7684\u7279\u5f81\uff0c\u5373\u667a\u80fd\u662f\u5426\u6e90\u4e8e\u611f\u89c9\u8fd0\u52a8\u4ea4\u4e92\u800c\u975e\u88ab\u52a8\u89c2\u5bdf\u3002", "method": "\u5c06\u5177\u8eab\u8ba4\u77e5\u8bc4\u4f30\u6784\u5efa\u4e3a\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u7528\u573a\u666f\u56fe\u53d8\u5316\u4f5c\u4e3a\u52a8\u4f5c\uff0c\u8bbe\u8ba1\u4e86\u4e24\u4e2a\u5e8f\u5217\u91cd\u6392\u5e8f\u4efb\u52a1\uff1a\u7ed9\u5b9a\u52a8\u4f5c\u91cd\u6392\u89c2\u5bdf\u5e8f\u5217\uff08\u524d\u5411\u4e16\u754c\u5efa\u6a21\uff09\u548c\u7ed9\u5b9a\u89c2\u5bdf\u91cd\u6392\u52a8\u4f5c\u5e8f\u5217\uff08\u9006\u5411\u4e16\u754c\u5efa\u6a21\uff09\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u524d\u6cbf\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u4e4b\u95f4\u5b58\u5728\u6027\u80fd\u5dee\u8ddd\uff0c\u4e14\u968f\u7740\u4ea4\u4e92\u89c6\u91ce\u5ef6\u957f\u5dee\u8ddd\u6269\u5927\u3002\u6a21\u578b\u5728\u9006\u5411\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u524d\u5411\u4efb\u52a1\uff0c\u5e76\u8868\u73b0\u51fa\u4eba\u7c7b\u4e2d\u5fc3\u504f\u89c1\uff0c\u5982\u504f\u597d\u53f3\u624b\u52a8\u4f5c\u3001\u5f53\u76f8\u673a\u53c2\u6570\u6216\u89c6\u89d2\u504f\u79bb\u4eba\u7c7b\u89c6\u89c9\u65f6\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "ENACT\u57fa\u51c6\u63ed\u793a\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u5177\u8eab\u8ba4\u77e5\u80fd\u529b\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdb\u6a21\u578b\u7684\u5177\u8eab\u667a\u80fd\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2511.20830", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20830", "abs": "https://arxiv.org/abs/2511.20830", "authors": ["Reza Mansouri", "Dustin Kempton", "Pete Riley", "Rafal Angryk"], "title": "Autoregressive Surrogate Modeling of the Solar Wind with Spherical Fourier Neural Operator", "comment": "IEEE Conference on Data Mining (ICDM 2025)", "summary": "The solar wind, a continuous outflow of charged particles from the Sun's corona, shapes the heliosphere and impacts space systems near Earth. Accurate prediction of features such as high-speed streams and coronal mass ejections is critical for space weather forecasting, but traditional three-dimensional magnetohydrodynamic (MHD) models are computationally expensive, limiting rapid exploration of boundary condition uncertainties. We introduce the first autoregressive machine learning surrogate for steady-state solar wind radial velocity using the Spherical Fourier Neural Operator (SFNO). By predicting a limited radial range and iteratively propagating the solution outward, the model improves accuracy in distant regions compared to a single-step approach. Compared with the numerical HUX surrogate, SFNO demonstrates superior or comparable performance while providing a flexible, trainable, and data-driven alternative, establishing a novel methodology for high-fidelity solar wind modeling. The source code and additional visual results are available at https://github.com/rezmansouri/solarwind-sfno-velocity-autoregressive.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u4f7f\u7528\u7403\u9762\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\u7684\u81ea\u56de\u5f52\u673a\u5668\u5b66\u4e60\u66ff\u4ee3\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u592a\u9633\u98ce\u5f84\u5411\u901f\u5ea6\uff0c\u76f8\u6bd4\u4f20\u7edf\u6570\u503c\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u51c6\u786e\u6027\u548c\u7075\u6d3b\u6027\u3002", "motivation": "\u4f20\u7edf\u4e09\u7ef4\u78c1\u6d41\u4f53\u52a8\u529b\u5b66\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u9650\u5236\u4e86\u8fb9\u754c\u6761\u4ef6\u4e0d\u786e\u5b9a\u6027\u7684\u5feb\u901f\u63a2\u7d22\uff0c\u9700\u8981\u5f00\u53d1\u9ad8\u6548\u7684\u66ff\u4ee3\u6a21\u578b\u6765\u6539\u8fdb\u7a7a\u95f4\u5929\u6c14\u9884\u62a5\u3002", "method": "\u4f7f\u7528\u7403\u9762\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\uff0c\u901a\u8fc7\u9884\u6d4b\u6709\u9650\u5f84\u5411\u8303\u56f4\u5e76\u8fed\u4ee3\u5411\u5916\u4f20\u64ad\u89e3\uff0c\u6784\u5efa\u81ea\u56de\u5f52\u673a\u5668\u5b66\u4e60\u66ff\u4ee3\u6a21\u578b\u3002", "result": "\u4e0e\u6570\u503cHUX\u66ff\u4ee3\u6a21\u578b\u76f8\u6bd4\uff0cSFNO\u8868\u73b0\u51fa\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u7075\u6d3b\u3001\u53ef\u8bad\u7ec3\u548c\u6570\u636e\u9a71\u52a8\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u9ad8\u4fdd\u771f\u592a\u9633\u98ce\u5efa\u6a21\u5efa\u7acb\u4e86\u65b0\u9896\u7684\u65b9\u6cd5\u8bba\uff0c\u4ee3\u7801\u548c\u53ef\u89c6\u5316\u7ed3\u679c\u5df2\u5f00\u6e90\u3002"}}
{"id": "2511.21260", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21260", "abs": "https://arxiv.org/abs/2511.21260", "authors": ["Joseph Y. Halpern", "Rafael Pass"], "title": "Causality Without Causal Models", "comment": "In Proceedings TARK 2025, arXiv:2511.20540", "summary": "Perhaps the most prominent current definition of (actual) causality is due to Halpern and Pearl.  It is defined using causal models (also known as structural equations models).  We abstract the definition, extracting its key features, so that it can be applied to any other model where counterfactuals are defined. By abstracting the definition, we gain a number of benefits. Not only can we apply the definition in a wider range of models, including ones that allow, for example, backtracking, but we can apply the definition to determine if A is a cause of B  even if A and B are formulas involving disjunctions, negations, beliefs, and nested counterfactuals (none of which can be handled by the Halpern-Pearl definition). Moreover, we can extend the ideas to getting an abstract definition of explanation that can be applied beyond causal models. Finally, we gain a deeper understanding of features of the definition  even in causal models.", "AI": {"tldr": "\u672c\u6587\u5bf9Halpern\u548cPearl\u7684\u56e0\u679c\u5b9a\u4e49\u8fdb\u884c\u4e86\u62bd\u8c61\u5316\uff0c\u63d0\u53d6\u5176\u5173\u952e\u7279\u5f81\uff0c\u4f7f\u5176\u80fd\u591f\u5e94\u7528\u4e8e\u4efb\u4f55\u5b9a\u4e49\u4e86\u53cd\u4e8b\u5b9e\u7684\u6a21\u578b\u3002", "motivation": "Halpern-Pearl\u7684\u56e0\u679c\u5b9a\u4e49\u4ec5\u9650\u4e8e\u56e0\u679c\u6a21\u578b\uff0c\u65e0\u6cd5\u5904\u7406\u5305\u542b\u6790\u53d6\u3001\u5426\u5b9a\u3001\u4fe1\u5ff5\u548c\u5d4c\u5957\u53cd\u4e8b\u5b9e\u7684\u590d\u6742\u60c5\u51b5\uff0c\u9700\u8981\u66f4\u901a\u7528\u7684\u5b9a\u4e49\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u62bd\u8c61\u5316Halpern-Pearl\u56e0\u679c\u5b9a\u4e49\u7684\u5173\u952e\u7279\u5f81\uff0c\u6784\u5efa\u4e00\u4e2a\u53ef\u4ee5\u5728\u4efb\u4f55\u53cd\u4e8b\u5b9e\u6a21\u578b\u4e0a\u5e94\u7528\u7684\u901a\u7528\u56e0\u679c\u5b9a\u4e49\u6846\u67b6\u3002", "result": "\u65b0\u5b9a\u4e49\u6846\u67b6\u4e0d\u4ec5\u80fd\u5e94\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u6a21\u578b\uff08\u5305\u62ec\u5141\u8bb8\u56de\u6eaf\u7684\u6a21\u578b\uff09\uff0c\u8fd8\u80fd\u5904\u7406\u590d\u6742\u903b\u8f91\u516c\u5f0f\uff0c\u5e76\u80fd\u6269\u5c55\u5230\u89e3\u91ca\u7684\u5b9a\u4e49\u3002", "conclusion": "\u62bd\u8c61\u5316\u65b9\u6cd5\u6269\u5c55\u4e86\u56e0\u679c\u5b9a\u4e49\u7684\u9002\u7528\u8303\u56f4\uff0c\u63d0\u4f9b\u4e86\u5bf9\u56e0\u679c\u5b9a\u4e49\u66f4\u6df1\u5165\u7684\u7406\u89e3\uff0c\u5e76\u4e3a\u6784\u5efa\u901a\u7528\u89e3\u91ca\u6846\u67b6\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.21417", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.21417", "abs": "https://arxiv.org/abs/2511.21417", "authors": ["Mia M\u00fc\u00dfig", "Jan Johannsen"], "title": "New Hybrid Heuristics for Pseudo-Boolean Propagation", "comment": null, "summary": "In pseudo-boolean solving the currently most successful unit propagation strategy is a hybrid mode combining the watched literal scheme with the counting method. This short paper introduces new heuristics for this hybrid decision, which are able to drastically outperform the current method in the RoundingSAT solver.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5728\u4f2a\u5e03\u5c14\u6c42\u89e3\u4e2d\u6df7\u5408\u5355\u5143\u4f20\u64ad\u7b56\u7565\u7684\u65b0\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u4f18\u4e8eRoundingSAT\u6c42\u89e3\u5668\u4e2d\u7684\u5f53\u524d\u65b9\u6cd5", "motivation": "\u5f53\u524d\u4f2a\u5e03\u5c14\u6c42\u89e3\u4e2d\u6700\u6210\u529f\u7684\u5355\u5143\u4f20\u64ad\u7b56\u7565\u662f\u7ed3\u5408\u89c2\u5bdf\u6587\u5b57\u65b9\u6848\u548c\u8ba1\u6570\u65b9\u6cd5\u7684\u6df7\u5408\u6a21\u5f0f\uff0c\u4f46\u9700\u8981\u6539\u8fdb\u5176\u51b3\u7b56\u542f\u53d1\u5f0f", "method": "\u4e3a\u6df7\u5408\u51b3\u7b56\u5f15\u5165\u65b0\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u7ed3\u5408\u89c2\u5bdf\u6587\u5b57\u65b9\u6848\u548c\u8ba1\u6570\u65b9\u6cd5", "result": "\u65b0\u542f\u53d1\u5f0f\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u4f18\u4e8eRoundingSAT\u6c42\u89e3\u5668\u4e2d\u7684\u5f53\u524d\u65b9\u6cd5", "conclusion": "\u65b0\u63d0\u51fa\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u5728\u4f2a\u5e03\u5c14\u6c42\u89e3\u7684\u6df7\u5408\u5355\u5143\u4f20\u64ad\u7b56\u7565\u4e2d\u8868\u73b0\u4f18\u5f02"}}
{"id": "2511.20913", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20913", "abs": "https://arxiv.org/abs/2511.20913", "authors": ["Yingchuan Sun", "Shengpu Tang"], "title": "Exploring Time-Step Size in Reinforcement Learning for Sepsis Treatment", "comment": null, "summary": "Existing studies on reinforcement learning (RL) for sepsis management have mostly followed an established problem setup, in which patient data are aggregated into 4-hour time steps. Although concerns have been raised regarding the coarseness of this time-step size, which might distort patient dynamics and lead to suboptimal treatment policies, the extent to which this is a problem in practice remains unexplored. In this work, we conducted empirical experiments for a controlled comparison of four time-step sizes ($\u0394t\\!=\\!1,2,4,8$ h) on this domain, following an identical offline RL pipeline. To enable a fair comparison across time-step sizes, we designed action re-mapping methods that allow for evaluation of policies on datasets with different time-step sizes, and conducted cross-$\u0394t$ model selections under two policy learning setups. Our goal was to quantify how time-step size influences state representation learning, behavior cloning, policy training, and off-policy evaluation. Our results show that performance trends across $\u0394t$ vary as learning setups change, while policies learned at finer time-step sizes ($\u0394t = 1$ h and $2$ h) using a static behavior policy achieve the overall best performance and stability. Our work highlights time-step size as a core design choice in offline RL for healthcare and provides evidence supporting alternatives beyond the conventional 4-hour setup.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u6bd4\u8f83\u4e86\u8113\u6bd2\u75c7\u7ba1\u7406\u4e2d\u4e0d\u540c\u65f6\u95f4\u6b65\u957f\uff081\u30012\u30014\u30018\u5c0f\u65f6\uff09\u5bf9\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u66f4\u7ec6\u7684\u65f6\u95f4\u6b65\u957f\uff081-2\u5c0f\u65f6\uff09\u5728\u9759\u6001\u884c\u4e3a\u7b56\u7565\u4e0b\u80fd\u83b7\u5f97\u66f4\u597d\u7684\u6027\u80fd\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u8113\u6bd2\u75c7\u7ba1\u7406\u5f3a\u5316\u5b66\u4e60\u7814\u7a76\u5927\u591a\u4f7f\u75284\u5c0f\u65f6\u65f6\u95f4\u6b65\u957f\uff0c\u4f46\u8be5\u7c97\u7c92\u5ea6\u53ef\u80fd\u626d\u66f2\u60a3\u8005\u52a8\u6001\u5e76\u5bfc\u81f4\u6b21\u4f18\u6cbb\u7597\u7b56\u7565\uff0c\u9700\u8981\u91cf\u5316\u65f6\u95f4\u6b65\u957f\u5bf9\u79bb\u7ebfRL\u5404\u73af\u8282\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u76f8\u540c\u79bb\u7ebfRL\u6d41\u7a0b\uff0c\u8bbe\u8ba1\u52a8\u4f5c\u91cd\u6620\u5c04\u65b9\u6cd5\u4ee5\u516c\u5e73\u6bd4\u8f83\u4e0d\u540c\u65f6\u95f4\u6b65\u957f\uff0c\u5728\u4e24\u79cd\u7b56\u7565\u5b66\u4e60\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u8de8\u65f6\u95f4\u6b65\u957f\u7684\u6a21\u578b\u9009\u62e9\uff0c\u8bc4\u4f30\u65f6\u95f4\u6b65\u957f\u5bf9\u72b6\u6001\u8868\u793a\u5b66\u4e60\u3001\u884c\u4e3a\u514b\u9686\u3001\u7b56\u7565\u8bad\u7ec3\u548c\u79bb\u7b56\u7565\u8bc4\u4f30\u7684\u5f71\u54cd\u3002", "result": "\u4e0d\u540c\u65f6\u95f4\u6b65\u957f\u7684\u6027\u80fd\u8d8b\u52bf\u968f\u5b66\u4e60\u8bbe\u7f6e\u53d8\u5316\uff0c\u4f7f\u7528\u9759\u6001\u884c\u4e3a\u7b56\u7565\u5728\u66f4\u7ec6\u65f6\u95f4\u6b65\u957f\uff081-2\u5c0f\u65f6\uff09\u5b66\u4e60\u7684\u7b56\u7565\u83b7\u5f97\u6574\u4f53\u6700\u4f73\u6027\u80fd\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "\u65f6\u95f4\u6b65\u957f\u662f\u533b\u7597\u9886\u57df\u79bb\u7ebfRL\u7684\u6838\u5fc3\u8bbe\u8ba1\u9009\u62e9\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u8d85\u8d8a\u4f20\u7edf4\u5c0f\u65f6\u8bbe\u7f6e\u7684\u66ff\u4ee3\u65b9\u6848\u63d0\u4f9b\u4e86\u8bc1\u636e\u652f\u6301\u3002"}}
{"id": "2511.21522", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21522", "abs": "https://arxiv.org/abs/2511.21522", "authors": ["Yanxing Huang", "Zihan Tang", "Zejin Lin", "Peng Li", "Yang Liu"], "title": "Pessimistic Verification for Open Ended Math Questions", "comment": null, "summary": "The key limitation of the verification performance lies in the ability of error detection. With this intuition we designed several variants of pessimistic verification, which are simple workflows that could significantly improve the verification of open-ended math questions. In pessimistic verification we construct multiple parallel verifications for the same proof, and the proof is deemed incorrect if any one of them reports an error. This simple technique significantly improves the performance across many math verification benchmarks without incurring substantial computational resources. Its token efficiency even surpassed extended long-CoT in test-time scaling. Our case studies further indicate that the majority of false negatives in stronger models are actually caused by annotation errors in the original dataset, so our method's performance is in fact underestimated. Self-verification for mathematical problems can effectively improve the reliability and performance of language model outputs, and it also plays a critical role in enabling long-horizon mathematical tasks. We believe that research on pessimistic verification will help enhance the mathematical capabilities of language models across a wide range of tasks.", "AI": {"tldr": "\u63d0\u51fa\u60b2\u89c2\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e76\u884c\u6784\u5efa\u591a\u4e2a\u9a8c\u8bc1\u6d41\u7a0b\u6765\u68c0\u6d4b\u6570\u5b66\u8bc1\u660e\u4e2d\u7684\u9519\u8bef\uff0c\u663e\u8457\u63d0\u5347\u9a8c\u8bc1\u6027\u80fd\u4e14\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u4f4e\u3002", "motivation": "\u73b0\u6709\u9a8c\u8bc1\u6027\u80fd\u53d7\u9650\u4e8e\u9519\u8bef\u68c0\u6d4b\u80fd\u529b\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u9a8c\u8bc1\u65b9\u6cd5\u6765\u63d0\u9ad8\u6570\u5b66\u95ee\u9898\u9a8c\u8bc1\u7684\u53ef\u9760\u6027\u3002", "method": "\u8bbe\u8ba1\u60b2\u89c2\u9a8c\u8bc1\u53d8\u4f53\uff0c\u4e3a\u540c\u4e00\u8bc1\u660e\u6784\u5efa\u591a\u4e2a\u5e76\u884c\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u53ea\u8981\u4efb\u4e00\u9a8c\u8bc1\u62a5\u544a\u9519\u8bef\u5c31\u5224\u5b9a\u8bc1\u660e\u4e0d\u6b63\u786e\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u5b66\u9a8c\u8bc1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0ctoken\u6548\u7387\u751a\u81f3\u8d85\u8fc7\u6269\u5c55\u957f\u94fe\u601d\u7ef4\uff0c\u4e14\u591a\u6570\u5047\u9634\u6027\u6e90\u4e8e\u539f\u59cb\u6570\u636e\u96c6\u6807\u6ce8\u9519\u8bef\u3002", "conclusion": "\u60b2\u89c2\u9a8c\u8bc1\u80fd\u6709\u6548\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7684\u53ef\u9760\u6027\u548c\u6027\u80fd\uff0c\u5bf9\u5b9e\u73b0\u957f\u89c6\u91ce\u6570\u5b66\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0c\u6709\u52a9\u4e8e\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u80fd\u529b\u3002"}}
{"id": "2511.20992", "categories": ["cs.LG", "cs.CR", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20992", "abs": "https://arxiv.org/abs/2511.20992", "authors": ["Akansha Kalra", "Soumil Datta", "Ethan Gilmore", "Duc La", "Guanhong Tao", "Daniel S. Brown"], "title": "Dataset Poisoning Attacks on Behavioral Cloning Policies", "comment": "Accepted at EAI SmartSP 2025", "summary": "Behavior Cloning (BC) is a popular framework for training sequential decision policies from expert demonstrations via supervised learning. As these policies are increasingly being deployed in the real world, their robustness and potential vulnerabilities are an important concern. In this work, we perform the first analysis of the efficacy of clean-label backdoor attacks on BC policies. Our backdoor attacks poison a dataset of demonstrations by injecting a visual trigger to create a spurious correlation that can be exploited at test time. We evaluate how policy vulnerability scales with the fraction of poisoned data, the strength of the trigger, and the trigger type. We also introduce a novel entropy-based test-time trigger attack that substantially degrades policy performance by identifying critical states where test-time triggering of the backdoor is expected to be most effective at degrading performance. We empirically demonstrate that BC policies trained on even minimally poisoned datasets exhibit deceptively high, near-baseline task performance despite being highly vulnerable to backdoor trigger attacks during deployment. Our results underscore the urgent need for more research into the robustness of BC policies, particularly as large-scale datasets are increasingly used to train policies for real-world cyber-physical systems. Videos and code are available at https://sites.google.com/view/dataset-poisoning-in-bc.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5206\u6790\u4e86\u884c\u4e3a\u514b\u9686\u7b56\u7565\u5bf9\u5e72\u51c0\u6807\u7b7e\u540e\u95e8\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u901a\u8fc7\u6ce8\u5165\u89c6\u89c9\u89e6\u53d1\u5668\u5728\u6f14\u793a\u6570\u636e\u4e2d\u521b\u5efa\u865a\u5047\u76f8\u5173\u6027\uff0c\u5e76\u5728\u6d4b\u8bd5\u65f6\u5229\u7528\u8fd9\u4e9b\u540e\u95e8\u663e\u8457\u964d\u4f4e\u7b56\u7565\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u884c\u4e3a\u514b\u9686\u7b56\u7565\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u90e8\u7f72\u7684\u589e\u52a0\uff0c\u5176\u9c81\u68d2\u6027\u548c\u6f5c\u5728\u6f0f\u6d1e\u6210\u4e3a\u91cd\u8981\u5173\u6ce8\u70b9\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76BC\u7b56\u7565\u5bf9\u540e\u95e8\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u7279\u522b\u662f\u5f53\u8bad\u7ec3\u6570\u636e\u88ab\u8f7b\u5fae\u6c61\u67d3\u65f6\u3002", "method": "\u901a\u8fc7\u5728\u6f14\u793a\u6570\u636e\u96c6\u4e2d\u6ce8\u5165\u89c6\u89c9\u89e6\u53d1\u5668\u6765\u6c61\u67d3\u6570\u636e\uff0c\u521b\u5efa\u865a\u5047\u76f8\u5173\u6027\uff1b\u5f15\u5165\u57fa\u4e8e\u71b5\u7684\u6d4b\u8bd5\u65f6\u89e6\u53d1\u5668\u653b\u51fb\uff0c\u8bc6\u522b\u5173\u952e\u72b6\u6001\uff1b\u8bc4\u4f30\u7b56\u7565\u8106\u5f31\u6027\u4e0e\u6c61\u67d3\u6570\u636e\u6bd4\u4f8b\u3001\u89e6\u53d1\u5668\u5f3a\u5ea6\u548c\u7c7b\u578b\u7684\u5173\u7cfb\u3002", "result": "\u5b9e\u8bc1\u8868\u660e\uff0c\u5373\u4f7f\u5728\u6700\u5c0f\u7a0b\u5ea6\u6c61\u67d3\u7684\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684BC\u7b56\u7565\uff0c\u5728\u90e8\u7f72\u671f\u95f4\u5bf9\u540e\u95e8\u89e6\u53d1\u5668\u653b\u51fb\u4e5f\u8868\u73b0\u51fa\u9ad8\u5ea6\u8106\u5f31\u6027\uff0c\u5c3d\u7ba1\u5176\u4efb\u52a1\u6027\u80fd\u63a5\u8fd1\u57fa\u7ebf\u6c34\u5e73\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u8feb\u5207\u9700\u8981\u52a0\u5f3a\u5bf9BC\u7b56\u7565\u9c81\u68d2\u6027\u7684\u7814\u7a76\uff0c\u7279\u522b\u662f\u5f53\u5927\u89c4\u6a21\u6570\u636e\u96c6\u88ab\u7528\u4e8e\u8bad\u7ec3\u73b0\u5b9e\u4e16\u754c\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u7684\u7b56\u7565\u65f6\u3002"}}
{"id": "2511.21570", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.21570", "abs": "https://arxiv.org/abs/2511.21570", "authors": ["Maria Perez-Ortiz"], "title": "From Prediction to Foresight: The Role of AI in Designing Responsible Futures", "comment": "Accessible at https://projecteuclid.org/journals/journal-of-artificial-intelligence-for-sustainable-development/volume-1/issue-1/From-Prediction-to-Foresight--The-Role-of-AI-in/10.69828/4d4kja.full", "summary": "In an era marked by rapid technological advancements and complex global challenges, responsible foresight has emerged as an essential framework for policymakers aiming to navigate future uncertainties and shape the future. Responsible foresight entails the ethical anticipation of emerging opportunities and risks, with a focus on fostering proactive, sustainable, and accountable future design. This paper coins the term \"responsible computational foresight\", examining the role of human-centric artificial intelligence and computational modeling in advancing responsible foresight, establishing a set of foundational principles for this new field and presenting a suite of AI-driven foresight tools currently shaping it. AI, particularly in conjunction with simulations and scenario analysis, enhances policymakers' ability to address uncertainty, evaluate risks, and devise strategies geared toward sustainable, resilient futures. However, responsible foresight extends beyond mere technical forecasting; it demands a nuanced understanding of the interdependencies within social, environmental, economic and political systems, alongside a commitment to ethical, long-term decision-making that supports human intelligence. We argue that AI will play a role as a supportive tool in responsible, human-centered foresight, complementing rather than substituting policymaker judgment to enable the proactive shaping of resilient and ethically sound futures. This paper advocates for the thoughtful integration of AI into foresight practices to empower policymakers and communities as they confront the grand challenges of the 21st century.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\"\u8d1f\u8d23\u4efb\u8ba1\u7b97\u524d\u77bb\"\u6982\u5ff5\uff0c\u63a2\u8ba8\u4eba\u5de5\u667a\u80fd\u5728\u8d1f\u8d23\u4efb\u524d\u77bb\u4e2d\u7684\u4f5c\u7528\uff0c\u5efa\u7acb\u8be5\u9886\u57df\u7684\u57fa\u672c\u539f\u5219\uff0c\u5e76\u5c55\u793aAI\u9a71\u52a8\u7684\u524d\u77bb\u5de5\u5177\u3002", "motivation": "\u5728\u6280\u672f\u5feb\u901f\u53d1\u5c55\u548c\u5168\u7403\u6311\u6218\u590d\u6742\u7684\u65f6\u4ee3\uff0c\u8d1f\u8d23\u4efb\u524d\u77bb\u5df2\u6210\u4e3a\u653f\u7b56\u5236\u5b9a\u8005\u5e94\u5bf9\u672a\u6765\u4e0d\u786e\u5b9a\u6027\u548c\u5851\u9020\u672a\u6765\u7684\u91cd\u8981\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u5efa\u7acb\u8d1f\u8d23\u4efb\u8ba1\u7b97\u524d\u77bb\u7684\u57fa\u672c\u539f\u5219\uff0c\u7ed3\u5408\u4eba\u5de5\u667a\u80fd\u3001\u6a21\u62df\u548c\u60c5\u666f\u5206\u6790\uff0c\u5f00\u53d1AI\u9a71\u52a8\u7684\u524d\u77bb\u5de5\u5177\u6765\u652f\u6301\u653f\u7b56\u5236\u5b9a\u3002", "result": "AI\u589e\u5f3a\u4e86\u653f\u7b56\u5236\u5b9a\u8005\u5e94\u5bf9\u4e0d\u786e\u5b9a\u6027\u3001\u8bc4\u4f30\u98ce\u9669\u548c\u5236\u5b9a\u53ef\u6301\u7eed\u3001\u6709\u97e7\u6027\u672a\u6765\u6218\u7565\u7684\u80fd\u529b\uff0c\u4f46\u9700\u8981\u4e0e\u4eba\u7c7b\u5224\u65ad\u76f8\u7ed3\u5408\u3002", "conclusion": "AI\u5e94\u4f5c\u4e3a\u652f\u6301\u6027\u5de5\u5177\u878d\u5165\u524d\u77bb\u5b9e\u8df5\uff0c\u8865\u5145\u800c\u975e\u66ff\u4ee3\u653f\u7b56\u5236\u5b9a\u8005\u7684\u5224\u65ad\uff0c\u4ee5\u5851\u9020\u6709\u97e7\u6027\u548c\u9053\u5fb7\u5065\u5168\u7684\u672a\u6765\u3002"}}
{"id": "2511.21011", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21011", "abs": "https://arxiv.org/abs/2511.21011", "authors": ["Sid Bharthulwar", "Stone Tao", "Hao Su"], "title": "Staggered Environment Resets Improve Massively Parallel On-Policy Reinforcement Learning", "comment": null, "summary": "Massively parallel GPU simulation environments have accelerated reinforcement learning (RL) research by enabling fast data collection for on-policy RL algorithms like Proximal Policy Optimization (PPO). To maximize throughput, it is common to use short rollouts per policy update, increasing the update-to-data (UTD) ra- tio. However, we find that, in this setting, standard synchronous resets introduce harmful nonstationarity, skewing the learning signal and destabilizing training. We introduce staggered resets, a simple yet effective technique where environments are initialized and reset at varied points within the task horizon. This yields training batches with greater temporal diversity, reducing the nonstationarity induced by synchronized rollouts. We characterize dimensions along which RL environments can benefit significantly from staggered resets through illustrative toy environ- ments. We then apply this technique to challenging high-dimensional robotics environments, achieving significantly higher sample efficiency, faster wall-clock convergence, and stronger final performance. Finally, this technique scales better with more parallel environments compared to naive synchronized rollouts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u4ea4\u9519\u91cd\u7f6e\uff08staggered resets\uff09\u7684\u6280\u672f\uff0c\u901a\u8fc7\u5728\u4efb\u52a1\u65f6\u95f4\u8f74\u7684\u4e0d\u540c\u70b9\u521d\u59cb\u5316\u548c\u91cd\u7f6e\u73af\u5883\uff0c\u51cf\u5c11\u540c\u6b65\u91cd\u7f6e\u5f15\u5165\u7684\u6709\u5bb3\u975e\u5e73\u7a33\u6027\uff0c\u4ece\u800c\u63d0\u9ad8\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u6837\u672c\u6548\u7387\u3001\u6536\u655b\u901f\u5ea6\u548c\u6700\u7ec8\u6027\u80fd\u3002", "motivation": "\u5728GPU\u5927\u89c4\u6a21\u5e76\u884c\u6a21\u62df\u73af\u5883\u4e2d\uff0c\u4e3a\u4e86\u6700\u5927\u5316\u541e\u5410\u91cf\u901a\u5e38\u4f7f\u7528\u77ed\u56de\u5408\u8fdb\u884c\u7b56\u7565\u66f4\u65b0\uff0c\u4f46\u8fd9\u4f1a\u5bfc\u81f4\u540c\u6b65\u91cd\u7f6e\u5f15\u5165\u6709\u5bb3\u7684\u975e\u5e73\u7a33\u6027\uff0c\u626d\u66f2\u5b66\u4e60\u4fe1\u53f7\u5e76\u7834\u574f\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u4ea4\u9519\u91cd\u7f6e\u6280\u672f\uff0c\u8ba9\u73af\u5883\u5728\u4efb\u52a1\u65f6\u95f4\u8f74\u7684\u4e0d\u540c\u70b9\u8fdb\u884c\u521d\u59cb\u5316\u548c\u91cd\u7f6e\uff0c\u4ece\u800c\u4ea7\u751f\u5177\u6709\u66f4\u5927\u65f6\u95f4\u591a\u6837\u6027\u7684\u8bad\u7ec3\u6279\u6b21\uff0c\u51cf\u5c11\u540c\u6b65\u56de\u5408\u5f15\u5165\u7684\u975e\u5e73\u7a33\u6027\u3002", "result": "\u5728\u6311\u6218\u6027\u7684\u9ad8\u7ef4\u673a\u5668\u4eba\u73af\u5883\u4e2d\uff0c\u8be5\u6280\u672f\u663e\u8457\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\u3001\u52a0\u5feb\u4e86\u5b9e\u9645\u6536\u655b\u901f\u5ea6\u5e76\u589e\u5f3a\u4e86\u6700\u7ec8\u6027\u80fd\uff0c\u4e14\u6bd4\u6734\u7d20\u540c\u6b65\u56de\u5408\u5177\u6709\u66f4\u597d\u7684\u6269\u5c55\u6027\u3002", "conclusion": "\u4ea4\u9519\u91cd\u7f6e\u662f\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u6280\u672f\uff0c\u80fd\u591f\u663e\u8457\u6539\u5584\u5927\u89c4\u6a21\u5e76\u884c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u6027\u80fd\u548c\u7a33\u5b9a\u6027\uff0c\u7279\u522b\u662f\u5728\u4f7f\u7528\u77ed\u56de\u5408\u548c\u9ad8\u66f4\u65b0\u6570\u636e\u6bd4\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2511.21034", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21034", "abs": "https://arxiv.org/abs/2511.21034", "authors": ["Mahdi Saki", "Justin Lipman"], "title": "Prediction of Herd Life in Dairy Cows Using Multi-Head Attention Transformers", "comment": null, "summary": "Dairy farmers should decide to keep or cull a cow based on an objective assessment of her likely performance in the herd. For this purpose, farmers need to identify more resilient cows, which can cope better with farm conditions and complete more lactations. This decision-making process is inherently complex, with significant environmental and economic implications. In this study, we develop an AI-driven model to predict cow longevity using historical multivariate time-series data recorded from birth. Leveraging advanced AI techniques, specifically Multi-Head Attention Transformers, we analysed approximately 780,000 records from 19,000 unique cows across 7 farms in Australia. The results demonstrate that our model achieves an overall determination coefficient of 83% in predicting herd life across the studied farms, highlighting its potential for practical application in dairy herd management.", "AI": {"tldr": "\u5f00\u53d1\u57fa\u4e8e\u591a\u5934\u6ce8\u610f\u529bTransformer\u7684AI\u6a21\u578b\uff0c\u5229\u7528\u5976\u725b\u4ece\u51fa\u751f\u5f00\u59cb\u7684\u5386\u53f2\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u6765\u9884\u6d4b\u5976\u725b\u5bff\u547d\uff0c\u5728\u6fb3\u5927\u5229\u4e9a7\u4e2a\u519c\u573a\u768419,000\u5934\u5976\u725b\u6570\u636e\u4e0a\u8fbe\u523083%\u7684\u51b3\u5b9a\u7cfb\u6570\u3002", "motivation": "\u5976\u519c\u9700\u8981\u57fa\u4e8e\u5ba2\u89c2\u8bc4\u4f30\u6765\u51b3\u5b9a\u4fdd\u7559\u8fd8\u662f\u6dd8\u6c70\u5976\u725b\uff0c\u9700\u8981\u8bc6\u522b\u66f4\u5177\u97e7\u6027\u7684\u5976\u725b\u4ee5\u5e94\u5bf9\u519c\u573a\u6761\u4ef6\u5e76\u5b8c\u6210\u66f4\u591a\u6ccc\u4e73\u671f\uff0c\u8fd9\u4e00\u51b3\u7b56\u8fc7\u7a0b\u590d\u6742\u4e14\u5177\u6709\u663e\u8457\u7684\u73af\u5883\u548c\u7ecf\u6d4e\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u591a\u5934\u6ce8\u610f\u529bTransformer\u6280\u672f\u5206\u6790\u5386\u53f2\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u6570\u636e\u96c6\u5305\u542b\u6765\u81ea7\u4e2a\u6fb3\u5927\u5229\u4e9a\u519c\u573a\u768419,000\u5934\u5976\u725b\u7684\u7ea6780,000\u6761\u8bb0\u5f55\u3002", "result": "\u6a21\u578b\u5728\u9884\u6d4b\u725b\u7fa4\u5bff\u547d\u65b9\u9762\u8fbe\u523083%\u7684\u6574\u4f53\u51b3\u5b9a\u7cfb\u6570\uff0c\u663e\u793a\u51fa\u5728\u5b9e\u9645\u5976\u725b\u7fa4\u7ba1\u7406\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "AI\u9a71\u52a8\u7684\u6a21\u578b\u80fd\u591f\u6709\u6548\u9884\u6d4b\u5976\u725b\u5bff\u547d\uff0c\u4e3a\u5976\u519c\u63d0\u4f9b\u5ba2\u89c2\u51b3\u7b56\u652f\u6301\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u5976\u725b\u7fa4\u7ba1\u7406\u6548\u7387\u3002"}}
{"id": "2511.21092", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21092", "abs": "https://arxiv.org/abs/2511.21092", "authors": ["Seunghun Baek", "Jaejin Lee", "Jaeyoon Sim", "Minjae Jeong", "Won Hwa Kim"], "title": "MNM : Multi-level Neuroimaging Meta-analysis with Hyperbolic Brain-Text Representations", "comment": "MICCAI 2025 (Provisional Accept; top ~9%)", "summary": "Various neuroimaging studies suffer from small sample size problem which often limit their reliability. Meta-analysis addresses this challenge by aggregating findings from different studies to identify consistent patterns of brain activity. However, traditional approaches based on keyword retrieval or linear mappings often overlook the rich hierarchical structure in the brain. In this work, we propose a novel framework that leverages hyperbolic geometry to bridge the gap between neuroscience literature and brain activation maps. By embedding text from research articles and corresponding brain images into a shared hyperbolic space via the Lorentz model, our method captures both semantic similarity and hierarchical organization inherent in neuroimaging data. In the hyperbolic space, our method performs multi-level neuroimaging meta-analysis (MNM) by 1) aligning brain and text embeddings for semantic correspondence, 2) guiding hierarchy between text and brain activations, and 3) preserving the hierarchical relationships within brain activation patterns. Experimental results demonstrate that our model outperforms baselines, offering a robust and interpretable paradigm of multi-level neuroimaging meta-analysis via hyperbolic brain-text representation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u53cc\u66f2\u51e0\u4f55\u8fde\u63a5\u795e\u7ecf\u79d1\u5b66\u6587\u732e\u548c\u8111\u6fc0\u6d3b\u56fe\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u7814\u7a76\u8bba\u6587\u6587\u672c\u548c\u8111\u56fe\u50cf\u5d4c\u5165\u5230\u5171\u4eab\u7684\u53cc\u66f2\u7a7a\u95f4\u4e2d\uff0c\u6355\u6349\u795e\u7ecf\u5f71\u50cf\u6570\u636e\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u548c\u5c42\u6b21\u7ed3\u6784\u3002", "motivation": "\u89e3\u51b3\u795e\u7ecf\u5f71\u50cf\u7814\u7a76\u4e2d\u6837\u672c\u91cf\u5c0f\u7684\u95ee\u9898\uff0c\u4f20\u7edf\u57fa\u4e8e\u5173\u952e\u8bcd\u68c0\u7d22\u6216\u7ebf\u6027\u6620\u5c04\u7684\u65b9\u6cd5\u5ffd\u7565\u4e86\u5927\u8111\u7684\u4e30\u5bcc\u5c42\u6b21\u7ed3\u6784\u3002", "method": "\u4f7f\u7528Lorentz\u6a21\u578b\u5c06\u7814\u7a76\u8bba\u6587\u6587\u672c\u548c\u5bf9\u5e94\u8111\u56fe\u50cf\u5d4c\u5165\u5230\u5171\u4eab\u53cc\u66f2\u7a7a\u95f4\uff0c\u6267\u884c\u591a\u7ea7\u795e\u7ecf\u5f71\u50cf\u5143\u5206\u6790\uff1a1) \u5bf9\u9f50\u8111\u548c\u6587\u672c\u5d4c\u5165\u4ee5\u83b7\u5f97\u8bed\u4e49\u5bf9\u5e94\uff1b2) \u5f15\u5bfc\u6587\u672c\u548c\u8111\u6fc0\u6d3b\u4e4b\u95f4\u7684\u5c42\u6b21\u5173\u7cfb\uff1b3) \u4fdd\u6301\u8111\u6fc0\u6d3b\u6a21\u5f0f\u4e2d\u7684\u5c42\u6b21\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9c81\u68d2\u4e14\u53ef\u89e3\u91ca\u7684\u591a\u7ea7\u795e\u7ecf\u5f71\u50cf\u5143\u5206\u6790\u8303\u5f0f\u3002", "conclusion": "\u901a\u8fc7\u53cc\u66f2\u8111-\u6587\u672c\u8868\u793a\uff0c\u8be5\u65b9\u6cd5\u4e3a\u795e\u7ecf\u5f71\u50cf\u5143\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u65b0\u6846\u67b6\uff0c\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u5927\u8111\u6d3b\u52a8\u7684\u8bed\u4e49\u548c\u5c42\u6b21\u7279\u5f81\u3002"}}
{"id": "2511.21109", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21109", "abs": "https://arxiv.org/abs/2511.21109", "authors": ["Mudi Jiang", "Jiahui Zhou", "Xinying Liu", "Zengyou He", "Zhikui Chen"], "title": "Interpretable Fair Clustering", "comment": null, "summary": "Fair clustering has gained increasing attention in recent years, especially in applications involving socially sensitive attributes. However, existing fair clustering methods often lack interpretability, limiting their applicability in high-stakes scenarios where understanding the rationale behind clustering decisions is essential. In this work, we address this limitation by proposing an interpretable and fair clustering framework, which integrates fairness constraints into the structure of decision trees. Our approach constructs interpretable decision trees that partition the data while ensuring fair treatment across protected groups. To further enhance the practicality of our framework, we also introduce a variant that requires no fairness hyperparameter tuning, achieved through post-pruning a tree constructed without fairness constraints. Extensive experiments on both real-world and synthetic datasets demonstrate that our method not only delivers competitive clustering performance and improved fairness, but also offers additional advantages such as interpretability and the ability to handle multiple sensitive attributes. These strengths enable our method to perform robustly under complex fairness constraints, opening new possibilities for equitable and transparent clustering.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u516c\u5e73\u805a\u7c7b\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u516c\u5e73\u7ea6\u675f\u96c6\u6210\u5230\u51b3\u7b56\u6811\u7ed3\u6784\u4e2d\uff0c\u5728\u4fdd\u8bc1\u805a\u7c7b\u6027\u80fd\u7684\u540c\u65f6\u63d0\u9ad8\u516c\u5e73\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u516c\u5e73\u805a\u7c7b\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u9650\u5236\u4e86\u5728\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u4fdd\u8bc1\u516c\u5e73\u6027\u53c8\u5177\u6709\u53ef\u89e3\u91ca\u6027\u7684\u805a\u7c7b\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u6811\u6765\u5212\u5206\u6570\u636e\uff0c\u540c\u65f6\u786e\u4fdd\u53d7\u4fdd\u62a4\u7fa4\u4f53\u95f4\u7684\u516c\u5e73\u5bf9\u5f85\u3002\u8fd8\u63d0\u51fa\u4e86\u65e0\u9700\u516c\u5e73\u8d85\u53c2\u6570\u8c03\u4f18\u7684\u53d8\u4f53\uff0c\u901a\u8fc7\u5bf9\u65e0\u516c\u5e73\u7ea6\u675f\u6784\u5efa\u7684\u6811\u8fdb\u884c\u540e\u526a\u679d\u5b9e\u73b0\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u4f9b\u6709\u7ade\u4e89\u529b\u7684\u805a\u7c7b\u6027\u80fd\u548c\u6539\u5584\u7684\u516c\u5e73\u6027\uff0c\u8fd8\u5177\u6709\u53ef\u89e3\u91ca\u6027\u3001\u5904\u7406\u591a\u4e2a\u654f\u611f\u5c5e\u6027\u7684\u80fd\u529b\u7b49\u4f18\u52bf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u590d\u6742\u516c\u5e73\u7ea6\u675f\u4e0b\u7a33\u5065\u8fd0\u884c\uff0c\u4e3a\u516c\u5e73\u900f\u660e\u7684\u805a\u7c7b\u5f00\u8f9f\u4e86\u65b0\u53ef\u80fd\u6027\u3002"}}
{"id": "2511.21118", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21118", "abs": "https://arxiv.org/abs/2511.21118", "authors": ["Pius Onobhayedo", "Paul Osemudiame Oamen"], "title": "Trustless Federated Learning at Edge-Scale: A Compositional Architecture for Decentralized, Verifiable, and Incentive-Aligned Coordination", "comment": null, "summary": "Artificial intelligence is retracing the Internet's path from centralized provision to distributed creation. Initially, resource-intensive computation concentrates within institutions capable of training and serving large models.Eventually, as federated learning matures, billions of edge devices holding sensitive data will be able to collectively improve models without surrendering raw information, enabling both contribution and consumption at scale. This democratic vision remains unrealized due to certain compositional gaps; aggregators handle updates without accountability, economic mechanisms are lacking and even when present remain vulnerable to gaming, coordination serializes state modifications limiting scalability, and governance permits retroactive manipulation. This work addresses these gaps by leveraging cryptographic receipts to prove aggregation correctness, geometric novelty measurement to prevent incentive gaming, parallel object ownership to achieve linear scalability, and time-locked policies to check retroactive manipulation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u4e2d\u7ec4\u6210\u6027\u5dee\u8ddd\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bc6\u7801\u5b66\u6536\u636e\u8bc1\u660e\u805a\u5408\u6b63\u786e\u6027\u3001\u51e0\u4f55\u65b0\u9896\u6027\u6d4b\u91cf\u9632\u6b62\u6fc0\u52b1\u535a\u5f08\u3001\u5e76\u884c\u5bf9\u8c61\u6240\u6709\u6743\u5b9e\u73b0\u7ebf\u6027\u53ef\u6269\u5c55\u6027\u4ee5\u53ca\u65f6\u95f4\u9501\u5b9a\u7b56\u7565\u68c0\u67e5\u8ffd\u6eaf\u6027\u64cd\u7eb5\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u6b63\u4ece\u96c6\u4e2d\u5f0f\u63d0\u4f9b\u8f6c\u5411\u5206\u5e03\u5f0f\u521b\u5efa\uff0c\u4f46\u6c11\u4e3b\u5316\u613f\u666f\u56e0\u7ec4\u6210\u6027\u5dee\u8ddd\u800c\u672a\u80fd\u5b9e\u73b0\uff0c\u5305\u62ec\u805a\u5408\u5668\u7f3a\u4e4f\u95ee\u8d23\u5236\u3001\u7ecf\u6d4e\u673a\u5236\u7f3a\u5931\u4e14\u6613\u88ab\u535a\u5f08\u3001\u534f\u8c03\u4e32\u884c\u5316\u72b6\u6001\u4fee\u6539\u9650\u5236\u53ef\u6269\u5c55\u6027\u4ee5\u53ca\u6cbb\u7406\u5141\u8bb8\u8ffd\u6eaf\u6027\u64cd\u7eb5\u3002", "method": "\u5229\u7528\u5bc6\u7801\u5b66\u6536\u636e\u8bc1\u660e\u805a\u5408\u6b63\u786e\u6027\uff0c\u51e0\u4f55\u65b0\u9896\u6027\u6d4b\u91cf\u9632\u6b62\u6fc0\u52b1\u535a\u5f08\uff0c\u5e76\u884c\u5bf9\u8c61\u6240\u6709\u6743\u5b9e\u73b0\u7ebf\u6027\u53ef\u6269\u5c55\u6027\uff0c\u65f6\u95f4\u9501\u5b9a\u7b56\u7565\u68c0\u67e5\u8ffd\u6eaf\u6027\u64cd\u7eb5\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u7ec4\u6210\u6027\u5dee\u8ddd\uff0c\u4e3a\u5927\u89c4\u6a21\u5206\u5e03\u5f0fAI\u521b\u5efa\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u65b9\u6848\u3002", "conclusion": "\u901a\u8fc7\u5bc6\u7801\u5b66\u3001\u51e0\u4f55\u6d4b\u91cf\u3001\u5e76\u884c\u6240\u6709\u6743\u548c\u65f6\u95f4\u9501\u5b9a\u7b56\u7565\u7684\u7efc\u5408\u5e94\u7528\uff0c\u5b9e\u73b0\u4e86\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u7684\u53ef\u95ee\u8d23\u6027\u3001\u6297\u535a\u5f08\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u9632\u8ffd\u6eaf\u64cd\u7eb5\u80fd\u529b\uff0c\u63a8\u52a8\u4e86\u5206\u5e03\u5f0fAI\u7684\u6c11\u4e3b\u5316\u613f\u666f\u3002"}}
{"id": "2511.21363", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21363", "abs": "https://arxiv.org/abs/2511.21363", "authors": ["Kevin Iselborn", "David Dembinsky", "Adriano Lucieri", "Andreas Dengel"], "title": "The Directed Prediction Change - Efficient and Trustworthy Fidelity Assessment for Local Feature Attribution Methods", "comment": "13 pages, 10 figures, 5 tables, accepted at AAAI SECURE-AI4H workshop", "summary": "The utility of an explanation method critically depends on its fidelity to the underlying machine learning model. Especially in high-stakes medical settings, clinicians and regulators require explanations that faithfully reflect the model's decision process. Existing fidelity metrics such as Infidelity rely on Monte Carlo approximation, which demands numerous model evaluations and introduces uncertainty due to random sampling. This work proposes a novel metric for evaluating the fidelity of local feature attribution methods by modifying the existing Prediction Change (PC) metric within the Guided Perturbation Experiment. By incorporating the direction of both perturbation and attribution, the proposed Directed Prediction Change (DPC) metric achieves an almost tenfold speedup and eliminates randomness, resulting in a deterministic and trustworthy evaluation procedure that measures the same property as local Infidelity. DPC is evaluated on two datasets (skin lesion images and financial tabular data), two black-box models, seven explanation algorithms, and a wide range of hyperparameters. Across $4\\,744$ distinct explanations, the results demonstrate that DPC, together with PC, enables a holistic and computationally efficient evaluation of both baseline-oriented and local feature attribution methods, while providing deterministic and reproducible outcomes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5c40\u90e8\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\u4fdd\u771f\u5ea6\u8bc4\u4f30\u6307\u6807DPC\uff0c\u901a\u8fc7\u7ed3\u5408\u6270\u52a8\u548c\u5f52\u56e0\u7684\u65b9\u5411\uff0c\u5b9e\u73b0\u4e86\u8fd110\u500d\u7684\u901f\u5ea6\u63d0\u5347\u5e76\u6d88\u9664\u4e86\u968f\u673a\u6027\uff0c\u4e3a\u533b\u7597\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u63d0\u4f9b\u786e\u5b9a\u6027\u3001\u53ef\u4fe1\u8d56\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u5728\u533b\u7597\u7b49\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\uff0c\u89e3\u91ca\u65b9\u6cd5\u7684\u4fdd\u771f\u5ea6\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u4fdd\u771f\u5ea6\u6307\u6807\u5982Infidelity\u4f9d\u8d56\u8499\u7279\u5361\u6d1b\u8fd1\u4f3c\uff0c\u9700\u8981\u5927\u91cf\u6a21\u578b\u8bc4\u4f30\u5e76\u5f15\u5165\u968f\u673a\u91c7\u6837\u4e0d\u786e\u5b9a\u6027\uff0c\u65e0\u6cd5\u6ee1\u8db3\u4e34\u5e8a\u548c\u76d1\u7ba1\u9700\u6c42\u3002", "method": "\u5728\u5f15\u5bfc\u6270\u52a8\u5b9e\u9a8c\u4e2d\u4fee\u6539\u73b0\u6709\u7684\u9884\u6d4b\u53d8\u5316(PC)\u6307\u6807\uff0c\u901a\u8fc7\u7ed3\u5408\u6270\u52a8\u548c\u5f52\u56e0\u7684\u65b9\u5411\uff0c\u63d0\u51fa\u5b9a\u5411\u9884\u6d4b\u53d8\u5316(DPC)\u6307\u6807\uff0c\u5b9e\u73b0\u786e\u5b9a\u6027\u8bc4\u4f30\u3002", "result": "\u5728\u76ae\u80a4\u75c5\u53d8\u56fe\u50cf\u548c\u91d1\u878d\u8868\u683c\u6570\u636e\u4e24\u4e2a\u6570\u636e\u96c6\u3001\u4e24\u4e2a\u9ed1\u76d2\u6a21\u578b\u3001\u4e03\u79cd\u89e3\u91ca\u7b97\u6cd5\u548c\u5e7f\u6cdb\u8d85\u53c2\u6570\u8303\u56f4\u5185\uff0c\u5bf94744\u4e2a\u4e0d\u540c\u89e3\u91ca\u8fdb\u884c\u8bc4\u4f30\uff0cDPC\u4e0ePC\u5171\u540c\u5b9e\u73b0\u4e86\u5bf9\u57fa\u7ebf\u5bfc\u5411\u548c\u5c40\u90e8\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\u7684\u5168\u9762\u9ad8\u6548\u8bc4\u4f30\u3002", "conclusion": "DPC\u6307\u6807\u63d0\u4f9b\u4e86\u786e\u5b9a\u6027\u3001\u53ef\u91cd\u590d\u7684\u7ed3\u679c\uff0c\u5b9e\u73b0\u4e86\u8fd110\u500d\u901f\u5ea6\u63d0\u5347\u5e76\u6d88\u9664\u4e86\u968f\u673a\u6027\uff0c\u80fd\u591f\u53ef\u9760\u8bc4\u4f30\u89e3\u91ca\u65b9\u6cd5\u7684\u4fdd\u771f\u5ea6\uff0c\u7279\u522b\u9002\u7528\u4e8e\u533b\u7597\u7b49\u9ad8\u98ce\u9669\u573a\u666f\u3002"}}
{"id": "2511.21354", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21354", "abs": "https://arxiv.org/abs/2511.21354", "authors": ["Umberto Michelucci", "Francesca Venturini"], "title": "Best Practices for Machine Learning Experimentation in Scientific Applications", "comment": null, "summary": "Machine learning (ML) is increasingly adopted in scientific research, yet the quality and reliability of results often depend on how experiments are designed and documented. Poor baselines, inconsistent preprocessing, or insufficient validation can lead to misleading conclusions about model performance. This paper presents a practical and structured guide for conducting ML experiments in scientific applications, focussing on reproducibility, fair comparison, and transparent reporting. We outline a step-by-step workflow, from dataset preparation to model selection and evaluation, and propose metrics that account for overfitting and instability across validation folds, including the Logarithmic Overfitting Ratio (LOR) and the Composite Overfitting Score (COS). Through recommended practices and example reporting formats, this work aims to support researchers in establishing robust baselines and drawing valid evidence-based insights from ML models applied to scientific problems.", "AI": {"tldr": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u7ed3\u6784\u5316\u6307\u5357\uff0c\u7528\u4e8e\u5728\u79d1\u5b66\u5e94\u7528\u4e2d\u8fdb\u884c\u673a\u5668\u5b66\u4e60\u5b9e\u9a8c\uff0c\u91cd\u70b9\u5173\u6ce8\u53ef\u91cd\u73b0\u6027\u3001\u516c\u5e73\u6bd4\u8f83\u548c\u900f\u660e\u62a5\u544a\u3002\u63d0\u51fa\u4e86\u5305\u542b\u5bf9\u6570\u8fc7\u62df\u5408\u6bd4\u7387\u548c\u590d\u5408\u8fc7\u62df\u5408\u5206\u6570\u7684\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u4f46\u5b9e\u9a8c\u8bbe\u8ba1\u548c\u6587\u6863\u8bb0\u5f55\u7684\u8d28\u91cf\u4f1a\u5f71\u54cd\u7ed3\u679c\u7684\u53ef\u9760\u6027\u3002\u7cdf\u7cd5\u7684\u57fa\u7ebf\u3001\u4e0d\u4e00\u81f4\u7684\u9884\u5904\u7406\u6216\u9a8c\u8bc1\u4e0d\u8db3\u53ef\u80fd\u5bfc\u81f4\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u8bef\u5bfc\u6027\u7ed3\u8bba\u3002", "method": "\u63d0\u51fa\u9010\u6b65\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4ece\u6570\u636e\u96c6\u51c6\u5907\u5230\u6a21\u578b\u9009\u62e9\u548c\u8bc4\u4f30\u3002\u5f15\u5165\u8003\u8651\u8fc7\u62df\u5408\u548c\u9a8c\u8bc1\u6298\u53e0\u4e0d\u7a33\u5b9a\u6027\u7684\u6307\u6807\uff0c\u5305\u62ec\u5bf9\u6570\u8fc7\u62df\u5408\u6bd4\u7387\u548c\u590d\u5408\u8fc7\u62df\u5408\u5206\u6570\u3002", "result": "\u901a\u8fc7\u63a8\u8350\u5b9e\u8df5\u548c\u793a\u4f8b\u62a5\u544a\u683c\u5f0f\uff0c\u652f\u6301\u7814\u7a76\u4eba\u5458\u5efa\u7acb\u7a33\u5065\u7684\u57fa\u7ebf\uff0c\u5e76\u4ece\u5e94\u7528\u4e8e\u79d1\u5b66\u95ee\u9898\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u5f97\u51fa\u6709\u6548\u7684\u57fa\u4e8e\u8bc1\u636e\u7684\u89c1\u89e3\u3002", "conclusion": "\u672c\u6587\u65e8\u5728\u63d0\u9ad8\u79d1\u5b66\u673a\u5668\u5b66\u4e60\u5b9e\u9a8c\u7684\u8d28\u91cf\u548c\u53ef\u9760\u6027\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u65b9\u6cd5\u548c\u8bc4\u4f30\u6307\u6807\u4fc3\u8fdb\u53ef\u91cd\u73b0\u548c\u516c\u5e73\u7684\u6bd4\u8f83\u3002"}}
{"id": "2511.21378", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21378", "abs": "https://arxiv.org/abs/2511.21378", "authors": ["Jungi Lee", "Jungkwon Kim", "Chi Zhang", "Kwangsun Yoo", "Seok-Joo Byun"], "title": "Anomaly Detection with Adaptive and Aggressive Rejection for Contaminated Training Data", "comment": null, "summary": "Handling contaminated data poses a critical challenge in anomaly detection, as traditional models assume training on purely normal data. Conventional methods mitigate contamination by relying on fixed contamination ratios, but discrepancies between assumed and actual ratios can severely degrade performance, especially in noisy environments where normal and abnormal data distributions overlap. To address these limitations, we propose Adaptive and Aggressive Rejection (AAR), a novel method that dynamically excludes anomalies using a modified z-score and Gaussian mixture model-based thresholds. AAR effectively balances the trade-off between preserving normal data and excluding anomalies by integrating hard and soft rejection strategies. Extensive experiments on two image datasets and thirty tabular datasets demonstrate that AAR outperforms the state-of-the-art method by 0.041 AUROC. By providing a scalable and reliable solution, AAR enhances robustness against contaminated datasets, paving the way for broader real-world applications in domains such as security and healthcare.", "AI": {"tldr": "\u63d0\u51faAAR\u65b9\u6cd5\u89e3\u51b3\u5f02\u5e38\u68c0\u6d4b\u4e2d\u6570\u636e\u6c61\u67d3\u95ee\u9898\uff0c\u901a\u8fc7\u52a8\u6001\u6392\u9664\u5f02\u5e38\u6570\u636e\uff0c\u5728\u56fe\u50cf\u548c\u8868\u683c\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u4f20\u7edf\u5f02\u5e38\u68c0\u6d4b\u6a21\u578b\u5047\u8bbe\u8bad\u7ec3\u6570\u636e\u7eaf\u51c0\uff0c\u4f46\u5b9e\u9645\u6570\u636e\u5e38\u88ab\u6c61\u67d3\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u6c61\u67d3\u6bd4\u4f8b\u5047\u8bbe\uff0c\u5f53\u5047\u8bbe\u4e0e\u5b9e\u9645\u4e0d\u7b26\u65f6\u6027\u80fd\u4e25\u91cd\u4e0b\u964d\uff0c\u7279\u522b\u662f\u5728\u6b63\u5e38\u4e0e\u5f02\u5e38\u6570\u636e\u5206\u5e03\u91cd\u53e0\u7684\u566a\u58f0\u73af\u5883\u4e2d", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u548c\u4e3b\u52a8\u62d2\u7edd\u65b9\u6cd5(AAR)\uff0c\u4f7f\u7528\u6539\u8fdb\u7684z-score\u548c\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u9608\u503c\u52a8\u6001\u6392\u9664\u5f02\u5e38\uff0c\u7ed3\u5408\u786c\u62d2\u7edd\u548c\u8f6f\u62d2\u7edd\u7b56\u7565\u5e73\u8861\u4fdd\u7559\u6b63\u5e38\u6570\u636e\u548c\u6392\u9664\u5f02\u5e38\u6570\u636e", "result": "\u5728\u4e24\u4e2a\u56fe\u50cf\u6570\u636e\u96c6\u548c\u4e09\u5341\u4e2a\u8868\u683c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAAR\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u63d0\u9ad8\u4e860.041 AUROC", "conclusion": "AAR\u4e3a\u6c61\u67d3\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u589e\u5f3a\u4e86\u9c81\u68d2\u6027\uff0c\u4e3a\u5b89\u5168\u548c\u533b\u7597\u7b49\u9886\u57df\u7684\u5b9e\u9645\u5e94\u7528\u94fa\u5e73\u4e86\u9053\u8def"}}
{"id": "2511.21514", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21514", "abs": "https://arxiv.org/abs/2511.21514", "authors": ["Mat\u012bss Kaln\u0101re", "Sofoklis Kitharidis", "Thomas B\u00e4ck", "Niki van Stein"], "title": "Mechanistic Interpretability for Transformer-based Time Series Classification", "comment": null, "summary": "Transformer-based models have become state-of-the-art tools in various machine learning tasks, including time series classification, yet their complexity makes understanding their internal decision-making challenging. Existing explainability methods often focus on input-output attributions, leaving the internal mechanisms largely opaque. This paper addresses this gap by adapting various Mechanistic Interpretability techniques; activation patching, attention saliency, and sparse autoencoders, from NLP to transformer architectures designed explicitly for time series classification. We systematically probe the internal causal roles of individual attention heads and timesteps, revealing causal structures within these models. Through experimentation on a benchmark time series dataset, we construct causal graphs illustrating how information propagates internally, highlighting key attention heads and temporal positions driving correct classifications. Additionally, we demonstrate the potential of sparse autoencoders for uncovering interpretable latent features. Our findings provide both methodological contributions to transformer interpretability and novel insights into the functional mechanics underlying transformer performance in time series classification tasks.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5c06\u673a\u5236\u53ef\u89e3\u91ca\u6027\u6280\u672f\u4eceNLP\u9886\u57df\u8fc1\u79fb\u5230\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u7684Transformer\u67b6\u6784\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5185\u90e8\u6ce8\u610f\u529b\u5934\u548c\u65f6\u95f4\u6b65\u7684\u56e0\u679c\u7ed3\u6784\uff0c\u6784\u5efa\u4e86\u4fe1\u606f\u4f20\u64ad\u7684\u56e0\u679c\u56fe\u3002", "motivation": "Transformer\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5185\u90e8\u51b3\u7b56\u673a\u5236\u96be\u4ee5\u7406\u89e3\u3002\u73b0\u6709\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u8f93\u5165\u8f93\u51fa\u5f52\u56e0\uff0c\u5bf9\u5185\u90e8\u673a\u5236\u63ed\u793a\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u6df1\u5165\u7684\u673a\u5236\u53ef\u89e3\u91ca\u6027\u5206\u6790\u3002", "method": "\u91c7\u7528\u673a\u5236\u53ef\u89e3\u91ca\u6027\u6280\u672f\uff1a\u6fc0\u6d3b\u4fee\u8865\u3001\u6ce8\u610f\u529b\u663e\u8457\u6027\u5206\u6790\u548c\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff0c\u7cfb\u7edf\u63a2\u6d4b\u6ce8\u610f\u529b\u5934\u548c\u65f6\u95f4\u6b65\u7684\u5185\u90e8\u56e0\u679c\u4f5c\u7528\uff0c\u6784\u5efa\u56e0\u679c\u56fe\u5c55\u793a\u4fe1\u606f\u4f20\u64ad\u8def\u5f84\u3002", "result": "\u5728\u57fa\u51c6\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u8bc6\u522b\u51fa\u9a71\u52a8\u6b63\u786e\u5206\u7c7b\u7684\u5173\u952e\u6ce8\u610f\u529b\u5934\u548c\u65f6\u95f4\u4f4d\u7f6e\uff0c\u5c55\u793a\u4e86\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5728\u53d1\u73b0\u53ef\u89e3\u91ca\u6f5c\u5728\u7279\u5f81\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u7814\u7a76\u4e3aTransformer\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u8d21\u732e\uff0c\u5e76\u63ed\u793a\u4e86\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\u4e2dTransformer\u529f\u80fd\u673a\u5236\u7684\u65b0\u89c1\u89e3\u3002"}}
{"id": "2511.21513", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21513", "abs": "https://arxiv.org/abs/2511.21513", "authors": ["Wanli Zhong", "Haibo Feng", "Zirui Zhou", "Hanyang Peng", "Shiqi Yu"], "title": "IntAttention: A Fully Integer Attention Pipeline for Efficient Edge Inference", "comment": null, "summary": "Deploying Transformer models on edge devices is limited by latency and energy budgets. While INT8 quantization effectively accelerates the primary matrix multiplications, it exposes the softmax as the dominant bottleneck. This stage incurs a costly dequantize-softmax-requantize detour, which can account for up to 65% of total attention latency and disrupts the end-to-end integer dataflow critical for edge hardware efficiency. To address this limitation, we present IntAttention, the first fully integer, plug-and-play attention pipeline without retraining. At the core of our approach lies IndexSoftmax, a hardware-friendly operator that replaces floating-point exponentials entirely within the integer domain. IntAttention integrates sparsity-aware clipping, a 32-entry lookup-table approximation, and direct integer normalization, thereby eliminating all datatype conversion overhead. We evaluate IntAttention and demonstrate consistent and substantial gains. Our method achieves up to 3.7x speedup and 61% energy reduction over FP16 baselines and 2.0x faster than conventional INT8 attention pipelines on Armv8 CPUs. These gains are achieved with high-fidelity accuracy comparable to baselines across diverse language and vision models, enabling practical and efficient Transformer inference on commodity edge devices. Code will be released in later version of this work.", "AI": {"tldr": "IntAttention\u662f\u4e00\u79cd\u5b8c\u5168\u6574\u6570\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7IndexSoftmax\u66ff\u4ee3\u6d6e\u70b9\u6307\u6570\u8fd0\u7b97\uff0c\u6d88\u9664\u91cf\u5316-\u53cd\u91cf\u5316\u5f00\u9500\uff0c\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u9ad8\u6548Transformer\u63a8\u7406\u3002", "motivation": "\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72Transformer\u6a21\u578b\u53d7\u9650\u4e8e\u5ef6\u8fdf\u548c\u80fd\u8017\uff0cINT8\u91cf\u5316\u867d\u7136\u52a0\u901f\u4e86\u77e9\u9635\u4e58\u6cd5\uff0c\u4f46softmax\u6210\u4e3a\u4e3b\u8981\u74f6\u9888\uff0c\u5360\u6ce8\u610f\u529b\u5ef6\u8fdf\u768465%\uff0c\u7834\u574f\u4e86\u7aef\u5230\u7aef\u6574\u6570\u6570\u636e\u6d41\u3002", "method": "\u63d0\u51faIntAttention\u5168\u6574\u6570\u6ce8\u610f\u529b\u6d41\u6c34\u7ebf\uff0c\u6838\u5fc3\u662fIndexSoftmax\u786c\u4ef6\u53cb\u597d\u7b97\u5b50\uff0c\u96c6\u6210\u7a00\u758f\u611f\u77e5\u88c1\u526a\u300132\u9879\u67e5\u627e\u8868\u8fd1\u4f3c\u548c\u76f4\u63a5\u6574\u6570\u5f52\u4e00\u5316\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002", "result": "\u5728Armv8 CPU\u4e0a\u5b9e\u73b03.7\u500d\u52a0\u901f\u548c61%\u80fd\u8017\u964d\u4f4e\uff0c\u6bd4\u4f20\u7edfINT8\u6ce8\u610f\u529b\u5feb2.0\u500d\uff0c\u5728\u5404\u79cd\u8bed\u8a00\u548c\u89c6\u89c9\u6a21\u578b\u4e2d\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u3002", "conclusion": "IntAttention\u4e3a\u8fb9\u7f18\u8bbe\u5907\u63d0\u4f9b\u4e86\u5b9e\u7528\u9ad8\u6548\u7684Transformer\u63a8\u7406\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2511.21560", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21560", "abs": "https://arxiv.org/abs/2511.21560", "authors": ["Jack Geary", "Boyan Gao", "Henry Gouk"], "title": "Computing Strategic Responses to Non-Linear Classifiers", "comment": null, "summary": "We consider the problem of strategic classification, where the act of deploying a classifier leads to strategic behaviour that induces a distribution shift on subsequent observations. Current approaches to learning classifiers in strategic settings are focused primarily on the linear setting, but in many cases non-linear classifiers are more suitable. A central limitation to progress for non-linear classifiers arises from the inability to compute best responses in these settings. We present a novel method for computing the best response by optimising the Lagrangian dual of the Agents' objective. We demonstrate that our method reproduces best responses in linear settings, identifying key weaknesses in existing approaches. We present further results demonstrating our method can be straight-forwardly applied to non-linear classifier settings, where it is useful for both evaluation and training.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba1\u7b97\u6218\u7565\u5206\u7c7b\u4e2d\u667a\u80fd\u4f53\u6700\u4f73\u54cd\u5e94\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u667a\u80fd\u4f53\u76ee\u6807\u7684\u62c9\u683c\u6717\u65e5\u5bf9\u5076\u6765\u89e3\u51b3\u975e\u7ebf\u6027\u5206\u7c7b\u5668\u8bbe\u7f6e\u4e2d\u7684\u5173\u952e\u9650\u5236\u3002", "motivation": "\u6218\u7565\u5206\u7c7b\u4e2d\u90e8\u7f72\u5206\u7c7b\u5668\u4f1a\u5bfc\u81f4\u6218\u7565\u884c\u4e3a\u5f15\u53d1\u5206\u5e03\u6f02\u79fb\uff0c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u7ebf\u6027\u8bbe\u7f6e\uff0c\u4f46\u8bb8\u591a\u60c5\u51b5\u4e0b\u975e\u7ebf\u6027\u5206\u7c7b\u5668\u66f4\u5408\u9002\uff0c\u800c\u8ba1\u7b97\u975e\u7ebf\u6027\u8bbe\u7f6e\u4e2d\u7684\u6700\u4f73\u54cd\u5e94\u5b58\u5728\u56f0\u96be\u3002", "method": "\u901a\u8fc7\u4f18\u5316\u667a\u80fd\u4f53\u76ee\u6807\u7684\u62c9\u683c\u6717\u65e5\u5bf9\u5076\u6765\u8ba1\u7b97\u6700\u4f73\u54cd\u5e94\uff0c\u8be5\u65b9\u6cd5\u5728\u975e\u7ebf\u6027\u5206\u7c7b\u5668\u8bbe\u7f6e\u4e2d\u53ef\u76f4\u63a5\u5e94\u7528\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u7ebf\u6027\u8bbe\u7f6e\u4e2d\u91cd\u73b0\u4e86\u6700\u4f73\u54cd\u5e94\uff0c\u8bc6\u522b\u51fa\u73b0\u6709\u65b9\u6cd5\u7684\u5173\u952e\u5f31\u70b9\uff0c\u5e76\u5728\u975e\u7ebf\u6027\u5206\u7c7b\u5668\u8bbe\u7f6e\u4e2d\u53ef\u7528\u4e8e\u8bc4\u4f30\u548c\u8bad\u7ec3\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u89e3\u51b3\u4e86\u6218\u7565\u5206\u7c7b\u4e2d\u975e\u7ebf\u6027\u5206\u7c7b\u5668\u6700\u4f73\u54cd\u5e94\u8ba1\u7b97\u7684\u9650\u5236\uff0c\u4e3a\u975e\u7ebf\u6027\u8bbe\u7f6e\u4e0b\u7684\u5206\u7c7b\u5668\u5b66\u4e60\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2511.21566", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21566", "abs": "https://arxiv.org/abs/2511.21566", "authors": ["Ali Amirahmadi", "G\u00f6k\u00e7e Geylan", "Leonardo De Maria", "Farzaneh Etminani", "Mattias Ohlsson", "Alessandro Tibo"], "title": "A decoupled alignment kernel for peptide membrane permeability predictions", "comment": "submitted to Journal of Cheminformatics", "summary": "Cyclic peptides are promising modalities for targeting intracellular sites; however, cell-membrane permeability remains a key bottleneck, exacerbated by limited public data and the need for well-calibrated uncertainty. Instead of relying on data-eager complex deep learning architecture, we propose a monomer-aware decoupled global alignment kernel (MD-GAK), which couples chemically meaningful residue-residue similarity with sequence alignment while decoupling local matches from gap penalties. MD-GAK is a relatively simple kernel. To further demonstrate the robustness of our framework, we also introduce a variant, PMD-GAK, which incorporates a triangular positional prior. As we will show in the experimental section, PMD-GAK can offer additional advantages over MD-GAK, particularly in reducing calibration errors. Since our focus is on uncertainty estimation, we use Gaussian Processes as the predictive model, as both MD-GAK and PMD-GAK can be directly applied within this framework. We demonstrate the effectiveness of our methods through an extensive set of experiments, comparing our fully reproducible approach against state-of-the-art models, and show that it outperforms them across all metrics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5355\u4f53\u611f\u77e5\u89e3\u8026\u5168\u5c40\u5bf9\u9f50\u6838\uff08MD-GAK\uff09\u53ca\u5176\u53d8\u4f53PMD-GAK\uff0c\u7528\u4e8e\u9884\u6d4b\u73af\u80bd\u7684\u7ec6\u80de\u819c\u6e17\u900f\u6027\uff0c\u91cd\u70b9\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u548c\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u95ee\u9898\u3002", "motivation": "\u73af\u80bd\u662f\u9776\u5411\u7ec6\u80de\u5185\u4f4d\u70b9\u7684\u6709\u524d\u666f\u6a21\u5f0f\uff0c\u4f46\u7ec6\u80de\u819c\u6e17\u900f\u6027\u4ecd\u662f\u5173\u952e\u74f6\u9888\uff0c\u4e14\u9762\u4e34\u516c\u5171\u6570\u636e\u6709\u9650\u548c\u9700\u8981\u826f\u597d\u6821\u51c6\u4e0d\u786e\u5b9a\u6027\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faMD-GAK\u6838\u65b9\u6cd5\uff0c\u5c06\u5316\u5b66\u6709\u610f\u4e49\u7684\u6b8b\u57fa-\u6b8b\u57fa\u76f8\u4f3c\u6027\u4e0e\u5e8f\u5217\u5bf9\u9f50\u8026\u5408\uff0c\u540c\u65f6\u5c06\u5c40\u90e8\u5339\u914d\u4e0e\u95f4\u9699\u60e9\u7f5a\u89e3\u8026\uff1b\u8fd8\u5f15\u5165\u53d8\u4f53PMD-GAK\u52a0\u5165\u4e09\u89d2\u4f4d\u7f6e\u5148\u9a8c\uff1b\u4f7f\u7528\u9ad8\u65af\u8fc7\u7a0b\u4f5c\u4e3a\u9884\u6d4b\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u5728\u6240\u6709\u6307\u6807\u4e0a\u8868\u73b0\u66f4\u4f18\uff0cPMD-GAK\u5728\u51cf\u5c11\u6821\u51c6\u8bef\u5dee\u65b9\u9762\u5177\u6709\u989d\u5916\u4f18\u52bf\u3002", "conclusion": "MD-GAK\u548cPMD-GAK\u662f\u7b80\u5355\u6709\u6548\u7684\u6838\u65b9\u6cd5\uff0c\u5728\u73af\u80bd\u7ec6\u80de\u819c\u6e17\u900f\u6027\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u5728\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002"}}
