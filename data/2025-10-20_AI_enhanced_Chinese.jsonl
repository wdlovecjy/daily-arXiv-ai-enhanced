{"id": "2510.15096", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15096", "abs": "https://arxiv.org/abs/2510.15096", "authors": ["Alana Renda", "Jillian Ross", "Michael Cafarella", "Jacob Andreas"], "title": "OpenEstimate: Evaluating LLMs on Reasoning Under Uncertainty with Real-World Data", "comment": null, "summary": "Real-world settings where language models (LMs) are deployed -- in domains\nspanning healthcare, finance, and other forms of knowledge work -- require\nmodels to grapple with incomplete information and reason under uncertainty. Yet\nmost LM evaluations focus on problems with well-defined answers and success\ncriteria. This gap exists in part because natural problems involving\nuncertainty are difficult to construct: given that LMs have access to most of\nthe same knowledge as humans, it is non-trivial to design questions for which\nLMs will struggle to produce correct answers, but which humans can answer\nreliably. As a result, LM performance on reasoning under uncertainty remains\npoorly characterized. To address this gap, we introduce OpenEstimate, an\nextensible, multi-domain benchmark for evaluating LMs on numerical estimation\ntasks that require models to synthesize significant amounts of background\ninformation and express predictions as probabilistic priors. We assess these\npriors for accuracy and calibration, quantifying their usefulness relative to\nsamples from the true distribution of interest. Across six frontier LMs, we\nfind that LM-elicited priors are often inaccurate and overconfident.\nPerformance improves modestly depending on how uncertainty is elicited from the\nmodel, but is largely unaffected by changes in sampling strategy, reasoning\neffort, or prompt design. The OpenEstimate benchmark thus offers a challenging\nevaluation for frontier LMs and a platform for developing models that are\nbetter at probabilistic estimation and reasoning under uncertainty.", "AI": {"tldr": "OpenEstimate\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u8fdb\u884c\u6570\u503c\u4f30\u8ba1\u4efb\u52a1\u7684\u591a\u9886\u57df\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u524d\u6cbf\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u5148\u9a8c\u6982\u7387\u901a\u5e38\u4e0d\u51c6\u786e\u4e14\u8fc7\u4e8e\u81ea\u4fe1\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u8bed\u8a00\u6a21\u578b\u9700\u8981\u5728\u4fe1\u606f\u4e0d\u5b8c\u6574\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u63a8\u7406\uff0c\u4f46\u73b0\u6709\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u6709\u660e\u786e\u7b54\u6848\u7684\u95ee\u9898\uff0c\u7f3a\u4e4f\u5bf9\u4e0d\u786e\u5b9a\u6027\u63a8\u7406\u80fd\u529b\u7684\u8bc4\u4f30\u3002", "method": "\u5f15\u5165OpenEstimate\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u9700\u8981\u7efc\u5408\u5927\u91cf\u80cc\u666f\u4fe1\u606f\u5e76\u4ee5\u6982\u7387\u5148\u9a8c\u5f62\u5f0f\u8868\u8fbe\u9884\u6d4b\u7684\u6570\u503c\u4f30\u8ba1\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u8bc4\u4f30\u5176\u51c6\u786e\u6027\u548c\u6821\u51c6\u5ea6\u3002", "result": "\u5728\u516d\u4e2a\u524d\u6cbf\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u6d4b\u8bd5\u663e\u793a\uff0c\u6a21\u578b\u751f\u6210\u7684\u5148\u9a8c\u6982\u7387\u901a\u5e38\u4e0d\u51c6\u786e\u4e14\u8fc7\u4e8e\u81ea\u4fe1\u3002\u6027\u80fd\u5728\u4e0d\u540c\u4e0d\u786e\u5b9a\u6027\u5f15\u5bfc\u65b9\u5f0f\u4e0b\u7565\u6709\u6539\u5584\uff0c\u4f46\u5728\u91c7\u6837\u7b56\u7565\u3001\u63a8\u7406\u52aa\u529b\u6216\u63d0\u793a\u8bbe\u8ba1\u65b9\u9762\u7684\u53d8\u5316\u5f71\u54cd\u4e0d\u5927\u3002", "conclusion": "OpenEstimate\u4e3a\u524d\u6cbf\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u8bc4\u4f30\u5e73\u53f0\uff0c\u53ef\u7528\u4e8e\u5f00\u53d1\u5728\u6982\u7387\u4f30\u8ba1\u548c\u4e0d\u786e\u5b9a\u6027\u63a8\u7406\u65b9\u9762\u8868\u73b0\u66f4\u597d\u7684\u6a21\u578b\u3002"}}
{"id": "2510.15128", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15128", "abs": "https://arxiv.org/abs/2510.15128", "authors": ["Marcus A. Thomas"], "title": "Towards Error Centric Intelligence I, Beyond Observational Learning", "comment": null, "summary": "We argue that progress toward AGI is theory limited rather than data or scale\nlimited. Building on the critical rationalism of Popper and Deutsch, we\nchallenge the Platonic Representation Hypothesis. Observationally equivalent\nworlds can diverge under interventions, so observational adequacy alone cannot\nguarantee interventional competence. We begin by laying foundations,\ndefinitions of knowledge, learning, intelligence, counterfactual competence and\nAGI, and then analyze the limits of observational learning that motivate an\nerror centric shift. We recast the problem as three questions about how\nexplicit and implicit errors evolve under an agent's actions, which errors are\nunreachable within a fixed hypothesis space, and how conjecture and criticism\nexpand that space. From these questions we propose Causal Mechanics, a\nmechanisms first program in which hypothesis space change is a first class\noperation and probabilistic structure is used when useful rather than presumed.\nWe advance structural principles that make error discovery and correction\ntractable, including a differential Locality and Autonomy Principle for modular\ninterventions, a gauge invariant form of Independent Causal Mechanisms for\nseparability, and the Compositional Autonomy Principle for analogy\npreservation, together with actionable diagnostics. The aim is a scaffold for\nsystems that can convert unreachable errors into reachable ones and correct\nthem.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8ba4\u4e3aAGI\u8fdb\u5c55\u53d7\u7406\u8bba\u9650\u5236\u800c\u975e\u6570\u636e\u6216\u89c4\u6a21\u9650\u5236\uff0c\u6311\u6218\u4e86\u67cf\u62c9\u56fe\u8868\u793a\u5047\u8bf4\uff0c\u63d0\u51fa\u56e0\u679c\u529b\u5b66\u6846\u67b6\uff0c\u5f3a\u8c03\u5047\u8bbe\u7a7a\u95f4\u53d8\u5316\u4f5c\u4e3a\u9996\u8981\u64cd\u4f5c\uff0c\u901a\u8fc7\u7ed3\u6784\u539f\u5219\u4f7f\u9519\u8bef\u53d1\u73b0\u548c\u4fee\u6b63\u53d8\u5f97\u53ef\u884c\u3002", "motivation": "\u5f53\u524dAGI\u53d1\u5c55\u9762\u4e34\u7406\u8bba\u74f6\u9888\uff0c\u89c2\u6d4b\u7b49\u4ef7\u4e16\u754c\u5728\u5e72\u9884\u4e0b\u53ef\u80fd\u4ea7\u751f\u5206\u6b67\uff0c\u4ec5\u9760\u89c2\u6d4b\u5145\u5206\u6027\u65e0\u6cd5\u4fdd\u8bc1\u5e72\u9884\u80fd\u529b\uff0c\u9700\u8981\u4ece\u89c2\u6d4b\u5b66\u4e60\u8f6c\u5411\u9519\u8bef\u4e2d\u5fc3\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u56e0\u679c\u529b\u5b66\u6846\u67b6\uff0c\u5c06\u5047\u8bbe\u7a7a\u95f4\u53d8\u5316\u4f5c\u4e3a\u9996\u8981\u64cd\u4f5c\uff0c\u5f15\u5165\u5c40\u90e8\u6027\u548c\u81ea\u4e3b\u6027\u539f\u5219\u3001\u72ec\u7acb\u56e0\u679c\u673a\u5236\u3001\u7ec4\u5408\u81ea\u4e3b\u6027\u539f\u5219\u7b49\u7ed3\u6784\u539f\u5219\uff0c\u5e76\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u8bca\u65ad\u65b9\u6cd5\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u80fd\u591f\u5c06\u4e0d\u53ef\u8fbe\u9519\u8bef\u8f6c\u5316\u4e3a\u53ef\u8fbe\u9519\u8bef\u5e76\u8fdb\u884c\u4fee\u6b63\u7684\u7cfb\u7edf\u6846\u67b6\uff0c\u4e3aAGI\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u65b9\u5411\u3002", "conclusion": "AGI\u8fdb\u5c55\u7684\u5173\u952e\u5728\u4e8e\u7406\u8bba\u7a81\u7834\u800c\u975e\u6570\u636e\u6269\u5c55\uff0c\u56e0\u679c\u529b\u5b66\u6846\u67b6\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u9519\u8bef\u53d1\u73b0\u548c\u4fee\u6b63\u673a\u5236\uff0c\u4e3a\u89e3\u51b3AGI\u7684\u7406\u8bba\u9650\u5236\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u8def\u5f84\u3002"}}
{"id": "2510.15144", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.15144", "abs": "https://arxiv.org/abs/2510.15144", "authors": ["Chance Jiajie Li", "Zhenze Mo", "Yuhan Tang", "Ao Qu", "Jiayi Wu", "Kaiya Ivy Zhao", "Yulu Gan", "Jie Fan", "Jiangbo Yu", "Hang Jiang", "Paul Pu Liang", "Jinhua Zhao", "Luis Alberto Alonso Pastor", "Kent Larson"], "title": "HugAgent: Evaluating LLMs in Simulating Human-Like Individual Reasoning on Open-Ended Tasks", "comment": "To appear in NeurIPS 2025 Workshop on Bridging Language, Agent, and\n  World Models (LAW)", "summary": "Simulating human reasoning in open-ended tasks has been a long-standing\naspiration in AI and cognitive science. While large language models now\napproximate human responses at scale, they remain tuned to population-level\nconsensus, often erasing the individuality of reasoning styles and belief\ntrajectories. To advance the vision of more human-like reasoning in machines,\nwe introduce HugAgent (Human-Grounded Agent Benchmark), a benchmark for\naverage-to-individual reasoning adaptation. The task is to predict how a\nspecific person would reason and update their beliefs in novel scenarios, given\npartial evidence of their past views. HugAgent adopts a dual-track design: a\nsynthetic track for scale and systematic stress tests, and a human track for\necologically valid, \"out-loud\" reasoning data. This design enables scalable,\nreproducible evaluation of intra-agent fidelity: whether models can capture not\njust what people believe, but how their reasoning evolves. Experiments with\nstate-of-the-art LLMs reveal persistent adaptation gaps, positioning HugAgent\nas the first extensible benchmark for aligning machine reasoning with the\nindividuality of human thought. Our benchmark and chatbot are open-sourced as\nHugAgent (https://anonymous.4open.science/r/HugAgent) and TraceYourThinking\n(https://anonymous.4open.science/r/trace-your-thinking).", "AI": {"tldr": "HugAgent\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30AI\u6a21\u578b\u4ece\u7fa4\u4f53\u63a8\u7406\u9002\u5e94\u5230\u4e2a\u4f53\u63a8\u7406\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u5408\u6210\u548c\u4eba\u7c7b\u53cc\u8f68\u8bbe\u8ba1\uff0c\u65e8\u5728\u8ba9\u673a\u5668\u63a8\u7406\u66f4\u8d34\u8fd1\u4eba\u7c7b\u4e2a\u4f53\u601d\u7ef4\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u53cd\u6620\u7fa4\u4f53\u5171\u8bc6\uff0c\u7f3a\u4e4f\u5bf9\u4e2a\u4f53\u63a8\u7406\u98ce\u683c\u548c\u4fe1\u5ff5\u8f68\u8ff9\u7684\u6355\u6349\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u6a21\u62df\u4e2a\u4f53\u4eba\u7c7b\u63a8\u7406\u7684AI\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u53cc\u8f68\u8bbe\u8ba1\uff1a\u5408\u6210\u8f68\u9053\u7528\u4e8e\u89c4\u6a21\u5316\u548c\u7cfb\u7edf\u538b\u529b\u6d4b\u8bd5\uff0c\u4eba\u7c7b\u8f68\u9053\u63d0\u4f9b\u751f\u6001\u6709\u6548\u7684\u51fa\u58f0\u63a8\u7406\u6570\u636e\uff0c\u901a\u8fc7\u90e8\u5206\u5386\u53f2\u89c2\u70b9\u8bc1\u636e\u9884\u6d4b\u4e2a\u4f53\u5728\u5168\u65b0\u573a\u666f\u4e2d\u7684\u63a8\u7406\u548c\u4fe1\u5ff5\u66f4\u65b0\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e2a\u4f53\u9002\u5e94\u65b9\u9762\u4ecd\u5b58\u5728\u6301\u7eed\u5dee\u8ddd\uff0cHugAgent\u6210\u4e3a\u9996\u4e2a\u53ef\u6269\u5c55\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "HugAgent\u4e3a\u673a\u5668\u63a8\u7406\u4e0e\u4eba\u7c7b\u4e2a\u4f53\u601d\u7ef4\u7684\u5bf9\u9f50\u63d0\u4f9b\u4e86\u9996\u4e2a\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u63a8\u52a8\u4e86\u66f4\u4eba\u6027\u5316AI\u63a8\u7406\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.15070", "categories": ["eess.SP", "math.DG", "94A14, 94A12, 14M15, 53C22"], "pdf": "https://arxiv.org/pdf/2510.15070", "abs": "https://arxiv.org/abs/2510.15070", "authors": ["\u00c1lvaro Pend\u00e1s-Recondo", "Enrique Pend\u00e1s-Recondo"], "title": "A Structured Family of Grassmannian Constellations via Geodesic Mapping for MIMO Noncoherent Communications", "comment": "13 pages, 7 figures", "summary": "This work presents a novel structured family of Grassmannian constellations\nfor multiple-input multiple-output (MIMO) noncoherent communications over\nRayleigh block-fading channels, where neither the transmitter nor the receiver\nhas channel state information (CSI). The proposed constellation design is built\nupon the geodesic curves of the Grassmann manifold, thereby exploiting its\nunderlying geometric structure. The resulting solution is limited in spectral\nefficiency (with a maximum constellation size of $4M^2$ points, where $M$ is\nthe number of transmit antennas), targeting a rate in the range of $0.25$-$1$\nbps/Hz. However, all space-time matrices resulting from this design exhibit the\nremarkable property of having a single nonzero entry per row, meaning that only\none transmit antenna is active per time slot. This property significantly\nreduces hardware complexity and implementation cost, while also lowering power\nconsumption, as only a single power amplifier is required for transmission.\nFurthermore, within the constellation size limits, the proposed design achieves\nerror performance comparable to state-of-the-art optimization-based\nunstructured designs, as validated through symbol error rate (SER) numerical\nresults. It also enables simple yet effective bit labeling, confirmed by\ncomparisons of bit error rate (BER) and SER, and reduces the computational\ncomplexity of the maximum-likelihood (ML) detector for Grassmannian\nconstellations by a factor of $M$.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGrassmann\u6d41\u5f62\u6d4b\u5730\u7ebf\u7684\u65b0\u578b\u7ed3\u6784\u5316\u661f\u5ea7\u8bbe\u8ba1\uff0c\u7528\u4e8eMIMO\u975e\u76f8\u5e72\u901a\u4fe1\uff0c\u5177\u6709\u5355\u5929\u7ebf\u6fc0\u6d3b\u7279\u6027\uff0c\u964d\u4f4e\u786c\u4ef6\u590d\u6742\u5ea6\u548c\u529f\u8017\uff0c\u5728\u6709\u9650\u9891\u8c31\u6548\u7387\u4e0b\u8fbe\u5230\u4e0e\u6700\u5148\u8fdb\u8bbe\u8ba1\u76f8\u5f53\u7684\u8bef\u7801\u6027\u80fd\u3002", "motivation": "\u9488\u5bf9MIMO\u975e\u76f8\u5e72\u901a\u4fe1\u7cfb\u7edf\uff0c\u5728\u7f3a\u4e4f\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\uff0c\u8bbe\u8ba1\u80fd\u591f\u964d\u4f4e\u786c\u4ef6\u590d\u6742\u5ea6\u3001\u529f\u8017\u548c\u68c0\u6d4b\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u7ed3\u6784\u5316\u661f\u5ea7\u65b9\u6848\u3002", "method": "\u57fa\u4e8eGrassmann\u6d41\u5f62\u7684\u6d4b\u5730\u66f2\u7ebf\u6784\u5efa\u661f\u5ea7\u8bbe\u8ba1\uff0c\u5229\u7528\u6d41\u5f62\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u786e\u4fdd\u6bcf\u4e2a\u65f6\u9699\u53ea\u6709\u4e00\u4e2a\u53d1\u5c04\u5929\u7ebf\u6fc0\u6d3b\u3002", "result": "\u661f\u5ea7\u5927\u5c0f\u9650\u5236\u57284M\u00b2\u70b9\uff0c\u9891\u8c31\u6548\u73870.25-1 bps/Hz\uff0c\u8bef\u7801\u6027\u80fd\u4e0e\u6700\u5148\u8fdb\u975e\u7ed3\u6784\u5316\u8bbe\u8ba1\u76f8\u5f53\uff0cML\u68c0\u6d4b\u5668\u8ba1\u7b97\u590d\u6742\u5ea6\u964d\u4f4eM\u500d\uff0c\u652f\u6301\u7b80\u5355\u6709\u6548\u7684\u6bd4\u7279\u6807\u8bb0\u3002", "conclusion": "\u8be5\u7ed3\u6784\u5316\u661f\u5ea7\u8bbe\u8ba1\u5728\u4fdd\u6301\u826f\u597d\u8bef\u7801\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u786c\u4ef6\u590d\u6742\u5ea6\u3001\u529f\u8017\u548c\u68c0\u6d4b\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4e3aMIMO\u975e\u76f8\u5e72\u901a\u4fe1\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.15011", "categories": ["stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.15011", "abs": "https://arxiv.org/abs/2510.15011", "authors": ["Tomasz Serafin", "Weronika Nitka"], "title": "Data-driven Calibration Sample Selection and Forecast Combination in Electricity Price Forecasting: An Application of the ARHNN Method", "comment": null, "summary": "Calibration sample selection and forecast combination are two simple yet\npowerful tools used in forecasting. They can be combined with a variety of\nmodels to significantly improve prediction accuracy, at the same time offering\neasy implementation and low computational complexity. While their effectiveness\nhas been repeatedly confirmed in prior scientific literature, the topic is\nstill underexplored in the field of electricity price forecasting. In this\nresearch article we apply the Autoregressive Hybrid Nearest Neighbors (ARHNN)\nmethod to three long-term time series describing the German, Spanish and New\nEngland electricity markets. We show that it outperforms popular literature\nbenchmarks in terms of forecast accuracy by up to 10%. We also propose two\nsimplified variants of the method, granting a vast decrease in computation time\nwith only minor loss of prediction accuracy. Finally, we compare the forecasts'\nperformance in a battery storage system trading case study. We find that using\na forecast-driven strategy can achieve up to 80% of theoretical maximum profits\nwhile trading, demonstrating business value in practical applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6821\u51c6\u6837\u672c\u9009\u62e9\u548c\u9884\u6d4b\u7ec4\u5408\u7684ARHNN\u65b9\u6cd5\uff0c\u5728\u7535\u529b\u4ef7\u683c\u9884\u6d4b\u4e2d\u663e\u8457\u63d0\u5347\u51c6\u786e\u6027\uff0c\u5e76\u5f00\u53d1\u4e86\u4e24\u79cd\u7b80\u5316\u7248\u672c\u4ee5\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u5728\u7535\u6c60\u50a8\u80fd\u4ea4\u6613\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u5176\u5546\u4e1a\u4ef7\u503c\u3002", "motivation": "\u6821\u51c6\u6837\u672c\u9009\u62e9\u548c\u9884\u6d4b\u7ec4\u5408\u662f\u4e24\u79cd\u7b80\u5355\u4f46\u5f3a\u5927\u7684\u9884\u6d4b\u5de5\u5177\uff0c\u4f46\u5728\u7535\u529b\u4ef7\u683c\u9884\u6d4b\u9886\u57df\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u5c06\u8fd9\u4e9b\u65b9\u6cd5\u5e94\u7528\u4e8e\u7535\u529b\u5e02\u573a\u9884\u6d4b\uff0c\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528\u81ea\u56de\u5f52\u6df7\u5408\u6700\u8fd1\u90bb\uff08ARHNN\uff09\u65b9\u6cd5\uff0c\u7ed3\u5408\u6821\u51c6\u6837\u672c\u9009\u62e9\u548c\u9884\u6d4b\u7ec4\u5408\u6280\u672f\uff0c\u5e94\u7528\u4e8e\u5fb7\u56fd\u3001\u897f\u73ed\u7259\u548c\u65b0\u82f1\u683c\u5170\u7535\u529b\u5e02\u573a\u7684\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002", "result": "ARHNN\u65b9\u6cd5\u5728\u9884\u6d4b\u51c6\u786e\u6027\u4e0a\u6bd4\u6d41\u884c\u6587\u732e\u57fa\u51c6\u9ad8\u51fa10%\uff0c\u63d0\u51fa\u7684\u4e24\u79cd\u7b80\u5316\u7248\u672c\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u65f6\u95f4\u800c\u4ec5\u8f7b\u5fae\u635f\u5931\u51c6\u786e\u6027\u3002\u5728\u7535\u6c60\u50a8\u80fd\u4ea4\u6613\u6848\u4f8b\u4e2d\uff0c\u57fa\u4e8e\u9884\u6d4b\u7684\u7b56\u7565\u53ef\u5b9e\u73b0\u7406\u8bba\u6700\u5927\u5229\u6da6\u768480%\u3002", "conclusion": "ARHNN\u65b9\u6cd5\u53ca\u5176\u7b80\u5316\u7248\u672c\u5728\u7535\u529b\u4ef7\u683c\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u5b9e\u9645\u5546\u4e1a\u5e94\u7528\u4ef7\u503c\uff0c\u7279\u522b\u662f\u5728\u80fd\u6e90\u4ea4\u6613\u7b56\u7565\u4e2d\u80fd\u663e\u8457\u63d0\u5347\u76c8\u5229\u80fd\u529b\u3002"}}
{"id": "2510.15221", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15221", "abs": "https://arxiv.org/abs/2510.15221", "authors": ["Xiao Sun"], "title": "WELD: A Large-Scale Longitudinal Dataset of Emotional Dynamics for Ubiquitous Affective Computing", "comment": "15 pages, 4 figures, 1 table. Dataset publicly available under CC BY\n  4.0 license", "summary": "Automated emotion recognition in real-world workplace settings remains a\nchallenging problem in affective computing due to the scarcity of large-scale,\nlongitudinal datasets collected in naturalistic environments. We present a\nnovel dataset comprising 733,651 facial expression records from 38 employees\ncollected over 30.5 months (November 2021 to May 2024) in an authentic office\nenvironment. Each record contains seven emotion probabilities (neutral, happy,\nsad, surprised, fear, disgusted, angry) derived from deep learning-based facial\nexpression recognition, along with comprehensive metadata including job roles,\nemployment outcomes, and personality traits. The dataset uniquely spans the\nCOVID-19 pandemic period, capturing emotional responses to major societal\nevents including the Shanghai lockdown and policy changes. We provide 32\nextended emotional metrics computed using established affective science\nmethods, including valence, arousal, volatility, predictability, inertia, and\nemotional contagion strength. Technical validation demonstrates high data\nquality through successful replication of known psychological patterns (weekend\neffect: +192% valence improvement, p < 0.001; diurnal rhythm validated) and\nperfect predictive validity for employee turnover (AUC=1.0). Baseline\nexperiments using Random Forest and LSTM models achieve 91.2% accuracy for\nemotion classification and R2 = 0.84 for valence prediction. This is the\nlargest and longest longitudinal workplace emotion dataset publicly available,\nenabling research in emotion recognition, affective dynamics modeling,\nemotional contagion, turnover prediction, and emotion-aware system design.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b733,651\u4e2a\u9762\u90e8\u8868\u60c5\u8bb0\u5f55\u7684\u5927\u89c4\u6a21\u7eb5\u5411\u5de5\u4f5c\u573a\u6240\u60c5\u611f\u6570\u636e\u96c6\uff0c\u6db5\u76d638\u540d\u5458\u5de530.5\u4e2a\u6708\u7684\u6570\u636e\uff0c\u5305\u542b\u60c5\u7eea\u6982\u7387\u548c\u5143\u6570\u636e\uff0c\u9a8c\u8bc1\u4e86\u5df2\u77e5\u5fc3\u7406\u6a21\u5f0f\u5e76\u5c55\u793a\u4e86\u9ad8\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u771f\u5b9e\u5de5\u4f5c\u573a\u6240\u73af\u5883\u4e2d\u60c5\u611f\u8bc6\u522b\u9762\u4e34\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u7f3a\u4e4f\u5927\u89c4\u6a21\u3001\u81ea\u7136\u73af\u5883\u4e0b\u6536\u96c6\u7684\u7eb5\u5411\u6570\u636e\u96c6\u7684\u95ee\u9898\u3002", "method": "\u6536\u96c638\u540d\u5458\u5de5\u572830.5\u4e2a\u6708\u5185\u7684\u9762\u90e8\u8868\u60c5\u6570\u636e\uff0c\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u8fdb\u884c\u60c5\u611f\u8bc6\u522b\uff0c\u8ba1\u7b9732\u4e2a\u6269\u5c55\u60c5\u611f\u6307\u6807\uff0c\u5e76\u8fdb\u884c\u6280\u672f\u9a8c\u8bc1\u548c\u57fa\u7ebf\u5b9e\u9a8c\u3002", "result": "\u6570\u636e\u96c6\u6210\u529f\u590d\u5236\u4e86\u5df2\u77e5\u5fc3\u7406\u6a21\u5f0f\uff08\u5468\u672b\u6548\u5e94\uff1a+192%\u6548\u4ef7\u6539\u5584\uff0cp<0.001\uff09\uff0c\u5458\u5de5\u6d41\u5931\u9884\u6d4bAUC=1.0\uff0c\u60c5\u611f\u5206\u7c7b\u51c6\u786e\u738791.2%\uff0c\u6548\u4ef7\u9884\u6d4bR\u00b2=0.84\u3002", "conclusion": "\u8fd9\u662f\u76ee\u524d\u516c\u5f00\u53ef\u7528\u7684\u6700\u5927\u3001\u6700\u957f\u7684\u7eb5\u5411\u5de5\u4f5c\u573a\u6240\u60c5\u611f\u6570\u636e\u96c6\uff0c\u4e3a\u60c5\u611f\u8bc6\u522b\u3001\u60c5\u611f\u52a8\u6001\u5efa\u6a21\u3001\u60c5\u611f\u4f20\u67d3\u7b49\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\u3002"}}
{"id": "2510.15014", "categories": ["stat.ML", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.15014", "abs": "https://arxiv.org/abs/2510.15014", "authors": ["Jack Kendrick"], "title": "The Tree-SNE Tree Exists", "comment": null, "summary": "The clustering and visualisation of high-dimensional data is a ubiquitous\ntask in modern data science. Popular techniques include nonlinear\ndimensionality reduction methods like t-SNE or UMAP. These methods face the\n`scale-problem' of clustering: when dealing with the MNIST dataset, do we want\nto distinguish different digits or do we want to distinguish different ways of\nwriting the digits? The answer is task dependent and depends on scale. We\nrevisit an idea of Robinson & Pierce-Hoffman that exploits an underlying\nscaling symmetry in t-SNE to replace 2-dimensional with (2+1)-dimensional\nembeddings where the additional parameter accounts for scale. This gives rise\nto the t-SNE tree (short: tree-SNE). We prove that the optimal embedding\ndepends continuously on the scaling parameter for all initial conditions\noutside a set of measure 0: the tree-SNE tree exists. This idea conceivably\nextends to other attraction-repulsion methods and is illustrated on several\nexamples.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fatree-SNE\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728t-SNE\u4e2d\u5f15\u5165\u989d\u5916\u7684\u5c3a\u5ea6\u53c2\u6570\u6765\u89e3\u51b3\u9ad8\u7ef4\u6570\u636e\u805a\u7c7b\u4e2d\u7684\u5c3a\u5ea6\u95ee\u9898\uff0c\u751f\u6210(2+1)\u7ef4\u5d4c\u5165\uff0c\u4f7f\u805a\u7c7b\u7ed3\u679c\u80fd\u591f\u6839\u636e\u4efb\u52a1\u9700\u6c42\u5728\u4e0d\u540c\u5c3a\u5ea6\u4e0b\u8fde\u7eed\u53d8\u5316\u3002", "motivation": "\u89e3\u51b3\u975e\u7ebf\u6027\u964d\u7ef4\u65b9\u6cd5\uff08\u5982t-SNE\u3001UMAP\uff09\u5728\u5904\u7406\u9ad8\u7ef4\u6570\u636e\u65f6\u9762\u4e34\u7684\u5c3a\u5ea6\u95ee\u9898\u2014\u2014\u5373\u5982\u4f55\u6839\u636e\u5177\u4f53\u4efb\u52a1\u9700\u6c42\u9009\u62e9\u9002\u5f53\u7684\u805a\u7c7b\u5c3a\u5ea6\uff0c\u4f8b\u5982\u5728MNIST\u6570\u636e\u96c6\u4e2d\u662f\u533a\u5206\u4e0d\u540c\u6570\u5b57\u8fd8\u662f\u533a\u5206\u540c\u4e00\u6570\u5b57\u7684\u4e0d\u540c\u4e66\u5199\u65b9\u5f0f\u3002", "method": "\u57fa\u4e8eRobinson & Pierce-Hoffman\u7684\u601d\u60f3\uff0c\u5229\u7528t-SNE\u4e2d\u7684\u5c3a\u5ea6\u5bf9\u79f0\u6027\uff0c\u5c06\u4f20\u7edf\u76842\u7ef4\u5d4c\u5165\u6269\u5c55\u4e3a(2+1)\u7ef4\u5d4c\u5165\uff0c\u5176\u4e2d\u989d\u5916\u53c2\u6570\u63a7\u5236\u5c3a\u5ea6\uff0c\u5f62\u6210t-SNE\u6811\uff08tree-SNE\uff09\u3002", "result": "\u8bc1\u660e\u4e86\u5bf9\u4e8e\u9664\u96f6\u6d4b\u96c6\u5916\u7684\u6240\u6709\u521d\u59cb\u6761\u4ef6\uff0c\u6700\u4f18\u5d4c\u5165\u968f\u5c3a\u5ea6\u53c2\u6570\u8fde\u7eed\u53d8\u5316\uff0c\u5373tree-SNE\u6811\u5b58\u5728\u3002\u8be5\u65b9\u6cd5\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u5438\u5f15-\u6392\u65a5\u65b9\u6cd5\uff0c\u5e76\u5728\u591a\u4e2a\u793a\u4f8b\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002", "conclusion": "tree-SNE\u63d0\u4f9b\u4e86\u4e00\u79cd\u89e3\u51b3\u805a\u7c7b\u5c3a\u5ea6\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u5c3a\u5ea6\u53c2\u6570\u5b9e\u73b0\u4e86\u805a\u7c7b\u7ed3\u679c\u5728\u4e0d\u540c\u5206\u8fa8\u7387\u4e0b\u7684\u8fde\u7eed\u53d8\u5316\uff0c\u589e\u5f3a\u4e86\u6570\u636e\u53ef\u89c6\u5316\u548c\u5206\u6790\u7684\u7075\u6d3b\u6027\u3002"}}
{"id": "2510.15278", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.15278", "abs": "https://arxiv.org/abs/2510.15278", "authors": ["Heyao Zhu", "Yimeng Zhao", "Zirui Zhang", "Huansheng Yi", "Chenbin Gao", "Canhua Xu", "Jianqi Wang", "Fugui Qi"], "title": "Multidimensional Physiology-Inspired Enhanced Vital Sign Monitoring Using MIMO mmWave Bio-radar", "comment": null, "summary": "With the intensiffcation of population aging and increasing burden of chronic\ndiseases, the demand for vital signs monitoring is becoming increasingly\nurgent. A key challenge facing current non-contact detection technologies using\nmillimeter wave (mmWave) radar is the low efffciency of multi-channel signal\nfusion in array radar systems based on equal weighting. To address this\nchallenge, this paper proposes a vital sign enhancement detection method for\nmultiple input and multiple output (MIMO) bio-radar, driven by multidimensional\nphysiological characteristics, which overcomes traditional limitations through\na two-stage fusion strategy. Stage 1: Enhanced Vital Sign Detection Using\nSingle-Channel Signals Based on Physiological Characteristics. First, a chest\nwall multi-scattering point model is constructed. For single channel\ntime-distance two-dimensional echo signals, effective range bins are selected\nbased on the respiratory/cardiac physiological frequency band energy ratio, and\nthe signal-to-noise ratio (SNR) of respiration/heart signals is enhanced using\nphase-aligned maximal ratio combining (MRC). Stage 2: Multi-Channel Fusion\nBased on Organ Radiation Spatial Distribution Characteristics. The spatial\nradiation characteristics of cardiopulmonary organs are introduced for the\nffrst time as the theoretical foundation for SNR-based channel screening,\nchannel attribute identiffcation, and multi-channel weighted fusion. Then, we\npropose a template matching method to extract respiratory rate (RR) and heart\nrate (HR) by adopting physical models of respiration and cardiac activities.\nThe experimental results demonstrate the existence of the spatial distribution\ncharacteristics of organ radiation. In addition, we analyzed the impact of\ndistance and state on the algorithm from these two aspects.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u7ef4\u751f\u7406\u7279\u5f81\u7684MIMO\u751f\u7269\u96f7\u8fbe\u751f\u547d\u4f53\u5f81\u589e\u5f3a\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u878d\u5408\u7b56\u7565\u89e3\u51b3\u4f20\u7edf\u7b49\u6743\u91cd\u591a\u901a\u9053\u4fe1\u53f7\u878d\u5408\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u4eba\u53e3\u8001\u9f84\u5316\u52a0\u5267\u548c\u6162\u6027\u75c5\u8d1f\u62c5\u589e\u52a0\uff0c\u751f\u547d\u4f53\u5f81\u76d1\u6d4b\u9700\u6c42\u65e5\u76ca\u8feb\u5207\u3002\u5f53\u524d\u57fa\u4e8e\u7b49\u6743\u91cd\u7684\u6beb\u7c73\u6ce2\u96f7\u8fbe\u9635\u5217\u7cfb\u7edf\u5728\u591a\u901a\u9053\u4fe1\u53f7\u878d\u5408\u65b9\u9762\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u878d\u5408\u7b56\u7565\uff1a\u7b2c\u4e00\u9636\u6bb5\u57fa\u4e8e\u751f\u7406\u7279\u5f81\u7684\u5355\u901a\u9053\u4fe1\u53f7\u589e\u5f3a\u68c0\u6d4b\uff0c\u6784\u5efa\u80f8\u58c1\u591a\u6563\u5c04\u70b9\u6a21\u578b\uff0c\u9009\u62e9\u6709\u6548\u8ddd\u79bb\u5355\u5143\u5e76\u4f7f\u7528\u76f8\u4f4d\u5bf9\u9f50MRC\u589e\u5f3a\u4fe1\u566a\u6bd4\uff1b\u7b2c\u4e8c\u9636\u6bb5\u57fa\u4e8e\u5668\u5b98\u8f90\u5c04\u7a7a\u95f4\u5206\u5e03\u7279\u5f81\u7684\u591a\u901a\u9053\u878d\u5408\uff0c\u9996\u6b21\u5f15\u5165\u5fc3\u80ba\u5668\u5b98\u7a7a\u95f4\u8f90\u5c04\u7279\u6027\u4f5c\u4e3a\u7406\u8bba\u57fa\u7840\uff0c\u8fdb\u884c\u901a\u9053\u7b5b\u9009\u548c\u52a0\u6743\u878d\u5408\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u5668\u5b98\u8f90\u5c04\u7a7a\u95f4\u5206\u5e03\u7279\u5f81\u7684\u5b58\u5728\uff0c\u5e76\u4ece\u8ddd\u79bb\u548c\u72b6\u6001\u4e24\u4e2a\u65b9\u9762\u5206\u6790\u4e86\u7b97\u6cd5\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u514b\u670d\u4e86\u4f20\u7edf\u7b49\u6743\u91cd\u591a\u901a\u9053\u878d\u5408\u7684\u5c40\u9650\u6027\uff0c\u63d0\u9ad8\u4e86\u751f\u547d\u4f53\u5f81\u68c0\u6d4b\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2510.15572", "categories": ["stat.AP", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.15572", "abs": "https://arxiv.org/abs/2510.15572", "authors": ["Kamel Lahssini", "Guerric le Maire", "Nicolas Baghdadi", "Ibrahim Fayad"], "title": "Residual Kriging for Regional-Scale Canopy Height Mapping: Insights into GEDI-Induced Anisotropies and Sparse Sampling", "comment": "22 pages, 12 figures", "summary": "Quantifying aboveground biomass (AGB) is essential in the context of global\nclimate change. Canopy height, which is related to AGB, can be mapped using\nmachine learning models trained with multi-source spatial data and GEDI\nmeasurements. In this study, a comparative analysis of canopy height estimates\nderived from two models is presented: a U-Net deep learning model (CHNET) and a\nRandom Forest algorithm (RFH). Both models were trained using GEDI lidar data\nand utilized multi-source inputs, including optical, radar, and environmental\ndata. While CHNET can leverage its convolutional architecture to account for\nspatial correlations, we observed that it does not fully incorporate all the\nspatial autocorrelation present in GEDI canopy height measurements. By\nconducting a spatial analysis of the models' residuals, we also identified that\nGEDI data acquisition parameters, particularly the variability in laser beam\nenergy combined with the azimuthal directions of the observation tracks,\nintroduce spatial inconsistencies in the measurements in the form of periodic\npatterns. To address these anisotropies, we considered exclusively GEDI power\nbeams, and we conducted our spatial autocorrelation analysis in the GEDI track\nazimuthal direction. Next, we employed the residual kriging (RK) spatial\ninterpolation technique to account for the spatial autocorrelation of canopy\nheights and improve the accuracies of CHNET and RFH estimates. Adding RK\ncorrections improved the performance of both CHNET and RFH, with more\nsubstantial gains observed for RFH. The corrections appeared to be localized\naround the GEDI sample points and the density of usable GEDI information is\ntherefore an important factor in the effectiveness of spatial interpolation.\nFurthermore, our findings reveal that a Random Forest model combined with\nspatial interpolation can deliver performance comparable to that of a U-Net\nmodel alone.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86\u57fa\u4e8eU-Net\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b(CHNET)\u548c\u968f\u673a\u68ee\u6797\u7b97\u6cd5(RFH)\u7684\u51a0\u5c42\u9ad8\u5ea6\u4f30\u7b97\uff0c\u53d1\u73b0GEDI\u6fc0\u5149\u96f7\u8fbe\u6570\u636e\u7684\u91c7\u96c6\u53c2\u6570\u4f1a\u5f15\u5165\u7a7a\u95f4\u4e0d\u4e00\u81f4\u6027\u3002\u901a\u8fc7\u6b8b\u5dee\u514b\u91cc\u91d1\u7a7a\u95f4\u63d2\u503c\u6280\u672f\u5904\u7406\u7a7a\u95f4\u81ea\u76f8\u5173\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u4e24\u79cd\u6a21\u578b\u7684\u7cbe\u5ea6\uff0c\u7279\u522b\u662fRFH\u6a21\u578b\u3002", "motivation": "\u5728\u5168\u7403\u6c14\u5019\u53d8\u5316\u80cc\u666f\u4e0b\uff0c\u51c6\u786e\u91cf\u5316\u5730\u4e0a\u751f\u7269\u91cf\u81f3\u5173\u91cd\u8981\u3002\u51a0\u5c42\u9ad8\u5ea6\u4e0e\u5730\u4e0a\u751f\u7269\u91cf\u76f8\u5173\uff0c\u53ef\u4ee5\u5229\u7528\u591a\u6e90\u7a7a\u95f4\u6570\u636e\u548cGEDI\u6d4b\u91cf\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u5236\u56fe\u3002", "method": "\u4f7f\u7528GEDI\u6fc0\u5149\u96f7\u8fbe\u6570\u636e\u8bad\u7ec3U-Net\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b(CHNET)\u548c\u968f\u673a\u68ee\u6797\u7b97\u6cd5(RFH)\uff0c\u8f93\u5165\u5305\u62ec\u5149\u5b66\u3001\u96f7\u8fbe\u548c\u73af\u5883\u6570\u636e\u3002\u901a\u8fc7\u6b8b\u5dee\u514b\u91cc\u91d1\u7a7a\u95f4\u63d2\u503c\u6280\u672f\u5904\u7406\u7a7a\u95f4\u81ea\u76f8\u5173\u6027\uff0c\u7279\u522b\u5173\u6ce8GEDI\u529f\u7387\u675f\u548c\u8f68\u9053\u65b9\u4f4d\u89d2\u65b9\u5411\u3002", "result": "\u6dfb\u52a0\u6b8b\u5dee\u514b\u91cc\u91d1\u6821\u6b63\u540e\uff0cCHNET\u548cRFH\u7684\u6027\u80fd\u5747\u5f97\u5230\u6539\u5584\uff0cRFH\u7684\u6539\u8fdb\u66f4\u4e3a\u663e\u8457\u3002\u6821\u6b63\u6548\u679c\u96c6\u4e2d\u5728GEDI\u91c7\u6837\u70b9\u5468\u56f4\uff0c\u53ef\u7528GEDI\u4fe1\u606f\u7684\u5bc6\u5ea6\u662f\u7a7a\u95f4\u63d2\u503c\u6709\u6548\u6027\u7684\u91cd\u8981\u56e0\u7d20\u3002", "conclusion": "\u968f\u673a\u68ee\u6797\u6a21\u578b\u7ed3\u5408\u7a7a\u95f4\u63d2\u503c\u53ef\u4ee5\u8fbe\u5230\u4e0e\u5355\u72ec\u4f7f\u7528U-Net\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u8868\u660e\u7b80\u5355\u6a21\u578b\u7ed3\u5408\u9002\u5f53\u7684\u7a7a\u95f4\u5904\u7406\u65b9\u6cd5\u53ef\u4ee5\u53d6\u5f97\u826f\u597d\u6548\u679c\u3002"}}
{"id": "2510.15575", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.15575", "abs": "https://arxiv.org/abs/2510.15575", "authors": ["Yi Tao", "Zhen Gao", "Zhuoran Li", "Ziwei Wan", "Tuan Li", "Chunli Zhu", "Lei Chen", "Guanghui Wen", "Dezhi Zheng", "Dusit Niyato"], "title": "Pseudo-Random TDM-MIMO FMCW Based Millimeter-Wave Sensing and Communication Integration for UAV Swarm", "comment": null, "summary": "The integrated sensing and communications (ISAC) can achieve the sharing of\nhardware and spectrum resources, enabling efficient data transmission and\nenvironmental sensing. This fusion is particularly important for unmanned\naerial vehicle (UAV) swarms, as it enhances the overall performance,\nflexibility, and efficiency of such systems. To facilitate the collaborative\noperations among UAVs, this paper proposes an ISAC solution based on the\npseudo-random time-division multiplexing (TDM)-multiple input multiple output\n(MIMO) millimeter-wave (mmWave) frequency modulated continuous wave (FMCW).\nSpecifically, a novel ISAC chirp waveform is proposed to modulate data in both\nthe delay domain and complex amplitude, while also possessing high-precision\nsensing capabilities. To address challenges in the TDM-MIMO, we utilize the\npseudo-random antenna selection and compressed sensing algorithms, ensuring\nthat the maximum unambiguous velocity is not compromised. Moreover, by\nemploying a chirp-division multiple access scheme, we propose an\ninterference-free multiple antenna transmission scheme to achieve dynamic\nallocation of time-frequency resources and multi-user transmission. Finally, we\npropose a communication and sensing fusion-based dynamic iterative computation\nscheme, simultaneously achieving data demodulation and sensing parameter\nestimation. Simulation results show that the proposed scheme can achieve ISAC\nunder the dynamic flight scenarios of UAVs. Meanwhile, the scheme outperforms\nthe mmWave-LoRadar in communication and sensing performance, yet its sensing\nperformance is slightly lower than that of the traditional FMCW. Under the\nurban clutter modeling, the scheme still maintains favorable robustness despite\na certain degree of performance degradation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f2a\u968f\u673a\u65f6\u5206\u590d\u7528MIMO\u6beb\u7c73\u6ce2\u8c03\u9891\u8fde\u7eed\u6ce2\u7684\u65e0\u4eba\u673a\u96c6\u7fa4\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u65b9\u6848\uff0c\u901a\u8fc7\u65b0\u578bISAC\u5541\u557e\u6ce2\u5f62\u3001\u4f2a\u968f\u673a\u5929\u7ebf\u9009\u62e9\u548c\u538b\u7f29\u611f\u77e5\u7b97\u6cd5\uff0c\u540c\u65f6\u5b9e\u73b0\u6570\u636e\u89e3\u8c03\u548c\u611f\u77e5\u53c2\u6570\u4f30\u8ba1\u3002", "motivation": "\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1(ISAC)\u80fd\u591f\u5171\u4eab\u786c\u4ef6\u548c\u9891\u8c31\u8d44\u6e90\uff0c\u63d0\u9ad8\u65e0\u4eba\u673a\u96c6\u7fa4\u7cfb\u7edf\u7684\u6574\u4f53\u6027\u80fd\u3001\u7075\u6d3b\u6027\u548c\u6548\u7387\uff0c\u4fc3\u8fdb\u65e0\u4eba\u673a\u95f4\u7684\u534f\u540c\u64cd\u4f5c\u3002", "method": "\u63d0\u51fa\u65b0\u578bISAC\u5541\u557e\u6ce2\u5f62\u5728\u5ef6\u8fdf\u57df\u548c\u590d\u632f\u5e45\u4e2d\u8c03\u5236\u6570\u636e\uff1b\u91c7\u7528\u4f2a\u968f\u673a\u5929\u7ebf\u9009\u62e9\u548c\u538b\u7f29\u611f\u77e5\u7b97\u6cd5\u89e3\u51b3TDM-MIMO\u6311\u6218\uff1b\u4f7f\u7528\u5541\u557e\u5206\u591a\u5740\u65b9\u6848\u5b9e\u73b0\u65e0\u5e72\u6270\u591a\u5929\u7ebf\u4f20\u8f93\uff1b\u63d0\u51fa\u57fa\u4e8e\u901a\u4fe1\u548c\u611f\u77e5\u878d\u5408\u7684\u52a8\u6001\u8fed\u4ee3\u8ba1\u7b97\u65b9\u6848\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6848\u80fd\u5728\u65e0\u4eba\u673a\u52a8\u6001\u98de\u884c\u573a\u666f\u4e0b\u5b9e\u73b0ISAC\uff0c\u5728\u901a\u4fe1\u548c\u611f\u77e5\u6027\u80fd\u4e0a\u4f18\u4e8e\u6beb\u7c73\u6ce2-LoRadar\uff0c\u4f46\u611f\u77e5\u6027\u80fd\u7565\u4f4e\u4e8e\u4f20\u7edfFMCW\uff0c\u5728\u57ce\u5e02\u6742\u6ce2\u5efa\u6a21\u4e0b\u4ecd\u4fdd\u6301\u826f\u597d\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u65b9\u6848\u6210\u529f\u5b9e\u73b0\u4e86\u65e0\u4eba\u673a\u96c6\u7fa4\u7684\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\uff0c\u5728\u52a8\u6001\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.15580", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.15580", "abs": "https://arxiv.org/abs/2510.15580", "authors": ["Kyle Stanley", "Nicole Lazar", "Matthew Reimherr"], "title": "Temporal Functional Factor Analysis of Brain Connectivity", "comment": null, "summary": "Many analyses of functional magnetic resonance imaging (fMRI) examine\nfunctional connectivity (FC), or the statistical dependencies among distant\nbrain regions. These analyses are typically exploratory, guiding future\nconfirmatory research. In this work, we present an approach based on factor\nanalysis (FA) that is well-suited to studying FC. FA is appealing in this\ncontext because its flexible model assumptions permit a guided investigation of\nits target subspace consistent with the exploratory role of connectivity\nanalyses. However, applying FA to fMRI data poses three problems: (1) its\ntarget subspace captures short-range spatial dependencies that should be\ntreated as noise, (2) it requires factorization of a massive spatial\ncovariance, and (3) it overlooks temporal dependencies in the data. To address\nthese limitations, we develop a factor model within the framework of functional\ndata analysis--a field which views certain data as arising from smooth\nunderlying curves. The proposed approach (1) uses matrix completion techniques\nto filter short-range spatial dependencies out of its target subspace, (2)\nemploys a distributed algorithm for factorizing large-scale covariance\nmatrices, and (3) leverages functional regression to exploit temporal dynamics.\nTogether, these innovations yield a comprehensive and scalable method for\nstudying FC.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u5b50\u5206\u6790\u7684\u529f\u80fd\u78c1\u5171\u632f\u6210\u50cf\u529f\u80fd\u8fde\u63a5\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u77e9\u9635\u8865\u5168\u6280\u672f\u8fc7\u6ee4\u77ed\u7a0b\u7a7a\u95f4\u4f9d\u8d56\uff0c\u4f7f\u7528\u5206\u5e03\u5f0f\u7b97\u6cd5\u5904\u7406\u5927\u89c4\u6a21\u534f\u65b9\u5dee\u77e9\u9635\uff0c\u5e76\u5229\u7528\u529f\u80fd\u56de\u5f52\u5229\u7528\u65f6\u95f4\u52a8\u6001\uff0c\u4e3a\u529f\u80fd\u8fde\u63a5\u7814\u7a76\u63d0\u4f9b\u4e86\u5168\u9762\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u3002", "motivation": "\u529f\u80fd\u78c1\u5171\u632f\u6210\u50cf\u4e2d\u7684\u529f\u80fd\u8fde\u63a5\u5206\u6790\u901a\u5e38\u662f\u63a2\u7d22\u6027\u7684\uff0c\u4f46\u4f20\u7edf\u56e0\u5b50\u5206\u6790\u5728\u5e94\u7528\u65f6\u9762\u4e34\u4e09\u4e2a\u95ee\u9898\uff1a\u76ee\u6807\u5b50\u7a7a\u95f4\u6355\u83b7\u77ed\u7a0b\u7a7a\u95f4\u4f9d\u8d56\u3001\u9700\u8981\u5206\u89e3\u5927\u89c4\u6a21\u7a7a\u95f4\u534f\u65b9\u5dee\u77e9\u9635\u3001\u5ffd\u89c6\u6570\u636e\u4e2d\u7684\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "\u5728\u529f\u80fd\u6570\u636e\u5206\u6790\u6846\u67b6\u4e0b\u5f00\u53d1\u56e0\u5b50\u6a21\u578b\uff0c\u4f7f\u7528\u77e9\u9635\u8865\u5168\u6280\u672f\u8fc7\u6ee4\u77ed\u7a0b\u7a7a\u95f4\u4f9d\u8d56\uff0c\u91c7\u7528\u5206\u5e03\u5f0f\u7b97\u6cd5\u5206\u89e3\u5927\u89c4\u6a21\u534f\u65b9\u5dee\u77e9\u9635\uff0c\u5229\u7528\u529f\u80fd\u56de\u5f52\u5229\u7528\u65f6\u95f4\u52a8\u6001\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u529f\u80fd\u78c1\u5171\u632f\u6210\u50cf\u6570\u636e\u4e2d\u7684\u7a7a\u95f4\u548c\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u4e3a\u529f\u80fd\u8fde\u63a5\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u7ed3\u5408\u4e86\u77e9\u9635\u8865\u5168\u3001\u5206\u5e03\u5f0f\u8ba1\u7b97\u548c\u529f\u80fd\u56de\u5f52\u6280\u672f\uff0c\u4e3a\u529f\u80fd\u8fde\u63a5\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u4e14\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u56e0\u5b50\u5206\u6790\u5728\u529f\u80fd\u78c1\u5171\u632f\u6210\u50cf\u5e94\u7528\u4e2d\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.15374", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15374", "abs": "https://arxiv.org/abs/2510.15374", "authors": ["Zezhong Tan", "Hang Gao", "Xinhong Ma", "Feng Zhang", "Ziqiang Dong"], "title": "Towards Flash Thinking via Decoupled Advantage Policy Optimization", "comment": null, "summary": "Recent Large Reasoning Models (LRMs) have achieved remarkable performance in\nsolving complex problems via supervised fine-tuning (SFT) and reinforcement\nlearning (RL). Although existing RL algorithms significantly enhance model\naccuracy, they still suffer from excessively lengthy responses and overthinking\nissues, resulting in increased inference latency and computational consumption,\nespecially for simple tasks that require minimal reasoning. To address this, we\npropose a novel RL framework, DEPO, to reduce inefficient reasoning for models.\nOur method mainly consists of three core components: (1) an innovative\nadvantage decoupled algorithm to guide model reduction of inefficient tokens;\n(2) a difficulty-aware length penalty to lower the overall length of model\nresponses; (3) an advantage clipping method to prevent bias in policy\noptimization. In our experiments, applied to DeepSeek-Distill-Qwen-7B and\nDeepSeek-Distill-Qwen-1.5B as base models, DEPO achieves a significant\nreduction in sequence length by 39% and reduces excessive reasoning paths in\ninefficient tokens, while outperforming the base model in overall accuracy.", "AI": {"tldr": "DEPO\u662f\u4e00\u4e2a\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u65e8\u5728\u51cf\u5c11\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u4f4e\u6548\u63a8\u7406\uff0c\u901a\u8fc7\u89e3\u8026\u4f18\u52bf\u7b97\u6cd5\u3001\u96be\u5ea6\u611f\u77e5\u957f\u5ea6\u60e9\u7f5a\u548c\u4f18\u52bf\u526a\u88c1\u65b9\u6cd5\uff0c\u663e\u8457\u7f29\u77ed\u54cd\u5e94\u957f\u5ea639%\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u867d\u7136\u63d0\u9ad8\u4e86\u6a21\u578b\u51c6\u786e\u6027\uff0c\u4f46\u5b58\u5728\u54cd\u5e94\u8fc7\u957f\u548c\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u5bfc\u81f4\u63a8\u7406\u5ef6\u8fdf\u548c\u8ba1\u7b97\u6d88\u8017\u589e\u52a0\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u7b80\u5355\u4efb\u52a1\u3002", "method": "DEPO\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u521b\u65b0\u7684\u4f18\u52bf\u89e3\u8026\u7b97\u6cd5\u51cf\u5c11\u4f4e\u6548token\uff1b\u96be\u5ea6\u611f\u77e5\u957f\u5ea6\u60e9\u7f5a\u964d\u4f4e\u6574\u4f53\u54cd\u5e94\u957f\u5ea6\uff1b\u4f18\u52bf\u526a\u88c1\u65b9\u6cd5\u9632\u6b62\u7b56\u7565\u4f18\u5316\u504f\u5dee\u3002", "result": "\u5728DeepSeek-Distill-Qwen-7B\u548c1.5B\u6a21\u578b\u4e0a\uff0cDEPO\u5b9e\u73b0\u4e86\u5e8f\u5217\u957f\u5ea6\u51cf\u5c1139%\uff0c\u51cf\u5c11\u4e86\u4f4e\u6548token\u4e2d\u7684\u8fc7\u5ea6\u63a8\u7406\u8def\u5f84\uff0c\u540c\u65f6\u5728\u6574\u4f53\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u57fa\u7840\u6a21\u578b\u3002", "conclusion": "DEPO\u6709\u6548\u89e3\u51b3\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u4f4e\u6548\u63a8\u7406\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u54cd\u5e94\u957f\u5ea6\u548c\u8ba1\u7b97\u6d88\u8017\u3002"}}
{"id": "2510.15763", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.15763", "abs": "https://arxiv.org/abs/2510.15763", "authors": ["Qihao Peng", "Jiuyu Liu", "Qu Luo", "Yi Ma", "Pei Xiao", "Maged Elkashlan", "George K. Karagiannidis"], "title": "RIS-assisted Atomic MIMO Receiver", "comment": "Submitted to IEEE journals", "summary": "In this paper, we propose a novel and low-complexity atomic multiple-input\nmultiple-output (MIMO) receiver architecture assisted by a reconfigurable\nintelligent surface (RIS). By introducing RIS and utilizing pulse amplitude\nmodulation (PAM), the phase of the transmitted signal is effectively aligned\nwith that of the local oscillator (LO), thereby mitigating phase ambiguity and\nsubstantially reducing both signal detection complexity and overall receiver\ncomplexity.To tackle the resulting non-convex optimization problem, we\nreformulate it into a tractable form by minimizing the Frobenius norm of an\nequivalent matrix, which is efficiently solved using an Adam-based gradient\ndescent algorithm.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(RIS)\u7684\u4f4e\u590d\u6742\u5ea6\u539f\u5b50MIMO\u63a5\u6536\u5668\u67b6\u6784\uff0c\u901a\u8fc7PAM\u8c03\u5236\u548cRIS\u8f85\u52a9\u6765\u5bf9\u9f50\u4fe1\u53f7\u76f8\u4f4d\uff0c\u964d\u4f4e\u68c0\u6d4b\u590d\u6742\u5ea6\u548c\u63a5\u6536\u5668\u590d\u6742\u5ea6\uff0c\u5e76\u4f7f\u7528Adam\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u89e3\u51b3\u975e\u51f8\u4f18\u5316\u95ee\u9898\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edfMIMO\u63a5\u6536\u5668\u76f8\u4f4d\u6a21\u7cca\u548c\u590d\u6742\u5ea6\u9ad8\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5f15\u5165RIS\u548cPAM\u8c03\u5236\u6765\u6709\u6548\u5bf9\u9f50\u4fe1\u53f7\u76f8\u4f4d\uff0c\u4ece\u800c\u964d\u4f4e\u63a5\u6536\u5668\u7684\u590d\u6742\u5ea6\u3002", "method": "\u91c7\u7528RIS\u8f85\u52a9\u7684\u539f\u5b50MIMO\u63a5\u6536\u5668\u67b6\u6784\uff0c\u7ed3\u5408PAM\u8c03\u5236\u5bf9\u9f50\u4fe1\u53f7\u76f8\u4f4d\uff0c\u5c06\u975e\u51f8\u4f18\u5316\u95ee\u9898\u91cd\u6784\u4e3aFrobenius\u8303\u6570\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u5e76\u4f7f\u7528Adam\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u8fdb\u884c\u9ad8\u6548\u6c42\u89e3\u3002", "result": "\u8be5\u65b9\u6cd5\u6709\u6548\u7f13\u89e3\u4e86\u76f8\u4f4d\u6a21\u7cca\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u4fe1\u53f7\u68c0\u6d4b\u590d\u6742\u5ea6\u548c\u6574\u4f53\u63a5\u6536\u5668\u590d\u6742\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u7684RIS\u8f85\u52a9\u539f\u5b50MIMO\u63a5\u6536\u5668\u67b6\u6784\u662f\u4e00\u79cd\u6709\u6548\u7684\u4f4e\u590d\u6742\u5ea6\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u901a\u8fc7\u76f8\u4f4d\u5bf9\u9f50\u548c\u4f18\u5316\u7b97\u6cd5\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u4fe1\u53f7\u63a5\u6536\u3002"}}
{"id": "2510.15422", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15422", "abs": "https://arxiv.org/abs/2510.15422", "authors": ["Lin Wang"], "title": "Information Theory in Open-world Machine Learning Foundations, Frameworks, and Future Direction", "comment": null, "summary": "Open world Machine Learning (OWML) aims to develop intelligent systems\ncapable of recognizing known categories, rejecting unknown samples, and\ncontinually learning from novel information. Despite significant progress in\nopen set recognition, novelty detection, and continual learning, the field\nstill lacks a unified theoretical foundation that can quantify uncertainty,\ncharacterize information transfer, and explain learning adaptability in\ndynamic, nonstationary environments. This paper presents a comprehensive review\nof information theoretic approaches in open world machine learning, emphasizing\nhow core concepts such as entropy, mutual information, and Kullback Leibler\ndivergence provide a mathematical language for describing knowledge\nacquisition, uncertainty suppression, and risk control under open world\nconditions. We synthesize recent studies into three major research axes:\ninformation theoretic open set recognition enabling safe rejection of unknowns,\ninformation driven novelty discovery guiding new concept formation, and\ninformation retentive continual learning ensuring stable long term adaptation.\nFurthermore, we discuss theoretical connections between information theory and\nprovable learning frameworks, including PAC Bayes bounds, open-space risk\ntheory, and causal information flow, to establish a pathway toward provable and\ntrustworthy open world intelligence. Finally, the review identifies key open\nproblems and future research directions, such as the quantification of\ninformation risk, development of dynamic mutual information bounds, multimodal\ninformation fusion, and integration of information theory with causal reasoning\nand world model learning.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u4fe1\u606f\u8bba\u65b9\u6cd5\u5728\u5f00\u653e\u4e16\u754c\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u63a2\u8ba8\u4e86\u71b5\u3001\u4e92\u4fe1\u606f\u548cKL\u6563\u5ea6\u7b49\u6838\u5fc3\u6982\u5ff5\u5982\u4f55\u4e3a\u5f00\u653e\u4e16\u754c\u6761\u4ef6\u4e0b\u7684\u77e5\u8bc6\u83b7\u53d6\u3001\u4e0d\u786e\u5b9a\u6027\u6291\u5236\u548c\u98ce\u9669\u63a7\u5236\u63d0\u4f9b\u6570\u5b66\u8bed\u8a00\u3002", "motivation": "\u5f00\u653e\u4e16\u754c\u673a\u5668\u5b66\u4e60\u9886\u57df\u7f3a\u4e4f\u7edf\u4e00\u7684\u7406\u8bba\u57fa\u7840\u6765\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u3001\u8868\u5f81\u4fe1\u606f\u4f20\u9012\u548c\u89e3\u91ca\u52a8\u6001\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u7684\u5b66\u4e60\u9002\u5e94\u6027\u3002", "method": "\u901a\u8fc7\u4fe1\u606f\u8bba\u65b9\u6cd5\uff0c\u5c06\u8fd1\u671f\u7814\u7a76\u7efc\u5408\u4e3a\u4e09\u4e2a\u4e3b\u8981\u7814\u7a76\u65b9\u5411\uff1a\u4fe1\u606f\u8bba\u5f00\u653e\u96c6\u8bc6\u522b\u3001\u4fe1\u606f\u9a71\u52a8\u7684\u65b0\u9896\u6027\u53d1\u73b0\u548c\u4fe1\u606f\u4fdd\u7559\u7684\u6301\u7eed\u5b66\u4e60\u3002", "result": "\u5efa\u7acb\u4e86\u4fe1\u606f\u8bba\u4e0e\u53ef\u8bc1\u660e\u5b66\u4e60\u6846\u67b6\u4e4b\u95f4\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u5305\u62ecPAC\u8d1d\u53f6\u65af\u8fb9\u754c\u3001\u5f00\u653e\u7a7a\u95f4\u98ce\u9669\u7406\u8bba\u548c\u56e0\u679c\u4fe1\u606f\u6d41\uff0c\u4e3a\u53ef\u8bc1\u660e\u548c\u53ef\u4fe1\u8d56\u7684\u5f00\u653e\u4e16\u754c\u667a\u80fd\u5efa\u7acb\u8def\u5f84\u3002", "conclusion": "\u8bc6\u522b\u4e86\u5173\u952e\u5f00\u653e\u95ee\u9898\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5982\u4fe1\u606f\u98ce\u9669\u91cf\u5316\u3001\u52a8\u6001\u4e92\u4fe1\u606f\u8fb9\u754c\u5f00\u53d1\u3001\u591a\u6a21\u6001\u4fe1\u606f\u878d\u5408\u4ee5\u53ca\u4fe1\u606f\u8bba\u4e0e\u56e0\u679c\u63a8\u7406\u548c\u4e16\u754c\u6a21\u578b\u5b66\u4e60\u7684\u6574\u5408\u3002"}}
{"id": "2510.15416", "categories": ["cs.AI", "68T05, 68T42", "I.2.11; I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2510.15416", "abs": "https://arxiv.org/abs/2510.15416", "authors": ["Pavan C Shekar", "Ashwanth Krishnan"], "title": "Adaptive Minds: Empowering Agents with LoRA-as-Tools", "comment": "12 pages, 1 figure, 7 tables . Code available at:\n  https://github.com/qpiai/adaptive-minds", "summary": "We present Adaptive Minds, an agentic system that treats LoRA adapters as\ndomain-specific tools. Instead of relying on a single fine-tuned model or rigid\nrule-based routing, our approach empowers the base LLM itself to act as a\nsemantic router analyzing each query and dynamically selecting the most\nrelevant LoRA tool. This enables the agent to seamlessly switch between\ndifferent domain experts on demand. By combining the flexibility of multi-agent\norchestration with the efficiency of parameter-efficient fine-tuning, Adaptive\nMinds delivers accurate, specialized responses while preserving conversational\nability. The system is built with LangGraph for workflow management, supports\nboth API and web interfaces, and is fully open source, providing a scalable and\nextensible foundation for domain-adaptive AI assistance.", "AI": {"tldr": "Adaptive Minds\u662f\u4e00\u4e2a\u5c06LoRA\u9002\u914d\u5668\u4f5c\u4e3a\u9886\u57df\u4e13\u7528\u5de5\u5177\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u8ba9\u57fa\u7840LLM\u4f5c\u4e3a\u8bed\u4e49\u8def\u7531\u5668\u52a8\u6001\u9009\u62e9\u6700\u76f8\u5173\u7684LoRA\u5de5\u5177\uff0c\u5b9e\u73b0\u6309\u9700\u5207\u6362\u9886\u57df\u4e13\u5bb6\u3002", "motivation": "\u65e8\u5728\u89e3\u51b3\u5355\u4e00\u5fae\u8c03\u6a21\u578b\u6216\u57fa\u4e8e\u89c4\u5219\u8def\u7531\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u7f16\u6392\u7684\u7075\u6d3b\u6027\u548c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u7684\u9ad8\u6548\u6027\uff0c\u63d0\u4f9b\u51c6\u786e\u7684\u4e13\u4e1a\u5316\u54cd\u5e94\u540c\u65f6\u4fdd\u6301\u5bf9\u8bdd\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u57fa\u7840LLM\u4f5c\u4e3a\u8bed\u4e49\u8def\u7531\u5668\u5206\u6790\u6bcf\u4e2a\u67e5\u8be2\uff0c\u52a8\u6001\u9009\u62e9\u6700\u76f8\u5173\u7684LoRA\u5de5\u5177\uff1b\u57fa\u4e8eLangGraph\u6784\u5efa\u5de5\u4f5c\u6d41\u7ba1\u7406\uff0c\u652f\u6301API\u548cWeb\u63a5\u53e3\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u65e0\u7f1d\u5728\u4e0d\u540c\u9886\u57df\u4e13\u5bb6\u4e4b\u95f4\u5207\u6362\uff0c\u63d0\u4f9b\u51c6\u786e\u7684\u4e13\u4e1a\u5316\u54cd\u5e94\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u8bdd\u80fd\u529b\uff1b\u7cfb\u7edf\u5b8c\u5168\u5f00\u6e90\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u548c\u53ef\u6269\u5c55\u7684\u9886\u57df\u81ea\u9002\u5e94AI\u52a9\u624b\u57fa\u7840\u3002", "conclusion": "Adaptive Minds\u901a\u8fc7\u5c06LoRA\u9002\u914d\u5668\u4f5c\u4e3a\u5de5\u5177\u7684\u52a8\u6001\u9009\u62e9\u673a\u5236\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u7075\u6d3b\u9ad8\u6548\u7684\u9886\u57df\u81ea\u9002\u5e94AI\u52a9\u624b\uff0c\u4e3a\u6784\u5efa\u53ef\u6269\u5c55\u7684\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.15005", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15005", "abs": "https://arxiv.org/abs/2510.15005", "authors": ["Allen Daniel Sunny"], "title": "TangledFeatures: Robust Feature Selection in Highly Correlated Spaces", "comment": "Accepted for poster presentation at the Machine Learning for\n  Structural Biology (MLSB) Workshop @ NeurIPS 2025, co-located with NeurIPS\n  2025 (San Diego, USA). Non-archival", "summary": "Feature selection is a fundamental step in model development, shaping both\npredictive performance and interpretability. Yet, most widely used methods\nfocus on predictive accuracy, and their performance degrades in the presence of\ncorrelated predictors. To address this gap, we introduce TangledFeatures, a\nframework for feature selection in correlated feature spaces. It identifies\nrepresentative features from groups of entangled predictors, reducing\nredundancy while retaining explanatory power. The resulting feature subset can\nbe directly applied in downstream models, offering a more interpretable and\nstable basis for analysis compared to traditional selection techniques. We\ndemonstrate the effectiveness of TangledFeatures on Alanine Dipeptide, applying\nit to the prediction of backbone torsional angles and show that the selected\nfeatures correspond to structurally meaningful intra-atomic distances that\nexplain variation in these angles.", "AI": {"tldr": "\u63d0\u51fa\u4e86TangledFeatures\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u76f8\u5173\u7279\u5f81\u7a7a\u95f4\u4e2d\u8fdb\u884c\u7279\u5f81\u9009\u62e9\uff0c\u901a\u8fc7\u8bc6\u522b\u7ea0\u7f20\u9884\u6d4b\u56e0\u5b50\u7ec4\u4e2d\u7684\u4ee3\u8868\u6027\u7279\u5f81\u6765\u51cf\u5c11\u5197\u4f59\uff0c\u540c\u65f6\u4fdd\u7559\u89e3\u91ca\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u4f46\u5728\u5b58\u5728\u76f8\u5173\u9884\u6d4b\u56e0\u5b50\u7684\u60c5\u51b5\u4e0b\u6027\u80fd\u4f1a\u4e0b\u964d\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5904\u7406\u76f8\u5173\u7279\u5f81\u7a7a\u95f4\u7684\u65b9\u6cd5\u3002", "method": "\u5f15\u5165TangledFeatures\u6846\u67b6\uff0c\u4ece\u7ea0\u7f20\u7684\u9884\u6d4b\u56e0\u5b50\u7ec4\u4e2d\u8bc6\u522b\u4ee3\u8868\u6027\u7279\u5f81\uff0c\u51cf\u5c11\u5197\u4f59\u540c\u65f6\u4fdd\u6301\u89e3\u91ca\u529b\u3002", "result": "\u5728Alanine Dipeptide\u6570\u636e\u96c6\u4e0a\u5e94\u7528\u8be5\u6846\u67b6\u9884\u6d4b\u4e3b\u94fe\u626d\u8f6c\u89d2\uff0c\u6240\u9009\u7279\u5f81\u5bf9\u5e94\u4e8e\u7ed3\u6784\u4e0a\u6709\u610f\u4e49\u7684\u539f\u5b50\u5185\u8ddd\u79bb\uff0c\u80fd\u591f\u89e3\u91ca\u8fd9\u4e9b\u89d2\u5ea6\u7684\u53d8\u5316\u3002", "conclusion": "TangledFeatures\u63d0\u4f9b\u4e86\u4e00\u79cd\u6bd4\u4f20\u7edf\u9009\u62e9\u6280\u672f\u66f4\u53ef\u89e3\u91ca\u548c\u7a33\u5b9a\u7684\u5206\u6790\u57fa\u7840\uff0c\u53ef\u76f4\u63a5\u5e94\u7528\u4e8e\u4e0b\u6e38\u6a21\u578b\u3002"}}
{"id": "2510.15006", "categories": ["cs.LG", "I.2.6"], "pdf": "https://arxiv.org/pdf/2510.15006", "abs": "https://arxiv.org/abs/2510.15006", "authors": ["Rijul Tandon", "Peter Vamplew", "Cameron Foale"], "title": "ES-C51: Expected Sarsa Based C51 Distributional Reinforcement Learning Algorithm", "comment": null, "summary": "In most value-based reinforcement learning (RL) algorithms, the agent\nestimates only the expected reward for each action and selects the action with\nthe highest reward. In contrast, Distributional Reinforcement Learning (DRL)\nestimates the entire probability distribution of possible rewards, providing\nricher information about uncertainty and variability. C51 is a popular DRL\nalgorithm for discrete action spaces. It uses a Q-learning approach, where the\ndistribution is learned using a greedy Bellman update. However, this can cause\nproblems if multiple actions at a state have similar expected reward but with\ndifferent distributions, as the algorithm may not learn a stable distribution.\nThis study presents a modified version of C51 (ES-C51) that replaces the greedy\nQ-learning update with an Expected Sarsa update, which uses a softmax\ncalculation to combine information from all possible actions at a state rather\nthan relying on a single best action. This reduces instability when actions\nhave similar expected rewards and allows the agent to learn higher-performing\npolicies. This approach is evaluated on classic control environments from Gym,\nand Atari-10 games. For a fair comparison, we modify the standard C51's\nexploration strategy from e-greedy to softmax, which we refer to as QL-C51 (Q-\nLearning based C51). The results demonstrate that ES-C51 outperforms QL-C51\nacross many environments.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684C51\u7b97\u6cd5\uff08ES-C51\uff09\uff0c\u7528Expected Sarsa\u66f4\u65b0\u66ff\u4ee3\u8d2a\u5a6aQ\u5b66\u4e60\u66f4\u65b0\uff0c\u901a\u8fc7softmax\u8ba1\u7b97\u7ed3\u5408\u6240\u6709\u53ef\u80fd\u52a8\u4f5c\u7684\u4fe1\u606f\uff0c\u5728\u52a8\u4f5c\u5177\u6709\u76f8\u4f3c\u671f\u671b\u5956\u52b1\u65f6\u51cf\u5c11\u4e0d\u7a33\u5b9a\u6027\uff0c\u4ece\u800c\u5b66\u4e60\u5230\u66f4\u9ad8\u6027\u80fd\u7684\u7b56\u7565\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u4ef7\u503c\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u53ea\u4f30\u8ba1\u6bcf\u4e2a\u52a8\u4f5c\u7684\u671f\u671b\u5956\u52b1\uff0c\u800c\u5206\u5e03\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u4f30\u8ba1\u53ef\u80fd\u5956\u52b1\u7684\u6574\u4e2a\u6982\u7387\u5206\u5e03\u3002C51\u662f\u79bb\u6563\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u6d41\u884c\u7684DRL\u7b97\u6cd5\uff0c\u4f46\u4f7f\u7528\u8d2a\u5a6aBellman\u66f4\u65b0\u53ef\u80fd\u5bfc\u81f4\u5728\u591a\u4e2a\u52a8\u4f5c\u5177\u6709\u76f8\u4f3c\u671f\u671b\u5956\u52b1\u4f46\u4e0d\u540c\u5206\u5e03\u65f6\u5b66\u4e60\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51faES-C51\u7b97\u6cd5\uff0c\u5c06C51\u7684\u8d2a\u5a6aQ\u5b66\u4e60\u66f4\u65b0\u66ff\u6362\u4e3aExpected Sarsa\u66f4\u65b0\uff0c\u4f7f\u7528softmax\u8ba1\u7b97\u7ed3\u5408\u6240\u6709\u53ef\u80fd\u52a8\u4f5c\u7684\u4fe1\u606f\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56\u5355\u4e2a\u6700\u4f73\u52a8\u4f5c\u3002\u540c\u65f6\u5c06\u6807\u51c6C51\u7684\u63a2\u7d22\u7b56\u7565\u4ece\u03b5-greedy\u6539\u4e3asoftmax\u4f5c\u4e3a\u516c\u5e73\u6bd4\u8f83\u57fa\u51c6\uff08QL-C51\uff09\u3002", "result": "\u5728Gym\u7684\u7ecf\u5178\u63a7\u5236\u73af\u5883\u548cAtari-10\u6e38\u620f\u4e0a\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660eES-C51\u5728\u591a\u4e2a\u73af\u5883\u4e2d\u4f18\u4e8eQL-C51\u3002", "conclusion": "\u4f7f\u7528Expected Sarsa\u66f4\u65b0\u66ff\u4ee3\u8d2a\u5a6aQ\u5b66\u4e60\u66f4\u65b0\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u5206\u5e03\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4e0d\u7a33\u5b9a\u6027\uff0c\u7279\u522b\u662f\u5728\u52a8\u4f5c\u5177\u6709\u76f8\u4f3c\u671f\u671b\u5956\u52b1\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u591f\u5b66\u4e60\u5230\u66f4\u9ad8\u6027\u80fd\u7684\u7b56\u7565\u3002"}}
{"id": "2510.15591", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.15591", "abs": "https://arxiv.org/abs/2510.15591", "authors": ["Lavanya Umapathy", "Patricia M Johnson", "Tarun Dutt", "Angela Tong", "Madhur Nayan", "Hersh Chandarana", "Daniel K Sodickson"], "title": "Context-aware deep learning using individualized prior information reduces false positives in disease risk prediction and longitudinal health assessment", "comment": "18 pages, 5 figures, 1 table", "summary": "Temporal context in medicine is valuable in assessing key changes in patient\nhealth over time. We developed a machine learning framework to integrate\ndiverse context from prior visits to improve health monitoring, especially when\nprior visits are limited and their frequency is variable. Our model first\nestimates initial risk of disease using medical data from the most recent\npatient visit, then refines this assessment using information digested from\npreviously collected imaging and/or clinical biomarkers. We applied our\nframework to prostate cancer (PCa) risk prediction using data from a large\npopulation (28,342 patients, 39,013 magnetic resonance imaging scans, 68,931\nblood tests) collected over nearly a decade. For predictions of the risk of\nclinically significant PCa at the time of the visit, integrating prior context\ndirectly converted false positives to true negatives, increasing overall\nspecificity while preserving high sensitivity. False positive rates were\nreduced progressively from 51% to 33% when integrating information from up to\nthree prior imaging examinations, as compared to using data from a single\nvisit, and were further reduced to 24% when also including additional context\nfrom prior clinical data. For predicting the risk of PCa within five years of\nthe visit, incorporating prior context reduced false positive rates still\nfurther (64% to 9%). Our findings show that information collected over time\nprovides relevant context to enhance the specificity of medical risk\nprediction. For a wide range of progressive conditions, sufficient reduction of\nfalse positive rates using context could offer a pathway to expand longitudinal\nhealth monitoring programs to large populations with comparatively low baseline\nrisk of disease, leading to earlier detection and improved health outcomes.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6574\u5408\u60a3\u8005\u5386\u53f2\u5c31\u8bca\u4fe1\u606f\u7684\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5f53\u524d\u548c\u65e2\u5f80\u7684\u533b\u5b66\u6570\u636e\u6765\u6539\u8fdb\u524d\u5217\u817a\u764c\u98ce\u9669\u9884\u6d4b\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5047\u9633\u6027\u7387\u3002", "motivation": "\u533b\u5b66\u4e2d\u7684\u65f6\u95f4\u80cc\u666f\u4fe1\u606f\u5bf9\u4e8e\u8bc4\u4f30\u60a3\u8005\u5065\u5eb7\u72b6\u51b5\u968f\u65f6\u95f4\u53d8\u5316\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u65e2\u5f80\u5c31\u8bca\u6b21\u6570\u6709\u9650\u4e14\u9891\u7387\u4e0d\u56fa\u5b9a\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u6574\u5408\u591a\u6837\u5316\u7684\u5386\u53f2\u80cc\u666f\u4fe1\u606f\u6765\u6539\u5584\u5065\u5eb7\u76d1\u6d4b\u3002", "method": "\u6a21\u578b\u9996\u5148\u4f7f\u7528\u6700\u8fd1\u4e00\u6b21\u5c31\u8bca\u7684\u533b\u5b66\u6570\u636e\u4f30\u8ba1\u75be\u75c5\u521d\u59cb\u98ce\u9669\uff0c\u7136\u540e\u901a\u8fc7\u6d88\u5316\u65e2\u5f80\u6536\u96c6\u7684\u5f71\u50cf\u5b66\u548c/\u6216\u4e34\u5e8a\u751f\u7269\u6807\u5fd7\u7269\u4fe1\u606f\u6765\u5b8c\u5584\u8bc4\u4f30\u3002", "result": "\u6574\u5408\u5386\u53f2\u80cc\u666f\u4fe1\u606f\u5c06\u5047\u9633\u6027\u8f6c\u5316\u4e3a\u771f\u9634\u6027\uff0c\u603b\u4f53\u7279\u5f02\u6027\u63d0\u9ad8\u540c\u65f6\u4fdd\u6301\u9ad8\u654f\u611f\u6027\u3002\u6574\u5408\u6700\u591a\u4e09\u6b21\u65e2\u5f80\u5f71\u50cf\u68c0\u67e5\u4fe1\u606f\u65f6\uff0c\u5047\u9633\u6027\u7387\u4ece51%\u964d\u81f333%\uff0c\u52a0\u5165\u65e2\u5f80\u4e34\u5e8a\u6570\u636e\u540e\u8fdb\u4e00\u6b65\u964d\u81f324%\u3002\u9884\u6d4b\u4e94\u5e74\u5185\u524d\u5217\u817a\u764c\u98ce\u9669\u65f6\uff0c\u5047\u9633\u6027\u7387\u4ece64%\u964d\u81f39%\u3002", "conclusion": "\u968f\u65f6\u95f4\u6536\u96c6\u7684\u4fe1\u606f\u63d0\u4f9b\u4e86\u76f8\u5173\u80cc\u666f\uff0c\u53ef\u589e\u5f3a\u533b\u5b66\u98ce\u9669\u9884\u6d4b\u7684\u7279\u5f02\u6027\u3002\u5bf9\u4e8e\u5e7f\u6cdb\u8fdb\u5c55\u6027\u75be\u75c5\uff0c\u901a\u8fc7\u80cc\u666f\u4fe1\u606f\u5145\u5206\u964d\u4f4e\u5047\u9633\u6027\u7387\u53ef\u4e3a\u6269\u5c55\u7eb5\u5411\u5065\u5eb7\u76d1\u6d4b\u9879\u76ee\u63d0\u4f9b\u9014\u5f84\uff0c\u4ece\u800c\u5b9e\u73b0\u65e9\u671f\u68c0\u6d4b\u548c\u6539\u5584\u5065\u5eb7\u7ed3\u679c\u3002"}}
{"id": "2510.15669", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15669", "abs": "https://arxiv.org/abs/2510.15669", "authors": ["Veranika Boukun", "J\u00f6rg L\u00fccke"], "title": "Disentanglement of Sources in a Multi-Stream Variational Autoencoder", "comment": null, "summary": "Variational autoencoders (VAEs) are a leading approach to address the problem\nof learning disentangled representations. Typically a single VAE is used and\ndisentangled representations are sought in its continuous latent space. Here we\nexplore a different approach by using discrete latents to combine\nVAE-representations of individual sources. The combination is done based on an\nexplicit model for source combination, and we here use a linear combination\nmodel which is well suited, e.g., for acoustic data. We formally define such a\nmulti-stream VAE (MS-VAE) approach, derive its inference and learning\nequations, and we numerically investigate its principled functionality. The\nMS-VAE is domain-agnostic, and we here explore its ability to separate sources\ninto different streams using superimposed hand-written digits, and mixed\nacoustic sources in a speaker diarization task. We observe a clear separation\nof digits, and on speaker diarization we observe an especially low rate of\nmissed speakers. Numerical experiments further highlight the flexibility of the\napproach across varying amounts of supervision and training data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6d41\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08MS-VAE\uff09\uff0c\u4f7f\u7528\u79bb\u6563\u9690\u53d8\u91cf\u6765\u7ec4\u5408\u5355\u4e2a\u6e90\u7684VAE\u8868\u793a\uff0c\u901a\u8fc7\u7ebf\u6027\u7ec4\u5408\u6a21\u578b\u5b9e\u73b0\u6e90\u5206\u79bb\uff0c\u5e76\u5728\u624b\u5199\u6570\u5b57\u53e0\u52a0\u548c\u8bf4\u8bdd\u4eba\u65e5\u5fd7\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edfVAE\u901a\u5e38\u4f7f\u7528\u5355\u4e00\u8fde\u7eed\u9690\u7a7a\u95f4\u5b66\u4e60\u89e3\u8026\u8868\u793a\uff0c\u672c\u6587\u63a2\u7d22\u4f7f\u7528\u79bb\u6563\u9690\u53d8\u91cf\u6765\u7ec4\u5408\u591a\u4e2a\u6e90\u7684VAE\u8868\u793a\uff0c\u7279\u522b\u9002\u7528\u4e8e\u58f0\u5b66\u6570\u636e\u7b49\u573a\u666f\u3002", "method": "\u63d0\u51fa\u591a\u6d41\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08MS-VAE\uff09\uff0c\u57fa\u4e8e\u663e\u5f0f\u7684\u6e90\u7ec4\u5408\u6a21\u578b\uff08\u7ebf\u6027\u7ec4\u5408\uff09\uff0c\u63a8\u5bfc\u4e86\u5176\u63a8\u7406\u548c\u5b66\u4e60\u65b9\u7a0b\uff0c\u5e76\u5728\u624b\u5199\u6570\u5b57\u53e0\u52a0\u548c\u8bf4\u8bdd\u4eba\u65e5\u5fd7\u4efb\u52a1\u4e0a\u8fdb\u884c\u6570\u503c\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u663e\u793aMS-VAE\u80fd\u591f\u6e05\u6670\u5206\u79bb\u53e0\u52a0\u7684\u624b\u5199\u6570\u5b57\uff0c\u5728\u8bf4\u8bdd\u4eba\u65e5\u5fd7\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u7279\u522b\u4f4e\u7684\u8bf4\u8bdd\u4eba\u6f0f\u68c0\u7387\uff0c\u4e14\u5728\u4e0d\u540c\u76d1\u7763\u7a0b\u5ea6\u548c\u8bad\u7ec3\u6570\u636e\u91cf\u4e0b\u90fd\u8868\u73b0\u51fa\u7075\u6d3b\u6027\u3002", "conclusion": "MS-VAE\u662f\u4e00\u79cd\u9886\u57df\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u5206\u79bb\u591a\u4e2a\u6e90\uff0c\u5728\u6e90\u5206\u79bb\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u8bf4\u8bdd\u4eba\u65e5\u5fd7\u4efb\u52a1\u4e2d\u663e\u8457\u964d\u4f4e\u4e86\u6f0f\u68c0\u7387\u3002"}}
{"id": "2510.15010", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15010", "abs": "https://arxiv.org/abs/2510.15010", "authors": ["Rekha R Nair", "Tina Babu", "Alavikunhu Panthakkan", "Balamurugan Balusamy", "Wathiq Mansoor"], "title": "Hybrid Autoencoder-Based Framework for Early Fault Detection in Wind Turbines", "comment": null, "summary": "Wind turbine reliability is critical to the growing renewable energy sector,\nwhere early fault detection significantly reduces downtime and maintenance\ncosts. This paper introduces a novel ensemble-based deep learning framework for\nunsupervised anomaly detection in wind turbines. The method integrates\nVariational Autoencoders (VAE), LSTM Autoencoders, and Transformer\narchitectures, each capturing different temporal and contextual patterns from\nhigh-dimensional SCADA data. A unique feature engineering pipeline extracts\ntemporal, statistical, and frequency-domain indicators, which are then\nprocessed by the deep models. Ensemble scoring combines model predictions,\nfollowed by adaptive thresholding to detect operational anomalies without\nrequiring labeled fault data. Evaluated on the CARE dataset containing 89 years\nof real-world turbine data across three wind farms, the proposed method\nachieves an AUC-ROC of 0.947 and early fault detection up to 48 hours prior to\nfailure. This approach offers significant societal value by enabling predictive\nmaintenance, reducing turbine failures, and enhancing operational efficiency in\nlarge-scale wind energy deployments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u96c6\u6210\u6df1\u5ea6\u5b66\u4e60\u7684\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u98ce\u529b\u6da1\u8f6e\u673a\u65e9\u671f\u6545\u969c\u68c0\u6d4b\uff0c\u7ed3\u5408VAE\u3001LSTM\u81ea\u7f16\u7801\u5668\u548cTransformer\u67b6\u6784\uff0c\u5728\u771f\u5b9eSCADA\u6570\u636e\u4e0a\u5b9e\u73b0AUC-ROC 0.947\u548c48\u5c0f\u65f6\u63d0\u524d\u6545\u969c\u68c0\u6d4b\u3002", "motivation": "\u98ce\u529b\u6da1\u8f6e\u673a\u53ef\u9760\u6027\u5bf9\u53ef\u518d\u751f\u80fd\u6e90\u90e8\u95e8\u81f3\u5173\u91cd\u8981\uff0c\u65e9\u671f\u6545\u969c\u68c0\u6d4b\u80fd\u663e\u8457\u51cf\u5c11\u505c\u673a\u65f6\u95f4\u548c\u7ef4\u62a4\u6210\u672c\u3002", "method": "\u96c6\u6210\u53d8\u5206\u81ea\u7f16\u7801\u5668\u3001LSTM\u81ea\u7f16\u7801\u5668\u548cTransformer\u67b6\u6784\uff0c\u7ed3\u5408\u7279\u5f81\u5de5\u7a0b\u63d0\u53d6\u65f6\u57df\u3001\u7edf\u8ba1\u548c\u9891\u57df\u6307\u6807\uff0c\u901a\u8fc7\u96c6\u6210\u8bc4\u5206\u548c\u81ea\u9002\u5e94\u9608\u503c\u8fdb\u884c\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "\u5728\u5305\u542b89\u5e74\u771f\u5b9e\u6da1\u8f6e\u673a\u6570\u636e\u7684CARE\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cAUC-ROC\u8fbe\u52300.947\uff0c\u80fd\u591f\u63d0\u524d48\u5c0f\u65f6\u68c0\u6d4b\u5230\u6545\u969c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u9884\u6d4b\u6027\u7ef4\u62a4\u663e\u8457\u51cf\u5c11\u6da1\u8f6e\u673a\u6545\u969c\uff0c\u63d0\u9ad8\u5927\u89c4\u6a21\u98ce\u80fd\u90e8\u7f72\u7684\u8fd0\u8425\u6548\u7387\uff0c\u5177\u6709\u91cd\u8981\u793e\u4f1a\u4ef7\u503c\u3002"}}
{"id": "2510.15624", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.15624", "abs": "https://arxiv.org/abs/2510.15624", "authors": ["Ed Li", "Junyu Ren", "Xintian Pan", "Cat Yan", "Chuanhao Li", "Dirk Bergemann", "Zhuoran Yang"], "title": "Build Your Personalized Research Group: A Multiagent Framework for Continual and Interactive Science Automation", "comment": "37 pages, 5 figures. Code: https://github.com/ltjed/freephdlabor", "summary": "The automation of scientific discovery represents a critical milestone in\nArtificial Intelligence (AI) research. However, existing agentic systems for\nscience suffer from two fundamental limitations: rigid, pre-programmed\nworkflows that cannot adapt to intermediate findings, and inadequate context\nmanagement that hinders long-horizon research. We present\n\\texttt{freephdlabor}, an open-source multiagent framework featuring\n\\textit{fully dynamic workflows} determined by real-time agent reasoning and a\n\\coloremph{\\textit{modular architecture}} enabling seamless customization --\nusers can modify, add, or remove agents to address domain-specific\nrequirements. The framework provides comprehensive infrastructure including\n\\textit{automatic context compaction}, \\textit{workspace-based communication}\nto prevent information degradation, \\textit{memory persistence} across\nsessions, and \\textit{non-blocking human intervention} mechanisms. These\nfeatures collectively transform automated research from isolated, single-run\nattempts into \\textit{continual research programs} that build systematically on\nprior explorations and incorporate human feedback. By providing both the\narchitectural principles and practical implementation for building customizable\nco-scientist systems, this work aims to facilitate broader adoption of\nautomated research across scientific domains, enabling practitioners to deploy\ninteractive multiagent systems that autonomously conduct end-to-end research --\nfrom ideation through experimentation to publication-ready manuscripts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3afreephdlabor\u7684\u5f00\u6e90\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u5de5\u4f5c\u6d41\u548c\u6a21\u5757\u5316\u67b6\u6784\u5b9e\u73b0\u79d1\u5b66\u53d1\u73b0\u7684\u81ea\u52a8\u5316\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7cfb\u7edf\u5de5\u4f5c\u6d41\u7a0b\u50f5\u5316\u548c\u4e0a\u4e0b\u6587\u7ba1\u7406\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u79d1\u5b66\u53d1\u73b0\u81ea\u52a8\u5316\u7cfb\u7edf\u5b58\u5728\u4e24\u4e2a\u6839\u672c\u9650\u5236\uff1a\u50f5\u5316\u7684\u9884\u7f16\u7a0b\u5de5\u4f5c\u6d41\u7a0b\u65e0\u6cd5\u9002\u5e94\u4e2d\u95f4\u53d1\u73b0\uff0c\u4ee5\u53ca\u4e0d\u5145\u5206\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u963b\u788d\u4e86\u957f\u671f\u7814\u7a76\u3002", "method": "\u91c7\u7528\u5b8c\u5168\u52a8\u6001\u5de5\u4f5c\u6d41\uff08\u7531\u5b9e\u65f6\u667a\u80fd\u4f53\u63a8\u7406\u51b3\u5b9a\uff09\u3001\u6a21\u5757\u5316\u67b6\u6784\uff08\u5141\u8bb8\u7528\u6237\u4fee\u6539\u3001\u6dfb\u52a0\u6216\u79fb\u9664\u667a\u80fd\u4f53\uff09\u3001\u81ea\u52a8\u4e0a\u4e0b\u6587\u538b\u7f29\u3001\u57fa\u4e8e\u5de5\u4f5c\u7a7a\u95f4\u7684\u901a\u4fe1\u3001\u8de8\u4f1a\u8bdd\u5185\u5b58\u6301\u4e45\u5316\u548c\u975e\u963b\u585e\u4eba\u5de5\u5e72\u9884\u673a\u5236\u3002", "result": "\u8be5\u6846\u67b6\u5c06\u81ea\u52a8\u5316\u7814\u7a76\u4ece\u5b64\u7acb\u7684\u5355\u6b21\u5c1d\u8bd5\u8f6c\u53d8\u4e3a\u6301\u7eed\u7684\u7814\u7a76\u7a0b\u5e8f\uff0c\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u5efa\u7acb\u5728\u5148\u524d\u63a2\u7d22\u57fa\u7840\u4e0a\u5e76\u6574\u5408\u4eba\u7c7b\u53cd\u9988\u3002", "conclusion": "\u901a\u8fc7\u63d0\u4f9b\u6784\u5efa\u53ef\u5b9a\u5236\u5408\u4f5c\u79d1\u5b66\u5bb6\u7cfb\u7edf\u7684\u67b6\u6784\u539f\u5219\u548c\u5b9e\u9645\u5b9e\u73b0\uff0c\u8fd9\u9879\u5de5\u4f5c\u65e8\u5728\u4fc3\u8fdb\u81ea\u52a8\u5316\u7814\u7a76\u5728\u79d1\u5b66\u9886\u57df\u7684\u66f4\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f7f\u4ece\u4e1a\u8005\u80fd\u591f\u90e8\u7f72\u4ea4\u4e92\u5f0f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6765\u81ea\u4e3b\u8fdb\u884c\u7aef\u5230\u7aef\u7814\u7a76\u3002"}}
{"id": "2510.15817", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15817", "abs": "https://arxiv.org/abs/2510.15817", "authors": ["Camille Touron", "Gabriel V. Cardoso", "Julyan Arbel", "Pedro L. C. Rodrigues"], "title": "Error analysis of a compositional score-based algorithm for simulation-based inference", "comment": null, "summary": "Simulation-based inference (SBI) has become a widely used framework in\napplied sciences for estimating the parameters of stochastic models that best\nexplain experimental observations. A central question in this setting is how to\neffectively combine multiple observations in order to improve parameter\ninference and obtain sharper posterior distributions. Recent advances in\nscore-based diffusion methods address this problem by constructing a\ncompositional score, obtained by aggregating individual posterior scores within\nthe diffusion process. While it is natural to suspect that the accumulation of\nindividual errors may significantly degrade sampling quality as the number of\nobservations grows, this important theoretical issue has so far remained\nunexplored. In this paper, we study the compositional score produced by the\nGAUSS algorithm of Linhart et al. (2024) and establish an upper bound on its\nmean squared error in terms of both the individual score errors and the number\nof observations. We illustrate our theoretical findings on a Gaussian example,\nwhere all analytical expressions can be derived in a closed form.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u6269\u6563\u7684\u6a21\u62df\u63a8\u7406\u4e2d\u7ec4\u5408\u8bc4\u5206\u65b9\u6cd5\u7684\u8bef\u5dee\u7d2f\u79ef\u95ee\u9898\uff0c\u4e3aGAUSS\u7b97\u6cd5\u5efa\u7acb\u4e86\u8bef\u5dee\u4e0a\u754c\uff0c\u5e76\u901a\u8fc7\u9ad8\u65af\u793a\u4f8b\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002", "motivation": "\u5728\u57fa\u4e8e\u6a21\u62df\u7684\u63a8\u7406\u4e2d\uff0c\u5982\u4f55\u6709\u6548\u7ec4\u5408\u591a\u4e2a\u89c2\u6d4b\u6570\u636e\u6765\u6539\u8fdb\u53c2\u6570\u63a8\u65ad\u662f\u4e00\u4e2a\u6838\u5fc3\u95ee\u9898\u3002\u867d\u7136\u6269\u6563\u65b9\u6cd5\u901a\u8fc7\u6784\u5efa\u7ec4\u5408\u8bc4\u5206\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f46\u968f\u7740\u89c2\u6d4b\u6570\u91cf\u589e\u52a0\uff0c\u4e2a\u4f53\u8bef\u5dee\u7d2f\u79ef\u53ef\u80fd\u663e\u8457\u964d\u4f4e\u91c7\u6837\u8d28\u91cf\uff0c\u8fd9\u4e00\u91cd\u8981\u7406\u8bba\u95ee\u9898\u5c1a\u672a\u88ab\u63a2\u7d22\u3002", "method": "\u7814\u7a76GAUSS\u7b97\u6cd5\u4ea7\u751f\u7684\u7ec4\u5408\u8bc4\u5206\uff0c\u5efa\u7acb\u5176\u5747\u65b9\u8bef\u5dee\u7684\u4e0a\u754c\uff0c\u8be5\u4e0a\u754c\u4e0e\u4e2a\u4f53\u8bc4\u5206\u8bef\u5dee\u548c\u89c2\u6d4b\u6570\u91cf\u76f8\u5173\uff0c\u5e76\u5728\u9ad8\u65af\u793a\u4f8b\u4e2d\u63a8\u5bfc\u6240\u6709\u89e3\u6790\u8868\u8fbe\u5f0f\u3002", "result": "\u5efa\u7acb\u4e86\u7ec4\u5408\u8bc4\u5206\u5747\u65b9\u8bef\u5dee\u7684\u4e0a\u754c\uff0c\u8868\u660e\u8bef\u5dee\u968f\u89c2\u6d4b\u6570\u91cf\u589e\u52a0\u800c\u7d2f\u79ef\uff0c\u4f46\u5728\u9ad8\u65af\u793a\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u7684\u6b63\u786e\u6027\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u5206\u6790\u4e86\u7ec4\u5408\u8bc4\u5206\u65b9\u6cd5\u4e2d\u7684\u8bef\u5dee\u7d2f\u79ef\u95ee\u9898\uff0c\u4e3a\u57fa\u4e8e\u6269\u6563\u7684\u6a21\u62df\u63a8\u7406\u65b9\u6cd5\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u7406\u8bba\u4fdd\u8bc1\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u591a\u89c2\u6d4b\u6570\u636e\u7ec4\u5408\u5bf9\u53c2\u6570\u63a8\u65ad\u8d28\u91cf\u7684\u5f71\u54cd\u3002"}}
{"id": "2510.15727", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.15727", "abs": "https://arxiv.org/abs/2510.15727", "authors": ["Sai Yashwant", "Anurag Dubey", "Praneeth Paikray", "Gantala Thulsiram"], "title": "Invoice Information Extraction: Methods and Performance Evaluation", "comment": null, "summary": "This paper presents methods for extracting structured information from\ninvoice documents and proposes a set of evaluation metrics (EM) to assess the\naccuracy of the extracted data against annotated ground truth. The approach\ninvolves pre-processing scanned or digital invoices, applying Docling and\nLlamaCloud Services to identify and extract key fields such as invoice number,\ndate, total amount, and vendor details. To ensure the reliability of the\nextraction process, we establish a robust evaluation framework comprising\nfield-level precision, consistency check failures, and exact match accuracy.\nThe proposed metrics provide a standardized way to compare different extraction\nmethods and highlight strengths and weaknesses in field-specific performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4ece\u53d1\u7968\u6587\u6863\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u4fe1\u606f\u7684\u65b9\u6cd5\uff0c\u5e76\u5efa\u7acb\u4e86\u4e00\u5957\u8bc4\u4f30\u6307\u6807\u6765\u8861\u91cf\u63d0\u53d6\u6570\u636e\u4e0e\u6807\u6ce8\u771f\u5b9e\u503c\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u9700\u8981\u6807\u51c6\u5316\u8bc4\u4f30\u53d1\u7968\u4fe1\u606f\u63d0\u53d6\u65b9\u6cd5\uff0c\u6bd4\u8f83\u4e0d\u540c\u63d0\u53d6\u6280\u672f\u7684\u6027\u80fd\uff0c\u5e76\u8bc6\u522b\u5404\u5b57\u6bb5\u63d0\u53d6\u7684\u4f18\u7f3a\u70b9\u3002", "method": "\u4f7f\u7528Docling\u548cLlamaCloud\u670d\u52a1\u5bf9\u626b\u63cf\u6216\u6570\u5b57\u53d1\u7968\u8fdb\u884c\u9884\u5904\u7406\uff0c\u8bc6\u522b\u5e76\u63d0\u53d6\u5173\u952e\u5b57\u6bb5\u5982\u53d1\u7968\u53f7\u7801\u3001\u65e5\u671f\u3001\u603b\u91d1\u989d\u548c\u4f9b\u5e94\u5546\u8be6\u60c5\u3002", "result": "\u5efa\u7acb\u4e86\u5305\u542b\u5b57\u6bb5\u7ea7\u7cbe\u5ea6\u3001\u4e00\u81f4\u6027\u68c0\u67e5\u5931\u8d25\u548c\u7cbe\u786e\u5339\u914d\u51c6\u786e\u7387\u7684\u7a33\u5065\u8bc4\u4f30\u6846\u67b6\u3002", "conclusion": "\u63d0\u51fa\u7684\u8bc4\u4f30\u6307\u6807\u4e3a\u6bd4\u8f83\u4e0d\u540c\u63d0\u53d6\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u65b9\u5f0f\uff0c\u5e76\u80fd\u7a81\u51fa\u663e\u793a\u5b57\u6bb5\u7279\u5b9a\u6027\u80fd\u7684\u5f3a\u5f31\u9879\u3002"}}
{"id": "2510.15056", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15056", "abs": "https://arxiv.org/abs/2510.15056", "authors": ["Ziqing Lu", "Babak Hassibi", "Lifeng Lai", "Weiyu Xu"], "title": "Learn to Change the World: Multi-level Reinforcement Learning with Model-Changing Actions", "comment": null, "summary": "Reinforcement learning usually assumes a given or sometimes even fixed\nenvironment in which an agent seeks an optimal policy to maximize its long-term\ndiscounted reward. In contrast, we consider agents that are not limited to\npassive adaptations: they instead have model-changing actions that actively\nmodify the RL model of world dynamics itself. Reconfiguring the underlying\ntransition processes can potentially increase the agents' rewards. Motivated by\nthis setting, we introduce the multi-layer configurable time-varying Markov\ndecision process (MCTVMDP). In an MCTVMDP, the lower-level MDP has a\nnon-stationary transition function that is configurable through upper-level\nmodel-changing actions. The agent's objective consists of two parts: Optimize\nthe configuration policies in the upper-level MDP and optimize the primitive\naction policies in the lower-level MDP to jointly improve its expected\nlong-term reward.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u5c42\u7ea7\u53ef\u914d\u7f6e\u65f6\u53d8\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MCTVMDP\uff09\uff0c\u5176\u4e2d\u667a\u80fd\u4f53\u4e0d\u4ec5\u53ef\u4ee5\u901a\u8fc7\u539f\u59cb\u52a8\u4f5c\u4e0e\u73af\u5883\u4ea4\u4e92\uff0c\u8fd8\u80fd\u901a\u8fc7\u4e0a\u5c42\u6a21\u578b\u6539\u53d8\u52a8\u4f5c\u4e3b\u52a8\u4fee\u6539\u73af\u5883\u52a8\u6001\u6a21\u578b\u672c\u8eab\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u5047\u8bbe\u73af\u5883\u662f\u7ed9\u5b9a\u6216\u56fa\u5b9a\u7684\uff0c\u800c\u672c\u6587\u8003\u8651\u667a\u80fd\u4f53\u80fd\u591f\u4e3b\u52a8\u4fee\u6539\u73af\u5883\u6a21\u578b\uff0c\u901a\u8fc7\u91cd\u65b0\u914d\u7f6e\u5e95\u5c42\u8f6c\u79fb\u8fc7\u7a0b\u6765\u589e\u52a0\u5956\u52b1\u3002", "method": "\u5f15\u5165MCTVMDP\u6846\u67b6\uff0c\u5305\u542b\u4e0a\u5c42MDP\u7528\u4e8e\u914d\u7f6e\u6a21\u578b\u6539\u53d8\u52a8\u4f5c\uff0c\u4e0b\u5c42MDP\u5177\u6709\u53ef\u901a\u8fc7\u4e0a\u5c42\u52a8\u4f5c\u914d\u7f6e\u7684\u975e\u5e73\u7a33\u8f6c\u79fb\u51fd\u6570\u3002\u667a\u80fd\u4f53\u9700\u8981\u8054\u5408\u4f18\u5316\u4e0a\u5c42\u914d\u7f6e\u7b56\u7565\u548c\u4e0b\u5c42\u539f\u59cb\u52a8\u4f5c\u7b56\u7565\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u80fd\u591f\u540c\u65f6\u5904\u7406\u73af\u5883\u914d\u7f6e\u548c\u7b56\u7565\u4f18\u5316\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u4e3b\u52a8\u6539\u53d8\u73af\u5883\u52a8\u6001\u6765\u6700\u5927\u5316\u957f\u671f\u5956\u52b1\u3002", "conclusion": "MCTVMDP\u4e3a\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u8d85\u8d8a\u88ab\u52a8\u9002\u5e94\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u4e3b\u52a8\u4fee\u6539\u73af\u5883\u6a21\u578b\u6765\u5b9e\u73b0\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2510.15748", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15748", "abs": "https://arxiv.org/abs/2510.15748", "authors": ["Minlin Zeng", "Zhipeng Zhou", "Yang Qiu", "Zhiqi Shen"], "title": "Towards Relaxed Multimodal Inputs for Gait-based Parkinson's Disease Assessment", "comment": null, "summary": "Parkinson's disease assessment has garnered growing interest in recent years,\nparticularly with the advent of sensor data and machine learning techniques.\nAmong these, multimodal approaches have demonstrated strong performance by\neffectively integrating complementary information from various data sources.\nHowever, two major limitations hinder their practical application: (1) the need\nto synchronize all modalities during training, and (2) the dependence on all\nmodalities during inference. To address these issues, we propose the first\nParkinson's assessment system that formulates multimodal learning as a\nmulti-objective optimization (MOO) problem. This not only allows for more\nflexible modality requirements during both training and inference, but also\nhandles modality collapse issue during multimodal information fusion. In\naddition, to mitigate the imbalance within individual modalities, we introduce\na margin-based class rebalancing strategy to enhance category learning. We\nconduct extensive experiments on three public datasets under both synchronous\nand asynchronous settings. The results show that our framework-Towards Relaxed\nInPuts (TRIP)-achieves state-of-the-art performance, outperforming the best\nbaselines by 16.48, 6.89, and 11.55 percentage points in the asynchronous\nsetting, and by 4.86 and 2.30 percentage points in the synchronous setting,\nhighlighting its effectiveness and adaptability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u5c06\u591a\u6a21\u6001\u5b66\u4e60\u5efa\u6a21\u4e3a\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\u7684\u5e15\u91d1\u68ee\u75c5\u8bc4\u4f30\u7cfb\u7edfTRIP\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u591a\u6a21\u6001\u65b9\u6cd5\u5728\u8bad\u7ec3\u65f6\u9700\u8981\u540c\u6b65\u6240\u6709\u6a21\u6001\u3001\u63a8\u7406\u65f6\u4f9d\u8d56\u6240\u6709\u6a21\u6001\u7684\u9650\u5236\uff0c\u5e76\u5904\u7406\u4e86\u6a21\u6001\u5d29\u6e83\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u591a\u6a21\u6001\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u9650\u5236\uff1a(1)\u8bad\u7ec3\u65f6\u9700\u8981\u540c\u6b65\u6240\u6709\u6a21\u6001\uff0c(2)\u63a8\u7406\u65f6\u4f9d\u8d56\u6240\u6709\u6a21\u6001\uff0c\u8fd9\u963b\u788d\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u5c06\u591a\u6a21\u6001\u5b66\u4e60\u5efa\u6a21\u4e3a\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u5f15\u5165\u57fa\u4e8e\u8fb9\u754c\u7684\u7c7b\u522b\u91cd\u5e73\u8861\u7b56\u7565\u6765\u7f13\u89e3\u6a21\u6001\u5185\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTRIP\u5728\u5f02\u6b65\u8bbe\u7f6e\u4e0b\u6bd4\u6700\u4f73\u57fa\u7ebf\u5206\u522b\u63d0\u534716.48\u30016.89\u548c11.55\u4e2a\u767e\u5206\u70b9\uff0c\u5728\u540c\u6b65\u8bbe\u7f6e\u4e0b\u5206\u522b\u63d0\u53474.86\u548c2.30\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "TRIP\u6846\u67b6\u5728\u5e15\u91d1\u68ee\u75c5\u8bc4\u4f30\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5177\u6709\u51fa\u8272\u7684\u6709\u6548\u6027\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2510.15132", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.15132", "abs": "https://arxiv.org/abs/2510.15132", "authors": ["Alex Shtoff"], "title": "A Simple Method for PMF Estimation on Large Supports", "comment": null, "summary": "We study nonparametric estimation of a probability mass function (PMF) on a\nlarge discrete support, where the PMF is multi-modal and heavy-tailed. The core\nidea is to treat the empirical PMF as a signal on a line graph and apply a\ndata-dependent low-pass filter. Concretely, we form a symmetric tri-diagonal\noperator, the path graph Laplacian perturbed with a diagonal matrix built from\nthe empirical PMF, then compute the eigenvectors, corresponding to the smallest\nfeq eigenvalues. Projecting the empirical PMF onto this low dimensional\nsubspace produces a smooth, multi-modal estimate that preserves coarse\nstructure while suppressing noise. A light post-processing step of clipping and\nre-normalizing yields a valid PMF.\n  Because we compute the eigenpairs of a symmetric tridiagonal matrix, the\ncomputation is reliable and runs time and memory proportional to the support\ntimes the dimension of the desired low-dimensional supspace. We also provide a\npractical, data-driven rule for selecting the dimension based on an\northogonal-series risk estimate, so the method \"just works\" with minimal\ntuning. On synthetic and real heavy-tailed examples, the approach preserves\ncoarse structure while suppressing sampling noise, compares favorably to\nlogspline and Gaussian-KDE baselines in the intended regimes. However, it has\nknown failure modes (e.g., abrupt discontinuities). The method is short to\nimplement, robust across sample sizes, and suitable for automated pipelines and\nexploratory analysis at scale because of its reliability and speed.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u56fe\u62c9\u666e\u62c9\u65af\u7b97\u5b50\u7684\u975e\u53c2\u6570\u6982\u7387\u8d28\u91cf\u51fd\u6570\u4f30\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u636e\u4f9d\u8d56\u7684\u4f4e\u901a\u6ee4\u6ce2\u5904\u7406\u591a\u6a21\u6001\u548c\u91cd\u5c3e\u5206\u5e03\uff0c\u8ba1\u7b97\u53ef\u9760\u4e14\u9002\u5408\u5927\u89c4\u6a21\u81ea\u52a8\u5316\u5206\u6790\u3002", "motivation": "\u9488\u5bf9\u5927\u578b\u79bb\u6563\u652f\u6491\u96c6\u4e0a\u591a\u6a21\u6001\u548c\u91cd\u5c3e\u6982\u7387\u8d28\u91cf\u51fd\u6570\u7684\u975e\u53c2\u6570\u4f30\u8ba1\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u5904\u7406\u8fd9\u7c7b\u590d\u6742\u5206\u5e03\u65f6\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u5c06\u7ecf\u9a8cPMF\u89c6\u4e3a\u7ebf\u56fe\u4e0a\u7684\u4fe1\u53f7\uff0c\u6784\u5efa\u5bf9\u79f0\u4e09\u5bf9\u89d2\u7b97\u5b50\uff08\u8def\u5f84\u56fe\u62c9\u666e\u62c9\u65af\u52a0\u4e0a\u57fa\u4e8e\u7ecf\u9a8cPMF\u7684\u5bf9\u89d2\u77e9\u9635\uff09\uff0c\u8ba1\u7b97\u6700\u5c0f\u7279\u5f81\u503c\u5bf9\u5e94\u7684\u7279\u5f81\u5411\u91cf\uff0c\u5c06\u7ecf\u9a8cPMF\u6295\u5f71\u5230\u4f4e\u7ef4\u5b50\u7a7a\u95f4\uff0c\u6700\u540e\u8fdb\u884c\u88c1\u526a\u548c\u91cd\u5f52\u4e00\u5316\u5904\u7406\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u91cd\u5c3e\u6570\u636e\u4e0a\uff0c\u8be5\u65b9\u6cd5\u80fd\u4fdd\u6301\u7c97\u7c92\u5ea6\u7ed3\u6784\u540c\u65f6\u6291\u5236\u91c7\u6837\u566a\u58f0\uff0c\u5728\u76ee\u6807\u573a\u666f\u4e0b\u4f18\u4e8elogspline\u548c\u9ad8\u65afKDE\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8ba1\u7b97\u53ef\u9760\u4e14\u5185\u5b58\u6548\u7387\u9ad8\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u7b80\u6d01\uff0c\u5bf9\u6837\u672c\u91cf\u7a33\u5065\uff0c\u56e0\u5176\u53ef\u9760\u6027\u548c\u901f\u5ea6\u9002\u5408\u81ea\u52a8\u5316\u6d41\u7a0b\u548c\u5927\u89c4\u6a21\u63a2\u7d22\u6027\u5206\u6790\uff0c\u4f46\u5b58\u5728\u5df2\u77e5\u7684\u5931\u6548\u6a21\u5f0f\uff08\u5982\u7a81\u7136\u7684\u4e0d\u8fde\u7eed\u6027\uff09\u3002"}}
{"id": "2510.15076", "categories": ["cs.LG", "cs.DM", "cs.DS"], "pdf": "https://arxiv.org/pdf/2510.15076", "abs": "https://arxiv.org/abs/2510.15076", "authors": ["Sami Davies", "Benjamin Moseley", "Heather Newman"], "title": "Online Correlation Clustering: Simultaneously Optimizing All $\\ell_p$-norms", "comment": "66 pages", "summary": "The $\\ell_p$-norm objectives for correlation clustering present a fundamental\ntrade-off between minimizing total disagreements (the $\\ell_1$-norm) and\nensuring fairness to individual nodes (the $\\ell_\\infty$-norm). Surprisingly,\nin the offline setting it is possible to simultaneously approximate all\n$\\ell_p$-norms with a single clustering. Can this powerful guarantee be\nachieved in an online setting? This paper provides the first affirmative\nanswer. We present a single algorithm for the online-with-a-sample (AOS) model\nthat, given a small constant fraction of the input as a sample, produces one\nclustering that is simultaneously $O(\\log^4 n)$-competitive for all\n$\\ell_p$-norms with high probability, $O(\\log n)$-competitive for the\n$\\ell_\\infty$-norm with high probability, and $O(1)$-competitive for the\n$\\ell_1$-norm in expectation. This work successfully translates the offline\n\"all-norms\" guarantee to the online world.\n  Our setting is motivated by a new hardness result that demonstrates a\nfundamental separation between these objectives in the standard random-order\n(RO) online model. Namely, while the $\\ell_1$-norm is trivially\n$O(1)$-approximable in the RO model, we prove that any algorithm in the RO\nmodel for the fairness-promoting $\\ell_\\infty$-norm must have a competitive\nratio of at least $\\Omega(n^{1/3})$. This highlights the necessity of a\ndifferent beyond-worst-case model. We complement our algorithm with lower\nbounds, showing our competitive ratios for the $\\ell_1$- and $\\ell_\\infty$-\nnorms are nearly tight in the AOS model.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u5728\u7ebf\u6837\u672c\u6a21\u578b\u4e0b\u7684\u76f8\u5173\u805a\u7c7b\u7b97\u6cd5\uff0c\u80fd\u591f\u540c\u65f6\u8fd1\u4f3c\u6240\u6709\u2113p\u8303\u6570\u76ee\u6807\uff0c\u89e3\u51b3\u4e86\u79bb\u7ebf\u73af\u5883\u4e2d\u21131\u8303\u6570\uff08\u6700\u5c0f\u5316\u603b\u5206\u6b67\uff09\u548c\u2113\u221e\u8303\u6570\uff08\u786e\u4fdd\u8282\u70b9\u516c\u5e73\u6027\uff09\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u6e90\u4e8e\u79bb\u7ebf\u73af\u5883\u4e2d\u53ef\u4ee5\u540c\u65f6\u8fd1\u4f3c\u6240\u6709\u2113p\u8303\u6570\u7684\u53d1\u73b0\uff0c\u4f46\u9700\u8981\u9a8c\u8bc1\u8fd9\u79cd\u5f3a\u5927\u4fdd\u8bc1\u662f\u5426\u80fd\u5728\u5728\u7ebf\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u3002\u540c\u65f6\uff0c\u4f5c\u8005\u8bc1\u660e\u4e86\u5728\u6807\u51c6\u968f\u673a\u987a\u5e8f\u5728\u7ebf\u6a21\u578b\u4e2d\uff0c\u2113\u221e\u8303\u6570\u5b58\u5728\u6839\u672c\u6027\u5206\u79bb\uff0c\u9700\u8981\u91c7\u7528\u4e0d\u540c\u7684\u8d85\u8d8a\u6700\u574f\u60c5\u51b5\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u7ebf\u6837\u672c\u6a21\u578b\uff08AOS\uff09\u7b97\u6cd5\uff0c\u7ed9\u5b9a\u8f93\u5165\u7684\u4e00\u5c0f\u90e8\u5206\u5e38\u6570\u6bd4\u4f8b\u4f5c\u4e3a\u6837\u672c\uff0c\u751f\u6210\u5355\u4e00\u805a\u7c7b\u3002\u8be5\u7b97\u6cd5\u80fd\u591f\u540c\u65f6\u5904\u7406\u6240\u6709\u2113p\u8303\u6570\u76ee\u6807\uff0c\u5728\u6837\u672c\u6a21\u578b\u4e0b\u5b9e\u73b0\u591a\u76ee\u6807\u8fd1\u4f3c\u3002", "result": "\u7b97\u6cd5\u5728AOS\u6a21\u578b\u4e2d\uff1a\u5bf9\u6240\u6709\u2113p\u8303\u6570\u9ad8\u6982\u7387\u8fbe\u5230O(log\u2074n)\u7ade\u4e89\u6bd4\uff1b\u5bf9\u2113\u221e\u8303\u6570\u9ad8\u6982\u7387\u8fbe\u5230O(logn)\u7ade\u4e89\u6bd4\uff1b\u5bf9\u21131\u8303\u6570\u671f\u671b\u8fbe\u5230O(1)\u7ade\u4e89\u6bd4\u3002\u540c\u65f6\u8bc1\u660e\u4e86\u5728\u6807\u51c6RO\u6a21\u578b\u4e2d\u2113\u221e\u8303\u6570\u81f3\u5c11\u9700\u8981\u03a9(n\u00b9/\u00b3)\u7ade\u4e89\u6bd4\u3002", "conclusion": "\u6210\u529f\u5c06\u79bb\u7ebf\u73af\u5883\u4e2d\u7684\"\u5168\u8303\u6570\"\u4fdd\u8bc1\u8fc1\u79fb\u5230\u5728\u7ebf\u4e16\u754c\uff0c\u8bc1\u660e\u4e86\u5728\u7ebf\u6837\u672c\u6a21\u578b\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u4e3a\u21131\u548c\u2113\u221e\u8303\u6570\u63d0\u4f9b\u4e86\u63a5\u8fd1\u7d27\u7684\u7ade\u4e89\u6bd4\u4e0b\u754c\u3002"}}
{"id": "2510.15262", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.15262", "abs": "https://arxiv.org/abs/2510.15262", "authors": ["Zhiyuan Fan", "Yifeng Liu", "Qingyue Zhao", "Angela Yuan", "Quanquan Gu"], "title": "Robust Layerwise Scaling Rules by Proper Weight Decay Tuning", "comment": null, "summary": "Empirical scaling laws prescribe how to allocate parameters, data, and\ncompute, while maximal-update parameterization ($\\mu$P) enables learning-rate\ntransfer across widths by equalizing early-time update magnitudes. However, in\nmodern scale-invariant architectures, training quickly enters an\noptimizer-governed steady state where normalization layers create backward\nscale sensitivity and the effective learning rate becomes width dependent,\ndegrading $\\mu$P transfer. We address this by introducing a weight-decay\nscaling rule for AdamW that preserves sublayer gain across widths. Empirically,\nthe singular-value spectrum of each matrix parameter scales in norm as\n$\\sqrt{\\eta/\\lambda}$ with an approximately invariant shape; under width\nscaling $d$, we observe that the top singular value scales approximately as\n$\\sqrt{\\eta/\\lambda}\\cdot d^{0.75}$. Combining this observation with the $\\mu$P\nlearning-rate rule $\\eta_2\\propto d^{-1}$ for matrix-like parameters implies an\nempirical weight-decay scaling rule $\\lambda_2\\propto \\sqrt{d}$ that\napproximately keeps sublayer gains width invariant. Together with vector-like\nparameters trained at $\\eta_1=\\Theta_d(1)$ and $\\lambda_1=0$, this yields\n\\emph{zero-shot} transfer of both learning rate and weight decay from proxy to\ntarget widths, removing per-width sweeps. We validate the rule on LLaMA-style\nTransformers and in a minimal synthetic setting, and we provide a simple\ndiagnostic, matching top singular values, to check sublayer-gain invariance.\nOur results extend $\\mu$P beyond the near-init regime by explicitly controlling\nsteady-state scales set by the optimizer, offering a practical recipe for\nwidth-robust hyperparameter transfer under AdamW.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9AdamW\u4f18\u5316\u5668\u7684\u6743\u91cd\u8870\u51cf\u7f29\u653e\u89c4\u5219\uff0c\u89e3\u51b3\u4e86\u5728\u5c3a\u5ea6\u4e0d\u53d8\u67b6\u6784\u4e2d\u03bcP\u65b9\u6cd5\u5728\u8bad\u7ec3\u7a33\u6001\u9636\u6bb5\u5931\u6548\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u5b66\u4e60\u7387\u548c\u6743\u91cd\u8870\u51cf\u5728\u4e0d\u540c\u5bbd\u5ea6\u6a21\u578b\u95f4\u7684\u96f6\u6837\u672c\u8fc1\u79fb\u3002", "motivation": "\u73b0\u4ee3\u5c3a\u5ea6\u4e0d\u53d8\u67b6\u6784\u7684\u8bad\u7ec3\u4f1a\u5feb\u901f\u8fdb\u5165\u4f18\u5316\u5668\u4e3b\u5bfc\u7684\u7a33\u6001\u9636\u6bb5\uff0c\u5f52\u4e00\u5316\u5c42\u5bfc\u81f4\u53cd\u5411\u5c3a\u5ea6\u654f\u611f\u6027\uff0c\u4f7f\u5f97\u6709\u6548\u5b66\u4e60\u7387\u53d8\u5f97\u5bbd\u5ea6\u4f9d\u8d56\uff0c\u4ece\u800c\u7834\u574f\u4e86\u03bcP\u65b9\u6cd5\u7684\u8fc1\u79fb\u6548\u679c\u3002", "method": "\u901a\u8fc7\u5206\u6790\u77e9\u9635\u53c2\u6570\u5947\u5f02\u503c\u8c31\u7684\u7f29\u653e\u89c4\u5f8b\uff0c\u7ed3\u5408\u03bcP\u5b66\u4e60\u7387\u89c4\u5219\uff0c\u63a8\u5bfc\u51fa\u7ecf\u9a8c\u6027\u7684\u6743\u91cd\u8870\u51cf\u7f29\u653e\u89c4\u5219\u03bb\u2082\u221d\u221ad\uff0c\u540c\u65f6\u4fdd\u6301\u5411\u91cf\u7c7b\u53c2\u6570\u7684\u5b66\u4e60\u7387\u4e0d\u53d8\u4e14\u6743\u91cd\u8870\u51cf\u4e3a0\u3002", "result": "\u5728LLaMA\u98ce\u683cTransformer\u548c\u6700\u5c0f\u5408\u6210\u8bbe\u7f6e\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u89c4\u5219\u7684\u6709\u6548\u6027\uff0c\u5b9e\u73b0\u4e86\u5b66\u4e60\u7387\u548c\u6743\u91cd\u8870\u51cf\u5728\u4e0d\u540c\u5bbd\u5ea6\u6a21\u578b\u95f4\u7684\u96f6\u6837\u672c\u8fc1\u79fb\uff0c\u6d88\u9664\u4e86\u6bcf\u4e2a\u5bbd\u5ea6\u90fd\u9700\u8981\u8fdb\u884c\u8d85\u53c2\u6570\u641c\u7d22\u7684\u9700\u6c42\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c06\u03bcP\u6269\u5c55\u5230\u8fd1\u521d\u59cb\u5316\u9636\u6bb5\u4e4b\u5916\uff0c\u901a\u8fc7\u663e\u5f0f\u63a7\u5236\u4f18\u5316\u5668\u8bbe\u7f6e\u7684\u7a33\u6001\u5c3a\u5ea6\uff0c\u4e3aAdamW\u4e0b\u7684\u5bbd\u5ea6\u9c81\u68d2\u8d85\u53c2\u6570\u8fc1\u79fb\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6848\u3002"}}
{"id": "2510.15479", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.15479", "abs": "https://arxiv.org/abs/2510.15479", "authors": ["Shiqin Tang", "Rong Feng", "Shuxin Zhuang", "Hongzong Li", "Youzhi Zhang"], "title": "Adversary-Free Counterfactual Prediction via Information-Regularized Representations", "comment": null, "summary": "We study counterfactual prediction under assignment bias and propose a\nmathematically grounded, information-theoretic approach that removes\ntreatment-covariate dependence without adversarial training. Starting from a\nbound that links the counterfactual-factual risk gap to mutual information, we\nlearn a stochastic representation Z that is predictive of outcomes while\nminimizing I(Z; T). We derive a tractable variational objective that\nupper-bounds the information term and couples it with a supervised decoder,\nyielding a stable, provably motivated training criterion. The framework extends\nnaturally to dynamic settings by applying the information penalty to sequential\nrepresentations at each decision time. We evaluate the method on controlled\nnumerical simulations and a real-world clinical dataset, comparing against\nrecent state-of-the-art balancing, reweighting, and adversarial baselines.\nAcross metrics of likelihood, counterfactual error, and policy evaluation, our\napproach performs favorably while avoiding the training instabilities and\ntuning burden of adversarial schemes.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u8868\u793a\u4e0e\u5904\u7406\u53d8\u91cf\u4e4b\u95f4\u7684\u4e92\u4fe1\u606f\u6765\u6d88\u9664\u5206\u914d\u504f\u5dee\uff0c\u65e0\u9700\u5bf9\u6297\u8bad\u7ec3\uff0c\u5728\u9759\u6001\u548c\u52a8\u6001\u573a\u666f\u4e2d\u5747\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u89e3\u51b3\u56e0\u679c\u63a8\u65ad\u4e2d\u7684\u5206\u914d\u504f\u5dee\u95ee\u9898\uff0c\u4f20\u7edf\u5bf9\u6297\u8bad\u7ec3\u65b9\u6cd5\u5b58\u5728\u4e0d\u7a33\u5b9a\u6027\u548c\u8c03\u53c2\u8d1f\u62c5\uff0c\u9700\u8981\u4e00\u79cd\u6570\u5b66\u57fa\u7840\u624e\u5b9e\u4e14\u8bad\u7ec3\u7a33\u5b9a\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u4ece\u8fde\u63a5\u53cd\u4e8b\u5b9e-\u4e8b\u5b9e\u98ce\u9669\u5dee\u8ddd\u4e0e\u4e92\u4fe1\u606f\u7684\u7406\u8bba\u8fb9\u754c\u51fa\u53d1\uff0c\u5b66\u4e60\u4e00\u4e2a\u9884\u6d4b\u7ed3\u679c\u7684\u968f\u673a\u8868\u793aZ\uff0c\u540c\u65f6\u6700\u5c0f\u5316I(Z;T)\u3002\u63a8\u5bfc\u51fa\u53ef\u5904\u7406\u7684\u53d8\u5206\u76ee\u6807\uff0c\u5c06\u4fe1\u606f\u9879\u4e0e\u76d1\u7763\u89e3\u7801\u5668\u8026\u5408\uff0c\u5f62\u6210\u7a33\u5b9a\u8bad\u7ec3\u51c6\u5219\u3002", "result": "\u5728\u53d7\u63a7\u6570\u503c\u6a21\u62df\u548c\u771f\u5b9e\u4e34\u5e8a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u4e0e\u6700\u65b0\u7684\u5e73\u8861\u3001\u91cd\u52a0\u6743\u548c\u5bf9\u6297\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u4f3c\u7136\u5ea6\u3001\u53cd\u4e8b\u5b9e\u8bef\u5dee\u548c\u653f\u7b56\u8bc4\u4f30\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u8d8a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u907f\u514d\u5bf9\u6297\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\u548c\u8c03\u53c2\u8d1f\u62c5\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u826f\u597d\u7684\u56e0\u679c\u63a8\u65ad\u6027\u80fd\uff0c\u4e3a\u5904\u7406\u5206\u914d\u504f\u5dee\u63d0\u4f9b\u4e86\u7406\u8bba\u624e\u5b9e\u4e14\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.15508", "categories": ["cs.LG", "cs.NA", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.15508", "abs": "https://arxiv.org/abs/2510.15508", "authors": ["Naoki Yoshida", "Satoshi Hayakawa", "Yuhta Takida", "Toshimitsu Uesaka", "Hiromi Wakaki", "Yuki Mitsufuji"], "title": "Theoretical Refinement of CLIP by Utilizing Linear Structure of Optimal Similarity", "comment": null, "summary": "In this study, we propose an enhancement to the similarity computation\nmechanism in multi-modal contrastive pretraining frameworks such as CLIP. Prior\ntheoretical research has demonstrated that the optimal similarity metrics\nbetween paired modalities should correspond to the pointwise mutual information\n(PMI) between the two modalities. However, the current implementations of CLIP\nand its variants fail to fully utilize the underlying linear structure of PMI.\nWe therefore propose KME-CLIP, which leverages this structure through the inner\nproduct in a reproducing kernel Hilbert space. We theoretically prove that our\nmethod can approximate PMI with arbitrary accuracy and empirically demonstrate\nthat our approach overall outperforms the standard CLIP formulation across\nseveral retrieval and classification tasks.", "AI": {"tldr": "\u63d0\u51faKME-CLIP\u65b9\u6cd5\uff0c\u901a\u8fc7\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u7684\u5185\u79ef\u6765\u6539\u8fdb\u591a\u6a21\u6001\u5bf9\u6bd4\u9884\u8bad\u7ec3\u4e2d\u7684\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u673a\u5236\uff0c\u66f4\u597d\u5730\u5229\u7528\u70b9\u4e92\u4fe1\u606f\u7684\u7ebf\u6027\u7ed3\u6784\u3002", "motivation": "\u73b0\u6709CLIP\u53ca\u5176\u53d8\u4f53\u672a\u80fd\u5145\u5206\u5229\u7528\u70b9\u4e92\u4fe1\u606f(PMI)\u7684\u7ebf\u6027\u7ed3\u6784\uff0c\u800c\u7406\u8bba\u7814\u7a76\u8868\u660e\u8de8\u6a21\u6001\u7684\u6700\u4f18\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u5e94\u5bf9\u5e94PMI\u3002", "method": "\u5728\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u4e2d\u4f7f\u7528\u5185\u79ef\u6765\u8fd1\u4f3cPMI\uff0c\u7406\u8bba\u4e0a\u8bc1\u660e\u53ef\u4ee5\u4efb\u610f\u7cbe\u5ea6\u903c\u8fd1PMI\u3002", "result": "\u5728\u591a\u4e2a\u68c0\u7d22\u548c\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cKME-CLIP\u6574\u4f53\u4f18\u4e8e\u6807\u51c6CLIP\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528PMI\u7684\u7ebf\u6027\u7ed3\u6784\uff0cKME-CLIP\u5728\u591a\u6a21\u6001\u5bf9\u6bd4\u9884\u8bad\u7ec3\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2510.15165", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.15165", "abs": "https://arxiv.org/abs/2510.15165", "authors": ["Xin Guo", "Zijiu Lyu"], "title": "Policy Transfer Ensures Fast Learning for Continuous-Time LQR with Entropy Regularization", "comment": null, "summary": "Reinforcement Learning (RL) enables agents to learn optimal decision-making\nstrategies through interaction with an environment, yet training from scratch\non complex tasks can be highly inefficient. Transfer learning (TL), widely\nsuccessful in large language models (LLMs), offers a promising direction for\nenhancing RL efficiency by leveraging pre-trained models.\n  This paper investigates policy transfer, a TL approach that initializes\nlearning in a target RL task using a policy from a related source task, in the\ncontext of continuous-time linear quadratic regulators (LQRs) with entropy\nregularization. We provide the first theoretical proof of policy transfer for\ncontinuous-time RL, proving that a policy optimal for one LQR serves as a\nnear-optimal initialization for closely related LQRs, while preserving the\noriginal algorithm's convergence rate. Furthermore, we introduce a novel policy\nlearning algorithm for continuous-time LQRs that achieves global linear and\nlocal super-linear convergence. Our results demonstrate both theoretical\nguarantees and algorithmic benefits of transfer learning in continuous-time RL,\naddressing a gap in existing literature and extending prior work from discrete\nto continuous time settings.\n  As a byproduct of our analysis, we derive the stability of a class of\ncontinuous-time score-based diffusion models via their connection with LQRs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8fde\u7eed\u65f6\u95f4\u7ebf\u6027\u4e8c\u6b21\u8c03\u8282\u5668\uff08LQR\uff09\u4e2d\u7684\u7b56\u7565\u8fc1\u79fb\u5b66\u4e60\uff0c\u8bc1\u660e\u4e86\u5728\u76f8\u5173LQR\u4efb\u52a1\u95f4\u8fc1\u79fb\u6700\u4f18\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5177\u6709\u5168\u5c40\u7ebf\u6027\u548c\u5c40\u90e8\u8d85\u7ebf\u6027\u6536\u655b\u7684\u65b0\u7b97\u6cd5\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u4ece\u5934\u8bad\u7ec3\u6548\u7387\u4f4e\u4e0b\uff0c\u800c\u8fc1\u79fb\u5b66\u4e60\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u5df2\u8bc1\u660e\u6709\u6548\u3002\u672c\u6587\u65e8\u5728\u5c06\u8fc1\u79fb\u5b66\u4e60\u5e94\u7528\u4e8e\u8fde\u7eed\u65f6\u95f4\u5f3a\u5316\u5b66\u4e60\uff0c\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002", "method": "\u91c7\u7528\u7b56\u7565\u8fc1\u79fb\u65b9\u6cd5\uff0c\u4f7f\u7528\u6e90\u4efb\u52a1\u7684\u6700\u4f18\u7b56\u7565\u521d\u59cb\u5316\u76ee\u6807\u4efb\u52a1\u5b66\u4e60\u3002\u5728\u8fde\u7eed\u65f6\u95f4LQR\u6846\u67b6\u4e0b\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u5e76\u5f00\u53d1\u65b0\u7684\u7b56\u7565\u5b66\u4e60\u7b97\u6cd5\u3002", "result": "\u9996\u6b21\u8bc1\u660e\u4e86\u8fde\u7eed\u65f6\u95f4RL\u4e2d\u7b56\u7565\u8fc1\u79fb\u7684\u7406\u8bba\u6709\u6548\u6027\uff1a\u4e00\u4e2aLQR\u7684\u6700\u4f18\u7b56\u7565\u53ef\u4f5c\u4e3a\u76f8\u5173LQR\u7684\u8fd1\u6700\u4f18\u521d\u59cb\u5316\uff0c\u540c\u65f6\u4fdd\u6301\u539f\u7b97\u6cd5\u7684\u6536\u655b\u901f\u5ea6\u3002\u65b0\u7b97\u6cd5\u5b9e\u73b0\u4e86\u5168\u5c40\u7ebf\u6027\u548c\u5c40\u90e8\u8d85\u7ebf\u6027\u6536\u655b\u3002", "conclusion": "\u7814\u7a76\u586b\u8865\u4e86\u8fde\u7eed\u65f6\u95f4RL\u4e2d\u8fc1\u79fb\u5b66\u4e60\u7684\u7406\u8bba\u7a7a\u767d\uff0c\u8bc1\u660e\u4e86\u7b56\u7565\u8fc1\u79fb\u7684\u7406\u8bba\u4fdd\u8bc1\u548c\u7b97\u6cd5\u4f18\u52bf\uff0c\u5e76\u5c06\u76f8\u5173\u5de5\u4f5c\u4ece\u79bb\u6563\u65f6\u95f4\u6269\u5c55\u5230\u8fde\u7eed\u65f6\u95f4\u8bbe\u7f6e\u3002"}}
{"id": "2510.15839", "categories": ["cs.LG", "econ.EM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.15839", "abs": "https://arxiv.org/abs/2510.15839", "authors": ["Yeshwanth Cherapanamjeri", "Constantinos Daskalakis", "Gabriele Farina", "Sobhan Mohammadpour"], "title": "Learning Correlated Reward Models: Statistical Barriers and Opportunities", "comment": null, "summary": "Random Utility Models (RUMs) are a classical framework for modeling user\npreferences and play a key role in reward modeling for Reinforcement Learning\nfrom Human Feedback (RLHF). However, a crucial shortcoming of many of these\ntechniques is the Independence of Irrelevant Alternatives (IIA) assumption,\nwhich collapses \\emph{all} human preferences to a universal underlying utility\nfunction, yielding a coarse approximation of the range of human preferences. On\nthe other hand, statistical and computational guarantees for models avoiding\nthis assumption are scarce. In this paper, we investigate the statistical and\ncomputational challenges of learning a \\emph{correlated} probit model, a\nfundamental RUM that avoids the IIA assumption. First, we establish that the\nclassical data collection paradigm of pairwise preference data is\n\\emph{fundamentally insufficient} to learn correlational information,\nexplaining the lack of statistical and computational guarantees in this\nsetting. Next, we demonstrate that \\emph{best-of-three} preference data\nprovably overcomes these shortcomings, and devise a statistically and\ncomputationally efficient estimator with near-optimal performance. These\nresults highlight the benefits of higher-order preference data in learning\ncorrelated utilities, allowing for more fine-grained modeling of human\npreferences. Finally, we validate these theoretical guarantees on several\nreal-world datasets, demonstrating improved personalization of human\npreferences.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5b66\u4e60\u76f8\u5173probit\u6a21\u578b\u7684\u7edf\u8ba1\u548c\u8ba1\u7b97\u6311\u6218\uff0c\u53d1\u73b0\u4f20\u7edf\u7684\u6210\u5bf9\u504f\u597d\u6570\u636e\u65e0\u6cd5\u5b66\u4e60\u76f8\u5173\u6027\u4fe1\u606f\uff0c\u800c\u4e09\u9009\u4e00\u504f\u597d\u6570\u636e\u80fd\u591f\u6709\u6548\u514b\u670d\u8fd9\u4e00\u9650\u5236\uff0c\u5e76\u63d0\u51fa\u4e86\u9ad8\u6548\u7684\u4f30\u8ba1\u7b97\u6cd5\u3002", "motivation": "\u968f\u673a\u6548\u7528\u6a21\u578b\u5728\u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60\u4e2d\u53d1\u6325\u5173\u952e\u4f5c\u7528\uff0c\u4f46\u8bb8\u591a\u6280\u672f\u4f9d\u8d56\u4e8e\u65e0\u5173\u9009\u9879\u72ec\u7acb\u6027\u5047\u8bbe\uff0c\u8fd9\u9650\u5236\u4e86\u4eba\u7c7b\u504f\u597d\u7684\u7cbe\u7ec6\u5efa\u6a21\u3002\u672c\u6587\u65e8\u5728\u7814\u7a76\u907f\u514d\u8be5\u5047\u8bbe\u7684\u76f8\u5173probit\u6a21\u578b\u7684\u5b66\u4e60\u6311\u6218\u3002", "method": "\u9996\u5148\u5206\u6790\u6210\u5bf9\u504f\u597d\u6570\u636e\u5728\u5b66\u4e60\u76f8\u5173\u6027\u4fe1\u606f\u65b9\u9762\u7684\u6839\u672c\u4e0d\u8db3\uff0c\u7136\u540e\u8bc1\u660e\u4e09\u9009\u4e00\u504f\u597d\u6570\u636e\u80fd\u591f\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u5e76\u5f00\u53d1\u4e86\u7edf\u8ba1\u548c\u8ba1\u7b97\u9ad8\u6548\u7684\u4f30\u8ba1\u7b97\u6cd5\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u4e09\u9009\u4e00\u504f\u597d\u6570\u636e\u80fd\u591f\u63d0\u4f9b\u5b66\u4e60\u76f8\u5173\u6027\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u63d0\u51fa\u7684\u4f30\u8ba1\u7b97\u6cd5\u5177\u6709\u8fd1\u6700\u4f18\u6027\u80fd\u3002\u5728\u591a\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u9a8c\u8bc1\u663e\u793a\u8be5\u65b9\u6cd5\u80fd\u591f\u6539\u5584\u4eba\u7c7b\u504f\u597d\u7684\u4e2a\u6027\u5316\u5efa\u6a21\u3002", "conclusion": "\u9ad8\u9636\u504f\u597d\u6570\u636e\u5728\u5b66\u4e60\u76f8\u5173\u6548\u7528\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u80fd\u591f\u5b9e\u73b0\u66f4\u7cbe\u7ec6\u7684\u4eba\u7c7b\u504f\u597d\u5efa\u6a21\uff0c\u4e3a\u4e2a\u6027\u5316\u504f\u597d\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u548c\u65b9\u6cd5\u57fa\u7840\u3002"}}
{"id": "2510.15211", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15211", "abs": "https://arxiv.org/abs/2510.15211", "authors": ["Yongchan Kwon", "Shang Zhu", "Federico Bianchi", "Kaitlyn Zhou", "James Zou"], "title": "ReasonIF: Large Reasoning Models Fail to Follow Instructions During Reasoning", "comment": null, "summary": "The ability of large language models (LLMs) to follow user instructions is\ncentral to their reliability, safety, and usefulness. While prior studies\nassess instruction adherence in the model's main responses, we argue that it is\nalso critical for large reasoning models (LRMs) to follow user instructions\nthroughout their reasoning process. Reasoning instruction following makes LRMs\nmore controllable and transparent, while reducing risks of undesirable\nshortcuts, hallucinations, or reward hacking within reasoning traces. To\nevaluate this dimension, we introduce ReasonIF, a systematic benchmark for\nassessing reasoning instruction following. ReasonIF includes six categories of\ninstruction prompts, spanning multilingual reasoning, formatting and length\ncontrol. Across many open-source LRMs including GPT-OSS, Qwen3, and\nDeepSeek-R1, we find substantial failures in reasoning instruction adherence:\nthe highest instruction following score (IFS) remains below 0.25, meaning that\nfewer than $25\\%$ of reasoning traces comply with the given instructions.\nNotably, as task difficulty increases, reasoning instruction following degrades\nfurther. We also explore two strategies to enhance reasoning instruction\nfidelity. (1) multi-turn reasoning and (2) Reasoning Instruction Finetuning\n(RIF) using synthetic data. RIF improves the IFS of $GPT-OSS-20B$ from 0.11 to\n0.27, indicating measurable progress but leaving ample room for improvement.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faReasonIF\u57fa\u51c6\u6765\u8bc4\u4f30\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u9075\u5faa\u7528\u6237\u6307\u4ee4\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u6307\u4ee4\u9075\u5faa\u7387\u4f4e\u4e8e25%\uff0c\u5e76\u63a2\u7d22\u4e86\u591a\u8f6e\u63a8\u7406\u548c\u6307\u4ee4\u5fae\u8c03\u4e24\u79cd\u6539\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u8bc4\u4f30\u6a21\u578b\u4e3b\u8981\u56de\u7b54\u7684\u6307\u4ee4\u9075\u5faa\u6027\uff0c\u4f46\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u6307\u4ee4\u9075\u5faa\u5bf9\u6a21\u578b\u53ef\u63a7\u6027\u3001\u900f\u660e\u6027\u548c\u51cf\u5c11\u4e0d\u826f\u884c\u4e3a\u540c\u6837\u91cd\u8981\u3002", "method": "\u5f15\u5165ReasonIF\u57fa\u51c6\uff0c\u5305\u542b\u516d\u7c7b\u6307\u4ee4\u63d0\u793a\uff0c\u8bc4\u4f30\u591a\u79cd\u5f00\u6e90\u5927\u578b\u63a8\u7406\u6a21\u578b\uff0c\u5e76\u63a2\u7d22\u591a\u8f6e\u63a8\u7406\u548c\u63a8\u7406\u6307\u4ee4\u5fae\u8c03\u4e24\u79cd\u6539\u8fdb\u7b56\u7565\u3002", "result": "\u73b0\u6709\u6a21\u578b\u63a8\u7406\u6307\u4ee4\u9075\u5faa\u7387\u666e\u904d\u4f4e\u4e8e25%\uff0c\u4efb\u52a1\u96be\u5ea6\u589e\u52a0\u65f6\u8868\u73b0\u66f4\u5dee\uff1b\u63a8\u7406\u6307\u4ee4\u5fae\u8c03\u5c06GPT-OSS-20B\u7684\u6307\u4ee4\u9075\u5faa\u5f97\u5206\u4ece0.11\u63d0\u5347\u52300.27\u3002", "conclusion": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u786e\u4fdd\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2510.15216", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.15216", "abs": "https://arxiv.org/abs/2510.15216", "authors": ["Xuansheng Wu", "Xiaoman Pan", "Wenlin Yao", "Jianshu Chen"], "title": "Soundness-Aware Level: A Microscopic Signature that Predicts LLM Reasoning Potential", "comment": "Pre-print", "summary": "Reinforcement learning with verifiable rewards (RLVR) can elicit strong\nreasoning in large language models (LLMs), while their performance after RLVR\nvaries dramatically across different base models. This raises a fundamental\nquestion: what microscopic property of pre-trained models leads to this\nvariation? To investigate, we formalize reasoning as chains of Horn clauses\n(\"if-then\" rules) built from features extracted from the LLM's latent space via\ncross-layer sparse autoencoders (SAEs). We estimate the transition\nprobabilities between its features, and further categorize each rule by its\nsemantic soundness level (e.g., strict, plausible, noisy) with an LLM. Our key\ndiscovery is that high-potential models are inherently soundness-aware: their\ninternal probability distributions systematically shift across rules' soundness\nlevels, becoming highly distinct for \"strict\" versus \"noisy\" rules. In\ncontrast, weaker models are soundness-agnostic, collapsing to one distribution\nregardless of soundness levels. To quantify this, we introduce the\nSoundness-Aware Level (SAL), a microscopic metric using the Jensen-Shannon\nDivergence to measure the separation between these distributions. We show that\nSAL's predictions of post-RLVR reasoning performance follow a precise empirical\nlaw (R^2=0.87) across diverse model families (Qwen, Mistral, Llama, DeepSeek)\nand scales (0.5B-14B). This reveals that a model's reasoning potential is tied\nto its intrinsic, pre-trained ability to distinguish sound knowledge from\nunsound ones. These findings underscore the critical role of model pre-training\nin shaping reasoning and offer a practical metric grounded in the model's\ninternal mechanisms for selecting/designing stronger base models.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.15217", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15217", "abs": "https://arxiv.org/abs/2510.15217", "authors": ["Emily Alsentzer", "Marie-Laure Charpignon", "Bill Chen", "Niharika D'Souza", "Jason Fries", "Yixing Jiang", "Aparajita Kashyap", "Chanwoo Kim", "Simon Lee", "Aishwarya Mandyam", "Ashery Christopher Mbilinyi", "Nikita Mehandru", "Nitish Nagesh", "Brighton Nuwagira", "Emma Pierson", "Arvind Pillai", "Akane Sano", "Tanveer Syeda-Mahmood", "Shashank Yadav", "Elias Adhanom", "Muhammad Umar Afza", "Amelia Archer", "Suhana Bedi", "Vasiliki Bikia", "Trenton Chang", "George H. Chen", "Winston Chen", "Erica Chiang", "Edward Choi", "Octavia Ciora", "Paz Dozie-Nnamah", "Shaza Elsharief", "Matthew Engelhard", "Ali Eshragh", "Jean Feng", "Josh Fessel", "Scott Fleming", "Kei Sen Fong", "Thomas Frost", "Soham Gadgil", "Judy Gichoya", "Leeor Hershkovich", "Sujeong Im", "Bhavya Jain", "Vincent Jeanselme", "Furong Jia", "Qixuan", "Jin", "Yuxuan Jin", "Daniel Kapash", "Geetika Kapoor", "Behdokht Kiafar", "Matthias Kleiner", "Stefan Kraft", "Annika Kumar", "Daeun Kyung", "Zhongyuan Liang", "Joanna Lin", "Qianchu", "Liu", "Chang Liu", "Hongzhou Luan", "Chris Lunt", "Leopoldo Jul\u00edan Lechuga L\u00f3pez", "Matthew B. A. McDermott", "Shahriar Noroozizadeh", "Connor O'Brien", "YongKyung Oh", "Mixail Ota", "Stephen Pfohl", "Meagan Pi", "Tanmoy Sarkar Pias", "Emma Rocheteau", "Avishaan Sethi", "Toru Shirakawa", "Anita Silver", "Neha Simha", "Kamile Stankeviciute", "Max Sunog", "Peter Szolovits", "Shengpu Tang", "Jialu Tang", "Aaron Tierney", "John Valdovinos", "Byron Wallace", "Will Ke Wang", "Peter Washington", "Jeremy Weiss", "Daniel Wolfe", "Emily Wong", "Hye Sun Yun", "Xiaoman Zhang", "Xiao Yu Cindy Zhang", "Hayoung Jeong", "Kaveri A. Thakoor"], "title": "Reflections from Research Roundtables at the Conference on Health, Inference, and Learning (CHIL) 2025", "comment": null, "summary": "The 6th Annual Conference on Health, Inference, and Learning (CHIL 2025),\nhosted by the Association for Health Learning and Inference (AHLI), was held in\nperson on June 25-27, 2025, at the University of California, Berkeley, in\nBerkeley, California, USA. As part of this year's program, we hosted Research\nRoundtables to catalyze collaborative, small-group dialogue around critical,\ntimely topics at the intersection of machine learning and healthcare. Each\nroundtable was moderated by a team of senior and junior chairs who fostered\nopen exchange, intellectual curiosity, and inclusive engagement. The sessions\nemphasized rigorous discussion of key challenges, exploration of emerging\nopportunities, and collective ideation toward actionable directions in the\nfield. In total, eight roundtables were held by 19 roundtable chairs on topics\nof \"Explainability, Interpretability, and Transparency,\" \"Uncertainty, Bias,\nand Fairness,\" \"Causality,\" \"Domain Adaptation,\" \"Foundation Models,\" \"Learning\nfrom Small Medical Data,\" \"Multimodal Methods,\" and \"Scalable, Translational\nHealthcare Solutions.\"", "AI": {"tldr": "CHIL 2025\u4f1a\u8bae\u4e3e\u529e\u4e868\u4e2a\u7814\u7a76\u5706\u684c\u4f1a\u8bae\uff0c\u805a\u7126\u673a\u5668\u5b66\u4e60\u4e0e\u533b\u7597\u4ea4\u53c9\u9886\u57df\u7684\u5173\u952e\u4e3b\u9898\uff0c\u5305\u62ec\u53ef\u89e3\u91ca\u6027\u3001\u516c\u5e73\u6027\u3001\u56e0\u679c\u63a8\u65ad\u7b49\uff0c\u65e8\u5728\u4fc3\u8fdb\u534f\u4f5c\u5bf9\u8bdd\u548c\u96c6\u4f53\u521b\u65b0\u3002", "motivation": "\u4e3a\u4e86\u5728\u673a\u5668\u5b66\u4e60\u548c\u533b\u7597\u4fdd\u5065\u7684\u4ea4\u53c9\u9886\u57df\u50ac\u5316\u534f\u4f5c\u6027\u5c0f\u7fa4\u4f53\u5bf9\u8bdd\uff0c\u8ba8\u8bba\u5173\u952e\u53ca\u65f6\u7684\u4e3b\u9898\uff0c\u4fc3\u8fdb\u5f00\u653e\u4ea4\u6d41\u3001\u77e5\u8bc6\u597d\u5947\u5fc3\u548c\u5305\u5bb9\u6027\u53c2\u4e0e\u3002", "method": "\u901a\u8fc7\u7531\u8d44\u6df1\u548c\u521d\u7ea7\u4e3b\u5e2d\u56e2\u961f\u4e3b\u6301\u7684\u7814\u7a76\u5706\u684c\u4f1a\u8bae\uff0c\u5f3a\u8c03\u5bf9\u5173\u952e\u6311\u6218\u7684\u4e25\u683c\u8ba8\u8bba\u3001\u65b0\u5174\u673a\u4f1a\u7684\u63a2\u7d22\u4ee5\u53ca\u96c6\u4f53\u6784\u601d\u53ef\u64cd\u4f5c\u65b9\u5411\u3002", "result": "\u6210\u529f\u4e3e\u529e\u4e868\u4e2a\u5706\u684c\u4f1a\u8bae\uff0c\u6d89\u53ca19\u4f4d\u4e3b\u5e2d\uff0c\u8986\u76d6\u4e86\u53ef\u89e3\u91ca\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u3001\u56e0\u679c\u6027\u3001\u9886\u57df\u9002\u5e94\u3001\u57fa\u7840\u6a21\u578b\u3001\u5c0f\u533b\u7597\u6570\u636e\u5b66\u4e60\u3001\u591a\u6a21\u6001\u65b9\u6cd5\u548c\u53ef\u6269\u5c55\u8f6c\u5316\u533b\u7597\u89e3\u51b3\u65b9\u6848\u7b49\u4e3b\u9898\u3002", "conclusion": "\u7814\u7a76\u5706\u684c\u4f1a\u8bae\u4e3a\u533b\u7597\u673a\u5668\u5b66\u4e60\u9886\u57df\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u534f\u4f5c\u5e73\u53f0\uff0c\u4fc3\u8fdb\u4e86\u5173\u952e\u6311\u6218\u7684\u6df1\u5165\u8ba8\u8bba\u548c\u96c6\u4f53\u521b\u65b0\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u53ef\u64cd\u4f5c\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2510.15219", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15219", "abs": "https://arxiv.org/abs/2510.15219", "authors": ["Patricia Medina", "Rasika Karkare"], "title": "Integrating Product Coefficients for Improved 3D LiDAR Data Classification (Part II)", "comment": "16 pages, 6 figures, 5 tables", "summary": "This work extends our previous study on enhancing 3D LiDAR point-cloud\nclassification with product coefficients\n\\cite{medina2025integratingproductcoefficientsimproved}, measure-theoretic\ndescriptors that complement the original spatial Lidar features. Here, we show\nthat combining product coefficients with an autoencoder representation and a\nKNN classifier delivers consistent performance gains over both PCA-based\nbaselines and our earlier framework. We also investigate the effect of adding\nproduct coefficients level by level, revealing a clear trend: richer sets of\ncoefficients systematically improve class separability and overall accuracy.\nThe results highlight the value of combining hierarchical product-coefficient\nfeatures with autoencoders to push LiDAR classification performance further.", "AI": {"tldr": "\u672c\u7814\u7a76\u6269\u5c55\u4e86\u5148\u524d\u5173\u4e8e\u4f7f\u7528\u4e58\u79ef\u7cfb\u6570\u589e\u5f3a3D LiDAR\u70b9\u4e91\u5206\u7c7b\u7684\u5de5\u4f5c\uff0c\u901a\u8fc7\u7ed3\u5408\u81ea\u7f16\u7801\u5668\u8868\u793a\u548cKNN\u5206\u7c7b\u5668\uff0c\u76f8\u6bd4PCA\u57fa\u7ebf\u548c\u65e9\u671f\u6846\u67b6\u83b7\u5f97\u4e86\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u7ed3\u5408\u4e58\u79ef\u7cfb\u6570\u4e0e\u81ea\u7f16\u7801\u5668\u8868\u793a\u6765\u8fdb\u4e00\u6b65\u63d0\u5347LiDAR\u70b9\u4e91\u5206\u7c7b\u6027\u80fd\uff0c\u5e76\u7814\u7a76\u4e0d\u540c\u5c42\u7ea7\u4e58\u79ef\u7cfb\u6570\u5bf9\u5206\u7c7b\u6548\u679c\u7684\u5f71\u54cd\u3002", "method": "\u5c06\u4e58\u79ef\u7cfb\u6570\u4e0e\u81ea\u7f16\u7801\u5668\u8868\u793a\u76f8\u7ed3\u5408\uff0c\u4f7f\u7528KNN\u5206\u7c7b\u5668\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u9010\u7ea7\u6dfb\u52a0\u4e58\u79ef\u7cfb\u6570\u6765\u7814\u7a76\u5176\u5bf9\u5206\u7c7b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u7ed3\u5408\u4e58\u79ef\u7cfb\u6570\u4e0e\u81ea\u7f16\u7801\u5668\u8868\u793a\u76f8\u6bd4PCA\u57fa\u7ebf\u548c\u65e9\u671f\u6846\u67b6\u83b7\u5f97\u4e86\u66f4\u597d\u7684\u6027\u80fd\uff0c\u4e14\u66f4\u4e30\u5bcc\u7684\u7cfb\u6570\u96c6\u5408\u80fd\u7cfb\u7edf\u6027\u5730\u63d0\u9ad8\u7c7b\u522b\u53ef\u5206\u6027\u548c\u6574\u4f53\u51c6\u786e\u7387\u3002", "conclusion": "\u5206\u5c42\u4e58\u79ef\u7cfb\u6570\u7279\u5f81\u4e0e\u81ea\u7f16\u7801\u5668\u7684\u7ed3\u5408\u5bf9\u4e8e\u63a8\u52a8LiDAR\u5206\u7c7b\u6027\u80fd\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u66f4\u4e30\u5bcc\u7684\u7cfb\u6570\u96c6\u5408\u80fd\u5e26\u6765\u66f4\u597d\u7684\u5206\u7c7b\u6548\u679c\u3002"}}
{"id": "2510.15232", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.15232", "abs": "https://arxiv.org/abs/2510.15232", "authors": ["Tiansheng Hu", "Tongyan Hu", "Liuyang Bai", "Yilun Zhao", "Arman Cohan", "Chen Zhao"], "title": "FinTrust: A Comprehensive Benchmark of Trustworthiness Evaluation in Finance Domain", "comment": "EMNLP 2025 Main", "summary": "Recent LLMs have demonstrated promising ability in solving finance related\nproblems. However, applying LLMs in real-world finance application remains\nchallenging due to its high risk and high stakes property. This paper\nintroduces FinTrust, a comprehensive benchmark specifically designed for\nevaluating the trustworthiness of LLMs in finance applications. Our benchmark\nfocuses on a wide range of alignment issues based on practical context and\nfeatures fine-grained tasks for each dimension of trustworthiness evaluation.\nWe assess eleven LLMs on FinTrust and find that proprietary models like o4-mini\noutperforms in most tasks such as safety while open-source models like\nDeepSeek-V3 have advantage in specific areas like industry-level fairness. For\nchallenging task like fiduciary alignment and disclosure, all LLMs fall short,\nshowing a significant gap in legal awareness. We believe that FinTrust can be a\nvaluable benchmark for LLMs' trustworthiness evaluation in finance domain.", "AI": {"tldr": "FinTrust\u662f\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u91d1\u878d\u9886\u57dfLLM\u53ef\u4fe1\u5ea6\u7684\u7efc\u5408\u57fa\u51c6\uff0c\u6db5\u76d6\u591a\u79cd\u5bf9\u9f50\u95ee\u9898\uff0c\u5e76\u5bf911\u4e2aLLM\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "motivation": "\u7531\u4e8e\u91d1\u878d\u9886\u57df\u7684\u9ad8\u98ce\u9669\u548c\u9ad8\u5229\u5bb3\u7279\u6027\uff0c\u5728\u771f\u5b9e\u91d1\u878d\u5e94\u7528\u4e2d\u90e8\u7f72LLM\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u4e13\u95e8\u7684\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u8bbe\u8ba1FinTrust\u57fa\u51c6\uff0c\u57fa\u4e8e\u5b9e\u9645\u60c5\u5883\u6784\u5efa\u5e7f\u6cdb\u7684\u5bf9\u9f50\u95ee\u9898\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u53ef\u4fe1\u5ea6\u7ef4\u5ea6\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u4efb\u52a1\uff0c\u8bc4\u4f3011\u4e2aLLM\u7684\u8868\u73b0\u3002", "result": "\u4e13\u6709\u6a21\u578b\u5982o4-mini\u5728\u5927\u591a\u6570\u4efb\u52a1\uff08\u5982\u5b89\u5168\u6027\uff09\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u800c\u5f00\u6e90\u6a21\u578b\u5982DeepSeek-V3\u5728\u7279\u5b9a\u9886\u57df\uff08\u5982\u884c\u4e1a\u7ea7\u516c\u5e73\u6027\uff09\u5177\u6709\u4f18\u52bf\uff1b\u6240\u6709LLM\u5728\u4fe1\u6258\u5bf9\u9f50\u548c\u62ab\u9732\u7b49\u6311\u6218\u6027\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "FinTrust\u53ef\u4ee5\u4f5c\u4e3a\u91d1\u878d\u9886\u57dfLLM\u53ef\u4fe1\u5ea6\u8bc4\u4f30\u7684\u6709\u4ef7\u503c\u57fa\u51c6\uff0c\u5f53\u524dLLM\u5728\u6cd5\u5f8b\u610f\u8bc6\u65b9\u9762\u4ecd\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002"}}
{"id": "2510.15456", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15456", "abs": "https://arxiv.org/abs/2510.15456", "authors": ["Jan Corazza", "Hadi Partovi Aria", "Daniel Neider", "Zhe Xu"], "title": "Expediting Reinforcement Learning by Incorporating Knowledge About Temporal Causality in the Environment", "comment": "Please cite the proceedings version. Source code:\n  https://github.com/corazza/tcrl", "summary": "Reinforcement learning (RL) algorithms struggle with learning optimal\npolicies for tasks where reward feedback is sparse and depends on a complex\nsequence of events in the environment. Probabilistic reward machines (PRMs) are\nfinite-state formalisms that can capture temporal dependencies in the reward\nsignal, along with nondeterministic task outcomes. While special RL algorithms\ncan exploit this finite-state structure to expedite learning, PRMs remain\ndifficult to modify and design by hand. This hinders the already difficult\ntasks of utilizing high-level causal knowledge about the environment, and\ntransferring the reward formalism into a new domain with a different causal\nstructure. This paper proposes a novel method to incorporate causal information\nin the form of Temporal Logic-based Causal Diagrams into the reward formalism,\nthereby expediting policy learning and aiding the transfer of task\nspecifications to new environments. Furthermore, we provide a theoretical\nresult about convergence to optimal policy for our method, and demonstrate its\nstrengths empirically.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u65f6\u5e8f\u903b\u8f91\u56e0\u679c\u56fe\u96c6\u6210\u5230\u6982\u7387\u5956\u52b1\u673a\u4e2d\u7684\u65b0\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u5728\u7a00\u758f\u5956\u52b1\u4efb\u52a1\u4e2d\u7684\u5b66\u4e60\u56f0\u96be\uff0c\u52a0\u901f\u7b56\u7565\u5b66\u4e60\u5e76\u4fc3\u8fdb\u4efb\u52a1\u89c4\u8303\u5728\u4e0d\u540c\u73af\u5883\u95f4\u7684\u8fc1\u79fb\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u5904\u7406\u5956\u52b1\u53cd\u9988\u7a00\u758f\u4e14\u4f9d\u8d56\u4e8e\u73af\u5883\u4e2d\u590d\u6742\u4e8b\u4ef6\u5e8f\u5217\u7684\u4efb\u52a1\u65f6\u5b58\u5728\u56f0\u96be\u3002\u6982\u7387\u5956\u52b1\u673a\u867d\u7136\u80fd\u6355\u6349\u5956\u52b1\u4fe1\u53f7\u4e2d\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u4f46\u96be\u4ee5\u624b\u52a8\u4fee\u6539\u548c\u8bbe\u8ba1\uff0c\u8fd9\u963b\u788d\u4e86\u5229\u7528\u9ad8\u5c42\u56e0\u679c\u77e5\u8bc6\u548c\u5728\u4e0d\u540c\u56e0\u679c\u7ed3\u6784\u9886\u57df\u95f4\u8fc1\u79fb\u5956\u52b1\u5f62\u5f0f\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5c06\u65f6\u5e8f\u903b\u8f91\u56e0\u679c\u56fe\u5f62\u5f0f\u5316\u7684\u56e0\u679c\u4fe1\u606f\u96c6\u6210\u5230\u5956\u52b1\u5f62\u5f0f\u5316\u4e2d\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u6982\u7387\u5956\u52b1\u673a\u548c\u56e0\u679c\u56fe\u6765\u6784\u5efa\u66f4\u6709\u6548\u7684\u5956\u52b1\u7ed3\u6784\u3002", "result": "\u63d0\u4f9b\u4e86\u5173\u4e8e\u65b9\u6cd5\u6536\u655b\u5230\u6700\u4f18\u7b56\u7565\u7684\u7406\u8bba\u7ed3\u679c\uff0c\u5e76\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u4f18\u52bf\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u52a0\u901f\u7b56\u7565\u5b66\u4e60\uff0c\u5e76\u4fc3\u8fdb\u4efb\u52a1\u89c4\u8303\u5728\u4e0d\u540c\u73af\u5883\u95f4\u7684\u8fc1\u79fb\uff0c\u4e3a\u89e3\u51b3\u7a00\u758f\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.15254", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15254", "abs": "https://arxiv.org/abs/2510.15254", "authors": ["Dingya Feng", "Dingyuan Xue"], "title": "Spatiotemporal Transformers for Predicting Avian Disease Risk from Migration Trajectories", "comment": null, "summary": "Accurate forecasting of avian disease outbreaks is critical for wildlife\nconservation and public health. This study presents a Transformer-based\nframework for predicting the disease risk at the terminal locations of\nmigratory bird trajectories. We integrate multi-source datasets, including GPS\ntracking data from Movebank, outbreak records from the World Organisation for\nAnimal Health (WOAH), and geospatial context from GADM and Natural Earth. The\nraw coordinates are processed using H3 hierarchical geospatial encoding to\ncapture spatial patterns. The model learns spatiotemporal dependencies from\nbird movement sequences to estimate endpoint disease risk. Evaluation on a\nheld-out test set demonstrates strong predictive performance, achieving an\naccuracy of 0.9821, area under the ROC curve (AUC) of 0.9803, average precision\n(AP) of 0.9299, and an F1-score of 0.8836 at the optimal threshold. These\nresults highlight the potential of Transformer architectures to support\nearly-warning systems for avian disease surveillance, enabling timely\nintervention and prevention strategies.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u57fa\u4e8eTransformer\u7684\u6846\u67b6\uff0c\u5229\u7528\u5019\u9e1f\u8fc1\u5f99\u8f68\u8ff9\u9884\u6d4b\u7ec8\u70b9\u75be\u75c5\u98ce\u9669\uff0c\u6574\u5408GPS\u8ffd\u8e2a\u3001\u75ab\u60c5\u8bb0\u5f55\u548c\u5730\u7406\u7a7a\u95f4\u6570\u636e\uff0c\u5728\u6d4b\u8bd5\u96c6\u4e0a\u53d6\u5f97\u9ad8\u7cbe\u5ea6\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u51c6\u786e\u9884\u6d4b\u79bd\u7c7b\u75be\u75c5\u66b4\u53d1\u5bf9\u91ce\u751f\u52a8\u7269\u4fdd\u62a4\u548c\u516c\u5171\u536b\u751f\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6355\u6349\u5019\u9e1f\u8fc1\u5f99\u6a21\u5f0f\u4e0e\u75be\u75c5\u4f20\u64ad\u5173\u7cfb\u7684\u9884\u6d4b\u6a21\u578b\u3002", "method": "\u96c6\u6210\u591a\u6e90\u6570\u636e\u96c6\uff08Movebank GPS\u8ffd\u8e2a\u6570\u636e\u3001WOAH\u75ab\u60c5\u8bb0\u5f55\u3001GADM\u548cNatural Earth\u5730\u7406\u7a7a\u95f4\u6570\u636e\uff09\uff0c\u4f7f\u7528H3\u5206\u5c42\u5730\u7406\u7a7a\u95f4\u7f16\u7801\u5904\u7406\u539f\u59cb\u5750\u6807\uff0c\u57fa\u4e8eTransformer\u67b6\u6784\u5b66\u4e60\u9e1f\u7fa4\u79fb\u52a8\u5e8f\u5217\u7684\u65f6\u7a7a\u4f9d\u8d56\u6027\u6765\u4f30\u8ba1\u7ec8\u70b9\u75be\u75c5\u98ce\u9669\u3002", "result": "\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff1a\u51c6\u786e\u73870.9821\uff0cROC\u66f2\u7ebf\u4e0b\u9762\u79ef0.9803\uff0c\u5e73\u5747\u7cbe\u5ea60.9299\uff0cF1\u5206\u65700.8836\uff08\u6700\u4f18\u9608\u503c\u4e0b\uff09\u3002", "conclusion": "Transformer\u67b6\u6784\u5728\u79bd\u7c7b\u75be\u75c5\u76d1\u6d4b\u65e9\u671f\u9884\u8b66\u7cfb\u7edf\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u80fd\u591f\u652f\u6301\u53ca\u65f6\u7684\u5e72\u9884\u548c\u9884\u9632\u7b56\u7565\u3002"}}
{"id": "2510.15511", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15511", "abs": "https://arxiv.org/abs/2510.15511", "authors": ["Giorgos Nikolaou", "Tommaso Mencattini", "Donato Crisostomi", "Andrea Santilli", "Yannis Panagakis", "Emanuele Rodola'"], "title": "Language Models are Injective and Hence Invertible", "comment": null, "summary": "Transformer components such as non-linear activations and normalization are\ninherently non-injective, suggesting that different inputs could map to the\nsame output and prevent exact recovery of the input from a model's\nrepresentations. In this paper, we challenge this view. First, we prove\nmathematically that transformer language models mapping discrete input\nsequences to their corresponding sequence of continuous representations are\ninjective and therefore lossless, a property established at initialization and\npreserved during training. Second, we confirm this result empirically through\nbillions of collision tests on six state-of-the-art language models, and\nobserve no collisions. Third, we operationalize injectivity: we introduce\nSipIt, the first algorithm that provably and efficiently reconstructs the exact\ninput text from hidden activations, establishing linear-time guarantees and\ndemonstrating exact invertibility in practice. Overall, our work establishes\ninjectivity as a fundamental and exploitable property of language models, with\ndirect implications for transparency, interpretability, and safe deployment.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660eTransformer\u8bed\u8a00\u6a21\u578b\u5728\u5c06\u79bb\u6563\u8f93\u5165\u5e8f\u5217\u6620\u5c04\u4e3a\u8fde\u7eed\u8868\u793a\u65f6\u662f\u5355\u5c04\u7684\uff0c\u56e0\u6b64\u662f\u65e0\u635f\u7684\uff0c\u5e76\u63d0\u51fa\u4e86\u9996\u4e2a\u80fd\u7cbe\u786e\u4ece\u9690\u85cf\u6fc0\u6d3b\u91cd\u5efa\u8f93\u5165\u6587\u672c\u7684\u7b97\u6cd5SipIt\u3002", "motivation": "\u4f20\u7edf\u89c2\u70b9\u8ba4\u4e3aTransformer\u7ec4\u4ef6\u5982\u975e\u7ebf\u6027\u6fc0\u6d3b\u548c\u5f52\u4e00\u5316\u672c\u8d28\u4e0a\u662f\u975e\u5355\u5c04\u7684\uff0c\u53ef\u80fd\u5bfc\u81f4\u4e0d\u540c\u8f93\u5165\u6620\u5c04\u5230\u76f8\u540c\u8f93\u51fa\uff0c\u963b\u788d\u4ece\u6a21\u578b\u8868\u793a\u4e2d\u7cbe\u786e\u6062\u590d\u8f93\u5165\u3002\u672c\u6587\u6311\u6218\u8fd9\u4e00\u89c2\u70b9\u3002", "method": "\u9996\u5148\u6570\u5b66\u8bc1\u660eTransformer\u8bed\u8a00\u6a21\u578b\u5728\u521d\u59cb\u5316\u548c\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u5355\u5c04\u6027\uff1b\u5176\u6b21\u5728\u516d\u4e2a\u6700\u5148\u8fdb\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u6570\u5341\u4ebf\u6b21\u78b0\u649e\u6d4b\u8bd5\uff1b\u6700\u540e\u63d0\u51faSipIt\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u80fd\u8bc1\u660e\u4e14\u9ad8\u6548\u5730\u4ece\u9690\u85cf\u6fc0\u6d3b\u91cd\u5efa\u7cbe\u786e\u8f93\u5165\u6587\u672c\u3002", "result": "\u6570\u5b66\u8bc1\u660e\u548c\u5b9e\u8bc1\u6d4b\u8bd5\u5747\u786e\u8ba4Transformer\u8bed\u8a00\u6a21\u578b\u662f\u5355\u5c04\u7684\uff0c\u672a\u89c2\u5bdf\u5230\u4efb\u4f55\u78b0\u649e\uff1bSipIt\u7b97\u6cd5\u5728\u5b9e\u8df5\u4e2d\u5b9e\u73b0\u4e86\u7cbe\u786e\u53ef\u9006\u6027\uff0c\u5e76\u5177\u6709\u7ebf\u6027\u65f6\u95f4\u4fdd\u8bc1\u3002", "conclusion": "\u5355\u5c04\u6027\u662f\u8bed\u8a00\u6a21\u578b\u7684\u57fa\u672c\u4e14\u53ef\u5229\u7528\u7684\u5c5e\u6027\uff0c\u5bf9\u900f\u660e\u5ea6\u3001\u53ef\u89e3\u91ca\u6027\u548c\u5b89\u5168\u90e8\u7f72\u5177\u6709\u76f4\u63a5\u610f\u4e49\u3002"}}
{"id": "2510.15623", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15623", "abs": "https://arxiv.org/abs/2510.15623", "authors": ["Parsa Abbasi", "Stefan Heindorf"], "title": "CQD-SHAP: Explainable Complex Query Answering via Shapley Values", "comment": null, "summary": "Complex query answering (CQA) goes beyond the well-studied link prediction\ntask by addressing more sophisticated queries that require multi-hop reasoning\nover incomplete knowledge graphs (KGs). Research on neural and neurosymbolic\nCQA methods is still an emerging field. Almost all of these methods can be\nregarded as black-box models, which may raise concerns about user trust.\nAlthough neurosymbolic approaches like CQD are slightly more interpretable,\nallowing intermediate results to be tracked, the importance of different parts\nof the query remains unexplained. In this paper, we propose CQD-SHAP, a novel\nframework that computes the contribution of each query part to the ranking of a\nspecific answer. This contribution explains the value of leveraging a neural\npredictor that can infer new knowledge from an incomplete KG, rather than a\nsymbolic approach relying solely on existing facts in the KG. CQD-SHAP is\nformulated based on Shapley values from cooperative game theory and satisfies\nall the fundamental Shapley axioms. Automated evaluation of these explanations\nin terms of necessary and sufficient explanations, and comparisons with various\nbaselines, shows the effectiveness of this approach for most query types.", "AI": {"tldr": "CQD-SHAP\u662f\u4e00\u4e2a\u57fa\u4e8eShapley\u503c\u7684\u53ef\u89e3\u91ca\u6027\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u590d\u6742\u67e5\u8be2\u56de\u7b54\u4e2d\u5404\u4e2a\u67e5\u8be2\u90e8\u5206\u5bf9\u7279\u5b9a\u7b54\u6848\u6392\u540d\u7684\u8d21\u732e\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u7f3a\u4e4f\u67e5\u8be2\u90e8\u5206\u91cd\u8981\u6027\u89e3\u91ca\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u590d\u6742\u67e5\u8be2\u56de\u7b54\u65b9\u6cd5\u591a\u4e3a\u9ed1\u76d2\u6a21\u578b\uff0c\u7f3a\u4e4f\u7528\u6237\u4fe1\u4efb\u3002\u867d\u7136\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u5982CQD\u5177\u6709\u4e00\u5b9a\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u80fd\u591f\u8ffd\u8e2a\u4e2d\u95f4\u7ed3\u679c\uff0c\u4f46\u65e0\u6cd5\u89e3\u91ca\u67e5\u8be2\u4e2d\u4e0d\u540c\u90e8\u5206\u7684\u91cd\u8981\u6027\u3002", "method": "\u57fa\u4e8e\u5408\u4f5c\u535a\u5f08\u8bba\u4e2d\u7684Shapley\u503c\uff0c\u63d0\u51faCQD-SHAP\u6846\u67b6\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u67e5\u8be2\u90e8\u5206\u5bf9\u7279\u5b9a\u7b54\u6848\u6392\u540d\u7684\u8d21\u732e\uff0c\u6ee1\u8db3\u6240\u6709\u57fa\u672cShapley\u516c\u7406\u3002", "result": "\u901a\u8fc7\u5fc5\u8981\u6027\u548c\u5145\u5206\u6027\u89e3\u91ca\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\uff0c\u4ee5\u53ca\u4e0e\u591a\u79cd\u57fa\u7ebf\u7684\u6bd4\u8f83\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u5bf9\u5927\u591a\u6570\u67e5\u8be2\u7c7b\u578b\u90fd\u6709\u6548\u3002", "conclusion": "CQD-SHAP\u80fd\u591f\u89e3\u91ca\u795e\u7ecf\u9884\u6d4b\u5668\u4ece\u4e0d\u5b8c\u6574\u77e5\u8bc6\u56fe\u8c31\u4e2d\u63a8\u65ad\u65b0\u77e5\u8bc6\u7684\u4ef7\u503c\uff0c\u76f8\u6bd4\u4ec5\u4f9d\u8d56\u77e5\u8bc6\u56fe\u8c31\u4e2d\u73b0\u6709\u4e8b\u5b9e\u7684\u7b26\u53f7\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2510.15720", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15720", "abs": "https://arxiv.org/abs/2510.15720", "authors": ["Edwin Hamel-De le Court", "Gaspard Ohlmann", "Francesco Belardinelli"], "title": "ProSh: Probabilistic Shielding for Model-free Reinforcement Learning", "comment": null, "summary": "Safety is a major concern in reinforcement learning (RL): we aim at\ndeveloping RL systems that not only perform optimally, but are also safe to\ndeploy by providing formal guarantees about their safety. To this end, we\nintroduce Probabilistic Shielding via Risk Augmentation (ProSh), a model-free\nalgorithm for safe reinforcement learning under cost constraints. ProSh\naugments the Constrained MDP state space with a risk budget and enforces safety\nby applying a shield to the agent's policy distribution using a learned cost\ncritic. The shield ensures that all sampled actions remain safe in expectation.\nWe also show that optimality is preserved when the environment is\ndeterministic. Since ProSh is model-free, safety during training depends on the\nknowledge we have acquired about the environment. We provide a tight\nupper-bound on the cost in expectation, depending only on the backup-critic\naccuracy, that is always satisfied during training. Under mild, practically\nachievable assumptions, ProSh guarantees safety even at training time, as shown\nin the experiments.", "AI": {"tldr": "ProSh\u662f\u4e00\u79cd\u65e0\u6a21\u578b\u7684\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u98ce\u9669\u9884\u7b97\u589e\u5f3a\u72b6\u6001\u7a7a\u95f4\uff0c\u4f7f\u7528\u5b66\u4e60\u5230\u7684\u6210\u672c\u8bc4\u8bba\u5668\u5bf9\u7b56\u7565\u5206\u5e03\u65bd\u52a0\u4fdd\u62a4\u7f69\uff0c\u786e\u4fdd\u6240\u6709\u91c7\u6837\u52a8\u4f5c\u5728\u671f\u671b\u4e0a\u4fdd\u6301\u5b89\u5168\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u662f\u4e3b\u8981\u5173\u6ce8\u70b9\uff0c\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u6700\u4f18\u6267\u884c\u53c8\u80fd\u63d0\u4f9b\u6b63\u5f0f\u5b89\u5168\u4fdd\u8bc1\u7684\u7cfb\u7edf\u3002", "method": "\u5f15\u5165\u6982\u7387\u4fdd\u62a4\u7f69\u901a\u8fc7\u98ce\u9669\u589e\u5f3a\uff08ProSh\uff09\uff0c\u5728\u7ea6\u675fMDP\u72b6\u6001\u7a7a\u95f4\u4e2d\u589e\u52a0\u98ce\u9669\u9884\u7b97\uff0c\u4f7f\u7528\u5b66\u4e60\u5230\u7684\u6210\u672c\u8bc4\u8bba\u5668\u5bf9\u7b56\u7565\u5206\u5e03\u65bd\u52a0\u4fdd\u62a4\u7f69\u3002", "result": "\u5728\u786e\u5b9a\u6027\u73af\u5883\u4e2d\u4fdd\u6301\u6700\u4f18\u6027\uff0c\u63d0\u4f9b\u4ec5\u4f9d\u8d56\u4e8e\u5907\u4efd\u8bc4\u8bba\u5668\u51c6\u786e\u5ea6\u7684\u6210\u672c\u671f\u671b\u7d27\u4e0a\u754c\uff0c\u5b9e\u9a8c\u663e\u793a\u5728\u8bad\u7ec3\u671f\u95f4\u4e5f\u80fd\u4fdd\u8bc1\u5b89\u5168\u6027\u3002", "conclusion": "ProSh\u80fd\u591f\u5728\u8bad\u7ec3\u671f\u95f4\u63d0\u4f9b\u5b89\u5168\u4fdd\u8bc1\uff0c\u540c\u65f6\u4fdd\u6301\u6700\u4f18\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u65e0\u6a21\u578b\u7684\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u573a\u666f\u3002"}}
{"id": "2510.15388", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15388", "abs": "https://arxiv.org/abs/2510.15388", "authors": ["Mingyang Sun", "Pengxiang Ding", "Weinan Zhang", "Donglin Wang"], "title": "Iterative Refinement of Flow Policies in Probability Space for Online Reinforcement Learning", "comment": null, "summary": "While behavior cloning with flow/diffusion policies excels at learning\ncomplex skills from demonstrations, it remains vulnerable to distributional\nshift, and standard RL methods struggle to fine-tune these models due to their\niterative inference process and the limitations of existing workarounds. In\nthis work, we introduce the Stepwise Flow Policy (SWFP) framework, founded on\nthe key insight that discretizing the flow matching inference process via a\nfixed-step Euler scheme inherently aligns it with the variational\nJordan-Kinderlehrer-Otto (JKO) principle from optimal transport. SWFP\ndecomposes the global flow into a sequence of small, incremental\ntransformations between proximate distributions. Each step corresponds to a JKO\nupdate, regularizing policy changes to stay near the previous iterate and\nensuring stable online adaptation with entropic regularization. This\ndecomposition yields an efficient algorithm that fine-tunes pre-trained flows\nvia a cascade of small flow blocks, offering significant advantages:\nsimpler/faster training of sub-models, reduced computational/memory costs, and\nprovable stability grounded in Wasserstein trust regions. Comprehensive\nexperiments demonstrate SWFP's enhanced stability, efficiency, and superior\nadaptation performance across diverse robotic control benchmarks.", "AI": {"tldr": "SWFP\u6846\u67b6\u901a\u8fc7\u5c06\u6d41\u5339\u914d\u63a8\u7406\u8fc7\u7a0b\u79bb\u6563\u5316\u4e3a\u56fa\u5b9a\u6b65\u957f\u7684\u6b27\u62c9\u683c\u5f0f\uff0c\u5c06\u5176\u4e0e\u6700\u4f18\u4f20\u8f93\u7684\u53d8\u5206JKO\u539f\u7406\u5bf9\u9f50\uff0c\u5b9e\u73b0\u4e86\u9884\u8bad\u7ec3\u6d41\u6a21\u578b\u7684\u9ad8\u6548\u7a33\u5b9a\u5fae\u8c03\u3002", "motivation": "\u884c\u4e3a\u514b\u9686\u4e2d\u7684\u6d41/\u6269\u6563\u7b56\u7565\u867d\u7136\u64c5\u957f\u4ece\u6f14\u793a\u4e2d\u5b66\u4e60\u590d\u6742\u6280\u80fd\uff0c\u4f46\u5bf9\u5206\u5e03\u504f\u79fb\u5f88\u8106\u5f31\uff0c\u4e14\u6807\u51c6RL\u65b9\u6cd5\u7531\u4e8e\u8fed\u4ee3\u63a8\u7406\u8fc7\u7a0b\u548c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u7684\u5c40\u9650\u6027\u800c\u96be\u4ee5\u5fae\u8c03\u8fd9\u4e9b\u6a21\u578b\u3002", "method": "SWFP\u5c06\u5168\u5c40\u6d41\u5206\u89e3\u4e3a\u4e00\u7cfb\u5217\u90bb\u8fd1\u5206\u5e03\u4e4b\u95f4\u7684\u5c0f\u589e\u91cf\u53d8\u6362\u5e8f\u5217\uff0c\u6bcf\u4e2a\u6b65\u9aa4\u5bf9\u5e94\u4e00\u4e2aJKO\u66f4\u65b0\uff0c\u901a\u8fc7\u71b5\u6b63\u5219\u5316\u786e\u4fdd\u7b56\u7565\u53d8\u5316\u4fdd\u6301\u5728\u5148\u524d\u8fed\u4ee3\u9644\u8fd1\uff0c\u5b9e\u73b0\u7a33\u5b9a\u7684\u5728\u7ebf\u9002\u5e94\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSWFP\u5728\u591a\u79cd\u673a\u5668\u4eba\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u51fa\u589e\u5f3a\u7684\u7a33\u5b9a\u6027\u3001\u6548\u7387\u548c\u4f18\u8d8a\u7684\u9002\u5e94\u6027\u80fd\u3002", "conclusion": "SWFP\u6846\u67b6\u901a\u8fc7\u5206\u89e3\u4e3a\u5c0f\u6d41\u5757\u7ea7\u8054\uff0c\u63d0\u4f9b\u4e86\u66f4\u7b80\u5355/\u66f4\u5feb\u7684\u5b50\u6a21\u578b\u8bad\u7ec3\u3001\u964d\u4f4e\u7684\u8ba1\u7b97/\u5185\u5b58\u6210\u672c\u4ee5\u53ca\u57fa\u4e8eWasserstein\u4fe1\u4efb\u533a\u57df\u7684\u53ef\u8bc1\u660e\u7a33\u5b9a\u6027\u3002"}}
{"id": "2510.15830", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15830", "abs": "https://arxiv.org/abs/2510.15830", "authors": ["Dominik Kallusky", "Vinay Rao", "Vishal Nandavanam", "Hao-Jun Michael Shi"], "title": "SNOO: Step-K Nesterov Outer Optimizer - The Surprising Effectiveness of Nesterov Momentum Applied to Pseudo-Gradients", "comment": null, "summary": "The rapid development of large language models (LLMs) has driven the demand\nfor more efficient optimization techniques. Among these, the Lookahead family\nof optimizers employs a two-loop framework, maintaining fast and slow sets of\nmodel weights. Multiple inner optimizer steps on the fast weights produce a\ntrajectory - the pseudo-gradient - that is used to update the slow weights.\nDiLoCo, a notable example originally designed for distributed training, applies\nNesterov momentum to the averaged pseudo-gradient from multiple workers,\nclaiming to even outperform AdamW in a non-distributed setup. In this paper, we\nempirically show that DiLoCo's surprising effectiveness stems primarily from\napplying Nesterov momentum to the pseudo-gradient, which improves training in a\nnon-distributed setting. We call this Lookahead variant the Step-$K$ Nesterov\nOuter Optimizer (SNOO). We demonstrate that SNOO achieves compute factor gains\nof 1.5 - 2.5$\\times$ in a non-distributed setting up to a scale of 1e23\ntraining FLOPs, with improvements that increase with model size. Because of its\nminimal compute and memory overhead and compatibility with model sharding, SNOO\nis a practical enhancement for a variety of inner optimizers, including AdamW\nand Muon.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSNOO\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u5c06Nesterov\u52a8\u91cf\u5e94\u7528\u4e8e\u4f2a\u68af\u5ea6\uff0c\u5728\u975e\u5206\u5e03\u5f0f\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u4e861.5-2.5\u500d\u7684\u8ba1\u7b97\u6548\u7387\u63d0\u5347\uff0c\u4e14\u6539\u8fdb\u6548\u679c\u968f\u6a21\u578b\u89c4\u6a21\u589e\u5927\u800c\u589e\u5f3a\u3002", "motivation": "\u7814\u7a76\u53d1\u73b0DiLoCo\u4f18\u5316\u5668\u5728\u975e\u5206\u5e03\u5f0f\u8bbe\u7f6e\u4e2d\u8868\u73b0\u51fa\u8272\u7684\u539f\u56e0\u4e3b\u8981\u662f\u5176\u5bf9\u4f2a\u68af\u5ea6\u5e94\u7528\u4e86Nesterov\u52a8\u91cf\uff0c\u8fd9\u542f\u53d1\u4e86\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u4f18\u5316\u6280\u672f\u3002", "method": "\u63d0\u51faStep-K Nesterov Outer Optimizer (SNOO)\uff0c\u8fd9\u662f\u4e00\u4e2aLookahead\u53d8\u4f53\uff0c\u5728\u5feb\u901f\u6743\u91cd\u4e0a\u6267\u884c\u591a\u4e2a\u5185\u90e8\u4f18\u5316\u5668\u6b65\u9aa4\u751f\u6210\u4f2a\u68af\u5ea6\u8f68\u8ff9\uff0c\u7136\u540e\u5bf9\u4f2a\u68af\u5ea6\u5e94\u7528Nesterov\u52a8\u91cf\u6765\u66f4\u65b0\u6162\u901f\u6743\u91cd\u3002", "result": "SNOO\u5728\u975e\u5206\u5e03\u5f0f\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u4e861.5-2.5\u500d\u7684\u8ba1\u7b97\u56e0\u5b50\u589e\u76ca\uff0c\u8bad\u7ec3FLOPs\u89c4\u6a21\u53ef\u8fbe1e23\uff0c\u4e14\u6539\u8fdb\u6548\u679c\u968f\u6a21\u578b\u89c4\u6a21\u589e\u5927\u800c\u589e\u5f3a\u3002", "conclusion": "SNOO\u56e0\u5176\u6700\u5c0f\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u4ee5\u53ca\u4e0e\u6a21\u578b\u5206\u7247\u7684\u517c\u5bb9\u6027\uff0c\u6210\u4e3a\u9002\u7528\u4e8e\u5305\u62ecAdamW\u548cMuon\u5728\u5185\u7684\u5404\u79cd\u5185\u90e8\u4f18\u5316\u5668\u7684\u5b9e\u7528\u589e\u5f3a\u65b9\u6cd5\u3002"}}
{"id": "2510.15404", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15404", "abs": "https://arxiv.org/abs/2510.15404", "authors": ["Christopher Salazar", "Krithika Manohar", "Ashis G. Banerjee"], "title": "Online Kernel Dynamic Mode Decomposition for Streaming Time Series Forecasting with Adaptive Windowing", "comment": null, "summary": "Real-time forecasting from streaming data poses critical challenges: handling\nnon-stationary dynamics, operating under strict computational limits, and\nadapting rapidly without catastrophic forgetting. However, many existing\napproaches face trade-offs between accuracy, adaptability, and efficiency,\nparticularly when deployed in constrained computing environments. We introduce\nWORK-DMD (Windowed Online Random Kernel Dynamic Mode Decomposition), a method\nthat combines Random Fourier Features with online Dynamic Mode Decomposition to\ncapture nonlinear dynamics through explicit feature mapping, while preserving\nfixed computational cost and competitive predictive accuracy across evolving\ndata. WORK-DMD employs Sherman-Morrison updates within rolling windows,\nenabling continuous adaptation to evolving dynamics from only current data,\neliminating the need for lengthy training or large storage requirements for\nhistorical data. Experiments on benchmark datasets across several domains show\nthat WORK-DMD achieves higher accuracy than several state-of-the-art online\nforecasting methods, while requiring only a single pass through the data and\ndemonstrating particularly strong performance in short-term forecasting. Our\nresults show that combining kernel evaluations with adaptive matrix updates\nachieves strong predictive performance with minimal data requirements. This\nsample efficiency offers a practical alternative to deep learning for streaming\nforecasting applications.", "AI": {"tldr": "WORK-DMD\u662f\u4e00\u79cd\u7528\u4e8e\u6d41\u6570\u636e\u5b9e\u65f6\u9884\u6d4b\u7684\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\u548c\u5728\u7ebf\u52a8\u6001\u6a21\u5f0f\u5206\u89e3\uff0c\u901a\u8fc7\u663e\u5f0f\u7279\u5f81\u6620\u5c04\u6355\u83b7\u975e\u7ebf\u6027\u52a8\u6001\uff0c\u540c\u65f6\u4fdd\u6301\u56fa\u5b9a\u8ba1\u7b97\u6210\u672c\u548c\u7ade\u4e89\u6027\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u89e3\u51b3\u6d41\u6570\u636e\u5b9e\u65f6\u9884\u6d4b\u4e2d\u7684\u5173\u952e\u6311\u6218\uff1a\u5904\u7406\u975e\u5e73\u7a33\u52a8\u6001\u3001\u5728\u4e25\u683c\u8ba1\u7b97\u9650\u5236\u4e0b\u8fd0\u884c\u3001\u5feb\u901f\u9002\u5e94\u800c\u4e0d\u53d1\u751f\u707e\u96be\u6027\u9057\u5fd8\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u3001\u9002\u5e94\u6027\u548c\u6548\u7387\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002", "method": "\u7ed3\u5408\u968f\u673a\u5085\u91cc\u53f6\u7279\u5f81\u4e0e\u5728\u7ebf\u52a8\u6001\u6a21\u5f0f\u5206\u89e3\uff0c\u4f7f\u7528Sherman-Morrison\u66f4\u65b0\u5728\u6eda\u52a8\u7a97\u53e3\u5185\u5b9e\u73b0\u8fde\u7eed\u9002\u5e94\uff0c\u4ec5\u9700\u5f53\u524d\u6570\u636e\uff0c\u65e0\u9700\u5927\u91cf\u5386\u53f2\u6570\u636e\u5b58\u50a8\u6216\u957f\u65f6\u95f4\u8bad\u7ec3\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cWORK-DMD\u6bd4\u51e0\u79cd\u6700\u5148\u8fdb\u7684\u5728\u7ebf\u9884\u6d4b\u65b9\u6cd5\u83b7\u5f97\u66f4\u9ad8\u51c6\u786e\u6027\uff0c\u4ec5\u9700\u5355\u6b21\u6570\u636e\u904d\u5386\uff0c\u5728\u77ed\u671f\u9884\u6d4b\u4e2d\u8868\u73b0\u5c24\u4e3a\u51fa\u8272\u3002", "conclusion": "\u5c06\u6838\u8bc4\u4f30\u4e0e\u81ea\u9002\u5e94\u77e9\u9635\u66f4\u65b0\u76f8\u7ed3\u5408\uff0c\u4ee5\u6700\u5c0f\u6570\u636e\u9700\u6c42\u5b9e\u73b0\u5f3a\u9884\u6d4b\u6027\u80fd\uff0c\u4e3a\u6d41\u9884\u6d4b\u5e94\u7528\u63d0\u4f9b\u4e86\u6df1\u5ea6\u5b66\u4e60\u7684\u5b9e\u7528\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2510.15425", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15425", "abs": "https://arxiv.org/abs/2510.15425", "authors": ["Wei Wang", "Xiao-Yong Wei", "Qing Li"], "title": "ParaFormer: Shallow Parallel Transformers with Progressive Approximation", "comment": null, "summary": "The widespread 'deeper is better' philosophy has driven the creation of\narchitectures like ResNet and Transformer, which achieve high performance by\nstacking numerous layers. However, increasing model depth comes with challenges\nsuch as longer training times, higher inference latency, and impracticality on\nresource-constrained devices. To address these issues, we propose ParaFormer, a\nshallow Transformer architecture designed for true parallelism in both\nstructure and computation. By formulating standard Transformers as function\napproximators in closed-form, our theoretical analysis shows that their\nperformance relies on inter-layer collaboration for progressive approximation,\nrather than depth itself. While deep Transformers enforce this collaboration\nthrough sequential designs, we demonstrate that such collaboration is not\ninherently tied to sequential structures. ParaFormer removes the sequential\nconstraint by organizing layers into parallel branches, enforcing inter-layer\ncollaboration algorithmically. Specifically, we implement progressive\napproximation, ensuring that each new branch further reduces the loss from\npreceding branches, enabling faster convergence. Extensive experiments validate\nParaFormer's effectiveness, outperforming standard Transformers like ViT.\nMoreover, ParaFormer supports up to 15.07x model compression and facilitates\nmodel expansion for adaptive continuous learning. Experimental results on\nmulti-GPU deployment demonstrate that ParaFormer is 3.30x faster than widely\nused parallelism solutions such as FairScale. These advancements stem from our\nclosed-form formulation of Transformers based on the Universal Approximation\nTheorem, which not only explains the ``depth belief'' but also opens new\navenues for designing efficient Transformer architectures. Source code:\nhttps://(open-upon-acceptance)", "AI": {"tldr": "ParaFormer\u662f\u4e00\u79cd\u6d45\u5c42Transformer\u67b6\u6784\uff0c\u901a\u8fc7\u5e76\u884c\u5206\u652f\u7ed3\u6784\u5b9e\u73b0\u771f\u6b63\u7684\u7ed3\u6784\u548c\u8ba1\u7b97\u5e76\u884c\u5316\uff0c\u89e3\u51b3\u4e86\u6df1\u5ea6\u6a21\u578b\u8bad\u7ec3\u65f6\u95f4\u957f\u3001\u63a8\u7406\u5ef6\u8fdf\u9ad8\u7684\u95ee\u9898\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u90fd\u4f18\u4e8e\u6807\u51c6Transformer\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6Transformer\u6a21\u578b\u5e26\u6765\u7684\u8bad\u7ec3\u65f6\u95f4\u957f\u3001\u63a8\u7406\u5ef6\u8fdf\u9ad8\u4ee5\u53ca\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u4e0d\u53ef\u884c\u7684\u95ee\u9898\uff0c\u6311\u6218'\u8d8a\u6df1\u8d8a\u597d'\u7684\u4f20\u7edf\u89c2\u5ff5\u3002", "method": "\u5c06\u6807\u51c6Transformer\u5efa\u6a21\u4e3a\u95ed\u5f0f\u51fd\u6570\u903c\u8fd1\u5668\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u53d1\u73b0\u6027\u80fd\u4f9d\u8d56\u4e8e\u5c42\u95f4\u534f\u4f5c\u800c\u975e\u6df1\u5ea6\u672c\u8eab\u3002ParaFormer\u901a\u8fc7\u5c06\u5c42\u7ec4\u7ec7\u6210\u5e76\u884c\u5206\u652f\uff0c\u7b97\u6cd5\u6027\u5730\u5f3a\u5236\u5c42\u95f4\u534f\u4f5c\uff0c\u5b9e\u73b0\u6e10\u8fdb\u903c\u8fd1\u3002", "result": "ParaFormer\u5728\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u6807\u51c6Transformer\u5982ViT\uff0c\u652f\u6301\u9ad8\u8fbe15.07\u500d\u7684\u6a21\u578b\u538b\u7f29\uff0c\u5e76\u4fc3\u8fdb\u81ea\u9002\u5e94\u6301\u7eed\u5b66\u4e60\u7684\u6a21\u578b\u6269\u5c55\u3002\u5728\u591aGPU\u90e8\u7f72\u4e2d\u6bd4FairScale\u7b49\u5e76\u884c\u89e3\u51b3\u65b9\u6848\u5feb3.30\u500d\u3002", "conclusion": "\u57fa\u4e8e\u901a\u7528\u903c\u8fd1\u5b9a\u7406\u7684\u95ed\u5f0fTransformer\u516c\u5f0f\u4e0d\u4ec5\u89e3\u91ca\u4e86'\u6df1\u5ea6\u4fe1\u5ff5'\uff0c\u8fd8\u4e3a\u8bbe\u8ba1\u9ad8\u6548Transformer\u67b6\u6784\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2510.15541", "categories": ["cs.LG", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2510.15541", "abs": "https://arxiv.org/abs/2510.15541", "authors": ["Saumya B"], "title": "An Empirical Study on MC Dropout--Based Uncertainty--Error Correlation in 2D Brain Tumor Segmentation", "comment": "Code and results available at\n  https://github.com/Saumya4321/mc-dropout-boundary-correlation", "summary": "Accurate brain tumor segmentation from MRI is vital for diagnosis and\ntreatment planning. Although Monte Carlo (MC) Dropout is widely used to\nestimate model uncertainty, its effectiveness in identifying segmentation\nerrors -- especially near tumor boundaries -- remains unclear. This study\nempirically examines the relationship between MC Dropout--based uncertainty and\nsegmentation error in 2D brain tumor MRI segmentation using a U-Net trained\nunder four augmentation settings: none, horizontal flip, rotation, and scaling.\nUncertainty was computed from 50 stochastic forward passes and correlated with\npixel-wise errors using Pearson and Spearman coefficients. Results show weak\nglobal correlations ($r \\approx 0.30$--$0.38$) and negligible boundary\ncorrelations ($|r| < 0.05$). Although differences across augmentations were\nstatistically significant ($p < 0.001$), they lacked practical relevance. These\nfindings suggest that MC Dropout uncertainty provides limited cues for boundary\nerror localization, underscoring the need for alternative or hybrid uncertainty\nestimation methods in medical image segmentation.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86MC Dropout\u65b9\u6cd5\u5728\u8111\u80bf\u7624MRI\u5206\u5272\u4e2d\u8bc6\u522b\u8fb9\u754c\u8bef\u5dee\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0\u5176\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u4e0e\u5206\u5272\u8bef\u5dee\u7684\u76f8\u5173\u6027\u8f83\u5f31\uff0c\u7279\u522b\u662f\u5728\u8fb9\u754c\u533a\u57df\u51e0\u4e4e\u65e0\u76f8\u5173\u6027\u3002", "motivation": "\u5c3d\u7ba1MC Dropout\u88ab\u5e7f\u6cdb\u7528\u4e8e\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u4f46\u5176\u5728\u8bc6\u522b\u5206\u5272\u8bef\u5dee\uff08\u7279\u522b\u662f\u80bf\u7624\u8fb9\u754c\u9644\u8fd1\uff09\u65b9\u9762\u7684\u6709\u6548\u6027\u5c1a\u4e0d\u660e\u786e\uff0c\u8fd9\u5bf9\u4e8e\u533b\u5b66\u56fe\u50cf\u5206\u5272\u7684\u8bca\u65ad\u548c\u6cbb\u7597\u89c4\u5212\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4f7f\u7528U-Net\u5728\u56db\u79cd\u6570\u636e\u589e\u5f3a\u8bbe\u7f6e\uff08\u65e0\u589e\u5f3a\u3001\u6c34\u5e73\u7ffb\u8f6c\u3001\u65cb\u8f6c\u3001\u7f29\u653e\uff09\u4e0b\u8fdb\u884c2D\u8111\u80bf\u7624MRI\u5206\u5272\uff0c\u901a\u8fc750\u6b21\u968f\u673a\u524d\u5411\u4f20\u64ad\u8ba1\u7b97MC Dropout\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u4f7f\u7528Pearson\u548cSpearman\u7cfb\u6570\u5206\u6790\u4e0d\u786e\u5b9a\u6027\u4e0e\u50cf\u7d20\u7ea7\u8bef\u5dee\u7684\u76f8\u5173\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\u5168\u5c40\u76f8\u5173\u6027\u8f83\u5f31\uff08r\u22480.30-0.38\uff09\uff0c\u8fb9\u754c\u76f8\u5173\u6027\u53ef\u5ffd\u7565\u4e0d\u8ba1\uff08|r|<0.05\uff09\u3002\u867d\u7136\u4e0d\u540c\u589e\u5f3a\u8bbe\u7f6e\u95f4\u7684\u5dee\u5f02\u5177\u6709\u7edf\u8ba1\u663e\u8457\u6027\uff08p<0.001\uff09\uff0c\u4f46\u7f3a\u4e4f\u5b9e\u9645\u76f8\u5173\u6027\u3002", "conclusion": "MC Dropout\u4e0d\u786e\u5b9a\u6027\u5728\u8fb9\u754c\u8bef\u5dee\u5b9a\u4f4d\u65b9\u9762\u63d0\u4f9b\u7684\u7ebf\u7d22\u6709\u9650\uff0c\u5f3a\u8c03\u4e86\u5728\u533b\u5b66\u56fe\u50cf\u5206\u5272\u4e2d\u9700\u8981\u66ff\u4ee3\u6216\u6df7\u5408\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2510.15653", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15653", "abs": "https://arxiv.org/abs/2510.15653", "authors": ["Yefan Zeng", "Shengyu Duan", "Rishad Shafik", "Alex Yakovlev"], "title": "Fast and Compact Tsetlin Machine Inference on CPUs Using Instruction-Level Optimization", "comment": null, "summary": "The Tsetlin Machine (TM) offers high-speed inference on resource-constrained\ndevices such as CPUs. Its logic-driven operations naturally lend themselves to\nparallel execution on modern CPU architectures. Motivated by this, we propose\nan efficient software implementation of the TM by leveraging instruction-level\nbitwise operations for compact model representation and accelerated processing.\nTo further improve inference speed, we introduce an early exit mechanism, which\nexploits the TM's AND-based clause evaluation to avoid unnecessary\ncomputations. Building upon this, we propose a literal Reorder strategy\ndesigned to maximize the likelihood of early exits. This strategy is applied\nduring a post-training, pre-inference stage through statistical analysis of all\nliterals and the corresponding actions of their associated Tsetlin Automata\n(TA), introducing negligible runtime overhead. Experimental results using the\ngem5 simulator with an ARM processor show that our optimized implementation\nreduces inference time by up to 96.71% compared to the conventional\ninteger-based TM implementations while maintaining comparable code density.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684Tsetlin\u673a\u5668\u8f6f\u4ef6\u5b9e\u73b0\uff0c\u901a\u8fc7\u4f4d\u8fd0\u7b97\u3001\u63d0\u524d\u9000\u51fa\u673a\u5236\u548c\u6587\u5b57\u91cd\u6392\u5e8f\u7b56\u7565\uff0c\u5728ARM\u5904\u7406\u5668\u4e0a\u5b9e\u73b0\u9ad8\u8fbe96.71%\u7684\u63a8\u7406\u65f6\u95f4\u51cf\u5c11\u3002", "motivation": "Tsetlin\u673a\u5668\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u63d0\u4f9b\u9ad8\u901f\u63a8\u7406\uff0c\u5176\u903b\u8f91\u9a71\u52a8\u64cd\u4f5c\u9002\u5408\u5728\u73b0\u4ee3CPU\u67b6\u6784\u4e0a\u5e76\u884c\u6267\u884c\uff0c\u8fd9\u6fc0\u53d1\u4e86\u5bf9\u5176\u9ad8\u6548\u8f6f\u4ef6\u5b9e\u73b0\u7684\u7814\u7a76\u3002", "method": "\u5229\u7528\u6307\u4ee4\u7ea7\u4f4d\u8fd0\u7b97\u8fdb\u884c\u7d27\u51d1\u6a21\u578b\u8868\u793a\u548c\u52a0\u901f\u5904\u7406\uff1b\u5f15\u5165\u63d0\u524d\u9000\u51fa\u673a\u5236\u907f\u514d\u4e0d\u5fc5\u8981\u8ba1\u7b97\uff1b\u63d0\u51fa\u6587\u5b57\u91cd\u6392\u5e8f\u7b56\u7565\u6700\u5927\u5316\u63d0\u524d\u9000\u51fa\u53ef\u80fd\u6027\uff1b\u5728\u8bad\u7ec3\u540e\u3001\u63a8\u7406\u524d\u9636\u6bb5\u901a\u8fc7\u7edf\u8ba1\u5206\u6790\u5e94\u7528\u8be5\u7b56\u7565\u3002", "result": "\u4f7f\u7528gem5\u6a21\u62df\u5668\u548cARM\u5904\u7406\u5668\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4f18\u5316\u5b9e\u73b0\u76f8\u6bd4\u4f20\u7edf\u57fa\u4e8e\u6574\u6570\u7684TM\u5b9e\u73b0\u51cf\u5c11\u4e86\u9ad8\u8fbe96.71%\u7684\u63a8\u7406\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684\u4ee3\u7801\u5bc6\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u4f4d\u8fd0\u7b97\u3001\u63d0\u524d\u9000\u51fa\u548c\u6587\u5b57\u91cd\u6392\u5e8f\u7684\u7ec4\u5408\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86Tsetlin\u673a\u5668\u7684\u63a8\u7406\u6548\u7387\uff0c\u4f7f\u5176\u66f4\u9002\u5408\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u90e8\u7f72\u3002"}}
{"id": "2510.15757", "categories": ["cs.LG", "cs.CV", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.15757", "abs": "https://arxiv.org/abs/2510.15757", "authors": ["Pieris Panagi", "Savvas Karatsiolis", "Kyriacos Mosphilis", "Nicholas Hadjisavvas", "Andreas Kamilaris", "Nicolas Nicolaou", "Efstathios Stavrakis", "Vassilis Vassiliades"], "title": "Poultry Farm Intelligence: An Integrated Multi-Sensor AI Platform for Enhanced Welfare and Productivity", "comment": null, "summary": "Poultry farming faces increasing pressure to meet productivity targets while\nensuring animal welfare and environmental compliance. Yet many small and\nmedium-sized farms lack affordable, integrated tools for continuous monitoring\nand decision-making, relying instead on manual, reactive inspections. This\npaper presents Poultry Farm Intelligence (PoultryFI) - a modular,\ncost-effective platform that integrates six AI-powered modules: Camera\nPlacement Optimizer, Audio-Visual Monitoring, Analytics & Alerting, Real-Time\nEgg Counting, Production & Profitability Forecasting, and a Recommendation\nModule.\n  Camera layouts are first optimized offline using evolutionary algorithms for\nfull poultry house coverage with minimal hardware. The Audio-Visual Monitoring\nmodule extracts welfare indicators from synchronized video, audio, and feeding\ndata. Analytics & Alerting produces daily summaries and real-time\nnotifications, while Real-Time Egg Counting uses an edge vision model to\nautomate production tracking. Forecasting models predict egg yield and feed\nconsumption up to 10 days in advance, and the Recommendation Module integrates\nforecasts with weather data to guide environmental and operational adjustments.\n  This is among the first systems to combine low-cost sensing, edge analytics,\nand prescriptive AI to continuously monitor flocks, predict production, and\noptimize performance. Field trials demonstrate 100% egg-count accuracy on\nRaspberry Pi 5, robust anomaly detection, and reliable short-term forecasting.\nPoultryFI bridges the gap between isolated pilot tools and scalable, farm-wide\nintelligence, empowering producers to proactively safeguard welfare and\nprofitability.", "AI": {"tldr": "PoultryFI\u662f\u4e00\u4e2a\u9762\u5411\u4e2d\u5c0f\u578b\u5bb6\u79bd\u517b\u6b96\u573a\u7684\u4f4e\u6210\u672cAI\u5e73\u53f0\uff0c\u96c6\u6210\u4e86\u6444\u50cf\u5934\u5e03\u5c40\u4f18\u5316\u3001\u89c6\u542c\u76d1\u63a7\u3001\u5206\u6790\u9884\u8b66\u3001\u5b9e\u65f6\u9e21\u86cb\u8ba1\u6570\u3001\u751f\u4ea7\u9884\u6d4b\u548c\u63a8\u8350\u7cfb\u7edf\u516d\u5927\u6a21\u5757\uff0c\u901a\u8fc7\u8fb9\u7f18\u8ba1\u7b97\u5b9e\u73b0\u5168\u81ea\u52a8\u5316\u76d1\u6d4b\u548c\u51b3\u7b56\u652f\u6301\u3002", "motivation": "\u4e2d\u5c0f\u578b\u5bb6\u79bd\u517b\u6b96\u573a\u7f3a\u4e4f\u7ecf\u6d4e\u5b9e\u60e0\u7684\u96c6\u6210\u5316\u76d1\u63a7\u5de5\u5177\uff0c\u4f9d\u8d56\u4eba\u5de5\u68c0\u67e5\u96be\u4ee5\u6ee1\u8db3\u751f\u4ea7\u6548\u7387\u3001\u52a8\u7269\u798f\u5229\u548c\u73af\u4fdd\u8981\u6c42\uff0c\u9700\u8981\u5f00\u53d1\u4f4e\u6210\u672c\u3001\u667a\u80fd\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u8fdb\u5316\u7b97\u6cd5\u4f18\u5316\u6444\u50cf\u5934\u5e03\u5c40\u5b9e\u73b0\u5168\u8986\u76d6\uff0c\u901a\u8fc7\u540c\u6b65\u89c6\u9891\u3001\u97f3\u9891\u548c\u9972\u5582\u6570\u636e\u7684\u89c6\u542c\u76d1\u63a7\u63d0\u53d6\u798f\u5229\u6307\u6807\uff0c\u4f7f\u7528\u8fb9\u7f18\u89c6\u89c9\u6a21\u578b\u8fdb\u884c\u5b9e\u65f6\u9e21\u86cb\u8ba1\u6570\uff0c\u7ed3\u5408\u5929\u6c14\u9884\u62a5\u8fdb\u884c\u751f\u4ea7\u9884\u6d4b\u548c\u64cd\u4f5c\u5efa\u8bae\u3002", "result": "\u73b0\u573a\u8bd5\u9a8c\u663e\u793a\u5728\u6811\u8393\u6d3e5\u4e0a\u5b9e\u73b0100%\u9e21\u86cb\u8ba1\u6570\u51c6\u786e\u7387\uff0c\u5177\u5907\u7a33\u5065\u7684\u5f02\u5e38\u68c0\u6d4b\u80fd\u529b\u548c\u53ef\u9760\u7684\u77ed\u671f\u9884\u6d4b\u6027\u80fd\u3002", "conclusion": "PoultryFI\u586b\u8865\u4e86\u5b64\u7acb\u8bd5\u70b9\u5de5\u5177\u4e0e\u53ef\u6269\u5c55\u519c\u573a\u667a\u80fd\u7cfb\u7edf\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u5e2e\u52a9\u751f\u4ea7\u8005\u4e3b\u52a8\u4fdd\u969c\u52a8\u7269\u798f\u5229\u548c\u76c8\u5229\u80fd\u529b\u3002"}}
