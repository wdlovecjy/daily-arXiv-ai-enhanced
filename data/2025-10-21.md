<div id=toc></div>

# Table of Contents

- [stat.AP](#stat.AP) [Total: 3]
- [cs.LG](#cs.LG) [Total: 60]
- [eess.SP](#eess.SP) [Total: 7]
- [cs.AI](#cs.AI) [Total: 19]
- [stat.ML](#stat.ML) [Total: 9]


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [1] [A Compositional Approach to Modelling Cause-specific Mortality with Zero Counts](https://arxiv.org/abs/2510.16244)
*Zhe Michelle Dong,Han Lin Shang,Francis Hui,Aaron Bruhn*

Main category: stat.AP

TL;DR: 本文提出使用α-变换的组成数据分析方法来改进特定死因死亡率预测，该方法能更好地处理零值问题，相比传统的对数比变换提高了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 准确预测特定死因死亡率对精算科学和公共政策决策至关重要，需要考虑死因间的依赖关系，并与总体死亡率预测保持一致。标准组成数据分析方法在处理零值时面临挑战。

Method: 使用组成数据分析和α-变换来建模特定死因生命表死亡计数，该方法为处理组成数据中的零值子组提供了统计严谨的方法。

Result: α-变换相比基于对数比的组成数据变换方法，提高了特定死因生命表死亡计数的预测准确性。预测显示主要心血管疾病死亡比例呈下降趋势。

Conclusion: α-变换为处理特定死因死亡率建模中的零值问题提供了有效解决方案，能够产生更准确的预测结果，有助于更好地理解死亡率趋势。

Abstract: Understanding and forecasting mortality by cause is an essential branch of
actuarial science, with wide-ranging implications for decision-makers in public
policy and industry. To accurately capture trends in cause-specific mortality,
it is critical to consider dependencies between causes of death and produce
forecasts by age and cause coherent with aggregate mortality forecasts. One way
to achieve these aims is to model cause-specific deaths using compositional
data analysis (CODA), treating the density of deaths by age and cause as a set
of dependent, non-negative values that sum to one. A major drawback of standard
CODA methods is the challenge of zero values, which frequently occur in
cause-of-death mortality modelling. Thus, we propose using a compositional
power transformation, the $\alpha$-transformation, to model cause-specific
life-table death counts. The $\alpha$-transformation offers a statistically
rigorous approach to handling zero value subgroups in CODA compared to
\emph{ad-hoc} techniques: adding an arbitrarily small amount. We illustrate the
$\alpha$-transformation on England and Wales, and US death counts by cause from
the Human Cause-of-Death database, for cardiovascular-related causes of death.
Results demonstrate the $\alpha$-transformation improves forecast accuracy of
cause-specific life-table death counts compared with log-ratio-based CODA
transformations. The forecasts suggest declines in proportions of deaths from
major cardiovascular causes (myocardial infarction and other ischemic heart
diseases (IHD)).

</details>


### [2] [Time-Varying Confounding Bias in Observational Geoscience with Application to Induced Seismicity](https://arxiv.org/abs/2510.16360)
*Yuchen Xiao,Corwin Zigler,Peter H. Hennings,Alexandros Savvaidis*

Main category: stat.AP

TL;DR: 本文采用因果推断框架分析废水注入与诱发地震的关系，通过模拟展示时间变化混杂因素的威胁，并应用纵向分析方法估计废水处置对地震的影响。


<details>
  <summary>Details</summary>
Motivation: 补充物理模型，使用统计/机器学习方法从观测数据中测量关联性，但难以将参数统计显著性或模型预测能力解释为因果证据。

Method: 采用潜在结果视角的因果推断框架，明确定义因果效应，声明必要的识别条件以恢复无偏因果效应估计，特别关注时间变化混杂因素。

Result: 通过模拟展示了时间变化混杂因素在观测性纵向地学数据中的威胁，并应用因果推断文献中建立的统计方法估计废水处置对地震的影响。

Conclusion: 因果推断框架为从观测数据中估计废水处置与诱发地震之间的因果关系提供了可靠方法，特别适用于处理时间变化混杂因素。

Abstract: Evidence derived primarily from physical models has identified saltwater
disposal as the dominant causal factor that contributes to induced seismicity.
To complement physical models, statistical/machine learning (ML) models are
designed to measure associations from observational data, either with
parametric regression models or more flexible ML models. However, it is often
difficult to interpret the statistical significance of a parameter or the
predicative power of a model as evidence of causation. We adapt a causal
inference framework with the potential outcomes perspective to explicitly
define what we meant by causal effect and declare necessary identification
conditions to recover unbiased causal effect estimates. In particular, we
illustrate the threat of time-varying confounding in observational longitudinal
geoscience data through simulations and adapt established statistical methods
for longitudinal analysis from the causal interference literature to estimate
the effect of wastewater disposal on earthquakes in the Fort-Worth Basin of
North Central Texas from 2013 to 2016.

</details>


### [3] [Bayesian reliability acceptance sampling plans for competing risks data under interval censoring](https://arxiv.org/abs/2510.16740)
*Biswabrata Pradhan,Rathin Das*

Main category: stat.AP

TL;DR: 本文提出了在区间删失独立竞争风险数据下使用贝叶斯方法的可靠性验收抽样计划，包括固定决策准则和最优决策函数的抽样方案，并提供了计算算法和数值比较。


<details>
  <summary>Details</summary>
Motivation: 针对大样本下贝叶斯风险计算复杂的问题，需要开发基于最大似然估计渐近性质的近似方法，为制造商提供最优决策函数以最小化贝叶斯风险。

Method: 使用贝叶斯方法构建可靠性验收抽样计划，包括固定决策准则和任意决策函数两种方案，利用最大似然估计的渐近性质计算近似贝叶斯风险，并通过最小化贝叶斯风险获得最优决策函数和抽样计划。

Result: 开发了计算最优贝叶斯可靠性验收抽样计划的算法，提供了数值结果，并对不同贝叶斯可靠性验收抽样计划进行了比较分析。

Conclusion: 贝叶斯方法能够有效处理区间删失竞争风险数据下的可靠性验收抽样问题，通过最小化贝叶斯风险可以获得最优决策函数和抽样计划，为制造商提供实用的质量验收工具。

Abstract: We obtain a reliability acceptance sampling plan for independent competing
risk data under interval censoring schemes using the Bayesian approach. At
first, the Bayesian reliability acceptance sampling plan is obtained where the
decision criteria of accepting a lot is pre-fixed. For large samples, computing
Bayes risk is computationally intensive. Therefore, an approximate Bayes risk
is obtained using the asymptotic properties of the maximum likelihood
estimators. Lastly, the Bayesian reliability acceptance sampling plan is
obtained, where the decision function is arbitrary. The manufacturer can derive
an optimal decision function by minimizing the Bayes risk among all decision
functions. This optimal decision function is known as Bayes decision function.
The optimal sampling plan is obtained by minimizing the Bayes risk. The
algorithms are provided for the computation of optimum Bayesian reliability
acceptance sampling plan. Numerical results are provided and comparisons
between the Bayesian reliability acceptance sampling plans are carried out.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Lean Finder: Semantic Search for Mathlib That Understands User Intents](https://arxiv.org/abs/2510.15940)
*Jialin Lu,Kye Emond,Kaiyu Yang,Swarat Chaudhuri,Weiran Sun,Wuyang Chen*

Main category: cs.LG

TL;DR: Lean Finder是一个针对Lean和mathlib的语义搜索引擎，通过理解数学家意图、分析公开讨论语义、微调文本嵌入和多样化反馈信号，相比现有搜索引擎和GPT-4o实现了30%以上的相对改进。


<details>
  <summary>Details</summary>
Motivation: 现有Lean搜索引擎主要依赖非形式化翻译，忽视了与现实用户查询的匹配问题，导致定理证明进展缓慢且费力。

Method: 分析并聚类公开Lean讨论的语义，在模拟用户意图的合成查询上微调文本嵌入，使用多样化反馈信号与数学家偏好对齐。

Result: 在真实世界查询、非形式化陈述和证明状态评估中，相比之前搜索引擎和GPT-4o实现了超过30%的相对改进。

Conclusion: Lean Finder是一个用户中心的语义搜索工具，能够与基于LLM的定理证明器兼容，桥接检索与形式推理。

Abstract: We present Lean Finder, a semantic search engine for Lean and mathlib that
understands and aligns with the intents of mathematicians. Progress in formal
theorem proving is often hindered by the difficulty of locating relevant
theorems and the steep learning curve of the Lean 4 language, making
advancement slow and labor-intensive. Existing Lean search engines, though
helpful, rely primarily on informalizations (natural language translation of
the formal statements), while largely overlooking the mismatch with real-world
user queries. In contrast, we propose a user-centered semantic search tailored
to the needs of mathematicians. Our approach begins by analyzing and clustering
the semantics of public Lean discussions, then fine-tuning text embeddings on
synthesized queries that emulate user intents. We further align Lean Finder
with mathematicians' preferences using diverse feedback signals, encoding it
with a rich awareness of their goals from multiple perspectives. Evaluations on
real-world queries, informalized statements, and proof states demonstrate that
our Lean Finder achieves over $30\%$ relative improvement compared to previous
search engines and GPT-4o. In addition, Lean Finder is compatible with
LLM-based theorem provers, bridging retrieval with formal reasoning. Lean
Finder is available at: https://leanfinder.github.io

</details>


### [5] [Lyapunov-Stable Adaptive Control for Multimodal Concept Drift](https://arxiv.org/abs/2510.15944)
*Tianyu Bell Pan,Mengdi Zhu,Alexa Jordyn Cole,Ronald Wilson,Damon L. Woodard*

Main category: cs.LG

TL;DR: LS-OGD是一个用于多模态学习的自适应控制框架，通过动态调整学习率和模态融合权重来应对概念漂移，确保系统在非平稳环境中的鲁棒性和容错性。


<details>
  <summary>Details</summary>
Motivation: 多模态学习系统在非平稳环境中面临概念漂移的挑战，特别是模态特定的漂移和缺乏持续稳定适应机制的问题，导致性能下降。

Method: 使用在线控制器动态调整模型学习率和不同数据模态之间的融合权重，响应检测到的漂移和预测误差变化。

Result: 在有限漂移条件下，LS-OGD系统的预测误差被证明是均匀最终有界的，如果漂移停止则收敛到零；自适应融合策略能有效隔离和减轻模态特定漂移的影响。

Conclusion: LS-OGD为开发可靠且持续自适应的多模态学习系统提供了理论基础，确保系统在面对概念漂移时的韧性和容错能力。

Abstract: Multimodal learning systems often struggle in non-stationary environments due
to concept drift, where changing data distributions can degrade performance.
Modality-specific drifts and the lack of mechanisms for continuous, stable
adaptation compound this challenge. This paper introduces LS-OGD, a novel
adaptive control framework for robust multimodal learning in the presence of
concept drift. LS-OGD uses an online controller that dynamically adjusts the
model's learning rate and the fusion weights between different data modalities
in response to detected drift and evolving prediction errors. We prove that
under bounded drift conditions, the LS-OGD system's prediction error is
uniformly ultimately bounded and converges to zero if the drift ceases.
Additionally, we demonstrate that the adaptive fusion strategy effectively
isolates and mitigates the impact of severe modality-specific drift, thereby
ensuring system resilience and fault tolerance. These theoretical guarantees
establish a principled foundation for developing reliable and continuously
adapting multimodal learning systems.

</details>


### [6] [Cross-dataset Multivariate Time-series Model for Parkinson's Diagnosis via Keyboard Dynamics](https://arxiv.org/abs/2510.15950)
*Arianna Francesconi,Donato Cappetta,Fabio Rebecchi,Paolo Soda,Valerio Guarrasi,Rosa Sicilia*

Main category: cs.LG

TL;DR: 本研究提出了一种基于击键动力学的新型管道，用于帕金森病的远程筛查和远程监测，通过深度学习模型在外部验证中取得了超过90%的AUC-ROC和70%以上的F1-Score。


<details>
  <summary>Details</summary>
Motivation: 帕金森病影响全球超过1000万人，预计到2040年患病率将翻倍。由于运动症状出现较晚且传统临床评估存在局限性，早期诊断仍然困难。

Method: 方法包括三个主要阶段：(i) 预处理四个不同数据集的数据，提取四个时间信号并比较三种方法解决类别不平衡；(ii) 在两个最大数据集上预训练八种最先进的深度学习架构，优化时间窗口、步长等超参数；(iii) 在中等规模数据集上进行微调，并在第四个独立队列中进行外部验证。

Result: 混合卷积-循环和基于Transformer的模型在外部验证中表现出色，AUC-ROC得分超过90%，F1-Score超过70%。特别是时间卷积模型在外部验证中达到91.14%的AUC-ROC，优于仅依赖内部验证的现有方法。

Conclusion: 这些发现强调了击键动力学作为帕金森病可靠数字生物标志物的潜力，为早期检测和持续监测提供了有前景的途径。

Abstract: Parkinson's disease (PD) presents a growing global challenge, affecting over
10 million individuals, with prevalence expected to double by 2040. Early
diagnosis remains difficult due to the late emergence of motor symptoms and
limitations of traditional clinical assessments. In this study, we propose a
novel pipeline that leverages keystroke dynamics as a non-invasive and scalable
biomarker for remote PD screening and telemonitoring. Our methodology involves
three main stages: (i) preprocessing of data from four distinct datasets,
extracting four temporal signals and addressing class imbalance through the
comparison of three methods; (ii) pre-training eight state-of-the-art
deep-learning architectures on the two largest datasets, optimizing temporal
windowing, stride, and other hyperparameters; (iii) fine-tuning on an
intermediate-sized dataset and performing external validation on a fourth,
independent cohort. Our results demonstrate that hybrid convolutional-recurrent
and transformer-based models achieve strong external validation performance,
with AUC-ROC scores exceeding 90% and F1-Score over 70%. Notably, a temporal
convolutional model attains an AUC-ROC of 91.14% in external validation,
outperforming existing methods that rely solely on internal validation. These
findings underscore the potential of keystroke dynamics as a reliable digital
biomarker for PD, offering a promising avenue for early detection and
continuous monitoring.

</details>


### [7] [Hydrogen production from blended waste biomass: pyrolysis, thermodynamic-kinetic analysis and AI-based modelling](https://arxiv.org/abs/2510.15960)
*Sana Kordoghli,Abdelhakim Settar,Oumayma Belaati,Mohammad Alkhatib*

Main category: cs.LG

TL;DR: 该研究通过热解技术转化食物基生物质（咖啡渣和枣核），利用人工智能优化过程建模，旨在实现可持续氢能生产和废物管理。


<details>
  <summary>Details</summary>
Motivation: 探索未充分利用的生物质资源（如咖啡渣和枣核）在可持续氢能生产中的潜力，通过热解技术实现能源回收和废物管理。

Method: 对纯枣核、咖啡渣及其混合样品进行多项分析（工业分析、元素分析、纤维分析、热重分析、动力学分析等），使用等转化率方法（KAS、FWO、Friedman）进行动力学建模，并开发LSTM人工智能模型预测热重曲线。

Result: 混合样品3（25%枣核-75%咖啡渣）具有最佳氢产率潜力但活化能最高（313.24 kJ/mol），混合样品1（75%枣核-25%咖啡渣）活化能最佳（161.75 kJ/mol）。KAS方法被确定为最准确的动力学模型，LSTM模型预测热重曲线精度极高（R²: 0.9996-0.9998）。

Conclusion: 人工智能在热解过程建模中表现出卓越性能，咖啡渣和枣核混合物具有可持续氢能生产的潜力，为生物质能源转化提供了有效的优化方法。

Abstract: This work contributes to advancing sustainable energy and waste management
strategies by investigating the thermochemical conversion of food-based biomass
through pyrolysis, highlighting the role of artificial intelligence (AI) in
enhancing process modelling accuracy and optimization efficiency. The main
objective is to explore the potential of underutilized biomass resources, such
as spent coffee grounds (SCG) and date seeds (DS), for sustainable hydrogen
production. Specifically, it aims to optimize the pyrolysis process while
evaluating the performance of these resources both individually and as blends.
Proximate, ultimate, fibre, TGA/DTG, kinetic, thermodynamic, and Py-Micro GC
analyses were conducted for pure DS, SCG, and blends (75% DS - 25% SCG, 50% DS
- 50% SCG, 25% DS - 75% SCG). Blend 3 offered superior hydrogen yield potential
but had the highest activation energy (Ea: 313.24 kJ/mol), while Blend 1
exhibited the best activation energy value (Ea: 161.75 kJ/mol). The kinetic
modelling based on isoconversional methods (KAS, FWO, Friedman) identified KAS
as the most accurate. These approaches provide a detailed understanding of the
pyrolysis process, with particular emphasis on the integration of artificial
intelligence. An LSTM model trained with lignocellulosic data predicted TGA
curves with exceptional accuracy (R^2: 0.9996-0.9998).

</details>


### [8] [Long Exposure: Accelerating Parameter-Efficient Fine-Tuning for LLMs under Shadowy Sparsity](https://arxiv.org/abs/2510.15964)
*Tuowei Wang,Kun Li,Zixu Hao,Donglin Bai,Ju Ren,Yaoxue Zhang,Ting Cao,Mao Yang*

Main category: cs.LG

TL;DR: Long Exposure是一个高效系统，通过解决微调中特有的Shadowy Sparsity问题来加速参数高效微调(PEFT)，包含三个关键组件：Shadowy-sparsity Exposer、Sequence-oriented Predictor和Dynamic-aware Operator，实现了最高2.49倍的端到端微调加速。


<details>
  <summary>Details</summary>
Motivation: 预训练大语言模型在下游任务中的参数高效微调存在效率低下问题，带来时间投入和运营成本的显著挑战。论文发现了一种微调特有的Shadowy Sparsity形式，但现有方法未能充分解决其加速问题。

Method: 提出Long Exposure系统，包含三个核心组件：1) Shadowy-sparsity Exposer使用延长感知范围捕获更多稀疏性细节；2) Sequence-oriented Predictor提供高效准确预测以处理大序列输入和不断演化的参数；3) Dynamic-aware Operator促进更结构化的计算模式和合并内存访问，解决动态稀疏操作。

Result: 广泛评估表明，Long Exposure在端到端微调中实现了最高2.49倍的加速，优于现有最先进方法。

Conclusion: Long Exposure为加速LLMs的PEFT提供了有前景的进展，通过专门针对Shadowy Sparsity设计的系统组件，显著提升了微调效率。

Abstract: The adaptation of pre-trained large language models (LLMs) to diverse
downstream tasks via fine-tuning is critical for numerous applications.
However, the inefficiency of parameter-efficient fine-tuning (PEFT) techniques
presents significant challenges in terms of time investments and operational
costs. In this paper, we first introduce a nuanced form of sparsity, termed
Shadowy Sparsity, which is distinctive in fine-tuning and has not been
adequately addressed for acceleration. Under Shadowy Sparsity, we propose Long
Exposure, an efficient system to accelerate PEFT for LLMs. Long Exposure
comprises three key components: Shadowy-sparsity Exposer employs a prolonged
sensing range to capture more sparsity details under shadowy sparsity;
Sequence-oriented Predictor provides efficient yet accurate predictions to
handle large sequence inputs and constantly-evolving parameters; and
Dynamic-aware Operator facilitates more structured computational patterns and
coalesced memory accesses, addressing dynamic sparse operations. Extensive
evaluations show that Long Exposure outperforms state-of-the-arts with up to a
$2.49\times$ speedup in end-to-end fine-tuning, offering promising advancements
in accelerating PEFT for LLMs.

</details>


### [9] [Gains: Fine-grained Federated Domain Adaptation in Open Set](https://arxiv.org/abs/2510.15967)
*Zhengyi Zhong,Wenzheng Jiang,Weidong Bao,Ji Wang,Cheems Wang,Guanbo Wang,Yongheng Deng,Ju Ren*

Main category: cs.LG

TL;DR: 本文提出了一种细粒度的联邦域自适应方法Gains，用于解决开放世界中新客户端不断加入的问题，通过知识发现和知识适应来检测和整合新知识，同时保持源域性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的联邦学习场景中，新客户端会不断加入并带来新知识，而传统联邦学习假设封闭世界且客户端数量固定。现有研究在知识发现方面粒度较粗，且往往牺牲源域性能和适应效率。

Method: 将模型分为编码器和分类器，发现编码器提取的特征对域偏移敏感，而分类器参数对类别增量敏感。基于此开发了细粒度知识发现和贡献驱动的聚合技术，并设计了抗遗忘机制来保持源域性能。

Result: 在三种典型数据偏移场景下的多域数据集实验中，Gains在源域和目标域客户端的性能均显著优于其他基线方法。

Conclusion: Gains方法能够有效处理开放世界联邦学习中的新知识发现和适应问题，在保持源域性能的同时提升目标域性能，实现了平衡的自适应。

Abstract: Conventional federated learning (FL) assumes a closed world with a fixed
total number of clients. In contrast, new clients continuously join the FL
process in real-world scenarios, introducing new knowledge. This raises two
critical demands: detecting new knowledge, i.e., knowledge discovery, and
integrating it into the global model, i.e., knowledge adaptation. Existing
research focuses on coarse-grained knowledge discovery, and often sacrifices
source domain performance and adaptation efficiency. To this end, we propose a
fine-grained federated domain adaptation approach in open set (Gains). Gains
splits the model into an encoder and a classifier, empirically revealing
features extracted by the encoder are sensitive to domain shifts while
classifier parameters are sensitive to class increments. Based on this, we
develop fine-grained knowledge discovery and contribution-driven aggregation
techniques to identify and incorporate new knowledge. Additionally, an
anti-forgetting mechanism is designed to preserve source domain performance,
ensuring balanced adaptation. Experimental results on multi-domain datasets
across three typical data-shift scenarios demonstrate that Gains significantly
outperforms other baselines in performance for both source-domain and
target-domain clients. Code is available at:
https://github.com/Zhong-Zhengyi/Gains.

</details>


### [10] [Self-Attention to Operator Learning-based 3D-IC Thermal Simulation](https://arxiv.org/abs/2510.15968)
*Zhen Huang,Hong Wang,Wenkai Yang,Muxi Tang,Depeng Xie,Ting-Jung Lin,Yu Zhang,Wei W. Xing,Lei He*

Main category: cs.LG

TL;DR: SAU-FNO是一种结合自注意力机制和U-Net的傅里叶神经算子框架，用于3D IC热管理，相比传统FEM方法提速842倍，同时保持高精度热预测。


<details>
  <summary>Details</summary>
Motivation: 3D IC中热管理因功率密度增加而日益困难，传统PDE方法虽准确但速度慢，机器学习方法如FNO虽快但存在高频信息丢失和高保真数据依赖问题。

Method: 提出SAU-FNO框架，结合自注意力机制和U-Net与FNO，捕捉长程依赖关系并有效建模局部高频特征，采用迁移学习微调低保真数据以减少高保真数据集需求。

Result: 实验表明SAU-FNO实现了最先进的热预测精度，相比传统FEM方法提供842倍的加速。

Conclusion: SAU-FNO是用于高级3D IC热模拟的高效工具，在精度和速度方面均表现出色。

Abstract: Thermal management in 3D ICs is increasingly challenging due to higher power
densities. Traditional PDE-solving-based methods, while accurate, are too slow
for iterative design. Machine learning approaches like FNO provide faster
alternatives but suffer from high-frequency information loss and high-fidelity
data dependency. We introduce Self-Attention U-Net Fourier Neural Operator
(SAU-FNO), a novel framework combining self-attention and U-Net with FNO to
capture long-range dependencies and model local high-frequency features
effectively. Transfer learning is employed to fine-tune low-fidelity data,
minimizing the need for extensive high-fidelity datasets and speeding up
training. Experiments demonstrate that SAU-FNO achieves state-of-the-art
thermal prediction accuracy and provides an 842x speedup over traditional FEM
methods, making it an efficient tool for advanced 3D IC thermal simulations.

</details>


### [11] [Predict Training Data Quality via Its Geometry in Metric Space](https://arxiv.org/abs/2510.15970)
*Yang Ba,Mohammad Sadeq Abolhasani,Rong Pan*

Main category: cs.LG

TL;DR: 本文提出使用持久同调分析训练数据的几何结构对机器学习模型性能的影响，强调数据表示的丰富性和冗余消除的重要性。


<details>
  <summary>Details</summary>
Motivation: 高质量训练数据是机器学习和人工智能的基础，但数据的几何结构对模型性能的影响尚未充分探索。作者认为数据的表示丰富性和冗余消除对学习结果有重要影响。

Method: 使用持久同调从度量空间中的数据提取拓扑特征，提供了一种超越基于熵的度量来量化多样性的原则性方法。

Result: 研究发现持久同调是分析和增强驱动AI系统的训练数据的强大工具。

Conclusion: 持久同调为理解和优化训练数据的几何结构提供了新的分析框架，有助于提升AI系统的性能。

Abstract: High-quality training data is the foundation of machine learning and
artificial intelligence, shaping how models learn and perform. Although much is
known about what types of data are effective for training, the impact of the
data's geometric structure on model performance remains largely underexplored.
We propose that both the richness of representation and the elimination of
redundancy within training data critically influence learning outcomes. To
investigate this, we employ persistent homology to extract topological features
from data within a metric space, thereby offering a principled way to quantify
diversity beyond entropy-based measures. Our findings highlight persistent
homology as a powerful tool for analyzing and enhancing the training data that
drives AI systems.

</details>


### [12] [DAWP: A framework for global observation forecasting via Data Assimilation and Weather Prediction in satellite observation space](https://arxiv.org/abs/2510.15978)
*Junchao Gong,Jingyi Xu,Ben Fei,Fenghua Ling,Wenlong Zhang,Kun Chen,Wanghan Xu,Weidong Yang,Xiaokang Yang,Lei Bai*

Main category: cs.LG

TL;DR: 提出了DAWP框架，通过人工智能数据同化模块(AIDA)将AI天气预测从再分析数据依赖中解放出来，实现基于观测数据的直接预测，显著提升了预测性能和效率。


<details>
  <summary>Details</summary>
Motivation: 传统AI天气预测方法依赖再分析数据，存在数据同化偏差和时间不一致性问题。观测预测作为一种变革性范式，可以解放AI天气预测对再分析数据的依赖。

Method: 提出DAWP框架，包含AIDA模块和AIWP模块。AIDA使用掩码多模态自编码器(MMAE)同化不规则卫星观测数据；AIWP采用时空解耦transformer和跨区域边界条件(CBC)学习观测空间中的动态特性。

Result: 实验表明AIDA初始化显著提高了AIWP的滚动预测能力和效率。DAWP在全球降水预测中显示出良好应用潜力。

Conclusion: DAWP框架成功实现了从观测数据直接进行天气预测，摆脱了对再分析数据的依赖，为AI天气预测开辟了新途径。

Abstract: Weather prediction is a critical task for human society, where impressive
progress has been made by training artificial intelligence weather prediction
(AIWP) methods with reanalysis data. However, reliance on reanalysis data
limits the AIWPs with shortcomings, including data assimilation biases and
temporal discrepancies. To liberate AIWPs from the reanalysis data, observation
forecasting emerges as a transformative paradigm for weather prediction. One of
the key challenges in observation forecasting is learning spatiotemporal
dynamics across disparate measurement systems with irregular high-resolution
observation data, which constrains the design and prediction of AIWPs. To this
end, we propose our DAWP as an innovative framework to enable AIWPs to operate
in a complete observation space by initialization with an artificial
intelligence data assimilation (AIDA) module. Specifically, our AIDA module
applies a mask multi-modality autoencoder(MMAE)for assimilating irregular
satellite observation tokens encoded by mask ViT-VAEs. For AIWP, we introduce a
spatiotemporal decoupling transformer with cross-regional boundary conditioning
(CBC), learning the dynamics in observation space, to enable sub-image-based
global observation forecasting. Comprehensive experiments demonstrate that AIDA
initialization significantly improves the roll out and efficiency of AIWP.
Additionally, we show that DAWP holds promising potential to be applied in
global precipitation forecasting.

</details>


### [13] [S4ECG: Exploring the impact of long-range interactions for arrhythmia prediction](https://arxiv.org/abs/2510.17406)
*Tiezhi Wang,Wilhelm Haverkamp,Nils Strodthoff*

Main category: cs.LG

TL;DR: S4ECG是一种基于结构化状态空间模型的新型深度学习架构，用于多时段心律失常分类，显著优于单时段方法，在房颤特异性方面表现尤为突出。


<details>
  <summary>Details</summary>
Motivation: 传统心电图分析方法难以同时捕捉全局趋势和局部波形特征的高时间分辨率交互作用，需要桥接全局和局部信号分析。

Method: 引入S4ECG架构，利用结构化状态空间模型进行多时段心律失常分类，系统研究最佳时间依赖窗口。

Result: 多时段联合预测在宏观AUROC上比单时段方法提高1.0-11.6%，房颤特异性从0.718-0.979提升至0.967-0.998，在分布内和分布外均表现出优越性能。

Conclusion: 这项工作推动了心律失常检测算法向时间感知范式的转变，为心电图解释特别是复杂心律失常如房颤和房扑开辟了新可能性。

Abstract: The electrocardiogram (ECG) exemplifies biosignal-based time series with
continuous, temporally ordered structure reflecting cardiac physiological and
pathophysiological dynamics. Detailed analysis of these dynamics has proven
challenging, as conventional methods capture either global trends or local
waveform features but rarely their simultaneous interplay at high temporal
resolution. To bridge global and local signal analysis, we introduce S4ECG, a
novel deep learning architecture leveraging structured state space models for
multi-epoch arrhythmia classification. Our joint multi-epoch predictions
significantly outperform single-epoch approaches by 1.0-11.6% in macro-AUROC,
with atrial fibrillation specificity improving from 0.718-0.979 to 0.967-0.998,
demonstrating superior performance in-distribution and enhanced
out-of-distribution robustness. Systematic investigation reveals optimal
temporal dependency windows spanning 10-20 minutes for peak performance. This
work contributes to a paradigm shift toward temporally-aware arrhythmia
detection algorithms, opening new possibilities for ECG interpretation, in
particular for complex arrhythmias like atrial fibrillation and atrial flutter.

</details>


### [14] [Reliable Inference in Edge-Cloud Model Cascades via Conformal Alignment](https://arxiv.org/abs/2510.17543)
*Jiayi Huang,Sangwoo Park,Nicola Paoletti,Osvaldo Simeone*

Main category: cs.LG

TL;DR: 本文提出了一种基于保形对齐的边缘-云级联机制(CAb)，通过多假设检验方法确保边缘模型预测集满足云级条件覆盖要求，在保持目标条件覆盖的同时显著减少向云端的卸载。


<details>
  <summary>Details</summary>
Motivation: 边缘智能虽然能通过紧凑的端侧模型实现低延迟推理，但保证可靠性仍然具有挑战性。需要确保边缘模型返回的预测集能够以用户指定的概率包含真实标签，就像云模型产生的一样。

Method: 提出基于保形对齐(CAb)的级联机制，将边缘到云端的升级过程建模为多假设检验问题，使用保形对齐来选择哪些输入可以在边缘安全处理。该方法适用于任意边缘预测集，包括保形预测的变体。

Result: 在CIFAR-100图像分类和TeleQnA问答基准测试中，CAb级联方法在保持目标条件覆盖的同时，显著减少了向云端的卸载，预测集大小仅有适度增加。

Conclusion: CAb级联方法为边缘预测提供了统计保证，确保满足云级条件覆盖要求，同时暴露了覆盖度、延迟率和集合大小之间的可调权衡。

Abstract: Edge intelligence enables low-latency inference via compact on-device models,
but assuring reliability remains challenging. We study edge-cloud cascades that
must preserve conditional coverage: whenever the edge returns a prediction set,
it should contain the true label with a user-specified probability, as if
produced by the cloud model. We formalize conditional coverage with respect to
the cloud predictive distribution, and introduce a conformal alignment-based
(CAb) cascading mechanism that certifies this property with user control over
the risk level. Our method casts escalation from edge to cloud models as a
multiple-hypothesis testing (MHT) problem, tailoring conformal alignment (CA)
to select which inputs can be safely handled at the edge. The proposed CAb
model cascading method yields statistical guarantees on the average fraction of
edge decisions that satisfy cloud-level conditional coverage. The procedure
applies to arbitrary edge prediction sets, including variants of conformal
prediction (CP), and exposes a tunable trade-off among coverage, deferral rate,
and set size. Experiments on CIFAR-100 image classification and the TeleQnA
question-answering (QA) benchmark show that the proposed CAb cascade maintains
the target conditional coverage for edge predictions while substantially
reducing offloading to the cloud and incurring modest increases in
prediction-set size.

</details>


### [15] [MEET-Sepsis: Multi-Endogenous-View Enhanced Time-Series Representation Learning for Early Sepsis Prediction Representation Learning for Early Sepsis Prediction](https://arxiv.org/abs/2510.15985)
*Zexi Tan,Tao Xie,Binbin Sun,Xiang Zhang,Yiqun Zhang,Yiu-Ming Cheung*

Main category: cs.LG

TL;DR: 提出MEET-Sepsis框架，通过多内源性视图表示增强机制和级联双卷积时间序列注意力模块，仅需20%ICU监测时间即可实现竞争性的脓毒症预测准确率。


<details>
  <summary>Details</summary>
Motivation: 脓毒症是ICU中死亡率高的威胁生命的感染综合征，早期准确预测对及时干预至关重要，但现有AI方法难以捕捉微弱的早期时间信号。

Method: 采用多内源性视图表示增强机制构建丰富特征视图，结合级联双卷积时间序列注意力模块进行多尺度时间表示学习。

Result: 仅需20%ICU监测时间即可达到与最先进方法竞争性的预测准确率，显著推进了早期脓毒症预测。

Conclusion: MEET-Sepsis框架在早期脓毒症预测方面表现出色，通过广泛验证确认了其有效性。

Abstract: Sepsis is a life-threatening infectious syndrome associated with high
mortality in intensive care units (ICUs). Early and accurate sepsis prediction
(SP) is critical for timely intervention, yet remains challenging due to subtle
early manifestations and rapidly escalating mortality. While AI has improved SP
efficiency, existing methods struggle to capture weak early temporal signals.
This paper introduces a Multi-Endogenous-view Representation Enhancement (MERE)
mechanism to construct enriched feature views, coupled with a Cascaded
Dual-convolution Time-series Attention (CDTA) module for multi-scale temporal
representation learning. The proposed MEET-Sepsis framework achieves
competitive prediction accuracy using only 20% of the ICU monitoring time
required by SOTA methods, significantly advancing early SP. Extensive
validation confirms its efficacy. Code is available at:
https://github.com/yueliangy/MEET-Sepsis.

</details>


### [16] [User Profiles of Sleep Disorder Sufferers: Towards Explainable Clustering and Differential Variable Analysis](https://arxiv.org/abs/2510.15986)
*Sifeddine Sellami,Juba Agoun,Lamia Yessad,Louenas Bounia*

Main category: cs.LG

TL;DR: 提出一种基于聚类的可解释AI方法，用于根据睡眠障碍特征对患者进行分组，并通过可解释性方法识别影响这些病理的关键因素。


<details>
  <summary>Details</summary>
Motivation: 睡眠障碍对患者健康和生活质量有重大影响，但由于症状多样性，诊断仍然复杂。技术进展和医疗数据分析为更好理解这些障碍提供了新视角。

Method: 采用基于聚类的可解释人工智能方法，将患者按不同睡眠障碍特征进行分组，并整合可解释性方法识别关键影响因素。

Result: 在匿名真实数据上的实验证明了该方法的有效性和相关性。

Conclusion: 所提出的基于聚类的可解释AI方法能够有效识别睡眠障碍患者的不同特征模式，并为理解这些障碍提供了有价值的见解。

Abstract: Sleep disorders have a major impact on patients' health and quality of life,
but their diagnosis remains complex due to the diversity of symptoms. Today,
technological advances, combined with medical data analysis, are opening new
perspectives for a better understanding of these disorders. In particular,
explainable artificial intelligence (XAI) aims to make AI model decisions
understandable and interpretable for users. In this study, we propose a
clustering-based method to group patients according to different sleep disorder
profiles. By integrating an explainable approach, we identify the key factors
influencing these pathologies. An experiment on anonymized real data
illustrates the effectiveness and relevance of our approach.

</details>


### [17] [Still Competitive: Revisiting Recurrent Models for Irregular Time Series Prediction](https://arxiv.org/abs/2510.16161)
*Ankitkumar Joshi,Milos Hauskrecht*

Main category: cs.LG

TL;DR: GRUwE是一种基于RNN的架构，用于处理不规则采样的多元时间序列预测问题，通过可学习的指数衰减机制实现连续时间预测，在多个真实世界基准测试中达到或超越现有最先进方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前处理不规则采样时间序列的复杂学习架构的真实效益不明确，需要验证简单高效的RNN改进方法是否仍具有竞争力。

Method: 提出GRUwE（带指数基函数的门控循环单元），通过两种重置机制更新马尔可夫状态：观测触发重置和时间触发重置，使用可学习的指数衰减支持连续时间预测。

Result: 在多个真实世界基准测试中，GRUwE在下一观测和下一事件预测任务上达到竞争性甚至优于现有最先进方法的性能。

Conclusion: GRUwE不仅性能优越，而且实现简单、超参数调优需求少，显著降低了在线部署的计算开销。

Abstract: Modeling irregularly sampled multivariate time series is a persistent
challenge in domains like healthcare and sensor networks. While recent works
have explored a variety of complex learning architectures to solve the
prediction problems for irregularly sampled time series, it remains unclear
what are the true benefits of some of these architectures, and whether clever
modifications of simpler and more efficient RNN-based algorithms are still
competitive, i.e. they are on par with or even superior to these methods. In
this work, we propose and study GRUwE: Gated Recurrent Unit with Exponential
basis functions, that builds upon RNN-based architectures for observations made
at irregular times. GRUwE supports both regression-based and event-based
predictions in continuous time. GRUwE works by maintaining a Markov state
representation of the time series that updates with the arrival of irregular
observations. The Markov state update relies on two reset mechanisms: (i)
observation-triggered reset, and (ii) time-triggered reset of the GRU state
using learnable exponential decays, to support the predictions in continuous
time. Our empirical evaluations across several real-world benchmarks on
next-observation and next-event prediction tasks demonstrate that GRUwE can
indeed achieve competitive to superior performance compared to the recent
state-of-the-art (SOTA) methods. Thanks to its simplicity, GRUwE offers
compelling advantages: it is easy to implement, requires minimal
hyper-parameter tuning efforts, and significantly reduces the computational
overhead in the online deployment.

</details>


### [18] [Expressive Reward Synthesis with the Runtime Monitoring Language](https://arxiv.org/abs/2510.16185)
*Daniel Donnelly,Angelo Ferrando,Francesco Belardinelli*

Main category: cs.LG

TL;DR: 提出了一种基于运行时监控语言（RML）的新型语言奖励机，能够表达非正则、非马尔可夫任务，解决了传统奖励机表达能力有限的问题。


<details>
  <summary>Details</summary>
Motivation: 强化学习中奖励函数通常被视为黑盒映射，缺乏解释性；传统奖励机只能表达正则语言，无法处理计数或参数化条件等复杂行为。

Method: 基于运行时监控语言（RML）构建新型语言奖励机，利用RML的内置内存机制来指定非正则、非马尔可夫任务的奖励函数。

Result: 实验证明了该方法在表达能力上的优势，相比现有基于奖励机的方法，在事件处理和任务规范方面更加灵活。

Conclusion: 基于RML的语言奖励机扩展了奖励函数的表达能力，能够处理更复杂的非正则、非马尔可夫任务，提高了强化学习的灵活性和解释性。

Abstract: A key challenge in reinforcement learning (RL) is reward (mis)specification,
whereby imprecisely defined reward functions can result in unintended, possibly
harmful, behaviours. Indeed, reward functions in RL are typically treated as
black-box mappings from state-action pairs to scalar values. While effective in
many settings, this approach provides no information about why rewards are
given, which can hinder learning and interpretability. Reward Machines address
this issue by representing reward functions as finite state automata, enabling
the specification of structured, non-Markovian reward functions. However, their
expressivity is typically bounded by regular languages, leaving them unable to
capture more complex behaviours such as counting or parametrised conditions. In
this work, we build on the Runtime Monitoring Language (RML) to develop a novel
class of language-based Reward Machines. By leveraging the built-in memory of
RML, our approach can specify reward functions for non-regular, non-Markovian
tasks. We demonstrate the expressiveness of our approach through experiments,
highlighting additional advantages in flexible event-handling and task
specification over existing Reward Machine-based methods.

</details>


### [19] [Stratos: An End-to-End Distillation Pipeline for Customized LLMs under Distributed Cloud Environments](https://arxiv.org/abs/2510.15992)
*Ziming Dai,Tuo Zhang,Fei Gao,Xingyi Cai,Xiaofei Wang,Cheng Zhang,Wenyu Wang,Chengjie Zang*

Main category: cs.LG

TL;DR: Stratos是一个端到端的LLM蒸馏管道，通过自动化服务器选择、师生模型配对和蒸馏策略，在满足用户定义约束下优化云部署，在特定领域任务中实现4倍精度提升并降低延迟和成本。


<details>
  <summary>Details</summary>
Motivation: 工业对定制化、成本效益高的大型语言模型需求增长，现有蒸馏框架需要人工干预且难以满足复杂用户需求。

Method: 提出Stratos端到端LLM蒸馏管道，自动化服务器和模型选择、知识蒸馏和分布式云环境部署，根据任务复杂度动态调整蒸馏策略。

Result: 在特定麻将推理任务中，学生模型达到GPT-4o教师基准4倍精度，同时降低延迟和成本而不影响准确性。

Conclusion: Stratos展示了在垂直领域LLM部署中的潜力，能够自动满足复杂约束条件并优化性能。

Abstract: The growing industrial demand for customized and cost-efficient large
language models (LLMs) is fueled by the rise of vertical, domain-specific tasks
and the need to optimize performance under constraints such as latency and
budget. Knowledge distillation, as an efficient model compression and transfer
technique, offers a feasible solution. However, existing distillation
frameworks often require manual intervention and struggle to meet such complex
user-defined distillation requirements. To bridge this gap, we propose Stratos,
an end-to-end LLM distillation pipeline that automates server and model
selection, knowledge distillation, and deployment in distributed cloud
environments. Given user-defined constraints on model performance and system
budget, Stratos automatically selects Pareto-optimal servers, dynamically
matches teacher-student pairs, and adapts distillation strategies based on task
complexity to optimize cloud hosting. Experiments show that Stratos produces a
student model that achieves four times the accuracy of its GPT-4o teacher
baseline on a rare, domain-specific Mahjong reasoning task with reverse
synthetic data and knowledge injection. Moreover, it achieves reduced latency
and cost without compromising accuracy. These results highlight its promise for
vertical-domain LLM deployment.

</details>


### [20] [Using Kolmogorov-Smirnov Distance for Measuring Distribution Shift in Machine Learning](https://arxiv.org/abs/2510.15996)
*Ozan K. Tonguz,Federico Taschin*

Main category: cs.LG

TL;DR: 该论文提出使用Kolmogorov-Smirnov检验来监测和量化机器学习系统中的分布偏移问题，特别是在智能交通应用中，KS距离=0.02可导致强化学习智能体在单个交叉口的旅行时间增加约50%。


<details>
  <summary>Details</summary>
Motivation: 解决机器学习系统中测试数据与训练数据概率分布偏离的问题，这种分布偏移会导致预测误差，在安全关键应用中尤其危险。

Method: 使用Kolmogorov-Smirnov检验来测量分布偏移，利用KS距离量化分布偏移及其对AI智能体性能的影响。

Result: 研究表明KS距离可作为监测分布偏移的有价值统计工具，即使KS=0.02的小偏移也会导致强化学习智能体在单个交叉口的旅行时间显著增加约50%。

Conclusion: 在基于AI的智能交通系统中使用KS检验和KS距离，可以实时评估AI智能体的性能退化，帮助智能体以更明智的方式应对分布偏移。

Abstract: One of the major problems in Machine Learning (ML) and Artificial
Intelligence (AI) is the fact that the probability distribution of the test
data in the real world could deviate substantially from the probability
distribution of the training data set. When this happens, the predictions of an
ML system or an AI agent could involve large errors which is very troublesome
and undesirable. While this is a well-known hard problem plaguing the AI and ML
systems' accuracy and reliability, in certain applications such errors could be
critical for safety and reliability of AI and ML systems. One approach to deal
with this problem is to monitor and measure the deviation in the probability
distribution of the test data in real time and to compensate for this
deviation. In this paper, we propose and explore the use of Kolmogorov-Smirnov
(KS) Test for measuring the distribution shift and we show how the KS distance
can be used to quantify the distribution shift and its impact on an AI agent's
performance. Our results suggest that KS distance could be used as a valuable
statistical tool for monitoring and measuring the distribution shift. More
specifically, it is shown that even a distance of KS=0.02 could lead to about
50\% increase in the travel time at a single intersection using a Reinforcement
Learning agent which is quite significant. It is hoped that the use of KS Test
and KS distance in AI-based smart transportation could be an important step
forward for gauging the performance degradation of an AI agent in real time and
this, in turn, could help the AI agent to cope with the distribution shift in a
more informed manner.

</details>


### [21] [Benchmarking noisy label detection methods](https://arxiv.org/abs/2510.16211)
*Henrique Pickler,Jorge K. S. Kamassury,Danilo Silva*

Main category: cs.LG

TL;DR: 本文对标签噪声检测方法进行了系统基准测试，通过将方法分解为三个核心组件（标签一致性函数、聚合方法和信息收集方式）来比较不同方法，发现在大多数场景下，使用对数边际作为标签一致性函数、平均概率聚合和样本内信息收集的组合效果最佳。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据集中的标签噪声问题普遍存在，会影响模型训练和验证效果。虽然已有多种噪声标签检测技术，但缺乏对最优方法的明确共识，需要系统性的比较和评估。

Method: 将噪声检测方法分解为三个基本组件：标签一致性函数、聚合方法和信息收集方式（样本内vs样本外），提出统一的基准任务和新的评估指标（固定操作点的假阴性率），在视觉和表格数据集上对合成和真实噪声条件进行全面评估。

Result: 研究发现，使用对数边际作为标签一致性函数、平均概率聚合和样本内信息收集的组合在大多数场景下表现最佳，为不同应用场景下的方法选择提供了实用指导。

Conclusion: 通过系统性的分解和比较，本文为设计新的检测方法和为特定应用选择合适技术提供了实用指导，识别出了在多种噪声条件下表现最优的检测方法组合。

Abstract: Label noise is a common problem in real-world datasets, affecting both model
training and validation. Clean data are essential for achieving strong
performance and ensuring reliable evaluation. While various techniques have
been proposed to detect noisy labels, there is no clear consensus on optimal
approaches. We perform a comprehensive benchmark of detection methods by
decomposing them into three fundamental components: label agreement function,
aggregation method, and information gathering approach (in-sample vs
out-of-sample). This decomposition can be applied to many existing detection
methods, and enables systematic comparison across diverse approaches. To fairly
compare methods, we propose a unified benchmark task, detecting a fraction of
training samples equal to the dataset's noise rate. We also introduce a novel
metric: the false negative rate at this fixed operating point. Our evaluation
spans vision and tabular datasets under both synthetic and real-world noise
conditions. We identify that in-sample information gathering using average
probability aggregation combined with the logit margin as the label agreement
function achieves the best results across most scenarios. Our findings provide
practical guidance for designing new detection methods and selecting techniques
for specific applications.

</details>


### [22] [Structured Temporal Causality for Interpretable Multivariate Time Series Anomaly Detection](https://arxiv.org/abs/2510.16511)
*Dongchan Cho,Jiho Han,Keumyeong Kang,Minsang Kim,Honggyu Ryu,Namsoon Jung*

Main category: cs.LG

TL;DR: OracleAD是一个简单可解释的无监督多元时间序列异常检测框架，通过因果嵌入建模时间动态，使用自注意力机制捕捉空间关系，并将投影嵌入对齐到表示正常状态关系的稳定潜在结构(SLS)，通过预测误差和SLS偏差的双重评分机制识别异常。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的多元时间序列异常稀少且通常无标签，现有方法依赖复杂架构，只能检测异常片段片段且夸大性能。

Method: 将每个变量的过去序列编码为因果嵌入来联合预测当前时间点和重建输入窗口，使用自注意力机制将嵌入投影到共享潜在空间捕捉空间关系，并将投影嵌入对齐到稳定潜在结构(SLS)。

Result: 在多个真实世界数据集和评估协议上实现了最先进的结果，同时通过SLS保持可解释性。

Conclusion: OracleAD通过直接定位违反正常数据时间因果性的嵌入，在嵌入级别直接识别根本原因变量，实现了有效的异常检测和诊断。

Abstract: Real-world multivariate time series anomalies are rare and often unlabeled.
Additionally, prevailing methods rely on increasingly complex architectures
tuned to benchmarks, detecting only fragments of anomalous segments and
overstating performance. In this paper, we introduce OracleAD, a simple and
interpretable unsupervised framework for multivariate time series anomaly
detection. OracleAD encodes each variable's past sequence into a single causal
embedding to jointly predict the present time point and reconstruct the input
window, effectively modeling temporal dynamics. These embeddings then undergo a
self-attention mechanism to project them into a shared latent space and capture
spatial relationships. These relationships are not static, since they are
modeled by a property that emerges from each variable's temporal dynamics. The
projected embeddings are aligned to a Stable Latent Structure (SLS)
representing normal-state relationships. Anomalies are identified using a dual
scoring mechanism based on prediction error and deviation from the SLS,
enabling fine-grained anomaly diagnosis at each time point and across
individual variables. Since any noticeable SLS deviation originates from
embeddings that violate the learned temporal causality of normal data, OracleAD
directly pinpoints the root-cause variables at the embedding level. OracleAD
achieves state-of-the-art results across multiple real-world datasets and
evaluation protocols, while remaining interpretable through SLS.

</details>


### [23] [eDCF: Estimating Intrinsic Dimension using Local Connectivity](https://arxiv.org/abs/2510.16513)
*Dhruv Gupta,Aditya Nagarsekar,Vraj Shah,Sujith Thomas*

Main category: cs.LG

TL;DR: 本文提出了一种基于连通性因子(CF)的新型可扩展并行方法eDCF，用于在不同尺度下稳健估计高维数据的本征维度，在噪声环境下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现代数据集通常包含具有复杂依赖关系的高维特征，而本征维度估计面临尺度依赖的挑战：在精细尺度下噪声会膨胀估计值，在粗粒度尺度下估计值稳定到较低的尺度不变值。

Method: 引入基于连通性因子(CF)的eDCF方法，这是一种局部连通性度量方法，具有可扩展性和并行化能力。

Result: 在合成基准测试中，该方法与领先估计器性能相当，在中等至高噪声水平和大数据集下，精确本征维度匹配率高达25.0%，优于MLE(16.7%)和TWO-NN(12.5%)。

Conclusion: eDCF方法能够准确检测决策边界中的分形几何结构，证实了其在分析现实结构化数据方面的实用性。

Abstract: Modern datasets often contain high-dimensional features exhibiting complex
dependencies. To effectively analyze such data, dimensionality reduction
methods rely on estimating the dataset's intrinsic dimension (id) as a measure
of its underlying complexity. However, estimating id is challenging due to its
dependence on scale: at very fine scales, noise inflates id estimates, while at
coarser scales, estimates stabilize to lower, scale-invariant values. This
paper introduces a novel, scalable, and parallelizable method called eDCF,
which is based on Connectivity Factor (CF), a local connectivity-based metric,
to robustly estimate intrinsic dimension across varying scales. Our method
consistently matches leading estimators, achieving comparable values of mean
absolute error (MAE) on synthetic benchmarks with noisy samples. Moreover, our
approach also attains higher exact intrinsic dimension match rates, reaching up
to 25.0% compared to 16.7% for MLE and 12.5% for TWO-NN, particularly excelling
under medium to high noise levels and large datasets. Further, we showcase our
method's ability to accurately detect fractal geometries in decision
boundaries, confirming its utility for analyzing realistic, structured data.

</details>


### [24] [Realizing LLMs' Causal Potential Requires Science-Grounded, Novel Benchmarks](https://arxiv.org/abs/2510.16530)
*Ashutosh Srivastava,Lokesh Nagalapatti,Gautam Jajoo,Aniket Vashishtha,Parameswari Krishnamurthy,Amit Sharma*

Main category: cs.LG

TL;DR: 论文质疑LLM在因果发现中的真实能力，指出现有评估存在数据泄露问题，提出基于新科学研究的评估协议和结合LLM知识与统计方法的混合方法。


<details>
  <summary>Details</summary>
Motivation: 挑战LLM在因果发现中表现优异的说法，因为现有评估可能受到预训练数据泄露的影响，需要开发更可靠的评估方法和实用的混合方法。

Method: 提出两个关键转变：开发基于新科学研究的评估协议以防止数据泄露，设计结合LLM知识和数据驱动统计的混合方法。通过从LLM训练截止后发布的科学文献中提取因果图来创建新基准。

Result: 相比BNLearn基准中LLM接近完美的表现，在作者策划的图上LLM表现差得多。使用LLM预测作为经典PC算法的先验显著提高了准确性，优于纯LLM和纯统计方法。

Conclusion: 呼吁社区采用基于科学、抗泄露的基准，并投资于适合真实世界研究的混合因果发现方法。

Abstract: Recent claims of strong performance by Large Language Models (LLMs) on causal
discovery are undermined by a key flaw: many evaluations rely on benchmarks
likely included in pretraining corpora. Thus, apparent success suggests that
LLM-only methods, which ignore observational data, outperform classical
statistical approaches. We challenge this narrative by asking: Do LLMs truly
reason about causal structure, and how can we measure it without memorization
concerns? Can they be trusted for real-world scientific discovery? We argue
that realizing LLMs' potential for causal analysis requires two shifts: (P.1)
developing robust evaluation protocols based on recent scientific studies to
guard against dataset leakage, and (P.2) designing hybrid methods that combine
LLM-derived knowledge with data-driven statistics. To address P.1, we encourage
evaluating discovery methods on novel, real-world scientific studies. We
outline a practical recipe for extracting causal graphs from recent
publications released after an LLM's training cutoff, ensuring relevance and
preventing memorization while capturing both established and novel relations.
Compared to benchmarks like BNLearn, where LLMs achieve near-perfect accuracy,
they perform far worse on our curated graphs, underscoring the need for
statistical grounding. Supporting P.2, we show that using LLM predictions as
priors for the classical PC algorithm significantly improves accuracy over both
LLM-only and purely statistical methods. We call on the community to adopt
science-grounded, leakage-resistant benchmarks and invest in hybrid causal
discovery methods suited to real-world inquiry.

</details>


### [25] [Data Reliability Scoring](https://arxiv.org/abs/2510.17085)
*Yiling Chen,Shi Feng,Paul Kattuman,Fang-Yi Yu*

Main category: cs.LG

TL;DR: 提出Gram行列式评分方法，用于在无法获取真实数据的情况下评估数据集的可靠性，该方法具有实验无关性，能有效衡量报告数据与真实数据的偏差程度。


<details>
  <summary>Details</summary>
Motivation: 解决在无法获取真实数据的情况下，如何评估来自潜在策略性来源的数据集可靠性问题。真实数据不可观测，只能看到依赖于真实数据的未知统计实验结果。

Method: 提出Gram行列式评分，通过计算描述观测数据和实验结果经验分布的向量所张成的体积来度量可靠性。该方法具有实验无关性，即无论实验如何，都能产生相同的数据集可靠性排序。

Result: 在合成噪声模型、CIFAR-10嵌入和真实就业数据上的实验表明，Gram行列式评分能够有效捕捉不同观测过程中的数据质量。

Conclusion: Gram行列式评分是一种有效的可靠性评估方法，能够在缺乏真实数据的情况下，保持基于真实数据的可靠性排序，并具有实验无关性的独特优势。

Abstract: How can we assess the reliability of a dataset without access to ground
truth? We introduce the problem of reliability scoring for datasets collected
from potentially strategic sources. The true data are unobserved, but we see
outcomes of an unknown statistical experiment that depends on them. To
benchmark reliability, we define ground-truth-based orderings that capture how
much reported data deviate from the truth. We then propose the Gram determinant
score, which measures the volume spanned by vectors describing the empirical
distribution of the observed data and experiment outcomes. We show that this
score preserves several ground-truth based reliability orderings and, uniquely
up to scaling, yields the same reliability ranking of datasets regardless of
the experiment -- a property we term experiment agnosticism. Experiments on
synthetic noise models, CIFAR-10 embeddings, and real employment data
demonstrate that the Gram determinant score effectively captures data quality
across diverse observation processes.

</details>


### [26] [Adapting to Stochastic and Adversarial Losses in Episodic MDPs with Aggregate Bandit Feedback](https://arxiv.org/abs/2510.17103)
*Shinji Ito,Kevin Jamieson,Haipeng Luo,Arnab Maiti,Taira Tsuchiya*

Main category: cs.LG

TL;DR: 该论文提出了首个在聚合bandit反馈下的表格MDP最佳两全(BOBW)算法，在已知转移概率时实现O(log T)随机遗憾和O(√T)对抗遗憾，并建立了匹配的下界证明最优性。


<details>
  <summary>Details</summary>
Motivation: 研究在聚合bandit反馈模型下的在线学习问题，该模型下学习者只能观察到每个episode的累积损失而非单个状态-动作对的损失。现有工作仅关注最坏情况分析，本文首次研究能在随机和对抗环境中都实现低遗憾的BOBW算法。

Method: 结合了基于占用度量的FTRL、自边界技术以及受在线最短路径问题启发的新损失估计器。对于未知转移概率的情况，还融入了基于置信度的技术。

Result: 在已知转移概率时，算法在随机环境中达到O(log T)遗憾，在对抗环境中达到O(√T)遗憾，并建立了匹配的下界。同时为最短路径问题提供了首个个体间隙相关的下界和近最优BOBW算法。

Conclusion: 成功设计了首个在聚合bandit反馈下表格MDP的BOBW算法，证明了其最优性，并将方法扩展到未知转移概率的情况，为在线强化学习中的聚合反馈问题提供了理论保证。

Abstract: We study online learning in finite-horizon episodic Markov decision processes
(MDPs) under the challenging aggregate bandit feedback model, where the learner
observes only the cumulative loss incurred in each episode, rather than
individual losses at each state-action pair. While prior work in this setting
has focused exclusively on worst-case analysis, we initiate the study of
best-of-both-worlds (BOBW) algorithms that achieve low regret in both
stochastic and adversarial environments. We propose the first BOBW algorithms
for episodic tabular MDPs with aggregate bandit feedback. In the case of known
transitions, our algorithms achieve $O(\log T)$ regret in stochastic settings
and ${O}(\sqrt{T})$ regret in adversarial ones. Importantly, we also establish
matching lower bounds, showing the optimality of our algorithms in this
setting. We further extend our approach to unknown-transition settings by
incorporating confidence-based techniques. Our results rely on a combination of
FTRL over occupancy measures, self-bounding techniques, and new loss estimators
inspired by recent advances in online shortest path problems. Along the way, we
also provide the first individual-gap-dependent lower bounds and demonstrate
near-optimal BOBW algorithms for shortest path problems with bandit feedback.

</details>


### [27] [AMS-QUANT: Adaptive Mantissa Sharing for Floating-point Quantization](https://arxiv.org/abs/2510.16045)
*Mengtao Lv,Ruiqi Zhu,Xinyu Wang,Yun Li*

Main category: cs.LG

TL;DR: AMS-Quant是一种新的浮点量化方法，通过引入非整数位宽量化和两种关键技术（尾数位共享和自适应搜索），在保持精度的同时显著加速大语言模型推理。


<details>
  <summary>Details</summary>
Motivation: 大语言模型参数规模庞大带来存储和推理效率瓶颈，浮点量化虽能加速推理但传统方法局限于整数位宽，需要探索更精细的量化方法来接近量化最佳点。

Method: 提出AMS-Quant方法：1）尾数位共享技术，将k个量化权重分组共享最低有效尾数位；2）自适应搜索技术，采用离线优化策略最小化共享带来的精度损失；3）实现高效CUDA线性核，将内存节省转化为实际延迟降低。

Result: 实验表明AMS-Quant可将模型量化为FP-5.33-e2m3和FP4.25-e2m2，相比FP16推理分别实现2.8倍和3.2倍的解码加速，且精度损失可忽略不计。

Conclusion: AMS-Quant首次将浮点量化从整数位宽扩展到非整数位宽，通过创新技术有效解决了大语言模型推理的存储和效率瓶颈问题。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in
various kinds of tasks, while the billion or even trillion parameters bring
storage and efficiency bottlenecks for inference. Quantization, particularly
floating-point quantization, is known to be capable of speeding up LLM
inference by reducing memory footprint and data movement during the inference
process. For the first time, we advance the floating-point quantization
exploration from integer bitwidths to non-integer bit-widths, namely AMS-Quant,
to further approach the quantization sweet spot. AMS-Quant incorporates two
novel techniques to put it into effect: (1) it proposes Mantissa-bit Sharing,
which groups k quantized weights and lets them share the least significant
mantissa bit, allowing us to further approach the minimum quantization
bit-width without accuracy loss. (2) It introduces Adaptive Searching, which
employs an offline optimization strategy to minimize the accuracy degradation
introduced by sharing. Moreover, AMS-Quant is also prototyped as efficient CUDA
Linear kernels, which translates memory savings into wall-clock latency
reduction by reducing memory access. Extensive experiments on large-scale
datasets and models show that AMS-Quant can quantize the model to FP-5.33-e2m3
and FP4.25-e2m2, and significantly speed up the LLM decoding over FP16
inference (2.8x and 3.2x), with negligible accuracy loss.

</details>


### [28] [GUIrilla: A Scalable Framework for Automated Desktop UI Exploration](https://arxiv.org/abs/2510.16051)
*Sofiya Garkot,Maksym Shamrai,Ivan Synytsia,Mariya Hirna*

Main category: cs.LG

TL;DR: GUIrilla是一个自动化可扩展框架，通过原生可访问性API系统探索应用程序，解决GUI自动化中的数据收集挑战。该框架构建了GUIrilla-Task数据集，包含27,171个功能基础任务，覆盖1,108个macOS应用，显著提升LLM智能体在UI任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 解决复杂图形用户界面自动化中的数据收集挑战，当前数据可用性受限于昂贵的手动标注、闭源数据集和表面级合成流程，特别是在macOS生态系统中的代表性不足。

Method: 使用原生可访问性API系统探索应用程序，将发现的界面元素和爬虫动作组织成层次化GUI图，采用专门的交互处理器实现全面应用覆盖，构建大规模功能基础任务数据集。

Result: 构建了GUIrilla-Task数据集（27,171个任务，1,108个应用），在ScreenSpot Pro基准测试中显著优于合成基线，使用数据量减少97%。发布了macapptree开源库、GUIrilla-Gold基准测试和框架代码。

Conclusion: GUIrilla框架有效解决了桌面自动化中的数据收集瓶颈，通过系统化应用探索和大规模数据集构建，显著提升了LLM智能体在复杂GUI环境中的性能，推动了桌面自主性的开放研究。

Abstract: Autonomous agents capable of operating complex graphical user interfaces
(GUIs) have the potential to transform desktop automation. While recent
advances in large language models (LLMs) have significantly improved UI
understanding, navigating full-window, multi-application desktop environments
remains a major challenge. Data availability is limited by costly manual
annotation, closed-source datasets and surface-level synthetic pipelines. We
introduce GUIrilla, an automated scalable framework that systematically
explores applications via native accessibility APIs to address the critical
data collection challenge in GUI automation. Our framework focuses on macOS -
an ecosystem with limited representation in current UI datasets - though many
of its components are designed for broader cross-platform applicability.
GUIrilla organizes discovered interface elements and crawler actions into
hierarchical GUI graphs and employs specialized interaction handlers to achieve
comprehensive application coverage. Using the application graphs from GUIrilla
crawler, we construct and release GUIrilla-Task, a large-scale dataset of
27,171 functionally grounded tasks across 1,108 macOS applications, each
annotated with full-desktop and window-level screenshots, accessibility
metadata, and semantic action traces. Empirical results show that tuning
LLM-based agents on GUIrilla-Task significantly improves performance on
downstream UI tasks, outperforming synthetic baselines on the ScreenSpot Pro
benchmark while using 97% less data. We also release macapptree, an open-source
library for reproducible collection of structured accessibility metadata, along
with the full GUIrilla-Task dataset, the manually verified GUIrilla-Gold
benchmark, and the framework code to support open research in desktop autonomy.

</details>


### [29] [Uncertainty-aware data assimilation through variational inference](https://arxiv.org/abs/2510.17268)
*Anthony Frion,David S Greenberg*

Main category: cs.LG

TL;DR: 本文提出了一种基于变分推断的扩展方法，将确定性机器学习方法扩展到状态预测遵循多元高斯分布的情况，用于数据同化中的不确定性建模。


<details>
  <summary>Details</summary>
Motivation: 数据同化涉及将动态模型与噪声和不完整观测相结合来推断系统状态，在大多数设置中都存在不确定性。现有的确定性机器学习方法需要扩展到能够处理不确定性的框架。

Method: 基于变分推断，构建了一个状态预测遵循多元高斯分布的模型，使用混沌Lorenz-96动力学作为测试平台，并可以集成到更广泛的变分数据同化流程中。

Result: 新模型能够获得近乎完美校准的预测，并且随着数据同化窗口长度的增加，可以在更广泛的变分数据同化流程中实现更大的效益。

Conclusion: 提出的基于变分推断的随机方法在数据同化中能够有效处理不确定性，提供校准良好的预测，并展示了在扩展数据同化窗口时的优势。

Abstract: Data assimilation, consisting in the combination of a dynamical model with a
set of noisy and incomplete observations in order to infer the state of a
system over time, involves uncertainty in most settings. Building upon an
existing deterministic machine learning approach, we propose a variational
inference-based extension in which the predicted state follows a multivariate
Gaussian distribution. Using the chaotic Lorenz-96 dynamics as a testing
ground, we show that our new model enables to obtain nearly perfectly
calibrated predictions, and can be integrated in a wider variational data
assimilation pipeline in order to achieve greater benefit from increasing
lengths of data assimilation windows. Our code is available at
https://github.com/anthony-frion/Stochastic_CODA.

</details>


### [30] [Stochastic Difference-of-Convex Optimization with Momentum](https://arxiv.org/abs/2510.17503)
*El Mahdi Chayti,Martin Jaggi*

Main category: cs.LG

TL;DR: 本文证明了动量方法对于随机DC优化的重要性，能够在任何批量大小下实现收敛，而无需动量则可能无法收敛。


<details>
  <summary>Details</summary>
Motivation: 随机DC优化在机器学习中广泛应用，但在小批量大小下的收敛特性尚未被充分理解。现有方法通常需要大批量或强噪声假设，限制了实际应用。

Method: 提出基于动量的算法，利用标准平滑性和有界方差假设（针对凹部分），证明动量是实现收敛的关键因素。

Result: 理论证明动量方法能够在任何批量大小下实现收敛，而无需动量则可能无法收敛，无论步长如何选择。实验结果表明该算法具有强大的实证性能。

Conclusion: 动量是随机DC优化中实现收敛的必要条件，提出的动量算法在理论和实证上都表现出色，解决了小批量场景下的收敛问题。

Abstract: Stochastic difference-of-convex (DC) optimization is prevalent in numerous
machine learning applications, yet its convergence properties under small batch
sizes remain poorly understood. Existing methods typically require large
batches or strong noise assumptions, which limit their practical use. In this
work, we show that momentum enables convergence under standard smoothness and
bounded variance assumptions (of the concave part) for any batch size. We prove
that without momentum, convergence may fail regardless of stepsize,
highlighting its necessity. Our momentum-based algorithm achieves provable
convergence and demonstrates strong empirical performance.

</details>


### [31] [MNO: Multiscale Neural Operator for Computational Fluid Dynamics with 3D Point Cloud Data](https://arxiv.org/abs/2510.16071)
*Qinxuan Wang,Chuang Wang,Mingyu Zhang,Jingwei Sun,Peipei Yang,Shuo Tang,Shiming Xiang*

Main category: cs.LG

TL;DR: 提出了一种用于三维非结构化点云计算流体动力学的多尺度神经算子(MNO)，通过显式分解三个尺度的信息来提升精度和可扩展性，在四个基准测试中均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有神经算子在求解偏微分方程时仍存在精度和可扩展性限制，特别是在不规则域上流体流动表现出丰富的多尺度结构时。

Method: MNO架构显式分解三个尺度：全局维度收缩注意力模块处理长程依赖，局部图注意力模块处理邻域级交互，微观点级注意力模块处理精细细节。

Result: 在四个涵盖稳态和非稳态流动场景的基准测试中，MNO始终优于最先进基线，预测误差降低5%至40%，在具有30万个点的挑战性3D CFD问题中表现出更好的鲁棒性。

Conclusion: 显式多尺度设计对神经算子至关重要，MNO为在不规则域上学习复杂流体动力学提供了一个可扩展框架。

Abstract: Neural operators have emerged as a powerful data-driven paradigm for solving
Partial Differential Equations (PDEs), offering orders-of-magnitude
acceleration over traditional solvers. However, existing approaches still
suffer from limited accuracy and scalability, particularly on irregular domains
where fluid flows exhibit rich multiscale structures. In this work, we
introduce the Multiscale Neural Operator (MNO), a new architecture for
Computational Fluid Dynamics (CFD) on three-dimensional (3D) unstructured point
clouds. MNO explicitly decomposes information across three scales: a global
dimension-shrinkage attention module for long-range dependencies, a local graph
attention module for neighborhood-level interactions, and a micro point-wise
attention module for fine-grained details. This design preserves multiscale
inductive biases while remaining computationally efficient. We evaluate MNO on
four diverse benchmarks, covering both steady-state and unsteady flow scenarios
with up to 300K points. Across all tasks, MNO consistently outperforms
state-of-the-art baselines, reducing prediction errors by 5% to 40% and
demonstrating improved robustness in challenging 3D CFD problems. Our results
highlight the importance of explicit multiscale design for neural operators and
establish MNO as a scalable framework for learning complex fluid dynamics on
irregular domains.

</details>


### [32] [Early-stopping for Transformer model training](https://arxiv.org/abs/2510.16074)
*Jing He,Hua Jiang,Cheng Li,Siqian Xin,Shuzhen Yang*

Main category: cs.LG

TL;DR: 本文基于随机矩阵理论提出分析Transformer训练动态的理论框架，推导出原则性的早停准则，通过自注意力矩阵的谱密度演化识别训练三阶段，并提出两个无需验证的收敛判断标准。


<details>
  <summary>Details</summary>
Motivation: 理解Transformer训练动态的底层机制，为性能改进提供理论依据，并建立无需验证数据的早停准则。

Method: 基于随机矩阵理论分析自注意力矩阵的谱密度演化，使用幂律拟合作为探针识别训练阶段，提出定量度量重尾动态和谱特征收敛标志。

Result: 发现浅层自注意力矩阵V的谱密度始终演化为重尾分布，训练可分为结构探索、重尾结构稳定和收敛饱和三阶段，提出的两个准则具有强一致性。

Conclusion: 随机矩阵理论为监控和诊断Transformer模型训练进展提供了有效工具，提出的早停准则具有实用价值。

Abstract: This work introduces a novel theoretical framework grounded in Random Matrix
Theory (RMT) for analyzing Transformer training dynamics. We focus on the
underlying mechanisms that drive performance improvements and derive principled
early-stopping criteria. Empirically, we observe that the spectral density of
the shallow self-attention matrix V consistently evolves into a heavy-tailed
distribution. Utilizing the PL (Power Law) fit to this matrix as a probe, we
demarcate training into three stages: structural exploration, heavy-tailed
structure stabilization, and convergence saturation. This staging provides
guidance for preliminary stopping decisions. Crucially, we propose two
consistent and validation-free criteria: a quantitative metric for heavy-tailed
dynamics and a novel spectral signature indicative of convergence. The strong
alignment between these criteria highlights the utility of RMT for monitoring
and diagnosing the progression of Transformer model training.

</details>


### [33] [BPL: Bias-adaptive Preference Distillation Learning for Recommender System](https://arxiv.org/abs/2510.16076)
*SeongKu Kang,Jianxun Lian,Dongha Lee,Wonbin Kweon,Sanghwan Jang,Jaehyun Lee,Jindong Wang,Xing Xie,Hwanjo Yu*

Main category: cs.LG

TL;DR: BPL是一个新的推荐系统学习框架，通过双重蒸馏策略在事实和反事实测试环境中都实现高性能，解决了推荐系统偏差问题。


<details>
  <summary>Details</summary>
Motivation: 推荐系统存在偏差问题，导致收集的反馈不能完全揭示用户偏好。现有去偏学习主要专注于反事实测试环境，但在基于实际用户-物品交互的事实测试环境中准确率显著下降。需要开发在两种测试环境中都表现良好的模型。

Method: 提出偏差自适应偏好蒸馏学习（BPL）框架，采用双重蒸馏策略：1）从有偏模型进行师生蒸馏，保留与收集反馈一致的准确偏好知识；2）通过可靠性过滤的自蒸馏，在训练过程中迭代精炼知识。

Result: 综合实验验证了BPL在事实和反事实测试中的有效性。

Conclusion: BPL框架能够逐步揭示用户偏好，在事实和反事实测试环境中都实现高性能，解决了推荐系统偏差问题。

Abstract: Recommender systems suffer from biases that cause the collected feedback to
incompletely reveal user preference. While debiasing learning has been
extensively studied, they mostly focused on the specialized (called
counterfactual) test environment simulated by random exposure of items,
significantly degrading accuracy in the typical (called factual) test
environment based on actual user-item interactions. In fact, each test
environment highlights the benefit of a different aspect: the counterfactual
test emphasizes user satisfaction in the long-terms, while the factual test
focuses on predicting subsequent user behaviors on platforms. Therefore, it is
desirable to have a model that performs well on both tests rather than only
one. In this work, we introduce a new learning framework, called Bias-adaptive
Preference distillation Learning (BPL), to gradually uncover user preferences
with dual distillation strategies. These distillation strategies are designed
to drive high performance in both factual and counterfactual test environments.
Employing a specialized form of teacher-student distillation from a biased
model, BPL retains accurate preference knowledge aligned with the collected
feedback, leading to high performance in the factual test. Furthermore, through
self-distillation with reliability filtering, BPL iteratively refines its
knowledge throughout the training process. This enables the model to produce
more accurate predictions across a broader range of user-item combinations,
thereby improving performance in the counterfactual test. Comprehensive
experiments validate the effectiveness of BPL in both factual and
counterfactual tests. Our implementation is accessible via:
https://github.com/SeongKu-Kang/BPL.

</details>


### [34] [STABLE: Gated Continual Learning for Large Language Models](https://arxiv.org/abs/2510.16089)
*William Hoy,Nurcin Celik*

Main category: cs.LG

TL;DR: STABLE提出了一种基于门控机制的持续自编辑框架，使用LoRA进行参数高效微调，通过三种指标评估编辑稳定性，有效缓解大语言模型在持续更新中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型需要持续适应新知识但避免完全重训练，而顺序更新会导致灾难性遗忘，新编辑会降低先前获得的知识。

Method: 使用LoRA进行参数高效微调，通过三种指标（精确匹配下降、比特增加、KL散度）评估候选编辑的稳定性，超过阈值时对LoRA更新进行裁剪或拒绝。

Result: 在Qwen-2.5-7B模型上的实验表明，门控机制有效缓解遗忘同时保持适应性，基于EM的门控在短持续学习序列中获得了最高的累积性能。

Conclusion: 不同门控策略可以实现相当的分布偏移但产生不同的准确度结果，突显了门控设计在持续适应中的重要性，为持续模型编辑提供了原则性方法。

Abstract: Large language models (LLMs) increasingly require mechanisms for continual
adaptation without full retraining. However, sequential updates can lead to
catastrophic forgetting, where new edits degrade previously acquired knowledge.
This work presents STABLE, a gated continual self editing framework that
constrains forgetting during sequential updates using parameter efficient fine
tuning via Low Rank Adaptation (LoRA; see arXiv:2106.09685). Each candidate
edit is evaluated against a stability budget using one of three metrics: (i)
Exact Match (EM) drop, capturing factual accuracy loss; (ii) bits increase,
reflecting reduced model confidence; and (iii) KL divergence, quantifying
distributional drift between the base and adapted models. If a threshold is
exceeded, the LoRA update is rescaled through a clipping procedure or rejected.
Experiments on the Qwen-2.5-7B model show that gating effectively mitigates
forgetting while preserving adaptability. EM based gating achieved the highest
cumulative performance in short continual learning sequences. Our results show
that different gating strategies can achieve comparable distribution shift
(measured by KL divergence) while producing different accuracy outcomes,
highlighting the importance of gating design in continual adaptation. This
approach offers a principled method for continual model editing, enabling LLMs
to integrate new knowledge while maintaining reliability. Code:
https://github.com/Bhoy1/STABLE

</details>


### [35] [Zero-shot World Models via Search in Memory](https://arxiv.org/abs/2510.16123)
*Federico Malato,Ville Hautamäki*

Main category: cs.LG

TL;DR: 提出了一种基于相似性搜索和随机表示的世界模型，无需训练过程，在图像重建质量和长期动态预测方面与训练型模型相当，且在长期预测上表现更优。


<details>
  <summary>Details</summary>
Motivation: 利用相似性搜索和随机表示来近似世界模型，避免复杂的训练过程，提高模型构建效率。

Method: 使用相似性搜索和随机表示构建无需训练的世界模型，与Dreamer家族的PlaNet模型进行对比评估。

Result: 搜索型世界模型在潜在重建质量和感知相似性方面与训练型模型相当，在长期预测任务中表现更优。

Conclusion: 基于搜索的方法可以构建有效的世界模型，无需复杂训练过程，在长期预测方面具有优势。

Abstract: World Models have vastly permeated the field of Reinforcement Learning. Their
ability to model the transition dynamics of an environment have greatly
improved sample efficiency in online RL. Among them, the most notorious example
is Dreamer, a model that learns to act in a diverse set of image-based
environments. In this paper, we leverage similarity search and stochastic
representations to approximate a world model without a training procedure. We
establish a comparison with PlaNet, a well-established world model of the
Dreamer family. We evaluate the models on the quality of latent reconstruction
and on the perceived similarity of the reconstructed image, on both next-step
and long horizon dynamics prediction. The results of our study demonstrate that
a search-based world model is comparable to a training based one in both cases.
Notably, our model show stronger performance in long-horizon prediction with
respect to the baseline on a range of visually different environments.

</details>


### [36] [Alignment is Localized: A Causal Probe into Preference Layers](https://arxiv.org/abs/2510.16167)
*Archie Chaudhury*

Main category: cs.LG

TL;DR: 本文通过层间因果修补分析语言模型对齐机制，发现对齐过程是空间局部化的，主要集中在中层激活的特定子空间，而非扩散的参数化过程。


<details>
  <summary>Details</summary>
Motivation: 尽管基于人类反馈的强化学习（RLHF）已成为语言模型偏好微调的流行方法，但其内部对齐机制仍然不透明，需要系统分析对齐是如何实现的。

Method: 在Llama-3.2-1B模型上应用层间因果修补技术，比较基础模型与其调优版本在人类偏好对上的差异，并使用LASSO回归分析激活距离与奖励增益的关系。

Result: 发现对齐是空间局部化的：中层激活编码了决定奖励一致行为的特定子空间，而早期和晚期层基本不受影响；只有少数层具有连接激活距离与奖励增益的非零系数。

Conclusion: 基于人类偏好的语言模型对齐是一个方向性的低秩过程，而非扩散的参数化过程。

Abstract: Reinforcement Learning frameworks, particularly those utilizing human
annotations, have become an increasingly popular method for preference
fine-tuning, where the outputs of a language model are tuned to match a certain
set of behavioral policies or guidelines. Reinforcement Learning through Human
Feedback (RLHF) is perhaps the most popular implementation of such a framework,
particularly for aligning LMs toward safety and human intent. However, the
internal workings of how such alignment is achieved remain largely opaque. In
this work, we systematically analyze preference optimization for language model
alignment by applying layer-wide causal patching between a base model and its
tuned counterpart across human preference pairs. We implement our methodology
on \textit{Llama-3.2-1B}, and find that alignment is spatially localized:
mid-layer activations encode a distinct subspace that causally determines
reward-consistent behavior, while early and late layers remain largely
unaffected. Utilizing LASSO regression, we also find that only a small number
of layers possess non-zero coefficients linking activation distances to reward
gains. Overall, we show that, at least for some language models, alignment from
human-based, preferential tuning is a directional, low rank process, rather
than diffuse and parameteric.

</details>


### [37] [Machine Learning for Climate Policy: Understanding Policy Progression in the European Green Deal](https://arxiv.org/abs/2510.16233)
*Patricia West,Michelle WL Wan,Alexander Hepburn,Edwin Simpson,Raul Santos-Rodriguez,Jeffrey N Clark*

Main category: cs.LG

TL;DR: 本研究应用机器学习预测欧盟绿色协议气候政策的进展状态，比较了不同文本表示方法，发现ClimateBERT在纯文本特征上表现最佳，而结合元数据后BERT效果更好，揭示了政策措辞和政治因素对政策进展的影响。


<details>
  <summary>Details</summary>
Motivation: 气候变化需要有效的立法行动来缓解其影响，本研究旨在探索机器学习如何帮助理解气候政策从宣布到采纳的进展过程。

Method: 构建了包含165项政策的文本和元数据数据集，使用TF-IDF、BERT和ClimateBERT等文本表示方法，结合元数据特征预测政策进展状态，并应用可解释AI方法分析影响因素。

Result: 纯文本特征下ClimateBERT表现最佳（RMSE=0.17，R²=0.29），结合元数据后BERT效果更好（RMSE=0.16，R²=0.38），可解释AI分析显示政策措辞、政党背景和国家代表性等因素对政策进展有显著影响。

Conclusion: 机器学习工具在支持气候政策分析和决策制定方面具有重要潜力，能够识别影响政策进展的关键因素。

Abstract: Climate change demands effective legislative action to mitigate its impacts.
This study explores the application of machine learning (ML) to understand the
progression of climate policy from announcement to adoption, focusing on
policies within the European Green Deal. We present a dataset of 165 policies,
incorporating text and metadata. We aim to predict a policy's progression
status, and compare text representation methods, including TF-IDF, BERT, and
ClimateBERT. Metadata features are included to evaluate the impact on
predictive performance. On text features alone, ClimateBERT outperforms other
approaches (RMSE = 0.17, R^2 = 0.29), while BERT achieves superior performance
with the addition of metadata features (RMSE = 0.16, R^2 = 0.38). Using methods
from explainable AI highlights the influence of factors such as policy wording
and metadata including political party and country representation. These
findings underscore the potential of ML tools in supporting climate policy
analysis and decision-making.

</details>


### [38] [QSVD: Efficient Low-rank Approximation for Unified Query-Key-Value Weight Compression in Low-Precision Vision-Language Models](https://arxiv.org/abs/2510.16292)
*Yutong Wang,Haiyu Wang,Sai Qian Zhang*

Main category: cs.LG

TL;DR: 该论文提出了一种结合奇异值分解(SVD)和量化的方法来优化视觉语言模型的效率和性能，显著减少内存使用和计算成本，同时提高准确性。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型(VLMs)在图像描述和视觉问答等任务中很重要，但其高计算成本和内存占用限制了可扩展性和实时应用性。

Method: 使用奇异值分解(SVD)对联合查询(Q)、键(K)、值(V)权重矩阵进行处理以减少KV缓存大小，并引入动态SVD秩分配策略，同时应用量化到权重和激活值。

Result: 该方法在减少硬件成本的同时实现了超过10%的准确率提升，优于仅使用量化或SVD的方法。

Conclusion: 该方法为资源受限设备上的实时部署提供了高效的视觉语言模型解决方案。

Abstract: Vision-Language Models (VLMs) are integral to tasks such as image captioning
and visual question answering, but their high computational cost, driven by
large memory footprints and processing time, limits their scalability and
real-time applicability. In this work, we propose leveraging Singular-Value
Decomposition (SVD) over the joint query (Q), key (K), and value (V) weight
matrices to reduce KV cache size and computational overhead. We in addition
introduce an efficient rank allocation strategy that dynamically adjusts the
SVD rank based on its impact on VLM accuracy, achieving a significant reduction
in both memory usage and computational cost. Finally, we extend this approach
by applying quantization to both VLM weights and activations, resulting in a
highly efficient VLM. Our method outperforms previous approaches that rely
solely on quantization or SVD by achieving more than $10\%$ accuracy
improvement while consuming less hardware cost, making it better for real-time
deployment on resource-constrained devices. We open source our code at
\href{https://github.com/SAI-Lab-NYU/QSVD}{\texttt{https://github.com/SAI-Lab-NYU/QSVD}}.

</details>


### [39] [Colliding with Adversaries at ECML-PKDD 2025 Adversarial Attack Competition 1st Prize Solution](https://arxiv.org/abs/2510.16440)
*Dimitris Stefanopoulos,Andreas Voskou*

Main category: cs.LG

TL;DR: 本文介绍了ECML-PKDD 2025高能物理发现鲁棒学习挑战赛中Task 1的获胜解决方案，该任务要求设计对抗攻击以最大化误分类同时最小化扰动。


<details>
  <summary>Details</summary>
Motivation: 该任务的动机是设计有效的对抗攻击方法，在保持扰动最小的前提下最大化分类模型的误分类率，以测试模型在对抗环境下的鲁棒性。

Method: 采用多轮梯度基策略，利用模型的可微分结构，结合随机初始化和样本混合技术来增强攻击效果。

Result: 所提出的攻击方法在扰动大小和欺骗成功率方面取得了最佳结果，在竞赛中获得第一名。

Conclusion: 该多轮梯度基攻击策略结合随机初始化和样本混合技术，能够有效生成高质量对抗样本，在保持小扰动的同时实现高误分类率。

Abstract: This report presents the winning solution for Task 1 of Colliding with
Adversaries: A Challenge on Robust Learning in High Energy Physics Discovery at
ECML-PKDD 2025. The task required designing an adversarial attack against a
provided classification model that maximizes misclassification while minimizing
perturbations. Our approach employs a multi-round gradient-based strategy that
leverages the differentiable structure of the model, augmented with random
initialization and sample-mixing techniques to enhance effectiveness. The
resulting attack achieved the best results in perturbation size and fooling
success rate, securing first place in the competition.

</details>


### [40] [Input Domain Aware MoE: Decoupling Routing Decisions from Task Optimization in Mixture of Experts](https://arxiv.org/abs/2510.16448)
*Yongxiang Hua,Haoyu Cao,Zhou Tao,Bocheng Li,Zihao Wu,Chaohu Liu,Linli Xu*

Main category: cs.LG

TL;DR: 提出Input Domain Aware MoE路由框架，通过概率混合模型更好地划分输入空间，在视觉语言任务中优于现有稀疏专家混合方法


<details>
  <summary>Details</summary>
Motivation: 现有基于相似性得分的路由机制难以有效捕捉输入结构，导致专家专业化与计算平衡之间的权衡，限制了可扩展性和性能

Method: 使用概率混合模型建模路由概率，使专家形成清晰的专业化边界，路由机制独立于任务特定目标进行训练

Result: 在视觉语言任务中一致优于现有稀疏专家混合方法，获得更高的任务性能和改善的专家利用平衡

Conclusion: 提出的路由框架通过更好的输入空间划分实现了专家专业化和计算平衡的改进

Abstract: Sparse Mixture of Experts (sMoE) has become a pivotal approach for scaling
large vision-language models, offering substantial capacity while maintaining
computational efficiency through dynamic, sparse activation of experts.
However, existing routing mechanisms, typically based on similarity scoring,
struggle to effectively capture the underlying input structure. This limitation
leads to a trade-off between expert specialization and balanced computation,
hindering both scalability and performance. We propose Input Domain Aware MoE,
a novel routing framework that leverages a probabilistic mixture model to
better partition the input space. By modeling routing probabilities as a
mixture of distributions, our method enables experts to develop clear
specialization boundaries while achieving balanced utilization. Unlike
conventional approaches, our routing mechanism is trained independently of
task-specific objectives, allowing for stable optimization and decisive expert
assignments. Empirical results on vision-language tasks demonstrate that our
method consistently outperforms existing sMoE approaches, achieving higher task
performance and improved expert utilization balance.

</details>


### [41] [High-Dimensional Privacy-Utility Dynamics of Noisy Stochastic Gradient Descent on Least Squares](https://arxiv.org/abs/2510.16687)
*Shurong Lin,Eric D. Kolaczyk,Adam Smith,Elliot Paquette*

Main category: cs.LG

TL;DR: 本文利用扩散方法精确分析噪声SGD，在高维环境中提供统计风险和隐私损失动态的连续时间视角，并研究了一种无需梯度敏感度显式知识的噪声SGD变体。


<details>
  <summary>Details</summary>
Motivation: 优化与隐私保护的相互作用已成为隐私保护机器学习的核心主题。噪声SGD已成为关键算法，但现有工作主要提供统计风险和隐私损失的各种界限，而过程的精确行为仍不清楚，特别是在高维环境中。

Method: 采用扩散方法分析噪声SGD，提供连续时间视角；研究一种无需梯度敏感度显式知识的噪声SGD变体，专注于带ℓ2正则化的最小二乘问题。

Result: 该方法能够精确捕捉高维环境中统计风险演化和隐私损失动态，相比现有需要梯度裁剪来强制敏感度的方法更具优势。

Conclusion: 扩散方法为分析噪声SGD提供了精确的连续时间框架，特别是在高维设置中，同时提出的无需显式敏感度知识的变体扩展了现有方法的适用性。

Abstract: The interplay between optimization and privacy has become a central theme in
privacy-preserving machine learning. Noisy stochastic gradient descent (SGD)
has emerged as a cornerstone algorithm, particularly in large-scale settings.
These variants of gradient methods inject carefully calibrated noise into each
update to achieve differential privacy, the gold standard notion of rigorous
privacy guarantees. Prior work primarily provides various bounds on statistical
risk and privacy loss for noisy SGD, yet the \textit{exact} behavior of the
process remains unclear, particularly in high-dimensional settings. This work
leverages a diffusion approach to analyze noisy SGD precisely, providing a
continuous-time perspective that captures both statistical risk evolution and
privacy loss dynamics in high dimensions. Moreover, we study a variant of noisy
SGD that does not require explicit knowledge of gradient sensitivity, unlike
existing work that assumes or enforces sensitivity through gradient clipping.
Specifically, we focus on the least squares problem with $\ell_2$
regularization.

</details>


### [42] [Resolution-Aware Retrieval Augmented Zero-Shot Forecasting](https://arxiv.org/abs/2510.16695)
*Iman Deznabi,Peeyush Kumar,Madalina Fiterau*

Main category: cs.LG

TL;DR: 提出了一种分辨率感知的检索增强预测模型，通过利用空间相关性和时间频率特征来提高零样本预测的准确性。模型将信号分解为不同频率分量，采用分辨率感知检索策略，低频分量依赖更广泛的空间上下文，高频分量关注局部影响。


<details>
  <summary>Details</summary>
Motivation: 零样本预测旨在预测没有直接历史数据的未见条件下的结果，这对传统预测方法构成重大挑战。需要开发能够适应新位置且历史上下文最少的方法。

Method: 分辨率感知检索增强预测模型，通过信号频率分解和分辨率感知检索机制，动态检索相关数据。低频分量使用更广泛的空间上下文，高频分量聚焦局部影响。

Result: 在微气候预测应用中，该模型显著优于传统预测方法、数值天气预报模型和现代基础时间序列模型，在ERA5数据集上比HRRR的MSE降低71%，比Chronos的MSE降低34%。

Conclusion: 检索增强和分辨率感知策略在零样本预测中非常有效，为微气候建模及其他领域的零样本预测提供了可扩展且数据高效的解决方案。

Abstract: Zero-shot forecasting aims to predict outcomes for previously unseen
conditions without direct historical data, posing a significant challenge for
traditional forecasting methods. We introduce a Resolution-Aware
Retrieval-Augmented Forecasting model that enhances predictive accuracy by
leveraging spatial correlations and temporal frequency characteristics. By
decomposing signals into different frequency components, our model employs
resolution-aware retrieval, where lower-frequency components rely on broader
spatial context, while higher-frequency components focus on local influences.
This allows the model to dynamically retrieve relevant data and adapt to new
locations with minimal historical context.
  Applied to microclimate forecasting, our model significantly outperforms
traditional forecasting methods, numerical weather prediction models, and
modern foundation time series models, achieving 71% lower MSE than HRRR and 34%
lower MSE than Chronos on the ERA5 dataset.
  Our results highlight the effectiveness of retrieval-augmented and
resolution-aware strategies, offering a scalable and data-efficient solution
for zero-shot forecasting in microclimate modeling and beyond.

</details>


### [43] [Zero-Shot Performance Prediction for Probabilistic Scaling Laws](https://arxiv.org/abs/2510.16743)
*Viktoria Schram,Markus Hiller,Daniel Beck,Trevor Cohn*

Main category: cs.LG

TL;DR: 本文提出了一种多任务学习方法，使用潜在变量多输出高斯过程来预测NLP模型的学习曲线，支持零样本预测并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 预测NLP模型的学习曲线可以在满足特定性能目标的同时减少计算开销和数据集获取成本，实现更明智的决策制定。

Method: 将学习曲线预测任务建模为多任务学习问题，使用潜在变量多输出高斯过程来建模任务间和层次间的共享信息和依赖关系。

Result: 该方法能够以较低成本开发概率性缩放定律，通过主动学习策略减少预测不确定性，提供接近真实缩放定律的预测结果。在三个小型NLP数据集上进行了验证。

Conclusion: 所提出的多任务学习框架能够有效预测NLP模型的学习曲线，支持零样本预测，并为模型缩放提供概率性指导。

Abstract: The prediction of learning curves for Natural Language Processing (NLP)
models enables informed decision-making to meet specific performance
objectives, while reducing computational overhead and lowering the costs
associated with dataset acquisition and curation. In this work, we formulate
the prediction task as a multitask learning problem, where each task's data is
modelled as being organized within a two-layer hierarchy. To model the shared
information and dependencies across tasks and hierarchical levels, we employ
latent variable multi-output Gaussian Processes, enabling to account for task
correlations and supporting zero-shot prediction of learning curves (LCs). We
demonstrate that this approach facilitates the development of probabilistic
scaling laws at lower costs. Applying an active learning strategy, LCs can be
queried to reduce predictive uncertainty and provide predictions close to
ground truth scaling laws. We validate our framework on three small-scale NLP
datasets with up to $30$ LCs. These are obtained from nanoGPT models, from
bilingual translation using mBART and Transformer models, and from multilingual
translation using M2M100 models of varying sizes.

</details>


### [44] [Learning to play: A Multimodal Agent for 3D Game-Play](https://arxiv.org/abs/2510.16774)
*Yuguang Yue,Irakli Salia,Samuel Hunt,Christopher Green,Wenzhe Shi,Jonathan J Hunt*

Main category: cs.LG

TL;DR: 该论文提出了一个大规模多样化的3D第一人称游戏数据集，训练了能够实时推理的文本条件游戏智能体，并展示了在多游戏环境中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 3D第一人称视频游戏为实时多模态推理提供了具有挑战性的环境，需要解决现有数据集规模小、多样性不足的问题。

Method: 收集大规模多样化的人类游戏数据集，学习逆动力学模型来推断缺失动作，使用行为克隆训练文本条件智能体，采用支持实时推理的自定义架构。

Result: 训练出的模型能够在多种3D游戏中响应文本指令进行游戏，并在消费级GPU上实现实时推理。

Conclusion: 虽然取得了进展，但仍面临长时程任务和大规模游戏定量评估等挑战。

Abstract: We argue that 3-D first-person video games are a challenging environment for
real-time multi-modal reasoning. We first describe our dataset of human
game-play, collected across a large variety of 3-D first-person games, which is
both substantially larger and more diverse compared to prior publicly disclosed
datasets, and contains text instructions. We demonstrate that we can learn an
inverse dynamics model from this dataset, which allows us to impute actions on
a much larger dataset of publicly available videos of human game play that lack
recorded actions. We then train a text-conditioned agent for game playing using
behavior cloning, with a custom architecture capable of realtime inference on a
consumer GPU. We show the resulting model is capable of playing a variety of
3-D games and responding to text input. Finally, we outline some of the
remaining challenges such as long-horizon tasks and quantitative evaluation
across a large set of games.

</details>


### [45] [3D-GSRD: 3D Molecular Graph Auto-Encoder with Selective Re-mask Decoding](https://arxiv.org/abs/2510.16780)
*Chang Wu,Zhiyuan Liu,Wen Shu,Liang Wang,Yanchen Luo,Wenqiang Lei,Yatao Bian,Junfeng Fang,Xiang Wang*

Main category: cs.LG

TL;DR: 3D-GSRD是一种用于分子表示学习的3D分子图自编码器，通过选择性重掩码解码解决2D到3D掩码图建模的挑战，在MD17基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 将掩码图建模从2D扩展到3D面临两个冲突挑战：避免2D结构泄漏到解码器，同时为重构重掩码原子提供足够的2D上下文信息。

Method: 提出选择性重掩码解码(SRD)，仅从编码器表示中重掩码3D相关信息，同时保留2D图结构。该方法与3D关系变换器编码器和结构无关解码器协同集成。

Result: 在广泛使用的MD17分子性质预测基准测试中，3D-GSRD在8个目标中的7个上实现了最先进的性能。

Conclusion: 选择性重掩码解码与结构无关解码器相结合增强了编码器在分子表示学习中的作用，3D-GSRD在分子性质预测任务中表现出色。

Abstract: Masked graph modeling (MGM) is a promising approach for molecular
representation learning (MRL).However, extending the success of re-mask
decoding from 2D to 3D MGM is non-trivial, primarily due to two conflicting
challenges: avoiding 2D structure leakage to the decoder, while still providing
sufficient 2D context for reconstructing re-masked atoms.To address these
challenges, we propose 3D-GSRD: a 3D Molecular Graph Auto-Encoder with
Selective Re-mask Decoding. The core innovation of 3D-GSRD lies in its
Selective Re-mask Decoding(SRD), which re-masks only 3D-relevant information
from encoder representations while preserving the 2D graph structures.This SRD
is synergistically integrated with a 3D Relational-Transformer(3D-ReTrans)
encoder alongside a structure-independent decoder. We analyze that SRD,
combined with the structure-independent decoder, enhances the encoder's role in
MRL. Extensive experiments show that 3D-GSRD achieves strong downstream
performance, setting a new state-of-the-art on 7 out of 8 targets in the widely
used MD17 molecular property prediction benchmark. The code is released at
https://github.com/WuChang0124/3D-GSRD.

</details>


### [46] [Computational Budget Should Be Considered in Data Selection](https://arxiv.org/abs/2510.16806)
*Weilin Wan,Weizhong Zhang,Cheng Jin*

Main category: cs.LG

TL;DR: 提出了一种计算预算感知的数据选择方法CADS，通过双层优化框架将计算预算整合到数据选择策略中，在视觉和语言基准测试中性能提升高达14.42%。


<details>
  <summary>Details</summary>
Motivation: 现有数据选择方法忽略了计算预算约束，而实证研究表明没有算法能在不同预算下始终优于其他方法（甚至随机选择），因此计算预算必须成为数据选择策略的核心要素。

Method: 提出了计算预算感知数据选择方法CADS，采用双层优化框架：内层在计算预算约束下在选定数据子集上训练模型，外层基于模型评估优化数据选择。使用概率重参数化策略和Hessian-free策略梯度估计器解决Hessian矩阵估计问题，将内层优化转化为外层目标中的惩罚项。

Result: 在视觉和语言基准测试上的广泛实验表明，该方法相比基线方法实现了高达14.42%的性能提升。

Conclusion: 计算预算应成为数据选择策略的组成部分，CADS方法通过双层优化框架有效解决了计算预算感知的数据选择问题，显著提高了训练效率。

Abstract: Data selection improves computational efficiency by choosing informative
subsets of training samples. However, existing methods ignore the compute
budget, treating data selection and importance evaluation independently of
compute budget constraints. Yet empirical studies show no algorithm can
consistently outperform others (or even random selection) across varying
budgets. We therefore argue that compute budget must be integral to
data-selection strategies, since different budgets impose distinct requirements
on data quantity, quality, and distribution for effective training. To this
end, we propose a novel Computational budget-Aware Data Selection (CADS) method
and naturally formulate it into a bilevel optimization framework, where the
inner loop trains the model within the constraints of the computational budget
on some selected subset of training data, while the outer loop optimizes data
selection based on model evaluation. Our technical contributions lie in
addressing two main challenges in solving this bilevel optimization problem:
the expensive Hessian matrix estimation for outer-loop gradients and the
computational burden of achieving inner-loop optimality during iterations. To
solve the first issue, we propose a probabilistic reparameterization strategy
and compute the gradient using a Hessian-free policy gradient estimator. To
address the second challenge, we transform the inner optimization problem into
a penalty term in the outer objective, further discovering that we only need to
estimate the minimum of a one-dimensional loss to calculate the gradient,
significantly improving efficiency. Extensive experiments show that our method
achieves performance gains of up to 14.42% over baselines in vision and
language benchmarks.

</details>


### [47] [Improving Model Representation and Reducing KV Cache via Skip Connections with First Value Heads](https://arxiv.org/abs/2510.16807)
*Zhoutong Wu,Yuan Zhang,Yiming Dong,Chenheng Zhang,Cong Fang,Kun Yuan,Zhouchen Lin*

Main category: cs.LG

TL;DR: SkipV1Former是一种Transformer变体，通过从第一层的Value头使用跳跃连接来增强模型表示能力并减少KV缓存，在减少约25% KV缓存的同时改善困惑度。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer模型在扩展时面临内存和计算成本高昂的问题，特别是自回归解码中的KV缓存。现有方法要么无法减少KV成本，要么以牺牲表示能力为代价来降低内存使用。

Method: 从第二个块开始，每个层重用第一层的一半Value头，同时正常计算另一半，从而将Value投影和V缓存减少近50%。该方法保留了未压缩的第一层Value信息。

Result: 在不同模型规模下，SkipV1Former相比标准MHA Transformer和某些先进变体，在减少约25% KV缓存的同时改善了困惑度。与YOCO结合时，KV缓存大小减少近50%且性能仍有所提升。

Conclusion: SkipV1Former提供了一种有效的方法来增强Transformer表示能力并显著减少KV缓存，且可通过额外10-15%计算量对现有MHA Transformer检查点进行上训练。

Abstract: Transformer models have driven breakthroughs across various language tasks by
their strong capability to learn rich contextual representations. Scaling them
to improve representation, however, often demands substantial memory and
compute costs, such as the Key-Value (KV) cache used during auto-regressive
decoding. Skip connections offer a promising way to improve representation
without bloating resource usage, yet most prior works either improve
expressivity while leaving KV costs unchanged, or reduce memory at the cost of
weaker representation. In this work, we propose SkipV1Former, a Transformer
variant that uses skip connections from the first layer's Value heads to
strengthen model representation and reduce KV cache. Specifically, from the
second block onward, each layer reuses half of its Value heads from the very
first layer, while computing the other half as usual-cutting Value projections
and V cache by nearly 50 \%. Theoretically, we show that routing uncompressed
first-layer Values into deeper layers restores information lost to compression
and accelerates the model's implicit mesa-optimization-a key pattern of
Transformer in auto-regressive tasks. Empirically, across different model
scales, SkipV1Former delivers consistent reductions of approximately 25 \% in
KV cache while improving perplexity relative to standard Multi-Head Attention
(MHA) Transformers and some advanced variants. Moreover, we propose a recipe
for uptraining existing MHA Transformer checkpoints to SkipV1Former with only
10-15\% additional compute. Finally, SkipV1Former can seamlessly combine
advanced methods like Group-Query Attention and Multi-Latent Attention to
achieve further KV cache savings and performance improvement. When combined
with YOCO, it cuts KV cache size by nearly 50 \% while still improving
performance.

</details>


### [48] [Graph Learning is Suboptimal in Causal Bandits](https://arxiv.org/abs/2510.16811)
*Mohammad Shahverdikondori,Jalal Etesami,Negar Kiyavash*

Main category: cs.LG

TL;DR: 本文研究了因果充分性下因果强盗问题中的遗憾最小化，发现学习父节点集是次优的，证明了遗憾最小化和父节点识别之间存在根本冲突，并提出了绕过图恢复的近乎最优算法。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注识别奖励的父节点然后应用经典强盗方法，或联合学习父节点同时最小化遗憾。本文研究这些策略是否最优，并探讨遗憾最小化和父节点识别之间的关系。

Method: 通过证明存在实例表明遗憾最小化和父节点识别是冲突目标，建立捕获动作空间组合结构的新遗憾下界，并提出绕过图和父节点恢复的近乎最优算法。

Result: 实验证实，在各种环境中，本文方法与现有基线方法之间存在较大的性能差距。

Conclusion: 父节点识别对于遗憾最小化是不必要的，学习父节点集是次优策略，提出的算法能够实现近乎最优的遗憾最小化。

Abstract: We study regret minimization in causal bandits under causal sufficiency where
the underlying causal structure is not known to the agent. Previous work has
focused on identifying the reward's parents and then applying classic bandit
methods to them, or jointly learning the parents while minimizing regret. We
investigate whether such strategies are optimal. Somewhat counterintuitively,
our results show that learning the parent set is suboptimal. We do so by
proving that there exist instances where regret minimization and parent
identification are fundamentally conflicting objectives. We further analyze
both the known and unknown parent set size regimes, establish novel regret
lower bounds that capture the combinatorial structure of the action space.
Building on these insights, we propose nearly optimal algorithms that bypass
graph and parent recovery, demonstrating that parent identification is indeed
unnecessary for regret minimization. Experiments confirm that there exists a
large performance gap between our method and existing baselines in various
environments.

</details>


### [49] [Needles in the Landscape: Semi-Supervised Pseudolabeling for Archaeological Site Discovery under Label Scarcity](https://arxiv.org/abs/2510.16814)
*Simon Jaxy,Anton Theys,Patrick Willett,W. Chris Carleton,Ralf Vandam,Pieter Libin*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度学习的考古预测模型，采用半监督正未标记学习策略，通过动态伪标签和条件随机场处理考古数据中标签稀缺和类别不平衡的问题。


<details>
  <summary>Details</summary>
Motivation: 考古预测建模需要从已知遗址位置结合环境、文化和地理空间变量来预测未知遗址位置，但面临正样本稀少和大多数位置未标记的结构性标签稀缺问题。

Method: 采用半监督正未标记学习策略，实现为语义分割模型，使用动态伪标签和通过RNN实现的条件随机场来提高标签置信度，在严重类别不平衡下进行优化。

Result: 在基于数字高程模型的地理空间数据集上，模型性能与最先进的LAMAP相当，同时获得更高的Dice分数；在原始卫星图像上，通过分层k折交叉验证评估，保持性能并产生具有更好可解释性的预测表面。

Conclusion: 半监督学习为在大规模稀疏标注景观中识别未发现遗址提供了一种有前景的方法。

Abstract: Archaeological predictive modelling estimates where undiscovered sites are
likely to occur by combining known locations with environmental, cultural, and
geospatial variables. We address this challenge using a deep learning approach
but must contend with structural label scarcity inherent to archaeology:
positives are rare, and most locations are unlabeled. To address this, we adopt
a semi-supervised, positive-unlabeled (PU) learning strategy, implemented as a
semantic segmentation model and evaluated on two datasets covering a
representative range of archaeological periods. Our approach employs dynamic
pseudolabeling, refined with a Conditional Random Field (CRF) implemented via
an RNN, increasing label confidence under severe class imbalance. On a
geospatial dataset derived from a digital elevation model (DEM), our model
performs on par with the state-of-the-art, LAMAP, while achieving higher Dice
scores. On raw satellite imagery, assessed end-to-end with stratified k-fold
cross-validation, it maintains performance and yields predictive surfaces with
improved interpretability. Overall, our results indicate that semi-supervised
learning offers a promising approach to identifying undiscovered sites across
large, sparsely annotated landscapes.

</details>


### [50] [Finding Manifolds With Bilinear Autoencoders](https://arxiv.org/abs/2510.16820)
*Thomas Dooms,Ward Gauderis*

Main category: cs.LG

TL;DR: 本文提出使用双线性自编码器将神经表示分解为二次多项式，作为可分析的非线性潜在表示工具。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器依赖输入进行解释，单独研究不完整。多项式作为代数基元，无需参考输入即可分析，能够描述从线性概念到复杂流形的结构。

Method: 使用双线性自编码器高效地将表示分解为二次多项式，并引入改进方法以诱导重要性排序、聚类和激活稀疏性。

Result: 实现了将神经表示分解为可分析的二次多项式形式，这是通过代数性质实现非线性但可分析潜在表示的第一步。

Conclusion: 双线性自编码器为通过代数性质研究非线性潜在表示提供了有效途径，是迈向可分析非线性潜在表示的重要初步工作。

Abstract: Sparse autoencoders are a standard tool for uncovering interpretable latent
representations in neural networks. Yet, their interpretation depends on the
inputs, making their isolated study incomplete. Polynomials offer a solution;
they serve as algebraic primitives that can be analysed without reference to
input and can describe structures ranging from linear concepts to complicated
manifolds. This work uses bilinear autoencoders to efficiently decompose
representations into quadratic polynomials. We discuss improvements that induce
importance ordering, clustering, and activation sparsity. This is an initial
step toward nonlinear yet analysable latents through their algebraic
properties.

</details>


### [51] [Utility-Diversity Aware Online Batch Selection for LLM Supervised Fine-tuning](https://arxiv.org/abs/2510.16882)
*Heming Zou,Yixiu Mao,Yun Qu,Qi Wang,Xiangyang Ji*

Main category: cs.LG

TL;DR: 本文提出了UDS（Utility-Diversity Sampling）框架，用于在监督微调中进行高效的在线批次选择，通过同时考虑数据效用和多样性来优化训练过程。


<details>
  <summary>Details</summary>
Motivation: 传统的全数据集监督微调计算成本高且容易过拟合或放大偏差，现有在线批次选择方法存在三个主要问题：(i)仅依赖数据效用而忽略多样性；(ii)需要外部资源如参考模型或验证集；(iii)训练时间超过全数据集训练。

Method: UDS框架利用对数矩阵的核范数捕获数据效用和样本内多样性，通过高效的低维嵌入比较和历史样本的轻量级内存缓冲区估计样本间多样性，无需外部资源和额外反向传播。

Result: 在多个基准测试上的实验表明，UDS在不同数据预算下始终优于最先进的在线批次选择方法，并显著减少了与全数据集微调相比的训练时间。

Conclusion: UDS提供了一种无需外部资源、计算高效的在线批次选择解决方案，有效平衡了数据效用和多样性，在监督微调中实现了更好的性能和效率。

Abstract: Supervised fine-tuning (SFT) is a commonly used technique to adapt large
language models (LLMs) to downstream tasks. In practice, SFT on a full dataset
is computationally expensive and sometimes suffers from overfitting or bias
amplification. This facilitates the rise of data curation in SFT, which
prioritizes the most valuable data to optimze. This work studies the online
batch selection family that dynamically scores and filters samples during the
training process. However, existing popular methods often (i) rely merely on
the utility of data to select a subset while neglecting other crucial factors
like diversity, (ii) rely on external resources such as reference models or
validation sets, and (iii) incur extra training time over full-dataset
training. To address these limitations, this work develops \textbf{UDS
(Utility-Diversity Sampling)}, a framework for efficient online batch selection
in SFT. UDS leverages the nuclear norm of the logits matrix to capture both
data utility and intra-sample diversity, while estimating inter-sample
diversity through efficient low-dimensional embedding comparisons with a
lightweight memory buffer of historical samples. Such a design eliminates the
need for external resources and unnecessary backpropagation, securing
computational efficiency. Experiments on multiple benchmarks demonstrate that
UDS consistently outperforms state-of-the-art online batch selection methods
under varying data budgets, and significantly reduces training time compared to
full-dataset fine-tuning. Code is available at https://github.com/gfyddha/UDS.

</details>


### [52] [Towards Interpretable and Trustworthy Time Series Reasoning: A BlueSky Vision](https://arxiv.org/abs/2510.16980)
*Kanghui Ning,Zijie Pan,Yushan Jiang,Anderson Schneider,Yuriy Nevmyvaka,Dongjin Song*

Main category: cs.LG

TL;DR: 本文提出了时间序列推理的愿景框架，包含两个互补方向：一是建立稳健的时间序列推理基础，二是推进系统级推理能力。


<details>
  <summary>Details</summary>
Motivation: 时间序列推理正成为时序分析的下一个前沿，旨在超越模式识别，实现显式、可解释且可信赖的推理。

Method: 构建两个互补方向：1）建立稳健的时间序列推理基础，包括全面的时序理解、结构化多步推理和忠实评估框架；2）推进系统级推理，超越纯语言解释，整合多智能体协作、多模态上下文和检索增强方法。

Result: 提出了一个灵活且可扩展的时间序列推理框架。

Conclusion: 该框架旨在为不同领域提供可解释和可信赖的时序智能。

Abstract: Time series reasoning is emerging as the next frontier in temporal analysis,
aiming to move beyond pattern recognition towards explicit, interpretable, and
trustworthy inference. This paper presents a BlueSky vision built on two
complementary directions. One builds robust foundations for time series
reasoning, centered on comprehensive temporal understanding, structured
multi-step reasoning, and faithful evaluation frameworks. The other advances
system-level reasoning, moving beyond language-only explanations by
incorporating multi-agent collaboration, multi-modal context, and
retrieval-augmented approaches. Together, these directions outline a flexible
and extensible framework for advancing time series reasoning, aiming to deliver
interpretable and trustworthy temporal intelligence across diverse domains.

</details>


### [53] [MuonBP: Faster Muon via Block-Periodic Orthogonalization](https://arxiv.org/abs/2510.16981)
*Ahmed Khaled,Kaan Ozkara,Tao Yu,Mingyi Hong,Youngsuk Park*

Main category: cs.LG

TL;DR: MuonBP优化器通过分块周期性正交化策略，在保持Muon优化器数据效率优势的同时，显著减少了模型并行训练中的通信开销，实现了与AdamW相当的吞吐量。


<details>
  <summary>Details</summary>
Motivation: Muon优化器在语言模型训练中表现出优于Adam/AdamW的数据效率，但在模型并行环境下，梯度正交化操作引入了额外的通信开销，导致5%-10%的吞吐量下降。

Method: 提出MuonBP方法：在每个设备上独立对矩阵分块进行正交化，并周期性执行完整正交化以维持训练稳定性；使用两个学习率分别处理分块正交化步骤和完整正交化步骤。

Result: 在8B模型训练中，使用八路张量并行和ZeRO优化器状态分片，MuonBP相比Muon实现了8%的吞吐量提升，且性能没有下降。

Conclusion: MuonBP在保持Muon优化器数据效率优势的同时，显著减少了模型并行训练中的通信开销，实现了与坐标优化器相当的吞吐量，为大规模语言模型训练提供了高效解决方案。

Abstract: Gradient orthogonalization is a simple strategy that shows great utility in
speeding up gradient descent. The Muon optimizer (Jordan, Jin, et al., 2024)
combines gradient orthogonalization with first-order momentum and achieves
significant improvement in data efficiency over Adam/AdamW (Loshchilov and
Hutter, 2019) for language model training. However, when using model
parallelism, gradient orthogonalization introduces additional overhead compared
to coordinate-wise optimizers (such as AdamW) due to additional gather and
scatter operations on gradient matrix shards from different devices. This
additional communication can amount to a throughput hit of 5%-10% compared to
Adam/AdamW. To remedy this, we propose Muon with Block-Periodic
Orthogonalization (MuonBP), which applies orthogonalization independently to
matrix shards on each device and periodically performs full orthogonalization
to maintain training stability at scale. We show how to adjust the learning
rate from the baseline to MuonBP and give convergence guarantees for this
algorithm. Crucially, our theory dictates that we use two stepsizes: one for
the blockwise orthogonalization steps, and one for the full orthogonalization
steps. Our method is simple, requires minimal hyperparameter adjustments, and
achieves competitive iteration complexity compared with baseline Muon while
providing per-iteration throughput comparable to coordinate-wise methods such
as AdamW. When training an 8B model with eight-way tensor parallelism and ZeRO
optimizer state sharding, MuonBP achieves 8% throughput increase compared to
Muon with no degradation in performance.

</details>


### [54] [Diverse Influence Component Analysis: A Geometric Approach to Nonlinear Mixture Identifiability](https://arxiv.org/abs/2510.17040)
*Hoang-Son Nguyen,Xiao Fu*

Main category: cs.LG

TL;DR: 本文提出了Diverse Influence Component Analysis (DICA)框架，通过最大化混合函数雅可比矩阵体积来识别非线性混合中的潜在成分，无需辅助信号、潜在成分独立性或雅可比稀疏性假设。


<details>
  <summary>Details</summary>
Motivation: 非线性独立成分分析(nICA)中，从未知非线性混合中识别潜在成分是一个基础挑战。现有方法需要辅助信号或结构假设来支持可识别性，本文旨在开发不依赖这些假设的新方法。

Method: 提出DICA框架和雅可比体积最大化(J-VolMax)准则，利用混合函数雅可比矩阵的凸几何特性，通过促进潜在成分对观测变量的影响多样性来实现识别。

Result: 在合理条件下，该方法实现了无需辅助信息、潜在成分独立性或雅可比稀疏性假设的可识别性，扩展了可识别性分析的范围。

Conclusion: DICA框架为现有方法提供了补充视角，通过雅可比几何特性实现了更广泛条件下的潜在成分识别。

Abstract: Latent component identification from unknown nonlinear mixtures is a
foundational challenge in machine learning, with applications in tasks such as
disentangled representation learning and causal inference. Prior work in
nonlinear independent component analysis (nICA) has shown that auxiliary
signals -- such as weak supervision -- can support identifiability of
conditionally independent latent components. More recent approaches explore
structural assumptions, e.g., sparsity in the Jacobian of the mixing function,
to relax such requirements. In this work, we introduce Diverse Influence
Component Analysis (DICA), a framework that exploits the convex geometry of the
mixing function's Jacobian. We propose a Jacobian Volume Maximization
(J-VolMax) criterion, which enables latent component identification by
encouraging diversity in their influence on the observed variables. Under
reasonable conditions, this approach achieves identifiability without relying
on auxiliary information, latent component independence, or Jacobian sparsity
assumptions. These results extend the scope of identifiability analysis and
offer a complementary perspective to existing methods.

</details>


### [55] [D2C-HRHR: Discrete Actions with Double Distributional Critics for High-Risk-High-Return Tasks](https://arxiv.org/abs/2510.17212)
*Jundong Zhang,Yuhui Situ,Fanji Zhang,Rongji Deng,Tianqi Wei*

Main category: cs.LG

TL;DR: 本文提出了一种针对高风险高回报任务的强化学习框架，通过离散化连续动作空间、熵正则化探索和双评论家架构来解决传统高斯策略在HRHR任务中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法假设单峰高斯策略和标量值评论家，在高风险高回报任务中效果有限，因为这类任务通常具有多峰动作分布和随机回报。

Method: 1) 离散化连续动作空间以近似多峰分布；2) 使用熵正则化探索提高对高风险但高回报动作的覆盖；3) 引入双评论家架构进行更准确的离散值分布估计。

Result: 在具有高失败风险的移动和操作基准测试中，该方法优于基线方法，证明了在多峰性和风险建模方面的重要性。

Conclusion: 该框架能够扩展到高维动作空间，支持复杂控制领域，为高风险高回报任务的强化学习提供了有效解决方案。

Abstract: Tasks involving high-risk-high-return (HRHR) actions, such as obstacle
crossing, often exhibit multimodal action distributions and stochastic returns.
Most reinforcement learning (RL) methods assume unimodal Gaussian policies and
rely on scalar-valued critics, which limits their effectiveness in HRHR
settings. We formally define HRHR tasks and theoretically show that Gaussian
policies cannot guarantee convergence to the optimal solution. To address this,
we propose a reinforcement learning framework that (i) discretizes continuous
action spaces to approximate multimodal distributions, (ii) employs
entropy-regularized exploration to improve coverage of risky but rewarding
actions, and (iii) introduces a dual-critic architecture for more accurate
discrete value distribution estimation. The framework scales to
high-dimensional action spaces, supporting complex control domains. Experiments
on locomotion and manipulation benchmarks with high risks of failure
demonstrate that our method outperforms baselines, underscoring the importance
of explicitly modeling multimodality and risk in RL.

</details>


### [56] [Learning After Model Deployment](https://arxiv.org/abs/2510.17160)
*Derda Kaymak,Gyuhak Kim,Tomoya Kaichi,Tatsuya Konishi,Bing Liu*

Main category: cs.LG

TL;DR: 本文提出了自主模型部署后学习（ALMD）范式，解决传统监督学习在动态环境中无法处理未知类别样本的问题。ALMD能够动态检测新类别样本并进行增量学习，无需人工工程师参与。


<details>
  <summary>Details</summary>
Motivation: 传统监督学习模型部署后固定不变，无法适应动态开放环境中出现的未知类别样本。需要一种能够在应用过程中持续检测新类别并学习的机制。

Method: 提出PLDA方法，实现动态OOD检测和增量学习。该方法能够在线学习新类别，无需使用所有历史数据重新训练模型。

Result: 经验评估将证明PLDA方法的有效性。

Conclusion: ALMD范式为动态环境中的机器学习提供了可行的解决方案，PLDA方法能够有效应对新类别检测和增量学习的挑战。

Abstract: In classic supervised learning, once a model is deployed in an application,
it is fixed. No updates will be made to it during the application. This is
inappropriate for many dynamic and open environments, where unexpected samples
from unseen classes may appear. In such an environment, the model should be
able to detect these novel samples from unseen classes and learn them after
they are labeled. We call this paradigm Autonomous Learning after Model
Deployment (ALMD). The learning here is continuous and involves no human
engineers. Labeling in this scenario is performed by human co-workers or other
knowledgeable agents, which is similar to what humans do when they encounter an
unfamiliar object and ask another person for its name. In ALMD, the detection
of novel samples is dynamic and differs from traditional out-of-distribution
(OOD) detection in that the set of in-distribution (ID) classes expands as new
classes are learned during application, whereas ID classes is fixed in
traditional OOD detection. Learning is also different from classic supervised
learning because in ALMD, we learn the encountered new classes immediately and
incrementally. It is difficult to retrain the model from scratch using all the
past data from the ID classes and the novel samples from newly discovered
classes, as this would be resource- and time-consuming. Apart from these two
challenges, ALMD faces the data scarcity issue because instances of new classes
often appear sporadically in real-life applications. To address these issues,
we propose a novel method, PLDA, which performs dynamic OOD detection and
incremental learning of new classes on the fly. Empirical evaluations will
demonstrate the effectiveness of PLDA.

</details>


### [57] [SOLE: Hardware-Software Co-design of Softmax and LayerNorm for Efficient Transformer Inference](https://arxiv.org/abs/2510.17189)
*Wenxun Wang,Shuchang Zhou,Wenyu Sun,Peiqin Sun,Yongpan Liu*

Main category: cs.LG

TL;DR: SOLE是一个软硬件协同设计，通过E2Softmax和AILayerNorm分别优化Transformer中的Softmax和LayerNorm操作，实现了无需重新训练的高效推理，在保持精度的同时显著提升速度和能效。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在NLP和CV任务中表现出色，但其实时推理速度和效率受到Softmax和LayerNorm操作效率低下的限制。现有基于函数逼近的方法存在实现效率低、忽略内存开销、需要重新训练等问题。

Method: 提出SOLE软硬件协同设计：E2Softmax采用指数函数的log2量化和基于对数的除法来逼近Softmax；AILayerNorm采用低精度统计计算。两者都实现了低精度计算和低比特位宽存储。

Result: 实验表明SOLE在无需重新训练的情况下保持推理精度，相比GPU实现了数量级的速度提升和能耗节省。相比现有最先进定制硬件，Softmax和LayerNorm分别实现了3.04倍和3.86倍的能效提升，以及2.82倍和3.32倍的面积效率提升。

Conclusion: SOLE通过软硬件协同设计有效解决了Transformer中Softmax和LayerNorm的效率瓶颈，在保持模型精度的同时显著提升了推理速度和能效。

Abstract: Transformers have shown remarkable performance in both natural language
processing (NLP) and computer vision (CV) tasks. However, their real-time
inference speed and efficiency are limited due to the inefficiency in Softmax
and Layer Normalization (LayerNorm). Previous works based on function
approximation suffer from inefficient implementation as they place emphasis on
computation while disregarding memory overhead concerns. Moreover, such methods
rely on retraining to compensate for approximation error which can be costly
and inconvenient.
  In this paper, we present SOLE, a hardware-software co-design for Softmax and
LayerNorm which is composed of E2Softmax and AILayerNorm. E2Softmax utilizes
log2 quantization of exponent function and log-based division to approximate
Softmax while AILayerNorm adopts low-precision statistic calculation. Compared
with state-of-the-art designs, we achieve both low-precision calculation and
low bit-width storage on Softmax and LayerNorm. Experiments show that SOLE
maintains inference accuracy without retraining while offering orders of
magnitude speedup and energy savings over GPU, achieving 3.04x, 3.86x
energy-efficiency improvements and 2.82x, 3.32x area-efficiency improvements
over prior state-of-the-art custom hardware for Softmax and LayerNorm,
respectively.

</details>


### [58] [LILO: Bayesian Optimization with Interactive Natural Language Feedback](https://arxiv.org/abs/2510.17671)
*Katarzyna Kobalczyk,Zhiyuan Jerry Lin,Benjamin Letham,Zhuokai Zhao,Maximilian Balandat,Eytan Bakshy*

Main category: cs.LG

TL;DR: 提出了一种语言在环框架，使用大语言模型将自然语言反馈转换为标量效用，以在数值搜索空间上进行贝叶斯优化。


<details>
  <summary>Details</summary>
Motivation: 许多实际应用中，反馈对于将复杂、细微或主观目标转化为可量化的优化目标至关重要。传统方法仅接受受限的反馈格式，需要为每个领域特定问题定制模型。

Method: 使用大语言模型将各种类型的文本反馈转换为一致的效用信号，无需手动设计核函数即可包含灵活的用户先验，同时保持贝叶斯优化的样本效率和原则性不确定性量化。

Result: 这种混合方法不仅为决策者提供了更自然的接口，而且在反馈受限的情况下优于传统的贝叶斯优化基线和仅使用LLM的优化器。

Conclusion: 语言在环框架通过结合大语言模型的自然语言理解能力和贝叶斯优化的效率，实现了更灵活和有效的优化过程。

Abstract: For many real-world applications, feedback is essential in translating
complex, nuanced, or subjective goals into quantifiable optimization
objectives. We propose a language-in-the-loop framework that uses a large
language model (LLM) to convert unstructured feedback in the form of natural
language into scalar utilities to conduct BO over a numeric search space.
Unlike preferential BO, which only accepts restricted feedback formats and
requires customized models for each domain-specific problem, our approach
leverages LLMs to turn varied types of textual feedback into consistent utility
signals and to easily include flexible user priors without manual kernel
design. At the same time, our method maintains the sample efficiency and
principled uncertainty quantification of BO. We show that this hybrid method
not only provides a more natural interface to the decision maker but also
outperforms conventional BO baselines and LLM-only optimizers, particularly in
feedback-limited regimes.

</details>


### [59] [Closing the Sim2Real Performance Gap in RL](https://arxiv.org/abs/2510.17709)
*Akhil S Anand,Shambhuraj Sawant,Jasper Hoffmann,Dirk Reinhardt,Sebastien Gros*

Main category: cs.LG

TL;DR: 本文提出了一种新的双层强化学习框架，通过直接基于真实世界性能调整模拟器参数来解决Sim2Real性能差距问题。


<details>
  <summary>Details</summary>
Motivation: 尽管模拟器精度和Sim2Real RL方法不断发展，但纯模拟训练的策略在真实环境中部署时仍存在显著的性能下降。现有方法优化的模拟器精度和变异性指标与策略的真实世界性能不一定相关。

Method: 采用双层RL框架：内层RL在模拟中训练策略，外层RL调整模拟模型和模拟内奖励参数，以最大化模拟策略在真实世界中的性能。

Result: 推导并验证了开发能够缩小Sim2Real性能差距的双层RL算法所需的数学工具。

Conclusion: 该框架通过直接基于真实世界性能优化模拟器参数，为解决Sim2Real性能差距问题提供了新的有效方法。

Abstract: Sim2Real aims at training policies in high-fidelity simulation environments
and effectively transferring them to the real world. Despite the developments
of accurate simulators and Sim2Real RL approaches, the policies trained purely
in simulation often suffer significant performance drops when deployed in real
environments. This drop is referred to as the Sim2Real performance gap. Current
Sim2Real RL methods optimize the simulator accuracy and variability as proxies
for real-world performance. However, these metrics do not necessarily correlate
with the real-world performance of the policy as established theoretically and
empirically in the literature. We propose a novel framework to address this
issue by directly adapting the simulator parameters based on real-world
performance. We frame this problem as a bi-level RL framework: the inner-level
RL trains a policy purely in simulation, and the outer-level RL adapts the
simulation model and in-sim reward parameters to maximize real-world
performance of the in-sim policy. We derive and validate in simple examples the
mathematical tools needed to develop bi-level RL algorithms that close the
Sim2Real performance gap.

</details>


### [60] [Disentanglement Beyond Static vs. Dynamic: A Benchmark and Evaluation Framework for Multi-Factor Sequential Representations](https://arxiv.org/abs/2510.17313)
*Tal Barami,Nimrod Berman,Ilan Naiman,Amos H. Hason,Rotem Ezra,Omri Azencot*

Main category: cs.LG

TL;DR: 提出了首个多因素序列解缠结标准化基准，包含六个数据集、评估工具和自动对齐方法，并展示了视觉语言模型在自动标注和评估中的应用。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据包含多个相互作用的语义因素，但先前工作主要关注简单的双因素静态和动态设置，忽视了数据的多因素本质。

Method: 引入标准化基准、后验潜在探索阶段自动对齐潜在维度与语义因素，提出Koopman启发的模型，并利用视觉语言模型进行自动标注和零样本评估。

Result: 提出的Koopman模型取得了最先进的结果，视觉语言模型能够有效自动化数据集标注和作为解缠结评估器。

Conclusion: 这些贡献为推进多因素序列解缠结提供了稳健且可扩展的基础。

Abstract: Learning disentangled representations in sequential data is a key goal in
deep learning, with broad applications in vision, audio, and time series. While
real-world data involves multiple interacting semantic factors over time, prior
work has mostly focused on simpler two-factor static and dynamic settings,
primarily because such settings make data collection easier, thereby
overlooking the inherently multi-factor nature of real-world data. We introduce
the first standardized benchmark for evaluating multi-factor sequential
disentanglement across six diverse datasets spanning video, audio, and time
series. Our benchmark includes modular tools for dataset integration, model
development, and evaluation metrics tailored to multi-factor analysis. We
additionally propose a post-hoc Latent Exploration Stage to automatically align
latent dimensions with semantic factors, and introduce a Koopman-inspired model
that achieves state-of-the-art results. Moreover, we show that Vision-Language
Models can automate dataset annotation and serve as zero-shot disentanglement
evaluators, removing the need for manual labels and human intervention.
Together, these contributions provide a robust and scalable foundation for
advancing multi-factor sequential disentanglement.

</details>


### [61] [Unbiased Gradient Low-Rank Projection](https://arxiv.org/abs/2510.17802)
*Rui Pan,Yang Luo,Yuxing Liu,Yang You,Tong Zhang*

Main category: cs.LG

TL;DR: 提出了一种名为GUM的无偏低秩优化方法，通过层间采样技术消除梯度低秩投影的偏差，在保持内存效率的同时实现与基础优化算法相同的收敛保证，并在LLM微调和预训练中表现出优于全参数训练的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有梯度低秩投影方法（如GaLore）缺乏收敛保证和存在固有偏差的问题，这些偏差导致与全参数训练存在性能差距。

Method: 基于GaLore机制和Muon算法，采用层间采样技术来消除低秩投影的偏差，提出GaLore Unbiased with Muon (GUM)方法。

Result: 理论证明GUM方法匹配基础Muon算法的收敛保证，同时保持低秩技术的内存效率。实证实验显示在LLM微调和预训练中优于GaLore，甚至超过全参数训练。

Conclusion: 该技术通过更均匀的层内知识分布，实现了模型参数空间的更高效利用和更好的记忆能力，为内存高效的LLM训练提供了有效的解决方案。

Abstract: Memory-efficient optimization is critical for training increasingly large
language models (LLMs). A popular strategy involves gradient low-rank
projection, storing only the projected optimizer states, with GaLore being a
representative example. However, a significant drawback of many such methods is
their lack of convergence guarantees, as various low-rank projection approaches
introduce inherent biases relative to the original optimization algorithms,
which contribute to performance gaps compared to full-parameter training.
Aiming to tackle this problem, this paper investigates the layerwise sampling
technique for debiasing low-rank projection mechanisms. In particular, an
instantiation of the paradigm gives rise to a novel and unbiased low-rank
optimization method built upon GaLore's mechanism and the Muon algorithm, named
GaLore Unbiased with Muon (GUM). We theoretically prove our method matches the
convergence guarantees of the base Muon algorithm while preserving the memory
efficiency of low-rank techniques. Empirical experiments on LLM fine-tuning and
pretraining also demonstrate non-trivial improvements over GaLore and even
better performance than full-parameter training. Further investigation shows
that the improvement of this technique comes from a more uniform distribution
of knowledge inside layers, leading to more efficient utilization of the model
parameter space and better memorization.

</details>


### [62] [Formally Exploring Time-Series Anomaly Detection Evaluation Metrics](https://arxiv.org/abs/2510.17562)
*Dennis Wagner,Arjun Nair,Billy Joe Franks,Justus Arweiler,Aparna Muraleedharan,Indra Jungjohann,Fabian Hartung,Mayank C. Ahuja,Andriy Balinskyy,Saurabh Varshneya,Nabeel Hussain Syed,Mayank Nagda,Phillip Liznerski,Steffen Reithermann,Maja Rudolph,Sebastian Vollmer,Ralf Schulz,Torsten Katz,Stephan Mandt,Michael Bortz,Heike Leitte,Daniel Neider,Jakob Burger,Fabian Jirasek,Hans Hasse,Sophie Fellenz,Marius Kloft*

Main category: cs.LG

TL;DR: 本文针对时间序列异常检测评估指标存在的问题，提出了可验证的属性来形式化评估要求，分析了37个常用指标的局限性，并提出了满足所有属性的新指标LARM及其扩展ALARM。


<details>
  <summary>Details</summary>
Motivation: 时间序列中的未检测异常可能导致安全关键系统的灾难性故障，现有检测方法的性能评估存在缺陷，因为当前指标仅捕捉任务的狭窄方面且经常产生误导性结果。

Method: 引入可验证属性来形式化评估时间序列异常检测的基本要求，建立理论框架支持原则性评估和可靠比较，分析37个广泛使用的指标，并提出满足所有属性的新指标LARM及其扩展ALARM。

Result: 分析显示大多数现有指标仅满足少数属性，没有一个指标满足所有属性，这解释了先前结果中持续存在的不一致性。

Conclusion: 提出的LARM和ALARM指标填补了现有评估指标的空白，为时间序列异常检测提供了更可靠和全面的评估框架。

Abstract: Undetected anomalies in time series can trigger catastrophic failures in
safety-critical systems, such as chemical plant explosions or power grid
outages. Although many detection methods have been proposed, their performance
remains unclear because current metrics capture only narrow aspects of the task
and often yield misleading results. We address this issue by introducing
verifiable properties that formalize essential requirements for evaluating
time-series anomaly detection. These properties enable a theoretical framework
that supports principled evaluations and reliable comparisons. Analyzing 37
widely used metrics, we show that most satisfy only a few properties, and none
satisfy all, explaining persistent inconsistencies in prior results. To close
this gap, we propose LARM, a flexible metric that provably satisfies all
properties, and extend it to ALARM, an advanced variant meeting stricter
requirements.

</details>


### [63] [Efficient Algorithms for Mitigating Uncertainty and Risk in Reinforcement Learning](https://arxiv.org/abs/2510.17690)
*Xihong Su*

Main category: cs.LG

TL;DR: 该论文提出了三种主要贡献：CADP算法连接策略梯度与动态规划，建立了ERM Bellman算子的收缩条件并提出了相关算法，以及提出了用于风险规避目标的Q学习算法。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决马尔可夫决策过程中的不确定性模型和风险规避问题，特别是在多模型MDPs中寻找最优策略。

Method: 方法包括：CADP算法迭代调整模型权重；建立ERM Bellman算子的收缩条件；提出指数值迭代、策略迭代和线性规划算法；开发模型无关的Q学习算法。

Result: 结果表明：CADP能保证策略单调改进到局部最优；证明了ERM-TRC和EVaR-TRC存在确定性最优策略；Q学习算法能收敛到最优风险规避值函数。

Conclusion: 结论是成功建立了策略梯度与动态规划的新联系，提出了多种计算风险规避最优策略的有效算法，并证明了其收敛性。

Abstract: This dissertation makes three main contributions. First, We identify a new
connection between policy gradient and dynamic programming in MMDPs and propose
the Coordinate Ascent Dynamic Programming (CADP) algorithm to compute a Markov
policy that maximizes the discounted return averaged over the uncertain models.
CADP adjusts model weights iteratively to guarantee monotone policy
improvements to a local maximum. Second, We establish sufficient and necessary
conditions for the exponential ERM Bellman operator to be a contraction and
prove the existence of stationary deterministic optimal policies for ERM-TRC
and EVaR-TRC. We also propose exponential value iteration, policy iteration,
and linear programming algorithms for computing optimal stationary policies for
ERM-TRC and EVaR-TRC. Third, We propose model-free Q-learning algorithms for
computing policies with risk-averse objectives: ERM-TRC and EVaR-TRC. The
challenge is that Q-learning ERM Bellman may not be a contraction. Instead, we
use the monotonicity of Q-learning ERM Bellman operators to derive a rigorous
proof that the ERM-TRC and the EVaR-TRC Q-learning algorithms converge to the
optimal risk-averse value functions. The proposed Q-learning algorithms compute
the optimal stationary policy for ERM-TRC and EVaR-TRC.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [64] [Wideband Antenna Deconvolution for Bistatic Millimeter Wave Radar Reflectivity Measurements](https://arxiv.org/abs/2510.16094)
*Carsten Andrich,Isabella Varga,Tobias F. Nowack,Alexander Ihlow,Sebastian Giehl,Michael Schubert,Reiner S. Thomä,Matthias A. Hein*

Main category: eess.SP

TL;DR: 提出了一种用于球面双基地测量系统的空中校准算法，该方法比现有算法更简单且速度快两倍。在76-81 GHz频段对金属球反射率测量的应用显示，与未校准数据相比，动态范围提高了40 dB。


<details>
  <summary>Details</summary>
Motivation: 双基地雷达测量具有独特的空间多样性和增强的目标表征能力，在现代传感应用中越来越重要。此类测量的可靠性取决于精确的系统与天线校准，而当前主流技术是使用已知参考物体的替代方法。

Method: 提出了一种球面双基地测量系统的空中校准算法，该方法相比现有算法显著简化且速度更快。

Result: 在76-81 GHz频段对金属球进行反射率测量的应用表明，与未校准数据相比，动态范围提高了40 dB。与仿真数据的比较显示测量与仿真之间具有高度一致性。

Conclusion: 所提出的空中校准算法为球面双基地测量系统提供了一种更简单、更快速的校准解决方案，显著提高了测量动态范围和与仿真的一致性。

Abstract: Bistatic radar measurements offer unique spatial diversity and enhanced
target characterization capabilities, rendering them increasingly vital for
contemporary sensing application research. The reliability of such measurements
is contingent upon precise system and antenna calibration. The prevailing
technique is the substitution method, which involves the use of known reference
objects. We propose an over-the-air calibration algorithm for spherical
bistatic measurement systems. Our method is both significantly simpler and
twice as fast as existing algorithms. The application of our technique to
reflectivity measurements of a metal sphere from 76 to 81 GHz demonstrates a
dynamic range enhancement of up to 40 dB when compared with uncalibrated data.
A comparison with simulation data demonstrates a high degree of agreement
between measurement and simulation.

</details>


### [65] [Fast, Differentiable, GPU-Accelerated Ray Tracing for Multiple Diffraction and Reflection Paths](https://arxiv.org/abs/2510.16172)
*Jérome Eertmans,Sophie Lequeu,Benoît Legat,Laurent Jacques,Claude Oestges*

Main category: eess.SP

TL;DR: 提出了一种基于费马原理的快速、可微分GPU加速优化方法，用于在包含平面反射器和直线衍射边缘的环境中计算射线路径追踪。该方法将路径寻找问题重新表述为总路径长度最小化问题，支持高效的并行GPU计算。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要为反射和衍射分别使用不同的算法，缺乏统一的处理框架。为了在无线传播建模中实现高效的逆设计和优化，需要一种能够统一处理各种交互序列且适合向量化计算的方法。

Method: 基于费马原理，将路径寻找问题重新表述为总路径长度最小化问题。通过隐式微分实现高效梯度计算，避免通过求解器迭代进行微分。该方法与JAX和DrJIT等可微分编程库无缝集成。

Result: 数值模拟显示收敛速度与专门的牛顿方法相当，同时在大规模应用中提供优越的可扩展性。相比传统的自动微分方法，性能显著提升。

Conclusion: 该方法为无线传播建模中的逆设计和优化提供了新的可能性，实现了反射和衍射的统一处理，并支持高效的GPU并行计算。

Abstract: We present a fast, differentiable, GPU-accelerated optimization method for
ray path tracing in environments containing planar reflectors and straight
diffraction edges. Based on Fermat's principle, our approach reformulates the
path-finding problem as the minimization of total path length, enabling
efficient parallel execution on modern GPU architectures. Unlike existing
methods that require separate algorithms for reflections and diffractions, our
unified formulation maintains consistent problem dimensions across all
interaction sequences, making it particularly suitable for vectorized
computation. Through implicit differentiation, we achieve efficient gradient
computation without differentiating through solver iterations, significantly
outperforming traditional automatic differentiation approaches. Numerical
simulations demonstrate convergence rates comparable to specialized Newton
methods while providing superior scalability for large-scale applications. The
method integrates seamlessly with differentiable programming libraries such as
JAX and DrJIT, enabling new possibilities in inverse design and optimization
for wireless propagation modeling. The source code is openly available at
https://github.com/jeertmans/fpt-jax.

</details>


### [66] [Adaptive Sensing Performance Design for Enhancing Secure Communication in Networked ISAC Systems](https://arxiv.org/abs/2510.16397)
*Yiming Xu,Dongfang Xu,Shenghui Song,Dusit Niyato*

Main category: eess.SP

TL;DR: 本文提出了一种具有自适应感知性能的感知增强安全通信方法，通过将感知性能隐含在信息泄漏率中并自适应优化，以最小化功耗，为物理层安全提供灵活解决方案。


<details>
  <summary>Details</summary>
Motivation: 由于窃听者的被动和非合作性质，获取其信道状态信息(CSI)对于物理层安全设计至关重要但很困难。现有研究通常施加明确固定的感知性能要求，而不考虑变化的通信条件，阻碍了系统充分利用感知与通信之间的协同作用。

Method: 提出感知增强安全通信框架，将感知性能隐含在信息泄漏率中并自适应优化。设计集中式和分布式两种方案：集中式采用基于块坐标下降(BCD)的方法；分布式采用基于共识交替方向乘子法(ADMM)的优化框架以降低复杂性和信息交换开销。

Result: 实验结果表明，所提出的隐式感知性能要求设计具有优势，因为它能够自适应调整感知性能，以增强不同系统配置下的系统性能。

Conclusion: 该研究通过自适应感知性能设计，为物理层安全提供了更灵活和适应性强的解决方案，有效解决了窃听者CSI获取困难的问题，并充分利用了感知与通信之间的协同作用。

Abstract: The channel state information (CSI) of an eavesdropper is crucial for
physical layer security (PLS) design, but it is difficult to obtain due to the
passive and non-cooperative nature of the eavesdropper. To this end, integrated
sensing and communication (ISAC) offers a novel solution by estimating the CSI
of the eavesdropper based on sensing information. However, existing studies
normally impose explicit and fixed sensing performance requirement without
considering the varying communication conditions, which hinders the system from
fully exploiting the synergy between sensing and communication. To address this
issue, this paper proposes sensing-enhanced secure communication with adaptive
sensing performance. Specifically, we formulate the sensing performance
implicitly in the information leakage rate and adaptively optimize it for the
minimization of the power consumption, offering enhanced flexibility and
adaptability in sensing performance. We consider both centralized and
decentralized designs to thoroughly investigate the impact of network structure
on system performance and complexity. Specifically, we devise a block
coordinate descent (BCD)-based method for centralized design. For decentralized
design, we develop an optimization framework based on consensus alternating
direction method of multipliers (ADMM) to reduce complexity and information
exchange overhead. Experimental results demonstrate the advantage of the
proposed implicit sensing performance requirement design due to its capability
to adaptively adjust the sensing performance to enhance the system performance
for varying system configurations.

</details>


### [67] [Performance Evaluation of High Power Microwave Systems Against UAVs A Probabilistic Antenna Propagation Framework with Sensitivity Analysis](https://arxiv.org/abs/2510.16495)
*Muhammad Khalil,Ke Wang,Jinho Choi*

Main category: eess.SP

TL;DR: 开发了一个概率框架来量化高功率微波对抗无人机的有效性，通过耦合随机无人机运动学、波束指向抖动-增益映射和大气传播，推导出接收脉冲能量的闭式统计量，并计算脉冲中和概率。


<details>
  <summary>Details</summary>
Motivation: 需要量化高功率微波对抗无人机的有效性，为系统设计和任务规划提供快速准确的性能预测。

Method: 采用概率性、天线和传播中心的方法，结合随机无人机运动学、波束指向抖动-增益映射和大气传播，使用对数正态闭包和高斯-埃尔米特求积推导可解析计算的脉冲中和概率。

Result: 对于商业无人机（阈值0.01J），模型预测每脉冲杀伤概率≥0.4，在kHz脉冲重复频率下0.1秒内总杀伤概率>99%；对于加固平台（阈值0.1J），每脉冲杀伤概率<1%，1秒后总杀伤概率<20%。性能主要受斜距影响。

Conclusion: 该框架提供了快速、准确且符合物理的性能预测，揭示了HPM系统设计和风险感知任务规划的清晰天线/传播设计杠杆。

Abstract: We develop a probabilistic, antenna- and propagation-centric framework to
quantify the effectiveness of high-power microwave (HPM) engagements against
unmanned aerial vehicles (UAVs). The model couples stochastic UAV kinematics, a
beam-steering jitter-to-gain mapping, and atmospheric propagation (free-space
spreading with gaseous and rain loss) to obtain closed-form statistics of the
received pulse energy. From these, we derive analytically evaluable per-pulse
and cumulative neutralization probabilities using log-normal closures and
Gaussian--Hermite quadrature, and we provide a dwell-time expression under a
standard pulse-independence assumption. Analytical predictions closely match
large-scale Monte-Carlo simulations across broad parameter ranges. For a
representative commercial threshold $E_{\mathrm{th}} = 10^{-2}\,\mathrm{J}$,
the model predicts $\bar{P}_{\mathrm{kill}} \gtrsim 0.4$ per pulse and
$P_{\mathrm{kill,tot}} > 99\%$ within about $0.1\,\mathrm{s}$ at kHz PRF; for
hardened platforms with $E_{\mathrm{th}} = 10^{-1}\,\mathrm{J}$,
$\bar{P}_{\mathrm{kill}} < 1\%$ and $P_{\mathrm{kill,tot}} < 20\%$ after
$1\,\mathrm{s}$. A closed-form sensitivity (elasticity) analysis shows
performance is dominated by slant range ($S_{\bar{R}} \approx -2$), with strong
secondary dependence on aperture diameter and transmit power; pointing jitter
and atmospheric variability are comparatively less influential in the evaluated
regimes. The framework yields fast, accurate, and physics-faithful performance
predictions and exposes clear antenna/propagation design levers for HPM system
sizing and risk-aware mission planning.

</details>


### [68] [Stochastic Geometry Analysis of Asymmetric Uplink Interference for Urban UAV-RC Networks](https://arxiv.org/abs/2510.16963)
*Donggu Lee,Sung Joon Maeng,Ismail Guvenc*

Main category: eess.SP

TL;DR: 本文提出了一种随机几何框架来分析城市环境中无人机通信的不对称干扰问题，通过LGCP模型捕捉干扰场的空间相关性，并定义了干扰不对称比来量化上下行干扰差异。


<details>
  <summary>Details</summary>
Motivation: 无人机在密集城市环境中部署时面临独特的挑战，特别是由于无人机更容易受到视距干扰而导致的上行链路不对称干扰问题。

Method: 采用随机几何框架和log-Gaussian Cox过程(LGCP)模型来捕捉干扰场的空间相关性，分析干扰随无人机高度和二维距离的变化规律。

Result: 数值结果表明，干扰不对称比随着无人机高度和二维距离的增加而增加，表明上行链路干扰情况恶化。

Conclusion: 提出的框架能够有效分析城市环境中无人机通信的不对称干扰特性，为无人机部署和干扰管理提供理论依据。

Abstract: Uncrewed aerial vehicles (UAVs) have emerged as a flexible platform for
providing coverage over challenging environments, particularly for public
safety and surveillance missions in urban areas. However, deploying the UAVs in
dense urban areas introduces unique challenges, most notably asymmetric uplink
(UL, remote controller to UAV) interference due to a higher chance of
line-of-sight (LoS) interference at the UAV. In this letter, we propose a
stochastic geometry framework to tractably analyze the large-scale asymmetric
interference in urban areas. We incorporate a log-Gaussian Cox process (LGCP)
model to capture the spatial correlation of the interference field in both UL
and downlink (DL) as a function of the UAV altitude and the two-dimensional
(2-D) distance between the remote controller and UAV. To quantify the UL and
the DL interference asymmetry, we also define the interference asymmetry ratio
characterizing the interference disparity between the UL and the DL. Our
numerical results demonstrate that the interference asymmetry ratio increases
as the UAV altitude and 2-D distance increase, highlighting that the UL
interference worsens.

</details>


### [69] [6D Movable Metasurface (6DMM) in Downlink NOMA Transmissions](https://arxiv.org/abs/2510.17502)
*Li-Hsiang Shen*

Main category: eess.SP

TL;DR: 提出了一种六维可移动超表面辅助的下行非正交多址系统，通过动态调整超表面元素位置和方向，实现空间和电磁控制，并使用概率交叉熵优化算法进行联合优化。


<details>
  <summary>Details</summary>
Motivation: 传统静态可重构智能表面存在灵活性不足的问题，需要开发具有更高空间配置自由度的超表面架构来提升系统性能。

Method: 采用六维可移动超表面架构，每个元素可动态调整位置和偏航-俯仰-滚转角度，并利用概率交叉熵优化算法联合优化基站波束成形、相移、元素位置和旋转角度。

Result: 仿真结果表明，所提出的CEO-based 6DMM-NOMA架构相比6DMM子结构、传统静态RIS和其他多址机制实现了显著的速率性能增益。

Conclusion: 六维可移动超表面结合概率交叉熵优化为高维可扩展超表面提供了有效的概率优化解决方案，显著提升了系统性能。

Abstract: This letter proposes a novel six-dimensional movable metasurface
(6DMM)-assisted downlink non-orthogonal multiple access (NOMA) system, in which
a conventional base station (BS) equipped with fixed antennas serves multiple
users with the assistance of a reconfigurable intelligent surface (RIS) with
six-dimensional spatial configurability. In contrast to traditional RIS with
static surface, the proposed 6DMM architecture allows each element to
dynamically adjust its position and orient the whole metasurface in
yaw-pitch-roll axes, enabling both in spatial and electromagnetic controls. We
formulate a sum-rate maximization problem that jointly optimizes the BS
NOMA-based beamforming, phase-shifts, element positions, and rotation angles of
metasurface under constraints of NOMA power levels, unit-modulus of
phase-shifts, power budget, inter-element separation and boundaries of element
position/orientation. Due to non-convexity and high-dimensionality, we employ a
probabilistic cross-entropy optimization (CEO) scheme to iteratively refine the
solution distribution based on maximizing likelihood and elite solution
sampling. Simulation results show that the proposed CEO-based 6DMM-NOMA
architecture achieves substantial rate performance gains compared to 6DMM
sub-structures, conventional static RIS, and other multiple access mechanisms.
It also highlights the effectiveness of CEO providing probabilistic
optimization for solving high-dimensional scalable metasurface.

</details>


### [70] [Precoding for Uplink RIS-Assisted Cell-Free MIMO-OFDM Systems with Hardware Impairments](https://arxiv.org/abs/2510.17741)
*Navid Reyhanian,Reza Ghaderi Zefreh,Parisa Ramezani,Emil Bjornson*

Main category: eess.SP

TL;DR: 本文研究了RIS辅助的CF-mMIMO系统，在UE和AP存在IQI的情况下，通过WMMSE-BCD方法联合优化传输预编码、RIS系数和接收组合，以最大化上行链路和速率。


<details>
  <summary>Details</summary>
Motivation: 在RIS辅助的CF-mMIMO系统中，UE和AP的IQI会严重影响系统性能，需要开发有效的联合优化方法来应对这一挑战。

Method: 提出了基于WMMSE的BCD方法，开发了新颖的迭代算法来高效解决BCD子问题。

Result: 通过广泛仿真验证了所提方法相对于启发式方法的效率优势。

Conclusion: 所提出的WMMSE-BCD方法能够有效解决RIS辅助CF-mMIMO系统中的联合优化问题，在存在IQI的情况下显著提升系统性能。

Abstract: This paper studies a reconfigurable intelligent surface (RIS)-assisted
cell-free massive multiple-input multiple-output (CF-mMIMO) system with
multiple RISs. Joint design of transmit precoding, RIS coefficients, and
receive combining is investigated for uplink sum-rate maximization under
in-phase and quadrature phase imbalance (IQI) at user equipments (UEs) and
access points (APs). A weighted minimum mean squared error (WMMSE) based block
coordinate descent (BCD) approach is proposed, where novel iterative methods
are developed to efficiently solve the BCD subproblems. The efficiency of
proposed approaches is demonstrated relative to heuristic methods via extensive
simulations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [71] [Executable Epistemology: The Structured Cognitive Loop as an Architecture of Intentional Understanding](https://arxiv.org/abs/2510.15952)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: 本文提出结构化认知循环（SCL）作为可执行的认知框架，将哲学见解转化为可计算结构，强调智能是执行过程而非属性，通过功能分离实现更连贯可解释的行为。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型缺乏真正认知理解的问题，填补认知架构的空白，从本体论转向认识论视角探索认知涌现的条件。

Method: 基于过程哲学、具身认知和扩展心智理论，构建包含判断、记忆、控制、行动和调节的连续循环认知框架，将哲学理论转化为可计算结构。

Result: SCL框架实现了可执行的认知论，功能分离的认知架构比单一提示系统产生更连贯可解释的行为，重新定义智能为通过意向性理解重建自身认知状态的能力。

Conclusion: 真正的进步需要实现认知原则的结构化架构而非更大的模型，该框架对心智哲学、认识论和AI产生重要影响，将知识视为在现象学连贯循环中的持续重建。

Abstract: Large language models exhibit intelligence without genuine epistemic
understanding, exposing a key gap: the absence of epistemic architecture. This
paper introduces the Structured Cognitive Loop (SCL) as an executable
epistemological framework for emergent intelligence. Unlike traditional AI
research asking "what is intelligence?" (ontological), SCL asks "under what
conditions does cognition emerge?" (epistemological). Grounded in philosophy of
mind and cognitive phenomenology, SCL bridges conceptual philosophy and
implementable cognition. Drawing on process philosophy, enactive cognition, and
extended mind theory, we define intelligence not as a property but as a
performed process -- a continuous loop of judgment, memory, control, action,
and regulation. SCL makes three contributions. First, it operationalizes
philosophical insights into computationally interpretable structures, enabling
"executable epistemology" -- philosophy as structural experiment. Second, it
shows that functional separation within cognitive architecture yields more
coherent and interpretable behavior than monolithic prompt based systems,
supported by agent evaluations. Third, it redefines intelligence: not
representational accuracy but the capacity to reconstruct its own epistemic
state through intentional understanding. This framework impacts philosophy of
mind, epistemology, and AI. For philosophy, it allows theories of cognition to
be enacted and tested. For AI, it grounds behavior in epistemic structure
rather than statistical regularity. For epistemology, it frames knowledge not
as truth possession but as continuous reconstruction within a
phenomenologically coherent loop. We situate SCL within debates on cognitive
phenomenology, emergence, normativity, and intentionality, arguing that real
progress requires not larger models but architectures that realize cognitive
principles structurally.

</details>


### [72] [Limits of Emergent Reasoning of Large Language Models in Agentic Frameworks for Deterministic Games](https://arxiv.org/abs/2510.15974)
*Chris Su,Harrison Li,Matheus Marques,George Flint,Kevin Zhu,Sunishchal Dev*

Main category: cs.AI

TL;DR: 研究发现大型推理模型在解决复杂谜题时会出现性能崩溃，即使提供环境接口让模型能够跟踪状态空间，也无法避免这种崩溃。模型表现出模式崩溃，性能取决于其模式是否匹配正确解法。


<details>
  <summary>Details</summary>
Motivation: 探索大型推理模型在解决复杂谜题时性能崩溃的根本原因，检验是否由于模型需要自行跟踪状态空间而导致评估混淆。

Method: 为大型语言模型提供汉诺塔问题的环境接口，允许其通过工具调用进行移动、提供书面理由、观察结果状态空间并重新提示下一步。进行LLM参数化策略分析。

Result: 环境接口的访问并不能延迟或消除性能崩溃。模型策略与最优策略和均匀随机策略的差异逐渐增大，表明在每种复杂度级别都出现模式崩溃，性能取决于模式是否反映问题的正确解决方案。

Conclusion: 大型推理模型在复杂推理任务中确实存在性能崩溃现象，这种崩溃与状态跟踪能力无关，而是源于模型本身的模式崩溃行为。类似现象可能也存在于其他大型推理模型中。

Abstract: Recent work reports that Large Reasoning Models (LRMs) undergo a collapse in
performance on solving puzzles beyond certain perplexity thresholds. In
subsequent discourse, questions have arisen as to whether the nature of the
task muddles an evaluation of true reasoning. One potential confound is the
requirement that the model keep track of the state space on its own. We provide
a large language model (LLM) with an environment interface for Tower of Hanoi
problems, allowing it to make a move with a tool call, provide written
justification, observe the resulting state space, and reprompt itself for the
next move. We observe that access to an environment interface does not delay or
eradicate performance collapse. Furthermore, LLM-parameterized policy analysis
reveals increasing divergence from both optimal policies and uniformly random
policies, suggesting that the model exhibits mode-like collapse at each level
of complexity, and that performance is dependent upon whether the mode reflects
the correct solution for the problem. We suggest that a similar phenomena might
take place in LRMs.

</details>


### [73] [ProofFlow: A Dependency Graph Approach to Faithful Proof Autoformalization](https://arxiv.org/abs/2510.15981)
*Rafael Cabral,Tuan Manh Do,Xuejun Yu,Wai Ming Tai,Zijin Feng,Xin Shen*

Main category: cs.AI

TL;DR: ProofFlow是一个新颖的自动形式化证明流水线，通过构建逻辑依赖图和使用基于引理的方法，在保持原始证明语义和逻辑结构的同时，将自然语言证明转换为机器可验证代码。


<details>
  <summary>Details</summary>
Motivation: 现有的自动形式化方法主要关注生成可执行代码，但经常无法保持原始人工编写证明的语义含义和逻辑结构。为了解决这个问题，需要将结构保真度作为主要目标。

Method: ProofFlow首先构建有向无环图来映射证明步骤之间的逻辑依赖关系，然后采用基于引理的方法系统地形式化每个步骤为中间引理，从而保持原始论证的逻辑结构。

Result: 实验结果显示，ProofFlow在自动形式化方面达到了新的最先进水平，ProofScore得分为0.545，显著超过全证明形式化（0.123）和步骤证明形式化（0.072）等基线方法。

Conclusion: ProofFlow通过关注结构保真度，在自动形式化证明方面取得了显著改进，其流水线、基准和评分指标已开源以促进进一步研究。

Abstract: Proof autoformalization, the task of translating natural language theorems
and proofs into machine-verifiable code, is a critical step for integrating
large language models into rigorous mathematical workflows. Current approaches
focus on producing executable code, but they frequently fail to preserve the
semantic meaning and logical structure of the original human-written argument.
To address this, we introduce ProofFlow, a novel pipeline that treats
structural fidelity as a primary objective. ProofFlow first constructs a
directed acyclic graph (DAG) to map the logical dependencies between proof
steps. Then, it employs a novel lemma-based approach to systematically
formalize each step as an intermediate lemma, preserving the logical structure
of the original argument. To facilitate evaluation, we present a new benchmark
of 184 undergraduate-level problems, manually annotated with step-by-step
solutions and logical dependency graphs, and introduce ProofScore, a new
composite metric to evaluate syntactic correctness, semantic faithfulness, and
structural fidelity. Experimental results show our pipeline sets a new
state-of-the-art for autoformalization, achieving a ProofScore of 0.545,
substantially exceeding baselines like full-proof formalization (0.123), which
processes the entire proof at once, and step-proof formalization (0.072), which
handles each step independently. Our pipeline, benchmark, and score metric are
open-sourced to encourage further progress at
https://github.com/Huawei-AI4Math/ProofFlow.

</details>


### [74] [Ontologies in Motion: A BFO-Based Approach to Knowledge Graph Construction for Motor Performance Research Data in Sports Science](https://arxiv.org/abs/2510.15983)
*Sarah Rebecca Ondraszek,Jörg Waitelonis,Katja Keller,Claudia Niessner,Anna M. Jacyszyn,Harald Sack*

Main category: cs.AI

TL;DR: 本文介绍了MO|RE数据知识图谱的构建愿景，旨在将运动科学中的运动表现数据标准化和机器可理解化。


<details>
  <summary>Details</summary>
Motivation: 为了评估和比较不同人群的生理和认知能力，需要测试与人类表现相关的各种因素。运动表现测试作为运动科学研究的核心部分，能够分析不同人口群体的身体健康状况并使其具有可比性。

Method: 基于基本形式本体论构建本体，重点形式化表示计划规范、特定过程和相关测量之间的相互关系。在MO|RE数据基础上创建知识图谱。

Result: 提出了一个将运动表现数据建模和共享标准化的方法，使其能够跨研究使用并被机器理解。

Conclusion: 通过知识图谱方法，MO|RE数据能够以标准化和机器可理解的方式被建模和共享，这将改变运动表现数据的使用方式。

Abstract: An essential component for evaluating and comparing physical and cognitive
capabilities between populations is the testing of various factors related to
human performance. As a core part of sports science research, testing motor
performance enables the analysis of the physical health of different
demographic groups and makes them comparable.
  The Motor Research (MO|RE) data repository, developed at the Karlsruhe
Institute of Technology, is an infrastructure for publishing and archiving
research data in sports science, particularly in the field of motor performance
research. In this paper, we present our vision for creating a knowledge graph
from MO|RE data. With an ontology rooted in the Basic Formal Ontology, our
approach centers on formally representing the interrelation of plan
specifications, specific processes, and related measurements. Our goal is to
transform how motor performance data are modeled and shared across studies,
making it standardized and machine-understandable. The idea presented here is
developed within the Leibniz Science Campus ``Digital Transformation of
Research'' (DiTraRe).

</details>


### [75] [A Non-overlap-based Conflict Measure for Random Permutation Sets](https://arxiv.org/abs/2510.16001)
*Ruolan Cheng,Yong Deng,Enrique Herrera-Viedma*

Main category: cs.AI

TL;DR: 本文提出了一种新的随机置换集冲突度量方法，从随机有限集和Dempster-Shafer理论两个角度分析冲突，基于秩偏重叠度量定义置换间的不一致性，并扩展为RPST的冲突度量方法。


<details>
  <summary>Details</summary>
Motivation: 随机置换集作为处理包含顺序信息的不确定性的新形式化方法，需要有效度量两个置换质量函数之间的冲突，以支持顺序结构不确定信息融合。

Method: 从置换观察出发，基于秩偏重叠度量定义置换间的不一致性，进一步提出非重叠基础的RPS冲突度量方法，将RPST视为DST的扩展，利用新增的顺序信息表征定性倾向性。

Result: 通过数值示例验证了所提冲突度量的行为和性质，该方法具有自然的顶部加权特性，能从DST视角有效度量RPS间的冲突，并为决策者提供权重、参数和截断深度的灵活选择。

Conclusion: 所提出的冲突度量方法不仅具备理论优势，还能为顺序结构不确定信息融合提供实用的冲突分析工具。

Abstract: Random permutation set (RPS) is a new formalism for reasoning with
uncertainty involving order information. Measuring the conflict between two
pieces of evidence represented by permutation mass functions remains an urgent
research topic in order-structured uncertain information fusion. In this paper,
a detailed analysis of conflicts in RPS is carried out from two different
perspectives: random finite set (RFS) and Dempster-Shafer theory (DST).
Starting from the observation of permutations, we first define an inconsistency
measure between permutations inspired by the rank-biased overlap(RBO) measure
and further propose a non-overlap-based conflict measure method for RPSs. This
paper regards RPS theory (RPST) as an extension of DST. The order information
newly added in focal sets indicates qualitative propensity, characterized by
top-ranked elements occupying a more critical position. Some numerical examples
are used to demonstrate the behavior and properties of the proposed conflict
measure. The proposed method not only has the natural top-weightedness property
and can effectively measure the conflict between RPSs from the DST view but
also provides decision-makers with a flexible selection of weights, parameters,
and truncated depths.

</details>


### [76] [Towards Automatic Evaluation and Selection of PHI De-identification Models via Multi-Agent Collaboration](https://arxiv.org/abs/2510.16194)
*Guanchen Wu,Zuhui Chen,Yuzhang Xie,Carl Yang*

Main category: cs.AI

TL;DR: TEAM-PHI是一个基于大语言模型的多智能体评估框架，用于自动评估和选择医疗信息去标识化模型，无需依赖昂贵的专家标注。


<details>
  <summary>Details</summary>
Motivation: 医疗信息去标识化对于安全重用临床笔记至关重要，但传统评估方法依赖成本高昂的小规模专家标注，限制了模型比较和选择。

Method: 部署多个评估智能体独立判断PHI提取的正确性，然后通过基于LLM的多数投票机制整合结果，生成稳定可重现的排名。

Result: 在真实临床笔记语料上的实验表明，TEAM-PHI能产生一致准确的排名，尽管个体评估者存在差异，但LLM投票能可靠地收敛到相同的最佳系统。

Conclusion: TEAM-PHI通过结合独立评估智能体和LLM多数投票，为PHI去标识化提供了实用、安全且成本效益高的自动评估和最佳模型选择解决方案。

Abstract: Protected health information (PHI) de-identification is critical for enabling
the safe reuse of clinical notes, yet evaluating and comparing PHI
de-identification models typically depends on costly, small-scale expert
annotations. We present TEAM-PHI, a multi-agent evaluation and selection
framework that uses large language models (LLMs) to automatically measure
de-identification quality and select the best-performing model without heavy
reliance on gold labels. TEAM-PHI deploys multiple Evaluation Agents, each
independently judging the correctness of PHI extractions and outputting
structured metrics. Their results are then consolidated through an LLM-based
majority voting mechanism that integrates diverse evaluator perspectives into a
single, stable, and reproducible ranking. Experiments on a real-world clinical
note corpus demonstrate that TEAM-PHI produces consistent and accurate
rankings: despite variation across individual evaluators, LLM-based voting
reliably converges on the same top-performing systems. Further comparison with
ground-truth annotations and human evaluation confirms that the framework's
automated rankings closely match supervised evaluation. By combining
independent evaluation agents with LLM majority voting, TEAM-PHI offers a
practical, secure, and cost-effective solution for automatic evaluation and
best-model selection in PHI de-identification, even when ground-truth labels
are limited.

</details>


### [77] [Beyond Fixed Anchors: Precisely Erasing Concepts with Sibling Exclusive Counterparts](https://arxiv.org/abs/2510.16342)
*Tong Zhang,Ru Zhang,Jianyi Liu,Zhen Yang,Gongshen Liu*

Main category: cs.AI

TL;DR: 本文提出SELECT方法，通过动态锚点选择解决文本到图像扩散模型中概念擦除的锚点固定问题，避免概念重现和侵蚀。


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除方法依赖固定锚点策略，导致概念重现和侵蚀等关键问题。

Method: 提出SELECT框架，采用两阶段评估机制自动发现最优擦除锚点并识别边界锚点以保护相关概念。

Result: SELECT作为通用锚点解决方案，能高效适配多种擦除框架，在关键性能指标上持续优于现有基线，单个概念锚点挖掘平均仅需4秒。

Conclusion: 动态锚点选择框架SELECT有效解决了固定锚点策略的局限性，提升了概念擦除的精确性和效率。

Abstract: Existing concept erasure methods for text-to-image diffusion models commonly
rely on fixed anchor strategies, which often lead to critical issues such as
concept re-emergence and erosion. To address this, we conduct causal tracing to
reveal the inherent sensitivity of erasure to anchor selection and define
Sibling Exclusive Concepts as a superior class of anchors. Based on this
insight, we propose \textbf{SELECT} (Sibling-Exclusive Evaluation for
Contextual Targeting), a dynamic anchor selection framework designed to
overcome the limitations of fixed anchors. Our framework introduces a novel
two-stage evaluation mechanism that automatically discovers optimal anchors for
precise erasure while identifying critical boundary anchors to preserve related
concepts. Extensive evaluations demonstrate that SELECT, as a universal anchor
solution, not only efficiently adapts to multiple erasure frameworks but also
consistently outperforms existing baselines across key performance metrics,
averaging only 4 seconds for anchor mining of a single concept.

</details>


### [78] [The Burden of Interactive Alignment with Inconsistent Preferences](https://arxiv.org/abs/2510.16368)
*Ali Shirali*

Main category: cs.AI

TL;DR: 该研究探讨了具有不一致偏好的用户如何通过战略性地与算法互动来引导算法更好地符合其真实兴趣。研究发现存在一个关键的时间跨度阈值：足够有远见的用户可以实现对齐，而短视的用户则会被算法目标所同化。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于用户与算法互动中的不一致偏好问题。用户可能花费大量时间在低价值内容上，无意中向算法传递错误信号。这引发了一个关键问题：这类用户需要什么条件才能让算法与其真实兴趣对齐？

Method: 将用户的决策过程建模为理性系统2（决定是否参与）和冲动系统1（决定参与时长）的分离。采用多领导者-单跟随者的扩展Stackelberg博弈框架，用户（系统2）通过承诺参与策略来领导，算法基于观察到的互动做出最佳响应。

Result: 研究发现存在一个对齐负担（alignment burden）——用户必须优化的最小时间跨度。足够有远见的用户可以实现对齐，而短视用户则会被算法目标同化。即使是一个小的、有成本的信号（如额外点击）也能显著降低这个关键时间跨度。

Conclusion: 该框架解释了具有不一致偏好的用户如何在Stackelberg均衡中使参与驱动的算法与其兴趣对齐，既突出了实现对齐的挑战，也指出了潜在的补救措施。

Abstract: From media platforms to chatbots, algorithms shape how people interact,
learn, and discover information. Such interactions between users and an
algorithm often unfold over multiple steps, during which strategic users can
guide the algorithm to better align with their true interests by selectively
engaging with content. However, users frequently exhibit inconsistent
preferences: they may spend considerable time on content that offers little
long-term value, inadvertently signaling that such content is desirable.
Focusing on the user side, this raises a key question: what does it take for
such users to align the algorithm with their true interests?
  To investigate these dynamics, we model the user's decision process as split
between a rational system 2 that decides whether to engage and an impulsive
system 1 that determines how long engagement lasts. We then study a
multi-leader, single-follower extensive Stackelberg game, where users,
specifically system 2, lead by committing to engagement strategies and the
algorithm best-responds based on observed interactions. We define the burden of
alignment as the minimum horizon over which users must optimize to effectively
steer the algorithm. We show that a critical horizon exists: users who are
sufficiently foresighted can achieve alignment, while those who are not are
instead aligned to the algorithm's objective. This critical horizon can be
long, imposing a substantial burden. However, even a small, costly signal
(e.g., an extra click) can significantly reduce it. Overall, our framework
explains how users with inconsistent preferences can align an engagement-driven
algorithm with their interests in a Stackelberg equilibrium, highlighting both
the challenges and potential remedies for achieving alignment.

</details>


### [79] [ReviewSense: Transforming Customer Review Dynamics into Actionable Business Insights](https://arxiv.org/abs/2510.16466)
*Siddhartha Krothapalli,Tridib Kumar Das,Praveen Kumar,Naveen Suravarpu,Pratik Narang*

Main category: cs.AI

TL;DR: ReviewSense是一个基于大语言模型的决策支持框架，可将客户评论转化为有针对性的商业建议，超越传统偏好预测系统，为企业提供可操作的洞察。


<details>
  <summary>Details</summary>
Motivation: 随着客户反馈对战略增长日益重要，需要从非结构化评论中提取可操作见解。传统AI系统擅长预测用户偏好，但缺乏将客户评论转化为面向业务的规范性建议的能力。

Method: 提出ReviewSense框架，整合聚类、大语言模型适应和专家驱动评估，形成统一的业务导向流程，识别关键趋势、重复问题和具体关注点。

Result: 初步人工评估显示模型建议与商业目标高度一致，突显其在数据驱动决策方面的潜力。

Conclusion: 该框架为AI驱动的情感分析提供了新视角，展示了其在优化商业策略和最大化客户反馈影响方面的价值。

Abstract: As customer feedback becomes increasingly central to strategic growth, the
ability to derive actionable insights from unstructured reviews is essential.
While traditional AI-driven systems excel at predicting user preferences, far
less work has focused on transforming customer reviews into prescriptive,
business-facing recommendations. This paper introduces ReviewSense, a novel
prescriptive decision support framework that leverages advanced large language
models (LLMs) to transform customer reviews into targeted, actionable business
recommendations. By identifying key trends, recurring issues, and specific
concerns within customer sentiments, ReviewSense extends beyond
preference-based systems to provide businesses with deeper insights for
sustaining growth and enhancing customer loyalty. The novelty of this work lies
in integrating clustering, LLM adaptation, and expert-driven evaluation into a
unified, business-facing pipeline. Preliminary manual evaluations indicate
strong alignment between the model's recommendations and business objectives,
highlighting its potential for driving data-informed decision-making. This
framework offers a new perspective on AI-driven sentiment analysis,
demonstrating its value in refining business strategies and maximizing the
impact of customer feedback.

</details>


### [80] [Count Counts: Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards](https://arxiv.org/abs/2510.16614)
*Xuan Zhang,Ruixiao Li,Zhijian Zhou,Long Li,Yulei Qin,Ke Li,Xing Sun,Xiaoyu Tan,Chao Qu,Yuan Qi*

Main category: cs.AI

TL;DR: MERCI是一种新颖的强化学习算法，通过基于计数的内在奖励来增强LLM推理中的探索能力，显著改善推理多样性和性能。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习范式依赖稀疏的结果奖励和有限探索，导致LLM陷入重复和次优的推理模式，需要设计更好的探索机制来提升推理能力。

Method: 基于计数探索思想，使用轻量级Coin Flipping Network估计推理轨迹的伪计数和认知不确定性，将其转化为内在奖励，并集成到GRPO等先进RL框架中。

Result: 在复杂推理基准测试中，MERCI鼓励更丰富多样的思维链，显著超越强基线性能，帮助策略逃离局部常规发现更好解决方案。

Conclusion: 针对性的内在动机可以使语言模型推理中的探索更加可靠有效。

Abstract: Reinforcement Learning (RL) has become a compelling way to strengthen the
multi step reasoning ability of Large Language Models (LLMs). However,
prevalent RL paradigms still lean on sparse outcome-based rewards and limited
exploration, which often drives LLMs toward repetitive and suboptimal reasoning
patterns. In this paper, we study the central question of how to design
exploration for LLM reasoning and introduce MERCI (Motivating Exploration in
LLM Reasoning with Count-based Intrinsic Rewards), a novel RL algorithm that
augments policy optimization with a principled intrinsic reward. Building on
the idea of count-based exploration, MERCI leverages a lightweight Coin
Flipping Network (CFN) to estimate the pseudo count and further epistemic
uncertainty over reasoning trajectories, and converts them into an intrinsic
reward that values novelty while preserving the learning signal from task
rewards. We integrate MERCI into some advanced RL frameworks like Group
Relative Policy Optimization (GRPO). Experiments on complex reasoning
benchmarks demonstrate that MERCI encourages richer and more varied chains of
thought, significantly improves performance over strong baselines, and helps
the policy escape local routines to discover better solutions. It indicates
that our targeted intrinsic motivation can make exploration reliable for
language model reasoning.

</details>


### [81] [Foundation and Large-Scale AI Models in Neuroscience: A Comprehensive Review](https://arxiv.org/abs/2510.16658)
*Shihao Yang,Xiying Huang,Danilo Bernardo,Jun-En Ding,Andrew Michael,Jingmei Yang,Patrick Kwan,Ashish Raj,Feng Liu*

Main category: cs.AI

TL;DR: 本文探讨大规模AI模型对神经科学研究的变革性影响，涵盖神经影像数据处理、脑机接口、分子神经科学、临床辅助和疾病应用等领域，强调AI在解决多模态神经数据整合、时空模式解释等挑战中的作用。


<details>
  <summary>Details</summary>
Motivation: 大规模AI模型的出现为神经科学研究带来了范式转变，促进了从原始脑信号和神经数据的端到端学习，需要系统评估这些模型在神经科学各领域的应用潜力。

Method: 通过综述分析大规模AI模型在五个主要神经科学领域的应用：神经影像数据处理、脑机接口与神经解码、分子神经科学与基因组建模、临床辅助与转化框架、神经系统和精神疾病的特定应用。

Result: 研究表明这些模型能有效解决多模态神经数据整合、时空模式解释等计算神经科学挑战，并促进神经科学与AI的双向互动，将生物学约束纳入模型开发。

Conclusion: 大规模AI模型在神经科学中具有显著潜力，但需要建立严格的评估框架、有效的领域知识整合以及全面的临床使用伦理指南，同时提供了关键神经科学数据集的系统清单。

Abstract: The advent of large-scale artificial intelligence (AI) models has a
transformative effect on neuroscience research, which represents a paradigm
shift from the traditional computational methods through the facilitation of
end-to-end learning from raw brain signals and neural data. In this paper, we
explore the transformative effects of large-scale AI models on five major
neuroscience domains: neuroimaging and data processing, brain-computer
interfaces and neural decoding, molecular neuroscience and genomic modeling,
clinical assistance and translational frameworks, and disease-specific
applications across neurological and psychiatric disorders. These models are
demonstrated to address major computational neuroscience challenges, including
multimodal neural data integration, spatiotemporal pattern interpretation, and
the derivation of translational frameworks for clinical deployment. Moreover,
the interaction between neuroscience and AI has become increasingly reciprocal,
as biologically informed architectural constraints are now incorporated to
develop more interpretable and computationally efficient models. This review
highlights both the notable promise of such technologies and key implementation
considerations, with particular emphasis on rigorous evaluation frameworks,
effective domain knowledge integration, and comprehensive ethical guidelines
for clinical use. Finally, a systematic listing of critical neuroscience
datasets used to derive and validate large-scale AI models across diverse
research applications is provided.

</details>


### [82] [ELMM: Efficient Lightweight Multimodal Large Language Models for Multimodal Knowledge Graph Completion](https://arxiv.org/abs/2510.16753)
*Wei Huang,Peining Li,Meiyu Liang,Xu Hou,Junping Du,Yingxia Shao,Guanhua Ye,Wu Liu,Kangkang Lu,Yang Yu*

Main category: cs.AI

TL;DR: 本文提出ELMM方法，通过多视图视觉标记压缩器和注意力剪枝策略，解决多模态知识图谱补全中的语义噪声、模态冲突和计算成本高的问题，在保持性能的同时显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 多模态知识图谱存在不完整性问题，而现有方法在处理多模态信息时面临语义噪声、模态冲突和高计算成本的挑战，需要开发更高效的补全方法。

Method: 提出ELMM框架，包含基于多头注意力的多视图视觉标记压缩器来压缩图像标记，以及注意力剪枝策略来减少冗余层，并使用线性投影补偿剪枝带来的性能损失。

Result: 在FB15k-237-IMG和WN18-IMG基准测试中，ELMM实现了最先进的性能，同时显著提高了计算效率。

Conclusion: ELMM为多模态知识图谱补全建立了新的范式，在保持高性能的同时大幅降低了计算成本。

Abstract: Multimodal Knowledge Graphs (MKGs) extend traditional knowledge graphs by
incorporating visual and textual modalities, enabling richer and more
expressive entity representations. However, existing MKGs often suffer from
incompleteness, which hinder their effectiveness in downstream tasks.
Therefore, multimodal knowledge graph completion (MKGC) task is receiving
increasing attention. While large language models (LLMs) have shown promise for
knowledge graph completion (KGC), their application to the multimodal setting
remains underexplored. Moreover, applying Multimodal Large Language Models
(MLLMs) to the task of MKGC introduces significant challenges: (1) the large
number of image tokens per entity leads to semantic noise and modality
conflicts, and (2) the high computational cost of processing large token
inputs. To address these issues, we propose Efficient Lightweight Multimodal
Large Language Models (ELMM) for MKGC. ELMM proposes a Multi-view Visual Token
Compressor (MVTC) based on multi-head attention mechanism, which adaptively
compresses image tokens from both textual and visual views, thereby effectively
reducing redundancy while retaining necessary information and avoiding modality
conflicts. Additionally, we design an attention pruning strategy to remove
redundant attention layers from MLLMs, thereby significantly reducing the
inference cost. We further introduce a linear projection to compensate for the
performance degradation caused by pruning. Extensive experiments on benchmark
FB15k-237-IMG and WN18-IMG demonstrate that ELMM achieves state-of-the-art
performance while substantially improving computational efficiency,
establishing a new paradigm for multimodal knowledge graph completion.

</details>


### [83] [Domain-Contextualized Concept Graphs: A Computable Framework for Knowledge Representation](https://arxiv.org/abs/2510.16802)
*Chao Li,Yuru Wang*

Main category: cs.AI

TL;DR: 本文提出了一种新的知识建模框架——领域情境化概念图（CDC），通过将领域提升为概念表示的一等元素，克服传统知识图谱固定本体的限制，实现上下文感知推理和跨领域类比。


<details>
  <summary>Details</summary>
Motivation: 传统知识图谱受限于固定本体，将领域作为隐式上下文而非显式推理组件，导致概念组织僵化。

Method: 采用C-D-C三元组结构<概念, 关系@领域, 概念'>，将领域规范作为按需定义的动态分类维度，基于认知-语言同构映射原理，实现人类通过上下文框架理解概念的方式。

Result: 在Prolog中实现CDC并具备完整推理能力，案例研究表明CDC能够实现上下文感知推理、跨领域类比和个性化知识建模。

Conclusion: CDC框架突破了传统基于本体的知识表示限制，为知识建模提供了更灵活和动态的方法。

Abstract: Traditional knowledge graphs are constrained by fixed ontologies that
organize concepts within rigid hierarchical structures. The root cause lies in
treating domains as implicit context rather than as explicit, reasoning-level
components. To overcome these limitations, we propose the Domain-Contextualized
Concept Graph (CDC), a novel knowledge modeling framework that elevates domains
to first-class elements of conceptual representation. CDC adopts a C-D-C triple
structure - <Concept, Relation@Domain, Concept'> - where domain specifications
serve as dynamic classification dimensions defined on demand. Grounded in a
cognitive-linguistic isomorphic mapping principle, CDC operationalizes how
humans understand concepts through contextual frames. We formalize more than
twenty standardized relation predicates (structural, logical, cross-domain, and
temporal) and implement CDC in Prolog for full inference capability. Case
studies in education, enterprise knowledge systems, and technical documentation
demonstrate that CDC enables context-aware reasoning, cross-domain analogy, and
personalized knowledge modeling - capabilities unattainable under traditional
ontology-based frameworks.

</details>


### [84] [ToolCritic: Detecting and Correcting Tool-Use Errors in Dialogue Systems](https://arxiv.org/abs/2510.17052)
*Hassan Hamad,Yingru Xu,Liang Zhao,Wenbo Yan,Narendra Gyanchandani*

Main category: cs.AI

TL;DR: ToolCritic是一个诊断框架，用于评估和改进大型语言模型在多轮工具增强对话中的行为，通过检测8种特定工具调用错误并提供针对性反馈，将工具调用准确率提升高达13%。


<details>
  <summary>Details</summary>
Motivation: 工具增强的大型语言模型在现实应用中越来越普遍，但工具使用错误仍然阻碍其可靠性，需要系统性的错误检测和改进机制。

Method: 提出ToolCritic框架，定义8种特定工具调用错误类型，构建合成数据集训练ToolCritic，让具备强推理能力的主LLM根据ToolCritic的反馈修正响应。

Result: 在Schema-Guided Dialogue数据集上的实验结果表明，ToolCritic相比基线方法（包括零样本提示和自校正技术）将工具调用准确率提升高达13%。

Conclusion: ToolCritic代表了在现实对话应用中实现更稳健的LLM与外部工具集成的有前景的一步。

Abstract: Tool-augmented large language models (LLMs) are increasingly employed in
real-world applications, but tool usage errors still hinder their reliability.
We introduce ToolCritic, a diagnostic framework that evaluates and improves LLM
behavior in multi-turn, tool-augmented dialogues. ToolCritic detects eight
distinct error types specific to tool-calling (e.g., premature invocation,
argument misalignment, and misinterpretation of tool outputs) and provides
targeted feedback to the main LLM. The main LLM, assumed to have strong
reasoning, task understanding and orchestration capabilities, then revises its
response based on ToolCritic's feedback. We systematically define these error
categories and construct a synthetic dataset to train ToolCritic. Experimental
results on the Schema-Guided Dialogue (SGD) dataset demonstrate that ToolCritic
improves tool-calling accuracy by up to 13% over baselines, including zero-shot
prompting and self-correction techniques. This represents a promising step
toward more robust LLM integration with external tools in real-world dialogue
applications.

</details>


### [85] [Which LLM Multi-Agent Protocol to Choose?](https://arxiv.org/abs/2510.17149)
*Hongyi Du,Jiaqi Su,Jisen Li,Lijie Ding,Yingxuan Yang,Peixuan Han,Xiangru Tang,Kunlun Zhu,Jiaxuan You*

Main category: cs.AI

TL;DR: ProtocolBench是一个系统评估多智能体系统通信协议的基准测试，比较了不同协议在任务成功率、延迟、消息开销和故障恢复能力四个维度上的表现。研究发现协议选择对系统性能有显著影响，并提出了ProtocolRouter学习型协议路由器来优化协议选择。


<details>
  <summary>Details</summary>
Motivation: 随着大规模多智能体系统的发展，通信协议层成为影响性能和可靠性的关键因素，但目前协议选择缺乏标准化指导，主要依赖直觉。

Method: 引入ProtocolBench基准测试系统，从四个可测量维度（任务成功率、端到端延迟、消息/字节开销、故障恢复能力）比较不同协议。同时提出ProtocolRouter学习型协议路由器，根据需求和运行时信号选择最优协议。

Result: 协议选择显著影响系统行为：在Streaming Queue场景中，总体完成时间差异达36.5%，平均端到端延迟差异3.48秒。ProtocolRouter相比最佳单协议基线，将Fail-Storm恢复时间减少18.1%，并在GAIA场景中实现更高成功率。

Conclusion: 通信协议选择对多智能体系统性能至关重要，ProtocolBench提供了标准化评估方法，ProtocolRouter通过智能协议选择显著提升了系统可靠性和性能。

Abstract: As large-scale multi-agent systems evolve, the communication protocol layer
has become a critical yet under-evaluated factor shaping performance and
reliability. Despite the existence of diverse protocols (A2A, ACP, ANP, Agora,
etc.), selection is often intuition-driven and lacks standardized guidance. We
introduce ProtocolBench, a benchmark that systematically compares agent
protocols along four measurable axes: task success, end-to-end latency, message
or byte overhead, and robustness under failures. On ProtocolBench, protocol
choice significantly influences system behavior. In the Streaming Queue
scenario, overall completion time varies by up to 36.5% across protocols, and
mean end-to-end latency differs by 3.48 s. Under Fail-Storm Recovery,
resilience also differs consistently across protocols. Beyond evaluation, we
present ProtocolRouter, a learnable protocol router that selects per-scenario
(or per-module) protocols from requirement and runtime signals. ProtocolRouter
reduces Fail-Storm recovery time by up to 18.1% versus the best single-protocol
baseline, and achieves scenario-specific gains such as higher success in GAIA.
We also release ProtocolRouterBench to standardize protocol evaluation and
improve reliability at scale.

</details>


### [86] [Combining ECG Foundation Model and XGBoost to Predict In-Hospital Malignant Ventricular Arrhythmias in AMI Patients](https://arxiv.org/abs/2510.17172)
*Shun Huang,Wenlu Xing,Shijia Geng,Hailong Wang,Guangkun Nie,Gongzheng Tang,Chenyang He,Shenda Hong*

Main category: cs.AI

TL;DR: 本研究开发了一种结合ECG基础模型和可解释XGBoost分类器的混合预测框架，用于预测急性心肌梗死后恶性室性心律失常风险，在提高准确性的同时保持可解释性。


<details>
  <summary>Details</summary>
Motivation: 急性心肌梗死后恶性室性心律失常是院内死亡的主要原因，但传统风险评分性能有限，而端到端深度学习模型缺乏临床信任所需的可解释性。

Method: 使用ECG基础模型提取150维诊断概率特征，通过特征选择后训练XGBoost分类器，并采用SHAP方法进行可解释性分析。

Result: 混合模型AUC达到0.801，优于KNN、RNN和1D-CNN模型，SHAP分析显示模型识别特征与临床知识高度一致。

Conclusion: 该混合框架为VT/VF风险预测提供了新范式，验证了基础模型输出作为有效自动化特征工程在构建可信赖、可解释AI临床决策支持系统中的应用。

Abstract: Malignant ventricular arrhythmias (VT/VF) following acute myocardial
infarction (AMI) are a major cause of in-hospital death, yet early
identification remains a clinical challenge. While traditional risk scores have
limited performance, end-to-end deep learning models often lack the
interpretability needed for clinical trust. This study aimed to develop a
hybrid predictive framework that integrates a large-scale electrocardiogram
(ECG) foundation model (ECGFounder) with an interpretable XGBoost classifier to
improve both accuracy and interpretability. We analyzed 6,634 ECG recordings
from AMI patients, among whom 175 experienced in-hospital VT/VF. The ECGFounder
model was used to extract 150-dimensional diagnostic probability features ,
which were then refined through feature selection to train the XGBoost
classifier. Model performance was evaluated using AUC and F1-score , and the
SHAP method was used for interpretability. The ECGFounder + XGBoost hybrid
model achieved an AUC of 0.801 , outperforming KNN (AUC 0.677), RNN (AUC
0.676), and an end-to-end 1D-CNN (AUC 0.720). SHAP analysis revealed that
model-identified key features, such as "premature ventricular complexes" (risk
predictor) and "normal sinus rhythm" (protective factor), were highly
consistent with clinical knowledge. We conclude that this hybrid framework
provides a novel paradigm for VT/VF risk prediction by validating the use of
foundation model outputs as effective, automated feature engineering for
building trustworthy, explainable AI-based clinical decision support systems.

</details>


### [87] [Label Indeterminacy in AI & Law](https://arxiv.org/abs/2510.17463)
*Cor Steging,Tadeusz Zbiegień*

Main category: cs.AI

TL;DR: 本文讨论了法律机器学习中的标签不确定性（label indeterminacy）问题，即法律案件结果可能因人为干预（如和解、上诉等）而改变，导致训练数据中的标签不具确定性。作者通过欧洲人权法院案例研究展示了标签构建方式如何显著影响模型行为。


<details>
  <summary>Details</summary>
Motivation: 法律机器学习通常将过去案件结果视为真实标签，但法律结果往往受到未记录的人为干预影响，导致标签不确定性。这种不确定性可能影响模型的可靠性和公平性。

Method: 在欧洲人权法院案例分类的背景下，研究不同标签构建方法对模型行为的影响，探讨处理标签不确定性的现有方法及其假设。

Result: 研究表明，训练过程中标签的构建方式会显著影响模型行为，验证了标签不确定性对法律机器学习的重要影响。

Conclusion: 标签不确定性是AI与法律领域的重要关注点，需要在法律机器学习应用中予以考虑，尽管现有处理方法都基于无法验证的假设。

Abstract: Machine learning is increasingly used in the legal domain, where it typically
operates retrospectively by treating past case outcomes as ground truth.
However, legal outcomes are often shaped by human interventions that are not
captured in most machine learning approaches. A final decision may result from
a settlement, an appeal, or other procedural actions. This creates label
indeterminacy: the outcome could have been different if the intervention had or
had not taken place. We argue that legal machine learning applications need to
account for label indeterminacy. Methods exist that can impute these
indeterminate labels, but they are all grounded in unverifiable assumptions. In
the context of classifying cases from the European Court of Human Rights, we
show that the way that labels are constructed during training can significantly
affect model behaviour. We therefore position label indeterminacy as a relevant
concern in AI & Law and demonstrate how it can shape model behaviour.

</details>


### [88] [A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2510.17697)
*Anjie Liu,Jianhong Wang,Samuel Kaski,Jun Wang,Mengyue Yang*

Main category: cs.AI

TL;DR: 本文提出使用多智能体影响图（MAIDs）作为图形框架来解决多智能体强化学习（MARL）中的协调问题，设计了基于MAIDs的定向干预范式，通过因果推断技术PSI实现单智能体干预，避免全局指导的复杂性。


<details>
  <summary>Details</summary>
Motivation: 在大规模MARL中，对整个多智能体系统进行全局人类指导不切实际，而现有协调机制设计主要依赖经验研究，缺乏易用的研究工具。

Method: 引入MAIDs作为图形框架分析现有MARL方法，设计基于MAIDs的定向干预范式，应用因果推断技术PSI实现单智能体干预，通过最大化因果效应达成复合期望结果。

Result: 实验证明了定向干预的有效性，并验证了相关性图分析的结果。

Conclusion: MAIDs提供了一个有效的框架来分析和设计MARL交互范式，定向干预能够缓解全局指导问题，PSI技术能够有效实现期望结果。

Abstract: Steering cooperative multi-agent reinforcement learning (MARL) towards
desired outcomes is challenging, particularly when the global guidance from a
human on the whole multi-agent system is impractical in a large-scale MARL. On
the other hand, designing mechanisms to coordinate agents most relies on
empirical studies, lacking a easy-to-use research tool. In this work, we employ
multi-agent influence diagrams (MAIDs) as a graphical framework to address the
above issues. First, we introduce interaction paradigms that leverage MAIDs to
analyze and visualize existing approaches in MARL. Then, we design a new
interaction paradigm based on MAIDs, referred to as targeted intervention that
is applied to only a single targeted agent, so the problem of global guidance
can be mitigated. In our implementation, we introduce a causal inference
technique-referred to as Pre-Strategy Intervention (PSI)-to realize the
targeted intervention paradigm. Since MAIDs can be regarded as a special class
of causal diagrams, a composite desired outcome that integrates the primary
task goal and an additional desired outcome can be achieved by maximizing the
corresponding causal effect through the PSI. Moreover, the bundled relevance
graph analysis of MAIDs provides a tool to identify whether an MARL learning
paradigm is workable under the design of an interaction paradigm. In
experiments, we demonstrate the effectiveness of our proposed targeted
intervention, and verify the result of relevance graph analysis.

</details>


### [89] [Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs](https://arxiv.org/abs/2510.17771)
*Zhining Liu,Ziyi Chen,Hui Liu,Chen Luo,Xianfeng Tang,Suhang Wang,Joy Zeng,Zhenwei Dai,Zhan Shi,Tianxin Wei,Benoit Dumoulin,Hanghang Tong*

Main category: cs.AI

TL;DR: 研究发现视觉语言模型在输出错误答案时仍能感知到正确的视觉证据，这种现象被称为"看见但不相信"。通过选择性注意力掩码干预，无需训练即可提高模型准确性。


<details>
  <summary>Details</summary>
Motivation: 系统研究视觉语言模型失败的原因：是未能感知视觉证据还是未能有效利用证据。

Method: 通过层间注意力动态分析，发现浅层主要关注文本，深层稀疏但可靠地关注局部证据区域。引入基于选择性注意力掩码的推理时干预方法。

Result: 干预方法在LLaVA、Qwen、Gemma和InternVL等多个VLM家族中一致提高准确性，证明模型内部编码了可靠证据但未充分利用。

Conclusion: VLMs内部编码可靠证据但利用不足，使这些信号显式化可以弥合感知与推理之间的差距，推进VLM的诊断理解和可靠性。

Abstract: Vision-Language Models (VLMs) achieve strong results on multimodal tasks such
as visual question answering, yet they can still fail even when the correct
visual evidence is present. In this work, we systematically investigate whether
these failures arise from not perceiving the evidence or from not leveraging it
effectively. By examining layer-wise attention dynamics, we find that shallow
layers focus primarily on text, while deeper layers sparsely but reliably
attend to localized evidence regions. Surprisingly, VLMs often perceive the
visual evidence when outputting incorrect answers, a phenomenon we term
``seeing but not believing'' that widely exists in major VLM families. Building
on this, we introduce an inference-time intervention that highlights deep-layer
evidence regions through selective attention-based masking. It requires no
training and consistently improves accuracy across multiple families, including
LLaVA, Qwen, Gemma, and InternVL. These results show that VLMs encode reliable
evidence internally but under-utilize it, making such signals explicit can
bridge the gap between perception and reasoning, advancing the diagnostic
understanding and reliability of VLMs.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [90] [A Bayesian Framework for Symmetry Inference in Chaotic Attractors](https://arxiv.org/abs/2510.16509)
*Ziad Ghanem,Chang Hyunwoong,Preskella Mrad*

Main category: stat.ML

TL;DR: 本文提出了一个贝叶斯框架用于从动态系统数据中检测对称性，通过将对称性检测建模为在候选子群格上的概率模型选择，使用基于Wasserstein距离的Gibbs后验分布，解决了传统方法缺乏不确定性量化和对噪声敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 动态系统数据中的对称性检测是信号分析的基本问题，能够揭示底层结构和约束。现有最优传输方法依赖确定性阈值且缺乏不确定性量化，限制了其对噪声的鲁棒性和分层对称结构的解析能力。

Method: 提出贝叶斯框架，将对称性检测表述为在候选子群格上的概率模型选择，使用基于Wasserstein距离的Gibbs后验分布，并通过Metropolis-Hastings采样进行后验推断。

Result: 数值实验表明，该方法在高噪声和小样本情况下能够准确恢复对称性。在人步态动力学应用中揭示了机械约束引起的对称性变化。

Conclusion: 该框架为生物力学和动态系统中的统计推断提供了实用工具，具有理论保证和实际应用价值。

Abstract: Detecting symmetry from data is a fundamental problem in signal analysis,
providing insight into underlying structure and constraints. When data emerge
as trajectories of dynamical systems, symmetries encode structural properties
of the dynamics that enable model reduction, principled comparison across
conditions, and detection of regime changes. While recent optimal transport
methods provide practical tools for data-driven symmetry detection in this
setting, they rely on deterministic thresholds and lack uncertainty
quantification, limiting robustness to noise and ability to resolve
hierarchical symmetry structures. We present a Bayesian framework that
formulates symmetry detection as probabilistic model selection over a lattice
of candidate subgroups, using a Gibbs posterior constructed from Wasserstein
distances between observed data and group-transformed copies. We establish
three theoretical guarantees: $(i)$ a Bayesian Occam's razor favoring minimal
symmetry consistent with data, $(ii)$ conjugation equivariance ensuring
frame-independence, and $(iii)$ stability bounds under perturbations for
robustness to noise. Posterior inference is performed via Metropolis-Hastings
sampling and numerical experiments on equivariant dynamical systems and
synthetic point clouds demonstrate accurate symmetry recovery under high noise
and small sample sizes. An application to human gait dynamics reveals symmetry
changes induced by mechanical constraints, demonstrating the framework's
utility for statistical inference in biomechanical and dynamical systems.

</details>


### [91] [From Reviews to Actionable Insights: An LLM-Based Approach for Attribute and Feature Extraction](https://arxiv.org/abs/2510.16551)
*Khaled Boughanmi,Kamel Jedidi,Nour Jedidi*

Main category: stat.ML

TL;DR: 本研究提出了一种基于大语言模型的系统方法，用于从客户评论中提取产品和服务属性、特征及相关情感。该方法基于营销理论，区分感知属性和可操作特征，生成可解释且具有管理指导意义的见解。


<details>
  <summary>Details</summary>
Motivation: 传统人工编码客户评论耗时耗力，难以大规模处理。研究旨在开发一种自动化方法，能够高效提取客户评论中的关键信息，为企业提供可操作的管理洞察。

Method: 采用大语言模型方法，设计了8种提示变体，应用于20,000条Yelp星巴克评论。通过人工标注一致性和客户评分预测有效性来评估模型性能。

Result: 结果显示LLM与人工编码者具有高度一致性，且预测有效性很强。LLM处理每条评论仅需2秒，而人工编码中位时间为6分钟，实现了人工无法达到的大规模分析。

Conclusion: 该方法能够可靠地识别影响客户满意度的关键属性和特征，帮助企业定位"愉悦点"、解决"痛点"，并设计针对性干预措施。模拟表明优化关键服务特征情感可获得1-2%的单店平均收入增长。

Abstract: This research proposes a systematic, large language model (LLM) approach for
extracting product and service attributes, features, and associated sentiments
from customer reviews. Grounded in marketing theory, the framework
distinguishes perceptual attributes from actionable features, producing
interpretable and managerially actionable insights. We apply the methodology to
20,000 Yelp reviews of Starbucks stores and evaluate eight prompt variants on a
random subset of reviews. Model performance is assessed through agreement with
human annotations and predictive validity for customer ratings. Results show
high consistency between LLMs and human coders and strong predictive validity,
confirming the reliability of the approach. Human coders required a median of
six minutes per review, whereas the LLM processed each in two seconds,
delivering comparable insights at a scale unattainable through manual coding.
Managerially, the analysis identifies attributes and features that most
strongly influence customer satisfaction and their associated sentiments,
enabling firms to pinpoint "joy points," address "pain points," and design
targeted interventions. We demonstrate how structured review data can power an
actionable marketing dashboard that tracks sentiment over time and across
stores, benchmarks performance, and highlights high-leverage features for
improvement. Simulations indicate that enhancing sentiment for key service
features could yield 1-2% average revenue gains per store.

</details>


### [92] [Local regression on path spaces with signature metrics](https://arxiv.org/abs/2510.16728)
*Christian Bayer,Davit Gogolashvili,Luca Pelizzari*

Main category: stat.ML

TL;DR: 该论文提出了一种结合签名变换和局部核回归的函数型Nadaraya-Watson估计器，用于路径值数据的非参数回归和分类。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理路径值数据时面临无限维空间中的计算和统计挑战，需要一种能够有效编码序列数据并实现高效计算的方法。

Method: 将粗糙路径理论中的签名变换与局部核回归相结合，利用签名诱导的距离在经典核回归框架中进行计算，避免大规模核矩阵操作的可扩展性瓶颈。

Result: 建立了有限样本收敛界，证明基于签名的距离在无限维设置中相比传统度量具有更优的统计特性，并在合成和真实数据应用中展现出竞争性精度和显著计算优势。

Conclusion: 签名变换为路径值数据的非参数回归和分类提供了一种原则性的方法，在保持统计性能的同时实现了计算效率的提升。

Abstract: We study nonparametric regression and classification for path-valued data. We
introduce a functional Nadaraya-Watson estimator that combines the signature
transform from rough path theory with local kernel regression. The signature
transform provides a principled way to encode sequential data through iterated
integrals, enabling direct comparison of paths in a natural metric space. Our
approach leverages signature-induced distances within the classical kernel
regression framework, achieving computational efficiency while avoiding the
scalability bottlenecks of large-scale kernel matrix operations. We establish
finite-sample convergence bounds demonstrating favorable statistical properties
of signature-based distances compared to traditional metrics in
infinite-dimensional settings. We propose robust signature variants that
provide stability against outliers, enhancing practical performance.
Applications to both synthetic and real-world data - including stochastic
differential equation learning and time series classification - demonstrate
competitive accuracy while offering significant computational advantages over
existing methods.

</details>


### [93] [Kernel-Based Nonparametric Tests For Shape Constraints](https://arxiv.org/abs/2510.16745)
*Rohan Sen*

Main category: stat.ML

TL;DR: 本文开发了一个再生核希尔伯特空间框架，用于非参数均值-方差优化和最优规则形状约束的推断。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够处理非参数均值-方差优化问题的理论框架，并提供对最优规则形状约束的统计推断方法。

Method: 使用再生核希尔伯特空间框架，推导样本估计量的统计性质，包括渐近一致性、泛函中心极限定理和有限样本偏差界。基于这些结果，引入联合Wald型统计量来测试有限网格上的形状约束，并采用基于主元Cholesky分解的高效计算程序。

Result: 获得了严格的理論保证，包括渐近一致性、泛函中心极限定理和与蒙特卡罗率匹配的有限样本偏差界。经验测试表明所提方法表现良好。

Conclusion: 提出的RKHS框架为形状约束下的非参数均值-方差优化提供了有效的统计推断工具，具有良好的理论性质和计算效率。

Abstract: We develop a reproducing kernel Hilbert space (RKHS) framework for
nonparametric mean-variance optimization and inference on shape constraints of
the optimal rule. We derive statistical properties of the sample estimator and
provide rigorous theoretical guarantees, such as asymptotic consistency, a
functional central limit theorem, and a finite-sample deviation bound that
matches the Monte Carlo rate up to regularization. Building on these findings,
we introduce a joint Wald-type statistic to test for shape constraints over
finite grids. The approach comes with an efficient computational procedure
based on a pivoted Cholesky factorization, facilitating scalability to large
datasets. Empirical tests suggest favorably of the proposed methodology.

</details>


### [94] [Prediction-Augmented Trees for Reliable Statistical Inference](https://arxiv.org/abs/2510.16937)
*Vikram Kher,Argyris Oikonomou,Manolis Zampetakis*

Main category: stat.ML

TL;DR: 本文提出了两种新的机器学习增强估计器PART和PAQ，用于在统计分析中安全使用ML预测。这些估计器结合了少量黄金标准标记样本和大量未标记样本，相比现有方法在多个领域的数据集上表现更优，并能构建有效的置信区间。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在预测任务中的成功，科学家们开始将ML预测作为科学发现流程的核心组成部分。本文旨在研究如何在统计数据分析中安全地使用ML预测，特别是在只有少量黄金标准标记样本和大量未标记样本的情况下。

Method: 提出了两种新的学习增强估计器：1）基于决策树的PART估计器，使用贪心准则构建；2）PAQ估计器，当PART树的深度趋于无穷时的极限情况。两种方法都结合了黄金标准样本和ML预测。

Result: PART在生态学、天文学和人口普查等多个领域的真实数据集上优于现有的PPI和PPI++方法。PAQ的方差收缩率为O(N^{-1} + n^{-4})，显著优于现有方法的O(N^{-1}+n^{-1})速率。

Conclusion: 提出的PART和PAQ估计器能够有效利用ML预测和黄金标准样本，提供更高置信度的估计结果，在科学发现中安全使用ML预测方面具有显著优势。

Abstract: The remarkable success of machine learning (ML) in predictive tasks has led
scientists to incorporate ML predictions as a core component of the scientific
discovery pipeline. This was exemplified by the landmark achievement of
AlphaFold (Jumper et al. (2021)). In this paper, we study how ML predictions
can be safely used in statistical analysis of data towards scientific
discovery. In particular, we follow the framework introduced by Angelopoulos et
al. (2023). In this framework, we assume access to a small set of $n$
gold-standard labeled samples, a much larger set of $N$ unlabeled samples, and
a ML model that can be used to impute the labels of the unlabeled data points.
We introduce two new learning-augmented estimators: (1) Prediction-Augmented
Residual Tree (PART), and (2) Prediction-Augmented Quadrature (PAQ). Both
estimators have significant advantages over existing estimators like PPI and
PPI++ introduced by Angelopoulos et al. (2023) and Angelopoulos et al. (2024),
respectively. PART is a decision-tree based estimator built using a greedy
criterion. We first characterize PART's asymptotic distribution and demonstrate
how to construct valid confidence intervals. Then we show that PART outperforms
existing methods in real-world datasets from ecology, astronomy, and census
reports, among other domains. This leads to estimators with higher confidence,
which is the result of using both the gold-standard samples and the machine
learning predictions. Finally, we provide a formal proof of the advantage of
PART by exploring PAQ, an estimation that arises when considering the limit of
PART when the depth its tree grows to infinity. Under appropriate assumptions
in the input data we show that the variance of PAQ shrinks at rate of $O(N^{-1}
+ n^{-4})$, improving significantly on the $O(N^{-1}+n^{-1})$ rate of existing
methods.

</details>


### [95] [Adaptive Sample Sharing for Linear Regression](https://arxiv.org/abs/2510.16986)
*Hamza Cherkaoui,Hélène Halconruy,Yohan Petetin*

Main category: stat.ML

TL;DR: 本文提出了一种基于岭回归的样本共享方法，通过数据驱动规则决定从辅助数据集中借用多少样本，以防止负迁移并提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 在商业环境中，特定任务的标记数据稀缺且获取成本高，这限制了监督学习的应用。为了应对这一挑战，研究如何在岭回归中安全地利用辅助数据集，同时明确防止负迁移。

Method: 引入基于转移增益估计的原则性数据驱动规则，该规则估计预测误差的边际减少量，并据此决定从辅助数据集中添加多少样本到目标训练集。在高斯特征设置下分析确保借用样本减少预测误差的数据集属性。

Result: 在合成和真实数据集上的验证表明，该方法相比强基线和单任务训练获得了一致的性能提升，同时成功避免了负迁移。

Conclusion: 提出的方法能够在改善参数估计时借用样本，否则保持克制，在标准条件下提供有限样本保证，有效解决了样本稀缺环境下的迁移学习问题。

Abstract: In many business settings, task-specific labeled data are scarce or costly to
obtain, which limits supervised learning on a specific task. To address this
challenge, we study sample sharing in the case of ridge regression: leveraging
an auxiliary data set while explicitly protecting against negative transfer. We
introduce a principled, data-driven rule that decides how many samples from an
auxiliary dataset to add to the target training set. The rule is based on an
estimate of the transfer gain i.e. the marginal reduction in the predictive
error. Building on this estimator, we derive finite-sample guaranties: under
standard conditions, the procedure borrows when it improves parameter
estimation and abstains otherwise. In the Gaussian feature setting, we analyze
which data set properties ensure that borrowing samples reduces the predictive
error. We validate the approach in synthetic and real datasets, observing
consistent gains over strong baselines and single-task training while avoiding
negative transfer.

</details>


### [96] [Mode Collapse of Mean-Field Variational Inference](https://arxiv.org/abs/2510.17063)
*Shunan Sheng,Bohan Wu,Alberto González-Sanz*

Main category: stat.ML

TL;DR: 该论文首次从理论上解释了平均场变分推断(MFVI)中的模式坍塌现象，并提出了旋转变分推断(RoVI)方法来解决该问题。


<details>
  <summary>Details</summary>
Motivation: MFVI在逼近高维概率分布时经常出现模式坍塌问题，即当目标分布是混合分布时，MFVI优化器倾向于将大部分质量集中在单个混合分量上。目前缺乏对这一现象的理论解释。

Method: 引入ε-分离度的概念来量化两个混合分量的分离程度，推导出当P₀和P₁充分ε-分离时，任何MFVI优化器分配给每个分量的质量比例的显式界限。为解决模式坍塌问题，提出了旋转变分推断(RoVI)，在MFVI基础上增加旋转矩阵。

Result: 理论分析表明模式坍塌的发生关键取决于混合分量的相对位置。数值研究支持了理论发现，并证明了RoVI方法的优势。

Conclusion: 该工作首次为MFVI中的模式坍塌现象提供了理论解释，并提出了有效的解决方案RoVI，通过旋转操作改善了变分推断在混合分布上的表现。

Abstract: Mean-field variational inference (MFVI) is a widely used method for
approximating high-dimensional probability distributions by product measures.
It has been empirically observed that MFVI optimizers often suffer from mode
collapse. Specifically, when the target measure $\pi$ is a mixture $\pi = w P_0
+ (1 - w) P_1$, the MFVI optimizer tends to place most of its mass near a
single component of the mixture. This work provides the first theoretical
explanation of mode collapse in MFVI. We introduce the notion to capture the
separatedness of the two mixture components -- called
$\varepsilon$-separateness -- and derive explicit bounds on the fraction of
mass that any MFVI optimizer assigns to each component when $P_0$ and $P_1$ are
$\varepsilon$-separated for sufficiently small $\varepsilon$. Our results
suggest that the occurrence of mode collapse crucially depends on the relative
position of the components. To address this issue, we propose the rotational
variational inference (RoVI), which augments MFVI with a rotation matrix. The
numerical studies support our theoretical findings and demonstrate the benefits
of RoVI.

</details>


### [97] [Optimal Best Arm Identification under Differential Privacy](https://arxiv.org/abs/2510.17348)
*Marc Jourdan,Achraf Azize*

Main category: stat.ML

TL;DR: 本文研究了在全局差分隐私（DP）约束下的固定置信度最佳臂识别（BAI）问题，针对伯努利分布。通过引入新的信息论量来优化KL散度和总变差距离之间的权衡，提出了匹配下界到常数倍内的上界算法。


<details>
  <summary>Details</summary>
Motivation: BAI算法应用于数据敏感场景（如自适应临床试验），存在隐私担忧。现有全局DP设置下的BAI算法在样本复杂度上下界之间存在显著差距，需要缩小这一差距。

Method: 1) 提供更紧的下界，用新的信息论量替换KL散度；2) 基于运输成本的停止规则和臂依赖几何批处理的私有均值估计器；3) 基于运输成本的Top Two采样规则。

Result: 对于任意隐私预算ε，提出的算法在期望样本复杂度上实现了与下界匹配的渐近上界，乘性常数小于8，优于现有算法。

Conclusion: 本文显著缩小了全局DP设置下BAI问题的样本复杂度上下界差距，为数据敏感应用中的隐私保护BAI提供了高效解决方案。

Abstract: Best Arm Identification (BAI) algorithms are deployed in data-sensitive
applications, such as adaptive clinical trials or user studies. Driven by the
privacy concerns of these applications, we study the problem of
fixed-confidence BAI under global Differential Privacy (DP) for Bernoulli
distributions. While numerous asymptotically optimal BAI algorithms exist in
the non-private setting, a significant gap remains between the best lower and
upper bounds in the global DP setting. This work reduces this gap to a small
multiplicative constant, for any privacy budget $\epsilon$. First, we provide a
tighter lower bound on the expected sample complexity of any $\delta$-correct
and $\epsilon$-global DP strategy. Our lower bound replaces the
Kullback-Leibler (KL) divergence in the transportation cost used by the
non-private characteristic time with a new information-theoretic quantity that
optimally trades off between the KL divergence and the Total Variation distance
scaled by $\epsilon$. Second, we introduce a stopping rule based on these
transportation costs and a private estimator of the means computed using an
arm-dependent geometric batching. En route to proving the correctness of our
stopping rule, we derive concentration results of independent interest for the
Laplace distribution and for the sum of Bernoulli and Laplace distributions.
Third, we propose a Top Two sampling rule based on these transportation costs.
For any budget $\epsilon$, we show an asymptotic upper bound on its expected
sample complexity that matches our lower bound to a multiplicative constant
smaller than $8$. Our algorithm outperforms existing $\delta$-correct and
$\epsilon$-global DP BAI algorithms for different values of $\epsilon$.

</details>


### [98] [Certified Self-Consistency: Statistical Guarantees and Test-Time Training for Reliable Reasoning in LLMs](https://arxiv.org/abs/2510.17472)
*Paula Cordero-Encinar,Andrew B. Duncan*

Main category: stat.ML

TL;DR: 本文提出了一个统一框架来证明LLMs中自一致性和测试时强化学习的统计保证，通过多数投票提供统计证书，并引入自适应停止规则MMC来减少认证所需样本数。


<details>
  <summary>Details</summary>
Motivation: 当前自一致性和测试时强化学习等方法虽然能提高LLM可靠性，但其内在机制和统计保证仍缺乏深入理解，需要建立统一的统计框架来解释这些方法。

Method: 使用多数投票提供自一致性的统计证书，推导有限样本和任意时间有效的集中界限，引入MMC序列停止规则，并提出新的后训练目标来优化锐度与偏差的权衡。

Result: 证明了多数投票聚合答案以高概率与模型终端分布的众数一致，TTRL通过指数倾斜使答案分布向众数集中，从而减少认证所需样本数。

Conclusion: 该研究在单一统计框架内解释了自一致性和TTRL这两种核心测试时扩展策略，为无标签、可证明可靠的推理LLMs提供了理论基础。

Abstract: Recent advances such as self-consistency and test-time reinforcement learning
(TTRL) improve the reliability of large language models (LLMs) without
additional supervision, yet their underlying mechanisms and statistical
guarantees remain poorly understood. We present a unified framework for
certifiable inference in LLMs, showing that majority voting provides a
statistical certificate of self-consistency: under mild assumptions, the
aggregated answer coincides with the mode of the model's terminal distribution
with high probability. We derive finite-sample and anytime-valid concentration
bounds that quantify this confidence, and introduce the Martingale Majority
Certificate (MMC), a sequential stopping rule that adaptively determines when
sufficient samples have been drawn. We further prove that label-free
post-training methods such as TTRL implicitly sharpen the answer distribution
by exponentially tilting it toward its mode, thereby reducing the number of
samples required for certification. Building on this insight, we propose new
post-training objectives that explicitly optimise this trade-off between
sharpness and bias. Together, these results explain and connect two central
test-time scaling strategies, self-consistency and TTRL, within a single
statistical framework for label-free, certifiable reliability in reasoning
LLMs.

</details>
