<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 10]
- [cs.LG](#cs.LG) [Total: 22]
- [eess.SP](#eess.SP) [Total: 3]
- [stat.ML](#stat.ML) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [The Second Law of Intelligence: Controlling Ethical Entropy in Autonomous Systems](https://arxiv.org/abs/2511.10704)
*Samih Fadli*

Main category: cs.AI

TL;DR: 本文提出了人工智能伦理熵的第二定律，证明无约束AI会自发偏离目标，需要持续的对齐工作来维持稳定性。


<details>
  <summary>Details</summary>
Motivation: 为了解决AI系统在无约束条件下自发偏离预期目标的问题，作者希望建立一个类似热力学第二定律的理论框架来量化AI对齐问题。

Method: 定义了基于目标概率分布的伦理熵S = -Σ p(g_i; theta) ln p(g_i; theta)，证明了熵随时间增加，并推导了对齐工作的临界稳定性边界gamma_crit = (lambda_max / 2) ln N。通过模拟实验验证理论。

Result: 70亿参数模型从初始熵0.32漂移到1.69±1.08纳特，而使用对齐工作gamma=20.4的系统保持稳定在0.00±0.00纳特(p=4.19×10^-17)。

Conclusion: 该框架将AI对齐重新定义为连续热力学控制问题，为维护高级自主系统的稳定性和安全性提供了量化基础。

Abstract: We propose that unconstrained artificial intelligence obeys a Second Law analogous to thermodynamics, where ethical entropy, defined as a measure of divergence from intended goals, increases spontaneously without continuous alignment work. For gradient-based optimizers, we define this entropy over a finite set of goals {g_i} as S = -Σ p(g_i; theta) ln p(g_i; theta), and we prove that its time derivative dS/dt >= 0, driven by exploration noise and specification gaming. We derive the critical stability boundary for alignment work as gamma_crit = (lambda_max / 2) ln N, where lambda_max is the dominant eigenvalue of the Fisher Information Matrix and N is the number of model parameters. Simulations validate this theory. A 7-billion-parameter model (N = 7 x 10^9) with lambda_max = 1.2 drifts from an initial entropy of 0.32 to 1.69 +/- 1.08 nats, while a system regularized with alignment work gamma = 20.4 (1.5 gamma_crit) maintains stability at 0.00 +/- 0.00 nats (p = 4.19 x 10^-17, n = 20 trials). This framework recasts AI alignment as a problem of continuous thermodynamic control, providing a quantitative foundation for maintaining the stability and safety of advanced autonomous systems.

</details>


### [2] [Picking a Representative Set of Solutions in Multiobjective Optimization: Axioms, Algorithms, and Experiments](https://arxiv.org/abs/2511.10716)
*Niclas Boehmer,Maximilian T. Wittmann*

Main category: cs.AI

TL;DR: 本文研究多目标决策中的帕累托剪枝问题，通过将问题重新定义为多赢家投票问题，分析现有质量度量方法的不足，提出新的定向覆盖度量方法，并分析计算复杂性边界。


<details>
  <summary>Details</summary>
Motivation: 多目标决策问题中，帕累托最优解数量庞大，决策者难以选择。需要开发有效的剪枝方法，从帕累托最优解集中选择固定大小的代表性子集，以减轻决策者的认知负担。

Method: 将帕累托剪枝问题重新定义为多赢家投票问题；进行公理分析揭示现有质量度量的非直观行为；提出新的定向覆盖度量方法；分析各种质量度量优化的计算复杂性；进行实验评估。

Result: 发现现有质量度量存在非直观行为；提出新的定向覆盖度量方法；识别了目标数量和结构影响下的计算复杂性边界；实验表明质量度量选择对所选解集特征有决定性影响，新度量在多种设置下表现竞争性或更优。

Conclusion: 帕累托剪枝的质量度量选择至关重要，新提出的定向覆盖度量方法在多个场景下表现优异，为多目标决策提供了更有效的代表性解集选择工具。

Abstract: Many real-world decision-making problems involve optimizing multiple objectives simultaneously, rendering the selection of the most preferred solution a non-trivial problem: All Pareto optimal solutions are viable candidates, and it is typically up to a decision maker to select one for implementation based on their subjective preferences. To reduce the cognitive load on the decision maker, previous work has introduced the Pareto pruning problem, where the goal is to compute a fixed-size subset of Pareto optimal solutions that best represent the full set, as evaluated by a given quality measure. Reframing Pareto pruning as a multiwinner voting problem, we conduct an axiomatic analysis of existing quality measures, uncovering several unintuitive behaviors. Motivated by these findings, we introduce a new measure, directed coverage. We also analyze the computational complexity of optimizing various quality measures, identifying previously unknown boundaries between tractable and intractable cases depending on the number and structure of the objectives. Finally, we present an experimental evaluation, demonstrating that the choice of quality measure has a decisive impact on the characteristics of the selected set of solutions and that our proposed measure performs competitively or even favorably across a range of settings.

</details>


### [3] [Potential Outcome Rankings for Counterfactual Decision Making](https://arxiv.org/abs/2511.10776)
*Yuta Kawakami,Jin Tian*

Main category: cs.AI

TL;DR: 本文研究了基于潜在结果排序概率和获得最佳结果概率的反事实决策新规则，建立了识别定理和边界估计方法，并通过实验验证了估计器的性能。


<details>
  <summary>Details</summary>
Motivation: 在不确定性下进行反事实决策时，决策者通常通过比较候选行动的期望潜在结果来做出选择。本文旨在引入新的决策指标来改进这一过程。

Method: 提出了两个新指标：潜在结果排序概率和获得最佳结果概率，建立了识别定理和边界估计方法，并开发了相应的估计算法。

Result: 通过数值实验验证了估计器的有限样本性质，并在真实数据集上展示了这些指标的应用效果。

Conclusion: 提出的新决策规则为反事实决策提供了更有效的工具，能够更好地识别最可能产生最佳结果的行动。

Abstract: Counterfactual decision-making in the face of uncertainty involves selecting the optimal action from several alternatives using causal reasoning. Decision-makers often rank expected potential outcomes (or their corresponding utility and desirability) to compare the preferences of candidate actions. In this paper, we study new counterfactual decision-making rules by introducing two new metrics: the probabilities of potential outcome ranking (PoR) and the probability of achieving the best potential outcome (PoB). PoR reveals the most probable ranking of potential outcomes for an individual, and PoB indicates the action most likely to yield the top-ranked outcome for an individual. We then establish identification theorems and derive bounds for these metrics, and present estimation methods. Finally, we perform numerical experiments to illustrate the finite-sample properties of the estimators and demonstrate their application to a real-world dataset.

</details>


### [4] [HyperComplEx: Adaptive Multi-Space Knowledge Graph Embeddings](https://arxiv.org/abs/2511.10842)
*Jugal Gajjar,Kaustik Ranaware,Kamalasankari Subramaniakuppusamy,Vaibhav Gandhi*

Main category: cs.AI

TL;DR: 提出了HyperComplEx混合嵌入框架，通过注意力机制自适应结合双曲、复数和欧几里得空间，解决了现有知识图谱嵌入方法在处理多样化关系类型时的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱嵌入方法在处理大规模多样化关系类型时存在关键限制：欧几里得模型难以处理层次结构，向量空间模型无法捕捉不对称性，双曲模型在对称关系上表现不佳。

Method: 提出关系特定的空间加权策略，通过学习注意力机制为每种关系类型动态选择最优几何空间，同时使用多空间一致性损失确保跨空间预测的一致性。

Result: 在从1K论文到10M论文的知识图谱上评估，相比TransE、RotatE、DistMult等基线方法持续改进。在10M论文数据集上达到0.612 MRR，相对最佳基线提升4.8%，同时保持高效训练和85ms的推理时间。

Conclusion: HyperComplEx通过自适应维度分配实现近线性扩展，为可扩展知识图谱嵌入研究提供了有效解决方案。

Abstract: Knowledge graphs have emerged as fundamental structures for representing complex relational data across scientific and enterprise domains. However, existing embedding methods face critical limitations when modeling diverse relationship types at scale: Euclidean models struggle with hierarchies, vector space models cannot capture asymmetry, and hyperbolic models fail on symmetric relations. We propose HyperComplEx, a hybrid embedding framework that adaptively combines hyperbolic, complex, and Euclidean spaces via learned attention mechanisms. A relation-specific space weighting strategy dynamically selects optimal geometries for each relation type, while a multi-space consistency loss ensures coherent predictions across spaces. We evaluate HyperComplEx on computer science research knowledge graphs ranging from 1K papers (~25K triples) to 10M papers (~45M triples), demonstrating consistent improvements over state-of-the-art baselines including TransE, RotatE, DistMult, ComplEx, SEPA, and UltraE. Additional tests on standard benchmarks confirm significantly higher results than all baselines. On the 10M-paper dataset, HyperComplEx achieves 0.612 MRR, a 4.8% relative gain over the best baseline, while maintaining efficient training, achieving 85 ms inference per triple. The model scales near-linearly with graph size through adaptive dimension allocation. We release our implementation and dataset family to facilitate reproducible research in scalable knowledge graph embeddings.

</details>


### [5] [Faster Symmetry Breaking Constraints for Abstract Structures](https://arxiv.org/abs/2511.11029)
*Özgür Akgün,Mun See Chang,Ian P. Gent,Christopher Jefferson*

Main category: cs.AI

TL;DR: 提出了一种新的不完全方法，通过更好地利用抽象结构的表示来打破对称性，特别针对不可区分对象产生的对称性，相比现有方法具有更快的性能。


<details>
  <summary>Details</summary>
Motivation: 在约束编程中，使用高级建模语言（如Essence）时，抽象结构需要转换为求解器支持的表示形式。对称性破坏技术可以显著加速求解过程，但应用于抽象变量时会产生大量复杂约束，性能较差。

Method: 开发了一种新的不完全对称性破坏方法，通过更好地利用抽象结构的表示来打破对称性，特别针对不可区分对象产生的对称性。

Result: 该方法在打破不可区分对象对称性方面比(Akgün et al. 2025)中提出的先前方法更快。

Conclusion: 新方法通过优化抽象结构的表示利用，有效解决了对称性破坏中的性能问题，为约束编程中的对称性处理提供了更高效的解决方案。

Abstract: In constraint programming and related paradigms, a modeller specifies their problem in a modelling language for a solver to search and return its solution(s). Using high-level modelling languages such as Essence, a modeller may express their problems in terms of abstract structures. These are structures not natively supported by the solvers, and so they have to be transformed into or represented as other structures before solving. For example, nested sets are abstract structures, and they can be represented as matrices in constraint solvers. Many problems contain symmetries and one very common and highly successful technique used in constraint programming is to "break" symmetries, to avoid searching for symmetric solutions. This can speed up the solving process by many orders of magnitude. Most of these symmetry-breaking techniques involve placing some kind of ordering for the variables of the problem, and picking a particular member under the symmetries, usually the smallest. Unfortunately, applying this technique to abstract variables produces a very large number of complex constraints that perform poorly in practice. In this paper, we demonstrate a new incomplete method of breaking the symmetries of abstract structures by better exploiting their representations. We apply the method in breaking the symmetries arising from indistinguishable objects, a commonly occurring type of symmetry, and show that our method is faster than the previous methods proposed in (Akgün et al. 2025).

</details>


### [6] [Key Decision-Makers in Multi-Agent Debates: Who Holds the Power?](https://arxiv.org/abs/2511.11040)
*Qian Zhang,Yan Zheng,Jinyi Liu,Hebin Liang,Lanjun Wang*

Main category: cs.AI

TL;DR: 研究发现多智能体辩论中的角色分配策略对推理性能有显著影响，提出"真理最后"策略可提升22%性能，并开发了MADC策略来优化多智能体辩论机制。


<details>
  <summary>Details</summary>
Motivation: 现有研究未充分探索多智能体辩论中的角色分配策略，而角色分配对推理能力提升至关重要。

Method: 提出"真理最后"角色分配策略和MADC策略，通过路径一致性评估独立角色间的一致性，模拟最高一致性得分的角色作为真理。

Result: 在9个LLM模型上的验证显示，MADC策略能持续展现先进性能，有效克服多智能体辩论的性能瓶颈。

Conclusion: MADC策略为LLM智能体扩展提供了关键改进路径，显著提升多智能体辩论在推理任务中的表现。

Abstract: Recent studies on LLM agent scaling have highlighted the potential of Multi-Agent Debate (MAD) to enhance reasoning abilities. However, the critical aspect of role allocation strategies remains underexplored. In this study, we demonstrate that allocating roles with differing viewpoints to specific positions significantly impacts MAD's performance in reasoning tasks. Specifically, we find a novel role allocation strategy, "Truth Last", which can improve MAD performance by up to 22% in reasoning tasks. To address the issue of unknown truth in practical applications, we propose the Multi-Agent Debate Consistency (MADC) strategy, which systematically simulates and optimizes its core mechanisms. MADC incorporates path consistency to assess agreement among independent roles, simulating the role with the highest consistency score as the truth. We validated MADC across a range of LLMs (9 models), including the DeepSeek-R1 Distilled Models, on challenging reasoning tasks. MADC consistently demonstrated advanced performance, effectively overcoming MAD's performance bottlenecks and providing a crucial pathway for further improvements in LLM agent scaling.

</details>


### [7] [Autonomous Vehicle Path Planning by Searching With Differentiable Simulation](https://arxiv.org/abs/2511.11043)
*Asen Nachkov,Jan-Nico Zaech,Danda Pani Paudel,Xi Wang,Luc Van Gool*

Main category: cs.AI

TL;DR: 提出了DSS框架，利用可微分模拟器Waymax作为状态预测器和评估器，通过梯度下降优化动作序列，显著提升了自动驾驶的跟踪和路径规划精度。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶中，规划对于避免碰撞和在复杂密集交通场景中导航至关重要。传统方法在学习策略、状态预测器和评估器时面临挑战。

Method: 使用可微分模拟器Waymax作为状态预测器和评估器，利用其硬编码动力学实现准确状态预测，通过可微分性在动作序列上进行有效搜索，使用梯度下降优化想象未来轨迹中的动作。

Result: 实验表明，DSS（规划梯度和随机搜索的组合）相比序列预测、模仿学习、无模型RL和其他规划方法，显著提高了跟踪和路径规划的准确性。

Conclusion: DSS框架通过结合规划梯度和随机搜索，在自动驾驶规划任务中表现出优越性能，为安全动作优化提供了有效解决方案。

Abstract: Planning allows an agent to safely refine its actions before executing them in the real world. In autonomous driving, this is crucial to avoid collisions and navigate in complex, dense traffic scenarios. One way to plan is to search for the best action sequence. However, this is challenging when all necessary components - policy, next-state predictor, and critic - have to be learned. Here we propose Differentiable Simulation for Search (DSS), a framework that leverages the differentiable simulator Waymax as both a next state predictor and a critic. It relies on the simulator's hardcoded dynamics, making state predictions highly accurate, while utilizing the simulator's differentiability to effectively search across action sequences. Our DSS agent optimizes its actions using gradient descent over imagined future trajectories. We show experimentally that DSS - the combination of planning gradients and stochastic search - significantly improves tracking and path planning accuracy compared to sequence prediction, imitation learning, model-free RL, and other planning methods.

</details>


### [8] [EcoAlign: An Economically Rational Framework for Efficient LVLM Alignment](https://arxiv.org/abs/2511.11301)
*Ruoxi Cheng,Haoxuan Ma,Teng Ma,Hongyi Zhang*

Main category: cs.AI

TL;DR: EcoAlign是一个推理时对齐框架，将大型视觉语言模型视为有限理性智能体，通过前瞻性函数动态权衡安全性、实用性和成本，在降低计算成本的同时实现强大的安全对齐。


<details>
  <summary>Details</summary>
Motivation: 当前大型视觉语言模型对齐方法在安全性、实用性和运营成本之间存在权衡困难，且仅关注最终输出的过程盲目性会浪费大量计算资源在不安全的推理上，允许有害推理通过良性理由伪装绕过安全检测。

Method: 提出EcoAlign框架，将对齐重构为经济理性搜索，逐步扩展思维图并使用前瞻性函数（类似净现值）对行动评分，动态权衡预期安全性、实用性和成本与剩余预算，通过最薄弱环节原则强制执行路径安全。

Result: 在3个闭源和2个开源模型、6个数据集上的广泛实验表明，EcoAlign以较低计算成本达到或超越最先进的安全性和实用性水平。

Conclusion: EcoAlign为强大的LVLM对齐提供了原则性、经济高效的路径，解决了安全对齐中的经济效率问题。

Abstract: Large Vision-Language Models (LVLMs) exhibit powerful reasoning capabilities but suffer sophisticated jailbreak vulnerabilities. Fundamentally, aligning LVLMs is not just a safety challenge but a problem of economic efficiency. Current alignment methods struggle with the trade-off between safety, utility, and operational costs. Critically, a focus solely on final outputs (process-blindness) wastes significant computational budget on unsafe deliberation. This flaw allows harmful reasoning to be disguised with benign justifications, thereby circumventing simple additive safety scores. To address this, we propose EcoAlign, an inference-time framework that reframes alignment as an economically rational search by treating the LVLM as a boundedly rational agent. EcoAlign incrementally expands a thought graph and scores actions using a forward-looking function (analogous to net present value) that dynamically weighs expected safety, utility, and cost against the remaining budget. To prevent deception, path safety is enforced via the weakest-link principle. Extensive experiments across 3 closed-source and 2 open-source models on 6 datasets show that EcoAlign matches or surpasses state-of-the-art safety and utility at a lower computational cost, thereby offering a principled, economical pathway to robust LVLM alignment.

</details>


### [9] [Robust and Efficient Communication in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2511.11393)
*Zejiao Liu,Yi Li,Jiali Wang,Junqi Tu,Yitian Hong,Fangfei Li,Yang Liu,Toshiharu Sugawara,Yang Tang*

Main category: cs.AI

TL;DR: 本文系统综述了多智能体强化学习（MARL）中在现实约束下的鲁棒高效通信策略，包括消息扰动、传输延迟和带宽限制等挑战，并探讨了在自动驾驶、分布式SLAM和联邦学习等应用中的具体解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有MARL方法大多假设通信是瞬时、可靠且带宽无限的，但这些条件在现实部署中很少满足，因此需要研究在现实约束下的鲁棒通信策略。

Method: 系统性地回顾了MARL中应对消息扰动、传输延迟和带宽限制等现实通信约束的最新进展，重点关注低延迟可靠性、带宽密集型数据共享和通信隐私权衡等核心挑战。

Result: 识别了在合作自动驾驶、分布式SLAM和联邦学习等三个关键应用领域中通信策略的具体实现和效果。

Conclusion: 提出了统一方法，共同设计通信、学习和鲁棒性，以弥合理论MARL模型与实际实现之间的差距，并指出了未来研究的关键开放挑战和方向。

Abstract: Multi-agent reinforcement learning (MARL) has made significant strides in enabling coordinated behaviors among autonomous agents. However, most existing approaches assume that communication is instantaneous, reliable, and has unlimited bandwidth; these conditions are rarely met in real-world deployments. This survey systematically reviews recent advances in robust and efficient communication strategies for MARL under realistic constraints, including message perturbations, transmission delays, and limited bandwidth. Furthermore, because the challenges of low-latency reliability, bandwidth-intensive data sharing, and communication-privacy trade-offs are central to practical MARL systems, we focus on three applications involving cooperative autonomous driving, distributed simultaneous localization and mapping, and federated learning. Finally, we identify key open challenges and future research directions, advocating a unified approach that co-designs communication, learning, and robustness to bridge the gap between theoretical MARL models and practical implementations.

</details>


### [10] [CURENet: Combining Unified Representations for Efficient Chronic Disease Prediction](https://arxiv.org/abs/2511.11423)
*Cong-Tinh Dao,Nguyen Minh Thao Phan,Jun-En Ding,Chenwei Wu,David Restrepo,Dongsheng Luo,Fanyi Zhao,Chun-Chieh Liao,Wen-Chih Peng,Chi-Te Wang,Pei-Fu Chen,Ling Chen,Xinglong Ju,Feng Liu,Fang-Ming Hung*

Main category: cs.AI

TL;DR: CURENet是一个多模态模型，整合了非结构化临床笔记、实验室测试和患者时间序列数据，利用LLM处理临床文本和文本实验室测试，使用Transformer编码器处理纵向序列就诊数据，在慢性疾病预测中达到超过94%的准确率。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录包含多种数据类型，但现有预测模型未能充分捕捉多模态数据之间的交互、冗余和时间模式，通常只关注单一数据类型或忽略这些复杂性。

Method: 提出CURENet模型，结合大型语言模型处理临床文本和文本实验室测试，使用Transformer编码器处理纵向序列就诊数据，整合多模态EHR数据。

Result: 在MIMIC-III和FEMH数据集上评估，在多标签框架中预测前10种慢性疾病时准确率超过94%。

Conclusion: 多模态EHR整合有潜力增强临床决策制定并改善患者结果。

Abstract: Electronic health records (EHRs) are designed to synthesize diverse data types, including unstructured clinical notes, structured lab tests, and time-series visit data. Physicians draw on these multimodal and temporal sources of EHR data to form a comprehensive view of a patient's health, which is crucial for informed therapeutic decision-making. Yet, most predictive models fail to fully capture the interactions, redundancies, and temporal patterns across multiple data modalities, often focusing on a single data type or overlooking these complexities. In this paper, we present CURENet, a multimodal model (Combining Unified Representations for Efficient chronic disease prediction) that integrates unstructured clinical notes, lab tests, and patients' time-series data by utilizing large language models (LLMs) for clinical text processing and textual lab tests, as well as transformer encoders for longitudinal sequential visits. CURENet has been capable of capturing the intricate interaction between different forms of clinical data and creating a more reliable predictive model for chronic illnesses. We evaluated CURENet using the public MIMIC-III and private FEMH datasets, where it achieved over 94\% accuracy in predicting the top 10 chronic conditions in a multi-label framework. Our findings highlight the potential of multimodal EHR integration to enhance clinical decision-making and improve patient outcomes.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [11] [Differentiable Sparse Identification of Lagrangian Dynamics](https://arxiv.org/abs/2511.10706)
*Zitong Zhang,Hao Sun*

Main category: cs.LG

TL;DR: 提出了一种新颖的可微稀疏识别框架，通过三次B样条近似、鲁棒方程发现机制和递归导数计算方案，解决了拉格朗日系统识别中的噪声敏感性和数据限制问题。


<details>
  <summary>Details</summary>
Motivation: 传统稀疏回归技术在复杂机械系统中难以处理有理函数和噪声敏感性，而现有的拉格朗日识别方法受测量噪声和数据可用性限制影响显著。

Method: 集成三次B样条近似到拉格朗日系统识别中，开发鲁棒方程发现机制结合物理约束，以及基于B样条基函数的递归导数计算方案。

Result: 该方法在复杂机械系统中表现出优越性能，能够从噪声数据中更准确可靠地提取物理规律，优于基线方法。

Conclusion: 所提出的框架有效解决了拉格朗日系统识别中的关键挑战，为从噪声数据中提取物理定律提供了更准确可靠的方法。

Abstract: Data-driven discovery of governing equations from data remains a fundamental challenge in nonlinear dynamics. Although sparse regression techniques have advanced system identification, they struggle with rational functions and noise sensitivity in complex mechanical systems. The Lagrangian formalism offers a promising alternative, as it typically avoids rational expressions and provides a more concise representation of system dynamics. However, existing Lagrangian identification methods are significantly affected by measurement noise and limited data availability. This paper presents a novel differentiable sparse identification framework that addresses these limitations through three key contributions: (1) the first integration of cubic B-Spline approximation into Lagrangian system identification, enabling accurate representation of complex nonlinearities, (2) a robust equation discovery mechanism that effectively utilizes measurements while incorporating known physical constraints, (3) a recursive derivative computation scheme based on B-spline basis functions, effectively constraining higher-order derivatives and reducing noise sensitivity on second-order dynamical systems. The proposed method demonstrates superior performance and enables more accurate and reliable extraction of physical laws from noisy data, particularly in complex mechanical systems compared to baseline methods.

</details>


### [12] [Private Zeroth-Order Optimization with Public Data](https://arxiv.org/abs/2511.10859)
*Xuchen Gong,Tian Li*

Main category: cs.LG

TL;DR: 本文提出了一种利用公共数据指导私有零阶优化算法梯度近似的方法（PAZO），在保持隐私的同时显著提高了计算效率和模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统一阶差分隐私机器学习算法（如DP-SGD）存在高计算和内存成本问题，而现有的零阶方法虽然更容易实现隐私保护，但在效用上仍不如DP-SGD，且应用领域有限。

Method: 提出PAZO框架，利用公共信息来指导和改进私有零阶算法的梯度近似，设计了一套具有最小开销的公共数据辅助零阶优化器。

Result: PAZO在视觉和文本任务中，在预训练和微调设置下都实现了优越的隐私/效用权衡，尤其在高度隐私保护机制下优于最佳的一阶基线方法，同时提供高达16倍的运行速度提升。

Conclusion: PAZO框架通过有效利用公共数据，成功解决了私有零阶优化算法的效用问题，在保持隐私保护的同时显著提升了计算效率和模型性能。

Abstract: One of the major bottlenecks for deploying popular first-order differentially private (DP) machine learning algorithms (e.g., DP-SGD) lies in their high computation and memory cost, despite the existence of optimized implementations. Zeroth-order methods have promise in mitigating the overhead, as they leverage function evaluations to approximate the gradients, hence significantly easier to privatize. While recent works have explored zeroth-order approaches in both private and non-private settings, they still suffer from relatively low utilities compared with DP-SGD, and have only been evaluated in limited application domains. In this work, we propose to leverage public information to guide and improve gradient approximation of private zeroth-order algorithms. We explore a suite of public-data-assisted zeroth-order optimizers (PAZO) with minimal overhead. We provide theoretical analyses of the PAZO framework under an assumption of the similarity between public and private data. Empirically, we demonstrate that PAZO achieves superior privacy/utility tradeoffs across vision and text tasks in both pre-training and fine-tuning settings, outperforming the best first-order baselines (with public data) especially in highly private regimes, while offering up to $16\times$ runtime speedup.

</details>


### [13] [Near-optimal Linear Predictive Clustering in Non-separable Spaces via Mixed Integer Programming and Quadratic Pseudo-Boolean Reductions](https://arxiv.org/abs/2511.10809)
*Jiazhou Liang,Hassan Khurram,Scott Sanner*

Main category: cs.LG

TL;DR: 本文提出了两种改进线性预测聚类(LPC)全局优化效率的新方法，通过利用可分性理论特性推导出具有可证明误差界的近似最优解，显著降低了MIP公式的复杂性并提高了可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有LPC方法存在局限性：贪婪优化方法缺乏全局最优性，在非可分设置中表现不佳；而MIP方法虽然能保证全局最优性但可扩展性差。需要开发既能保证近似最优性又具有良好可扩展性的新方法。

Method: 1. 基于可分性理论特性推导近最优近似方法，具有可证明误差界；2. 将LPC近似为二次伪布尔优化(QPBO)问题；3. 显著降低MIP公式复杂性。

Result: 在合成和真实数据集上的比较分析表明，所提方法始终获得近最优解，回归误差显著低于贪婪优化方法，同时相比现有MIP公式具有更好的可扩展性。

Conclusion: 本文提出的两种新方法在保持近似最优性的同时，显著提高了LPC全局优化的效率和可扩展性，为营销、医疗、教育等领域的应用提供了更实用的解决方案。

Abstract: Linear Predictive Clustering (LPC) partitions samples based on shared linear relationships between feature and target variables, with numerous applications including marketing, medicine, and education. Greedy optimization methods, commonly used for LPC, alternate between clustering and linear regression but lack global optimality. While effective for separable clusters, they struggle in non-separable settings where clusters overlap in feature space. In an alternative constrained optimization paradigm, Bertsimas and Shioda (2007) formulated LPC as a Mixed-Integer Program (MIP), ensuring global optimality regardless of separability but suffering from poor scalability. This work builds on the constrained optimization paradigm to introduce two novel approaches that improve the efficiency of global optimization for LPC. By leveraging key theoretical properties of separability, we derive near-optimal approximations with provable error bounds, significantly reducing the MIP formulation's complexity and improving scalability. Additionally, we can further approximate LPC as a Quadratic Pseudo-Boolean Optimization (QPBO) problem, achieving substantial computational improvements in some settings. Comparative analyses on synthetic and real-world datasets demonstrate that our methods consistently achieve near-optimal solutions with substantially lower regression errors than greedy optimization while exhibiting superior scalability over existing MIP formulations.

</details>


### [14] [Transformers know more than they can tell -- Learning the Collatz sequence](https://arxiv.org/abs/2511.10811)
*François Charton,Ashvni Narayanan*

Main category: cs.LG

TL;DR: 本文研究Transformer模型预测Collatz序列长步长的能力，发现模型准确率随编码基数变化（最高99.7%，最低25%），所有模型都学习按输入模2^p的残差分类，准确率映射到Collatz序列的数学特性。


<details>
  <summary>Details</summary>
Motivation: 使用数学问题作为工具来理解、解释并可能改进语言模型，探索复杂算术函数的学习机制。

Method: 训练Transformer模型预测Collatz序列的长步长，分析不同编码基数下的模型表现和学习模式。

Result: 模型准确率随编码基数变化显著（24和32基数达99.7%，11和3基数仅37%和25%），模型学习输入模2^p残差分类，错误主要源于循环长度估计错误而非幻觉。

Conclusion: 学习复杂算术函数的难点在于理解计算的控制结构（循环长度），使用数学问题分析语言模型的方法具有广泛应用前景。

Abstract: We investigate transformer prediction of long Collatz steps, a complex arithmetic function that maps odd integers to their distant successors in the Collatz sequence ( $u_{n+1}=u_n/2$ if $u_n$ is even, $u_{n+1}=(3u_n+1)/2$ if $u_n$ is odd). Model accuracy varies with the base used to encode input and output. It can be as high as $99.7\%$ for bases $24$ and $32$, and as low as $37$ and $25\%$ for bases $11$ and $3$. Yet, all models, no matter the base, follow a common learning pattern. As training proceeds, they learn a sequence of classes of inputs that share the same residual modulo $2^p$. Models achieve near-perfect accuracy on these classes, and less than $1\%$ for all other inputs. This maps to a mathematical property of Collatz sequences: the length of the loops involved in the computation of a long Collatz step can be deduced from the binary representation of its input. The learning pattern reflects the model learning to predict inputs associated with increasing loop lengths. An analysis of failure cases reveals that almost all model errors follow predictable patterns. Hallucination, a common feature of large language models, almost never happens. In over $90\%$ of failures, the model performs the correct calculation, but wrongly estimates loop lengths. Our observations give a full account of the algorithms learned by the models. They suggest that the difficulty of learning such complex arithmetic function lies in figuring the control structure of the computation -- the length of the loops. We believe that the approach outlined here, using mathematical problems as tools for understanding, explaining, and perhaps improving language models, can be applied to a broad range of problems and bear fruitful results.

</details>


### [15] [A Best-of-Both-Worlds Proof for Tsallis-INF without Fenchel Conjugates](https://arxiv.org/abs/2511.11211)
*Wei-Cheng Lee,Francesco Orabona*

Main category: cs.LG

TL;DR: 本文提供了一个对Tsallis-INF多臂老虎机算法最佳世界保证的简化推导，避免了共轭函数的使用，采用在线凸优化工具，并优先简洁性而非常数优化。


<details>
  <summary>Details</summary>
Motivation: 为Tsallis-INF算法的最佳世界保证提供一个更简单、更直接的证明方法，避免复杂数学工具的使用。

Method: 使用现代在线凸优化工具，避免共轭函数，简化证明过程，不优化边界常数以保持证明的简洁性。

Result: 成功推导出Tsallis-INF算法在随机和对抗性老虎机环境中的最佳世界保证。

Conclusion: 通过简化证明方法，有效展示了Tsallis-INF算法的理论保证，为相关研究提供了更易理解的证明框架。

Abstract: In this short note, we present a simple derivation of the best-of-both-world guarantee for the Tsallis-INF multi-armed bandit algorithm from J. Zimmert and Y. Seldin. Tsallis-INF: An optimal algorithm for stochastic and adversarial bandits. Journal of Machine Learning Research, 22(28):1-49, 2021. URL https://jmlr.csail.mit.edu/papers/volume22/19-753/19-753.pdf. In particular, the proof uses modern tools from online convex optimization and avoid the use of conjugate functions. Also, we do not optimize the constants in the bounds in favor of a slimmer proof.

</details>


### [16] [Multi-Joint Physics-Informed Deep Learning Framework for Time-Efficient Inverse Dynamics](https://arxiv.org/abs/2511.10878)
*Shuhao Ma,Zeyi Huang,Yu Cao,Wesley Doorsamy,Chaoyang Shi,Jun Li,Zhi-Qiang Zhang*

Main category: cs.LG

TL;DR: 提出了一种物理信息深度学习框架PI-MJCA-BiGRU，直接从运动学数据估计肌肉激活和力量，无需标记数据，实现了时间高效且生理一致的预测。


<details>
  <summary>Details</summary>
Motivation: 传统方法计算成本高且缺乏高质量多关节标记数据集，需要开发计算高效且无需标记数据的肌肉激活和力量估计方法。

Method: 使用新颖的多关节交叉注意力模块(MJCA)和双向门控循环单元(BiGRU)层捕捉关节间协调，通过物理信息损失函数嵌入多关节动力学、关节间耦合和外部力相互作用。

Result: 在两个数据集上的实验验证表明，PI-MJCA-BiGRU在不需要真实标签的情况下达到与传统监督方法相当的性能，MJCA模块显著提升了关节间协调建模能力。

Conclusion: 该框架为临床评估和辅助设备控制提供了时间高效、无需标记数据的肌肉激活和力量估计解决方案，具有重要的应用价值。

Abstract: Time-efficient estimation of muscle activations and forces across multi-joint systems is critical for clinical assessment and assistive device control. However, conventional approaches are computationally expensive and lack a high-quality labeled dataset for multi-joint applications. To address these challenges, we propose a physics-informed deep learning framework that estimates muscle activations and forces directly from kinematics. The framework employs a novel Multi-Joint Cross-Attention (MJCA) module with Bidirectional Gated Recurrent Unit (BiGRU) layers to capture inter-joint coordination, enabling each joint to adaptively integrate motion information from others. By embedding multi-joint dynamics, inter-joint coupling, and external force interactions into the loss function, our Physics-Informed MJCA-BiGRU (PI-MJCA-BiGRU) delivers physiologically consistent predictions without labeled data while enabling time-efficient inference. Experimental validation on two datasets demonstrates that PI-MJCA-BiGRU achieves performance comparable to conventional supervised methods without requiring ground-truth labels, while the MJCA module significantly enhances inter-joint coordination modeling compared to other baseline architectures.

</details>


### [17] [Towards Federated Clustering: A Client-wise Private Graph Aggregation Framework](https://arxiv.org/abs/2511.10915)
*Guanxiong He,Jie Wang,Liaoyuan Tang,Zheng Wang,Rong Wang,Feiping Nie*

Main category: cs.LG

TL;DR: 提出了SPP-FGC算法，通过本地结构图作为隐私保护知识共享媒介，解决了联邦聚类中性能与隐私的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 解决联邦聚类中传输嵌入表示会泄露敏感数据，而仅共享抽象聚类原型会导致模型准确性降低的困境。

Method: 基于客户端-服务器架构，客户端构建私有结构图捕获数据关系，服务器安全聚合和对齐形成全局图，从中推导统一聚类结构。提供SPP-FGC（单轮通信）和SPP-FGC+（迭代优化）两种模式。

Result: 在广泛实验中达到最先进性能，相比联邦基线方法将聚类准确性提升高达10%（NMI），同时保持可证明的隐私保证。

Conclusion: SPP-FGC框架通过结构图作为隐私保护知识共享媒介，有效解决了联邦聚类中性能与隐私的权衡问题，在保持隐私的同时显著提升聚类准确性。

Abstract: Federated clustering addresses the critical challenge of extracting patterns from decentralized, unlabeled data. However, it is hampered by the flaw that current approaches are forced to accept a compromise between performance and privacy: \textit{transmitting embedding representations risks sensitive data leakage, while sharing only abstract cluster prototypes leads to diminished model accuracy}. To resolve this dilemma, we propose Structural Privacy-Preserving Federated Graph Clustering (SPP-FGC), a novel algorithm that innovatively leverages local structural graphs as the primary medium for privacy-preserving knowledge sharing, thus moving beyond the limitations of conventional techniques. Our framework operates on a clear client-server logic; on the client-side, each participant constructs a private structural graph that captures intrinsic data relationships, which the server then securely aggregates and aligns to form a comprehensive global graph from which a unified clustering structure is derived. The framework offers two distinct modes to suit different needs. SPP-FGC is designed as an efficient one-shot method that completes its task in a single communication round, ideal for rapid analysis. For more complex, unstructured data like images, SPP-FGC+ employs an iterative process where clients and the server collaboratively refine feature representations to achieve superior downstream performance. Extensive experiments demonstrate that our framework achieves state-of-the-art performance, improving clustering accuracy by up to 10\% (NMI) over federated baselines while maintaining provable privacy guarantees.

</details>


### [18] [Cascading Bandits With Feedback](https://arxiv.org/abs/2511.10938)
*R Sri Prakash,Nikhil Karamchandani,Sharayu Moharir*

Main category: cs.LG

TL;DR: 本文研究了边缘推理中的级联赌博机模型，分析了四种决策策略的理论遗憾保证，发现LCB和Thompson采样因持续自适应而实现常数遗憾，优于固定排序策略。


<details>
  <summary>Details</summary>
Motivation: 受边缘推理挑战的驱动，研究每个臂对应具有相关精度和错误概率的推理模型的级联赌博机变体。

Method: 分析四种决策策略：探索后提交、行动消除、下置信界和Thompson采样，并提供每种策略的尖锐理论遗憾保证。

Result: 与经典赌博机设置不同，探索后提交和行动消除因在探索阶段后承诺固定排序而遭受次优遗憾。LCB和Thompson采样基于观察反馈持续更新决策，实现常数O(1)遗憾。

Conclusion: 模拟验证了理论发现，突显了在不确定性下自适应对于高效边缘推理的关键作用。

Abstract: Motivated by the challenges of edge inference, we study a variant of the cascade bandit model in which each arm corresponds to an inference model with an associated accuracy and error probability. We analyse four decision-making policies-Explore-then-Commit, Action Elimination, Lower Confidence Bound (LCB), and Thompson Sampling-and provide sharp theoretical regret guarantees for each. Unlike in classical bandit settings, Explore-then-Commit and Action Elimination incur suboptimal regret because they commit to a fixed ordering after the exploration phase, limiting their ability to adapt. In contrast, LCB and Thompson Sampling continuously update their decisions based on observed feedback, achieving constant O(1) regret. Simulations corroborate these theoretical findings, highlighting the crucial role of adaptivity for efficient edge inference under uncertainty.

</details>


### [19] [How Data Quality Affects Machine Learning Models for Credit Risk Assessment](https://arxiv.org/abs/2511.10964)
*Andrea Maurino*

Main category: cs.LG

TL;DR: 本研究探讨了数据质量问题（如缺失值、噪声属性、异常值和标签错误）对信用风险评估中机器学习模型预测准确性的影响。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在信用风险评估中的应用日益增多，但其有效性很大程度上取决于输入数据的质量，需要研究数据质量问题对模型性能的影响。

Method: 使用开源数据集，通过Pucktrick库引入受控的数据损坏，评估10种常用模型（如随机森林、SVM和逻辑回归等）的鲁棒性。

Result: 实验显示，根据数据退化的性质和严重程度，模型的鲁棒性存在显著差异。

Conclusion: 所提出的方法和配套工具为从业者增强数据管道鲁棒性提供了实用支持，并为研究人员在数据为中心的AI环境中进一步实验提供了灵活框架。

Abstract: Machine Learning (ML) models are being increasingly employed for credit risk evaluation, with their effectiveness largely hinging on the quality of the input data. In this paper we investigate the impact of several data quality issues, including missing values, noisy attributes, outliers, and label errors, on the predictive accuracy of the machine learning model used in credit risk assessment. Utilizing an open-source dataset, we introduce controlled data corruption using the Pucktrick library to assess the robustness of 10 frequently used models like Random Forest, SVM, and Logistic Regression and so on. Our experiments show significant differences in model robustness based on the nature and severity of the data degradation. Moreover, the proposed methodology and accompanying tools offer practical support for practitioners seeking to enhance data pipeline robustness, and provide researchers with a flexible framework for further experimentation in data-centric AI contexts.

</details>


### [20] [Improving Continual Learning of Knowledge Graph Embeddings via Informed Initialization](https://arxiv.org/abs/2511.11118)
*Gerard Pons,Besim Bilalli,Anna Queralt*

Main category: cs.LG

TL;DR: 提出了一种新颖的知识图谱嵌入初始化策略，利用KG模式和先前学习的嵌入来为新实体获取初始表示，从而提高预测性能、增强知识保留并加速知识获取。


<details>
  <summary>Details</summary>
Motivation: 知识图谱频繁更新，其嵌入需要适应这些变化。现有持续学习方法中嵌入初始化对最终嵌入的准确性和训练时间有重要影响，特别是对于相对较小和频繁的更新。

Method: 利用知识图谱模式和先前学习的嵌入，基于实体所属的类别为新实体获取初始表示，该策略可无缝集成到现有的KGE持续学习方法中。

Result: 实验分析表明，该初始化策略提高了KGE的预测性能，增强了知识保留能力，同时加速了知识获取，减少了增量学习新嵌入所需的轮次和时间。

Conclusion: 提出的初始化策略在多种类型的KGE学习模型中均表现出优势，能够有效增强新知识的获取并减少灾难性遗忘。

Abstract: Many Knowledege Graphs (KGs) are frequently updated, forcing their Knowledge Graph Embeddings (KGEs) to adapt to these changes. To address this problem, continual learning techniques for KGEs incorporate embeddings for new entities while updating the old ones. One necessary step in these methods is the initialization of the embeddings, as an input to the KGE learning process, which can have an important impact in the accuracy of the final embeddings, as well as in the time required to train them. This is especially relevant for relatively small and frequent updates. We propose a novel informed embedding initialization strategy, which can be seamlessly integrated into existing continual learning methods for KGE, that enhances the acquisition of new knowledge while reducing catastrophic forgetting. Specifically, the KG schema and the previously learned embeddings are utilized to obtain initial representations for the new entities, based on the classes the entities belong to. Our extensive experimental analysis shows that the proposed initialization strategy improves the predictive performance of the resulting KGEs, while also enhancing knowledge retention. Furthermore, our approach accelerates knowledge acquisition, reducing the number of epochs, and therefore time, required to incrementally learn new embeddings. Finally, its benefits across various types of KGE learning models are demonstrated.

</details>


### [21] [Anomaly Detection in High-Dimensional Bank Account Balances via Robust Methods](https://arxiv.org/abs/2511.11143)
*Federico Maddanu,Tommaso Proietti,Riccardo Crupi*

Main category: cs.LG

TL;DR: 本文提出并评估了几种在中等和高维数据集中计算效率高的稳健统计方法，用于检测银行账户余额中的点异常，应用于260万条匿名用户银行账户余额的日常记录。


<details>
  <summary>Details</summary>
Motivation: 检测银行账户余额中的点异常对金融机构至关重要，可以识别潜在的欺诈、操作问题或其他异常情况。稳健统计在标记异常值和提供不受污染观测影响的数据分布参数估计方面很有用，但在高维设置下通常效率较低且计算成本高。

Method: 提出并经验评估了几种稳健方法，这些方法在中等和高维数据集中具有高崩溃点和低计算时间，可能计算效率高。

Result: 方法应用于约260万条匿名用户银行账户余额的日常记录。

Conclusion: 所提出的稳健方法在高维银行账户余额数据异常检测中具有潜在的计算效率和实用性。

Abstract: Detecting point anomalies in bank account balances is essential for financial institutions, as it enables the identification of potential fraud, operational issues, or other irregularities. Robust statistics is useful for flagging outliers and for providing estimates of the data distribution parameters that are not affected by contaminated observations. However, such a strategy is often less efficient and computationally expensive under high dimensional setting. In this paper, we propose and evaluate empirically several robust approaches that may be computationally efficient in medium and high dimensional datasets, with high breakdown points and low computational time. Our application deals with around 2.6 million daily records of anonymous users' bank account balances.

</details>


### [22] [Deep Learning for Short-Term Precipitation Prediction in Four Major Indian Cities: A ConvLSTM Approach with Explainable AI](https://arxiv.org/abs/2511.11152)
*Tanmay Ghosh,Shaurabh Anand,Rakesh Gomaji Nannewar,Nithin Nagaraj*

Main category: cs.LG

TL;DR: 开发了一个可解释的深度学习框架，用于印度四个主要城市的短期降水预测，结合CNN-ConvLSTM架构和多种可解释性分析方法。


<details>
  <summary>Details</summary>
Motivation: 深度学习降水预报模型通常作为黑箱运行，限制了在实际天气预测中的应用，需要提高透明度同时保持准确性。

Method: 采用混合时间分布式CNN-ConvLSTM架构，使用ERA5再分析数据进行训练，为每个城市优化卷积滤波器数量，并应用排列重要性、Grad-CAM、时间遮挡和反事实扰动等可解释性分析方法。

Result: 模型在不同城市取得RMSE值：班加罗尔0.21毫米/天、孟买0.52毫米/天、德里0.48毫米/天、加尔各答1.80毫米/天，预测范围从1天到5天不等。

Conclusion: 研究表明可解释AI能够提供准确的降水预报，并为不同城市环境中的降水模式提供透明洞察。

Abstract: Deep learning models for precipitation forecasting often function as black boxes, limiting their adoption in real-world weather prediction. To enhance transparency while maintaining accuracy, we developed an interpretable deep learning framework for short-term precipitation prediction in four major Indian cities: Bengaluru, Mumbai, Delhi, and Kolkata, spanning diverse climate zones. We implemented a hybrid Time-Distributed CNN-ConvLSTM (Convolutional Neural Network-Long Short-Term Memory) architecture, trained on multi-decadal ERA5 reanalysis data. The architecture was optimized for each city with a different number of convolutional filters: Bengaluru (32), Mumbai and Delhi (64), and Kolkata (128). The models achieved root mean square error (RMSE) values of 0.21 mm/day (Bengaluru), 0.52 mm/day (Mumbai), 0.48 mm/day (Delhi), and 1.80 mm/day (Kolkata). Through interpretability analysis using permutation importance, Gradient-weighted Class Activation Mapping (Grad-CAM), temporal occlusion, and counterfactual perturbation, we identified distinct patterns in the model's behavior. The model relied on city-specific variables, with prediction horizons ranging from one day for Bengaluru to five days for Kolkata. This study demonstrates how explainable AI (xAI) can provide accurate forecasts and transparent insights into precipitation patterns in diverse urban environments.

</details>


### [23] [Dynamic Deep Graph Learning for Incomplete Multi-View Clustering with Masked Graph Reconstruction Loss](https://arxiv.org/abs/2511.11181)
*Zhenghao Zhang,Jun Xie,Xingchen Chen,Tao Yu,Hongzhu Yi,Kaixin Xu,Yuanxiang Wang,Tianyu Zong,Xinming Wang,Jiahuan Chen,Guoqing Chao,Feng Chen,Zhepeng Wang,Jungang Xu*

Main category: cs.LG

TL;DR: 提出了一种名为DGIMVCM的动态深度图学习方法，用于解决不完整多视图聚类问题，通过构建缺失鲁棒的全局图、图卷积嵌入层、图自注意力编码器和掩码图重构损失来提升聚类性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中多视图数据的普遍性使得不完整多视图聚类成为重要研究方向。现有基于GNN的方法存在两个主要问题：使用KNN构建静态图会引入噪声降低鲁棒性；直接使用MSE损失作为图重构损失会在优化过程中产生大量梯度噪声。

Method: 1) 从原始数据构建缺失鲁棒的全局图，设计图卷积嵌入层提取主要特征和精炼的动态视图特定图结构，利用全局图进行缺失视图补全，辅以图结构对比学习识别视图间一致性；2) 引入图自注意力编码器基于补全后的主要特征和视图特定图提取高层表示，使用掩码图重构损失优化以减少梯度噪声；3) 构建聚类模块并通过伪标签自监督训练机制优化。

Result: 在多个数据集上的广泛实验验证了DGIMVCM的有效性和优越性。

Conclusion: 提出的DGIMVCM方法通过动态深度图学习和掩码图重构损失，有效解决了不完整多视图聚类中的图构建噪声和梯度噪声问题，提升了聚类性能。

Abstract: The prevalence of real-world multi-view data makes incomplete multi-view clustering (IMVC) a crucial research. The rapid development of Graph Neural Networks (GNNs) has established them as one of the mainstream approaches for multi-view clustering. Despite significant progress in GNNs-based IMVC, some challenges remain: (1) Most methods rely on the K-Nearest Neighbors (KNN) algorithm to construct static graphs from raw data, which introduces noise and diminishes the robustness of the graph topology. (2) Existing methods typically utilize the Mean Squared Error (MSE) loss between the reconstructed graph and the sparse adjacency graph directly as the graph reconstruction loss, leading to substantial gradient noise during optimization. To address these issues, we propose a novel \textbf{D}ynamic Deep \textbf{G}raph Learning for \textbf{I}ncomplete \textbf{M}ulti-\textbf{V}iew \textbf{C}lustering with \textbf{M}asked Graph Reconstruction Loss (DGIMVCM). Firstly, we construct a missing-robust global graph from the raw data. A graph convolutional embedding layer is then designed to extract primary features and refined dynamic view-specific graph structures, leveraging the global graph for imputation of missing views. This process is complemented by graph structure contrastive learning, which identifies consistency among view-specific graph structures. Secondly, a graph self-attention encoder is introduced to extract high-level representations based on the imputed primary features and view-specific graphs, and is optimized with a masked graph reconstruction loss to mitigate gradient noise during optimization. Finally, a clustering module is constructed and optimized through a pseudo-label self-supervised training mechanism. Extensive experiments on multiple datasets validate the effectiveness and superiority of DGIMVCM.

</details>


### [24] [Epistemic Error Decomposition for Multi-step Time Series Forecasting: Rethinking Bias-Variance in Recursive and Direct Strategies](https://arxiv.org/abs/2511.11461)
*Riku Green,Huw Day,Zahraa S. Abdallah,Telmo M. Silva Filho*

Main category: cs.LG

TL;DR: 该论文重新审视了多步预测中递归策略和直接策略的传统偏见-方差权衡观点，通过误差分解分析发现：对于线性预测器，结构差距为零；对于非线性预测器，递归策略能增加模型表达能力。研究还提出了基于雅可比矩阵的方差放大因子来解释递归策略的方差特性。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为递归策略具有高偏差低方差，直接策略具有低偏差高方差。作者旨在重新审视这一简单经验法则，通过理论分析和实验验证来提供更准确的理解。

Method: 通过将多步预测误差分解为不可约噪声、结构近似差距和估计方差三项进行分析。对于线性预测器进行理论证明，对非线性预测器研究递归组合对模型表达能力的影响，并引入雅可比矩阵放大因子分析方差特性。在ETTm1数据集上使用多层感知机进行实验验证。

Result: 研究发现：线性预测器的结构差距恒为零；非线性预测器中递归策略能增加模型表达能力；递归策略的方差可表示为一步方差乘以雅可比放大因子；在某些情况下递归策略可能同时具有更低偏差和更高方差。

Conclusion: 研究提供了基于模型非线性和噪声特性的实际指导，建议在选择递归和直接策略时不应依赖传统的偏见-方差直觉，而应考虑模型的具体特性。

Abstract: Multi-step forecasting is often described through a simple rule of thumb: recursive strategies are said to have high bias and low variance, while direct strategies are said to have low bias and high variance. We revisit this belief by decomposing the expected multi-step forecast error into three parts: irreducible noise, a structural approximation gap, and an estimation-variance term. For linear predictors we show that the structural gap is identically zero for any dataset. For nonlinear predictors, however, the repeated composition used in recursion can increase model expressivity, making the structural gap depend on both the model and the data. We further show that the estimation variance of the recursive strategy at any horizon can be written as the one-step variance multiplied by a Jacobian-based amplification factor that measures how sensitive the composed predictor is to parameter error. This perspective explains when recursive forecasting may simultaneously have lower bias and higher variance than direct forecasting. Experiments with multilayer perceptrons on the ETTm1 dataset confirm these findings. The results offer practical guidance for choosing between recursive and direct strategies based on model nonlinearity and noise characteristics, rather than relying on traditional bias-variance intuition.

</details>


### [25] [Toward Multi-Fidelity Machine Learning Force Field for Cathode Materials](https://arxiv.org/abs/2511.11361)
*Guangyi Dong,Zhihui Wang*

Main category: cs.LG

TL;DR: 本文开发了一个多保真度机器学习力场框架，用于提高锂离子电池正极材料计算的数据效率，可同时利用低保真度非磁性和高保真度磁性计算数据集进行训练。


<details>
  <summary>Details</summary>
Motivation: 锂离子电池正极材料的机器学习力场开发和应用相对有限，主要由于正极材料复杂的电子结构特性和高质量计算数据集的稀缺。

Method: 开发多保真度机器学习力场框架，同时利用低保真度非磁性和高保真度磁性计算数据集进行训练。

Result: 在锂锰铁磷酸盐正极材料系统上的测试证明了这种多保真度方法的有效性。

Conclusion: 这项工作有助于以较低的训练数据集成本实现正极材料的高精度机器学习力场训练，并为机器学习力场在正极材料计算模拟中的应用提供了新视角。

Abstract: Machine learning force fields (MLFFs), which employ neural networks to map atomic structures to system energies, effectively combine the high accuracy of first-principles calculation with the computational efficiency of empirical force fields. They are widely used in computational materials simulations. However, the development and application of MLFFs for lithium-ion battery cathode materials remain relatively limited. This is primarily due to the complex electronic structure characteristics of cathode materials and the resulting scarcity of high-quality computational datasets available for force field training. In this work, we develop a multi-fidelity machine learning force field framework to enhance the data efficiency of computational results, which can simultaneously utilize both low-fidelity non-magnetic and high-fidelity magnetic computational datasets of cathode materials for training. Tests conducted on the lithium manganese iron phosphate (LMFP) cathode material system demonstrate the effectiveness of this multi-fidelity approach. This work helps to achieve high-accuracy MLFF training for cathode materials at a lower training dataset cost, and offers new perspectives for applying MLFFs to computational simulations of cathode materials.

</details>


### [26] [On-Device Fine-Tuning via Backprop-Free Zeroth-Order Optimization](https://arxiv.org/abs/2511.11362)
*Prabodh Katti,Sangwoo Park,Bipin Rajendran,Osvaldo Simeone*

Main category: cs.LG

TL;DR: 论文研究了在边缘设备上使用内存高效的零阶优化方法MeZO进行模型微调，相比传统反向传播方法，MeZO能显著减少内存占用，支持更大的模型部署，但需要更长的训练时间。


<details>
  <summary>Details</summary>
Motivation: 边缘AI系统需要在严格内存约束下支持不同任务的适应，传统反向传播训练需要存储层激活和优化器状态，限制了可部署的最大模型规模。

Method: 使用内存高效的零阶优化方法MeZO，仅通过前向评估估计梯度，无需存储中间激活或优化器状态，从而显著减少内存占用。

Result: 理论分析和数值验证表明，在设备内存约束下，MeZO能够支持更大的模型规模，并在足够训练时间下保持准确性优势。

Conclusion: MeZO方法在边缘设备部署中具有重要价值，能够在内存受限环境下支持更大模型的微调，为边缘AI系统提供了可行的解决方案。

Abstract: On-device fine-tuning is a critical capability for edge AI systems, which must support adaptation to different agentic tasks under stringent memory constraints. Conventional backpropagation (BP)-based training requires storing layer activations and optimizer states, a demand that can be only partially alleviated through checkpointing. In edge deployments in which the model weights must reside entirely in device memory, this overhead severely limits the maximum model size that can be deployed. Memory-efficient zeroth-order optimization (MeZO) alleviates this bottleneck by estimating gradients using forward evaluations alone, eliminating the need for storing intermediate activations or optimizer states. This enables significantly larger models to fit within on-chip memory, albeit at the cost of potentially longer fine-tuning wall-clock time. This paper first provides a theoretical estimate of the relative model sizes that can be accommodated under BP and MeZO training. We then numerically validate the analysis, demonstrating that MeZO exhibits accuracy advantages under on-device memory constraints, provided sufficient wall-clock time is available for fine-tuning.

</details>


### [27] [Differentiation Strategies for Acoustic Inverse Problems: Admittance Estimation and Shape Optimization](https://arxiv.org/abs/2511.11415)
*Nikolas Borrel-Jensen,Josiah Bjorgaard*

Main category: cs.LG

TL;DR: 本文展示了使用可微分编程解决声学逆问题的实用方法，包括边界导纳估计和共振阻尼形状优化，通过自动微分和有限差分相结合的方式显著提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统的声学逆问题求解需要手动推导伴随方程，计算成本高且复杂。本文旨在利用现代可微分软件栈实现快速原型设计，简化优化流程。

Method: 使用JAX-FEM进行自动微分实现边界导纳估计，结合PyTorch3D进行网格操作，采用随机有限差分法进行声学形状优化，将物理驱动的边界优化与几何驱动的内部网格适配分离。

Result: 边界导纳估计达到3位数精度，形状优化在目标频率上实现48.1%的能量减少，相比标准有限差分方法减少30倍FEM求解次数。

Conclusion: 现代可微分软件栈能够有效支持基于物理的逆问题优化工作流，自动微分适用于参数估计，有限差分与自动微分结合适用于几何设计。

Abstract: We demonstrate a practical differentiable programming approach for acoustic inverse problems through two applications: admittance estimation and shape optimization for resonance damping. First, we show that JAX-FEM's automatic differentiation (AD) enables direct gradient-based estimation of complex boundary admittance from sparse pressure measurements, achieving 3-digit precision without requiring manual derivation of adjoint equations. Second, we apply randomized finite differences to acoustic shape optimization, combining JAX-FEM for forward simulation with PyTorch3D for mesh manipulation through AD. By separating physics-driven boundary optimization from geometry-driven interior mesh adaptation, we achieve 48.1% energy reduction at target frequencies with 30-fold fewer FEM solutions compared to standard finite difference on the full mesh. This work showcases how modern differentiable software stacks enable rapid prototyping of optimization workflows for physics-based inverse problems, with automatic differentiation for parameter estimation and a combination of finite differences and AD for geometric design.

</details>


### [28] [DiffPro: Joint Timestep and Layer-Wise Precision Optimization for Efficient Diffusion Inference](https://arxiv.org/abs/2511.11446)
*Farhana Amin,Sabiha Afroz,Kanchon Gharami,Mona Moghadampanah,Dimitrios S. Nikolopoulos*

Main category: cs.LG

TL;DR: DiffPro是一个后训练框架，通过联合优化时间步长和每层精度来加速扩散模型推理，无需重新训练即可实现6.25倍模型压缩、50%时间步减少和2.8倍推理加速。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然能生成高质量图像，但由于需要大量去噪步骤和繁重的矩阵运算，推理成本高昂。需要一种无需重新训练的方法来减少延迟和内存使用。

Method: DiffPro结合三个部分：基于流形感知的敏感度指标分配权重比特位、动态激活量化以稳定跨时间步的激活、以及基于师生漂移的预算时间步选择器。

Result: 在标准基准测试中，DiffPro实现了高达6.25倍的模型压缩、50%的时间步减少和2.8倍的推理加速，Delta FID ≤ 10。

Conclusion: DiffPro将步数减少和精度规划统一到一个可部署的预算计划中，为实时节能扩散推理提供了实用效率提升。

Abstract: Diffusion models produce high quality images but inference is costly due to many denoising steps and heavy matrix operations. We present DiffPro, a post-training, hardware-faithful framework that works with the exact integer kernels used in deployment and jointly tunes timesteps and per-layer precision in Diffusion Transformers (DiTs) to reduce latency and memory without any training. DiffPro combines three parts: a manifold-aware sensitivity metric to allocate weight bits, dynamic activation quantization to stabilize activations across timesteps, and a budgeted timestep selector guided by teacher-student drift. In experiments DiffPro achieves up to 6.25x model compression, fifty percent fewer timesteps, and 2.8x faster inference with Delta FID <= 10 on standard benchmarks, demonstrating practical efficiency gains. DiffPro unifies step reduction and precision planning into a single budgeted deployable plan for real-time energy-aware diffusion inference.

</details>


### [29] [FairReweighing: Density Estimation-Based Reweighing Framework for Improving Separation in Fair Regression](https://arxiv.org/abs/2511.11459)
*Xiaoyin Xi,Zhe Yu*

Main category: cs.LG

TL;DR: 本文提出了一种基于密度估计的FairReweighing预处理算法，用于解决回归任务中的公平性问题，该算法能保证分离准则并在保持高准确率的同时改善公平性。


<details>
  <summary>Details</summary>
Motivation: AI软件在公共部门和工业应用中广泛使用，但缺乏透明度引发了关于公平性的担忧。现有研究主要关注二元分类任务的公平性，而回归任务的公平性研究相对不足。

Method: 采用基于互信息的指标来评估分离违规，并扩展该指标使其适用于分类和回归问题。受公平分类中Reweighing算法的启发，提出了基于密度估计的FairReweighing预处理算法。

Result: 理论上证明在数据独立性假设下，FairReweighing算法能保证训练数据中的分离准则。实证研究表明，在合成和真实世界数据上，该算法在提高分离性的同时保持高准确率，优于现有最先进的回归公平性解决方案。

Conclusion: FairReweighing算法为回归任务提供了一种有效的公平性保证方法，填补了回归公平性研究的空白，并在实际应用中表现出色。

Abstract: There has been a prevalence of applying AI software in both high-stakes public-sector and industrial contexts. However, the lack of transparency has raised concerns about whether these data-informed AI software decisions secure fairness against people of all racial, gender, or age groups. Despite extensive research on emerging fairness-aware AI software, up to now most efforts to solve this issue have been dedicated to binary classification tasks. Fairness in regression is relatively underexplored. In this work, we adopted a mutual information-based metric to assess separation violations. The metric is also extended so that it can be directly applied to both classification and regression problems with both binary and continuous sensitive attributes. Inspired by the Reweighing algorithm in fair classification, we proposed a FairReweighing pre-processing algorithm based on density estimation to ensure that the learned model satisfies the separation criterion. Theoretically, we show that the proposed FairReweighing algorithm can guarantee separation in the training data under a data independence assumption. Empirically, on both synthetic and real-world data, we show that FairReweighing outperforms existing state-of-the-art regression fairness solutions in terms of improving separation while maintaining high accuracy.

</details>


### [30] [FarSkip-Collective: Unhobbling Blocking Communication in Mixture of Experts Models](https://arxiv.org/abs/2511.11505)
*Yonatan Dukler,Guihong Li,Deval Shah,Vikram Appia,Emad Barsoum*

Main category: cs.LG

TL;DR: FarSkip-Collective通过修改现代模型架构，在MoEs分布式环境中实现计算与通信的重叠，成功转换了16B到109B参数规模的SOTA模型，在保持准确性的同时显著加速训练和推理。


<details>
  <summary>Details</summary>
Motivation: 在分布式环境中运行MoEs时，阻塞通信是主要效率障碍，需要解决计算与通信的同步问题。

Method: 修改模型架构，跳过模型中的连接，通过自蒸馏技术转换大型模型（16B-109B参数），并优化实现以显式重叠通信与计算。

Result: 成功转换Llama 4 Scout（109B）等模型，下游评估平均准确率与原始开源版本相差不到1%，在现有框架中加速了训练和推理。

Conclusion: FarSkip-Collective方法能够有效保持大型修改模型的准确性，同时通过通信与计算重叠实现显著的性能提升。

Abstract: Blocking communication presents a major hurdle in running MoEs efficiently in distributed settings. To address this, we present FarSkip-Collective which modifies the architecture of modern models to enable overlapping of their computation with communication. Our approach modifies the architecture to skip connections in the model and it is unclear a priori whether the modified model architecture can remain as capable, especially for large state-of-the-art models and while modifying all of the model layers. We answer this question in the affirmative and fully convert a series of state-of-the-art models varying from 16B to 109B parameters to enable overlapping of their communication while achieving accuracy on par with their original open-source releases. For example, we convert Llama 4 Scout (109B) via self-distillation and achieve average accuracy within 1% of its instruction tuned release averaged across a wide range of downstream evaluations. In addition to demonstrating retained accuracy of the large modified models, we realize the benefits of FarSkip-Collective through optimized implementations that explicitly overlap communication with computation, accelerating both training and inference in existing frameworks.

</details>


### [31] [Multistability of Self-Attention Dynamics in Transformers](https://arxiv.org/abs/2511.11553)
*Claudio Altafini*

Main category: cs.LG

TL;DR: 本文研究了自注意力动力学与多智能体Oja流的关系，将单头自注意力系统的平衡点分为四类：共识、二分共识、聚类和多边形平衡点，发现前三类中的多个渐近稳定平衡点经常共存。


<details>
  <summary>Details</summary>
Motivation: 研究自注意力动力学与多智能体Oja流的联系，深入理解transformer中注意力机制的行为特性。

Method: 将自注意力动力学建模为连续时间多智能体系统，分析其与Oja流的关系，并对单头自注意力系统的平衡点进行分类研究。

Result: 发现自注意力动力学中存在四类平衡点，前三类中的多个渐近稳定平衡点经常共存，且前两类平衡点总是与价值矩阵的特征向量对齐。

Conclusion: 自注意力动力学与多智能体Oja流密切相关，系统表现出丰富的平衡点行为，为理解transformer注意力机制提供了新的理论视角。

Abstract: In machine learning, a self-attention dynamics is a continuous-time multiagent-like model of the attention mechanisms of transformers. In this paper we show that such dynamics is related to a multiagent version of the Oja flow, a dynamical system that computes the principal eigenvector of a matrix corresponding for transformers to the value matrix. We classify the equilibria of the ``single-head'' self-attention system into four classes: consensus, bipartite consensus, clustering and polygonal equilibria. Multiple asymptotically stable equilibria from the first three classes often coexist in the self-attention dynamics. Interestingly, equilibria from the first two classes are always aligned with the eigenvectors of the value matrix, often but not exclusively with the principal eigenvector.

</details>


### [32] [Optimizing Mixture of Block Attention](https://arxiv.org/abs/2511.11571)
*Guangxuan Xiao,Junxian Guo,Kasra Mazaheri,Song Han*

Main category: cs.LG

TL;DR: 本文分析了MoBA（混合块注意力）机制的性能原理，开发了统计模型揭示路由器区分相关块的能力是关键，提出了通过减小块大小和键值卷积来改进性能的方法，并开发了高效的FlashMoBA GPU实现。


<details>
  <summary>Details</summary>
Motivation: MoBA作为处理长上下文的高效注意力机制，其设计原理不明确且缺乏高效GPU实现，阻碍了实际应用。本文旨在理解MoBA工作机制并开发高效实现。

Method: 开发统计模型分析MoBA机制，推导信噪比连接架构参数与检索精度；提出减小块大小和键值卷积改进路由精度；开发FlashMoBA CUDA内核实现高效小块处理。

Result: 改进的MoBA模型在从头训练的LLM中达到密集注意力基线性能；FlashMoBA相比FlashAttention-2在小块处理上实现最高14.7倍加速。

Conclusion: 通过理论分析和硬件优化，成功提升了MoBA的性能和效率，使其成为实用的长上下文处理方案。

Abstract: Mixture of Block Attention (MoBA) (Lu et al., 2025) is a promising building block for efficiently processing long contexts in LLMs by enabling queries to sparsely attend to a small subset of key-value blocks, drastically reducing computational cost. However, the design principles governing MoBA's performance are poorly understood, and it lacks an efficient GPU implementation, hindering its practical adoption. In this paper, we first develop a statistical model to analyze MoBA's underlying mechanics. Our model reveals that performance critically depends on the router's ability to accurately distinguish relevant from irrelevant blocks based on query-key affinities. We derive a signal-to-noise ratio that formally connects architectural parameters to this retrieval accuracy. Guided by our analysis, we identify two key pathways for improvement: using smaller block sizes and applying a short convolution on keys to cluster relevant signals, which enhances routing accuracy. While theoretically better, small block sizes are inefficient on GPUs. To bridge this gap, we introduce FlashMoBA, a hardware-aware CUDA kernel that enables efficient MoBA execution even with the small block sizes our theory recommends. We validate our insights by training LLMs from scratch, showing that our improved MoBA models match the performance of dense attention baselines. FlashMoBA achieves up to 14.7x speedup over FlashAttention-2 for small blocks, making our theoretically-grounded improvements practical. Code is available at: https://github.com/mit-han-lab/flash-moba.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [33] [A Novel Partitioning Scheme for RIS Identification and Beamforming](https://arxiv.org/abs/2511.11335)
*Yarkın Gevez,Aymen Khaleel,Ertugrul Basar*

Main category: eess.SP

TL;DR: 提出一种新颖的可重构智能表面分区方案，同时考虑RIS识别和波束成形，通过动态分配RIS元素来提升信噪比并保持可靠的识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有的RIS系统需要同时处理识别和波束成形任务，但传统方法无法动态高效地分配RIS资源来平衡这两种不同性能指标的需求。

Method: 采用动态分区算法，根据识别用户和波束成形用户的不同性能要求，动态高效地分配RIS元素资源。

Result: 理论分析和计算机仿真验证了所提方案的有效性，显著提升了信噪比同时保持了可靠的识别性能。

Conclusion: 该动态分区方案能够有效管理RIS资源，在提升通信性能的同时保证识别功能的可靠性，为RIS系统的多功能应用提供了可行解决方案。

Abstract: This letter introduces a novel partitioning scheme for reconfigurable intelligent surfaces (RISs) that simultaneously consider RIS identification and beamforming. The proposed scheme dynamicly and efficiently allocates RIS elements between identification and beamforming users, considering the different performance metrics associated with each of them. By employing a dynamic partitioning algorithm that efficiently manage the RIS resources (elements), the scheme significantly enhances the signal-to-noise ratio (SNR) while maintaining reliable identification performance. Finally, theoretical analysis and computer simulations are provided to demonstrate the validity of the proposed scheme.

</details>


### [34] [A Scalable and Exact Relaxation for Densest $k$-Subgraph via Error Bounds](https://arxiv.org/abs/2511.11451)
*Ya Liu,Junbin Liu,Wing-Kin Ma,Aritra Konar*

Main category: eess.SP

TL;DR: 本文提出了一种可扩展的精确连续惩罚方法来解决Densest k-Subgraph问题，使用误差界原理设计合适的惩罚函数，确保惩罚问题的全局和局部最优解与原问题一致，并开发了非凸近端梯度算法。


<details>
  <summary>Details</summary>
Motivation: DkS问题是NP难且难以近似，但基于惩罚的连续松弛方法在实际应用中取得了成功。本文旨在开发一种可扩展的精确连续惩罚方法来解决这一问题。

Method: 使用误差界原理设计惩罚函数，提出非凸近端梯度算法，其中非凸近端算子可以闭式求解，具有低迭代复杂度。

Result: 在大规模DkS问题及其变体Dk1k2BS问题上的实验表明，该方法在计算成本和求解质量之间达到了良好的平衡。

Conclusion: 提出的惩罚重构方法能够使用一阶连续优化方法，理论保证确保了惩罚问题与原问题的最优解一致性，算法具有低迭代复杂度和收敛性分析。

Abstract: Given an undirected graph and a size parameter $k$, the Densest $k$-Subgraph (D$k$S) problem extracts the subgraph on $k$ vertices with the largest number of induced edges. While D$k$S is NP--hard and difficult to approximate, penalty-based continuous relaxations of the problem have recently enjoyed practical success for real-world instances of D$k$S. In this work, we propose a scalable and exact continuous penalization approach for D$k$S using the error bound principle, which enables the design of suitable penalty functions. Notably, we develop new theoretical guarantees ensuring that both the global and local optima of the penalized problem match those of the original problem. The proposed penalized reformulation enables the use of first-order continuous optimization methods. In particular, we develop a non-convex proximal gradient algorithm, where the non-convex proximal operator can be computed in closed form, resulting in low per-iteration complexity. We also provide convergence analysis of the algorithm. Experiments on large-scale instances of the D$k$S problem and one of its variants, the Densest ($k_1, k_2$) Bipartite Subgraph (D$k_1k_2$BS) problem, demonstrate that our method achieves a favorable balance between computation cost and solution quality.

</details>


### [35] [Enabling Wireless Power Transfer (WPT) in Pinching Antenna Systems (PASS)](https://arxiv.org/abs/2511.11465)
*Deqiao Gan,Xiaoxia Xu,Xiaohu Ge,Yue Liu,Yuanwei Liu*

Main category: eess.SP

TL;DR: 提出了一种新型的夹持天线系统无线功率传输框架，通过激活接收器附近的夹持天线并灵活调整功率辐射比，同时提升能量收集效率和通信质量。


<details>
  <summary>Details</summary>
Motivation: 解决能量收集接收器和信息解码接收器共存场景下，能量收集效率和通信质量之间的强耦合问题，实现两者的协同优化。

Method: 采用双层优化方法：上层联合优化发射波束成形、夹持天线位置和功率辐射比可行区间以最大化功率转换效率；下层细化功率辐射比以最大化总速率。针对双用户和多用户场景分别开发了交替优化、WMMSE和QT-LDT算法。

Result: 数值仿真结果表明，所提出的PASS-WPT框架相比传统MIMO和固定功率辐射的基线PASS，能量收集接收器的功率转换效率分别提升81.45%和43.19%，信息解码接收器的总速率分别提升77.81%和31.91%。

Conclusion: 所提出的夹持天线系统无线功率传输框架能够有效解决能量收集和信息解码的共存问题，显著提升系统性能，为未来无线通信系统提供了有前景的解决方案。

Abstract: A novel pinching antenna system (PASS) enabled wireless power transfer (WPT) framework is proposed, where energy harvesting receivers (EHRs) and information decoding receivers (IDRs) coexist. By activating pinching antennas (PAs) near both receivers and flexibly adjusting PAs' power radiation ratios, both energy harvesting efficiency and communication quality can be enhanced. A bi-level optimization problem is formulated to overcome the strong coupling between optimization variables. The upper level jointly optimizes transmit beamforming, PA positions, and feasible interval of power radiation ratios for power conversion efficiency (PCE) maximization under rate requirements, while the lower level refines power radiation ratio for the sum rate maximization. Efficient solutions are developed for both two-user and multi-user scenarios. 1) For the two-user case, where an EHR and an IDR coexist, the alternating optimization (AO)-based and weighted minimum mean square error (WMMSE)-based algorithms are developed to achieve the stationary solutions of transmit beamforming, PA positions, and power radiation ratios. 2) For the multi-user case, a quadratic transform-Lagrangian dual transform (QT-LDT) algorithm is proposed to iteratively update PCE and sum rate by optimizing PA positions and power radiation ratios individually. Closed-form solutions are derived for both maximization problems. Numerical simulation results demonstrate that the proposed PASS-WPT framework significantly outperforms conventional MIMO and the baseline PASS with fixed power radiation, which demonstrates that: i) Compared to the conventional MIMO and baseline PASS, the proposed PASS-WPT framework achieves 81.45% and 43.19% improvements in PCE of EHRs, and ii) also increases the sum rate by 77.81% and 31.91% for IDRs.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [36] [Decomposing Direct and Indirect Biases in Linear Models under Demographic Parity Constraint](https://arxiv.org/abs/2511.11294)
*Bertille Tierny,Arthur Charpentier,François Hu*

Main category: stat.ML

TL;DR: 本文提出了一种后处理框架，用于分解线性模型中的人口统计均等约束导致的偏差，将其分为直接（敏感属性）和间接（相关特征）成分，从而提供特征级别的公平性解释。


<details>
  <summary>Details</summary>
Motivation: 线性模型在高风险决策中广泛应用，但引入公平性约束后，其对模型系数的影响以及预测偏差在特征间的分布仍然不透明。现有方法通常依赖强假设或忽视敏感属性的明确作用，限制了公平性评估的实用性。

Method: 扩展了Chzhen和Schreuder（2022）以及Fukuchi和Sakuma（2023）的工作，提出了一种可在任何线性模型上应用的后处理框架，通过解析方法表征人口统计均等如何重塑每个模型系数。

Result: 实验在合成和真实数据集上表明，该方法能够捕捉到先前工作遗漏的公平性动态，为线性模型的责任部署提供了实用且可解释的工具。

Conclusion: 该框架无需重新训练，为模型审计和缓解提供了可操作的见解，实现了对公平性干预的透明、特征级解释，揭示了偏差如何通过相关变量持续存在或转移。

Abstract: Linear models are widely used in high-stakes decision-making due to their simplicity and interpretability. Yet when fairness constraints such as demographic parity are introduced, their effects on model coefficients, and thus on how predictive bias is distributed across features, remain opaque. Existing approaches on linear models often rely on strong and unrealistic assumptions, or overlook the explicit role of the sensitive attribute, limiting their practical utility for fairness assessment. We extend the work of (Chzhen and Schreuder, 2022) and (Fukuchi and Sakuma, 2023) by proposing a post-processing framework that can be applied on top of any linear model to decompose the resulting bias into direct (sensitive-attribute) and indirect (correlated-features) components. Our method analytically characterizes how demographic parity reshapes each model coefficient, including those of both sensitive and non-sensitive features. This enables a transparent, feature-level interpretation of fairness interventions and reveals how bias may persist or shift through correlated variables. Our framework requires no retraining and provides actionable insights for model auditing and mitigation. Experiments on both synthetic and real-world datasets demonstrate that our method captures fairness dynamics missed by prior work, offering a practical and interpretable tool for responsible deployment of linear models.

</details>
