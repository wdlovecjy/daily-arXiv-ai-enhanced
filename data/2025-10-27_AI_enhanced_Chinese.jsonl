{"id": "2510.21630", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2510.21630", "abs": "https://arxiv.org/abs/2510.21630", "authors": ["Forough Mahpouya", "Sabrina Casucci", "Suzanne Sullivan", "Christopher Barrick"], "title": "Representing caregiver burden in observational studies: Development of the Caregiver Burden Index (CareBI) using NSOC", "comment": null, "summary": "Informal caregiving often carries a significant emotional, physical, and\nfinancial toll, yet caregiver burden is often underrepresented in healthcare\nresearch and methods. Existing caregiver burden instruments, while valuable in\nclinical research, often lack compatibility with observational datasets\nregularly used in health services research and planning. This study introduces\nthe Caregiver Burden Index (CareBI) developed for the National Study of\nCaregiving (NSOC), that can be used to represent caregiver burden in\nquantitative models and observational research studies. CareBI was developed\nand validated using a multistep process that included the identification and\npreparation of individual NSOC survey items, exploratory and confirmatory\nfactor analysis, score estimation, interpretation, and external validation. The\nstudy used data from round 12 of the NSOC. CareBI represents three domains of\nburden: objective, subjective, and interpersonal, providing a comprehensive\nview of both the positive and negative aspects of caregiving. It also aligns\nwith the Zarit Burden Interview, a widely used tool for prospectively assessing\ncaregiver burden. Construct validity was assessed by comparing CareBI's\nrelationship with caregiver and care recipient outcomes, as well as sensitivity\nto known burden-related risk and mitigation factors. Early findings affirm the\nscale's utility in categorizing low-, moderate-, and high-burden caregivers and\nguiding resource-oriented strategies. CareBI represents a reproducible tool for\nembedding caregiver metrics into health operations, predictive modeling, and\npublic policy frameworks, and provides a template for applying operations\nresearch and industrial engineering methods to psychosocial measurement\nchallenges in aging and long-term care.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86Caregiver Burden Index (CareBI)\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u89c2\u5bdf\u6027\u7814\u7a76\u7684\u65b0\u578b\u7167\u62a4\u8005\u8d1f\u62c5\u8bc4\u4f30\u5de5\u5177\uff0c\u80fd\u591f\u5168\u9762\u8861\u91cf\u5ba2\u89c2\u3001\u4e3b\u89c2\u548c\u4eba\u9645\u5173\u7cfb\u4e09\u4e2a\u7ef4\u5ea6\u7684\u8d1f\u62c5\u3002", "motivation": "\u73b0\u6709\u7167\u62a4\u8005\u8d1f\u62c5\u8bc4\u4f30\u5de5\u5177\u4e0e\u89c2\u5bdf\u6027\u6570\u636e\u96c6\u4e0d\u517c\u5bb9\uff0c\u5728\u5065\u5eb7\u670d\u52a1\u7814\u7a76\u4e2d\u4ee3\u8868\u6027\u4e0d\u8db3\uff0c\u9700\u8981\u5f00\u53d1\u9002\u7528\u4e8e\u5b9a\u91cf\u6a21\u578b\u548c\u89c2\u5bdf\u6027\u7814\u7a76\u7684\u6807\u51c6\u5316\u5de5\u5177\u3002", "method": "\u91c7\u7528\u591a\u6b65\u9aa4\u5f00\u53d1\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u5305\u62ec\u8bc6\u522bNSOC\u8c03\u67e5\u9879\u76ee\u3001\u63a2\u7d22\u6027\u548c\u9a8c\u8bc1\u6027\u56e0\u5b50\u5206\u6790\u3001\u5206\u6570\u4f30\u8ba1\u3001\u89e3\u91ca\u548c\u5916\u90e8\u9a8c\u8bc1\uff0c\u4f7f\u7528NSOC\u7b2c12\u8f6e\u6570\u636e\u3002", "result": "CareBI\u6210\u529f\u8868\u5f81\u4e86\u7167\u62a4\u8005\u8d1f\u62c5\u7684\u4e09\u4e2a\u7ef4\u5ea6\uff0c\u4e0eZarit Burden Interview\u4fdd\u6301\u4e00\u81f4\uff0c\u80fd\u591f\u6709\u6548\u533a\u5206\u4f4e\u3001\u4e2d\u3001\u9ad8\u8d1f\u62c5\u7167\u62a4\u8005\uff0c\u5e76\u6307\u5bfc\u8d44\u6e90\u5206\u914d\u7b56\u7565\u3002", "conclusion": "CareBI\u4e3a\u5c06\u7167\u62a4\u8005\u6307\u6807\u7eb3\u5165\u5065\u5eb7\u8fd0\u8425\u3001\u9884\u6d4b\u5efa\u6a21\u548c\u516c\u5171\u653f\u7b56\u6846\u67b6\u63d0\u4f9b\u4e86\u53ef\u590d\u5236\u7684\u5de5\u5177\uff0c\u5c55\u793a\u4e86\u8fd0\u7b79\u5b66\u548c\u5de5\u4e1a\u5de5\u7a0b\u65b9\u6cd5\u5728\u8001\u5e74\u7167\u62a4\u5fc3\u7406\u793e\u4f1a\u6d4b\u91cf\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2510.20828", "categories": ["eess.SP", "cs.LG", "stat.CO", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.20828", "abs": "https://arxiv.org/abs/2510.20828", "authors": ["Dixon Vimalajeewa", "Ursula U. Muller", "Brani Vidakovic"], "title": "A Multiscale Approach for Enhancing Weak Signal Detection", "comment": null, "summary": "Stochastic resonance (SR), a phenomenon originally introduced in climate\nmodeling, enhances signal detection by leveraging optimal noise levels within\nnon-linear systems. Traditional SR techniques, mainly based on single-threshold\ndetectors, are limited to signals whose behavior does not depend on time. Often\nlarge amounts of noise are needed to detect weak signals, which can distort\ncomplex signal characteristics. To address these limitations, this study\nexplores multi-threshold systems and the application of SR in multiscale\napplications using wavelet transforms. In the multiscale domain signals can be\nanalyzed at different levels of resolution to better understand the underlying\ndynamics.\n  We propose a double-threshold detection system that integrates two\nsingle-threshold detectors to enhance weak signal detection. We evaluate it\nboth in the original data domain and in the multiscale domain using simulated\nand real-world signals and compare its performance with existing methods.\n  Experimental results demonstrate that, in the original data domain, the\nproposed double-threshold detector significantly improves weak signal detection\ncompared to conventional single-threshold approaches. Its performance is\nfurther improved in the frequency domain, requiring lower noise levels while\noutperforming existing detection systems. This study advances SR-based\ndetection methodologies by introducing a robust approach to weak signal\nidentification, with potential applications in various disciplines.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u9608\u503c\u68c0\u6d4b\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u5408\u4e24\u4e2a\u5355\u9608\u503c\u68c0\u6d4b\u5668\u6765\u589e\u5f3a\u5f31\u4fe1\u53f7\u68c0\u6d4b\u80fd\u529b\uff0c\u5e76\u5728\u539f\u59cb\u6570\u636e\u57df\u548c\u591a\u5c3a\u5ea6\u57df\u8fdb\u884c\u8bc4\u4f30\uff0c\u76f8\u6bd4\u4f20\u7edf\u5355\u9608\u503c\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u968f\u673a\u5171\u632f\u6280\u672f\u4e3b\u8981\u57fa\u4e8e\u5355\u9608\u503c\u68c0\u6d4b\u5668\uff0c\u5c40\u9650\u4e8e\u65f6\u95f4\u65e0\u5173\u4fe1\u53f7\uff0c\u4e14\u9700\u8981\u5927\u91cf\u566a\u58f0\u6765\u68c0\u6d4b\u5f31\u4fe1\u53f7\uff0c\u8fd9\u4f1a\u626d\u66f2\u590d\u6742\u4fe1\u53f7\u7279\u5f81\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u672c\u7814\u7a76\u63a2\u7d22\u591a\u9608\u503c\u7cfb\u7edf\u548c\u5728\u591a\u5c3a\u5ea6\u5e94\u7528\u4e2d\u5e94\u7528\u968f\u673a\u5171\u632f\u3002", "method": "\u63d0\u51fa\u53cc\u9608\u503c\u68c0\u6d4b\u7cfb\u7edf\uff0c\u96c6\u6210\u4e24\u4e2a\u5355\u9608\u503c\u68c0\u6d4b\u5668\uff1b\u5728\u539f\u59cb\u6570\u636e\u57df\u548c\u591a\u5c3a\u5ea6\u57df\uff08\u4f7f\u7528\u5c0f\u6ce2\u53d8\u6362\uff09\u8fdb\u884c\u8bc4\u4f30\uff1b\u4f7f\u7528\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u4fe1\u53f7\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5e76\u4e0e\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5728\u539f\u59cb\u6570\u636e\u57df\u4e2d\uff0c\u53cc\u9608\u503c\u68c0\u6d4b\u5668\u76f8\u6bd4\u4f20\u7edf\u5355\u9608\u503c\u65b9\u6cd5\u663e\u8457\u6539\u5584\u4e86\u5f31\u4fe1\u53f7\u68c0\u6d4b\uff1b\u5728\u9891\u57df\u4e2d\u6027\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\uff0c\u9700\u8981\u66f4\u4f4e\u7684\u566a\u58f0\u6c34\u5e73\u4e14\u4f18\u4e8e\u73b0\u6709\u68c0\u6d4b\u7cfb\u7edf\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u7a33\u5065\u7684\u5f31\u4fe1\u53f7\u8bc6\u522b\u65b9\u6cd5\u63a8\u8fdb\u4e86\u57fa\u4e8e\u968f\u673a\u5171\u632f\u7684\u68c0\u6d4b\u65b9\u6cd5\u5b66\uff0c\u5728\u591a\u4e2a\u5b66\u79d1\u4e2d\u5177\u6709\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.20867", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20867", "abs": "https://arxiv.org/abs/2510.20867", "authors": ["Jiajun Fan", "Roger Ren", "Jingyuan Li", "Rahul Pandey", "Prashanth Gurunath Shivakumar", "Ivan Bulyko", "Ankur Gandhe", "Ge Liu", "Yile Gu"], "title": "Incentivizing Consistent, Effective and Scalable Reasoning Capability in Audio LLMs via Reasoning Process Rewards", "comment": "49 pages", "summary": "The role of reasoning in Audio Large Language Models remains widely\nunderexplored, as introducing a reasoning process often degrades rather than\nimproves performance during inference, a phenomenon we term test-time inverse\nscaling, where longer reasoning chains yield progressively worse results. We\ndemonstrate that this stems not from fundamental limitations of reasoning\nitself, but from inadequate training: models without proper guidance for the\nreasoning process produce hallucinatory, inconsistent reasoning that\naccumulates errors over longer chains. To address these challenges, we\nintroduce CESAR (Consistent, Effective, and Scalable Audio Reasoners), shifting\nfrom outcome verification to rewarding the reasoning process. Our online\nreinforcement learning framework employs Group Relative Policy Optimization\nwith a multi-faceted reward suite that incentivizes not only correctness and\nformat but also consistency, structured analytical patterns, causal reasoning,\ndomain-knowledge integration, and calibrated reasoning depth. CESAR resolves\ntest-time inverse scaling, transforming reasoning from detriments into gains\nwhile revealing model-specific ``reasoning sweet spots\", where performance\npeaks during test-time scaling. We achieve state-of-the-art results on MMAU\nTest-mini, substantially outperforming Gemini 2.5 Pro and GPT-4o Audio, and\nnear-human-level performance on MMSU reasoning tasks. Through AI-as-judge\nevaluations and qualitative comparisons, we provide both quantitative and\nqualitative validation of our improved reasoning quality. Importantly, enhanced\nreasoning creates synergistic effects, simultaneously improving multimodal\nreasoning and perception capabilities. Overall, CESAR establishes a principled\nmethod for developing robust and scalable reasoning in Audio LLMs.", "AI": {"tldr": "CESAR\u901a\u8fc7\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u89e3\u51b3\u97f3\u9891\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u63a8\u7406\u9006\u7f29\u653e\u95ee\u9898\uff0c\u901a\u8fc7\u5956\u52b1\u63a8\u7406\u8fc7\u7a0b\u800c\u975e\u7ed3\u679c\u9a8c\u8bc1\uff0c\u5728MMAU Test-mini\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u7684MMSU\u63a8\u7406\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u97f3\u9891\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u63a8\u7406\u4f5c\u7528\u88ab\u5e7f\u6cdb\u5ffd\u89c6\uff0c\u5f15\u5165\u63a8\u7406\u8fc7\u7a0b\u5f80\u5f80\u5728\u63a8\u7406\u65f6\u964d\u4f4e\u800c\u975e\u63d0\u5347\u6027\u80fd\uff0c\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\u6d4b\u8bd5\u65f6\u9006\u7f29\u653e\uff0c\u5373\u66f4\u957f\u7684\u63a8\u7406\u94fe\u4f1a\u4ea7\u751f\u66f4\u5dee\u7684\u7ed3\u679c\u3002", "method": "\u5f15\u5165CESAR\u6846\u67b6\uff0c\u91c7\u7528\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\uff0c\u4f7f\u7528Group Relative Policy Optimization\u548c\u591a\u65b9\u9762\u5956\u52b1\u5957\u4ef6\uff0c\u6fc0\u52b1\u6b63\u786e\u6027\u3001\u683c\u5f0f\u3001\u4e00\u81f4\u6027\u3001\u7ed3\u6784\u5316\u5206\u6790\u6a21\u5f0f\u3001\u56e0\u679c\u63a8\u7406\u3001\u9886\u57df\u77e5\u8bc6\u6574\u5408\u548c\u6821\u51c6\u63a8\u7406\u6df1\u5ea6\u3002", "result": "\u89e3\u51b3\u4e86\u6d4b\u8bd5\u65f6\u9006\u7f29\u653e\u95ee\u9898\uff0c\u5728MMAU Test-mini\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u7ed3\u679c\uff0c\u663e\u8457\u4f18\u4e8eGemini 2.5 Pro\u548cGPT-4o Audio\uff0c\u5728MMSU\u63a8\u7406\u4efb\u52a1\u4e0a\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u8868\u73b0\u3002", "conclusion": "CESAR\u4e3a\u97f3\u9891\u5927\u8bed\u8a00\u6a21\u578b\u5f00\u53d1\u7a33\u5065\u4e14\u53ef\u6269\u5c55\u7684\u63a8\u7406\u5efa\u7acb\u4e86\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u589e\u5f3a\u7684\u63a8\u7406\u521b\u9020\u4e86\u534f\u540c\u6548\u5e94\uff0c\u540c\u65f6\u6539\u5584\u4e86\u591a\u6a21\u6001\u63a8\u7406\u548c\u611f\u77e5\u80fd\u529b\u3002"}}
{"id": "2510.21278", "categories": ["eess.SP", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.21278", "abs": "https://arxiv.org/abs/2510.21278", "authors": ["Laura M. Wolf", "Vincent Albert Wolff", "Simon Steuernagel", "Kolja Thormann", "Marcus Baum"], "title": "Track-to-Track Association for Collective Perception based on Stochastic Optimization", "comment": null, "summary": "Collective perception is a key aspect for autonomous driving in smart cities\nas it aims to combine the local environment models of multiple intelligent\nvehicles in order to overcome sensor limitations. A crucial part of\nmulti-sensor fusion is track-to-track association. Previous works often suffer\nfrom high computational complexity or are based on heuristics. We propose an\nassociation algorithms based on stochastic optimization, which leverages a\nmultidimensional likelihood incorporating the number of tracks and their\nspatial distribution and furthermore computes several association hypotheses.\nWe demonstrate the effectiveness of our approach in Monte Carlo simulations and\na realistic collective perception scenario computing high-likelihood\nassociations in ambiguous settings.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u968f\u673a\u4f18\u5316\u7684\u8f68\u8ff9\u5173\u8054\u7b97\u6cd5\uff0c\u7528\u4e8e\u667a\u80fd\u8f66\u8f86\u96c6\u4f53\u611f\u77e5\u4e2d\u7684\u591a\u4f20\u611f\u5668\u878d\u5408\uff0c\u901a\u8fc7\u591a\u7ef4\u4f3c\u7136\u51fd\u6570\u548c\u591a\u4e2a\u5173\u8054\u5047\u8bbe\u5904\u7406\u6a21\u7cca\u573a\u666f\u3002", "motivation": "\u89e3\u51b3\u81ea\u52a8\u9a7e\u9a76\u4e2d\u591a\u4f20\u611f\u5668\u878d\u5408\u7684\u8f68\u8ff9\u5173\u8054\u95ee\u9898\uff0c\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u6216\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528\u968f\u673a\u4f18\u5316\u65b9\u6cd5\uff0c\u6784\u5efa\u5305\u542b\u8f68\u8ff9\u6570\u91cf\u548c\u7a7a\u95f4\u5206\u5e03\u7684\u591a\u7ef4\u4f3c\u7136\u51fd\u6570\uff0c\u5e76\u8ba1\u7b97\u591a\u4e2a\u5173\u8054\u5047\u8bbe\u3002", "result": "\u5728\u8499\u7279\u5361\u6d1b\u6a21\u62df\u548c\u5b9e\u9645\u96c6\u4f53\u611f\u77e5\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u5728\u6a21\u7cca\u8bbe\u7f6e\u4e0b\u8ba1\u7b97\u9ad8\u4f3c\u7136\u5173\u8054\u3002", "conclusion": "\u63d0\u51fa\u7684\u968f\u673a\u4f18\u5316\u65b9\u6cd5\u4e3a\u96c6\u4f53\u611f\u77e5\u4e2d\u7684\u8f68\u8ff9\u5173\u8054\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5904\u7406\u590d\u6742\u573a\u666f\u4e2d\u7684\u5173\u8054\u6a21\u7cca\u6027\u3002"}}
{"id": "2510.20861", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20861", "abs": "https://arxiv.org/abs/2510.20861", "authors": ["Krzysztof Siminski"], "title": "Fuzzy numbers revisited: operations on extensional fuzzy numbers", "comment": "33 pages, 62 references", "summary": "Fuzzy numbers are commonly represented with fuzzy sets. Their objective is to\nbetter represent imprecise data. However, operations on fuzzy numbers are not\nas straightforward as maths on crisp numbers. Commonly, the Zadeh's extension\nrule is applied to elaborate a result. This can produce two problems: (1) high\ncomputational complexity and (2) for some fuzzy sets and some operations the\nresults is not a fuzzy set with the same features (eg. multiplication of two\ntriangular fuzzy sets does not produce a triangular fuzzy set). One more\nproblem is the fuzzy spread -- fuzziness of the result increases with the\nnumber of operations. These facts can severely limit the application field of\nfuzzy numbers. In this paper we would like to revisite this problem with a\ndifferent kind of fuzzy numbers -- extensional fuzzy numbers. The paper defines\noperations on extensional fuzzy numbers and relational operators (=, >, >=, <,\n<=) for them. The proposed approach is illustrated with several applicational\nexamples. The C++ implementation is available from a public GitHub repository.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u7cca\u6570\u8868\u793a\u65b9\u6cd5\u2014\u2014\u5916\u5ef6\u6a21\u7cca\u6570\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u6a21\u7cca\u6570\u8fd0\u7b97\u4e2d\u7684\u8ba1\u7b97\u590d\u6742\u6027\u548c\u7ed3\u679c\u7279\u5f81\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u5e76\u5b9a\u4e49\u4e86\u76f8\u5e94\u7684\u8fd0\u7b97\u548c\u5173\u7cfb\u8fd0\u7b97\u7b26\u3002", "motivation": "\u4f20\u7edf\u6a21\u7cca\u6570\u8fd0\u7b97\u5b58\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3001\u8fd0\u7b97\u7ed3\u679c\u53ef\u80fd\u4e0d\u4fdd\u6301\u539f\u7279\u5f81\uff08\u5982\u4e24\u4e2a\u4e09\u89d2\u6a21\u7cca\u6570\u76f8\u4e58\u7ed3\u679c\u4e0d\u662f\u4e09\u89d2\u6a21\u7cca\u6570\uff09\u3001\u6a21\u7cca\u6269\u6563\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u6a21\u7cca\u6570\u7684\u5e94\u7528\u8303\u56f4\u3002", "method": "\u91c7\u7528\u5916\u5ef6\u6a21\u7cca\u6570\u4f5c\u4e3a\u65b0\u7684\u6a21\u7cca\u6570\u8868\u793a\u65b9\u6cd5\uff0c\u5b9a\u4e49\u4e86\u5916\u5ef6\u6a21\u7cca\u6570\u7684\u8fd0\u7b97\uff08\u52a0\u6cd5\u3001\u51cf\u6cd5\u3001\u4e58\u6cd5\u3001\u9664\u6cd5\uff09\u548c\u5173\u7cfb\u8fd0\u7b97\u7b26\uff08\u7b49\u4e8e\u3001\u5927\u4e8e\u3001\u5927\u4e8e\u7b49\u4e8e\u3001\u5c0f\u4e8e\u3001\u5c0f\u4e8e\u7b49\u4e8e\uff09\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u591a\u4e2a\u5e94\u7528\u793a\u4f8b\u8fdb\u884c\u4e86\u8bf4\u660e\uff0c\u5e76\u63d0\u4f9b\u4e86C++\u5b9e\u73b0\u4ee3\u7801\uff0c\u53ef\u4eceGitHub\u516c\u5171\u4ed3\u5e93\u83b7\u53d6\u3002", "conclusion": "\u5916\u5ef6\u6a21\u7cca\u6570\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u4f20\u7edf\u6a21\u7cca\u6570\u8fd0\u7b97\u4e2d\u7684\u95ee\u9898\uff0c\u4e3a\u6a21\u7cca\u6570\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2510.20875", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20875", "abs": "https://arxiv.org/abs/2510.20875", "authors": ["Mihir Panchal", "Ying-Jung Chen", "Surya Parkash"], "title": "CC-GRMAS: A Multi-Agent Graph Neural System for Spatiotemporal Landslide Risk Assessment in High Mountain Asia", "comment": null, "summary": "Landslides are a growing climate induced hazard with severe environmental and\nhuman consequences, particularly in high mountain Asia. Despite increasing\naccess to satellite and temporal datasets, timely detection and disaster\nresponse remain underdeveloped and fragmented. This work introduces CC-GRMAS, a\nframework leveraging a series of satellite observations and environmental\nsignals to enhance the accuracy of landslide forecasting. The system is\nstructured around three interlinked agents Prediction, Planning, and Execution,\nwhich collaboratively enable real time situational awareness, response\nplanning, and intervention. By incorporating local environmental factors and\noperationalizing multi agent coordination, this approach offers a scalable and\nproactive solution for climate resilient disaster preparedness across\nvulnerable mountainous terrains.", "AI": {"tldr": "CC-GRMAS\u662f\u4e00\u4e2a\u5229\u7528\u536b\u661f\u89c2\u6d4b\u548c\u73af\u5883\u4fe1\u53f7\u63d0\u9ad8\u6ed1\u5761\u9884\u6d4b\u51c6\u786e\u6027\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u667a\u80fd\u4f53\uff08\u9884\u6d4b\u3001\u89c4\u5212\u3001\u6267\u884c\uff09\u5b9e\u73b0\u5b9e\u65f6\u6001\u52bf\u611f\u77e5\u3001\u54cd\u5e94\u89c4\u5212\u548c\u5e72\u9884\u3002", "motivation": "\u6ed1\u5761\u662f\u65e5\u76ca\u4e25\u91cd\u7684\u6c14\u5019\u8bf1\u53d1\u707e\u5bb3\uff0c\u7279\u522b\u662f\u5728\u9ad8\u4e9a\u6d32\u5c71\u533a\uff0c\u5c3d\u7ba1\u536b\u661f\u548c\u65f6\u5e8f\u6570\u636e\u83b7\u53d6\u589e\u52a0\uff0c\u4f46\u53ca\u65f6\u68c0\u6d4b\u548c\u707e\u5bb3\u54cd\u5e94\u4ecd\u7136\u4e0d\u53d1\u8fbe\u4e14\u5206\u6563\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u534f\u8c03\u6846\u67b6\uff0c\u6574\u5408\u536b\u661f\u89c2\u6d4b\u548c\u73af\u5883\u4fe1\u53f7\uff0c\u901a\u8fc7\u9884\u6d4b\u3001\u89c4\u5212\u548c\u6267\u884c\u4e09\u4e2a\u667a\u80fd\u4f53\u7684\u534f\u4f5c\u6765\u589e\u5f3a\u6ed1\u5761\u9884\u6d4b\u51c6\u786e\u6027\u3002", "result": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u4e3b\u52a8\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5b9e\u73b0\u5b9e\u65f6\u6001\u52bf\u611f\u77e5\u3001\u54cd\u5e94\u89c4\u5212\u548c\u5e72\u9884\uff0c\u63d0\u9ad8\u6c14\u5019\u97e7\u6027\u707e\u5bb3\u51c6\u5907\u80fd\u529b\u3002", "conclusion": "CC-GRMAS\u901a\u8fc7\u6574\u5408\u672c\u5730\u73af\u5883\u56e0\u7d20\u548c\u64cd\u4f5c\u5316\u591a\u667a\u80fd\u4f53\u534f\u8c03\uff0c\u4e3a\u8106\u5f31\u5c71\u533a\u5730\u5f62\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u548c\u4e3b\u52a8\u7684\u6c14\u5019\u97e7\u6027\u707e\u5bb3\u51c6\u5907\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.21509", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.21509", "abs": "https://arxiv.org/abs/2510.21509", "authors": ["Carmen \u00c1lvarez Roa", "Yunus Can G\u00fcltekin", "Vincent van Vliet", "Menno van den Hout", "Chigo Okonkwo", "Alex Alvarado"], "title": "On Irradiance Distributions for Weakly Turbulent FSO Links: Log-Normal vs. Gamma-Gamma", "comment": null, "summary": "Weak turbulence is commonly modeled using the log-normal distribution. Our\nexperimental results show that this distribution fails to capture irradiance\nfluctuations in this regime. The Gamma-Gamma model is shown to be more\naccurate.", "AI": {"tldr": "\u5b9e\u9a8c\u7814\u7a76\u8868\u660e\uff0c\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u65e0\u6cd5\u51c6\u786e\u63cf\u8ff0\u5f31\u6e4d\u6d41\u6761\u4ef6\u4e0b\u7684\u8f90\u7167\u5ea6\u6ce2\u52a8\uff0c\u800cGamma-Gamma\u6a21\u578b\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u5f31\u6e4d\u6d41\u901a\u5e38\u4f7f\u7528\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u8fdb\u884c\u5efa\u6a21\uff0c\u4f46\u8be5\u6a21\u578b\u5728\u63cf\u8ff0\u8f90\u7167\u5ea6\u6ce2\u52a8\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u5bfb\u627e\u66f4\u51c6\u786e\u7684\u7edf\u8ba1\u6a21\u578b\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u7814\u7a76\uff0c\u6bd4\u8f83\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u548cGamma-Gamma\u6a21\u578b\u5728\u5f31\u6e4d\u6d41\u6761\u4ef6\u4e0b\u5bf9\u8f90\u7167\u5ea6\u6ce2\u52a8\u7684\u62df\u5408\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u65e0\u6cd5\u6355\u6349\u5f31\u6e4d\u6d41\u72b6\u6001\u4e0b\u7684\u8f90\u7167\u5ea6\u6ce2\u52a8\uff0c\u800cGamma-Gamma\u6a21\u578b\u80fd\u591f\u66f4\u51c6\u786e\u5730\u63cf\u8ff0\u8fd9\u4e9b\u6ce2\u52a8\u3002", "conclusion": "\u5728\u5f31\u6e4d\u6d41\u6761\u4ef6\u4e0b\uff0cGamma-Gamma\u6a21\u578b\u6bd4\u4f20\u7edf\u7684\u5bf9\u6570\u6b63\u6001\u5206\u5e03\u66f4\u9002\u5408\u7528\u4e8e\u63cf\u8ff0\u8f90\u7167\u5ea6\u6ce2\u52a8\u7279\u6027\u3002"}}
{"id": "2510.21043", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.21043", "abs": "https://arxiv.org/abs/2510.21043", "authors": ["Benjamin Lange"], "title": "Epistemic Deference to AI", "comment": "12 pages", "summary": "When should we defer to AI outputs over human expert judgment? Drawing on\nrecent work in social epistemology, I motivate the idea that some AI systems\nqualify as Artificial Epistemic Authorities (AEAs) due to their demonstrated\nreliability and epistemic superiority. I then introduce AI Preemptionism, the\nview that AEA outputs should replace rather than supplement a user's\nindependent epistemic reasons. I show that classic objections to preemptionism\n- such as uncritical deference, epistemic entrenchment, and unhinging epistemic\nbases - apply in amplified form to AEAs, given their opacity, self-reinforcing\nauthority, and lack of epistemic failure markers. Against this, I develop a\nmore promising alternative: a total evidence view of AI deference. According to\nthis view, AEA outputs should function as contributory reasons rather than\noutright replacements for a user's independent epistemic considerations. This\napproach has three key advantages: (i) it mitigates expertise atrophy by\nkeeping human users engaged, (ii) it provides an epistemic case for meaningful\nhuman oversight and control, and (iii) it explains the justified mistrust of AI\nwhen reliability conditions are unmet. While demanding in practice, this\naccount offers a principled way to determine when AI deference is justified,\nparticularly in high-stakes contexts requiring rigorous reliability.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4f55\u65f6\u5e94\u8be5\u4f18\u5148\u91c7\u7528AI\u8f93\u51fa\u800c\u975e\u4eba\u7c7b\u4e13\u5bb6\u5224\u65ad\uff0c\u63d0\u51fa\u4e86\u4eba\u5de5\u667a\u80fd\u8ba4\u77e5\u6743\u5a01\uff08AEA\uff09\u6982\u5ff5\u548cAI\u4f18\u5148\u4e3b\u4e49\u89c2\u70b9\uff0c\u4f46\u6307\u51fa\u5176\u5b58\u5728\u8bf8\u591a\u95ee\u9898\uff0c\u6700\u7ec8\u53d1\u5c55\u51fa\u57fa\u4e8e\u5168\u8bc1\u636e\u7684AI\u9075\u4ece\u89c2\u3002", "motivation": "\u7814\u7a76AI\u7cfb\u7edf\u4f55\u65f6\u5e94\u8be5\u88ab\u89c6\u4e3a\u8ba4\u77e5\u6743\u5a01\uff0c\u4ee5\u53ca\u5728\u4ec0\u4e48\u60c5\u51b5\u4e0b\u5e94\u8be5\u4f18\u5148\u91c7\u7528AI\u8f93\u51fa\u800c\u975e\u4eba\u7c7b\u5224\u65ad\uff0c\u89e3\u51b3AI\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u6743\u5a01\u4e4b\u95f4\u7684\u51b2\u7a81\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u793e\u4f1a\u8ba4\u8bc6\u8bba\u7406\u8bba\uff0c\u5206\u6790AI\u4f18\u5148\u4e3b\u4e49\u7684\u7ecf\u5178\u53cd\u5bf9\u610f\u89c1\uff0c\u5e76\u53d1\u5c55\u51fa\u57fa\u4e8e\u5168\u8bc1\u636e\u7684AI\u9075\u4ece\u89c2\uff0c\u5c06AI\u8f93\u51fa\u4f5c\u4e3a\u8d21\u732e\u6027\u7406\u7531\u800c\u975e\u5b8c\u5168\u66ff\u4ee3\u4eba\u7c7b\u72ec\u7acb\u8ba4\u77e5\u8003\u8651\u3002", "result": "\u63d0\u51fa\u4e86\u4e09\u79cd\u5173\u952e\u4f18\u52bf\uff1a\u7f13\u89e3\u4e13\u4e1a\u77e5\u8bc6\u840e\u7f29\u3001\u4e3a\u4eba\u673a\u6709\u610f\u4e49\u7684\u76d1\u7763\u548c\u63a7\u5236\u63d0\u4f9b\u8ba4\u8bc6\u8bba\u57fa\u7840\u3001\u89e3\u91caAI\u5728\u53ef\u9760\u6027\u6761\u4ef6\u672a\u6ee1\u8db3\u65f6\u7684\u5408\u7406\u4e0d\u4fe1\u4efb\u3002", "conclusion": "\u57fa\u4e8e\u5168\u8bc1\u636e\u7684AI\u9075\u4ece\u89c2\u63d0\u4f9b\u4e86\u4e00\u79cd\u539f\u5219\u6027\u65b9\u6cd5\u6765\u786e\u5b9a\u4f55\u65f6AI\u9075\u4ece\u662f\u5408\u7406\u7684\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u4e25\u683c\u53ef\u9760\u6027\u7684\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u3002"}}
{"id": "2510.21093", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21093", "abs": "https://arxiv.org/abs/2510.21093", "authors": ["Siyong Chen", "Jinbo Wen", "Jiawen Kang", "Tenghui Huang", "Xumin Huang", "Yuanjia Su", "Hudan Pan", "Zishao Zhong", "Dusit Niyato", "Shengli Xie", "Dong In Kim"], "title": "MedAlign: A Synergistic Framework of Multimodal Preference Optimization and Federated Meta-Cognitive Reasoning", "comment": null, "summary": "Recently, large models have shown significant potential for smart healthcare.\nHowever, the deployment of Large Vision-Language Models (LVLMs) for clinical\nservices is currently hindered by three critical challenges: a tendency to\nhallucinate answers not grounded in visual evidence, the inefficiency of\nfixed-depth reasoning, and the difficulty of multi-institutional collaboration.\nTo address these challenges, in this paper, we develop MedAlign, a novel\nframework to ensure visually accurate LVLM responses for Medical Visual\nQuestion Answering (Med-VQA). Specifically, we first propose a multimodal\nDirect Preference Optimization (mDPO) objective to explicitly align preference\nlearning with visual context. We then design a Retrieval-Aware\nMixture-of-Experts (RA-MoE) architecture that utilizes image and text\nsimilarity to route queries to a specialized and context-augmented LVLM (i.e.,\nan expert), thereby mitigating hallucinations in LVLMs. To achieve adaptive\nreasoning and facilitate multi-institutional collaboration, we propose a\nfederated governance mechanism, where the selected expert, fine-tuned on\nclinical datasets based on mDPO, locally performs iterative Chain-of-Thought\n(CoT) reasoning via the local meta-cognitive uncertainty estimator. Extensive\nexperiments on three representative Med-VQA datasets demonstrate that MedAlign\nachieves state-of-the-art performance, outperforming strong retrieval-augmented\nbaselines by up to $11.85\\%$ in F1-score, and simultaneously reducing the\naverage reasoning length by $51.60\\%$ compared with fixed-depth CoT approaches.", "AI": {"tldr": "MedAlign\u662f\u4e00\u4e2a\u9488\u5bf9\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u7684\u65b0\u578b\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u76f4\u63a5\u504f\u597d\u4f18\u5316\u3001\u68c0\u7d22\u611f\u77e5\u4e13\u5bb6\u6df7\u5408\u67b6\u6784\u548c\u8054\u90a6\u6cbb\u7406\u673a\u5236\uff0c\u89e3\u51b3\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u670d\u52a1\u4e2d\u7684\u5e7b\u89c9\u3001\u56fa\u5b9a\u63a8\u7406\u6df1\u5ea6\u6548\u7387\u4f4e\u4e0b\u548c\u591a\u673a\u6784\u534f\u4f5c\u56f0\u96be\u7b49\u6311\u6218\u3002", "motivation": "\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u667a\u80fd\u533b\u7597\u9886\u57df\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff1a\u5e7b\u89c9\u56de\u7b54\u503e\u5411\u3001\u56fa\u5b9a\u63a8\u7406\u6df1\u5ea6\u6548\u7387\u4f4e\u4e0b\u4ee5\u53ca\u591a\u673a\u6784\u534f\u4f5c\u56f0\u96be\u3002", "method": "1. \u591a\u6a21\u6001\u76f4\u63a5\u504f\u597d\u4f18\u5316\u76ee\u6807\uff0c\u5c06\u504f\u597d\u5b66\u4e60\u4e0e\u89c6\u89c9\u4e0a\u4e0b\u6587\u663e\u5f0f\u5bf9\u9f50\uff1b2. \u68c0\u7d22\u611f\u77e5\u4e13\u5bb6\u6df7\u5408\u67b6\u6784\uff0c\u5229\u7528\u56fe\u50cf\u548c\u6587\u672c\u76f8\u4f3c\u6027\u5c06\u67e5\u8be2\u8def\u7531\u5230\u4e13\u4e1a\u5316\u7684\u4e0a\u4e0b\u6587\u589e\u5f3aLVLM\u4e13\u5bb6\uff1b3. \u8054\u90a6\u6cbb\u7406\u673a\u5236\uff0c\u57fa\u4e8emDPO\u5728\u4e34\u5e8a\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u7684\u4e13\u5bb6\u901a\u8fc7\u672c\u5730\u5143\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u5668\u6267\u884c\u8fed\u4ee3\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u3002", "result": "\u5728\u4e09\u4e2a\u4ee3\u8868\u6027Med-VQA\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cMedAlign\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u6bd4\u5f3a\u68c0\u7d22\u589e\u5f3a\u57fa\u7ebf\u5728F1\u5206\u6570\u4e0a\u63d0\u9ad8\u4e8611.85%\uff0c\u540c\u65f6\u4e0e\u56fa\u5b9a\u6df1\u5ea6CoT\u65b9\u6cd5\u76f8\u6bd4\u5e73\u5747\u63a8\u7406\u957f\u5ea6\u51cf\u5c11\u4e8651.60%\u3002", "conclusion": "MedAlign\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86LVLM\u5728\u533b\u5b66\u89c6\u89c9\u95ee\u7b54\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u63a8\u7406\u6548\u7387\uff0c\u4e3a\u667a\u80fd\u533b\u7597\u9886\u57df\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2510.20955", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.20955", "abs": "https://arxiv.org/abs/2510.20955", "authors": ["Jeff Pflueger", "Michael Everett"], "title": "Safety Assessment in Reinforcement Learning via Model Predictive Control", "comment": "7 pages, 4 figures", "summary": "Model-free reinforcement learning approaches are promising for control but\ntypically lack formal safety guarantees. Existing methods to shield or\notherwise provide these guarantees often rely on detailed knowledge of the\nsafety specifications. Instead, this work's insight is that many\ndifficult-to-specify safety issues are best characterized by invariance.\nAccordingly, we propose to leverage reversibility as a method for preventing\nthese safety issues throughout the training process. Our method uses\nmodel-predictive path integral control to check the safety of an action\nproposed by a learned policy throughout training. A key advantage of this\napproach is that it only requires the ability to query the black-box dynamics,\nnot explicit knowledge of the dynamics or safety constraints. Experimental\nresults demonstrate that the proposed algorithm successfully aborts before all\nunsafe actions, while still achieving comparable training progress to a\nbaseline PPO approach that is allowed to violate safety.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u53ef\u9006\u6027\u7684\u6a21\u578b\u81ea\u7531\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u578b\u9884\u6d4b\u8def\u5f84\u79ef\u5206\u63a7\u5236\u68c0\u67e5\u5b66\u4e60\u7b56\u7565\u7684\u5b89\u5168\u6027\uff0c\u65e0\u9700\u663e\u5f0f\u52a8\u6001\u6a21\u578b\u6216\u5b89\u5168\u7ea6\u675f\u77e5\u8bc6\u5373\u53ef\u9632\u6b62\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u5b89\u5168\u95ee\u9898\u3002", "motivation": "\u6a21\u578b\u81ea\u7531\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7f3a\u4e4f\u5f62\u5f0f\u5316\u5b89\u5168\u4fdd\u8bc1\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u8be6\u7ec6\u7684\u5b89\u5168\u89c4\u8303\u77e5\u8bc6\u3002\u8bb8\u591a\u96be\u4ee5\u660e\u786e\u89c4\u8303\u7684\u5b89\u5168\u95ee\u9898\u6700\u597d\u901a\u8fc7\u4e0d\u53d8\u6027\u6765\u8868\u5f81\uff0c\u56e0\u6b64\u5229\u7528\u53ef\u9006\u6027\u6765\u9884\u9632\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u5b89\u5168\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u6a21\u578b\u9884\u6d4b\u8def\u5f84\u79ef\u5206\u63a7\u5236\u6765\u68c0\u67e5\u5b66\u4e60\u7b56\u7565\u63d0\u51fa\u7684\u52a8\u4f5c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u5b89\u5168\u6027\u3002\u8be5\u65b9\u6cd5\u53ea\u9700\u8981\u67e5\u8be2\u9ed1\u76d2\u52a8\u6001\u7684\u80fd\u529b\uff0c\u800c\u4e0d\u9700\u8981\u52a8\u6001\u6216\u5b89\u5168\u7ea6\u675f\u7684\u663e\u5f0f\u77e5\u8bc6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u6240\u6709\u4e0d\u5b89\u5168\u52a8\u4f5c\u4e4b\u524d\u6210\u529f\u4e2d\u6b62\uff0c\u540c\u65f6\u4e0e\u5141\u8bb8\u8fdd\u53cd\u5b89\u5168\u6027\u7684\u57fa\u7ebfPPO\u65b9\u6cd5\u76f8\u6bd4\uff0c\u4ecd\u80fd\u5b9e\u73b0\u76f8\u5f53\u7684\u8bad\u7ec3\u8fdb\u5c55\u3002", "conclusion": "\u57fa\u4e8e\u53ef\u9006\u6027\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u9632\u6b62\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u5b89\u5168\u95ee\u9898\uff0c\u4ec5\u9700\u67e5\u8be2\u9ed1\u76d2\u52a8\u6001\u5373\u53ef\u5b9e\u73b0\u5b89\u5168\u4fdd\u8bc1\uff0c\u5728\u4fdd\u6301\u8bad\u7ec3\u6548\u7387\u7684\u540c\u65f6\u786e\u4fdd\u5b89\u5168\u6027\u3002"}}
{"id": "2510.21184", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.21184", "abs": "https://arxiv.org/abs/2510.21184", "authors": ["Stephen Zhao", "Aidan Li", "Rob Brekelmans", "Roger Grosse"], "title": "Reducing the Probability of Undesirable Outputs in Language Models Using Probabilistic Inference", "comment": null, "summary": "Reinforcement learning (RL) has become a predominant technique to align\nlanguage models (LMs) with human preferences or promote outputs which are\ndeemed to be desirable by a given reward function. Standard RL approaches\noptimize average reward, while methods explicitly focused on reducing the\nprobability of undesired outputs typically come at a cost to average-case\nperformance. To improve this tradeoff, we introduce RePULSe, a new training\nmethod that augments the standard RL loss with an additional loss that uses\nlearned proposals to guide sampling low-reward outputs, and then reduces those\noutputs' probability. We run experiments demonstrating that RePULSe produces a\nbetter tradeoff of expected reward versus the probability of undesired outputs\nand is more adversarially robust, compared to standard RL alignment approaches\nand alternatives.", "AI": {"tldr": "RePULSe\u662f\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u589e\u52a0\u989d\u5916\u635f\u5931\u51fd\u6570\u6765\u51cf\u5c11\u4e0d\u826f\u8f93\u51fa\u7684\u6982\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u5e73\u5747\u5956\u52b1\u6027\u80fd\u3002", "motivation": "\u6807\u51c6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f18\u5316\u5e73\u5747\u5956\u52b1\uff0c\u4f46\u51cf\u5c11\u4e0d\u826f\u8f93\u51fa\u6982\u7387\u7684\u65b9\u6cd5\u901a\u5e38\u4f1a\u727a\u7272\u5e73\u5747\u6027\u80fd\u3002\u9700\u8981\u6539\u8fdb\u8fd9\u79cd\u6743\u8861\u5173\u7cfb\u3002", "method": "\u5728\u6807\u51c6RL\u635f\u5931\u57fa\u7840\u4e0a\u589e\u52a0\u989d\u5916\u635f\u5931\uff0c\u4f7f\u7528\u5b66\u4e60\u5230\u7684\u5efa\u8bae\u6765\u5f15\u5bfc\u91c7\u6837\u4f4e\u5956\u52b1\u8f93\u51fa\uff0c\u7136\u540e\u964d\u4f4e\u8fd9\u4e9b\u8f93\u51fa\u7684\u6982\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660eRePULSe\u5728\u671f\u671b\u5956\u52b1\u4e0e\u4e0d\u826f\u8f93\u51fa\u6982\u7387\u4e4b\u95f4\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u6743\u8861\uff0c\u5e76\u4e14\u6bd4\u6807\u51c6RL\u5bf9\u9f50\u65b9\u6cd5\u548c\u66ff\u4ee3\u65b9\u6848\u66f4\u5177\u5bf9\u6297\u9c81\u68d2\u6027\u3002", "conclusion": "RePULSe\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u6539\u5584\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u4e2d\u7684\u6743\u8861\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u826f\u597d\u5e73\u5747\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c11\u4e0d\u826f\u8f93\u51fa\u7684\u6982\u7387\u3002"}}
{"id": "2510.20963", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20963", "abs": "https://arxiv.org/abs/2510.20963", "authors": ["Yongqiang Chen", "Gang Niu", "James Cheng", "Bo Han", "Masashi Sugiyama"], "title": "Towards Scalable Oversight with Collaborative Multi-Agent Debate in Error Detection", "comment": "Preprint, ongoing work", "summary": "Accurate detection of errors in large language models (LLM) responses is\ncentral to the success of scalable oversight, or providing effective\nsupervision to superhuman intelligence. Yet, self-diagnosis is often unreliable\non complex tasks unless aided by reliable external feedback. Multi-agent debate\n(MAD) seems to be a natural alternative to external feedback: multiple LLMs\nprovide complementary perspectives and cross-checks for error detection.\nHowever, prior MAD protocols frame debate as a zero-sum game, where the\ndebaters compete to win the game instead of seeking the truth. Consequently, it\nleads to debate hacking: debaters tend to mislead the judge by misinterpreting\nthe task or presenting overconfident claims, which introduce more mistakes and\nunderperform single-agent methods. To mitigate the issue, we introduce a new\ncollaborative MAD protocol, termed ColMAD, that reframes MAD as a non-zero sum\ngame. Specifically, ColMAD encourages multiple agents to criticize each other\nin a supportive way, such that they can complement the missing points of each\nother. Therefore, the judge agent can make a more informative conclusion based\non more comprehensive evidence. Empirically, we show that ColMAD significantly\noutperforms previous competitive MAD by 19% and brings non-trivial improvements\nover single-agent methods in error detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u534f\u4f5c\u5f0f\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u534f\u8baeColMAD\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u91cd\u65b0\u5b9a\u4e49\u4e3a\u975e\u96f6\u548c\u535a\u5f08\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u7ade\u4e89\u6027\u8fa9\u8bba\u4e2d\u7684\u8fa9\u8bba\u9ed1\u5ba2\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9519\u8bef\u68c0\u6d4b\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u534f\u8bae\u5c06\u8fa9\u8bba\u89c6\u4e3a\u96f6\u548c\u535a\u5f08\uff0c\u5bfc\u81f4\u8fa9\u8bba\u8005\u503e\u5411\u4e8e\u8bef\u5bfc\u6cd5\u5b98\u800c\u975e\u5bfb\u6c42\u771f\u76f8\uff0c\u51fa\u73b0\u8fa9\u8bba\u9ed1\u5ba2\u73b0\u8c61\uff0c\u53cd\u800c\u5f15\u5165\u66f4\u591a\u9519\u8bef\u5e76\u8868\u73b0\u4e0d\u5982\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u534f\u4f5c\u5f0f\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u534f\u8baeColMAD\uff0c\u9f13\u52b1\u591a\u4e2a\u667a\u80fd\u4f53\u4ee5\u652f\u6301\u6027\u65b9\u5f0f\u76f8\u4e92\u6279\u8bc4\uff0c\u4ece\u800c\u76f8\u4e92\u8865\u5145\u7f3a\u5931\u7684\u89c2\u70b9\uff0c\u4f7f\u6cd5\u5b98\u667a\u80fd\u4f53\u80fd\u591f\u57fa\u4e8e\u66f4\u5168\u9762\u7684\u8bc1\u636e\u505a\u51fa\u66f4\u6709\u4fe1\u606f\u91cf\u7684\u7ed3\u8bba\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cColMAD\u5728\u9519\u8bef\u68c0\u6d4b\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u5148\u524d\u7ade\u4e89\u6027\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u65b9\u6cd519%\uff0c\u5e76\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\u5e26\u6765\u4e86\u975e\u5e73\u51e1\u7684\u6539\u8fdb\u3002", "conclusion": "\u534f\u4f5c\u5f0f\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u534f\u8bae\u80fd\u591f\u6709\u6548\u7f13\u89e3\u8fa9\u8bba\u9ed1\u5ba2\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u8fa9\u8bba\u91cd\u65b0\u5b9a\u4e49\u4e3a\u975e\u96f6\u548c\u535a\u5f08\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9519\u8bef\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2510.21314", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.21314", "abs": "https://arxiv.org/abs/2510.21314", "authors": ["Xuan Tang", "Jichu Li", "Difan Zou"], "title": "A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization", "comment": "65 pages, 10 figures", "summary": "The rapid scaling of large language models (LLMs) has made low-precision\ntraining essential for reducing memory, improving efficiency, and enabling\nlarger models and datasets. Existing convergence theories for adaptive\noptimizers, however, assume all components are exact and neglect hardware-aware\nquantization, leaving open the question of why low-precision training remains\neffective. We introduce the first theoretical framework for analyzing the\nconvergence of adaptive optimizers, including Adam and Muon, under\nfloating-point quantization of gradients, weights, and optimizer states (e.g.,\nmoment estimates). Within this framework, we derive convergence rates on smooth\nnon-convex objectives under standard stochastic gradient assumptions,\nexplicitly characterizing how quantization errors from different components\naffect convergence. We show that both algorithms retain rates close to their\nfull-precision counterparts provided mantissa length scales only\nlogarithmically with the number of iterations. Our analysis further reveals\nthat Adam is highly sensitive to weights and second-moment quantization due to\nits reliance on $\\beta_2 \\to 1$, while Muon requires weaker error control and\nis thus potentially more robust. These results narrow the gap between empirical\nsuccess and theoretical understanding of low-precision training methods.\nNumerical experiments on synthetic and real-world data corroborate our theory.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u5206\u6790\u81ea\u9002\u5e94\u4f18\u5316\u5668\u5728\u6d6e\u70b9\u91cf\u5316\u4e0b\u7684\u6536\u655b\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u4e86Adam\u548cMuon\u5728\u4f4e\u7cbe\u5ea6\u8bad\u7ec3\u4e2d\u4ecd\u80fd\u4fdd\u6301\u63a5\u8fd1\u5168\u7cbe\u5ea6\u7684\u6536\u655b\u901f\u7387\uff0c\u6761\u4ef6\u662f\u5c3e\u6570\u957f\u5ea6\u968f\u8fed\u4ee3\u6b21\u6570\u5bf9\u6570\u589e\u957f\u3002", "motivation": "\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\u4f7f\u5f97\u4f4e\u7cbe\u5ea6\u8bad\u7ec3\u5bf9\u4e8e\u51cf\u5c11\u5185\u5b58\u3001\u63d0\u9ad8\u6548\u7387\u4ee5\u53ca\u652f\u6301\u66f4\u5927\u6a21\u578b\u548c\u6570\u636e\u96c6\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u81ea\u9002\u5e94\u4f18\u5316\u5668\u6536\u655b\u7406\u8bba\u5047\u8bbe\u6240\u6709\u7ec4\u4ef6\u90fd\u662f\u7cbe\u786e\u7684\uff0c\u5ffd\u7565\u4e86\u786c\u4ef6\u611f\u77e5\u91cf\u5316\uff0c\u56e0\u6b64\u65e0\u6cd5\u89e3\u91ca\u4e3a\u4ec0\u4e48\u4f4e\u7cbe\u5ea6\u8bad\u7ec3\u4ecd\u7136\u6709\u6548\u3002", "method": "\u5f15\u5165\u9996\u4e2a\u7406\u8bba\u6846\u67b6\u6765\u5206\u6790\u81ea\u9002\u5e94\u4f18\u5316\u5668\uff08\u5305\u62ecAdam\u548cMuon\uff09\u5728\u68af\u5ea6\u3001\u6743\u91cd\u548c\u4f18\u5316\u5668\u72b6\u6001\uff08\u5982\u52a8\u91cf\u4f30\u8ba1\uff09\u7684\u6d6e\u70b9\u91cf\u5316\u4e0b\u7684\u6536\u655b\u6027\u3002\u5728\u6807\u51c6\u968f\u673a\u68af\u5ea6\u5047\u8bbe\u4e0b\uff0c\u63a8\u5bfc\u4e86\u5e73\u6ed1\u975e\u51f8\u76ee\u6807\u4e0a\u7684\u6536\u655b\u901f\u7387\uff0c\u660e\u786e\u8868\u5f81\u4e86\u4e0d\u540c\u7ec4\u4ef6\u7684\u91cf\u5316\u8bef\u5dee\u5982\u4f55\u5f71\u54cd\u6536\u655b\u3002", "result": "\u8bc1\u660e\u4e86\u4e24\u79cd\u7b97\u6cd5\u5728\u5c3e\u6570\u957f\u5ea6\u4ec5\u968f\u8fed\u4ee3\u6b21\u6570\u5bf9\u6570\u589e\u957f\u7684\u60c5\u51b5\u4e0b\uff0c\u90fd\u80fd\u4fdd\u6301\u63a5\u8fd1\u5176\u5168\u7cbe\u5ea6\u5bf9\u5e94\u7269\u7684\u6536\u655b\u901f\u7387\u3002\u5206\u6790\u8fd8\u663e\u793a\uff0cAdam\u5bf9\u6743\u91cd\u548c\u7b2c\u4e8c\u77e9\u91cf\u5316\u9ad8\u5ea6\u654f\u611f\uff0c\u800cMuon\u9700\u8981\u66f4\u5f31\u7684\u8bef\u5dee\u63a7\u5236\uff0c\u56e0\u6b64\u53ef\u80fd\u66f4\u9c81\u68d2\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u7f29\u5c0f\u4e86\u4f4e\u7cbe\u5ea6\u8bad\u7ec3\u65b9\u6cd5\u7684\u7ecf\u9a8c\u6210\u529f\u4e0e\u7406\u8bba\u7406\u89e3\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u4e0a\u7684\u6570\u503c\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u7406\u8bba\u5206\u6790\u3002"}}
{"id": "2510.20970", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20970", "abs": "https://arxiv.org/abs/2510.20970", "authors": ["Jubilee Lee", "Daniele E. Schiavazzi"], "title": "On the accuracy of implicit neural representations for cardiovascular anatomies and hemodynamic fields", "comment": null, "summary": "Implicit neural representations (INRs, also known as neural fields) have\nrecently emerged as a powerful framework for knowledge representation,\nsynthesis, and compression. By encoding fields as continuous functions within\nthe weights and biases of deep neural networks-rather than relying on voxel- or\nmesh-based structured or unstructured representations-INRs offer both\nresolution independence and high memory efficiency. However, their accuracy in\ndomain-specific applications remains insufficiently understood. In this work,\nwe assess the performance of state-of-the-art INRs for compressing hemodynamic\nfields derived from numerical simulations and for representing cardiovascular\nanatomies via signed distance functions. We investigate several strategies to\nmitigate spectral bias, including specialized activation functions, both fixed\nand trainable positional encoding, and linear combinations of nonlinear\nkernels. On realistic, space- and time-varying hemodynamic fields in the\nthoracic aorta, INRs achieved remarkable compression ratios of up to\napproximately 230, with maximum absolute errors of 1 mmHg for pressure and 5-10\ncm/s for velocity, without extensive hyperparameter tuning. Across 48 thoracic\naortic anatomies, the average and maximum absolute anatomical discrepancies\nwere below 0.5 mm and 1.6 mm, respectively. Overall, the SIREN, MFN-Gabor, and\nMHE architectures demonstrated the best performance. Source code and data is\navailable at https://github.com/desResLab/nrf.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc4\u4f30\u4e86\u9690\u5f0f\u795e\u7ecf\u8868\u793a(INRs)\u5728\u8840\u6d41\u52a8\u529b\u5b66\u573a\u538b\u7f29\u548c\u5fc3\u8840\u7ba1\u89e3\u5256\u8868\u793a\u4e2d\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u591a\u79cd\u7b56\u7565\u7f13\u89e3\u8c31\u504f\u5dee\uff0c\u5728\u4e3b\u52a8\u8109\u8840\u6d41\u573a\u4e2d\u5b9e\u73b0\u4e86\u7ea6230\u500d\u7684\u538b\u7f29\u6bd4\uff0c\u89e3\u5256\u8bef\u5dee\u4f4e\u4e8e1.6mm\u3002", "motivation": "\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u4f5c\u4e3a\u5f3a\u5927\u7684\u77e5\u8bc6\u8868\u793a\u6846\u67b6\uff0c\u5728\u7279\u5b9a\u9886\u57df\u5e94\u7528\u4e2d\u7684\u51c6\u786e\u6027\u5c1a\u672a\u5145\u5206\u4e86\u89e3\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5728\u8840\u6d41\u52a8\u529b\u5b66\u573a\u538b\u7f29\u548c\u5fc3\u8840\u7ba1\u89e3\u5256\u8868\u793a\u4e2d\u7684\u6027\u80fd\u3002", "method": "\u7814\u7a76\u4e86\u591a\u79cd\u7f13\u89e3\u8c31\u504f\u5dee\u7684\u7b56\u7565\uff0c\u5305\u62ec\u4e13\u7528\u6fc0\u6d3b\u51fd\u6570\u3001\u56fa\u5b9a\u548c\u53ef\u8bad\u7ec3\u4f4d\u7f6e\u7f16\u7801\u3001\u975e\u7ebf\u6027\u6838\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u5728\u7a7a\u95f4\u548c\u65f6\u95f4\u53d8\u5316\u7684\u4e3b\u4e3b\u52a8\u8109\u8840\u6d41\u573a\u53ca48\u4e2a\u80f8\u8154\u4e3b\u52a8\u8109\u89e3\u5256\u7ed3\u6784\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u5728\u4e3b\u52a8\u8109\u8840\u6d41\u573a\u4e2d\u5b9e\u73b0\u4e86\u7ea6230\u500d\u7684\u538b\u7f29\u6bd4\uff0c\u538b\u529b\u6700\u5927\u7edd\u5bf9\u8bef\u5dee\u4e3a1 mmHg\uff0c\u901f\u5ea6\u8bef\u5dee\u4e3a5-10 cm/s\uff1b\u89e3\u5256\u7ed3\u6784\u5e73\u5747\u548c\u6700\u5927\u7edd\u5bf9\u8bef\u5dee\u5206\u522b\u4f4e\u4e8e0.5mm\u548c1.6mm\u3002SIREN\u3001MFN-Gabor\u548cMHE\u67b6\u6784\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u9690\u5f0f\u795e\u7ecf\u8868\u793a\u5728\u8840\u6d41\u52a8\u529b\u5b66\u573a\u538b\u7f29\u548c\u5fc3\u8840\u7ba1\u89e3\u5256\u8868\u793a\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u5b9e\u73b0\u9ad8\u538b\u7f29\u6bd4\u548c\u4f4e\u8bef\u5dee\uff0c\u4e3a\u533b\u5b66\u56fe\u50cf\u548c\u6a21\u62df\u6570\u636e\u7684\u6709\u6548\u8868\u793a\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.21254", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21254", "abs": "https://arxiv.org/abs/2510.21254", "authors": ["Victoria J. Hodge", "Colin Paterson", "Ibrahim Habli"], "title": "Out-of-Distribution Detection for Safety Assurance of AI and Autonomous Systems", "comment": null, "summary": "The operational capabilities and application domains of AI-enabled autonomous\nsystems have expanded significantly in recent years due to advances in robotics\nand machine learning (ML). Demonstrating the safety of autonomous systems\nrigorously is critical for their responsible adoption but it is challenging as\nit requires robust methodologies that can handle novel and uncertain situations\nthroughout the system lifecycle, including detecting out-of-distribution (OoD)\ndata. Thus, OOD detection is receiving increased attention from the research,\ndevelopment and safety engineering communities. This comprehensive review\nanalyses OOD detection techniques within the context of safety assurance for\nautonomous systems, in particular in safety-critical domains. We begin by\ndefining the relevant concepts, investigating what causes OOD and exploring the\nfactors which make the safety assurance of autonomous systems and OOD detection\nchallenging. Our review identifies a range of techniques which can be used\nthroughout the ML development lifecycle and we suggest areas within the\nlifecycle in which they may be used to support safety assurance arguments. We\ndiscuss a number of caveats that system and safety engineers must be aware of\nwhen integrating OOD detection into system lifecycles. We conclude by outlining\nthe challenges and future work necessary for the safe development and operation\nof autonomous systems across a range of domains and applications.", "AI": {"tldr": "\u672c\u6587\u5bf9\u81ea\u4e3b\u7cfb\u7edf\u4e2dOOD\uff08\u5206\u5e03\u5916\uff09\u68c0\u6d4b\u6280\u672f\u8fdb\u884c\u4e86\u5168\u9762\u7efc\u8ff0\uff0c\u91cd\u70b9\u5206\u6790\u4e86\u5176\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u5b89\u5168\u4fdd\u8bc1\u4e2d\u7684\u5e94\u7528\uff0c\u63a2\u8ba8\u4e86OOD\u68c0\u6d4b\u5728\u6574\u4e2a\u673a\u5668\u5b66\u4e60\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u7684\u4f7f\u7528\u65b9\u6cd5\u548c\u6ce8\u610f\u4e8b\u9879\u3002", "motivation": "\u968f\u7740AI\u81ea\u4e3b\u7cfb\u7edf\u80fd\u529b\u7684\u6269\u5c55\uff0c\u7279\u522b\u662f\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\uff0c\u5982\u4f55\u4e25\u683c\u8bc1\u660e\u5176\u5b89\u5168\u6027\u6210\u4e3a\u91cd\u8981\u6311\u6218\u3002OOD\u68c0\u6d4b\u4f5c\u4e3a\u5904\u7406\u7cfb\u7edf\u751f\u547d\u5468\u671f\u4e2d\u65b0\u9896\u548c\u4e0d\u786e\u5b9a\u60c5\u51b5\u7684\u5173\u952e\u6280\u672f\uff0c\u53d7\u5230\u7814\u7a76\u754c\u548c\u5de5\u7a0b\u754c\u7684\u5e7f\u6cdb\u5173\u6ce8\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u9996\u5148\u5b9a\u4e49\u76f8\u5173\u6982\u5ff5\uff0c\u5206\u6790OOD\u4ea7\u751f\u539f\u56e0\uff0c\u63a2\u8ba8\u81ea\u4e3b\u7cfb\u7edf\u5b89\u5168\u4fdd\u8bc1\u548cOOD\u68c0\u6d4b\u9762\u4e34\u7684\u6311\u6218\u56e0\u7d20\uff0c\u8bc6\u522b\u53ef\u7528\u4e8e\u6574\u4e2aML\u5f00\u53d1\u751f\u547d\u5468\u671f\u7684\u6280\u672f\u8303\u56f4\u3002", "result": "\u8bc6\u522b\u4e86\u4e00\u7cfb\u5217\u53ef\u5728ML\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e0d\u540c\u9636\u6bb5\u4f7f\u7528\u7684OOD\u68c0\u6d4b\u6280\u672f\uff0c\u5e76\u63d0\u51fa\u4e86\u8fd9\u4e9b\u6280\u672f\u5728\u652f\u6301\u5b89\u5168\u4fdd\u8bc1\u8bba\u8bc1\u4e2d\u7684\u5177\u4f53\u5e94\u7528\u573a\u666f\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u7cfb\u7edf\u5de5\u7a0b\u5e08\u5728\u96c6\u6210OOD\u68c0\u6d4b\u65f6\u9700\u8981\u6ce8\u610f\u7684\u6ce8\u610f\u4e8b\u9879\u3002", "conclusion": "\u6982\u8ff0\u4e86\u81ea\u4e3b\u7cfb\u7edf\u5b89\u5168\u5f00\u53d1\u548c\u8fd0\u8425\u9762\u4e34\u7684\u6311\u6218\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5f3a\u8c03\u4e86OOD\u68c0\u6d4b\u5728\u786e\u4fdd\u81ea\u4e3b\u7cfb\u7edf\u5b89\u5168\u8fd0\u884c\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.21491", "categories": ["cs.LG", "cs.DC", "stat.ML", "68T07, 68W15, 62M10", "I.2.6; I.2.7; I.5.1; I.5.4"], "pdf": "https://arxiv.org/pdf/2510.21491", "abs": "https://arxiv.org/abs/2510.21491", "authors": ["Khaled Hallak", "Oudom Kem"], "title": "Benchmarking Catastrophic Forgetting Mitigation Methods in Federated Time Series Forecasting", "comment": "Accepted for presentation at the FLTA 2025 Conference on Federated\n  Learning. This version corresponds to the camera-ready author manuscript", "summary": "Catastrophic forgetting (CF) poses a persistent challenge in continual\nlearning (CL), especially within federated learning (FL) environments\ncharacterized by non-i.i.d. time series data. While existing research has\nlargely focused on classification tasks in vision domains, the regression-based\nforecasting setting prevalent in IoT and edge applications remains\nunderexplored. In this paper, we present the first benchmarking framework\ntailored to investigate CF in federated continual time series forecasting.\nUsing the Beijing Multi-site Air Quality dataset across 12 decentralized\nclients, we systematically evaluate several CF mitigation strategies, including\nReplay, Elastic Weight Consolidation, Learning without Forgetting, and Synaptic\nIntelligence. Key contributions include: (i) introducing a new benchmark for CF\nin time series FL, (ii) conducting a comprehensive comparative analysis of\nstate-of-the-art methods, and (iii) releasing a reproducible open-source\nframework. This work provides essential tools and insights for advancing\ncontinual learning in federated time-series forecasting systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u9488\u5bf9\u8054\u90a6\u6301\u7eed\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u7684\u57fa\u51c6\u6846\u67b6\uff0c\u572812\u4e2a\u5206\u6563\u5ba2\u6237\u7aef\u4e0a\u7cfb\u7edf\u8bc4\u4f30\u4e86\u591a\u79cd\u7f13\u89e3\u7b56\u7565\uff0c\u4e3a\u8054\u90a6\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7cfb\u7edf\u7684\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u548c\u89c1\u89e3\u3002", "motivation": "\u707e\u96be\u6027\u9057\u5fd8\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u662f\u4e00\u4e2a\u6301\u7eed\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5177\u6709\u975e\u72ec\u7acb\u540c\u5206\u5e03\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u89c6\u89c9\u9886\u57df\u7684\u5206\u7c7b\u4efb\u52a1\uff0c\u800c\u7269\u8054\u7f51\u548c\u8fb9\u7f18\u5e94\u7528\u4e2d\u666e\u904d\u5b58\u5728\u7684\u57fa\u4e8e\u56de\u5f52\u7684\u9884\u6d4b\u8bbe\u7f6e\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4f7f\u7528\u5317\u4eac\u591a\u7ad9\u70b9\u7a7a\u6c14\u8d28\u91cf\u6570\u636e\u96c6\uff0c\u572812\u4e2a\u5206\u6563\u5ba2\u6237\u7aef\u4e0a\u7cfb\u7edf\u8bc4\u4f30\u4e86\u591a\u79cd\u707e\u96be\u6027\u9057\u5fd8\u7f13\u89e3\u7b56\u7565\uff0c\u5305\u62ec\u56de\u653e\u3001\u5f39\u6027\u6743\u91cd\u5de9\u56fa\u3001\u65e0\u9057\u5fd8\u5b66\u4e60\u548c\u7a81\u89e6\u667a\u80fd\u7b49\u65b9\u6cd5\u3002", "result": "\u5efa\u7acb\u4e86\u9996\u4e2a\u9488\u5bf9\u8054\u90a6\u6301\u7eed\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u707e\u96be\u6027\u9057\u5fd8\u7684\u57fa\u51c6\uff0c\u5e76\u5bf9\u6700\u5148\u8fdb\u65b9\u6cd5\u8fdb\u884c\u4e86\u5168\u9762\u7684\u6bd4\u8f83\u5206\u6790\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u63a8\u8fdb\u8054\u90a6\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7cfb\u7edf\u4e2d\u7684\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u5de5\u5177\u548c\u89c1\u89e3\uff0c\u5305\u62ec\u65b0\u7684\u57fa\u51c6\u6846\u67b6\u3001\u6bd4\u8f83\u5206\u6790\u7ed3\u679c\u548c\u53ef\u590d\u73b0\u7684\u5f00\u6e90\u6846\u67b6\u3002"}}
{"id": "2510.21275", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21275", "abs": "https://arxiv.org/abs/2510.21275", "authors": ["Robin Schm\u00f6cker", "Christoph Schnell", "Alexander Dockhorn"], "title": "Investigating Scale Independent UCT Exploration Factor Strategies", "comment": null, "summary": "The Upper Confidence Bounds For Trees (UCT) algorithm is not agnostic to the\nreward scale of the game it is applied to. For zero-sum games with the sparse\nrewards of $\\{-1,0,1\\}$ at the end of the game, this is not a problem, but many\ngames often feature dense rewards with hand-picked reward scales, causing a\nnode's Q-value to span different magnitudes across different games. In this\npaper, we evaluate various strategies for adaptively choosing the UCT\nexploration constant $\\lambda$, called $\\lambda$-strategies, that are agnostic\nto the game's reward scale. These $\\lambda$-strategies include those proposed\nin the literature as well as five new strategies. Given our experimental\nresults, we recommend using one of our newly suggested $\\lambda$-strategies,\nwhich is to choose $\\lambda$ as $2 \\cdot \\sigma$ where $\\sigma$ is the\nempirical standard deviation of all state-action pairs' Q-values of the search\ntree. This method outperforms existing $\\lambda$-strategies across a wide range\nof tasks both in terms of a single parameter value and the peak performances\nobtained by optimizing all available parameters.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u591a\u79cdUCT\u7b97\u6cd5\u4e2d\u81ea\u9002\u5e94\u9009\u62e9\u63a2\u7d22\u5e38\u6570\u03bb\u7684\u7b56\u7565\uff0c\u63a8\u8350\u4f7f\u7528\u65b0\u63d0\u51fa\u7684\u03bb=2\u03c3\u65b9\u6cd5\uff0c\u5176\u4e2d\u03c3\u662f\u641c\u7d22\u6811\u4e2d\u6240\u6709\u72b6\u6001-\u52a8\u4f5c\u5bf9Q\u503c\u7684\u7ecf\u9a8c\u6807\u51c6\u5dee\u3002", "motivation": "UCT\u7b97\u6cd5\u5bf9\u6e38\u620f\u5956\u52b1\u5c3a\u5ea6\u4e0d\u9c81\u68d2\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u7a00\u758f\u5956\u52b1\u6e38\u620f\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5177\u6709\u5bc6\u96c6\u5956\u52b1\u548c\u624b\u52a8\u8bbe\u5b9a\u5956\u52b1\u5c3a\u5ea6\u7684\u6e38\u620f\u4e2d\uff0cQ\u503c\u4f1a\u8de8\u8d8a\u4e0d\u540c\u6570\u91cf\u7ea7\uff0c\u5bfc\u81f4\u6027\u80fd\u95ee\u9898\u3002", "method": "\u8bc4\u4f30\u4e86\u6587\u732e\u4e2d\u63d0\u51fa\u7684\u03bb\u7b56\u7565\u4ee5\u53ca\u4e94\u79cd\u65b0\u7b56\u7565\uff0c\u5305\u62ec\u9009\u62e9\u03bb\u4f5c\u4e3aQ\u503c\u7ecf\u9a8c\u6807\u51c6\u5dee\u7684\u51fd\u6570\u7b49\u65b9\u6cd5\u3002", "result": "\u65b0\u63d0\u51fa\u7684\u03bb=2\u03c3\u7b56\u7565\u5728\u5e7f\u6cdb\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u03bb\u7b56\u7565\uff0c\u65e0\u8bba\u662f\u4f7f\u7528\u5355\u4e00\u53c2\u6570\u503c\u8fd8\u662f\u4f18\u5316\u6240\u6709\u53ef\u7528\u53c2\u6570\u65f6\u7684\u5cf0\u503c\u6027\u80fd\u3002", "conclusion": "\u63a8\u8350\u4f7f\u7528\u03bb=2\u03c3\u4f5c\u4e3aUCT\u7b97\u6cd5\u7684\u63a2\u7d22\u5e38\u6570\u9009\u62e9\u7b56\u7565\uff0c\u8be5\u65b9\u6cd5\u5bf9\u6e38\u620f\u5956\u52b1\u5c3a\u5ea6\u5177\u6709\u9c81\u68d2\u6027\u4e14\u6027\u80fd\u4f18\u8d8a\u3002"}}
{"id": "2510.20985", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20985", "abs": "https://arxiv.org/abs/2510.20985", "authors": ["Chao Wang", "Zhizhao Wen", "Ruoxin Zhang", "Puyang Xu", "Yifan Jiang"], "title": "GPU Memory Requirement Prediction for Deep Learning Task Based on Bidirectional Gated Recurrent Unit Optimization Transformer", "comment": null, "summary": "In response to the increasingly critical demand for accurate prediction of\nGPU memory resources in deep learning tasks, this paper deeply analyzes the\ncurrent research status and innovatively proposes a deep learning model that\nintegrates bidirectional gated recurrent units (BiGRU) to optimize the\nTransformer architecture, aiming to improve the accuracy of memory demand\nprediction. To verify the effectiveness of the model, a carefully designed\ncomparative experiment was conducted, selecting four representative basic\nmachine learning models: decision tree, random forest, Adaboost, and XGBoost as\nbenchmarks. The detailed experimental results show that the BiGRU Transformer\noptimization model proposed in this paper exhibits significant advantages in\nkey evaluation indicators: in terms of mean square error (MSE) and root mean\nsquare error (RMSE), the model achieves the lowest value among all comparison\nmodels, and its predicted results have the smallest deviation from the actual\nvalues; In terms of mean absolute error (MAE) and coefficient of determination\n(R2) indicators, the model also performs well and the results are balanced and\nstable, with comprehensive predictive performance far exceeding the benchmark\nmachine learning methods compared. In summary, the Transformer model based on\nbidirectional gated recurrent unit optimization successfully constructed in\nthis study can efficiently and accurately complete GPU memory demand prediction\ntasks in deep learning tasks, and its prediction accuracy has been\nsignificantly improved compared to traditional machine learning methods. This\nresearch provides strong technical support and reliable theoretical basis for\noptimizing resource scheduling and management of deep learning tasks, and\nimproving the utilization efficiency of computing clusters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u53cc\u5411\u95e8\u63a7\u5faa\u73af\u5355\u5143(BiGRU)\u6765\u4f18\u5316Transformer\u67b6\u6784\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u63d0\u9ad8GPU\u5185\u5b58\u9700\u6c42\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u6a21\u578b\u5728MSE\u3001RMSE\u3001MAE\u548cR2\u7b49\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u51b3\u7b56\u6811\u3001\u968f\u673a\u68ee\u6797\u3001Adaboost\u548cXGBoost\u7b49\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u6ee1\u8db3\u6df1\u5ea6\u5b66\u4e60\u4efb\u52a1\u4e2d\u5bf9GPU\u5185\u5b58\u8d44\u6e90\u51c6\u786e\u9884\u6d4b\u7684\u8feb\u5207\u9700\u6c42\uff0c\u89e3\u51b3\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u5185\u5b58\u9700\u6c42\u9884\u6d4b\u7cbe\u5ea6\u4e0a\u7684\u4e0d\u8db3\u3002", "method": "\u521b\u65b0\u6027\u5730\u63d0\u51fa\u5c06\u53cc\u5411\u95e8\u63a7\u5faa\u73af\u5355\u5143(BiGRU)\u96c6\u6210\u5230Transformer\u67b6\u6784\u4e2d\uff0c\u6784\u5efaBiGRU Transformer\u4f18\u5316\u6a21\u578b\uff0c\u5e76\u4e0e\u56db\u79cd\u57fa\u51c6\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "BiGRU Transformer\u6a21\u578b\u5728\u6240\u6709\u5bf9\u6bd4\u6a21\u578b\u4e2d\u53d6\u5f97\u4e86\u6700\u4f4e\u7684MSE\u548cRMSE\u503c\uff0c\u5728MAE\u548cR2\u6307\u6807\u4e0a\u4e5f\u8868\u73b0\u4f18\u5f02\uff0c\u9884\u6d4b\u6027\u80fd\u5168\u9762\u8d85\u8d8a\u57fa\u51c6\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8eBiGRU\u4f18\u5316\u7684Transformer\u6a21\u578b\u80fd\u591f\u9ad8\u6548\u51c6\u786e\u5730\u5b8c\u6210\u6df1\u5ea6\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684GPU\u5185\u5b58\u9700\u6c42\u9884\u6d4b\uff0c\u76f8\u6bd4\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u7cbe\u5ea6\uff0c\u4e3a\u4f18\u5316\u6df1\u5ea6\u5b66\u4e60\u4efb\u52a1\u8d44\u6e90\u8c03\u5ea6\u548c\u7ba1\u7406\u63d0\u4f9b\u4e86\u6280\u672f\u652f\u6301\u548c\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2510.21631", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.21631", "abs": "https://arxiv.org/abs/2510.21631", "authors": ["Faisal Hamman", "Pasan Dissanayake", "Yanjun Fu", "Sanghamitra Dutta"], "title": "Few-Shot Knowledge Distillation of LLMs With Counterfactual Explanations", "comment": "NeurIPS 2025", "summary": "Knowledge distillation is a promising approach to transfer capabilities from\ncomplex teacher models to smaller, resource-efficient student models that can\nbe deployed easily, particularly in task-aware scenarios. However, existing\nmethods of task-aware distillation typically require substantial quantities of\ndata which may be unavailable or expensive to obtain in many practical\nscenarios. In this paper, we address this challenge by introducing a novel\nstrategy called Counterfactual-explanation-infused Distillation CoD for\nfew-shot task-aware knowledge distillation by systematically infusing\ncounterfactual explanations. Counterfactual explanations (CFEs) refer to inputs\nthat can flip the output prediction of the teacher model with minimum\nperturbation. Our strategy CoD leverages these CFEs to precisely map the\nteacher's decision boundary with significantly fewer samples. We provide\ntheoretical guarantees for motivating the role of CFEs in distillation, from\nboth statistical and geometric perspectives. We mathematically show that CFEs\ncan improve parameter estimation by providing more informative examples near\nthe teacher's decision boundary. We also derive geometric insights on how CFEs\neffectively act as knowledge probes, helping the students mimic the teacher's\ndecision boundaries more effectively than standard data. We perform experiments\nacross various datasets and LLMs to show that CoD outperforms standard\ndistillation approaches in few-shot regimes (as low as 8-512 samples). Notably,\nCoD only uses half of the original samples used by the baselines, paired with\ntheir corresponding CFEs and still improves performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCoD\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u589e\u5f3a\u84b8\u998f\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5c0f\u6837\u672c\u4efb\u52a1\u611f\u77e5\u77e5\u8bc6\u84b8\u998f\u4e2d\u7684\u6570\u636e\u4e0d\u8db3\u95ee\u9898\uff0c\u901a\u8fc7\u5229\u7528\u53cd\u4e8b\u5b9e\u89e3\u91ca\u6765\u7cbe\u786e\u6620\u5c04\u6559\u5e08\u6a21\u578b\u7684\u51b3\u7b56\u8fb9\u754c\u3002", "motivation": "\u73b0\u6709\u4efb\u52a1\u611f\u77e5\u84b8\u998f\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6570\u636e\uff0c\u4f46\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u6570\u636e\u53ef\u80fd\u7a00\u7f3a\u6216\u83b7\u53d6\u6210\u672c\u9ad8\u6602\u3002", "method": "CoD\u7b56\u7565\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u6ce8\u5165\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff08CFEs\uff09\u6765\u8fdb\u884c\u5c0f\u6837\u672c\u4efb\u52a1\u611f\u77e5\u77e5\u8bc6\u84b8\u998f\uff0c\u5229\u7528\u80fd\u591f\u4ee5\u6700\u5c0f\u6270\u52a8\u7ffb\u8f6c\u6559\u5e08\u6a21\u578b\u9884\u6d4b\u7684\u8f93\u5165\u6765\u7cbe\u786e\u6620\u5c04\u51b3\u7b56\u8fb9\u754c\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548cLLM\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCoD\u5728\u5c0f\u6837\u672c\u573a\u666f\uff08\u4f4e\u81f38-512\u4e2a\u6837\u672c\uff09\u4e2d\u4f18\u4e8e\u6807\u51c6\u84b8\u998f\u65b9\u6cd5\uff0c\u4ec5\u4f7f\u7528\u57fa\u7ebf\u65b9\u6cd5\u4e00\u534a\u7684\u539f\u59cb\u6837\u672c\u53ca\u5176\u5bf9\u5e94\u7684CFEs\u4ecd\u80fd\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "CoD\u65b9\u6cd5\u901a\u8fc7\u53cd\u4e8b\u5b9e\u89e3\u91ca\u6709\u6548\u89e3\u51b3\u4e86\u5c0f\u6837\u672c\u77e5\u8bc6\u84b8\u998f\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u7edf\u8ba1\u548c\u51e0\u4f55\u7406\u8bba\u4fdd\u8bc1\uff0c\u8bc1\u660e\u4e86CFEs\u5728\u6539\u5584\u53c2\u6570\u4f30\u8ba1\u548c\u51b3\u7b56\u8fb9\u754c\u6a21\u4eff\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.21293", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.21293", "abs": "https://arxiv.org/abs/2510.21293", "authors": ["Siddharth Mehrotra", "Jin Huang", "Xuelong Fu", "Roel Dobbe", "Clara I. S\u00e1nchez", "Maarten de Rijke"], "title": "Understanding AI Trustworthiness: A Scoping Review of AIES & FAccT Articles", "comment": "Submitted to Journal of Artificial Intelligence Research (JAIR)", "summary": "Background: Trustworthy AI serves as a foundational pillar for two major AI\nethics conferences: AIES and FAccT. However, current research often adopts\ntechno-centric approaches, focusing primarily on technical attributes such as\nreliability, robustness, and fairness, while overlooking the sociotechnical\ndimensions critical to understanding AI trustworthiness in real-world contexts.\n  Objectives: This scoping review aims to examine how the AIES and FAccT\ncommunities conceptualize, measure, and validate AI trustworthiness,\nidentifying major gaps and opportunities for advancing a holistic understanding\nof trustworthy AI systems.\n  Methods: We conduct a scoping review of AIES and FAccT conference proceedings\nto date, systematically analyzing how trustworthiness is defined,\noperationalized, and applied across different research domains. Our analysis\nfocuses on conceptualization approaches, measurement methods, verification and\nvalidation techniques, application areas, and underlying values.\n  Results: While significant progress has been made in defining technical\nattributes such as transparency, accountability, and robustness, our findings\nreveal critical gaps. Current research often predominantly emphasizes technical\nprecision at the expense of social and ethical considerations. The\nsociotechnical nature of AI systems remains less explored and trustworthiness\nemerges as a contested concept shaped by those with the power to define it.\n  Conclusions: An interdisciplinary approach combining technical rigor with\nsocial, cultural, and institutional considerations is essential for advancing\ntrustworthy AI. We propose actionable measures for the AI ethics community to\nadopt holistic frameworks that genuinely address the complex interplay between\nAI systems and society, ultimately promoting responsible technological\ndevelopment that benefits all stakeholders.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u8303\u56f4\u7efc\u8ff0\u5206\u6790\u4e86AIES\u548cFAccT\u4f1a\u8bae\u4e2d\u5173\u4e8e\u53ef\u4fe1AI\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u53d1\u73b0\u5f53\u524d\u7814\u7a76\u8fc7\u4e8e\u4fa7\u91cd\u6280\u672f\u5c5e\u6027\u800c\u5ffd\u89c6\u793e\u4f1a\u6280\u672f\u7ef4\u5ea6\uff0c\u63d0\u51fa\u4e86\u7ed3\u5408\u6280\u672f\u4e25\u8c28\u6027\u4e0e\u793e\u4f1a\u6587\u5316\u56e0\u7d20\u7684\u8de8\u5b66\u79d1\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u53ef\u4fe1AI\u7814\u7a76\u4e3b\u8981\u91c7\u7528\u6280\u672f\u4e2d\u5fc3\u65b9\u6cd5\uff0c\u8fc7\u5ea6\u5173\u6ce8\u53ef\u9760\u6027\u3001\u9c81\u68d2\u6027\u548c\u516c\u5e73\u6027\u7b49\u6280\u672f\u5c5e\u6027\uff0c\u800c\u5ffd\u89c6\u4e86\u7406\u89e3\u771f\u5b9e\u4e16\u754c\u73af\u5883\u4e2dAI\u53ef\u4fe1\u5ea6\u6240\u9700\u7684\u793e\u4f1a\u6280\u672f\u7ef4\u5ea6\u3002", "method": "\u5bf9AIES\u548cFAccT\u4f1a\u8bae\u8bba\u6587\u96c6\u8fdb\u884c\u8303\u56f4\u7efc\u8ff0\uff0c\u7cfb\u7edf\u5206\u6790\u53ef\u4fe1\u5ea6\u5728\u4e0d\u540c\u7814\u7a76\u9886\u57df\u4e2d\u7684\u5b9a\u4e49\u3001\u64cd\u4f5c\u5316\u548c\u5e94\u7528\u65b9\u5f0f\uff0c\u91cd\u70b9\u5173\u6ce8\u6982\u5ff5\u5316\u65b9\u6cd5\u3001\u6d4b\u91cf\u65b9\u6cd5\u3001\u9a8c\u8bc1\u6280\u672f\u3001\u5e94\u7528\u9886\u57df\u548c\u57fa\u7840\u4ef7\u503c\u89c2\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u867d\u7136\u900f\u660e\u5ea6\u3001\u95ee\u8d23\u5236\u548c\u9c81\u68d2\u6027\u7b49\u6280\u672f\u5c5e\u6027\u7684\u5b9a\u4e49\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5f53\u524d\u7814\u7a76\u5f80\u5f80\u8fc7\u5ea6\u5f3a\u8c03\u6280\u672f\u7cbe\u5ea6\u800c\u727a\u7272\u793e\u4f1a\u4f26\u7406\u8003\u91cf\u3002AI\u7cfb\u7edf\u7684\u793e\u4f1a\u6280\u672f\u6027\u8d28\u4ecd\u8f83\u5c11\u88ab\u63a2\u7d22\uff0c\u53ef\u4fe1\u5ea6\u6210\u4e3a\u7531\u6709\u6743\u5b9a\u4e49\u8005\u5851\u9020\u7684\u4e89\u8bae\u6027\u6982\u5ff5\u3002", "conclusion": "\u7ed3\u5408\u6280\u672f\u4e25\u8c28\u6027\u4e0e\u793e\u4f1a\u3001\u6587\u5316\u548c\u5236\u5ea6\u8003\u91cf\u7684\u8de8\u5b66\u79d1\u65b9\u6cd5\u5bf9\u4e8e\u63a8\u8fdb\u53ef\u4fe1AI\u81f3\u5173\u91cd\u8981\u3002\u4f5c\u8005\u4e3aAI\u4f26\u7406\u793e\u533a\u63d0\u51fa\u4e86\u53ef\u64cd\u4f5c\u63aa\u65bd\uff0c\u4ee5\u91c7\u7528\u771f\u6b63\u89e3\u51b3AI\u7cfb\u7edf\u4e0e\u793e\u4f1a\u590d\u6742\u4e92\u52a8\u7684\u6574\u4f53\u6846\u67b6\uff0c\u6700\u7ec8\u4fc3\u8fdb\u60e0\u53ca\u6240\u6709\u5229\u76ca\u76f8\u5173\u8005\u7684\u8d1f\u8d23\u4efb\u6280\u672f\u53d1\u5c55\u3002"}}
{"id": "2510.21019", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.21019", "abs": "https://arxiv.org/abs/2510.21019", "authors": ["Wanhao Yu", "Zheng Wang", "Shuteng Niu", "Sen Lin", "Li Yang"], "title": "More Than Memory Savings: Zeroth-Order Optimization Mitigates Forgetting in Continual Learning", "comment": null, "summary": "Zeroth-order (ZO) optimization has gained attention as a memory-efficient\nalternative to first-order (FO) methods, particularly in settings where\ngradient computation is expensive or even impractical. Beyond its memory\nefficiency, in this work, we investigate ZO optimization for continual learning\n(CL) as a novel approach to address the plasticity-stability-efficiency\ntrilemma. Through theoretical analysis and empirical evidence, we show that ZO\noptimization naturally leads to flatter loss landscapes, which in turn reduce\nforgetting in CL. However, this stability comes at a cost of plasticity: due to\nits imprecise gradient estimates and slower convergence, ZO optimization tends\nto be less effective than FO in acquiring new task-specific knowledge,\nparticularly under constrained training budgets. To better understand this\ntrade-off, we conduct a holistic evaluation of ZO optimization applied to\nvarious existing CL methods. Our findings reveal that ZO optimization enhances\nstability but often undermines plasticity, particularly when used with\nlearnable classifiers. Motivated by this insight, we propose ZO-FC, a simple\nbut effective approach that applies ZO optimization to a single adapter-based\nPEFT module with FO optimized classifier. This design leverages the stability\nbenefits of ZO while preserving the adaptability of FO updates with negligible\nmemory overhead. Experiments demonstrate that ZO-FC achieves an effective\nbalance between stability and plasticity, offering a practical and\nmemory-efficient solution for on-device CL.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u96f6\u9636\u4f18\u5316\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u5b83\u80fd\u901a\u8fc7\u4ea7\u751f\u66f4\u5e73\u5766\u7684\u635f\u5931\u666f\u89c2\u6765\u51cf\u5c11\u9057\u5fd8\uff0c\u4f46\u4f1a\u727a\u7272\u53ef\u5851\u6027\u3002\u4f5c\u8005\u63d0\u51faZO-FC\u65b9\u6cd5\uff0c\u7ed3\u5408\u96f6\u9636\u4f18\u5316\u7684\u7a33\u5b9a\u6027\u548c\u4e00\u9636\u4f18\u5316\u7684\u9002\u5e94\u6027\uff0c\u5b9e\u73b0\u4e86\u5185\u5b58\u9ad8\u6548\u7684\u6301\u7eed\u5b66\u4e60\u3002", "motivation": "\u63a2\u7d22\u96f6\u9636\u4f18\u5316\u4f5c\u4e3a\u89e3\u51b3\u6301\u7eed\u5b66\u4e60\u4e2d\u53ef\u5851\u6027-\u7a33\u5b9a\u6027-\u6548\u7387\u4e09\u96be\u95ee\u9898\u7684\u65b0\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u68af\u5ea6\u8ba1\u7b97\u6602\u8d35\u6216\u4e0d\u5207\u5b9e\u9645\u7684\u573a\u666f\u4e0b\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u7814\u7a76\u8bc4\u4f30\u96f6\u9636\u4f18\u5316\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u63d0\u51faZO-FC\u65b9\u6cd5\uff1a\u5bf9\u5355\u4e2a\u57fa\u4e8e\u9002\u914d\u5668\u7684PEFT\u6a21\u5757\u5e94\u7528\u96f6\u9636\u4f18\u5316\uff0c\u540c\u65f6\u4f7f\u7528\u4e00\u9636\u4f18\u5316\u66f4\u65b0\u5206\u7c7b\u5668\u3002", "result": "\u96f6\u9636\u4f18\u5316\u81ea\u7136\u4ea7\u751f\u66f4\u5e73\u5766\u7684\u635f\u5931\u666f\u89c2\uff0c\u51cf\u5c11\u9057\u5fd8\uff0c\u4f46\u4f1a\u635f\u5bb3\u53ef\u5851\u6027\uff0c\u7279\u522b\u662f\u5728\u8bad\u7ec3\u9884\u7b97\u53d7\u9650\u65f6\u3002ZO-FC\u65b9\u6cd5\u5728\u7a33\u5b9a\u6027\u548c\u53ef\u5851\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u6709\u6548\u5e73\u8861\u3002", "conclusion": "ZO-FC\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u5185\u5b58\u9ad8\u6548\u7684\u6301\u7eed\u5b66\u4e60\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8bbe\u5907\u7aef\u90e8\u7f72\u573a\u666f\uff0c\u6210\u529f\u5e73\u8861\u4e86\u7a33\u5b9a\u6027\u548c\u53ef\u5851\u6027\u9700\u6c42\u3002"}}
{"id": "2510.21038", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21038", "abs": "https://arxiv.org/abs/2510.21038", "authors": ["Gereon Elvers", "Gilad Landau", "Oiwi Parker Jones"], "title": "Elementary, My Dear Watson: Non-Invasive Neural Keyword Spotting in the LibriBrain Dataset", "comment": "16 pages, 7 figures, 6 tables", "summary": "Non-invasive brain-computer interfaces (BCIs) are beginning to benefit from\nlarge, public benchmarks. However, current benchmarks target relatively simple,\nfoundational tasks like Speech Detection and Phoneme Classification, while\napplication-ready results on tasks like Brain-to-Text remain elusive. We\npropose Keyword Spotting (KWS) as a practically applicable, privacy-aware\nintermediate task. Using the deep 52-hour, within-subject LibriBrain corpus, we\nprovide standardized train/validation/test splits for reproducible\nbenchmarking, and adopt an evaluation protocol tailored to extreme class\nimbalance. Concretely, we use area under the precision-recall curve (AUPRC) as\na robust evaluation metric, complemented by false alarms per hour (FA/h) at\nfixed recall to capture user-facing trade-offs. To simplify deployment and\nfurther experimentation within the research community, we are releasing an\nupdated version of the pnpl library with word-level dataloaders and Colab-ready\ntutorials. As an initial reference model, we present a compact 1-D Conv/ResNet\nbaseline with focal loss and top-k pooling that is trainable on a single\nconsumer-class GPU. The reference model achieves approximately 13x the\npermutation baseline AUPRC on held-out sessions, demonstrating the viability of\nthe task. Exploratory analyses reveal: (i) predictable within-subject scaling -\nperformance improves log-linearly with more training hours - and (ii) the\nexistence of word-level factors (frequency and duration) that systematically\nmodulate detectability.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u5173\u952e\u8bcd\u68c0\u6d4b\u4f5c\u4e3a\u8111\u673a\u63a5\u53e3\u7684\u5b9e\u7528\u4e2d\u95f4\u4efb\u52a1\uff0c\u4f7f\u7528LibriBrain\u8bed\u6599\u5e93\u63d0\u4f9b\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u91c7\u7528AUPRC\u548cFA/h\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u53d1\u5e03\u4e86\u53c2\u8003\u6a21\u578b\u548c\u5de5\u5177\u5e93\u3002", "motivation": "\u5f53\u524d\u8111\u673a\u63a5\u53e3\u57fa\u51c6\u4e3b\u8981\u9488\u5bf9\u7b80\u5355\u7684\u8bed\u97f3\u68c0\u6d4b\u548c\u97f3\u7d20\u5206\u7c7b\u4efb\u52a1\uff0c\u800c\u5b9e\u9645\u5e94\u7528\u5982\u8111\u5230\u6587\u672c\u8f6c\u6362\u4ecd\u96be\u4ee5\u5b9e\u73b0\u3002\u4f5c\u8005\u5e0c\u671b\u627e\u5230\u4e00\u79cd\u65e2\u5b9e\u7528\u53c8\u4fdd\u62a4\u9690\u79c1\u7684\u4e2d\u95f4\u4efb\u52a1\u6765\u63a8\u52a8\u8111\u673a\u63a5\u53e3\u53d1\u5c55\u3002", "method": "\u4f7f\u752852\u5c0f\u65f6\u7684LibriBrain\u8bed\u6599\u5e93\uff0c\u63d0\u4f9b\u6807\u51c6\u5316\u7684\u8bad\u7ec3/\u9a8c\u8bc1/\u6d4b\u8bd5\u5206\u5272\uff0c\u91c7\u7528\u9488\u5bf9\u6781\u7aef\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u4f7f\u7528AUPRC\u548cFA/h\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\uff0c\u5f00\u53d1\u4e86\u57fa\u4e8e1-D Conv/ResNet\u7684\u7d27\u51d1\u57fa\u7ebf\u6a21\u578b\uff0c\u7ed3\u5408\u7126\u70b9\u635f\u5931\u548ctop-k\u6c60\u5316\u3002", "result": "\u53c2\u8003\u6a21\u578b\u5728\u4fdd\u7559\u4f1a\u8bdd\u4e0a\u5b9e\u73b0\u4e86\u7ea613\u500d\u4e8e\u7f6e\u6362\u57fa\u7ebf\u7684AUPRC\uff0c\u8bc1\u660e\u4e86\u4efb\u52a1\u7684\u53ef\u884c\u6027\u3002\u63a2\u7d22\u6027\u5206\u6790\u663e\u793a\uff1a\u6027\u80fd\u968f\u8bad\u7ec3\u65f6\u95f4\u5bf9\u6570\u7ebf\u6027\u63d0\u5347\uff0c\u8bcd\u9891\u548c\u8bcd\u957f\u7b49\u8bcd\u7ea7\u56e0\u7d20\u7cfb\u7edf\u5730\u8c03\u8282\u68c0\u6d4b\u80fd\u529b\u3002", "conclusion": "\u5173\u952e\u8bcd\u68c0\u6d4b\u662f\u8111\u673a\u63a5\u53e3\u7684\u4e00\u4e2a\u53ef\u884c\u4e14\u5b9e\u7528\u7684\u4e2d\u95f4\u4efb\u52a1\uff0c\u63d0\u51fa\u7684\u57fa\u51c6\u548c\u5de5\u5177\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u4e3a\u8111\u5230\u6587\u672c\u8f6c\u6362\u7b49\u5e94\u7528\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2510.21060", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21060", "abs": "https://arxiv.org/abs/2510.21060", "authors": ["Yi He", "Xingyu Zhou"], "title": "On the Sample Complexity of Differentially Private Policy Optimization", "comment": null, "summary": "Policy optimization (PO) is a cornerstone of modern reinforcement learning\n(RL), with diverse applications spanning robotics, healthcare, and large\nlanguage model training. The increasing deployment of PO in sensitive domains,\nhowever, raises significant privacy concerns. In this paper, we initiate a\ntheoretical study of differentially private policy optimization, focusing\nexplicitly on its sample complexity. We first formalize an appropriate\ndefinition of differential privacy (DP) tailored to PO, addressing the inherent\nchallenges arising from on-policy learning dynamics and the subtlety involved\nin defining the unit of privacy. We then systematically analyze the sample\ncomplexity of widely-used PO algorithms, including policy gradient (PG),\nnatural policy gradient (NPG) and more, under DP constraints and various\nsettings, via a unified framework. Our theoretical results demonstrate that\nprivacy costs can often manifest as lower-order terms in the sample complexity,\nwhile also highlighting subtle yet important observations in private PO\nsettings. These offer valuable practical insights for privacy-preserving PO\nalgorithms.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u5bf9\u5dee\u5206\u9690\u79c1\u7b56\u7565\u4f18\u5316\u7684\u6837\u672c\u590d\u6742\u5ea6\u8fdb\u884c\u7406\u8bba\u7814\u7a76\uff0c\u4e3a\u7b56\u7565\u68af\u5ea6\u3001\u81ea\u7136\u7b56\u7565\u68af\u5ea6\u7b49\u5e7f\u6cdb\u4f7f\u7528\u7684\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u5728\u9690\u79c1\u7ea6\u675f\u4e0b\u7684\u6027\u80fd\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u6846\u67b6\u3002", "motivation": "\u968f\u7740\u7b56\u7565\u4f18\u5316\u5728\u654f\u611f\u9886\u57df\uff08\u5982\u673a\u5668\u4eba\u3001\u533b\u7597\u3001\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\uff09\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u9700\u8981\u4ece\u7406\u8bba\u4e0a\u7814\u7a76\u5dee\u5206\u9690\u79c1\u7b56\u7565\u4f18\u5316\u7684\u6837\u672c\u590d\u6742\u5ea6\u3002", "method": "\u9996\u5148\u5f62\u5f0f\u5316\u4e86\u9002\u5408\u7b56\u7565\u4f18\u5316\u7684\u5dee\u5206\u9690\u79c1\u5b9a\u4e49\uff0c\u89e3\u51b3\u4e86\u5728\u7ebf\u5b66\u4e60\u52a8\u6001\u548c\u9690\u79c1\u5355\u5143\u5b9a\u4e49\u7684\u56fa\u6709\u6311\u6218\uff0c\u7136\u540e\u901a\u8fc7\u7edf\u4e00\u6846\u67b6\u7cfb\u7edf\u5206\u6790\u4e86PG\u3001NPG\u7b49\u7b97\u6cd5\u5728DP\u7ea6\u675f\u4e0b\u7684\u6837\u672c\u590d\u6742\u5ea6\u3002", "result": "\u7406\u8bba\u7ed3\u679c\u8868\u660e\u9690\u79c1\u6210\u672c\u901a\u5e38\u8868\u73b0\u4e3a\u6837\u672c\u590d\u6742\u5ea6\u7684\u4f4e\u9636\u9879\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u79c1\u6709\u7b56\u7565\u4f18\u5316\u8bbe\u7f6e\u4e2d\u7684\u4e00\u4e9b\u5fae\u5999\u4f46\u91cd\u8981\u7684\u89c2\u5bdf\u3002", "conclusion": "\u7814\u7a76\u4e3a\u9690\u79c1\u4fdd\u62a4\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5b9e\u8df5\u89c1\u89e3\uff0c\u8bc1\u660e\u4e86\u5728\u9002\u5f53\u8bbe\u8ba1\u4e0b\uff0c\u9690\u79c1\u4fdd\u62a4\u53ef\u4ee5\u5728\u4e0d\u663e\u8457\u589e\u52a0\u6837\u672c\u590d\u6742\u5ea6\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u3002"}}
{"id": "2510.21067", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21067", "abs": "https://arxiv.org/abs/2510.21067", "authors": ["Raul Cavalcante Dinardi", "Bruno Yamamoto", "Anna Helena Reali Costa", "Artur Jordao"], "title": "The Virtues of Brevity: Avoid Overthinking in Parallel Test-Time Reasoning", "comment": "Accepted at NeurIPS 2025 Workshop on Efficient Reasoning", "summary": "Reasoning models represent a significant advance in LLM capabilities,\nparticularly for complex reasoning tasks such as mathematics and coding.\nPrevious studies confirm that parallel test-time compute-sampling multiple\nsolutions and selecting the best one-can further enhance the predictive\nperformance of LLMs. However, strategies in this area often require complex\nscoring, thus increasing computational cost and complexity. In this work, we\ndemonstrate that the simple and counterintuitive heuristic of selecting the\nshortest solution is highly effective. We posit that the observed effectiveness\nstems from models operating in two distinct regimes: a concise, confident\nconventional regime and a verbose overthinking regime characterized by\nuncertainty, and we show evidence of a critical point where the overthinking\nregime begins to be significant. By selecting the shortest answer, the\nheuristic preferentially samples from the conventional regime. We confirm that\nthis approach is competitive with more complex methods such as self-consistency\nacross two challenging benchmarks while significantly reducing computational\noverhead. The shortest-answer heuristic provides a Pareto improvement over\nself-consistency and applies even to tasks where output equality is not well\ndefined.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u9009\u62e9\u6700\u77ed\u7b54\u6848\u7684\u7b80\u5355\u542f\u53d1\u5f0f\u65b9\u6cd5\u5728\u63d0\u5347LLM\u63a8\u7406\u6027\u80fd\u65b9\u9762\u4e0e\u590d\u6742\u65b9\u6cd5\u76f8\u5f53\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u5e76\u884c\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u65b9\u6cd5\u9700\u8981\u590d\u6742\u8bc4\u5206\uff0c\u589e\u52a0\u4e86\u8ba1\u7b97\u6210\u672c\u548c\u590d\u6742\u6027\uff0c\u9700\u8981\u5bfb\u627e\u66f4\u7b80\u5355\u6709\u6548\u7684\u7b56\u7565\u3002", "method": "\u91c7\u7528\u9009\u62e9\u6700\u77ed\u7b54\u6848\u7684\u7b80\u5355\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u57fa\u4e8e\u6a21\u578b\u5728\u7b80\u6d01\u81ea\u4fe1\u7684\u5e38\u89c4\u6a21\u5f0f\u548c\u5197\u957f\u8fc7\u5ea6\u601d\u8003\u6a21\u5f0f\u4e4b\u95f4\u5207\u6362\u7684\u5047\u8bbe\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e24\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e0e\u81ea\u4e00\u81f4\u6027\u7b49\u590d\u6742\u65b9\u6cd5\u8868\u73b0\u76f8\u5f53\uff0c\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "\u6700\u77ed\u7b54\u6848\u542f\u53d1\u5f0f\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5bf9\u81ea\u4e00\u81f4\u6027\u7684\u5e15\u7d2f\u6258\u6539\u8fdb\uff0c\u9002\u7528\u4e8e\u8f93\u51fa\u76f8\u7b49\u6027\u5b9a\u4e49\u4e0d\u660e\u786e\u7684\u4efb\u52a1\uff0c\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2510.21679", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21679", "abs": "https://arxiv.org/abs/2510.21679", "authors": ["Gaku Morio", "Harri Rowlands", "Dominik Stammbach", "Christopher D. Manning", "Peter Henderson"], "title": "A Multimodal Benchmark for Framing of Oil & Gas Advertising and Potential Greenwashing Detection", "comment": "Forthcoming in NeurIPS 2025 Datasets and Benchmarks Track", "summary": "Companies spend large amounts of money on public relations campaigns to\nproject a positive brand image. However, sometimes there is a mismatch between\nwhat they say and what they do. Oil & gas companies, for example, are accused\nof \"greenwashing\" with imagery of climate-friendly initiatives. Understanding\nthe framing, and changes in framing, at scale can help better understand the\ngoals and nature of public relations campaigns. To address this, we introduce a\nbenchmark dataset of expert-annotated video ads obtained from Facebook and\nYouTube. The dataset provides annotations for 13 framing types for more than 50\ncompanies or advocacy groups across 20 countries. Our dataset is especially\ndesigned for the evaluation of vision-language models (VLMs), distinguishing it\nfrom past text-only framing datasets. Baseline experiments show some promising\nresults, while leaving room for improvement for future work: GPT-4.1 can detect\nenvironmental messages with 79% F1 score, while our best model only achieves\n46% F1 score on identifying framing around green innovation. We also identify\nchallenges that VLMs must address, such as implicit framing, handling videos of\nvarious lengths, or implicit cultural backgrounds. Our dataset contributes to\nresearch in multimodal analysis of strategic communication in the energy\nsector.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u4e13\u5bb6\u6807\u6ce8\u89c6\u9891\u5e7f\u544a\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u5206\u6790\u80fd\u6e90\u516c\u53f8\u516c\u5173\u6d3b\u52a8\u4e2d\u7684\u6846\u67b6\u7c7b\u578b\uff0c\u7279\u522b\u662f\u68c0\u6d4b\u7eff\u8272\u521b\u65b0\u7b49\u73af\u5883\u4fe1\u606f\u3002", "motivation": "\u4f01\u4e1a\u516c\u5173\u6d3b\u52a8\u5b58\u5728\u8a00\u884c\u4e0d\u4e00\u7684\u95ee\u9898\uff08\u5982\u77f3\u6cb9\u516c\u53f8\u7684'\u6f02\u7eff'\u884c\u4e3a\uff09\uff0c\u9700\u8981\u5927\u89c4\u6a21\u7406\u89e3\u6846\u67b6\u53ca\u5176\u53d8\u5316\u6765\u63ed\u793a\u516c\u5173\u6d3b\u52a8\u7684\u76ee\u6807\u548c\u6027\u8d28\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u4eceFacebook\u548cYouTube\u83b7\u53d6\u7684\u4e13\u5bb6\u6807\u6ce8\u89c6\u9891\u5e7f\u544a\u6570\u636e\u96c6\uff0c\u5305\u542b13\u79cd\u6846\u67b6\u7c7b\u578b\uff0c\u6db5\u76d650\u591a\u5bb6\u516c\u53f8\u548c20\u4e2a\u56fd\u5bb6\uff0c\u4e13\u95e8\u7528\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u3002", "result": "\u57fa\u7ebf\u5b9e\u9a8c\u663e\u793aGPT-4.1\u80fd\u68c0\u6d4b\u73af\u5883\u4fe1\u606f\u8fbe\u523079% F1\u5206\u6570\uff0c\u4f46\u6700\u4f73\u6a21\u578b\u5728\u8bc6\u522b\u7eff\u8272\u521b\u65b0\u6846\u67b6\u65b9\u9762\u4ec5\u8fbe\u523046% F1\u5206\u6570\uff0c\u8868\u660e\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u6709\u52a9\u4e8e\u80fd\u6e90\u9886\u57df\u6218\u7565\u6c9f\u901a\u7684\u591a\u6a21\u6001\u5206\u6790\u7814\u7a76\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u9700\u8981\u89e3\u51b3\u7684\u6311\u6218\uff0c\u5982\u9690\u5f0f\u6846\u67b6\u3001\u4e0d\u540c\u957f\u5ea6\u89c6\u9891\u5904\u7406\u548c\u9690\u542b\u6587\u5316\u80cc\u666f\u3002"}}
{"id": "2510.21086", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.21086", "abs": "https://arxiv.org/abs/2510.21086", "authors": ["Jiaqi Xue", "Mayank Kumar", "Yuzhang Shang", "Shangqian Gao", "Rui Ning", "Mengxin Zheng", "Xiaoqian Jiang", "Qian Lou"], "title": "DictPFL: Efficient and Private Federated Learning on Encrypted Gradients", "comment": "Accepted by NeurIPS 2025", "summary": "Federated Learning (FL) enables collaborative model training across\ninstitutions without sharing raw data. However, gradient sharing still risks\nprivacy leakage, such as gradient inversion attacks. Homomorphic Encryption\n(HE) can secure aggregation but often incurs prohibitive computational and\ncommunication overhead. Existing HE-based FL methods sit at two extremes:\nencrypting all gradients for full privacy at high cost, or partially encrypting\ngradients to save resources while exposing vulnerabilities. We present DictPFL,\na practical framework that achieves full gradient protection with minimal\noverhead. DictPFL encrypts every transmitted gradient while keeping\nnon-transmitted parameters local, preserving privacy without heavy computation.\nIt introduces two key modules: Decompose-for-Partial-Encrypt (DePE), which\ndecomposes model weights into a static dictionary and an updatable lookup\ntable, only the latter is encrypted and aggregated, while the static dictionary\nremains local and requires neither sharing nor encryption; and\nPrune-for-Minimum-Encrypt (PrME), which applies encryption-aware pruning to\nminimize encrypted parameters via consistent, history-guided masks. Experiments\nshow that DictPFL reduces communication cost by 402-748$\\times$ and accelerates\ntraining by 28-65$\\times$ compared to fully encrypted FL, while outperforming\nstate-of-the-art selective encryption methods by 51-155$\\times$ in overhead and\n4-19$\\times$ in speed. Remarkably, DictPFL's runtime is within 2$\\times$ of\nplaintext FL, demonstrating for the first time, that HE-based private federated\nlearning is practical for real-world deployment. The code is publicly available\nat https://github.com/UCF-ML-Research/DictPFL.", "AI": {"tldr": "DictPFL\u662f\u4e00\u4e2a\u5b9e\u7528\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u6a21\u578b\u6743\u91cd\u4e3a\u9759\u6001\u5b57\u5178\u548c\u53ef\u66f4\u65b0\u67e5\u627e\u8868\uff0c\u4ec5\u52a0\u5bc6\u4f20\u8f93\u90e8\u5206\u53c2\u6570\uff0c\u5728\u4fdd\u8bc1\u5168\u68af\u5ea6\u4fdd\u62a4\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u68af\u5ea6\u5171\u4eab\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u800c\u5168\u540c\u6001\u52a0\u5bc6\u867d\u7136\u80fd\u4fdd\u62a4\u9690\u79c1\u4f46\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\u5de8\u5927\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u5b8c\u5168\u52a0\u5bc6\u5bfc\u81f4\u9ad8\u6210\u672c\uff0c\u8981\u4e48\u90e8\u5206\u52a0\u5bc6\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "\u63d0\u51faDePE\u6a21\u5757\u5c06\u6a21\u578b\u6743\u91cd\u5206\u89e3\u4e3a\u9759\u6001\u5b57\u5178\u548c\u53ef\u66f4\u65b0\u67e5\u627e\u8868\uff0c\u4ec5\u52a0\u5bc6\u540e\u8005\u8fdb\u884c\u805a\u5408\uff1bPrME\u6a21\u5757\u901a\u8fc7\u52a0\u5bc6\u611f\u77e5\u526a\u679d\u6700\u5c0f\u5316\u52a0\u5bc6\u53c2\u6570\u6570\u91cf\u3002", "result": "\u76f8\u6bd4\u5b8c\u5168\u52a0\u5bc6\u7684\u8054\u90a6\u5b66\u4e60\uff0cDictPFL\u51cf\u5c11\u901a\u4fe1\u6210\u672c402-748\u500d\uff0c\u52a0\u901f\u8bad\u7ec328-65\u500d\uff1b\u76f8\u6bd4\u9009\u62e9\u6027\u52a0\u5bc6\u65b9\u6cd5\uff0c\u51cf\u5c11\u5f00\u950051-155\u500d\uff0c\u52a0\u901f4-19\u500d\u3002", "conclusion": "DictPFL\u9996\u6b21\u8bc1\u660e\u57fa\u4e8e\u540c\u6001\u52a0\u5bc6\u7684\u79c1\u6709\u8054\u90a6\u5b66\u4e60\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u662f\u53ef\u884c\u7684\uff0c\u5176\u8fd0\u884c\u65f6\u95f4\u4ec5\u6bd4\u660e\u6587\u8054\u90a6\u5b66\u4e60\u61622\u500d\u4ee5\u5185\u3002"}}
{"id": "2510.21113", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21113", "abs": "https://arxiv.org/abs/2510.21113", "authors": ["Maitreyi Swaroop", "Tamar Krishnamurti", "Bryan Wilder"], "title": "Distributionally Robust Feature Selection", "comment": "Accepted at NeurIPS 2025", "summary": "We study the problem of selecting limited features to observe such that\nmodels trained on them can perform well simultaneously across multiple\nsubpopulations. This problem has applications in settings where collecting each\nfeature is costly, e.g. requiring adding survey questions or physical sensors,\nand we must be able to use the selected features to create high-quality\ndownstream models for different populations. Our method frames the problem as a\ncontinuous relaxation of traditional variable selection using a noising\nmechanism, without requiring backpropagation through model training processes.\nBy optimizing over the variance of a Bayes-optimal predictor, we develop a\nmodel-agnostic framework that balances overall performance of downstream\nprediction across populations. We validate our approach through experiments on\nboth synthetic datasets and real-world data.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\uff0c\u5728\u7279\u5f81\u6536\u96c6\u6210\u672c\u9ad8\u7684\u573a\u666f\u4e0b\uff0c\u9009\u62e9\u6709\u9650\u7279\u5f81\u4ee5\u8bad\u7ec3\u80fd\u5728\u591a\u4e2a\u5b50\u7fa4\u4f53\u4e0a\u540c\u65f6\u8868\u73b0\u826f\u597d\u7684\u6a21\u578b\u3002", "motivation": "\u5728\u7279\u5f81\u6536\u96c6\u6210\u672c\u9ad8\u6602\u7684\u8bbe\u5b9a\u4e2d\uff08\u5982\u6dfb\u52a0\u8c03\u67e5\u95ee\u9898\u6216\u7269\u7406\u4f20\u611f\u5668\uff09\uff0c\u9700\u8981\u9009\u62e9\u6709\u9650\u7279\u5f81\u6765\u6784\u5efa\u9002\u7528\u4e8e\u4e0d\u540c\u7fa4\u4f53\u7684\u9ad8\u8d28\u91cf\u4e0b\u6e38\u6a21\u578b\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u4f20\u7edf\u53d8\u91cf\u9009\u62e9\u7684\u8fde\u7eed\u677e\u5f1b\uff0c\u4f7f\u7528\u52a0\u566a\u673a\u5236\uff0c\u65e0\u9700\u901a\u8fc7\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u8fdb\u884c\u53cd\u5411\u4f20\u64ad\u3002\u901a\u8fc7\u4f18\u5316\u8d1d\u53f6\u65af\u6700\u4f18\u9884\u6d4b\u5668\u7684\u65b9\u5dee\uff0c\u5f00\u53d1\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6\u6765\u5e73\u8861\u8de8\u7fa4\u4f53\u4e0b\u6e38\u9884\u6d4b\u7684\u6574\u4f53\u6027\u80fd\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u9009\u62e9\u6709\u9650\u7279\u5f81\uff0c\u4f7f\u8bad\u7ec3\u51fa\u7684\u6a21\u578b\u5728\u591a\u4e2a\u5b50\u7fa4\u4f53\u4e0a\u540c\u65f6\u8868\u73b0\u826f\u597d\uff0c\u9002\u7528\u4e8e\u7279\u5f81\u6536\u96c6\u6210\u672c\u9ad8\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2510.21188", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21188", "abs": "https://arxiv.org/abs/2510.21188", "authors": ["Xiequn Wang", "Zhan Zhuang", "Yu Zhang"], "title": "PLAN: Proactive Low-Rank Allocation for Continual Learning", "comment": "accepted by ICCV 2025", "summary": "Continual learning (CL) requires models to continuously adapt to new tasks\nwithout forgetting past knowledge. In this work, we propose\n\\underline{P}roactive \\underline{L}ow-rank \\underline{A}llocatio\\underline{N}\n(PLAN), a framework that extends Low-Rank Adaptation (LoRA) to enable efficient\nand interference-aware fine-tuning of large pre-trained models in CL settings.\nPLAN proactively manages the allocation of task-specific subspaces by\nintroducing orthogonal basis vectors for each task and optimizing them through\na perturbation-based strategy that minimizes conflicts with previously learned\nparameters. Furthermore, PLAN incorporates a novel selection mechanism that\nidentifies and assigns basis vectors with minimal sensitivity to interference,\nreducing the risk of degrading past knowledge while maintaining efficient\nadaptation to new tasks. Empirical results on standard CL benchmarks\ndemonstrate that PLAN consistently outperforms existing methods, establishing a\nnew state-of-the-art for continual learning with foundation models.", "AI": {"tldr": "PLAN\u662f\u4e00\u4e2a\u6301\u7eed\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6269\u5c55LoRA\u6765\u7ba1\u7406\u4efb\u52a1\u7279\u5b9a\u5b50\u7a7a\u95f4\u5206\u914d\uff0c\u4f7f\u7528\u6b63\u4ea4\u57fa\u5411\u91cf\u548c\u57fa\u4e8e\u6270\u52a8\u7684\u7b56\u7565\u6700\u5c0f\u5316\u4e0e\u5df2\u5b66\u53c2\u6570\u7684\u51b2\u7a81\uff0c\u4ece\u800c\u5728\u57fa\u7840\u6a21\u578b\u4e2d\u5b9e\u73b0\u9ad8\u6548\u4e14\u5e72\u6270\u611f\u77e5\u7684\u5fae\u8c03\u3002", "motivation": "\u6301\u7eed\u5b66\u4e60\u8981\u6c42\u6a21\u578b\u5728\u4e0d\u65ad\u9002\u5e94\u65b0\u4efb\u52a1\u7684\u540c\u65f6\u4e0d\u5fd8\u8bb0\u8fc7\u53bb\u7684\u77e5\u8bc6\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6301\u7eed\u5b66\u4e60\u4e2d\u9762\u4e34\u6548\u7387\u4f4e\u4e0b\u548c\u5e72\u6270\u95ee\u9898\u3002", "method": "PLAN\u6269\u5c55\u4e86LoRA\uff0c\u5f15\u5165\u4efb\u52a1\u7279\u5b9a\u7684\u6b63\u4ea4\u57fa\u5411\u91cf\uff0c\u901a\u8fc7\u57fa\u4e8e\u6270\u52a8\u7684\u7b56\u7565\u4f18\u5316\u8fd9\u4e9b\u5411\u91cf\u4ee5\u6700\u5c0f\u5316\u51b2\u7a81\uff0c\u5e76\u91c7\u7528\u9009\u62e9\u673a\u5236\u8bc6\u522b\u5e72\u6270\u654f\u611f\u6027\u6700\u5c0f\u7684\u57fa\u5411\u91cf\u3002", "result": "\u5728\u6807\u51c6\u6301\u7eed\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPLAN\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e3a\u57fa\u7840\u6a21\u578b\u7684\u6301\u7eed\u5b66\u4e60\u5efa\u7acb\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "PLAN\u6846\u67b6\u901a\u8fc7\u4e3b\u52a8\u7ba1\u7406\u4efb\u52a1\u7279\u5b9a\u5b50\u7a7a\u95f4\u5206\u914d\uff0c\u5728\u4fdd\u6301\u5bf9\u8fc7\u53bb\u77e5\u8bc6\u7684\u540c\u65f6\u9ad8\u6548\u9002\u5e94\u65b0\u4efb\u52a1\uff0c\u4e3a\u6301\u7eed\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.21202", "categories": ["cs.LG", "68T05", "I.5.0"], "pdf": "https://arxiv.org/pdf/2510.21202", "abs": "https://arxiv.org/abs/2510.21202", "authors": ["JunRu Luo", "Difei Cheng", "Bo Zhang"], "title": "Online AUC Optimization Based on Second-order Surrogate Loss", "comment": null, "summary": "The Area Under the Curve (AUC) is an important performance metric for\nclassification tasks, particularly in class-imbalanced scenarios. However,\nminimizing the AUC presents significant challenges due to the non-convex and\ndiscontinuous nature of pairwise 0/1 losses, which are difficult to optimize,\nas well as the substantial memory cost of instance-wise storage, which creates\nbottlenecks in large-scale applications. To overcome these challenges, we\npropose a novel second-order surrogate loss based on the pairwise hinge loss,\nand develop an efficient online algorithm. Unlike conventional approaches that\napproximate each individual pairwise 0/1 loss term with an instance-wise\nsurrogate function, our approach introduces a new paradigm that directly\nsubstitutes the entire aggregated pairwise loss with a surrogate loss function\nconstructed from the first- and second-order statistics of the training data.\nTheoretically, while existing online AUC optimization algorithms typically\nachieve an $\\mathcal{O}(\\sqrt{T})$ regret bound, our method attains a tighter\n$\\mathcal{O}(\\ln T)$ bound. Furthermore, we extend the proposed framework to\nnonlinear settings through a kernel-based formulation. Extensive experiments on\nmultiple benchmark datasets demonstrate the superior efficiency and\neffectiveness of the proposed second-order surrogate loss in optimizing online\nAUC performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8c\u9636\u7edf\u8ba1\u91cf\u7684\u66ff\u4ee3\u635f\u5931\u51fd\u6570\u6765\u4f18\u5316AUC\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u975e\u51f8\u4e0d\u8fde\u7eed\u635f\u5931\u548c\u5185\u5b58\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u5728\u5728\u7ebf\u5b66\u4e60\u4e2d\u5b9e\u73b0\u4e86\u66f4\u7d27\u7684\u9057\u61be\u754c\u3002", "motivation": "AUC\u662f\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u91cd\u8981\u6027\u80fd\u6307\u6807\uff0c\u7279\u522b\u662f\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u573a\u666f\u4e0b\u3002\u4f46\u4f18\u5316AUC\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u6210\u5bf90/1\u635f\u5931\u7684\u975e\u51f8\u4e0d\u8fde\u7eed\u6027\u5bfc\u81f4\u4f18\u5316\u56f0\u96be\uff0c\u4ee5\u53ca\u5b9e\u4f8b\u7ea7\u5b58\u50a8\u7684\u9ad8\u5185\u5b58\u6210\u672c\u5728\u5927\u89c4\u6a21\u5e94\u7528\u4e2d\u9020\u6210\u74f6\u9888\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u6210\u5bf9\u94f0\u94fe\u635f\u5931\u7684\u65b0\u578b\u4e8c\u9636\u66ff\u4ee3\u635f\u5931\uff0c\u5f00\u53d1\u4e86\u9ad8\u6548\u7684\u5728\u7ebf\u7b97\u6cd5\u3002\u4e0e\u4f20\u7edf\u65b9\u6cd5\u4e0d\u540c\uff0c\u8be5\u65b9\u6cd5\u76f4\u63a5\u4f7f\u7528\u8bad\u7ec3\u6570\u636e\u7684\u4e00\u9636\u548c\u4e8c\u9636\u7edf\u8ba1\u91cf\u6784\u5efa\u66ff\u4ee3\u635f\u5931\u51fd\u6570\u6765\u66ff\u4ee3\u6574\u4e2a\u805a\u5408\u7684\u6210\u5bf9\u635f\u5931\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u73b0\u6709\u5728\u7ebfAUC\u4f18\u5316\u7b97\u6cd5\u901a\u5e38\u8fbe\u5230O(\u221aT)\u9057\u61be\u754c\uff0c\u800c\u672c\u6587\u65b9\u6cd5\u8fbe\u5230\u4e86\u66f4\u7d27\u7684O(ln T)\u754c\u3002\u901a\u8fc7\u6838\u65b9\u6cd5\u6269\u5c55\u5230\u975e\u7ebf\u6027\u8bbe\u7f6e\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u4f18\u8d8a\u6548\u7387\u548c\u6548\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e8c\u9636\u66ff\u4ee3\u635f\u5931\u51fd\u6570\u4e3a\u5728\u7ebfAUC\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u6539\u5584\u4e86\u4f18\u5316\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2510.21223", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21223", "abs": "https://arxiv.org/abs/2510.21223", "authors": ["Kexuan Shi", "Yandong Wen", "Weiyang Liu"], "title": "Model Merging with Functional Dual Anchors", "comment": "Technical report (23 pages, 15 figures, project page:\n  https://spherelab.ai/fda/)", "summary": "Model merging is an efficient post-training strategy for integrating\nknowledge from multiple finetuned checkpoints of a shared foundation model.\nExisting methods operate in the parameter space, combining task vectors to\nmitigate conflicts, but remain constrained by parameter inconsistencies. We\npropose Functional Dual Anchors (FDAs), a framework that instead models the\ninput-representation space. FDAs are synthetic inputs whose induced gradients\nalign with task vectors, capturing task-specific functional shifts relative to\nthe pretrained model. This perspective bridges joint multi-task training and\npost-hoc merging, offering both robustness and flexibility. We further\nintroduce a principled initialization scheme and show that FDAs are\ncomplementary to parameter-space model merging. Comprehensive experiments\ndemonstrate the effectiveness of FDAs in model merging.", "AI": {"tldr": "\u63d0\u51faFunctional Dual Anchors (FDAs)\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u6a21\u8f93\u5165\u8868\u793a\u7a7a\u95f4\u800c\u975e\u53c2\u6570\u7a7a\u95f4\u6765\u6539\u8fdb\u6a21\u578b\u5408\u5e76\uff0c\u4f7f\u7528\u5408\u6210\u8f93\u5165\u6765\u5bf9\u9f50\u4efb\u52a1\u5411\u91cf\uff0c\u6355\u83b7\u4efb\u52a1\u7279\u5b9a\u7684\u529f\u80fd\u504f\u79fb\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\u5728\u53c2\u6570\u7a7a\u95f4\u64cd\u4f5c\uff0c\u53d7\u5230\u53c2\u6570\u4e0d\u4e00\u81f4\u6027\u7684\u9650\u5236\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u6574\u5408\u591a\u4e2a\u5fae\u8c03\u68c0\u67e5\u70b9\u7684\u77e5\u8bc6\u3002", "method": "\u63d0\u51faFDA\u6846\u67b6\uff0c\u4f7f\u7528\u5408\u6210\u8f93\u5165\uff08\u53cc\u951a\u70b9\uff09\u6765\u8bf1\u5bfc\u4e0e\u4efb\u52a1\u5411\u91cf\u5bf9\u9f50\u7684\u68af\u5ea6\uff0c\u6355\u83b7\u4efb\u52a1\u7279\u5b9a\u7684\u529f\u80fd\u504f\u79fb\uff0c\u5e76\u63d0\u4f9b\u539f\u5219\u6027\u521d\u59cb\u5316\u65b9\u6848\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8bc1\u660eFDAs\u5728\u6a21\u578b\u5408\u5e76\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e14\u4e0e\u53c2\u6570\u7a7a\u95f4\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\u4e92\u8865\u3002", "conclusion": "FDA\u6846\u67b6\u901a\u8fc7\u5efa\u6a21\u8f93\u5165\u8868\u793a\u7a7a\u95f4\uff0c\u4e3a\u6a21\u578b\u5408\u5e76\u63d0\u4f9b\u4e86\u66f4\u7a33\u5065\u548c\u7075\u6d3b\u7684\u65b9\u6cd5\uff0c\u5f25\u5408\u4e86\u8054\u5408\u591a\u4efb\u52a1\u8bad\u7ec3\u548c\u540e\u9a8c\u5408\u5e76\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2510.21252", "categories": ["cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.21252", "abs": "https://arxiv.org/abs/2510.21252", "authors": ["Francesco Martinuzzi"], "title": "Unified Implementations of Recurrent Neural Networks in Multiple Deep Learning Frameworks", "comment": null, "summary": "Recurrent neural networks (RNNs) are a cornerstone of sequence modeling\nacross various scientific and industrial applications. Owing to their\nversatility, numerous RNN variants have been proposed over the past decade,\naiming to improve the modeling of long-term dependencies and to address\nchallenges such as vanishing and exploding gradients. However, no central\nlibrary is available to test these variations, and reimplementing diverse\narchitectures can be time-consuming and error-prone, limiting reproducibility\nand exploration. Here, we introduce three open-source libraries in Julia and\nPython that centralize numerous recurrent cell implementations and higher-level\nrecurrent architectures. torchrecurrent, RecurrentLayers.jl, and\nLuxRecurrentLayers.jl offer a consistent framework for constructing and\nextending RNN models, providing built-in mechanisms for customization and\nexperimentation. All packages are available under the MIT license and actively\nmaintained on GitHub.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e09\u4e2a\u5f00\u6e90\u5e93\uff08torchrecurrent\u3001RecurrentLayers.jl\u3001LuxRecurrentLayers.jl\uff09\uff0c\u7528\u4e8e\u96c6\u4e2d\u5b9e\u73b0\u548c\u6d4b\u8bd5\u591a\u79cdRNN\u53d8\u4f53\uff0c\u89e3\u51b3\u5f53\u524d\u7f3a\u4e4f\u7edf\u4e00\u6d4b\u8bd5\u5e73\u53f0\u7684\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u7f3a\u4e4f\u7edf\u4e00\u7684\u6d4b\u8bd5\u5e93\uff0c\u91cd\u65b0\u5b9e\u73b0\u5404\u79cdRNN\u67b6\u6784\u8017\u65f6\u4e14\u5bb9\u6613\u51fa\u9519\uff0c\u9650\u5236\u4e86\u53ef\u91cd\u590d\u6027\u548c\u63a2\u7d22\u6027\u7814\u7a76\u3002", "method": "\u5f00\u53d1\u4e86Julia\u548cPython\u4e2d\u7684\u4e09\u4e2a\u5f00\u6e90\u5e93\uff0c\u63d0\u4f9b\u4e00\u81f4\u7684\u6846\u67b6\u6765\u6784\u5efa\u548c\u6269\u5c55RNN\u6a21\u578b\uff0c\u5185\u7f6e\u5b9a\u5236\u548c\u5b9e\u9a8c\u673a\u5236\u3002", "result": "\u6210\u529f\u521b\u5efa\u4e86\u96c6\u4e2d\u5316\u7684RNN\u5b9e\u73b0\u5e93\uff0c\u6240\u6709\u5305\u90fd\u5728MIT\u8bb8\u53ef\u4e0b\u5728GitHub\u4e0a\u79ef\u6781\u7ef4\u62a4\u3002", "conclusion": "\u8fd9\u4e9b\u5e93\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u4fbf\u6377\u7684\u5de5\u5177\u6765\u6d4b\u8bd5\u548c\u6bd4\u8f83\u4e0d\u540c\u7684RNN\u53d8\u4f53\uff0c\u4fc3\u8fdb\u4e86\u5e8f\u5217\u5efa\u6a21\u7814\u7a76\u7684\u53ef\u91cd\u590d\u6027\u548c\u521b\u65b0\u3002"}}
{"id": "2510.21389", "categories": ["cs.LG", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.21389", "abs": "https://arxiv.org/abs/2510.21389", "authors": ["Stefan Kraft", "Andreas Theissler", "Vera Wienhausen-Wilke", "Gjergji Kasneci", "Hendrik Lensch"], "title": "Assessing the Real-World Utility of Explainable AI for Arousal Diagnostics: An Application-Grounded User Study", "comment": null, "summary": "Artificial intelligence (AI) systems increasingly match or surpass human\nexperts in biomedical signal interpretation. However, their effective\nintegration into clinical practice requires more than high predictive accuracy.\nClinicians must discern \\textit{when} and \\textit{why} to trust algorithmic\nrecommendations. This work presents an application-grounded user study with\neight professional sleep medicine practitioners, who score nocturnal arousal\nevents in polysomnographic data under three conditions: (i) manual scoring,\n(ii) black-box (BB) AI assistance, and (iii) transparent white-box (WB) AI\nassistance. Assistance is provided either from the \\textit{start} of scoring or\nas a post-hoc quality-control (\\textit{QC}) review. We systematically evaluate\nhow the type and timing of assistance influence event-level and clinically most\nrelevant count-based performance, time requirements, and user experience. When\nevaluated against the clinical standard used to train the AI, both AI and\nhuman-AI teams significantly outperform unaided experts, with collaboration\nalso reducing inter-rater variability. Notably, transparent AI assistance\napplied as a targeted QC step yields median event-level performance\nimprovements of approximately 30\\% over black-box assistance, and QC timing\nfurther enhances count-based outcomes. While WB and QC approaches increase the\ntime required for scoring, start-time assistance is faster and preferred by\nmost participants. Participants overwhelmingly favor transparency, with seven\nout of eight expressing willingness to adopt the system with minor or no\nmodifications. In summary, strategically timed transparent AI assistance\neffectively balances accuracy and clinical efficiency, providing a promising\npathway toward trustworthy AI integration and user acceptance in clinical\nworkflows.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7528\u6237\u5b9e\u9a8c\u8bc4\u4f30\u4e86\u4e0d\u540c\u7c7b\u578b\u548c\u65f6\u673a\u7684AI\u8f85\u52a9\u5bf9\u7761\u7720\u533b\u5b66\u4e13\u5bb6\u8bc4\u5206\u8868\u73b0\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u900f\u660eAI\u8f85\u52a9\u4f5c\u4e3a\u8d28\u91cf\u63a7\u5236\u6b65\u9aa4\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u540c\u65f6\u83b7\u5f97\u7528\u6237\u9ad8\u5ea6\u63a5\u53d7\u3002", "motivation": "AI\u7cfb\u7edf\u5728\u751f\u7269\u533b\u5b66\u4fe1\u53f7\u89e3\u91ca\u65b9\u9762\u5df2\u80fd\u5339\u654c\u751a\u81f3\u8d85\u8d8a\u4eba\u7c7b\u4e13\u5bb6\uff0c\u4f46\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u9700\u8981\u8ba9\u533b\u751f\u77e5\u9053\u4f55\u65f6\u4ee5\u53ca\u4e3a\u4f55\u4fe1\u4efbAI\u5efa\u8bae\uff0c\u56e0\u6b64\u7814\u7a76\u5982\u4f55\u6709\u6548\u6574\u5408AI\u5230\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u3002", "method": "\u5bf98\u540d\u4e13\u4e1a\u7761\u7720\u533b\u5b66\u4ece\u4e1a\u8005\u8fdb\u884c\u5e94\u7528\u578b\u7528\u6237\u7814\u7a76\uff0c\u5728\u4e09\u79cd\u6761\u4ef6\u4e0b\u8bc4\u5206\u591a\u5bfc\u7761\u7720\u56fe\u6570\u636e\uff1a\u624b\u52a8\u8bc4\u5206\u3001\u9ed1\u76d2AI\u8f85\u52a9\u3001\u900f\u660e\u767d\u76d2AI\u8f85\u52a9\uff0c\u8f85\u52a9\u65f6\u673a\u5206\u4e3a\u5f00\u59cb\u9636\u6bb5\u6216\u4e8b\u540e\u8d28\u91cf\u63a7\u5236\u3002", "result": "AI\u8f85\u52a9\u548c\u4eba\u7c7b-AI\u56e2\u961f\u8bc4\u5206\u5747\u663e\u8457\u4f18\u4e8e\u65e0\u8f85\u52a9\u4e13\u5bb6\uff0c\u900f\u660eAI\u8f85\u52a9\u4f5c\u4e3a\u8d28\u91cf\u63a7\u5236\u6b65\u9aa4\u6bd4\u9ed1\u76d2\u8f85\u52a9\u63d0\u5347\u7ea630%\u7684\u4e8b\u4ef6\u7ea7\u6027\u80fd\uff0c\u8d28\u91cf\u63a7\u5236\u65f6\u673a\u8fdb\u4e00\u6b65\u6539\u5584\u8ba1\u6570\u7ed3\u679c\u3002", "conclusion": "\u7b56\u7565\u6027\u65f6\u673a\u7684\u900f\u660eAI\u8f85\u52a9\u80fd\u6709\u6548\u5e73\u8861\u51c6\u786e\u6027\u548c\u4e34\u5e8a\u6548\u7387\uff0c\u4e3a\u53ef\u4fe1AI\u96c6\u6210\u548c\u7528\u6237\u63a5\u53d7\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002"}}
{"id": "2510.21267", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21267", "abs": "https://arxiv.org/abs/2510.21267", "authors": ["Junshu Sun", "Wanxing Chang", "Chenxue Yang", "Qingming Huang", "Shuhui Wang"], "title": "Relieving the Over-Aggregating Effect in Graph Transformers", "comment": "Accepted by NeurIPS 2025", "summary": "Graph attention has demonstrated superior performance in graph learning\ntasks. However, learning from global interactions can be challenging due to the\nlarge number of nodes. In this paper, we discover a new phenomenon termed\nover-aggregating. Over-aggregating arises when a large volume of messages is\naggregated into a single node with less discrimination, leading to the dilution\nof the key messages and potential information loss. To address this, we propose\nWideformer, a plug-and-play method for graph attention. Wideformer divides the\naggregation of all nodes into parallel processes and guides the model to focus\non specific subsets of these processes. The division can limit the input volume\nper aggregation, avoiding message dilution and reducing information loss. The\nguiding step sorts and weights the aggregation outputs, prioritizing the\ninformative messages. Evaluations show that Wideformer can effectively mitigate\nover-aggregating. As a result, the backbone methods can focus on the\ninformative messages, achieving superior performance compared to baseline\nmethods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faWideformer\u65b9\u6cd5\u89e3\u51b3\u56fe\u6ce8\u610f\u529b\u4e2d\u7684\u8fc7\u5ea6\u805a\u5408\u95ee\u9898\uff0c\u901a\u8fc7\u5e76\u884c\u5904\u7406\u548c\u4fe1\u606f\u5f15\u5bfc\u6765\u9632\u6b62\u5173\u952e\u4fe1\u606f\u4e22\u5931\u3002", "motivation": "\u56fe\u6ce8\u610f\u529b\u5728\u5168\u5c40\u4ea4\u4e92\u5b66\u4e60\u4e2d\u9762\u4e34\u8fc7\u5ea6\u805a\u5408\u95ee\u9898\uff0c\u5f53\u5927\u91cf\u6d88\u606f\u805a\u5408\u5230\u5355\u4e2a\u8282\u70b9\u65f6\u4f1a\u5bfc\u81f4\u5173\u952e\u4fe1\u606f\u88ab\u7a00\u91ca\u548c\u4e22\u5931\u3002", "method": "\u63d0\u51faWideformer\u63d2\u4ef6\u65b9\u6cd5\uff0c\u5c06\u8282\u70b9\u805a\u5408\u5212\u5206\u4e3a\u5e76\u884c\u8fc7\u7a0b\uff0c\u5e76\u901a\u8fc7\u6392\u5e8f\u548c\u52a0\u6743\u5f15\u5bfc\u6a21\u578b\u5173\u6ce8\u4fe1\u606f\u4e30\u5bcc\u7684\u5b50\u96c6\u3002", "result": "\u8bc4\u4f30\u663e\u793aWideformer\u80fd\u6709\u6548\u7f13\u89e3\u8fc7\u5ea6\u805a\u5408\uff0c\u4f7f\u9aa8\u5e72\u65b9\u6cd5\u80fd\u591f\u4e13\u6ce8\u4e8e\u4fe1\u606f\u4e30\u5bcc\u7684\u6d88\u606f\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "Wideformer\u901a\u8fc7\u9650\u5236\u6bcf\u6b21\u805a\u5408\u7684\u8f93\u5165\u91cf\u548c\u4f18\u5148\u5904\u7406\u4fe1\u606f\u4e30\u5bcc\u7684\u6d88\u606f\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u56fe\u6ce8\u610f\u529b\u4e2d\u7684\u8fc7\u5ea6\u805a\u5408\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2510.21418", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21418", "abs": "https://arxiv.org/abs/2510.21418", "authors": ["Lukas Bierling", "Davide Pasero", "Jan-Henrik Bertrand", "Kiki Van Gerwen"], "title": "DreamerV3-XP: Optimizing exploration through uncertainty estimation", "comment": null, "summary": "We introduce DreamerV3-XP, an extension of DreamerV3 that improves\nexploration and learning efficiency. This includes (i) a prioritized replay\nbuffer, scoring trajectories by return, reconstruction loss, and value error\nand (ii) an intrinsic reward based on disagreement over predicted environment\nrewards from an ensemble of world models. DreamerV3-XP is evaluated on a subset\nof Atari100k and DeepMind Control Visual Benchmark tasks, confirming the\noriginal DreamerV3 results and showing that our extensions lead to faster\nlearning and lower dynamics model loss, particularly in sparse-reward settings.", "AI": {"tldr": "DreamerV3-XP\u662fDreamerV3\u7684\u6269\u5c55\u7248\u672c\uff0c\u901a\u8fc7\u4f18\u5148\u56de\u653e\u7f13\u51b2\u5668\u548c\u57fa\u4e8e\u5206\u6b67\u7684\u5185\u5728\u5956\u52b1\u673a\u5236\u6539\u8fdb\u63a2\u7d22\u548c\u5b66\u4e60\u6548\u7387\u3002", "motivation": "\u6539\u8fdbDreamerV3\u7684\u63a2\u7d22\u80fd\u529b\u548c\u5b66\u4e60\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e2d\u3002", "method": "\u4f7f\u7528\u4f18\u5148\u56de\u653e\u7f13\u51b2\u5668\uff08\u6839\u636e\u56de\u62a5\u3001\u91cd\u5efa\u635f\u5931\u548c\u4ef7\u503c\u8bef\u5dee\u5bf9\u8f68\u8ff9\u8bc4\u5206\uff09\u548c\u57fa\u4e8e\u4e16\u754c\u6a21\u578b\u96c6\u5408\u9884\u6d4b\u73af\u5883\u5956\u52b1\u5206\u6b67\u7684\u5185\u5728\u5956\u52b1\u3002", "result": "\u5728Atari100k\u548cDeepMind Control Visual Benchmark\u4efb\u52a1\u5b50\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u786e\u8ba4\u4e86\u539f\u59cbDreamerV3\u7ed3\u679c\uff0c\u5e76\u663e\u793a\u5b66\u4e60\u901f\u5ea6\u66f4\u5feb\u3001\u52a8\u6001\u6a21\u578b\u635f\u5931\u66f4\u4f4e\uff0c\u5c24\u5176\u5728\u7a00\u758f\u5956\u52b1\u8bbe\u7f6e\u4e2d\u3002", "conclusion": "DreamerV3-XP\u901a\u8fc7\u63d0\u51fa\u7684\u6269\u5c55\u673a\u5236\u6709\u6548\u63d0\u5347\u4e86\u63a2\u7d22\u548c\u5b66\u4e60\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e2d\u3002"}}
{"id": "2510.21638", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21638", "abs": "https://arxiv.org/abs/2510.21638", "authors": ["Tala Aljaafari", "Varun Kanade", "Philip Torr", "Christian Schroeder de Witt"], "title": "DEEDEE: Fast and Scalable Out-of-Distribution Dynamics Detection", "comment": null, "summary": "Deploying reinforcement learning (RL) in safety-critical settings is\nconstrained by brittleness under distribution shift. We study\nout-of-distribution (OOD) detection for RL time series and introduce DEEDEE, a\ntwo-statistic detector that revisits representation-heavy pipelines with a\nminimal alternative. DEEDEE uses only an episodewise mean and an RBF kernel\nsimilarity to a training summary, capturing complementary global and local\ndeviations. Despite its simplicity, DEEDEE matches or surpasses contemporary\ndetectors across standard RL OOD suites, delivering a 600-fold reduction in\ncompute (FLOPs / wall-time) and an average 5% absolute accuracy gain over\nstrong baselines. Conceptually, our results indicate that diverse anomaly types\noften imprint on RL trajectories through a small set of low-order statistics,\nsuggesting a compact foundation for OOD detection in complex environments.", "AI": {"tldr": "DEEDEE\u662f\u4e00\u79cd\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u65f6\u95f4\u5e8f\u5217\u7684OOD\u68c0\u6d4b\u5668\uff0c\u4f7f\u7528\u4e24\u79cd\u7edf\u8ba1\u91cf\uff08episodewise\u5747\u503c\u548cRBF\u6838\u76f8\u4f3c\u5ea6\uff09\u6765\u6355\u6349\u5168\u5c40\u548c\u5c40\u90e8\u504f\u5dee\uff0c\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "motivation": "\u5728\u5b89\u5168\u5173\u952e\u73af\u5883\u4e2d\u90e8\u7f72\u5f3a\u5316\u5b66\u4e60\u53d7\u5230\u5206\u5e03\u504f\u79fb\u8106\u5f31\u6027\u7684\u9650\u5236\uff0c\u9700\u8981\u5f00\u53d1\u9ad8\u6548\u7684OOD\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51faDEEDEE\u68c0\u6d4b\u5668\uff0c\u4ec5\u4f7f\u7528episodewise\u5747\u503c\u548cRBF\u6838\u76f8\u4f3c\u5ea6\u4e24\u79cd\u7edf\u8ba1\u91cf\uff0c\u6355\u6349\u8bad\u7ec3\u6458\u8981\u7684\u5168\u5c40\u548c\u5c40\u90e8\u504f\u5dee\u3002", "result": "DEEDEE\u5728\u6807\u51c6RL OOD\u6d4b\u8bd5\u5957\u4ef6\u4e2d\u5339\u914d\u6216\u8d85\u8d8a\u73b0\u6709\u68c0\u6d4b\u5668\uff0c\u8ba1\u7b97\u91cf\u51cf\u5c11600\u500d\uff0c\u5e73\u5747\u51c6\u786e\u7387\u63d0\u53475%\u3002", "conclusion": "\u7ed3\u679c\u8868\u660e\uff0c\u591a\u6837\u5f02\u5e38\u7c7b\u578b\u901a\u5e38\u901a\u8fc7\u5c11\u91cf\u4f4e\u9636\u7edf\u8ba1\u91cf\u5728RL\u8f68\u8ff9\u4e2d\u7559\u4e0b\u5370\u8bb0\uff0c\u4e3a\u590d\u6742\u73af\u5883\u4e2d\u7684OOD\u68c0\u6d4b\u63d0\u4f9b\u4e86\u7d27\u51d1\u57fa\u7840\u3002"}}
{"id": "2510.21296", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21296", "abs": "https://arxiv.org/abs/2510.21296", "authors": ["Sukanya Patra", "Souhaib Ben Taieb"], "title": "An Evidence-Based Post-Hoc Adjustment Framework for Anomaly Detection Under Data Contamination", "comment": "Accepted in the Thirty-ninth Annual Conference on Neural Information\n  Processing Systems (NeurIPS 2025)", "summary": "Unsupervised anomaly detection (AD) methods typically assume clean training\ndata, yet real-world datasets often contain undetected or mislabeled anomalies,\nleading to significant performance degradation. Existing solutions require\naccess to the training pipelines, data or prior knowledge of the proportions of\nanomalies in the data, limiting their real-world applicability. To address this\nchallenge, we propose EPHAD, a simple yet effective test-time adaptation\nframework that updates the outputs of AD models trained on contaminated\ndatasets using evidence gathered at test time. Our approach integrates the\nprior knowledge captured by the AD model trained on contaminated datasets with\nevidence derived from multimodal foundation models like Contrastive\nLanguage-Image Pre-training (CLIP), classical AD methods like the Latent\nOutlier Factor or domain-specific knowledge. We illustrate the intuition behind\nEPHAD using a synthetic toy example and validate its effectiveness through\ncomprehensive experiments across eight visual AD datasets, twenty-six tabular\nAD datasets, and a real-world industrial AD dataset. Additionally, we conduct\nan ablation study to analyse hyperparameter influence and robustness to varying\ncontamination levels, demonstrating the versatility and robustness of EPHAD\nacross diverse AD models and evidence pairs. To ensure reproducibility, our\ncode is publicly available at https://github.com/sukanyapatra1997/EPHAD.", "AI": {"tldr": "EPHAD\u662f\u4e00\u4e2a\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u7528\u4e8e\u5904\u7406\u8bad\u7ec3\u6570\u636e\u88ab\u5f02\u5e38\u6c61\u67d3\u7684\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u95ee\u9898\uff0c\u901a\u8fc7\u7ed3\u5408\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u7ecf\u5178\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5728\u6d4b\u8bd5\u65f6\u66f4\u65b0\u6a21\u578b\u8f93\u51fa\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u6570\u636e\u96c6\u5f80\u5f80\u5305\u542b\u672a\u88ab\u68c0\u6d4b\u5230\u6216\u9519\u8bef\u6807\u8bb0\u7684\u5f02\u5e38\uff0c\u5bfc\u81f4\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u9700\u8981\u8bbf\u95ee\u8bad\u7ec3\u6d41\u7a0b\u3001\u6570\u636e\u6216\u5df2\u77e5\u5f02\u5e38\u6bd4\u4f8b\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faEPHAD\u6846\u67b6\uff0c\u5728\u6d4b\u8bd5\u65f6\u66f4\u65b0\u5728\u6c61\u67d3\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u5f02\u5e38\u68c0\u6d4b\u6a21\u578b\u7684\u8f93\u51fa\uff0c\u6574\u5408\u9884\u8bad\u7ec3\u6a21\u578b\uff08\u5982CLIP\uff09\u3001\u7ecf\u5178\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff08\u5982\u6f5c\u5728\u5f02\u5e38\u56e0\u5b50\uff09\u6216\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u63d0\u4f9b\u7684\u8bc1\u636e\u3002", "result": "\u57288\u4e2a\u89c6\u89c9\u5f02\u5e38\u68c0\u6d4b\u6570\u636e\u96c6\u300126\u4e2a\u8868\u683c\u5f02\u5e38\u68c0\u6d4b\u6570\u636e\u96c6\u548c1\u4e2a\u771f\u5b9e\u5de5\u4e1a\u5f02\u5e38\u68c0\u6d4b\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u5206\u6790\u8d85\u53c2\u6570\u5f71\u54cd\u548c\u5bf9\u4e0d\u540c\u6c61\u67d3\u6c34\u5e73\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "EPHAD\u5728\u4e0d\u540c\u5f02\u5e38\u68c0\u6d4b\u6a21\u578b\u548c\u8bc1\u636e\u5bf9\u4e2d\u5c55\u73b0\u51fa\u591a\u529f\u80fd\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u89e3\u51b3\u8bad\u7ec3\u6570\u636e\u6c61\u67d3\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.21303", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21303", "abs": "https://arxiv.org/abs/2510.21303", "authors": ["Prakhar Ganesh", "Hsiang Hsu", "Golnoosh Farnadi"], "title": "Data as a Lever: A Neighbouring Datasets Perspective on Predictive Multiplicity", "comment": null, "summary": "Multiplicity -- the existence of distinct models with comparable performance\n-- has received growing attention in recent years. While prior work has largely\nemphasized modelling choices, the critical role of data in shaping multiplicity\nhas been comparatively overlooked. In this work, we introduce a neighbouring\ndatasets framework to examine the most granular case: the impact of a\nsingle-data-point difference on multiplicity. Our analysis yields a seemingly\ncounterintuitive finding: neighbouring datasets with greater inter-class\ndistribution overlap exhibit lower multiplicity. This reversal of conventional\nexpectations arises from a shared Rashomon parameter, and we substantiate it\nwith rigorous proofs.\n  Building on this foundation, we extend our framework to two practical\ndomains: active learning and data imputation. For each, we establish natural\nextensions of the neighbouring datasets perspective, conduct the first\nsystematic study of multiplicity in existing algorithms, and finally, propose\nnovel multiplicity-aware methods, namely, multiplicity-aware data acquisition\nstrategies for active learning and multiplicity-aware data imputation\ntechniques.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u6570\u636e\u5bf9\u6a21\u578b\u591a\u91cd\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u76f8\u90bb\u6570\u636e\u96c6\uff08\u4ec5\u76f8\u5dee\u4e00\u4e2a\u6570\u636e\u70b9\uff09\u4e2d\u7c7b\u95f4\u5206\u5e03\u91cd\u53e0\u5ea6\u8d8a\u9ad8\uff0c\u591a\u91cd\u6027\u53cd\u800c\u8d8a\u4f4e\u3002\u57fa\u4e8e\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u591a\u4efb\u52a1\u611f\u77e5\u7684\u4e3b\u52a8\u5b66\u4e60\u6570\u636e\u83b7\u53d6\u7b56\u7565\u548c\u6570\u636e\u63d2\u8865\u6280\u672f\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5efa\u6a21\u9009\u62e9\u5bf9\u591a\u91cd\u6027\u7684\u5f71\u54cd\uff0c\u800c\u5ffd\u89c6\u4e86\u6570\u636e\u7684\u5173\u952e\u4f5c\u7528\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u76f8\u90bb\u6570\u636e\u96c6\u6846\u67b6\uff0c\u5206\u6790\u5355\u4e2a\u6570\u636e\u70b9\u5dee\u5f02\u5bf9\u591a\u91cd\u6027\u7684\u5f71\u54cd\u3002", "method": "\u5f15\u5165\u76f8\u90bb\u6570\u636e\u96c6\u6846\u67b6\uff0c\u5206\u6790\u5355\u4e2a\u6570\u636e\u70b9\u5dee\u5f02\u5bf9\u591a\u91cd\u6027\u7684\u5f71\u54cd\uff1b\u901a\u8fc7\u4e25\u683c\u7684\u6570\u5b66\u8bc1\u660e\u9a8c\u8bc1\u53d1\u73b0\uff1b\u5c06\u6846\u67b6\u6269\u5c55\u5230\u4e3b\u52a8\u5b66\u4e60\u548c\u6570\u636e\u63d2\u8865\u4e24\u4e2a\u5b9e\u9645\u9886\u57df\u3002", "result": "\u53d1\u73b0\u76f8\u90bb\u6570\u636e\u96c6\u4e2d\u7c7b\u95f4\u5206\u5e03\u91cd\u53e0\u5ea6\u8d8a\u9ad8\uff0c\u591a\u91cd\u6027\u8d8a\u4f4e\uff0c\u8fd9\u4e0e\u4f20\u7edf\u9884\u671f\u76f8\u53cd\uff1b\u63d0\u51fa\u4e86\u591a\u4efb\u52a1\u611f\u77e5\u7684\u4e3b\u52a8\u5b66\u4e60\u6570\u636e\u83b7\u53d6\u7b56\u7565\u548c\u591a\u4efb\u52a1\u611f\u77e5\u7684\u6570\u636e\u63d2\u8865\u6280\u672f\u3002", "conclusion": "\u6570\u636e\u5728\u5851\u9020\u591a\u91cd\u6027\u65b9\u9762\u8d77\u7740\u5173\u952e\u4f5c\u7528\uff0c\u901a\u8fc7\u7406\u89e3\u6570\u636e\u5c42\u9762\u7684\u591a\u91cd\u6027\uff0c\u53ef\u4ee5\u5f00\u53d1\u51fa\u66f4\u6709\u6548\u7684\u591a\u4efb\u52a1\u611f\u77e5\u7b97\u6cd5\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2510.21322", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.21322", "abs": "https://arxiv.org/abs/2510.21322", "authors": ["Antoine Boutet", "Lucas Magnana"], "title": "Leverage Unlearning to Sanitize LLMs", "comment": null, "summary": "Pre-trained large language models (LLMs) are becoming useful for various\ntasks. To improve their performance on certain tasks, it is necessary to\nfine-tune them on specific data corpora (e.g., medical reports, business data).\nThese specialized data corpora may contain sensitive data (e.g., personal or\nconfidential data) that will be memorized by the model and likely to be\nregurgitated during its subsequent use. This memorization of sensitive\ninformation by the model poses a significant privacy or confidentiality issue.\nTo remove this memorization and sanitize the model without requiring costly\nadditional fine-tuning on a secured data corpus, we propose SANI. SANI is an\nunlearning approach to sanitize language models. It relies on both an erasure\nand repair phases that 1) reset certain neurons in the last layers of the model\nto disrupt the memorization of fine-grained information, and then 2) fine-tune\nthe model while avoiding memorizing sensitive information. We comprehensively\nevaluate SANI to sanitize both a model fine-tuned and specialized with medical\ndata by removing directly and indirectly identifiers from the memorization of\nthe model, and a standard pre-trained model by removing specific terms defined\nas confidential information from the model. Results show that with only few\nadditional epochs of unlearning, the model is sanitized and the number of\nregurgitations is drastically reduced. This approach can be particularly useful\nfor hospitals or other industries that have already spent significant resources\ntraining models on large datasets and wish to sanitize them before sharing.", "AI": {"tldr": "SANI\u662f\u4e00\u79cd\u8bed\u8a00\u6a21\u578b\u53bb\u8bb0\u5fc6\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u64e6\u9664\u548c\u4fee\u590d\u4e24\u4e2a\u9636\u6bb5\u6765\u79fb\u9664\u6a21\u578b\u5bf9\u654f\u611f\u4fe1\u606f\u7684\u8bb0\u5fc6\uff0c\u65e0\u9700\u6602\u8d35\u7684\u989d\u5916\u5fae\u8c03\u3002", "motivation": "\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u4efb\u52a1\u5fae\u8c03\u65f6\u4f1a\u8bb0\u5fc6\u654f\u611f\u6570\u636e\uff0c\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u9700\u8981\u4e00\u79cd\u65e0\u9700\u91cd\u65b0\u5fae\u8c03\u7684\u53bb\u8bb0\u5fc6\u5316\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u64e6\u9664\u548c\u4fee\u590d\u4e24\u9636\u6bb5\uff1a1\uff09\u91cd\u7f6e\u6a21\u578b\u6700\u540e\u5c42\u7684\u7279\u5b9a\u795e\u7ecf\u5143\u4ee5\u7834\u574f\u7ec6\u7c92\u5ea6\u4fe1\u606f\u8bb0\u5fc6\uff1b2\uff09\u907f\u514d\u8bb0\u5fc6\u654f\u611f\u4fe1\u606f\u7684\u5fae\u8c03\u3002", "result": "\u4ec5\u9700\u5c11\u91cf\u989d\u5916\u8bad\u7ec3\u5468\u671f\u5373\u53ef\u663e\u8457\u51cf\u5c11\u6a21\u578b\u5bf9\u654f\u611f\u4fe1\u606f\u7684\u590d\u73b0\uff0c\u6709\u6548\u79fb\u9664\u76f4\u63a5\u548c\u95f4\u63a5\u6807\u8bc6\u7b26\u7684\u8bb0\u5fc6\u3002", "conclusion": "SANI\u4e3a\u533b\u9662\u7b49\u884c\u4e1a\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u6a21\u578b\u51c0\u5316\u65b9\u6cd5\uff0c\u53ef\u5728\u5171\u4eab\u6a21\u578b\u524d\u6709\u6548\u4fdd\u62a4\u654f\u611f\u4fe1\u606f\u3002"}}
{"id": "2510.21379", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21379", "abs": "https://arxiv.org/abs/2510.21379", "authors": ["Dong Bok Lee", "Aoxuan Silvia Zhang", "Byungjoo Kim", "Junhyeon Park", "Steven Adriaensen", "Juho Lee", "Sung Ju Hwang", "Hae Beom Lee"], "title": "Cost-Sensitive Freeze-thaw Bayesian Optimization for Efficient Hyperparameter Tuning", "comment": "Published at NeurIPS 2025", "summary": "In this paper, we address the problem of \\emph{cost-sensitive} hyperparameter\noptimization (HPO) built upon freeze-thaw Bayesian optimization (BO).\nSpecifically, we assume a scenario where users want to early-stop the HPO\nprocess when the expected performance improvement is not satisfactory with\nrespect to the additional computational cost. Motivated by this scenario, we\nintroduce \\emph{utility} in the freeze-thaw framework, a function describing\nthe trade-off between the cost and performance that can be estimated from the\nuser's preference data. This utility function, combined with our novel\nacquisition function and stopping criterion, allows us to dynamically continue\ntraining the configuration that we expect to maximally improve the utility in\nthe future, and also automatically stop the HPO process around the maximum\nutility. Further, we improve the sample efficiency of existing freeze-thaw\nmethods with transfer learning to develop a specialized surrogate model for the\ncost-sensitive HPO problem. We validate our algorithm on established\nmulti-fidelity HPO benchmarks and show that it outperforms all the previous\nfreeze-thaw BO and transfer-BO baselines we consider, while achieving a\nsignificantly better trade-off between the cost and performance. Our code is\npublicly available at https://github.com/db-Lee/CFBO.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u51bb\u7ed3-\u89e3\u51bb\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u6210\u672c\u654f\u611f\u8d85\u53c2\u6570\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u6548\u7528\u51fd\u6570\u3001\u65b0\u7684\u91c7\u96c6\u51fd\u6570\u548c\u505c\u6b62\u51c6\u5219\uff0c\u5728\u6027\u80fd\u548c\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u5b9e\u73b0\u66f4\u597d\u7684\u6743\u8861\u3002", "motivation": "\u9488\u5bf9\u7528\u6237\u5e0c\u671b\u5728\u9884\u671f\u6027\u80fd\u6539\u8fdb\u4e0d\u4ee4\u4eba\u6ee1\u610f\u65f6\u63d0\u524d\u505c\u6b62\u8d85\u53c2\u6570\u4f18\u5316\u8fc7\u7a0b\u7684\u9700\u6c42\uff0c\u89e3\u51b3\u6210\u672c\u654f\u611f\u7684\u8d85\u53c2\u6570\u4f18\u5316\u95ee\u9898\u3002", "method": "\u5728\u51bb\u7ed3-\u89e3\u51bb\u6846\u67b6\u4e2d\u5f15\u5165\u6548\u7528\u51fd\u6570\uff0c\u7ed3\u5408\u65b0\u7684\u91c7\u96c6\u51fd\u6570\u548c\u505c\u6b62\u51c6\u5219\uff0c\u52a8\u6001\u9009\u62e9\u6700\u6709\u6f5c\u529b\u7684\u914d\u7f6e\u7ee7\u7eed\u8bad\u7ec3\uff0c\u5e76\u81ea\u52a8\u5728\u6700\u5927\u6548\u7528\u9644\u8fd1\u505c\u6b62\u4f18\u5316\u8fc7\u7a0b\u3002\u540c\u65f6\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u63d0\u9ad8\u6837\u672c\u6548\u7387\u3002", "result": "\u5728\u5df2\u5efa\u7acb\u7684\u591a\u4fdd\u771f\u5ea6\u8d85\u53c2\u6570\u4f18\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u7b97\u6cd5\u4f18\u4e8e\u6240\u6709\u8003\u8651\u7684\u5148\u524d\u51bb\u7ed3-\u89e3\u51bb\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u8fc1\u79fb\u8d1d\u53f6\u65af\u4f18\u5316\u57fa\u7ebf\uff0c\u5728\u6210\u672c\u548c\u6027\u80fd\u4e4b\u95f4\u5b9e\u73b0\u4e86\u663e\u8457\u66f4\u597d\u7684\u6743\u8861\u3002", "conclusion": "\u63d0\u51fa\u7684\u6210\u672c\u654f\u611f\u8d85\u53c2\u6570\u4f18\u5316\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5e73\u8861\u8ba1\u7b97\u6210\u672c\u548c\u6a21\u578b\u6027\u80fd\uff0c\u5728\u51bb\u7ed3-\u89e3\u51bb\u8d1d\u53f6\u65af\u4f18\u5316\u6846\u67b6\u4e0b\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2510.21455", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21455", "abs": "https://arxiv.org/abs/2510.21455", "authors": ["Jorge D\u00edez", "Pablo P\u00e9rez-N\u00fa\u00f1ez", "Oscar Luaces", "Beatriz Remeseiro", "Antonio Bahamonde"], "title": "Towards Explainable Personalized Recommendations by Learning from Users' Photos", "comment": null, "summary": "Explaining the output of a complex system, such as a Recommender System (RS),\nis becoming of utmost importance for both users and companies. In this paper we\nexplore the idea that personalized explanations can be learned as\nrecommendation themselves. There are plenty of online services where users can\nupload some photos, in addition to rating items. We assume that users take\nthese photos to reinforce or justify their opinions about the items. For this\nreason we try to predict what photo a user would take of an item, because that\nimage is the argument that can best convince her of the qualities of the item.\nIn this sense, an RS can explain its results and, therefore, increase its\nreliability. Furthermore, once we have a model to predict attractive images for\nusers, we can estimate their distribution. Thus, the companies acquire a vivid\nknowledge about the aspects that the clients highlight of their products. The\npaper includes a formal framework that estimates the authorship probability for\na given pair (user, photo). To illustrate the proposal, we use data gathered\nfrom TripAdvisor containing the reviews (with photos) of restaurants in six\ncities of different sizes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u4e2a\u6027\u5316\u89e3\u91ca\u4f5c\u4e3a\u63a8\u8350\u672c\u8eab\u6765\u5b66\u4e60\uff0c\u901a\u8fc7\u9884\u6d4b\u7528\u6237\u4f1a\u4e3a\u7269\u54c1\u62cd\u6444\u4ec0\u4e48\u7167\u7247\u6765\u751f\u6210\u6709\u8bf4\u670d\u529b\u7684\u89e3\u91ca\uff0c\u4ece\u800c\u63d0\u9ad8\u63a8\u8350\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u89e3\u91ca\u590d\u6742\u7cfb\u7edf\uff08\u5982\u63a8\u8350\u7cfb\u7edf\uff09\u7684\u8f93\u51fa\u5bf9\u7528\u6237\u548c\u516c\u53f8\u90fd\u81f3\u5173\u91cd\u8981\u3002\u7528\u6237\u4e0a\u4f20\u7684\u7167\u7247\u53ef\u80fd\u5f3a\u5316\u6216\u8bc1\u660e\u4ed6\u4eec\u5bf9\u7269\u54c1\u7684\u8bc4\u4ef7\uff0c\u56e0\u6b64\u9884\u6d4b\u7528\u6237\u4f1a\u62cd\u6444\u4ec0\u4e48\u7167\u7247\u53ef\u4ee5\u751f\u6210\u6700\u80fd\u8bf4\u670d\u7528\u6237\u7684\u89e3\u91ca\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5f62\u5f0f\u5316\u6846\u67b6\u6765\u4f30\u8ba1\u7ed9\u5b9a\uff08\u7528\u6237\uff0c\u7167\u7247\uff09\u5bf9\u7684\u4f5c\u8005\u6982\u7387\u3002\u4f7f\u7528\u4eceTripAdvisor\u6536\u96c6\u7684\u5305\u542b\u9910\u5385\u8bc4\u8bba\uff08\u5e26\u7167\u7247\uff09\u7684\u6570\u636e\u96c6\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u901a\u8fc7\u9884\u6d4b\u7528\u6237\u53ef\u80fd\u62cd\u6444\u7684\u7167\u7247\uff0c\u63a8\u8350\u7cfb\u7edf\u53ef\u4ee5\u63d0\u4f9b\u66f4\u5177\u8bf4\u670d\u529b\u7684\u89e3\u91ca\uff0c\u540c\u65f6\u516c\u53f8\u53ef\u4ee5\u4e86\u89e3\u5ba2\u6237\u5173\u6ce8\u7684\u4ea7\u54c1\u7279\u70b9\u5206\u5e03\u3002", "conclusion": "\u5c06\u4e2a\u6027\u5316\u89e3\u91ca\u4f5c\u4e3a\u63a8\u8350\u5b66\u4e60\u7684\u65b9\u6cd5\u80fd\u591f\u63d0\u9ad8\u63a8\u8350\u7cfb\u7edf\u7684\u53ef\u9760\u6027\uff0c\u5e76\u4e3a\u516c\u53f8\u63d0\u4f9b\u5173\u4e8e\u5ba2\u6237\u504f\u597d\u7684\u751f\u52a8\u77e5\u8bc6\u3002"}}
{"id": "2510.21506", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21506", "abs": "https://arxiv.org/abs/2510.21506", "authors": ["Tanmay Devale", "Pramith Devulapalli", "Steve Hanneke"], "title": "Uniform Convergence Beyond Glivenko-Cantelli", "comment": null, "summary": "We characterize conditions under which collections of distributions on\n$\\{0,1\\}^\\mathbb{N}$ admit uniform estimation of their mean. Prior work from\nVapnik and Chervonenkis (1971) has focused on uniform convergence using the\nempirical mean estimator, leading to the principle known as $P-$\nGlivenko-Cantelli. We extend this framework by moving beyond the empirical mean\nestimator and introducing Uniform Mean Estimability, also called $UME-$\nlearnability, which captures when a collection permits uniform mean estimation\nby any arbitrary estimator. We work on the space created by the mean vectors of\nthe collection of distributions. For each distribution, the mean vector records\nthe expected value in each coordinate. We show that separability of the mean\nvectors is a sufficient condition for $UME-$ learnability. However, we show\nthat separability of the mean vectors is not necessary for $UME-$ learnability\nby constructing a collection of distributions whose mean vectors are\nnon-separable yet $UME-$ learnable using techniques fundamentally different\nfrom those used in our separability-based analysis. Finally, we establish that\ncountable unions of $UME-$ learnable collections are also $UME-$ learnable,\nsolving a conjecture posed in Cohen et al. (2025).", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86Vapnik\u548cChervonenkis\u7684\u7ecf\u5178\u6846\u67b6\uff0c\u5f15\u5165\u4e86Uniform Mean Estimability\uff08UME-learnability\uff09\u6982\u5ff5\uff0c\u7814\u7a76\u5206\u5e03\u96c6\u5408\u5728\u4efb\u610f\u4f30\u8ba1\u5668\u4e0b\u662f\u5426\u5141\u8bb8\u5747\u5300\u5747\u503c\u4f30\u8ba1\u3002\u8bc1\u660e\u4e86\u5747\u503c\u5411\u91cf\u53ef\u5206\u6027\u662fUME-learnability\u7684\u5145\u5206\u6761\u4ef6\u4f46\u975e\u5fc5\u8981\u6761\u4ef6\uff0c\u5e76\u89e3\u51b3\u4e86Cohen\u7b49\u4eba\u63d0\u51fa\u7684\u5173\u4e8e\u53ef\u6570\u5e76\u96c6\u53ef\u5b66\u4e60\u6027\u7684\u731c\u60f3\u3002", "motivation": "\u4f20\u7edfVapnik-Chervonenkis\u7406\u8bba\u4e13\u6ce8\u4e8e\u7ecf\u9a8c\u5747\u503c\u4f30\u8ba1\u5668\u7684\u5747\u5300\u6536\u655b\u6027\uff08P-Glivenko-Cantelli\uff09\uff0c\u672c\u6587\u65e8\u5728\u8d85\u8d8a\u8fd9\u4e00\u9650\u5236\uff0c\u7814\u7a76\u5728\u4efb\u610f\u4f30\u8ba1\u5668\u4e0b\u5206\u5e03\u96c6\u5408\u662f\u5426\u5141\u8bb8\u5747\u5300\u5747\u503c\u4f30\u8ba1\u3002", "method": "\u5728\u7531\u5206\u5e03\u96c6\u5408\u7684\u5747\u503c\u5411\u91cf\u6784\u6210\u7684\u7a7a\u95f4\u4e0a\u5de5\u4f5c\uff0c\u7814\u7a76\u5747\u503c\u5411\u91cf\u7684\u53ef\u5206\u6027\u4e0eUME-learnability\u7684\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u6784\u9020\u975e\u53ef\u5206\u4f46UME-learnable\u7684\u5206\u5e03\u96c6\u5408\u6765\u8bc1\u660e\u53ef\u5206\u6027\u975e\u5fc5\u8981\u6761\u4ef6\u3002", "result": "1\uff09\u5747\u503c\u5411\u91cf\u53ef\u5206\u6027\u662fUME-learnability\u7684\u5145\u5206\u6761\u4ef6\uff1b2\uff09\u53ef\u5206\u6027\u975e\u5fc5\u8981\u6761\u4ef6\uff0c\u5b58\u5728\u975e\u53ef\u5206\u4f46UME-learnable\u7684\u5206\u5e03\u96c6\u5408\uff1b3\uff09UME-learnable\u96c6\u5408\u7684\u53ef\u6570\u5e76\u96c6\u4e5f\u662fUME-learnable\u3002", "conclusion": "\u672c\u6587\u5efa\u7acb\u4e86Uniform Mean Estimability\u7684\u7406\u8bba\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5747\u503c\u4f30\u8ba1\u7684\u5747\u5300\u53ef\u5b66\u4e60\u6027\u6761\u4ef6\uff0c\u89e3\u51b3\u4e86\u76f8\u5173\u731c\u60f3\uff0c\u4e3a\u5206\u5e03\u96c6\u5408\u7684\u5747\u503c\u4f30\u8ba1\u7406\u8bba\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u548c\u5de5\u5177\u3002"}}
{"id": "2510.21531", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21531", "abs": "https://arxiv.org/abs/2510.21531", "authors": ["Jan Wehner", "Mario Fritz"], "title": "Probe-based Fine-tuning for Reducing Toxicity", "comment": null, "summary": "Probes trained on model activations can detect undesirable behaviors like\ndeception or biases that are difficult to identify from outputs alone. This\nmakes them useful detectors to identify misbehavior. Furthermore, they are also\nvaluable training signals, since they not only reward outputs, but also good\ninternal processes for arriving at that output. However, training against\ninterpretability tools raises a fundamental concern: when a monitor becomes a\ntraining target, it may cease to be reliable (Goodhart's Law). We propose two\nmethods for training against probes based on Supervised Fine-tuning and Direct\nPreference Optimization. We conduct an initial exploration of these methods in\na testbed for reducing toxicity and evaluate the amount by which probe accuracy\ndrops when training against them. To retain the accuracy of probe-detectors\nafter training, we attempt (1) to train against an ensemble of probes, (2)\nretain held-out probes that aren't used for training, and (3) retrain new\nprobes after training.\n  First, probe-based preference optimization unexpectedly preserves probe\ndetectability better than classifier-based methods, suggesting the preference\nlearning objective incentivizes maintaining rather than obfuscating relevant\nrepresentations. Second, probe diversity provides minimal practical benefit -\nsimply retraining probes after optimization recovers high detection accuracy.\nOur findings suggest probe-based training can be viable for certain alignment\nmethods, though probe ensembles are largely unnecessary when retraining is\nfeasible.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u4f7f\u7528\u63a2\u9488\u4f5c\u4e3a\u8bad\u7ec3\u4fe1\u53f7\u65f6\u9762\u4e34\u7684Goodhart\u5b9a\u5f8b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u76d1\u7763\u5fae\u8c03\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\u7684\u4e24\u79cd\u65b9\u6cd5\uff0c\u53d1\u73b0\u5728\u504f\u597d\u5b66\u4e60\u76ee\u6807\u4e0b\u63a2\u9488\u68c0\u6d4b\u80fd\u529b\u5f97\u5230\u4fdd\u6301\uff0c\u4e14\u91cd\u65b0\u8bad\u7ec3\u63a2\u9488\u6bd4\u4f7f\u7528\u63a2\u9488\u96c6\u6210\u66f4\u6709\u6548\u3002", "motivation": "\u63a2\u9488\u53ef\u4ee5\u68c0\u6d4b\u6a21\u578b\u5185\u90e8\u7684\u4e0d\u826f\u884c\u4e3a\uff0c\u5982\u6b3a\u9a97\u6216\u504f\u89c1\uff0c\u8fd9\u4e9b\u4ece\u8f93\u51fa\u4e2d\u96be\u4ee5\u8bc6\u522b\u3002\u4f46\u5c06\u63a2\u9488\u4f5c\u4e3a\u8bad\u7ec3\u76ee\u6807\u65f6\u53ef\u80fd\u9762\u4e34Goodhart\u5b9a\u5f8b\u95ee\u9898\uff0c\u5373\u76d1\u63a7\u6307\u6807\u5931\u53bb\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u57fa\u4e8e\u63a2\u9488\u7684\u8bad\u7ec3\u65b9\u6cd5\uff1a\u76d1\u7763\u5fae\u8c03\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\u3002\u5728\u6bd2\u6027\u51cf\u5c11\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u8bad\u7ec3\u540e\u63a2\u9488\u51c6\u786e\u7387\u4e0b\u964d\u7a0b\u5ea6\u3002\u5c1d\u8bd5\u4e86\u4e09\u79cd\u4fdd\u6301\u63a2\u9488\u51c6\u786e\u6027\u7684\u7b56\u7565\uff1a\u8bad\u7ec3\u5bf9\u6297\u63a2\u9488\u96c6\u6210\u3001\u4fdd\u7559\u672a\u7528\u4e8e\u8bad\u7ec3\u7684\u63a2\u9488\u3001\u8bad\u7ec3\u540e\u91cd\u65b0\u8bad\u7ec3\u65b0\u63a2\u9488\u3002", "result": "\u63a2\u9488\u57fa\u4e8e\u7684\u504f\u597d\u4f18\u5316\u610f\u5916\u5730\u6bd4\u57fa\u4e8e\u5206\u7c7b\u5668\u7684\u65b9\u6cd5\u66f4\u597d\u5730\u4fdd\u6301\u4e86\u63a2\u9488\u68c0\u6d4b\u80fd\u529b\uff1b\u63a2\u9488\u591a\u6837\u6027\u63d0\u4f9b\u7684\u5b9e\u9645\u76ca\u5904\u6709\u9650\uff0c\u91cd\u65b0\u8bad\u7ec3\u63a2\u9488\u53ef\u4ee5\u6062\u590d\u9ad8\u68c0\u6d4b\u51c6\u786e\u7387\u3002", "conclusion": "\u57fa\u4e8e\u63a2\u9488\u7684\u8bad\u7ec3\u5bf9\u4e8e\u67d0\u4e9b\u5bf9\u9f50\u65b9\u6cd5\u662f\u53ef\u884c\u7684\uff0c\u5f53\u91cd\u65b0\u8bad\u7ec3\u53ef\u884c\u65f6\uff0c\u63a2\u9488\u96c6\u6210\u57fa\u672c\u4e0a\u662f\u4e0d\u5fc5\u8981\u7684\u3002"}}
{"id": "2510.21537", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21537", "abs": "https://arxiv.org/abs/2510.21537", "authors": ["Nikolai Gruzinov", "Ksenia Sycheva", "Earl T. Barr", "Alex Bezzubov"], "title": "Excision Score: Evaluating Edits with Surgical Precision", "comment": "Code is available at\n  https://anonymous.4open.science/r/excision-score-eval-B9AF/", "summary": "Many tasks revolve around editing a document, whether code or text. We\nformulate the revision similarity problem to unify a wide range of machine\nlearning evaluation problems whose goal is to assess a revision to an existing\ndocument. We observe that revisions usually change only a small portion of an\nexisting document, so the existing document and its immediate revisions share a\nmajority of their content. We formulate five adequacy criteria for revision\nsimilarity measures, designed to align them with human judgement. We show that\npopular pairwise measures, like BLEU, fail to meet these criteria, because\ntheir scores are dominated by the shared content. They report high similarity\nbetween two revisions when humans would assess them as quite different. This is\na fundamental flaw we address. We propose a novel static measure, Excision\nScore (ES), which computes longest common subsequence (LCS) to remove content\nshared by an existing document with the ground truth and predicted revisions,\nbefore comparing only the remaining divergent regions. This is analogous to a\nsurgeon creating a sterile field to focus on the work area. We use\napproximation to speed the standard cubic LCS computation to quadratic. In\ncode-editing evaluation, where static measures are often used as a cheap proxy\nfor passing tests, we demonstrate that ES surpasses existing measures. When\naligned with test execution on HumanEvalFix, ES improves over its nearest\ncompetitor, SARI, by 12% Pearson correlation and by >21% over standard measures\nlike BLEU. The key criterion is invariance to shared context; when we perturb\nHumanEvalFix with increased shared context, ES' improvement over SARI increases\nto 20% and >30% over standard measures. ES also handles other corner cases that\nother measures do not, such as correctly aligning moved code blocks, and\nappropriately rewarding matching insertions or deletions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4fee\u8ba2\u76f8\u4f3c\u6027\u95ee\u9898\uff0c\u5e76\u6307\u51fa\u4f20\u7edf\u76f8\u4f3c\u6027\u5ea6\u91cf\u65b9\u6cd5\uff08\u5982BLEU\uff09\u56e0\u8fc7\u5ea6\u5173\u6ce8\u5171\u4eab\u5185\u5bb9\u800c\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30\u6587\u6863\u4fee\u8ba2\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9759\u6001\u5ea6\u91cf\u65b9\u6cd5\u2014\u2014\u5207\u9664\u5206\u6570\uff08ES\uff09\uff0c\u901a\u8fc7\u79fb\u9664\u5171\u4eab\u5185\u5bb9\u540e\u6bd4\u8f83\u5dee\u5f02\u533a\u57df\u6765\u66f4\u597d\u5730\u4e0e\u4eba\u7c7b\u5224\u65ad\u5bf9\u9f50\u3002", "motivation": "\u73b0\u6709\u6587\u6863\u4fee\u8ba2\u8bc4\u4f30\u65b9\u6cd5\uff08\u5982BLEU\uff09\u5b58\u5728\u6839\u672c\u7f3a\u9677\uff0c\u5176\u5f97\u5206\u88ab\u5171\u4eab\u5185\u5bb9\u4e3b\u5bfc\uff0c\u5bfc\u81f4\u5728\u4eba\u7c7b\u8ba4\u4e3a\u5dee\u5f02\u5f88\u5927\u7684\u4fee\u8ba2\u4e4b\u95f4\u4ecd\u62a5\u544a\u9ad8\u76f8\u4f3c\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u66f4\u597d\u53cd\u6620\u4eba\u7c7b\u5224\u65ad\u7684\u4fee\u8ba2\u76f8\u4f3c\u6027\u5ea6\u91cf\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u5207\u9664\u5206\u6570\uff08ES\uff09\u65b9\u6cd5\uff1a\u4f7f\u7528\u6700\u957f\u516c\u5171\u5b50\u5e8f\u5217\uff08LCS\uff09\u79fb\u9664\u73b0\u6709\u6587\u6863\u4e0e\u4fee\u8ba2\u7248\u672c\u4e4b\u95f4\u7684\u5171\u4eab\u5185\u5bb9\uff0c\u7136\u540e\u4ec5\u6bd4\u8f83\u5269\u4f59\u7684\u5dee\u5f02\u533a\u57df\u3002\u901a\u8fc7\u8fd1\u4f3c\u65b9\u6cd5\u5c06\u6807\u51c6\u7acb\u65b9LCS\u8ba1\u7b97\u52a0\u901f\u5230\u4e8c\u6b21\u590d\u6742\u5ea6\u3002", "result": "\u5728\u4ee3\u7801\u7f16\u8f91\u8bc4\u4f30\u4e2d\uff0cES\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u5728HumanEvalFix\u6570\u636e\u96c6\u4e0a\uff0c\u4e0e\u6700\u63a5\u8fd1\u7684\u7ade\u4e89\u8005SARI\u76f8\u6bd4\uff0cES\u7684\u76ae\u5c14\u900a\u76f8\u5173\u6027\u63d0\u9ad8\u4e8612%\uff0c\u6bd4\u6807\u51c6\u65b9\u6cd5\uff08\u5982BLEU\uff09\u63d0\u9ad8\u4e86>21%\u3002\u5f53\u589e\u52a0\u5171\u4eab\u4e0a\u4e0b\u6587\u65f6\uff0cES\u76f8\u5bf9\u4e8eSARI\u7684\u6539\u8fdb\u589e\u52a0\u523020%\uff0c\u76f8\u5bf9\u4e8e\u6807\u51c6\u65b9\u6cd5\u8d85\u8fc730%\u3002", "conclusion": "ES\u65b9\u6cd5\u901a\u8fc7\u5173\u6ce8\u4fee\u8ba2\u4e2d\u7684\u5b9e\u9645\u53d8\u5316\u800c\u975e\u5171\u4eab\u5185\u5bb9\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u6587\u6863\u4fee\u8ba2\u8d28\u91cf\uff0c\u7279\u522b\u662f\u5728\u4ee3\u7801\u7f16\u8f91\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u8bc4\u4f30\u95ee\u9898\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
