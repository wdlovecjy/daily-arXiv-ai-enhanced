<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 25]
- [stat.ML](#stat.ML) [Total: 4]
- [eess.SP](#eess.SP) [Total: 7]
- [cs.AI](#cs.AI) [Total: 12]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Long-Context Attention Benchmark: From Kernel Efficiency to Distributed Context Parallelism](https://arxiv.org/abs/2510.17896)
*Tao Bu,Qiangang Wang,Bowen Zeng,Hanwen Sun,Yunpeng Huang,Chun Cao,Jingwei Xu*

Main category: cs.LG

TL;DR: 本文提出了一个统一的基准测试框架，用于系统评估长上下文LLM训练中的注意力机制优化方法，包括内核级优化和模块级并行策略。


<details>
  <summary>Details</summary>
Motivation: Transformer大语言模型的标准注意力机制存在二次计算和内存成本问题，成为长上下文训练的主要瓶颈。现有研究缺乏系统评估，操作级比较不完整，上下文并行策略通常是框架特定的。

Method: 提出了一个统一的基准测试，集成代表性注意力内核和上下文并行机制，通过模块化可扩展接口进行评估。评估维度包括注意力掩码模式和序列长度/分布式规模。

Result: 在最多96个GPU的集群上进行全面实验，实现了可重复的比较，突出了方法特定的权衡，为长上下文LLM训练中的注意力机制设计和部署提供了实用指导。

Conclusion: 该基准测试填补了现有研究的空白，为系统评估和比较不同注意力优化方法提供了标准化框架，有助于推动长上下文LLM训练技术的发展。

Abstract: Transformer-based large language models (LLMs) have achieved remarkable
success, yet their standard attention mechanism incurs quadratic computation
and memory costs with respect to sequence length, posing a major bottleneck for
long-context training. Prior work tackles this challenge along two directions:
(1) kernel-level optimizations, which accelerate dense and sparse attention
operators; and (2) module-level strategies, often referred to as distributed
attention or context parallel training, which scale attention across multiple
devices. However, systematic evaluation still remains limited: operator-level
comparisons are often incomplete, while context parallel strategies are
typically framework-specific, with unclear performance analysis across
contexts. To address these gaps, we propose a unified benchmark that integrates
representative attention kernels and context parallel mechanisms with a modular
and extensible interface for evaluation. The benchmark evaluates methods along
two critical dimensions: (1) attention mask patterns, which strongly affect
efficiency, scalability, and usability, and (2) sequence length and distributed
scale, which determine performance under extreme long-context training. Through
comprehensive experiments on the cluster of up to 96 GPUs, our benchmark
enables reproducible comparisons, highlights method-specific trade-offs, and
provides practical guidance for designing and deploying attention mechanisms in
long-context LLM training.

</details>


### [2] [Rethinking PCA Through Duality](https://arxiv.org/abs/2510.18130)
*Jan Quan,Johan Suykens,Panagiotis Patrinos*

Main category: cs.LG

TL;DR: 本文基于自注意力机制与主成分分析(PCA)的联系，重新审视PCA基础理论，提出了多种新公式和理论见解，包括核化能力、样本外应用、鲁棒PCA变体等，并开发了新算法。


<details>
  <summary>Details</summary>
Motivation: 受自注意力机制与核主成分分析(PCA)之间新发现的联系启发，重新审视PCA的基本原理，探索其理论扩展和算法改进。

Method: 使用凸差(DC)框架，提出了多个PCA的新公式化方法，包括核化版本、样本外应用算法，以及基于l1范数重构误差的鲁棒PCA变体。

Result: 揭示了同时迭代(与经典QR算法相关)是凸差算法(DCA)的一个实例，提供了对该长期使用方法的优化视角；开发了新的PCA算法并在实证中与最先进方法进行比较。

Conclusion: 通过DC框架为PCA提供了新的理论见解和算法实现，扩展了PCA的核化能力和鲁棒性，并为经典数值方法提供了优化理论解释。

Abstract: Motivated by the recently shown connection between self-attention and
(kernel) principal component analysis (PCA), we revisit the fundamentals of
PCA. Using the difference-of-convex (DC) framework, we present several novel
formulations and provide new theoretical insights. In particular, we show the
kernelizability and out-of-sample applicability for a PCA-like family of
problems. Moreover, we uncover that simultaneous iteration, which is connected
to the classical QR algorithm, is an instance of the difference-of-convex
algorithm (DCA), offering an optimization perspective on this longstanding
method. Further, we describe new algorithms for PCA and empirically compare
them with state-of-the-art methods. Lastly, we introduce a kernelizable dual
formulation for a robust variant of PCA that minimizes the $l_1$ deviation of
the reconstruction errors.

</details>


### [3] [NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation](https://arxiv.org/abs/2510.17914)
*Rikard Vinge,Isabelle Wittmann,Jannik Schneider,Michael Marszalek,Luis Gilch,Thomas Brunschwiler,Conrad M Albrecht*

Main category: cs.LG

TL;DR: NeuCo-Bench是一个用于评估地球观测领域神经压缩和表示学习的新基准框架，包含可重用嵌入评估流程、隐藏任务排行榜和平衡精度与稳定性的评分系统。


<details>
  <summary>Details</summary>
Motivation: 为地球观测领域提供社区驱动的标准化神经嵌入评估框架，解决现有评估方法中预训练偏差问题。

Method: 构建基于固定大小嵌入的评估框架，包括可重用嵌入评估流程、隐藏任务挑战模式和平衡评分系统，并发布SSL4EO-S12-downstream数据集支持可复现性。

Result: 在2025年CVPR EARTHVISION研讨会上进行了公开挑战赛，并与最先进的基础模型进行了消融实验，展示了框架的有效性。

Conclusion: NeuCo-Bench为地球观测及其他领域的神经嵌入标准化评估提供了重要基础，推动了社区驱动的评估方法发展。

Abstract: We introduce NeuCo-Bench, a novel benchmark framework for evaluating (lossy)
neural compression and representation learning in the context of Earth
Observation (EO). Our approach builds on fixed-size embeddings that act as
compact, task-agnostic representations applicable to a broad range of
downstream tasks. NeuCo-Bench comprises three core components: (i) an
evaluation pipeline built around reusable embeddings, (ii) a new challenge mode
with a hidden-task leaderboard designed to mitigate pretraining bias, and (iii)
a scoring system that balances accuracy and stability. To support
reproducibility, we release SSL4EO-S12-downstream, a curated multispectral,
multitemporal EO dataset. We present initial results from a public challenge at
the 2025 CVPR EARTHVISION workshop and conduct ablations with state-of-the-art
foundation models. NeuCo-Bench provides a first step towards community-driven,
standardized evaluation of neural embeddings for EO and beyond.

</details>


### [4] [Preference-based Reinforcement Learning beyond Pairwise Comparisons: Benefits of Multiple Options](https://arxiv.org/abs/2510.18713)
*Joongkyu Lee,Seouh-won Yi,Min-hwan Oh*

Main category: cs.LG

TL;DR: 本文研究了基于偏好的在线强化学习（PbRL），提出了一种使用Plackett-Luce排名反馈模型的新算法M-AUPO，通过最大化提供子集内的平均不确定性来选择多个动作，显著提高了样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于偏好的强化学习理论工作大多只关注成对比较，少数探索多比较和排名反馈的研究在反馈长度增加时性能保证无法改善甚至恶化。本文旨在解决这一差距，利用更丰富的排名反馈信息提高样本效率。

Method: 采用Plackett-Luce模型对动作子集进行排名反馈，提出M-AUPO算法，通过最大化提供子集内的平均不确定性来选择多个动作。

Result: M-AUPO实现了$\tilde{\mathcal{O}}\left( \frac{d}{T} \sqrt{ \sum_{t=1}^T \frac{1}{|S_t|}} \right)$的次优性差距，表明更大的子集直接带来性能提升，且避免了先前工作中对未知参数范数的指数依赖。

Conclusion: 这是PbRL中排名反馈领域的首个理论结果，明确显示了样本效率随子集大小的增加而改善，建立了近乎匹配的下界$\Omega \left( \frac{d}{K \sqrt{T}} \right)$。

Abstract: We study online preference-based reinforcement learning (PbRL) with the goal
of improving sample efficiency. While a growing body of theoretical work has
emerged-motivated by PbRL's recent empirical success, particularly in aligning
large language models (LLMs)-most existing studies focus only on pairwise
comparisons. A few recent works (Zhu et al., 2023, Mukherjee et al., 2024,
Thekumparampil et al., 2024) have explored using multiple comparisons and
ranking feedback, but their performance guarantees fail to improve-and can even
deteriorate-as the feedback length increases, despite the richer information
available. To address this gap, we adopt the Plackett-Luce (PL) model for
ranking feedback over action subsets and propose M-AUPO, an algorithm that
selects multiple actions by maximizing the average uncertainty within the
offered subset. We prove that M-AUPO achieves a suboptimality gap of
$\tilde{\mathcal{O}}\left( \frac{d}{T} \sqrt{ \sum_{t=1}^T \frac{1}{|S_t|}}
\right)$, where $T$ is the total number of rounds, $d$ is the feature
dimension, and $|S_t|$ is the size of the subset at round $t$. This result
shows that larger subsets directly lead to improved performance and, notably,
the bound avoids the exponential dependence on the unknown parameter's norm,
which was a fundamental limitation in most previous works. Moreover, we
establish a near-matching lower bound of $\Omega \left( \frac{d}{K \sqrt{T}}
\right)$, where $K$ is the maximum subset size. To the best of our knowledge,
this is the first theoretical result in PbRL with ranking feedback that
explicitly shows improved sample efficiency as a function of the subset size.

</details>


### [5] [Enhancing Fractional Gradient Descent with Learned Optimizers](https://arxiv.org/abs/2510.18783)
*Jan Sobotka,Petr Šimánek,Pavel Kordík*

Main category: cs.LG

TL;DR: 提出L2O-CFGD方法，通过元学习动态调整Caputo分数梯度下降的超参数，解决了分数梯度下降在收敛行为和超参数选择方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 分数梯度下降虽然能加速优化，但在收敛行为和超参数选择方面存在显著挑战，特别是在非凸设置下超参数调度困难。

Method: 提出L2O-CFGD方法，通过元学习动态调整Caputo分数梯度下降的超参数，生成元学习调度策略。

Result: 元学习调度策略优于通过广泛搜索找到的静态超参数CFGD，在某些任务中性能可与完全黑盒元学习优化器相媲美。

Conclusion: L2O-CFGD可作为强大工具，帮助研究人员识别高性能超参数，并深入理解分数微分的历史依赖性在优化中的应用。

Abstract: Fractional Gradient Descent (FGD) offers a novel and promising way to
accelerate optimization by incorporating fractional calculus into machine
learning. Although FGD has shown encouraging initial results across various
optimization tasks, it faces significant challenges with convergence behavior
and hyperparameter selection. Moreover, the impact of its hyperparameters is
not fully understood, and scheduling them is particularly difficult in
non-convex settings such as neural network training. To address these issues,
we propose a novel approach called Learning to Optimize Caputo Fractional
Gradient Descent (L2O-CFGD), which meta-learns how to dynamically tune the
hyperparameters of Caputo FGD (CFGD). Our method's meta-learned schedule
outperforms CFGD with static hyperparameters found through an extensive search
and, in some tasks, achieves performance comparable to a fully black-box
meta-learned optimizer. L2O-CFGD can thus serve as a powerful tool for
researchers to identify high-performing hyperparameters and gain insights on
how to leverage the history-dependence of the fractional differential in
optimization.

</details>


### [6] [R2L: Reliable Reinforcement Learning: Guaranteed Return & Reliable Policies in Reinforcement Learning](https://arxiv.org/abs/2510.18074)
*Nadir Farhi*

Main category: cs.LG

TL;DR: 提出一种可靠强化学习框架，目标不是最大化期望回报，而是最大化累积回报超过预设阈值的概率，适用于需要性能保证的实际应用场景。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习算法专注于最大化期望回报，但许多实际应用（如路由、资源分配、风险决策）需要确保高平均性能和成功概率保证的策略。

Method: 通过状态增强表示将可靠RL问题重新表述为标准RL问题，允许使用现有RL和深度RL算法，无需全新算法框架。

Result: 理论结果证明两种表述的等价性，数值实验表明该方法在可靠路由问题中能有效平衡效率和可靠性。

Conclusion: 可靠强化学习在随机和安全关键环境中具有实际应用潜力，能够通过现有方法推导出可靠策略。

Abstract: In this work, we address the problem of determining reliable policies in
reinforcement learning (RL), with a focus on optimization under uncertainty and
the need for performance guarantees. While classical RL algorithms aim at
maximizing the expected return, many real-world applications - such as routing,
resource allocation, or sequential decision-making under risk - require
strategies that ensure not only high average performance but also a guaranteed
probability of success. To this end, we propose a novel formulation in which
the objective is to maximize the probability that the cumulative return exceeds
a prescribed threshold. We demonstrate that this reliable RL problem can be
reformulated, via a state-augmented representation, into a standard RL problem,
thereby allowing the use of existing RL and deep RL algorithms without the need
for entirely new algorithmic frameworks. Theoretical results establish the
equivalence of the two formulations and show that reliable strategies can be
derived by appropriately adapting well-known methods such as Q-learning or
Dueling Double DQN. To illustrate the practical relevance of the approach, we
consider the problem of reliable routing, where the goal is not to minimize the
expected travel time but rather to maximize the probability of reaching the
destination within a given time budget. Numerical experiments confirm that the
proposed formulation leads to policies that effectively balance efficiency and
reliability, highlighting the potential of reliable RL for applications in
stochastic and safety-critical environments.

</details>


### [7] [Enhancing mortality prediction in cardiac arrest ICU patients through meta-modeling of structured clinical data from MIMIC-IV](https://arxiv.org/abs/2510.18103)
*Nursultan Mamatov,Philipp Kellmeyer*

Main category: cs.LG

TL;DR: 该研究开发了结合结构化临床数据和非结构化文本信息（出院小结和放射学报告）的机器学习模型，用于ICU住院死亡率的早期预测。通过LASSO和XGBoost进行特征选择，结合TF-IDF和BERT嵌入处理文本特征，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: ICU住院死亡率的准确早期预测对于及时临床干预和高效资源配置至关重要。现有模型主要依赖结构化数据，忽略了非结构化文本信息中的宝贵临床洞察。

Method: 使用MIMIC-IV数据库，结合LASSO和XGBoost进行特征选择，采用TF-IDF和BERT嵌入处理文本特征，构建多元逻辑回归模型。

Result: 结合结构化和文本输入的逻辑回归模型AUC达到0.918，相比仅使用结构化数据的0.753，相对提升22%。决策曲线分析显示在广泛阈值概率范围内具有优越的标准化净效益。

Conclusion: 非结构化临床记录具有额外的预后价值，应将其整合到可解释的特征驱动风险预测模型中，以改善ICU患者的临床决策。

Abstract: Accurate early prediction of in-hospital mortality in intensive care units
(ICUs) is essential for timely clinical intervention and efficient resource
allocation. This study develops and evaluates machine learning models that
integrate both structured clinical data and unstructured textual information,
specifically discharge summaries and radiology reports, from the MIMIC-IV
database. We used LASSO and XGBoost for feature selection, followed by a
multivariate logistic regression trained on the top features identified by both
models. Incorporating textual features using TF-IDF and BERT embeddings
significantly improved predictive performance. The final logistic regression
model, which combined structured and textual input, achieved an AUC of 0.918,
compared to 0.753 when using structured data alone, a relative improvement 22%.
The analysis of the decision curve demonstrated a superior standardized net
benefit in a wide range of threshold probabilities (0.2-0.8), confirming the
clinical utility of the model. These results underscore the added prognostic
value of unstructured clinical notes and support their integration into
interpretable feature-driven risk prediction models for ICU patients.

</details>


### [8] [Efficient Long-context Language Model Training by Core Attention Disaggregation](https://arxiv.org/abs/2510.18121)
*Yonghao Zhuang,Junda Chen,Bo Pang,Yi Gu,Yibo Zhu,Yimin Jiang,Ion Stoica,Eric Xing,Hao Zhang*

Main category: cs.LG

TL;DR: 提出核心注意力解耦（CAD）技术，通过将核心注意力计算与其他模型层分离并在专用设备上执行，解决长上下文训练中的负载不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有系统中核心注意力与其他层共存，在长上下文长度下其二次计算增长导致数据并行和流水线并行组之间的负载不平衡和滞后问题。

Method: 将核心注意力分解为token级任务并分发到专用注意力服务器，动态重新批处理任务以均衡计算而不牺牲内核效率，使用乒乓执行方案完全重叠通信与计算。

Result: 在512个H200 GPU和512k token上下文长度下，DistCA系统将端到端训练吞吐量提升1.35倍，消除数据并行和流水线并行滞后，实现近乎完美的计算和内存平衡。

Conclusion: CAD技术通过解耦核心注意力计算有效解决了长上下文训练中的负载不平衡问题，显著提升了训练效率和系统性能。

Abstract: We present core attention disaggregation (CAD), a technique that improves
long-context large language model training by decoupling the core attention
computation, softmax(QK^T)V, from the rest of the model and executing it on a
separate pool of devices. In existing systems, core attention is colocated with
other layers; at long context lengths, its quadratic compute growth compared to
the near-linear growth of other components causes load imbalance and stragglers
across data and pipeline parallel groups. CAD is enabled by two observations.
First, core attention is stateless: it has no trainable parameters and only
minimal transient data, so balancing reduces to scheduling compute-bound tasks.
Second, it is composable: modern attention kernels retain high efficiency when
processing fused batches of token-level shards with arbitrary lengths. CAD
partitions core attention into token-level tasks and dispatches them to
dedicated attention servers, which dynamically rebatch tasks to equalize
compute without sacrificing kernel efficiency. We implement CAD in a system
called DistCA, which uses a ping-pong execution scheme to fully overlap
communication with computation and in-place execution on attention servers to
reduce memory use. On 512 H200 GPUs and context lengths up to 512k tokens,
DistCA improves end-to-end training throughput by up to 1.35x, eliminates data
and pipeline parallel stragglers, and achieves near-perfect compute and memory
balance.

</details>


### [9] [Fostering the Ecosystem of AI for Social Impact Requires Expanding and Strengthening Evaluation Standards](https://arxiv.org/abs/2510.18238)
*Bryan Wilder,Angela Zhou*

Main category: cs.LG

TL;DR: 论文主张AI/ML社会影响研究需要更广泛的社会影响定义和更严格的部署系统评估，而不是仅关注同时实现部署和方法创新的项目。


<details>
  <summary>Details</summary>
Motivation: 当前AI/ML社会影响研究的评审标准过度强调同时实现部署和方法创新的项目，这削弱了更广泛研究生态系统的可持续性。

Method: 提出立场观点，主张研究人员和评审者应采纳：1）超越部署的更广泛社会影响概念；2）对部署系统影响进行更严格评估。

Result: 识别了当前评审标准带来的激励问题，并提出了改进方向。

Conclusion: AI/ML社会影响研究需要重新定义成功标准，以支持更可持续的研究生态系统，更好地满足项目合作伙伴的需求。

Abstract: There has been increasing research interest in AI/ML for social impact, and
correspondingly more publication venues have refined review criteria for
practice-driven AI/ML research. However, these review guidelines tend to most
concretely recognize projects that simultaneously achieve deployment and novel
ML methodological innovation. We argue that this introduces incentives for
researchers that undermine the sustainability of a broader research ecosystem
of social impact, which benefits from projects that make contributions on
single front (applied or methodological) that may better meet project partner
needs. Our position is that researchers and reviewers in machine learning for
social impact must simultaneously adopt: 1) a more expansive conception of
social impacts beyond deployment and 2) more rigorous evaluations of the impact
of deployed systems.

</details>


### [10] [Scaling Laws Meet Model Architecture: Toward Inference-Efficient LLMs](https://arxiv.org/abs/2510.18245)
*Song Bian,Tao Yu,Shivaram Venkataraman,Youngsuk Park*

Main category: cs.LG

TL;DR: 本文研究了大型语言模型架构因素（隐藏层大小、MLP与注意力参数分配比例、分组查询注意力）对推理成本和准确性的影响，提出了条件缩放定律和搜索框架，训练了200多个模型验证效果。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型参数规模和训练数据量的增长，推理成本成为重要问题，但模型准确性与推理效率之间的权衡关系尚未充分探索。

Method: 引入条件缩放定律，在Chinchilla框架基础上加入架构信息，提出搜索框架来识别同时具备推理效率和准确性的架构，训练了80M到3B参数的200多个模型进行验证。

Result: 条件缩放定律能可靠预测最优架构选择，优化后的模型在相同训练预算下比LLaMA-3.2准确率提高2.1%，推理吞吐量提升42%。

Conclusion: 通过条件缩放定律和架构优化，可以在保持模型性能的同时显著提升推理效率，为大语言模型的实用化部署提供了有效方法。

Abstract: Scaling the number of parameters and the size of training data has proven to
be an effective strategy for improving large language model (LLM) performance.
Yet, as these models grow increasingly powerful and widely deployed, the cost
of inference has become a pressing concern. Despite its importance, the
trade-off between model accuracy and inference efficiency remains
underexplored. In this work, we examine how key architectural factors, hidden
size, the allocation of parameters between MLP and attention (mlp-to-attention
ratio), and grouped-query attention (GQA), influence both inference cost and
accuracy. We introduce a conditional scaling law that augments the Chinchilla
framework with architectural information, along with a search framework for
identifying architectures that are simultaneously inference-efficient and
accurate. To validate our approach, we train more than 200 models spanning 80M
to 3B parameters and 8B to 100B training tokens, and fit the proposed
conditional scaling law. Our results show that the conditional scaling law
reliably predicts optimal architectural choices and that the resulting models
outperform existing open-source baselines. Under the same training budget,
optimized architectures achieve up to 2.1% higher accuracy and 42% greater
inference throughput compared to LLaMA-3.2.

</details>


### [11] [Higher Embedding Dimension Creates a Stronger World Model for a Simple Sorting Task](https://arxiv.org/abs/2510.18315)
*Brady Bhalla,Honglu Fan,Nancy Chen,Tony Yue YU*

Main category: cs.LG

TL;DR: 本文研究了嵌入维度如何影响在强化学习训练下执行冒泡排序相邻交换的transformer内部"世界模型"的形成。研究发现更大的嵌入维度能产生更忠实、一致和鲁棒的内部表示，并增强结构化内部表示的形成和可解释性。


<details>
  <summary>Details</summary>
Motivation: 研究嵌入维度对transformer内部世界模型形成的影响，探索模型大小如何改善表示质量而不仅仅是最终性能。

Method: 使用强化学习训练transformer执行冒泡排序相邻交换，通过数百次实验观察不同嵌入维度下模型的内部机制。

Result: 发现两个一致机制：(1)注意力权重矩阵的最后一行单调编码token的全局排序；(2)选择的交换操作与这些编码值的最大相邻差异对齐。高嵌入维度模型产生更结构化、一致和鲁棒的内部表示。

Conclusion: 研究提供了定量证据表明transformer构建了结构化的内部世界模型，模型大小不仅改善最终性能，还提高了表示质量。

Abstract: We investigate how embedding dimension affects the emergence of an internal
"world model" in a transformer trained with reinforcement learning to perform
bubble-sort-style adjacent swaps. Models achieve high accuracy even with very
small embedding dimensions, but larger dimensions yield more faithful,
consistent, and robust internal representations. In particular, higher
embedding dimensions strengthen the formation of structured internal
representation and lead to better interpretability. After hundreds of
experiments, we observe two consistent mechanisms: (1) the last row of the
attention weight matrix monotonically encodes the global ordering of tokens;
and (2) the selected transposition aligns with the largest adjacent difference
of these encoded values. Our results provide quantitative evidence that
transformers build structured internal world models and that model size
improves representation quality in addition to end performance. We release our
metrics and analyses, which can be used to probe similar algorithmic tasks.

</details>


### [12] [Why Policy Gradient Algorithms Work for Undiscounted Total-Reward MDPs](https://arxiv.org/abs/2510.18340)
*Jongmin Lee,Ernest K. Ryu*

Main category: cs.LG

TL;DR: 本文分析了在折扣因子γ=1的无折扣总奖励无限时域MDP中，基于策略梯度方法的理论分析，通过引入瞬态访问测度来替代经典的状态访问测度。


<details>
  <summary>Details</summary>
Motivation: 现代基于策略的强化学习算法在理论分析中通常假设折扣因子γ<1，但最近在大语言模型等应用中广泛使用γ=1的无折扣设置，这使得现有理论不适用，需要建立新的理论框架。

Method: 基于两个关键洞察：(1) MDP状态在采用严格正概率策略时，其循环状态和瞬态状态的分类是不变的；(2) 用新的瞬态访问测度替代经典的状态访问测度。

Result: 为无折扣总奖励无限时域MDP中的策略梯度方法提供了理论分析框架，解决了γ=1时经典状态访问测度可能未定义的问题。

Conclusion: 提出的瞬态访问测度和状态分类不变性为无折扣设置下的策略梯度方法提供了理论基础，填补了现有理论在γ=1情况下的空白。

Abstract: The classical policy gradient method is the theoretical and conceptual
foundation of modern policy-based reinforcement learning (RL) algorithms. Most
rigorous analyses of such methods, particularly those establishing convergence
guarantees, assume a discount factor $\gamma < 1$. In contrast, however, a
recent line of work on policy-based RL for large language models uses the
undiscounted total-reward setting with $\gamma = 1$, rendering much of the
existing theory inapplicable. In this paper, we provide analyses of the policy
gradient method for undiscounted expected total-reward infinite-horizon MDPs
based on two key insights: (i) the classification of the MDP states into
recurrent and transient states is invariant over the set of policies that
assign strictly positive probability to every action (as is typical in deep RL
models employing a softmax output layer) and (ii) the classical state
visitation measure (which may be ill-defined when $\gamma = 1$) can be replaced
with a new object that we call the transient visitation measure.

</details>


### [13] [Towards Unsupervised Open-Set Graph Domain Adaptation via Dual Reprogramming](https://arxiv.org/abs/2510.18363)
*Zhen Zhang,Bingsheng He*

Main category: cs.LG

TL;DR: 提出GraphRTA框架，解决无监督开放集图域自适应问题，通过图重编程和模型重编程来识别目标图中的已知类和未知类。


<details>
  <summary>Details</summary>
Motivation: 现有图域自适应模型主要关注闭集设置，但现实场景中目标域可能包含源域中不存在的类别，因此需要解决开放集图域自适应问题。

Method: GraphRTA框架包含图重编程（修改目标图结构和节点特征）和模型重编程（剪枝域特定参数），并扩展分类器维度以识别未知类。

Result: 在多个公共数据集上的综合实验表明，该模型相比现有最先进基线方法取得了满意的性能。

Conclusion: GraphRTA能够有效解决开放集图域自适应问题，无需手动指定阈值即可识别未知类，具有实际应用价值。

Abstract: Unsupervised Graph Domain Adaptation has become a promising paradigm for
transferring knowledge from a fully labeled source graph to an unlabeled target
graph. Existing graph domain adaptation models primarily focus on the
closed-set setting, where the source and target domains share the same label
spaces. However, this assumption might not be practical in the real-world
scenarios, as the target domain might include classes that are not present in
the source domain. In this paper, we investigate the problem of unsupervised
open-set graph domain adaptation, where the goal is to not only correctly
classify target nodes into the known classes, but also recognize previously
unseen node types into the unknown class. Towards this end, we propose a novel
framework called GraphRTA, which conducts reprogramming on both the graph and
model sides. Specifically, we reprogram the graph by modifying target graph
structure and node features, which facilitates better separation of known and
unknown classes. Meanwhile, we also perform model reprogramming by pruning
domain-specific parameters to reduce bias towards the source graph while
preserving parameters that capture transferable patterns across graphs.
Additionally, we extend the classifier with an extra dimension for the unknown
class, thus eliminating the need of manually specified threshold in open-set
recognition. Comprehensive experiments on several public datasets demonstrate
that our proposed model can achieve satisfied performance compared with recent
state-of-the-art baselines. Our source codes and datasets are publicly
available at https://github.com/cszhangzhen/GraphRTA.

</details>


### [14] [Safe But Not Sorry: Reducing Over-Conservatism in Safety Critics via Uncertainty-Aware Modulation](https://arxiv.org/abs/2510.18478)
*Daniel Bethell,Simos Gerasimou,Radu Calinescu,Calum Imrie*

Main category: cs.LG

TL;DR: 提出不确定安全评论家(USC)方法，通过在不确定和高成本区域集中保守性，在安全区域保持锐利梯度，实现强化学习的安全探索与任务性能的有效平衡。


<details>
  <summary>Details</summary>
Motivation: 现有安全强化学习方法难以平衡安全约束和任务性能：严格的安全约束会削弱任务性能，而优先考虑奖励的方法则频繁违反安全约束，导致成本梯度平坦化并阻碍策略改进。

Method: 引入不确定安全评论家(USC)，将不确定性感知的调制和精炼集成到评论家训练中，在不确定和高成本区域集中保守性，同时在安全区域保持锐利梯度。

Result: 实验表明USC将安全违规减少约40%，同时保持竞争性或更高的奖励，并将预测成本梯度与真实成本梯度之间的误差减少约83%。

Conclusion: USC打破了安全与性能之间的普遍权衡，为可扩展的安全强化学习铺平了道路。

Abstract: Ensuring the safe exploration of reinforcement learning (RL) agents is
critical for deployment in real-world systems. Yet existing approaches struggle
to strike the right balance: methods that tightly enforce safety often cripple
task performance, while those that prioritize reward leave safety constraints
frequently violated, producing diffuse cost landscapes that flatten gradients
and stall policy improvement. We introduce the Uncertain Safety Critic (USC), a
novel approach that integrates uncertainty-aware modulation and refinement into
critic training. By concentrating conservatism in uncertain and costly regions
while preserving sharp gradients in safe areas, USC enables policies to achieve
effective reward-safety trade-offs. Extensive experiments show that USC reduces
safety violations by approximately 40% while maintaining competitive or higher
rewards, and reduces the error between predicted and true cost gradients by
approximately 83%, breaking the prevailing trade-off between safety and
performance and paving the way for scalable safe RL.

</details>


### [15] [Alibaba International E-commerce Product Search Competition DILAB Team Technical Report](https://arxiv.org/abs/2510.18499)
*Hyewon Lee,Junghyun Oh,Minkyung Song,Soyoung Park,Seunghoon Han*

Main category: cs.LG

TL;DR: DILAB团队开发的多语言电商搜索系统在最终排行榜上获得第5名，总体得分0.8819。该系统采用多阶段流水线设计，包括数据精炼、轻量级预处理和自适应建模，在查询类别和查询物品任务上均表现稳定且高性能。


<details>
  <summary>Details</summary>
Motivation: 解决多语言查询-物品理解中的挑战，开发一个在多语言和跨领域环境下具有鲁棒性和适应性的电商搜索系统。

Method: 设计多阶段流水线：数据精炼阶段增强数据集一致性和类别覆盖；语言标记和噪声过滤提高输入质量；建模阶段探索多种架构和微调策略，使用精选验证集优化超参数以平衡查询类别和查询物品任务的性能。

Result: 系统在最终排行榜上获得第5名，总体得分0.8819，在各项评估指标上均表现出稳定且高性能的结果。

Conclusion: 该框架在多语言和跨领域环境下展现出鲁棒性和适应性，突显了系统化数据管理和迭代评估对多语言搜索系统的有效性。

Abstract: This study presents the multilingual e-commerce search system developed by
the DILAB team, which achieved 5th place on the final leaderboard with a
competitive overall score of 0.8819, demonstrating stable and high-performing
results across evaluation metrics. To address challenges in multilingual
query-item understanding, we designed a multi-stage pipeline integrating data
refinement, lightweight preprocessing, and adaptive modeling. The data
refinement stage enhanced dataset consistency and category coverage, while
language tagging and noise filtering improved input quality. In the modeling
phase, multiple architectures and fine-tuning strategies were explored, and
hyperparameters optimized using curated validation sets to balance performance
across query-category (QC) and query-item (QI) tasks. The proposed framework
exhibited robustness and adaptability across languages and domains,
highlighting the effectiveness of systematic data curation and iterative
evaluation for multilingual search systems. The source code is available at
https://github.com/2noweyh/DILAB-Alibaba-Ecommerce-Search.

</details>


### [16] [Pay Attention to the Triggers: Constructing Backdoors That Survive Distillation](https://arxiv.org/abs/2510.18541)
*Giovanni De Muri,Mark Vero,Robin Staab,Martin Vechev*

Main category: cs.LG

TL;DR: 本文研究从后门教师模型进行知识蒸馏的安全风险，发现现有LLM后门方法由于使用罕见触发词而无法传递到学生模型，因此提出T-MTB技术构建可转移的后门。


<details>
  <summary>Details</summary>
Motivation: 由于教师模型可能来自不可信方，知识蒸馏可能带来意想不到的安全风险，特别是后门攻击的传递问题。

Method: 提出T-MTB后门技术，构建由多个特定令牌组成的复合后门触发器，这些令牌在预期的蒸馏数据集中单独出现频率较高，从而保持教师模型的隐蔽性同时确保后门传递。

Result: 使用T-MTB在两个攻击场景（越狱和内容调节）和四个LLM模型家族中展示和广泛研究了可转移后门的安全风险。

Conclusion: 知识蒸馏确实存在安全风险，T-MTB技术能够有效构建可转移的后门，揭示了当前低估了知识蒸馏安全威胁的问题。

Abstract: LLMs are often used by downstream users as teacher models for knowledge
distillation, compressing their capabilities into memory-efficient models.
However, as these teacher models may stem from untrusted parties, distillation
can raise unexpected security risks. In this paper, we investigate the security
implications of knowledge distillation from backdoored teacher models. First,
we show that prior backdoors mostly do not transfer onto student models. Our
key insight is that this is because existing LLM backdooring methods choose
trigger tokens that rarely occur in usual contexts. We argue that this
underestimates the security risks of knowledge distillation and introduce a new
backdooring technique, T-MTB, that enables the construction and study of
transferable backdoors. T-MTB carefully constructs a composite backdoor
trigger, made up of several specific tokens that often occur individually in
anticipated distillation datasets. As such, the poisoned teacher remains
stealthy, while during distillation the individual presence of these tokens
provides enough signal for the backdoor to transfer onto the student. Using
T-MTB, we demonstrate and extensively study the security risks of transferable
backdoors across two attack scenarios, jailbreaking and content modulation, and
across four model families of LLMs.

</details>


### [17] [RAISE: A Unified Framework for Responsible AI Scoring and Evaluation](https://arxiv.org/abs/2510.18559)
*Loc Phuc Truong Nguyen,Hung Thanh Do*

Main category: cs.LG

TL;DR: RAISE框架是一个统一评估AI系统在可解释性、公平性、鲁棒性和可持续性四个维度的评分框架，通过综合评分帮助选择负责任模型。研究发现不同模型在不同维度表现各异，需要多维度评估。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统进入高风险领域，评估需要超越预测准确性，扩展到可解释性、公平性、鲁棒性和可持续性等维度。

Method: 提出了RAISE框架，量化模型在四个维度的表现并聚合成综合责任评分。评估了三种深度学习模型在金融、医疗和社会经济数据集上的表现。

Result: MLP在可持续性和鲁棒性方面表现强劲，Transformer在可解释性和公平性方面表现出色但环境成本很高，Tabular ResNet提供了平衡的性能。

Conclusion: 没有单一模型在所有责任标准上都占主导地位，强调多维度评估对于负责任模型选择的必要性。

Abstract: As AI systems enter high-stakes domains, evaluation must extend beyond
predictive accuracy to include explainability, fairness, robustness, and
sustainability. We introduce RAISE (Responsible AI Scoring and Evaluation), a
unified framework that quantifies model performance across these four
dimensions and aggregates them into a single, holistic Responsibility Score. We
evaluated three deep learning models: a Multilayer Perceptron (MLP), a Tabular
ResNet, and a Feature Tokenizer Transformer, on structured datasets from
finance, healthcare, and socioeconomics. Our findings reveal critical
trade-offs: the MLP demonstrated strong sustainability and robustness, the
Transformer excelled in explainability and fairness at a very high
environmental cost, and the Tabular ResNet offered a balanced profile. These
results underscore that no single model dominates across all responsibility
criteria, highlighting the necessity of multi-dimensional evaluation for
responsible model selection. Our implementation is available at:
https://github.com/raise-framework/raise.

</details>


### [18] [Unrolled-SINDy: A Stable Explicit Method for Non linear PDE Discovery from Sparsely Sampled Data](https://arxiv.org/abs/2510.18611)
*Fayad Ali Banna,Antoine Caradot,Eduardo Brandao,Jean-Philippe Colombier,Rémi Emonet,Marc Sebban*

Main category: cs.LG

TL;DR: Unrolled-SINDy是一种改进SINDy方法稳定性的新方法，通过解耦数值时间步长与数据采样率，解决了稀疏时间采样数据下的物理动力学微分方程识别问题。


<details>
  <summary>Details</summary>
Motivation: 现有SINDy方法在处理时间稀疏采样的真实世界数据时存在局限性，由于局部截断误差较大，无法正确恢复方程参数。

Method: 采用展开方案，通过迭代闭式方法或梯度下降方案，将数值时间步长与数据采样率解耦，提高显式方法的稳定性。

Result: 实验表明该方法具有通用性，在传统SINDy和先进的噪声鲁棒iNeuralSINDy上，配合不同数值方案（欧拉法、RK4），都能解决非展开方法无法处理的问题。

Conclusion: Unrolled-SINDy通过展开方案有效解决了稀疏时间采样数据下的微分方程识别问题，扩展了SINDy方法的应用范围。

Abstract: Identifying from observation data the governing differential equations of a
physical dynamics is a key challenge in machine learning. Although approaches
based on SINDy have shown great promise in this area, they still fail to
address a whole class of real world problems where the data is sparsely sampled
in time. In this article, we introduce Unrolled-SINDy, a simple methodology
that leverages an unrolling scheme to improve the stability of explicit methods
for PDE discovery. By decorrelating the numerical time step size from the
sampling rate of the available data, our approach enables the recovery of
equation parameters that would not be the minimizers of the original SINDy
optimization problem due to large local truncation errors. Our method can be
exploited either through an iterative closed-form approach or by a gradient
descent scheme. Experiments show the versatility of our method. On both
traditional SINDy and state-of-the-art noise-robust iNeuralSINDy, with
different numerical schemes (Euler, RK4), our proposed unrolling scheme allows
to tackle problems not accessible to non-unrolled methods.

</details>


### [19] [Hardness of Learning Regular Languages in the Next Symbol Prediction Setting](https://arxiv.org/abs/2510.18634)
*Satwik Bhattamishra,Phil Blunsom,Varun Kanade*

Main category: cs.LG

TL;DR: 该论文研究在下一个符号预测(NSP)设置下语言的可学习性，证明即使在这种提供更丰富标签信息的环境中，学习DFA和布尔公式等概念类仍然是计算困难的。


<details>
  <summary>Details</summary>
Motivation: NSP设置已被用于实证分析神经序列模型，且该设置中的高效算法可用于学习语言模型的截断支持。作者希望将这一设置形式化以进行PAC学习分析，探索在这种更丰富标签信息下的学习能力。

Method: 通过构造使几乎所有额外标签变得无信息，从而将传统学习问题归约到NSP标签学习问题。在密码学假设下，这种归约表明在NSP设置中学习DFA是计算困难的。

Result: 研究发现，尽管NSP设置提供了比传统分类设置更丰富的标签集，但学习DFA和布尔公式等概念类仍然保持计算困难。

Conclusion: 即使在学习者获得更丰富标签信息的NSP设置中，学习某些概念类（如DFA和布尔公式）的计算困难性仍然存在，这通过从传统学习问题到NSP标签学习的归约得到证明。

Abstract: We study the learnability of languages in the Next Symbol Prediction (NSP)
setting, where a learner receives only positive examples from a language
together with, for every prefix, (i) whether the prefix itself is in the
language and (ii) which next symbols can lead to an accepting string. This
setting has been used in prior works to empirically analyze neural sequence
models, and additionally, we observe that efficient algorithms for the NSP
setting can be used to learn the (truncated) support of language models. We
formalize the setting so as to make it amenable to PAC-learning analysis. While
the setting provides a much richer set of labels than the conventional
classification setting, we show that learning concept classes such as DFAs and
Boolean formulas remains computationally hard. The proof is via a construction
that makes almost all additional labels uninformative, yielding a reduction
from the conventional learning problem to learning with NSP labels. Under
cryptographic assumptions, the reduction implies that the problem of learning
DFAs is computationally hard in the NSP setting.

</details>


### [20] [Informed Learning for Estimating Drought Stress at Fine-Scale Resolution Enables Accurate Yield Prediction](https://arxiv.org/abs/2510.18648)
*Miro Miranda,Marcela Charfuelan,Matias Valdenegro Toro,Andreas Dengel*

Main category: cs.LG

TL;DR: 该研究提出了一种结合作物模拟模型和机器学习优势的混合方法，通过将作物产量建模为时间性水分稀缺的函数，并引入物理信息损失函数，实现了高精度且可解释的作物产量预测。


<details>
  <summary>Details</summary>
Motivation: 作物模拟模型具有物理可解释性但性能较差，而机器学习模型性能强大但缺乏物理一致性。本研究旨在结合两者的优势，为农业决策提供既准确又可解释的产量预测工具。

Method: 将作物产量建模为时间性水分稀缺的函数，预测作物干旱胁迫和对水分稀缺的敏感性；提出新颖的物理信息损失函数确保物理一致性；利用多光谱卫星影像、气象数据和精细尺度产量数据；采用深度集成方法处理模型不确定性。

Result: 该方法在作物产量预测方面超越了LSTM和Transformer等最先进模型，决定系数（R²-score）高达0.82，同时保持了高可解释性。

Conclusion: 该方法为行业、政策制定者和农民在气候变化时期构建更具韧性的农业提供了决策支持，成功结合了物理过程的一致性和机器学习模型的强大预测能力。

Abstract: Water is essential for agricultural productivity. Assessing water shortages
and reduced yield potential is a critical factor in decision-making for
ensuring agricultural productivity and food security. Crop simulation models,
which align with physical processes, offer intrinsic explainability but often
perform poorly. Conversely, machine learning models for crop yield modeling are
powerful and scalable, yet they commonly operate as black boxes and lack
adherence to the physical principles of crop growth. This study bridges this
gap by coupling the advantages of both worlds. We postulate that the crop yield
is inherently defined by the water availability. Therefore, we formulate crop
yield as a function of temporal water scarcity and predict both the crop
drought stress and the sensitivity to water scarcity at fine-scale resolution.
Sequentially modeling the crop yield response to water enables accurate yield
prediction. To enforce physical consistency, a novel physics-informed loss
function is proposed. We leverage multispectral satellite imagery,
meteorological data, and fine-scale yield data. Further, to account for the
uncertainty within the model, we build upon a deep ensemble approach. Our
method surpasses state-of-the-art models like LSTM and Transformers in crop
yield prediction with a coefficient of determination ($R^2$-score) of up to
0.82 while offering high explainability. This method offers decision support
for industry, policymakers, and farmers in building a more resilient
agriculture in times of changing climate conditions.

</details>


### [21] [Learning Task-Agnostic Representations through Multi-Teacher Distillation](https://arxiv.org/abs/2510.18680)
*Philippe Formont,Maxime Darrin,Banafsheh Karimian,Jackie CK Cheung,Eric Granger,Ismail Ben Ayed,Mohammadhadi Shateri,Pablo Piantanida*

Main category: cs.LG

TL;DR: 提出基于"多数投票"目标函数的任务无关多教师蒸馏框架，通过最大化学生与教师嵌入之间的互信息，无需任务特定标签或先验知识，在文本、视觉和分子建模中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有多教师蒸馏方法通常针对特定任务设计，无法充分利用不同嵌入模型在架构、损失函数、输入模态和数据集上的多样性来丰富表示学习。

Method: 引入基于"多数投票"目标函数的任务无关蒸馏框架，该函数受学生与教师嵌入间互信息的上界约束，从而推导出无需任务特定标签的蒸馏损失函数。

Result: 在文本、视觉模型和分子建模上的评估表明，该方法能有效利用教师多样性，产生的表示在分类、聚类和回归等广泛下游任务中表现更好，并发布了最先进的嵌入模型。

Conclusion: 提出的任务无关多教师蒸馏框架通过"多数投票"目标成功利用教师多样性，无需任务特定知识即可生成高质量表示，在各种模态中提升下游任务性能。

Abstract: Casting complex inputs into tractable representations is a critical step
across various fields. Diverse embedding models emerge from differences in
architectures, loss functions, input modalities and datasets, each capturing
unique aspects of the input. Multi-teacher distillation leverages this
diversity to enrich representations but often remains tailored to specific
tasks. In this paper, we introduce a task-agnostic framework based on a
``majority vote" objective function. We demonstrate that this function is
bounded by the mutual information between student and teachers' embeddings,
leading to a task-agnostic distillation loss that eliminates dependence on
task-specific labels or prior knowledge. Our evaluations across text, vision
models, and molecular modeling show that our method effectively leverages
teacher diversity, resulting in representations enabling better performance for
a wide range of downstream tasks such as classification, clustering, or
regression. Additionally, we train and release state-of-the-art embedding
models, enhancing downstream performance in various modalities.

</details>


### [22] [Reinforcement Learning with Imperfect Transition Predictions: A Bellman-Jensen Approach](https://arxiv.org/abs/2510.18687)
*Chenbei Lu,Zaiwei Chen,Tongxin Li,Chenye Wu,Adam Wierman*

Main category: cs.LG

TL;DR: 本文提出了一种处理多步预测增强MDP的新方法，通过贝叶斯价值函数和Bellman-Jensen Gap分析来解决传统RL在多步预测场景下的维度灾难问题，并开发了BOLA算法实现高效学习。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习基于单步转移模型，但在能源管理和股票投资等实际应用中，智能体可以获得多步未来状态预测，这些预测为决策提供了额外优势。然而，多步预测具有高维特性，直接嵌入MDP会导致状态空间指数爆炸和维度灾难。

Method: 提出贝叶斯价值函数来表征最优预测感知策略；开发新颖的Bellman-Jensen Gap分析来表征不完美预测的价值；引入BOLA（贝叶斯离线学习与在线适应）算法，将离线贝叶斯价值学习与轻量级在线适应分离。

Result: 证明了BOLA即使在预测不完美的情况下仍保持样本效率；在合成MDP和真实世界风能存储控制问题上验证了理论和算法的有效性。

Conclusion: 该方法成功解决了多步预测增强MDP的维度灾难问题，为实际应用中利用多步预测进行决策提供了理论保证和实用算法。

Abstract: Traditional reinforcement learning (RL) assumes the agents make decisions
based on Markov decision processes (MDPs) with one-step transition models. In
many real-world applications, such as energy management and stock investment,
agents can access multi-step predictions of future states, which provide
additional advantages for decision making. However, multi-step predictions are
inherently high-dimensional: naively embedding these predictions into an MDP
leads to an exponential blow-up in state space and the curse of dimensionality.
Moreover, existing RL theory provides few tools to analyze prediction-augmented
MDPs, as it typically works on one-step transition kernels and cannot
accommodate multi-step predictions with errors or partial action-coverage. We
address these challenges with three key innovations: First, we propose the
\emph{Bayesian value function} to characterize the optimal prediction-aware
policy tractably. Second, we develop a novel \emph{Bellman-Jensen Gap} analysis
on the Bayesian value function, which enables characterizing the value of
imperfect predictions. Third, we introduce BOLA (Bayesian Offline Learning with
Online Adaptation), a two-stage model-based RL algorithm that separates offline
Bayesian value learning from lightweight online adaptation to real-time
predictions. We prove that BOLA remains sample-efficient even under imperfect
predictions. We validate our theory and algorithm on synthetic MDPs and a
real-world wind energy storage control problem.

</details>


### [23] [CAGE: Curvature-Aware Gradient Estimation For Accurate Quantization-Aware Training](https://arxiv.org/abs/2510.18784)
*Soroush Tabesh,Mher Safaryan,Dan Alistarh*

Main category: cs.LG

TL;DR: CAGE是一种新的量化感知训练方法，通过曲率感知梯度估计来弥补量化带来的精度损失，在Llama风格模型上能恢复超过10%的量化损失。


<details>
  <summary>Details</summary>
Motivation: 现有的低位量化感知训练方法与原生训练之间仍存在较大的精度差距，需要新的方法来缩小这一差距。

Method: 引入CAGE方法，在直通估计器梯度基础上增加曲率感知修正项，基于多目标优化视角平衡损失最小化和量化约束，利用局部曲率信息进行梯度修正。

Result: 在800M参数的Llama风格模型预训练中，CAGE在W4A4量化模式下相比异常值处理方法能恢复超过10%的量化损失增加。

Conclusion: 曲率感知梯度修正能够弥补当前异常值处理方法之外的性能差距，为量化训练提供了新的有效解决方案。

Abstract: Despite significant work on low-bit quantization-aware training (QAT), there
is still a large accuracy gap between such techniques and native training. To
address this, we introduce CAGE (Curvature-Aware Gradient Estimation), a new
QAT method that augments the straight-through estimator (STE) gradient with a
curvature-aware correction designed to counteract the loss increase induced by
quantization. CAGE is derived from a multi-objective view of QAT that balances
loss minimization with adherence to quantization constraints, yielding a
principled correction term that depends on local curvature information. On the
theoretical side, we introduce the notion of Pareto-optimal solutions for
quantized optimization, and establish that CAGE yields strong convergence
guarantees in the smooth non-convex setting. In terms of implementation, our
approach is optimizer-agnostic, but we provide a highly-efficient
implementation that leverages Adam statistics. When pre-training Llama-style
models of up to 800M-parameters, CAGE recovers over 10% of the
quantization-induced loss increase in the W4A4 regime over outlier-mitigation
methods. These results indicate that curvature-aware gradient corrections can
bridge the remaining performance gap beyond current outlier-handling methods.

</details>


### [24] [Stick-Breaking Embedded Topic Model with Continuous Optimal Transport for Online Analysis of Document Streams](https://arxiv.org/abs/2510.18786)
*Federica Granese,Serena Villata,Charles Bouveyron*

Main category: cs.LG

TL;DR: SB-SETM是一种创新的在线主题模型，通过合并连续文档批次上的模型来处理数据流，能够自动推断每个时间步的活动主题数量，并在俄乌战争新闻语料上表现出色。


<details>
  <summary>Details</summary>
Motivation: 在线主题模型能够识别随时间不断演化的数据流中的潜在主题，与现实场景自然契合，但由于面临特定额外挑战，相比离线模型受到的关注较少。

Method: SB-SETM扩展了嵌入式主题模型（ETM），通过截断stick-breaking构造处理文档-主题分布，自动推断每个时间步的活动主题数量；并引入基于连续最优传输的合并策略来处理高维潜在主题空间中的主题嵌入。

Result: 数值实验显示SB-SETM在模拟场景中优于基线方法，并在2022-2023年俄乌战争新闻文章的真实语料上进行了广泛测试。

Conclusion: SB-SETM通过创新的模型合并策略和自动主题数量推断机制，有效解决了在线主题建模的挑战，在真实数据流场景中表现出优越性能。

Abstract: Online topic models are unsupervised algorithms to identify latent topics in
data streams that continuously evolve over time. Although these methods
naturally align with real-world scenarios, they have received considerably less
attention from the community compared to their offline counterparts, due to
specific additional challenges. To tackle these issues, we present SB-SETM, an
innovative model extending the Embedded Topic Model (ETM) to process data
streams by merging models formed on successive partial document batches. To
this end, SB-SETM (i) leverages a truncated stick-breaking construction for the
topic-per-document distribution, enabling the model to automatically infer from
the data the appropriate number of active topics at each timestep; and (ii)
introduces a merging strategy for topic embeddings based on a continuous
formulation of optimal transport adapted to the high dimensionality of the
latent topic space. Numerical experiments show SB-SETM outperforming baselines
on simulated scenarios. We extensively test it on a real-world corpus of news
articles covering the Russian-Ukrainian war throughout 2022-2023.

</details>


### [25] [When LRP Diverges from Leave-One-Out in Transformers](https://arxiv.org/abs/2510.18810)
*Weiqiu You,Siqi Zeng,Yao-Hung Hubert Tsai,Makoto Yamada,Han Zhao*

Main category: cs.LG

TL;DR: 本文分析了在Transformer模型中，层间相关性传播（LRP）方法在逼近留一法（LOO）特征重要性时的局限性，发现双线性传播规则违反实现不变性公理，且绕过softmax层传播相关性可改善与LOO的对齐度。


<details>
  <summary>Details</summary>
Motivation: 研究LRP方法在Transformer中逼近LOO特征重要性的有效性，因为LOO计算成本高而LRP可能提供高效替代，但其在现代Transformer中的公理合理性尚未充分验证。

Method: 首先分析AttnLRP中双线性传播规则违反实现不变性公理，通过理论证明和线性注意力层实验验证；其次重新评估CP-LRP作为诊断基线，研究绕过softmax层传播相关性的效果。

Result: 双线性传播规则确实违反实现不变性公理；绕过softmax层、仅通过值矩阵反向传播相关性显著改善了与LOO的对齐度，特别是在Transformer的中后期层。

Conclusion: 双线性因子化敏感性和softmax传播误差可能共同削弱LRP在Transformer中逼近LOO的能力，建议在相关方法设计中考虑这些因素。

Abstract: Leave-One-Out (LOO) provides an intuitive measure of feature importance but
is computationally prohibitive. While Layer-Wise Relevance Propagation (LRP)
offers a potentially efficient alternative, its axiomatic soundness in modern
Transformers remains largely under-examined. In this work, we first show that
the bilinear propagation rules used in recent advances of AttnLRP violate the
implementation invariance axiom. We prove this analytically and confirm it
empirically in linear attention layers. Second, we also revisit CP-LRP as a
diagnostic baseline and find that bypassing relevance propagation through the
softmax layer -- backpropagating relevance only through the value matrices --
significantly improves alignment with LOO, particularly in middle-to-late
Transformer layers. Overall, our results suggest that (i) bilinear
factorization sensitivity and (ii) softmax propagation error potentially
jointly undermine LRP's ability to approximate LOO in Transformers.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [26] [Arbitrated Indirect Treatment Comparisons](https://arxiv.org/abs/2510.18071)
*Yixin Fang,Weili He*

Main category: stat.ML

TL;DR: 本文提出了一种新的仲裁间接治疗比较方法，旨在解决MAIC悖论问题，通过估计共同目标人群（重叠人群）的治疗效果来消除不同赞助商分析同一数据时得出矛盾结论的问题。


<details>
  <summary>Details</summary>
Motivation: MAIC方法在健康技术评估中应用日益广泛，但存在MAIC悖论问题，即不同赞助商分析相同数据时会得出相互矛盾的治疗效果结论，这是因为每个赞助商隐式地针对不同人群。

Method: 提出仲裁间接治疗比较方法，通过重新加权个体参与者数据试验的受试者，使其与仅具有汇总数据的试验的协变量汇总统计量匹配，重点估计共同目标人群（重叠人群）的治疗效果。

Result: 新方法能够解决MAIC悖论，确保不同分析者使用相同数据时得到一致的结论，通过明确定义共同目标人群来消除不一致性。

Conclusion: 仲裁间接治疗比较方法为解决MAIC悖论提供了有效途径，通过聚焦于重叠人群的治疗效果估计，确保了分析结果的一致性和可靠性。

Abstract: Matching-adjusted indirect comparison (MAIC) has been increasingly employed
in health technology assessments (HTA). By reweighting subjects from a trial
with individual participant data (IPD) to match the covariate summary
statistics of another trial with only aggregate data (AgD), MAIC facilitates
the estimation of a treatment effect defined with respect to the AgD trial
population. This manuscript introduces a new class of methods, termed
arbitrated indirect treatment comparisons, designed to address the ``MAIC
paradox'' -- a phenomenon highlighted by Jiang et al.~(2025). The MAIC paradox
arises when different sponsors, analyzing the same data, reach conflicting
conclusions regarding which treatment is more effective. The underlying issue
is that each sponsor implicitly targets a different population. To resolve this
inconsistency, the proposed methods focus on estimating treatment effects in a
common target population, specifically chosen to be the overlap population.

</details>


### [27] [Beating the Winner's Curse via Inference-Aware Policy Optimization](https://arxiv.org/abs/2510.18161)
*Hamsa Bastani,Osbert Bastani,Bryce McLaughlin*

Main category: stat.ML

TL;DR: 提出了一种新的策略优化方法——推理感知策略优化，通过同时优化估计目标值和策略在统计上显著优于现有策略的概率，来解决赢家诅咒问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于机器学习预测反事实结果来优化治疗决策策略的方法存在赢家诅咒问题，即策略优化过程会利用预测误差而非真正改进，导致预测的性能改进无法在下游策略评估中得到验证。

Method: 提出推理感知策略优化方法，不仅优化估计目标值，还优化策略在统计上显著优于观察策略的概率。通过数学表征这两个目标的帕累托前沿，设计策略优化算法，使用机器学习预测反事实结果并估计帕累托前沿。

Result: 通过模拟实验验证了该方法的有效性，决策者可以根据期望的权衡选择策略，然后按常规在测试集上进行策略评估。

Conclusion: 推理感知策略优化方法能够有效解决赢家诅咒问题，确保学习到的策略在下游评估中具有统计显著性的改进。

Abstract: There has been a surge of recent interest in automatically learning policies
to target treatment decisions based on rich individual covariates. A common
approach is to train a machine learning model to predict counterfactual
outcomes, and then select the policy that optimizes the predicted objective
value. In addition, practitioners also want confidence that the learned policy
has better performance than the incumbent policy according to downstream policy
evaluation. However, due to the winner's curse-an issue where the policy
optimization procedure exploits prediction errors rather than finding actual
improvements-predicted performance improvements are often not substantiated by
downstream policy optimization. To address this challenge, we propose a novel
strategy called inference-aware policy optimization, which modifies policy
optimization to account for how the policy will be evaluated downstream.
Specifically, it optimizes not only for the estimated objective value, but also
for the chances that the policy will be statistically significantly better than
the observational policy used to collect data. We mathematically characterize
the Pareto frontier of policies according to the tradeoff of these two goals.
Based on our characterization, we design a policy optimization algorithm that
uses machine learning to predict counterfactual outcomes, and then plugs in
these predictions to estimate the Pareto frontier; then, the decision-maker can
select the policy that optimizes their desired tradeoff, after which policy
evaluation can be performed on the test set as usual. Finally, we perform
simulations to illustrate the effectiveness of our methodology.

</details>


### [28] [The Bias-Variance Tradeoff in Data-Driven Optimization: A Local Misspecification Perspective](https://arxiv.org/abs/2510.18215)
*Haixiang Lan,Luofeng Liao,Adam N. Elmachtoub,Christian Kroer,Henry Lam,Haofeng Zhang*

Main category: stat.ML

TL;DR: 本文在局部误设条件下分析了样本平均近似(SAA)、估计-优化(ETO)和集成估计-优化(IEO)三种数据驱动随机优化方法的相对性能，揭示了它们之间的偏差-方差权衡关系。


<details>
  <summary>Details</summary>
Motivation: 当前对数据驱动随机优化方法相对性能的理解有限，大多数结果局限于模型完全正确或完全误设的二元情况。本文旨在在局部误设场景下进行更细粒度的分析。

Method: 利用统计学中的连续性理论工具，在局部误设条件下分析SAA、IEO和ETO方法的性能，推导决策偏差的显式表达式。

Result: 发现在局部误设条件下，三种方法存在偏差-方差权衡关系，偏差和方差的相对重要性取决于局部误设的程度。推导出了决策偏差的显式表达式，能够刻画(非)有影响的误设方向。

Conclusion: 提供了对数据驱动随机优化方法在局部误设条件下相对性能的几何理解，揭示了偏差-方差权衡机制，为方法选择提供了理论指导。

Abstract: Data-driven stochastic optimization is ubiquitous in machine learning and
operational decision-making problems. Sample average approximation (SAA) and
model-based approaches such as estimate-then-optimize (ETO) or integrated
estimation-optimization (IEO) are all popular, with model-based approaches
being able to circumvent some of the issues with SAA in complex
context-dependent problems. Yet the relative performance of these methods is
poorly understood, with most results confined to the dichotomous cases of the
model-based approach being either well-specified or misspecified. We develop
the first results that allow for a more granular analysis of the relative
performance of these methods under a local misspecification setting, which
models the scenario where the model-based approach is nearly well-specified. By
leveraging tools from contiguity theory in statistics, we show that there is a
bias-variance tradeoff between SAA, IEO, and ETO under local misspecification,
and that the relative importance of the bias and the variance depends on the
degree of local misspecification. Moreover, we derive explicit expressions for
the decision bias, which allows us to characterize (un)impactful
misspecification directions, and provide further geometric understanding of the
variance.

</details>


### [29] [Learning under Quantization for High-Dimensional Linear Regression](https://arxiv.org/abs/2510.18259)
*Dechen Zhang,Junwei Su,Difan Zou*

Main category: stat.ML

TL;DR: 本文首次系统性地从理论上研究了低比特量化对高维线性回归中随机梯度下降学习性能的影响，分析了数据、标签、参数、激活和梯度五种量化类型对学习过程的不同影响机制。


<details>
  <summary>Details</summary>
Motivation: 尽管低比特量化在大规模模型高效训练中广泛应用且经验上成功，但其对学习性能影响的理论理解仍然缺乏，即使在最简单的线性回归设置中也是如此。

Method: 建立了一个新颖的分析框架，研究高维线性回归中有限步随机梯度下降在五种量化目标下的表现：数据、标签、参数、激活和梯度量化，分析算法依赖和数据依赖的过量风险界限。

Result: 发现参数、激活和梯度量化在训练过程中放大噪声；数据量化扭曲数据谱；数据和标签量化引入额外近似和量化误差。对于乘法量化可以消除谱失真，对于加法量化则出现批次大小的有益缩放效应。

Conclusion: 该理论为理解量化如何塑造优化算法的学习动态提供了强大视角，为在实用硬件约束下进一步探索学习理论铺平了道路。

Abstract: The use of low-bit quantization has emerged as an indispensable technique for
enabling the efficient training of large-scale models. Despite its widespread
empirical success, a rigorous theoretical understanding of its impact on
learning performance remains notably absent, even in the simplest linear
regression setting. We present the first systematic theoretical study of this
fundamental question, analyzing finite-step stochastic gradient descent (SGD)
for high-dimensional linear regression under a comprehensive range of
quantization targets: data, labels, parameters, activations, and gradients. Our
novel analytical framework establishes precise algorithm-dependent and
data-dependent excess risk bounds that characterize how different quantization
affects learning: parameter, activation, and gradient quantization amplify
noise during training; data quantization distorts the data spectrum; and data
and label quantization introduce additional approximation and quantized error.
Crucially, we prove that for multiplicative quantization (with input-dependent
quantization step), this spectral distortion can be eliminated, and for
additive quantization (with constant quantization step), a beneficial scaling
effect with batch size emerges. Furthermore, for common polynomial-decay data
spectra, we quantitatively compare the risks of multiplicative and additive
quantization, drawing a parallel to the comparison between FP and integer
quantization methods. Our theory provides a powerful lens to characterize how
quantization shapes the learning dynamics of optimization algorithms, paving
the way to further explore learning theory under practical hardware
constraints.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [30] [In-Process Monitoring of Gear Power Honing Using Vibration Signal Analysis and Machine Learning](https://arxiv.org/abs/2510.17809)
*Massimo Capurso,Luciano Afferrante*

Main category: eess.SP

TL;DR: 提出了一种基于振动信号分析和机器学习的数据驱动框架，用于齿轮强力珩磨过程中的实时监控，通过三种子空间学习方法提取特征，结合SVM分类器实现高达100%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 现代齿轮制造对NVH性能要求严格，传统质量控制方法无法捕捉瞬时加工异常和实现实时缺陷检测，需要开发新的过程监控方法。

Method: 使用加速度计连续采集振动数据，进行时频信号分析，比较三种子空间学习方法（PCA、PCA+LDA、R-UMLDA）进行特征提取，然后用SVM分类器预测四个齿轮质量类别。

Result: 在工业环境中收集的实验数据集上，该框架实现了高分类准确率（最高达100%），提供了与工艺动力学相关的可解释频谱特征。

Conclusion: 该数据驱动框架能够有效实现齿轮强力珩磨过程的实时监控，为集成到实时监控和预测性维护系统提供了实用解决方案。

Abstract: In modern gear manufacturing, stringent Noise, Vibration, and Harshness (NVH)
requirements demand high-precision finishing operations such as power honing.
Conventional quality control strategies rely on post-process inspections and
Statistical Process Control (SPC), which fail to capture transient machining
anomalies and cannot ensure real-time defect detection. This study proposes a
novel, data-driven framework for in-process monitoring of gear power honing
using vibration signal analysis and machine learning. Our proposed methodology
involves continuous data acquisition via accelerometers, followed by
time-frequency signal analysis. We investigate and compare the efficacy of
three subspace learning methods for features extraction: (1) Principal
Component Analysis (PCA) for dimensionality reduction; (2) a two-stage
framework combining PCA with Linear Discriminant Analysis (LDA) for enhanced
class separation; and (3) Uncorrelated Multilinear Discriminant Analysis with
Regularization (R-UMLDA), adapted for tensor data, which enforces feature
decorrelation and includes regularization for small sample sizes. These
extracted features are then fed into a Support Vector Machine (SVM) classifier
to predict four distinct gear quality categories, established through rigorous
geometrical inspections and test bench results of assembled gearboxes. The
models are trained and validated on an experimental dataset collected in an
industrial context during gear power-honing operations, with gears classified
into four different quality categories. The proposed framework achieves high
classification accuracy (up to 100%) in an industrial setting. The approach
offers interpretable spectral features that correlate with process dynamics,
enabling practical integration into real-time monitoring and predictive
maintenance systems.

</details>


### [31] [Exploring Complexity Changes in Diseased ECG Signals for Enhanced Classification](https://arxiv.org/abs/2510.17810)
*Camilo Quiceno Quintero,Sandip Varkey George*

Main category: eess.SP

TL;DR: 本研究使用非线性时间序列分析ECG复杂度与心脏病理的关系，发现非线性指标能显著区分健康和患病个体，并提升机器学习分类准确率。


<details>
  <summary>Details</summary>
Motivation: 心脏的复杂动态反映在其电活动（ECG）中，本研究旨在理解ECG复杂度如何随心脏病理变化，为疾病诊断提供新方法。

Method: 使用PTB-XL数据集，从导联II ECG提取非线性指标，并使用Spearman相关性和互信息计算跨导联（II、V2、AVL）指标。

Result: 几乎所有非线性指标在健康和患病个体间均存在显著差异（p<.001），将复杂度指标加入机器学习模型使AUC从0.86提升至0.87（仅非线性指标）和0.90（包括跨时间序列指标）。

Conclusion: 非线性时间序列分析能有效量化ECG复杂度差异，显著提升心脏疾病分类性能，为ECG分析提供了有价值的补充工具。

Abstract: The complex dynamics of the heart are reflected in its electrical activity,
captured through electrocardiograms (ECGs). In this study we use nonlinear time
series analysis to understand how ECG complexity varies with cardiac pathology.
Using the large PTB-XL dataset, we extracted nonlinear measures from lead II
ECGs, and cross-channel metrics (leads II, V2, AVL) using Spearman correlations
and mutual information. Significant differences between diseased and healthy
individuals were found in almost all measures between healthy and diseased
classes, and between 5 diagnostic superclasses ($p<.001$). Moreover,
incorporating these complexity quantifiers into machine learning models
substantially improved classification accuracy measured using area under the
ROC curve (AUC) from 0.86 (baseline) to 0.87 (nonlinear measures) and 0.90
(including cross-time series metrics).

</details>


### [32] [Channel Modeling of Satellite-to-Underwater Laser Communication Links: An Analytical-Monte Carlo Hybrid Approach](https://arxiv.org/abs/2510.17811)
*Zhixing Wang,Renzhi Yuan,Haifeng Yao,Chuang Yang,Mugen Peng*

Main category: eess.SP

TL;DR: 本文建立了卫星到水下激光通信的完整信道模型，采用分析-蒙特卡洛混合方法，同时考虑粒子和湍流效应，分析了不同环境条件下的误码率和中断概率。


<details>
  <summary>Details</summary>
Motivation: 卫星到水下激光通信信道建模面临挑战，现有研究要么关注分离信道，要么忽略粒子和湍流对激光传播的综合影响，需要建立综合考虑这些因素的完整模型。

Method: 采用分析-蒙特卡洛混合方法：基于扩展惠更斯-菲涅耳原理获得湍流大气中传输激光束的强度分布；推导空气-水界面后光子传播方向的闭式概率密度函数；使用蒙特卡洛方法模拟水下链路并获得接收平面功率分布。

Result: 数值结果表明，水下粒子浓度对通信性能的影响远大于大气湍流和水下湍流；增加空气-水界面的风速不会显著恶化通信性能。

Conclusion: 建立了综合考虑粒子和湍流效应的卫星到水下激光通信完整信道模型，发现水下粒子浓度是影响通信性能的主要因素，而界面风速影响较小。

Abstract: Channel modeling for satellite-to-underwater laser communication (StULC)
links remains challenging due to long distances and the diversity of the
channel constituents. The StULC channel is typically segmented into three
isolated channels: the atmospheric channel, the air-water interface channel,
and the underwater channel. Previous studies involving StULC channel modeling
either focused on separated channels or neglected the combined effects of
particles and turbulence on laser propagation. In this paper, we established a
comprehensive StULC channel model by an analytical-Monte Carlo hybrid approach,
taking into account the effects of both particles and turbulence. We first
obtained the intensity distribution of the transmitted laser beam after passing
through the turbulent atmosphere based on the extended Huygens-Fresnel
principle. Then we derived a closed-form probability density function of the
photon propagating direction after passing through the air-water interface,
which greatly simplified the modeling of StULC links. At last, we employed a
Monte Carlo method to model the underwater links and obtained the power
distribution at the receiving plane. Based on the proposed StULC channel model,
we analyzed the bit error rate and the outage probability under different
environmental conditions. Numerical results demonstrated that, the influence of
underwater particle concentration on the communication performance is much
pronounced than those of both the atmospheric turbulence and the underwater
turbulence. Notably, increasing the wind speed at the air-water interface does
not significantly worsen the communication performance of the StULC links.

</details>


### [33] [Cross-Domain Multi-Person Human Activity Recognition via Near-Field Wi-Fi Sensing](https://arxiv.org/abs/2510.17816)
*Xin Li,Jingzhi Hu,Yinghui He,Hongbo Wang,Jin Gan,Jun Luo*

Main category: eess.SP

TL;DR: WiAnchor是一个用于Wi-Fi多用户活动识别的跨域适应训练框架，通过锚点匹配机制在不完整活动类别情况下实现高效适应。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi活动识别在多用户场景下因空间分辨率限制而难以区分不同用户，且近场信号具有用户特定特征和模式不规则性，导致跨域适应困难，特别是在某些活动类别不可用时。

Method: 采用三步训练框架：预训练阶段扩大类间特征边界增强活动可分性；微调阶段引入锚点匹配机制进行跨域适应，基于不完整活动类别过滤用户特定干扰；最后基于输入样本与锚点的特征相似性进一步改进识别。

Result: 构建了全面数据集进行评估，在活动类别缺失情况下实现了超过90%的跨域准确率。

Conclusion: WiAnchor框架有效解决了Wi-Fi多用户活动识别中的跨域适应问题，特别是在不完整活动类别情况下仍能保持高识别精度。

Abstract: Wi-Fi-based human activity recognition (HAR) provides substantial convenience
and has emerged as a thriving research field, yet the coarse spatial resolution
inherent to Wi-Fi significantly hinders its ability to distinguish multiple
subjects. By exploiting the near-field domination effect, establishing a
dedicated sensing link for each subject through their personal Wi-Fi device
offers a promising solution for multi-person HAR under native traffic. However,
due to the subject-specific characteristics and irregular patterns of
near-field signals, HAR neural network models require fine-tuning (FT) for
cross-domain adaptation, which becomes particularly challenging with certain
categories unavailable. In this paper, we propose WiAnchor, a novel training
framework for efficient cross-domain adaptation in the presence of incomplete
activity categories. This framework processes Wi-Fi signals embedded with
irregular time information in three steps: during pre-training, we enlarge
inter-class feature margins to enhance the separability of activities; in the
FT stage, we innovate an anchor matching mechanism for cross-domain adaptation,
filtering subject-specific interference informed by incomplete activity
categories, rather than attempting to extract complete features from them;
finally, the recognition of input samples is further improved based on their
feature-level similarity with anchors. We construct a comprehensive dataset to
thoroughly evaluate WiAnchor, achieving over 90% cross-domain accuracy with
absent activity categories.

</details>


### [34] [Single-Snapshot Gridless 2D-DoA Estimation for UCAs: A Joint Optimization Approach](https://arxiv.org/abs/2510.17818)
*Salar Nouri*

Main category: eess.SP

TL;DR: 提出了一种用于均匀圆阵列单快照数据的无网格二维波达方向估计算法，通过联合估计流形变换矩阵和源方位-仰角对，避免了传统方法的计算复杂性和鲁棒性问题。


<details>
  <summary>Details</summary>
Motivation: 传统无网格方法在单快照场景下由于计算成本过高或缺乏鲁棒性而失效，需要一种能够克服这些限制的新框架。

Method: 通过联合估计流形变换矩阵和源方位-仰角对，构建统一优化问题，并使用不精确增广拉格朗日方法高效求解，完全避免了半定规划。

Result: 仿真结果表明，所提出的iALM框架能够提供鲁棒且高分辨率的无网格二维波达方向估计。

Conclusion: 该方法特别适用于具有挑战性的单快照阵列信号处理应用，证明了其在复杂场景下的有效性。

Abstract: This paper tackles the challenging problem of gridless two-dimensional (2D)
direction-of-arrival (DOA) estimation for a uniform circular array (UCA) from a
single snapshot of data. Conventional gridless methods often fail in this
scenario due to prohibitive computational costs or a lack of robustness. We
propose a novel framework that overcomes these limitations by jointly
estimating a manifold transformation matrix and the source azimuth-elevation
pairs within a single, unified optimization problem. This problem is solved
efficiently using an inexact Augmented Lagrangian Method (iALM), which
completely circumvents the need for semidefinite programming. By unifying the
objectives of data fidelity and transformation robustness, our approach is
uniquely suited for the demanding single-snapshot case. Simulation results
confirm that the proposed iALM framework provides robust and high-resolution,
gridless 2D-DOA estimates, establishing its efficacy for challenging array
signal processing applications.

</details>


### [35] [CLARAE: Clarity Preserving Reconstruction AutoEncoder for Denoising and Rhythm Classification of Intracardiac Electrograms](https://arxiv.org/abs/2510.17821)
*Long Lin,Pablo Peiro-Corbacho,Pablo Ávila,Alejandro Carta-Bergaz,Ángel Arenal,Gonzalo R. Ríos-Muñoz,Carlos Sevilla-Salcedo*

Main category: eess.SP

TL;DR: CLARAE是一种用于心房内电图的1D自编码器，能够实现高保真重建和紧凑的64维潜在表示，在噪声抑制和节律分类方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 心房内电图常受噪声污染且维度较高，限制了实时分析能力，需要开发既能降噪又能提供紧凑表示的方法。

Method: 采用编码器-解码器架构，通过池化下采样、混合插值-卷积上采样路径和有界潜在空间三个原则来保持波形形态并减少重建伪影。

Result: 在495,731个电图段上测试，CLARAE在所有节律类型上F1分数超过0.97，潜在空间显示清晰的节律聚类，在去噪任务中表现优异。

Conclusion: CLARAE结合了鲁棒的去噪能力和紧凑的判别性表示，为节律鉴别、信号质量评估和实时映射等临床工作流程提供了实用基础。

Abstract: Intracavitary atrial electrograms (EGMs) provide high-resolution insights
into cardiac electrophysiology but are often contaminated by noise and remain
high-dimensional, limiting real-time analysis. We introduce CLARAE
(CLArity-preserving Reconstruction AutoEncoder), a one-dimensional
encoder--decoder designed for atrial EGMs, which achieves both high-fidelity
reconstruction and a compact 64-dimensional latent representation. CLARAE is
designed to preserve waveform morphology, mitigate reconstruction artifacts,
and produce interpretable embeddings through three principles: downsampling
with pooling, a hybrid interpolation--convolution upsampling path, and a
bounded latent space.
  We evaluated CLARAE on 495,731 EGM segments (unipolar and bipolar) from 29
patients across three rhythm types (AF, SR300, SR600). Performance was
benchmarked against six state-of-the-art autoencoders using reconstruction
metrics, rhythm classification, and robustness across signal-to-noise ratios
from -5 to 15 dB. In downstream rhythm classification, CLARAE achieved
F1-scores above 0.97 for all rhythm types, and its latent space showed clear
clustering by rhythm. In denoising tasks, it consistently ranked among the top
performers for both unipolar and bipolar signals.
  In order to promote reproducibility and enhance accessibility, we offer an
interactive web-based application. This platform enables users to explore
pre-trained CLARAE models, visualize the reconstructions, and compute metrics
in real time. Overall, CLARAE combines robust denoising with compact,
discriminative representations, offering a practical foundation for clinical
workflows such as rhythm discrimination, signal quality assessment, and
real-time mapping.

</details>


### [36] [Analyse comparative d'algorithmes de restauration en architecture dépliée pour des signaux chromatographiques parcimonieux](https://arxiv.org/abs/2510.18760)
*Mouna Gharbi,Silvia Villa,Emilie Chouzenoux,Jean-Christophe Pesquet,Laurent Duval*

Main category: eess.SP

TL;DR: 本文对三种展开式架构在参数化色谱信号数据库上进行了比较研究，重点评估了这些方法在物理化学峰信号表征方面的性能。


<details>
  <summary>Details</summary>
Motivation: 数据恢复是研究稀疏假设下退化观测数据重建的活跃领域，传统迭代优化方法与深度学习技术相互补充，展开式方法结合了两者的优势。

Method: 在参数化色谱信号数据库上对三种展开式架构进行对比研究，使用适应物理化学峰信号表征的指标进行评估。

Result: 研究突出了这些方法的性能表现，特别是在采用适应物理化学峰信号表征的指标时。

Conclusion: 展开式方法结合了传统优化和深度学习的优势，在色谱信号恢复任务中表现出色，特别是使用专门设计的物理化学指标进行评估时。

Abstract: Data restoration from degraded observations, of sparsity hypotheses, is an
active field of study. Traditional iterative optimization methods are now
complemented by deep learning techniques. The development of unfolded methods
benefits from both families. We carry out a comparative study of three
architectures on parameterized chromatographic signal databases, highlighting
the performance of these approaches, especially when employing metrics adapted
to physico-chemical peak signal characterization.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [37] [OPTAGENT: Optimizing Multi-Agent LLM Interactions Through Verbal Reinforcement Learning for Enhanced Reasoning](https://arxiv.org/abs/2510.18032)
*Zhenyu Bi,Meng Lu,Yang Li,Swastik Roy,Weijie Guan,Morteza Ziyadi,Xuan Wang*

Main category: cs.AI

TL;DR: 提出了一种多智能体口头强化学习算法，通过动态构建和优化多智能体协作结构来增强复杂推理能力，在数学推理、创意写作等任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统要么采用预定义结构，要么依赖多数投票或圆桌辩论，这会压制正确但非主导的智能体贡献。作者假设有效的智能体通信对多智能体推理至关重要，辩论质量起着重要作用。

Method: 提出多智能体口头强化学习算法，定义动作空间和反馈机制，评估整个辩论过程中的通信鲁棒性和连贯性，最终通过所有智能体的多数投票做出决策。

Result: 在数学推理、创意写作、科学推理和数值排序等各种推理任务上的评估表明，该方法显著优于单智能体提示方法和最先进的多智能体框架。

Conclusion: 通过动态优化多智能体协作结构和强调通信质量，能够显著提升复杂推理任务的性能，验证了有效智能体通信在多智能体系统中的重要性。

Abstract: Large Language Models (LLMs) have shown remarkable reasoning capabilities in
mathematical and scientific tasks. To enhance complex reasoning, multi-agent
systems have been proposed to harness the collective intelligence of LLM
agents. However, existing collaboration structures are either predefined or
rely on majority voting or round-table debates, which can suppress correct but
less dominant agent contributions. Recent approaches model multi-agent systems
as graph networks but optimize purely for agent performance, neglecting the
quality of interactions. We hypothesize that effective agent communication is
crucial for multi-agent reasoning and that debating quality plays a significant
role. To address this, we propose $\ours$, a multi-agent verbal reinforcement
learning algorithm that dynamically constructs and refines multi-agent
collaboration structures. Our method defines action spaces and a feedback
mechanism that evaluates communication robustness and coherence throughout the
debate. The final decision is achieved through a majority vote over all the
agents. We assess $\ours$ on various reasoning tasks, including mathematical
reasoning, creative writing, scientific reasoning, and numerical sorting.
Results demonstrate that our approach significantly outperforms single-agent
prompting methods and state-of-the-art multi-agent frameworks on diverse tasks.

</details>


### [38] [Subject-Event Ontology Without Global Time: Foundations and Execution Semantics](https://arxiv.org/abs/2510.18040)
*Alexander Boldachev*

Main category: cs.AI

TL;DR: 提出了一种基于主体-事件的本体论形式化方法，用于在没有全局时间的情况下建模复杂动态系统。该方法通过事件固定、因果顺序、声明式数据流等机制确保确定性，并在boldsea系统中实现了可执行本体。


<details>
  <summary>Details</summary>
Motivation: 为复杂动态系统提供不依赖全局时间的建模方法，解决分布式系统、微服务架构、DLT平台等场景中的多视角和冲突事实问题。

Method: 基于九个公理(A1-A9)的形式化本体论，包括事件作为固定行为、因果顺序通过happens-before定义、声明式数据流机制、模型作为认知过滤器等核心原则。

Result: 开发了boldsea系统作为可执行本体的工作流引擎，在BSL语言中实现了理论构造，证明了方法的实际适用性。

Conclusion: 该形式化方法适用于分布式系统、微服务架构、DLT平台和多视角场景，能够处理来自不同主体的冲突事实，为复杂动态系统建模提供了有效的理论基础和实现框架。

Abstract: A formalization of a subject-event ontology is proposed for modeling complex
dynamic systems without reliance on global time. Key principles: (1) event as
an act of fixation - a subject discerns and fixes changes according to models
(conceptual templates) available to them; (2) causal order via happens-before -
the order of events is defined by explicit dependencies, not timestamps; (3)
making the ontology executable via a declarative dataflow mechanism, ensuring
determinism; (4) models as epistemic filters - a subject can only fix what
falls under its known concepts and properties; (5) presumption of truth - the
declarative content of an event is available for computation from the moment of
fixation, without external verification. The formalization includes nine axioms
(A1-A9), ensuring the correctness of executable ontologies: monotonicity of
history (I1), acyclicity of causality (I2), traceability (I3). Special
attention is given to the model-based approach (A9): event validation via
schemas, actor authorization, automatic construction of causal chains (W3)
without global time. Practical applicability is demonstrated on the boldsea
system - a workflow engine for executable ontologies, where the theoretical
constructs are implemented in BSL (Boldsea Semantic Language). The
formalization is applicable to distributed systems, microservice architectures,
DLT platforms, and multiperspectivity scenarios (conflicting facts from
different subjects).

</details>


### [39] [Annotating the Chain-of-Thought: A Behavior-Labeled Dataset for AI Safety](https://arxiv.org/abs/2510.18154)
*Antonio-Gabriel Chacón Menke,Phan Xuan Tan,Eiji Kamioka*

Main category: cs.AI

TL;DR: 该研究提出了一个句子级标注的数据集，用于在LLM推理过程中基于激活状态监控安全行为，通过提取引导向量来检测和影响模型激活中的安全行为。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本推理步骤的安全监控方法可能遗漏微妙的有害模式，且可能被隐藏不安全推理的模型规避，需要更细粒度的安全监控技术。

Method: 构建包含推理序列和句子级安全行为标注的数据集，提取引导向量用于在模型激活中检测和影响安全行为。

Result: 展示了数据集的实用性，提取的表征能够检测和引导模型激活中的安全行为。

Conclusion: 激活级技术有潜力改善推理过程中的安全监督，填补了安全研究中精确识别推理链中特定行为发生时机的重要空白。

Abstract: Recent work has highlighted the importance of monitoring chain-of-thought
reasoning for AI safety; however, current approaches that analyze textual
reasoning steps can miss subtle harmful patterns and may be circumvented by
models that hide unsafe reasoning. We present a sentence-level labeled dataset
that enables activation-based monitoring of safety behaviors during LLM
reasoning. Our dataset contains reasoning sequences with sentence-level
annotations of safety behaviors such as expression of safety concerns or
speculation on user intent, which we use to extract steering vectors for
detecting and influencing these behaviors within model activations. The dataset
fills a key gap in safety research: while existing datasets label reasoning
holistically, effective application of steering vectors for safety monitoring
could be improved by identifying precisely when specific behaviors occur within
reasoning chains. We demonstrate the dataset's utility by extracting
representations that both detect and steer safety behaviors in model
activations, showcasing the potential of activation-level techniques for
improving safety oversight on reasoning.
  Content Warning: This paper discusses AI safety in the context of harmful
prompts and may contain references to potentially harmful content.

</details>


### [40] [ssToken: Self-modulated and Semantic-aware Token Selection for LLM Fine-tuning](https://arxiv.org/abs/2510.18250)
*Xiaohan Qin,Xiaoxing Wang,Ning Liao,Cancheng Zhang,Xiangdong Zhang,Mingquan Feng,Jingzhi Wang,Junchi Yan*

Main category: cs.AI

TL;DR: 提出ssToken方法，通过自调制和语义感知的token选择来解决现有token级数据选择方法的局限性，无需额外参考模型且能保留语义重要token。


<details>
  <summary>Details</summary>
Motivation: 现有token级数据选择方法需要训练或访问额外参考模型，且仅依赖损失信息进行token选择，无法很好保留语义重要但损失指标不偏好的token。

Method: ssToken利用历史模型计算当前模型的每token损失差异作为自调制信号，并引入基于注意力的语义感知token重要性估计指标，提供补充语义信息。

Result: 实验表明自调制选择和语义感知选择单独使用均优于全数据微调，两者结合的ssToken实现协同增益，超越现有token级选择方法。

Conclusion: ssToken在保持训练效率的同时提供性能改进，证明了自调制和语义感知token选择的有效性。

Abstract: Data quality plays a critical role in enhancing supervised fine-tuning (SFT)
for large language models (LLMs), and token-level data selection has emerged as
a promising direction for its fine-grained nature. Despite their strong
empirical performance, existing token-level selection methods share two key
limitations: (1) requiring training or accessing an additional reference model,
and (2) relying solely on loss information for token selection, which cannot
well preserve semantically important tokens that are not favored by loss-based
metrics. To address these challenges, we propose ssToken, a Self-modulated and
Semantic-aware Token Selection approach. ssToken leverages readily accessible
history models to compute the per-token loss difference with the current model,
which serves as a self-modulated signal that enables the model to adaptively
select tokens along its optimization trajectory, rather than relying on excess
loss from an offline-trained reference model as in prior works. We further
introduce a semantic-aware, attention-based token importance estimation metric,
orthogonal to loss-based selection and providing complementary semantic
information for more effective filtering. Extensive experiments across
different model families and scales demonstrate that both self-modulated
selection and semantic-aware selection alone outperform full-data fine-tuning,
while their integration--ssToken--achieves synergistic gains and further
surpasses prior token-level selection methods, delivering performance
improvements while maintaining training efficiency.

</details>


### [41] [Illusions of reflection: open-ended task reveals systematic failures in Large Language Models' reflective reasoning](https://arxiv.org/abs/2510.18254)
*Sion Weatherhead,Flora Salim,Aaron Belbasis*

Main category: cs.AI

TL;DR: 该研究测试了8个前沿大语言模型在开放但规则约束的任务中的自我反思能力，发现模型反思只能带来有限的改进，且经常重复相同的约束违规，表明缺乏真正的人类式目标驱动监控机制。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究当前大语言模型的'反思'能力是否在功能上等同于人类的反思推理，特别是在开放但规则约束的任务中，而非仅在有明确正确性信号的封闭任务中。

Method: 测试8个前沿模型在一个简单但现实的任务上：生成有效的科学测试项目，然后基于自我批评进行修订。任务具有可审计的成功标准。

Result: 首次尝试性能较差（平均约1个有效项目），反思后仅有适度改进（也约1个）。关键发现是第二次尝试经常重复相同的约束违规，表明'纠正收益'主要来自偶然生成有效项目而非真正的错误检测和原则性修复。

Conclusion: 当前LLM的'反思'缺乏功能性证据表明存在主动、目标驱动的监控机制，这种机制能帮助人类即使在首次尝试时也尊重约束。在模型本身实例化此类机制之前，可靠性能需要强制执行约束的外部结构。

Abstract: Humans do not just find mistakes after the fact -- we often catch them
mid-stream because 'reflection' is tied to the goal and its constraints.
Today's large language models produce reasoning tokens and 'reflective' text,
but is it functionally equivalent with human reflective reasoning? Prior work
on closed-ended tasks -- with clear, external 'correctness' signals -- can make
'reflection' look effective while masking limits in self-correction. We
therefore test eight frontier models on a simple, real-world task that is
open-ended yet rule-constrained, with auditable success criteria: to produce
valid scientific test items, then revise after considering their own critique.
First-pass performance is poor (often zero valid items out of 4 required; mean
$\approx$ 1), and reflection yields only modest gains (also $\approx$ 1).
Crucially, the second attempt frequently repeats the same violation of
constraint, indicating 'corrective gains' arise largely from chance production
of a valid item rather than error detection and principled,
constraint-sensitive repair. Performance before and after reflection
deteriorates as open-endedness increases, and models marketed for 'reasoning'
show no advantage. Our results suggest that current LLM 'reflection' lacks
functional evidence of the active, goal-driven monitoring that helps humans
respect constraints even on a first pass. Until such mechanisms are
instantiated in the model itself, reliable performance requires external
structure that enforces constraints.

</details>


### [42] [ShortcutBreaker: Low-Rank Noisy Bottleneck with Global Perturbation Attention for Multi-Class Unsupervised Anomaly Detection](https://arxiv.org/abs/2510.18342)
*Peng Tang,Xiaoxiao Yan,Xiaobin Hu,Yuning Cui,Donghao Luo,Jiangning Zhang,Pengcheng Xu,Jinlong Peng,Qingdong He,Feiyue Huang,Song Xue,Tobias Lasser*

Main category: cs.AI

TL;DR: 提出ShortcutBreaker框架解决多类无监督异常检测中的身份捷径问题，通过低秩噪声瓶颈和全局扰动注意力机制防止输入直接复制到输出，在四个基准数据集上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 多类无监督异常检测需要统一模型检测多个类别的异常，但现有Transformer架构存在身份捷径问题，即直接复制输入到输出，导致正常和异常样本的重构误差差异缩小，难以区分。

Method: 提出ShortcutBreaker框架：1）基于矩阵秩不等式设计低秩噪声瓶颈，将高维特征投影到低秩潜在空间防止平凡身份复制；2）利用ViT的全局建模能力引入全局扰动注意力，防止解码器中的信息捷径。

Result: 在四个基准数据集（三个工业数据集MVTec-AD、ViSA、Real-IAD和一个医学数据集Universal Medical）上分别达到99.8%、98.9%、90.6%和87.8%的图像级AUROC，显著优于现有MUAD方法。

Conclusion: ShortcutBreaker通过有效解决身份捷径问题，在多类无监督异常检测任务中实现了卓越性能，为统一异常检测模型提供了有效解决方案。

Abstract: Multi-class unsupervised anomaly detection (MUAD) has garnered growing
research interest, as it seeks to develop a unified model for anomaly detection
across multiple classes, i.e., eliminating the need to train separate models
for distinct objects and thereby saving substantial computational resources.
Under the MUAD setting, while advanced Transformer-based architectures have
brought significant performance improvements, identity shortcuts persist: they
directly copy inputs to outputs, narrowing the gap in reconstruction errors
between normal and abnormal cases, and thereby making the two harder to
distinguish. Therefore, we propose ShortcutBreaker, a novel unified
feature-reconstruction framework for MUAD tasks, featuring two key innovations
to address the issue of shortcuts. First, drawing on matrix rank inequality, we
design a low-rank noisy bottleneck (LRNB) to project highdimensional features
into a low-rank latent space, and theoretically demonstrate its capacity to
prevent trivial identity reproduction. Second, leveraging ViTs global modeling
capability instead of merely focusing on local features, we incorporate a
global perturbation attention to prevent information shortcuts in the decoders.
Extensive experiments are performed on four widely used anomaly detection
benchmarks, including three industrial datasets (MVTec-AD, ViSA, and Real-IAD)
and one medical dataset (Universal Medical). The proposed method achieves a
remarkable image-level AUROC of 99.8%, 98.9%, 90.6%, and 87.8% on these four
datasets, respectively, consistently outperforming previous MUAD methods across
different scenarios.

</details>


### [43] [PlanU: Large Language Model Decision Making through Planning under Uncertainty](https://arxiv.org/abs/2510.18442)
*Ziwei Deng,Mian Deng,Chenjing Liang,Zeming Gao,Chennan Ma,Chenxing Lin,Haipeng Zhang,Songzhu Mei,Cheng Wang,Siqi Shen*

Main category: cs.AI

TL;DR: PlanU是一种基于LLM的规划方法，通过蒙特卡洛树搜索捕获不确定性，使用分位数分布建模回报，并引入UCC评分平衡探索与利用。


<details>
  <summary>Details</summary>
Motivation: LLM在不确定性决策任务中表现不佳，特别是在随机环境中规划行动时。现有方法主要处理LLM不确定性，但忽略了环境不确定性，导致在随机状态转换环境中性能较差。

Method: 将不确定性建模到蒙特卡洛树搜索中，使用分位数分布表示每个节点的回报分布，并引入UCC评分来估计MCTS节点的不确定性。

Result: 通过大量实验验证了PlanU在基于LLM的不确定性决策任务中的有效性。

Conclusion: PlanU成功解决了LLM决策中的不确定性挑战，特别是在随机环境中的多步决策任务。

Abstract: Large Language Models (LLMs) are increasingly being explored across a range
of decision-making tasks. However, LLMs sometimes struggle with decision-making
tasks under uncertainty that are relatively easy for humans, such as planning
actions in stochastic environments. The adoption of LLMs for decision-making is
impeded by uncertainty challenges, such as LLM uncertainty and environmental
uncertainty. LLM uncertainty arises from the stochastic sampling process
inherent to LLMs. Most LLM-based Decision-Making (LDM) approaches address LLM
uncertainty through multiple reasoning chains or search trees. However, these
approaches overlook environmental uncertainty, which leads to poor performance
in environments with stochastic state transitions. Some recent LDM approaches
deal with uncertainty by forecasting the probability of unknown variables.
However, they are not designed for multi-step decision-making tasks that
require interaction with the environment. To address uncertainty in LLM
decision-making, we introduce PlanU, an LLM-based planning method that captures
uncertainty within Monte Carlo Tree Search (MCTS). PlanU models the return of
each node in the MCTS as a quantile distribution, which uses a set of quantiles
to represent the return distribution. To balance exploration and exploitation
during tree search, PlanU introduces an Upper Confidence Bounds with Curiosity
(UCC) score which estimates the uncertainty of MCTS nodes. Through extensive
experiments, we demonstrate the effectiveness of PlanU in LLM-based
decision-making tasks under uncertainty.

</details>


### [44] [CircuitSeer: Mining High-Quality Data by Probing Mathematical Reasoning Circuits in LLMs](https://arxiv.org/abs/2510.18470)
*Shaobo Wang,Yongliang Miao,Yuancheng Liu,and Qianli Ma,Ning Liao,Linfeng Zhang*

Main category: cs.AI

TL;DR: CircuitSeer是一种基于模型内部注意力机制的数据选择方法，通过识别核心推理电路来量化数据复杂度，仅使用10%数据就能提升模型性能


<details>
  <summary>Details</summary>
Motivation: 现有数据选择方法依赖昂贵的外部模型或不透明的启发式方法，而大语言模型的推理能力扩展需要大量计算资源，因此需要更高效的数据选择策略

Method: 通过分析模型内部注意力机制，发现复杂推理任务会激活稀疏的专用注意力头，形成核心推理电路。CircuitSeer通过测量数据对这些关键电路的影响来量化推理复杂度

Result: 在4个模型和9个数据集上的实验表明，CircuitSeer优于现有方法。使用该方法选择的10%数据微调Qwen2.5-Math-7B，平均Pass@1比完整数据集训练提高了1.4个百分点

Conclusion: 基于模型内部机制的数据选择方法CircuitSeer能够高效识别高质量训练数据，显著减少训练成本同时提升模型性能

Abstract: Large language models (LLMs) have demonstrated impressive reasoning
capabilities, but scaling their performance often relies on massive reasoning
datasets that are computationally expensive to train on. Existing data
selection methods aim to curate smaller, high-quality subsets but often rely on
costly external models or opaque heuristics. In this work, we shift the focus
from external heuristics to the model's internal mechanisms. We find that
complex reasoning tasks consistently activate a sparse, specialized subset of
attention heads, forming core reasoning circuits. Building on this insight, we
propose CircuitSeer, a novel data selection method that quantifies the
reasoning complexity of data by measuring its influence on these crucial
circuits. Extensive experiments on 4 models and 9 datasets demonstrate
CircuitSeer's superiority. Notably, fine-tuning Qwen2.5-Math-7B on just 10% of
data selected by our method achieves a 1.4-point gain in average Pass@1 over
training on the full dataset, highlighting its efficiency and effectiveness.

</details>


### [45] [Extracting alignment data in open models](https://arxiv.org/abs/2510.18554)
*Federico Barbero,Xiangming Gu,Christopher A. Choquette-Choo,Chawin Sitawarin,Matthew Jagielski,Itay Yona,Petar Veličković,Ilia Shumailov,Jamie Hayes*

Main category: cs.AI

TL;DR: 该研究表明可以从后训练模型中提取大量对齐训练数据，用于提升模型在长上下文推理、安全性、指令遵循和数学等方面的能力。研究发现模型容易重现SFT或RL等后训练阶段使用的数据，这些数据可用于训练基础模型，恢复相当程度的原始性能。


<details>
  <summary>Details</summary>
Motivation: 探索从后训练模型中提取对齐训练数据的可能性，揭示可能被忽视的对齐数据提取风险，并讨论蒸馏实践的下游影响。

Method: 使用高质量嵌入模型来衡量字符串之间的语义相似性，而非传统的字符串匹配方法。通过嵌入距离识别语义相似性，克服了编辑距离等传统指标的局限性。

Result: 研究发现近似字符串匹配会严重低估可提取的数据量（保守估计低估10倍）。模型容易重现后训练阶段使用的数据，这些提取的数据可用于训练基础模型，恢复有意义的原始性能。

Conclusion: 这项工作暴露了提取对齐数据的潜在风险，并开启了关于蒸馏实践下游影响的讨论：由于模型似乎在重现其训练集的某些方面，蒸馏可以被视为间接在模型原始数据集上进行训练。

Abstract: In this work, we show that it is possible to extract significant amounts of
alignment training data from a post-trained model -- useful to steer the model
to improve certain capabilities such as long-context reasoning, safety,
instruction following, and maths. While the majority of related work on
memorisation has focused on measuring success of training data extraction
through string matching, we argue that embedding models are better suited for
our specific goals. Distances measured through a high quality embedding model
can identify semantic similarities between strings that a different metric such
as edit distance will struggle to capture. In fact, in our investigation,
approximate string matching would have severely undercounted (by a conservative
estimate of $10\times$) the amount of data that can be extracted due to trivial
artifacts that deflate the metric. Interestingly, we find that models readily
regurgitate training data that was used in post-training phases such as SFT or
RL. We show that this data can be then used to train a base model, recovering a
meaningful amount of the original performance. We believe our work exposes a
possibly overlooked risk towards extracting alignment data. Finally, our work
opens up an interesting discussion on the downstream effects of distillation
practices: since models seem to be regurgitating aspects of their training set,
distillation can therefore be thought of as indirectly training on the model's
original dataset.

</details>


### [46] [Comparative Expressivity for Structured Argumentation Frameworks with Uncertain Rules and Premises](https://arxiv.org/abs/2510.18631)
*Carlo Proietti,Antonio Yuste-Ginel*

Main category: cs.AI

TL;DR: 本文研究了形式论证中定性不确定性的建模，比较了抽象模型和结构化模型的表达能力，提出了处理这两种形式主义的新表达性概念，并给出了负面和正面的表达性结果。


<details>
  <summary>Details</summary>
Motivation: 在形式论证中建模定性不确定性对于实际应用和理论理解都至关重要，但现有工作大多关注抽象模型。本文旨在研究这些抽象模型的合理实例化，将论证的不确定性基于其组成部分（规则和前提）。

Method: 通过将论证的不确定性基于其组成部分（规则和前提），引入了一个能够处理抽象和结构化形式主义的表达性概念，比较了抽象模型（包括不完整抽象论证框架及其依赖扩展）和结构化模型（ASPIC+）的表达能力。

Result: 提出了负面和正面的表达性结果，表明抽象模型和结构化模型在表达能力上存在差异，这些结果影响了不完整抽象论证框架及其依赖扩展。

Conclusion: 通过比较抽象和结构化论证模型在不确定性方面的表达能力，为形式论证中定性不确定性的建模提供了理论支持，有助于理解不同建模方法的优势和局限性。

Abstract: Modelling qualitative uncertainty in formal argumentation is essential both
for practical applications and theoretical understanding. Yet, most of the
existing works focus on \textit{abstract} models for arguing with uncertainty.
Following a recent trend in the literature, we tackle the open question of
studying plausible instantiations of these abstract models. To do so, we ground
the uncertainty of arguments in their components, structured within rules and
premises. Our main technical contributions are: i) the introduction of a notion
of expressivity that can handle abstract and structured formalisms, and ii) the
presentation of both negative and positive expressivity results, comparing the
expressivity of abstract and structured models of argumentation with
uncertainty. These results affect incomplete abstract argumentation frameworks,
and their extension with dependencies, on the abstract side, and ASPIC+, on the
structured side.

</details>


### [47] [Seg the HAB: Language-Guided Geospatial Algae Bloom Reasoning and Segmentation](https://arxiv.org/abs/2510.18751)
*Patterson Hsieh,Jerry Yeh,Mao-Chi He,Wen-Han Hsieh,Elvis Hsieh*

Main category: cs.AI

TL;DR: ALGOS是一个用于有害藻华监测的分割和推理系统，结合遥感图像理解和严重程度估计，通过GeoSAM辅助人工评估和视觉语言模型微调，在分割和严重程度估计方面表现稳健。


<details>
  <summary>Details</summary>
Motivation: 气候变化加剧了有害藻华的发生，特别是蓝藻，通过耗氧、释放毒素和破坏海洋生物多样性威胁水生生态系统和人类健康。传统监测方法劳动密集且时空覆盖有限，需要可扩展的AI驱动解决方案。

Method: 结合遥感图像理解与严重程度估计，集成GeoSAM辅助人工评估进行高质量分割掩码管理，并使用NASA的蓝藻聚合人工标签微调视觉语言模型进行严重程度预测。

Result: 实验表明ALGOS在分割和严重程度级别估计方面均实现了稳健性能。

Conclusion: ALGOS为实用和自动化的蓝藻监测系统铺平了道路。

Abstract: Climate change is intensifying the occurrence of harmful algal bloom (HAB),
particularly cyanobacteria, which threaten aquatic ecosystems and human health
through oxygen depletion, toxin release, and disruption of marine biodiversity.
Traditional monitoring approaches, such as manual water sampling, remain
labor-intensive and limited in spatial and temporal coverage. Recent advances
in vision-language models (VLMs) for remote sensing have shown potential for
scalable AI-driven solutions, yet challenges remain in reasoning over imagery
and quantifying bloom severity. In this work, we introduce ALGae Observation
and Segmentation (ALGOS), a segmentation-and-reasoning system for HAB
monitoring that combines remote sensing image understanding with severity
estimation. Our approach integrates GeoSAM-assisted human evaluation for
high-quality segmentation mask curation and fine-tunes vision language model on
severity prediction using the Cyanobacteria Aggregated Manual Labels (CAML)
from NASA. Experiments demonstrate that ALGOS achieves robust performance on
both segmentation and severity-level estimation, paving the way toward
practical and automated cyanobacterial monitoring systems.

</details>


### [48] [Decoding Funded Research: Comparative Analysis of Topic Models and Uncovering the Effect of Gender and Geographic Location](https://arxiv.org/abs/2510.18803)
*Shirin Tavakoli Kafiabad,Andrea Schiffauerova,Ashkan Ebadi*

Main category: cs.AI

TL;DR: 本研究比较了三种主题建模方法（LDA、STM、BERTopic）在分析加拿大NSERC 18年研究提案中的应用，并开发了COFFEE算法来增强BERTopic的协变量分析能力。结果显示BERTopic在识别细粒度、连贯性和新兴主题方面表现最佳，协变量分析揭示了省级研究专业化和性别主题模式。


<details>
  <summary>Details</summary>
Motivation: 为了优化国家科学投资，需要了解研究趋势的演变以及塑造这些趋势的人口和地理因素，特别是在公平、多样性和包容性承诺的背景下。

Method: 分析了2005-2022年加拿大自然科学与工程研究委员会资助的研究提案，比较了LDA、STM和BERTopic三种主题建模方法，并开发了COFFEE算法用于BERTopic的协变量效应估计。

Result: 所有模型都能有效识别核心科学领域，但BERTopic在识别细粒度、连贯性和新兴主题（如人工智能的快速扩张）方面表现最佳。COFFEE协变量分析确认了省级研究专业化和跨学科一致的性别主题模式。

Conclusion: 这些见解为资助组织制定更公平、更有影响力的资助策略提供了坚实的实证基础，从而提升科学生态系统的有效性。

Abstract: Optimizing national scientific investment requires a clear understanding of
evolving research trends and the demographic and geographical forces shaping
them, particularly in light of commitments to equity, diversity, and inclusion.
This study addresses this need by analyzing 18 years (2005-2022) of research
proposals funded by the Natural Sciences and Engineering Research Council of
Canada (NSERC). We conducted a comprehensive comparative evaluation of three
topic modelling approaches: Latent Dirichlet Allocation (LDA), Structural Topic
Modelling (STM), and BERTopic. We also introduced a novel algorithm, named
COFFEE, designed to enable robust covariate effect estimation for BERTopic.
This advancement addresses a significant gap, as BERTopic lacks a native
function for covariate analysis, unlike the probabilistic STM. Our findings
highlight that while all models effectively delineate core scientific domains,
BERTopic outperformed by consistently identifying more granular, coherent, and
emergent themes, such as the rapid expansion of artificial intelligence.
Additionally, the covariate analysis, powered by COFFEE, confirmed distinct
provincial research specializations and revealed consistent gender-based
thematic patterns across various scientific disciplines. These insights offer a
robust empirical foundation for funding organizations to formulate more
equitable and impactful funding strategies, thereby enhancing the effectiveness
of the scientific ecosystem.

</details>
