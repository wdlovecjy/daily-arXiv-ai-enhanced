<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 4]
- [cs.LG](#cs.LG) [Total: 30]
- [stat.ML](#stat.ML) [Total: 3]
- [stat.AP](#stat.AP) [Total: 2]
- [eess.SP](#eess.SP) [Total: 11]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [UCO: A Multi-Turn Interactive Reinforcement Learning Method for Adaptive Teaching with Large Language Models](https://arxiv.org/abs/2511.08873)
*Shouang Wei,Min Zhang,Xin Lin,Bo Jiang,Kun Kuang,Zhongxiang Dai*

Main category: cs.AI

TL;DR: 提出了单向认知优化（UCO）方法，通过多轮交互式强化学习解决LLM作为智能导师时的动态适应问题，包含两个协同奖励函数来评估学生认知进步和识别最近发展区。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在教学中仅学习表面教学模式，缺乏动态适应能力；现有强化学习方法无法区分学生真实理解与简单复述，也无法感知学生实时认知状态。

Method: UCO采用多轮交互式强化学习范式，包含两个关键奖励函数：进步奖励捕捉学生认知进步，支架奖励动态识别学生最近发展区。

Result: 在BigMath和MathTutorBench基准测试中，UCO模型优于所有同等规模模型，性能与先进闭源模型相当。

Conclusion: UCO方法有效解决了LLM作为智能导师时的动态适应问题，通过认知导向的奖励机制提升了教学效果。

Abstract: Large language models (LLMs) are shifting from answer providers to intelligent tutors in educational settings, yet current supervised fine-tuning methods only learn surface teaching patterns without dynamic adaptation capabilities. Recent reinforcement learning approaches address this limitation but face two critical challenges. First, they evaluate teaching effectiveness solely based on whether students produce correct outputs, unable to distinguish whether students genuinely understand or echo teacher-provided answers during interaction. Second, they cannot perceive students' evolving cognitive states in real time through interactive dialogue, thus failing to adapt teaching strategies to match students' cognitive levels dynamically. We propose the Unidirectional Cognitive Optimization (UCO) method to address these challenges. UCO uses a multi-turn interactive reinforcement learning paradigm where the innovation lies in two synergistic reward functions: the Progress Reward captures students' cognitive advancement, evaluating whether students truly transition from confusion to comprehension, while the Scaffold Reward dynamically identifies each student's Zone of Proximal Development (ZPD), encouraging teachers to maintain productive teaching within this zone. We evaluate UCO by comparing it against 11 baseline models on BigMath and MathTutorBench benchmarks. Experimental results demonstrate that our UCO model outperforms all models of equivalent scale and achieves performance comparable to advanced closed-source models. The code and data are available at https://github.com/Mind-Lab-ECNU/UCO.

</details>


### [2] [A Research on Business Process Optimisation Model Integrating AI and Big Data Analytics](https://arxiv.org/abs/2511.08934)
*Di Liao,Ruijia Liang,Ziyi Ye*

Main category: cs.AI

TL;DR: 构建了融合人工智能与大数据的业务流程优化模型，采用三层架构实现流程全生命周期智能管理，显著提升企业运营效率。


<details>
  <summary>Details</summary>
Motivation: 随着数字化转型深入，业务流程优化成为提升企业竞争力的关键，需要智能化的全生命周期管理解决方案。

Method: 采用包含数据处理、AI算法和业务逻辑的三层架构，结合分布式计算和深度学习技术，实现实时流程监控与优化。

Result: 实验验证显示：流程处理时间缩短42%，资源利用率提升28%，运营成本降低35%，高并发负载下保持99.9%可用性。

Conclusion: 研究成果对企业数字化转型具有重要理论与实践价值，为提升企业运营效率提供了新思路。

Abstract: With the deepening of digital transformation, business process optimisation has become the key to improve the competitiveness of enterprises. This study constructs a business process optimisation model integrating artificial intelligence and big data to achieve intelligent management of the whole life cycle of processes. The model adopts a three-layer architecture incorporating data processing, AI algorithms, and business logic to enable real-time process monitoring and optimization. Through distributed computing and deep learning techniques, the system can handle complex business scenarios while maintaining high performance and reliability. Experimental validation across multiple enterprise scenarios shows that the model shortens process processing time by 42%, improves resource utilisation by 28%, and reduces operating costs by 35%. The system maintained 99.9% availability under high concurrent loads. The research results have important theoretical and practical value for promoting the digital transformation of enterprises, and provide new ideas for improving the operational efficiency of enterprises.

</details>


### [3] [HyperD: Hybrid Periodicity Decoupling Framework for Traffic Forecasting](https://arxiv.org/abs/2511.09275)
*Minlan Shao,Zijian Zhang,Yili Wang,Yiwei Dai,Xu Shen,Xin Wang*

Main category: cs.AI

TL;DR: HyperD是一个用于交通预测的新框架，通过将交通数据解耦为周期性和残差分量来处理复杂的时空依赖性和多尺度模式。


<details>
  <summary>Details</summary>
Motivation: 交通预测面临复杂空间依赖性和多尺度周期性模式与不规则波动共存的挑战，需要更有效的建模方法。

Method: 提出HyperD框架，包含混合周期性表示模块处理周期性分量，频率感知残差表示模块处理非周期性波动，并使用双视图对齐损失确保语义分离。

Result: 在四个真实世界交通数据集上的实验表明，HyperD实现了最先进的预测精度，同时具有更好的抗干扰鲁棒性和计算效率。

Conclusion: HyperD通过解耦周期性模式和残差波动，有效解决了交通预测中的关键挑战，为智能交通系统提供了强大的预测工具。

Abstract: Accurate traffic forecasting plays a vital role in intelligent transportation systems, enabling applications such as congestion control, route planning, and urban mobility optimization.However, traffic forecasting remains challenging due to two key factors: (1) complex spatial dependencies arising from dynamic interactions between road segments and traffic sensors across the network, and (2) the coexistence of multi-scale periodic patterns (e.g., daily and weekly periodic patterns driven by human routines) with irregular fluctuations caused by unpredictable events (e.g., accidents, weather, or construction). To tackle these challenges, we propose HyperD (Hybrid Periodic Decoupling), a novel framework that decouples traffic data into periodic and residual components. The periodic component is handled by the Hybrid Periodic Representation Module, which extracts fine-grained daily and weekly patterns using learnable periodic embeddings and spatial-temporal attention. The residual component, which captures non-periodic, high-frequency fluctuations, is modeled by the Frequency-Aware Residual Representation Module, leveraging complex-valued MLP in frequency domain. To enforce semantic separation between the two components, we further introduce a Dual-View Alignment Loss, which aligns low-frequency information with the periodic branch and high-frequency information with the residual branch. Extensive experiments on four real-world traffic datasets demonstrate that HyperD achieves state-of-the-art prediction accuracy, while offering superior robustness under disturbances and improved computational efficiency compared to existing methods.

</details>


### [4] [From Model Training to Model Raising - A call to reform AI model training paradigms from post-hoc alignment to intrinsic, identity-based development](https://arxiv.org/abs/2511.09287)
*Roland Aydin,Christian Cyron,Steve Bachelor,Ashton Anderson,Robert West*

Main category: cs.AI

TL;DR: 提出从"模型训练"到"模型培养"的范式转变，将价值观对齐从模型开发之初就融入其中，通过重新设计训练语料库来实现早期价值承诺。


<details>
  <summary>Details</summary>
Motivation: 当前AI训练方法只在核心能力建立后才进行价值观对齐，导致模型容易被误导且缺乏深层价值体系。在LLM能力开始超越人类的情况下，需要从根本上改变训练范式。

Method: 重新设计训练语料库：采用第一人称视角重构训练数据、将信息重新情境化为生活经验、模拟社会互动、搭建训练数据排序的脚手架。

Result: 预期这种训练语料库的重新设计将导致从第一个训练标记开始就形成早期价值承诺，使知识、技能和价值观内在更难分离。

Conclusion: 在大型语言模型能力开始超越人类的生态系统中，这种从模型训练到模型培养的范式转变至关重要。

Abstract: Current AI training methods align models with human values only after their core capabilities have been established, resulting in models that are easily misaligned and lack deep-rooted value systems. We propose a paradigm shift from "model training" to "model raising", in which alignment is woven into a model's development from the start. We identify several key components for this paradigm, all centered around redesigning the training corpus: reframing training data from a first-person perspective, recontextualizing information as lived experience, simulating social interactions, and scaffolding the ordering of training data. We expect that this redesign of the training corpus will lead to an early commitment to values from the first training token onward, such that knowledge, skills, and values are intrinsically much harder to separate. In an ecosystem in which large language model capabilities start overtaking human capabilities in many tasks, this seems to us like a critical need.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [Accelerating Training Speed of Tiny Recursive Models via Curriculum Guided Adaptive Recursion](https://arxiv.org/abs/2511.08653)
*Kaleem Ullah Qasim,Jiashu Zhang*

Main category: cs.LG

TL;DR: CGAR是一种新的递归推理模型训练方法，通过渐进深度课程学习和分层监督加权，显著降低了训练计算成本（42%成本减少），同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 递归推理模型虽然性能优异，但训练计算成本高昂（约36 GPU小时/数据集），限制了广泛应用和研究。

Method: 提出CGAR方法：1）渐进深度课程学习 - 动态调整递归深度从浅到深；2）分层监督加权 - 对监督步骤应用指数衰减重要性权重。

Result: 在Sudoku-Extreme数据集上，CGAR实现1.71倍训练加速（10.93到6.38小时），精度仅下降0.63%（86.65%到86.02%）。推理效率提升，100%停止精度和11%更少推理步骤。

Conclusion: 基于架构深度的原则性课程学习能够有效训练递归推理模型，在有限硬件上实现效率和质量的双重提升。

Abstract: Recursive reasoning models achieve remarkable performance on complex reasoning tasks through iterative refinement, enabling tiny networks to match large language models thousands of times their size. However, training remains computationally expensive, prior work reporting approximately 36 GPU-hours per dataset, limiting broader adoption and research. We propose CGAR, a novel training methodology that applies curriculum learning to architectural depth rather than traditional data ordering. CGAR introduces two synergistic components: Progressive Depth Curriculum dynamically adjusts recursion depth from shallow to deep configurations during training, preventing early overfitting while reducing computational cost, and Hierarchical Supervision Weighting applies exponentially decaying importance to supervision steps, aligning loss weighting with observed gradient magnitude decay. On Sudoku-Extreme with 423,168 test puzzles, CGAR achieves 1.71x training speedup (10.93 to 6.38 hours, 42% cost reduction) with only 0.63% accuracy drop (86.65% to 86.02%). Systematic ablations reveal Progressive Depth Curriculum alone achieves 2.26x speedup with 85.47% accuracy, demonstrating a rare Pareto improvement where architectural curriculum simultaneously enhances training efficiency and solution quality. CGAR-trained models exhibit superior inference efficiency with 100% halting accuracy and 11% fewer reasoning steps. Our work demonstrates that principled curriculum on architectural depth enables efficient training of recursive reasoning models on modest hardware. Code and models: https://github.com/Kaleemullahqasim/CGAR and https://huggingface.co/Kaleemullah/trm-cgar-sudoku

</details>


### [6] [ForeSWE: Forecasting Snow-Water Equivalent with an Uncertainty-Aware Attention Model](https://arxiv.org/abs/2511.08856)
*Krishu K Thapa,Supriya Savalkar,Bhupinderjeet Singh,Trong Nghia Hoang,Kirti Rajagopalan,Ananth Kalyanaraman*

Main category: cs.LG

TL;DR: ForeSWE是一个新的概率时空预测模型，结合深度学习和经典概率技术，用于预测雪水当量(SWE)，在准确性和不确定性量化方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统SWE预测方法未能充分利用时空相关性，也不提供不确定性估计，而这对水资源管理决策者具有重要价值。

Method: 结合注意力机制整合时空特征和交互，以及高斯过程模块提供预测不确定性的原则性量化。

Result: 在西部美国512个SNOTEL站点数据上的评估显示，在预测准确性和预测区间方面相比现有方法有显著改进。

Conclusion: 该模型为水资源管理社区提供了一个部署和反馈的平台，突出了不同方法在不确定性估计方面的有效性。

Abstract: Various complex water management decisions are made in snow-dominant watersheds with the knowledge of Snow-Water Equivalent (SWE) -- a key measure widely used to estimate the water content of a snowpack. However, forecasting SWE is challenging because SWE is influenced by various factors including topography and an array of environmental conditions, and has therefore been observed to be spatio-temporally variable. Classical approaches to SWE forecasting have not adequately utilized these spatial/temporal correlations, nor do they provide uncertainty estimates -- which can be of significant value to the decision maker. In this paper, we present ForeSWE, a new probabilistic spatio-temporal forecasting model that integrates deep learning and classical probabilistic techniques. The resulting model features a combination of an attention mechanism to integrate spatiotemporal features and interactions, alongside a Gaussian process module that provides principled quantification of prediction uncertainty. We evaluate the model on data from 512 Snow Telemetry (SNOTEL) stations in the Western US. The results show significant improvements in both forecasting accuracy and prediction interval compared to existing approaches. The results also serve to highlight the efficacy in uncertainty estimates between different approaches. Collectively, these findings have provided a platform for deployment and feedback by the water management community.

</details>


### [7] [Gromov-Wasserstein Graph Coarsening](https://arxiv.org/abs/2511.08733)
*Carlos A. Taveras,Santiago Segarra,César A. Uribe*

Main category: cs.LG

TL;DR: 该论文提出了两种基于Gromov-Wasserstein几何的图粗化算法：GPC和KGPC，通过最小化节点合并引起的失真来优化图结构，并在大规模数据集上验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 研究图粗化问题在Gromov-Wasserstein几何框架下的解决方案，旨在开发能够有效减少图规模同时保持结构特征的方法。

Method: 提出了两种算法：GPC（贪婪对粗化）迭代合并最小化局部失真的节点对；KGPC（k均值贪婪对粗化）基于成对失真度量的聚类直接合并节点簇。

Result: 在六个大规模数据集和下游聚类任务上的验证表明，所提方法在广泛参数和场景下优于现有方法。

Conclusion: 基于Gromov-Wasserstein几何的图粗化方法能够有效保持图结构特征，在多种应用场景中表现出优越性能。

Abstract: We study the problem of graph coarsening within the Gromov-Wasserstein geometry. Specifically, we propose two algorithms that leverage a novel representation of the distortion induced by merging pairs of nodes. The first method, termed Greedy Pair Coarsening (GPC), iteratively merges pairs of nodes that locally minimize a measure of distortion until the desired size is achieved. The second method, termed $k$-means Greedy Pair Coarsening (KGPC), leverages clustering based on pairwise distortion metrics to directly merge clusters of nodes. We provide conditions guaranteeing optimal coarsening for our methods and validate their performance on six large-scale datasets and a downstream clustering task. Results show that the proposed methods outperform existing approaches on a wide range of parameters and scenarios.

</details>


### [8] [A metrological framework for uncertainty evaluation in machine learning classification models](https://arxiv.org/abs/2504.03359)
*Samuel Bilson,Maurice Cox,Anna Pustogvar,Andrew Thompson*

Main category: cs.LG

TL;DR: 本文提出了一个用于名义属性的计量学概念不确定性评估框架，基于概率质量函数及其汇总统计量，适用于机器学习分类模型的不确定性评估。


<details>
  <summary>Details</summary>
Motivation: 机器学习分类模型在气候观测、医疗诊断等关键应用中需要提供不确定性信息，但现有国际计量学词汇和测量不确定度表达指南未定义名义属性的不确定性评估概念。

Method: 基于概率质量函数及其汇总统计量构建计量学概念不确定性评估框架，并在气候与地球观测、医疗诊断两个应用场景中进行验证。

Result: 提出的框架能够为名义属性提供不确定性评估，使测量不确定度表达指南可扩展到机器学习分类模型。

Conclusion: 该框架填补了名义属性不确定性评估的空白，为机器学习分类模型在关键应用中的可靠使用提供了计量学基础。

Abstract: Machine learning (ML) classification models are increasingly being used in a wide range of applications where it is important that predictions are accompanied by uncertainties, including in climate and earth observation, medical diagnosis and bioaerosol monitoring. The output of an ML classification model is a type of categorical variable known as a nominal property in the International Vocabulary of Metrology (VIM). However, concepts related to uncertainty evaluation for nominal properties are not defined in the VIM, nor is such evaluation addressed by the Guide to the Expression of Uncertainty in Measurement (GUM). In this paper we propose a metrological conceptual uncertainty evaluation framework for nominal properties. This framework is based on probability mass functions and summary statistics thereof, and it is applicable to ML classification. We also illustrate its use in the context of two applications that exemplify the issues and have significant societal impact, namely, climate and earth observation and medical diagnosis. Our framework would enable an extension of the GUM to uncertainty for nominal properties, which would make both applicable to ML classification models.

</details>


### [9] [Physics-Informed Machine Learning for Characterizing System Stability](https://arxiv.org/abs/2511.08831)
*Tomoki Koike,Elizabeth Qian*

Main category: cs.LG

TL;DR: 提出了一种基于物理信息机器学习的Lyapunov函数推断方法（LyapInf），通过系统轨迹数据推断Lyapunov函数来估计稳定性区域，无需系统控制方程的显式知识。


<details>
  <summary>Details</summary>
Motivation: 在复杂动力系统设计中，确保状态轨迹收敛到期望平衡点至关重要，但稳定性区域往往难以计算。现有方法需要系统控制方程的显式知识，限制了实际应用。

Method: 提出LyapInf方法，假设Lyapunov函数为二次型，通过最小化Zubov方程的平均残差来拟合未知的二次算子，从而从轨迹数据中推断Lyapunov函数。

Result: 数值实验表明，该方法成功推断出接近最大椭球形的稳定性区域估计，无需系统控制方程知识。

Conclusion: LyapInf方法提供了一种基于数据驱动的稳定性分析框架，能够有效估计动力系统的稳定性区域，适用于黑盒系统分析。

Abstract: In the design and operation of complex dynamical systems, it is essential to ensure that all state trajectories of the dynamical system converge to a desired equilibrium within a guaranteed stability region. Yet, for many practical systems -- especially in aerospace -- this region cannot be determined a priori and is often challenging to compute. One of the most common methods for computing the stability region is to identify a Lyapunov function. A Lyapunov function is a positive function whose time derivative along system trajectories is non-positive, which provides a sufficient condition for stability and characterizes an estimated stability region. However, existing methods of characterizing a stability region via a Lyapunov function often rely on explicit knowledge of the system governing equations. In this work, we present a new physics-informed machine learning method of characterizing an estimated stability region by inferring a Lyapunov function from system trajectory data that treats the dynamical system as a black box and does not require explicit knowledge of the system governing equations. In our presented Lyapunov function Inference method (LyapInf), we propose a quadratic form for the unknown Lyapunov function and fit the unknown quadratic operator to system trajectory data by minimizing the average residual of the Zubov equation, a first-order partial differential equation whose solution yields a Lyapunov function. The inferred quadratic Lyapunov function can then characterize an ellipsoidal estimate of the stability region. Numerical results on benchmark examples demonstrate that our physics-informed stability analysis method successfully characterizes a near-maximal ellipsoid of the system stability region associated with the inferred Lyapunov function without requiring knowledge of the system governing equations.

</details>


### [10] [TIGER-MARL: Enhancing Multi-Agent Reinforcement Learning with Temporal Information through Graph-based Embeddings and Representations](https://arxiv.org/abs/2511.08832)
*Nikunj Gupta,Ludwika Twardecka,James Zachary Hare,Jesse Milzman,Rajgopal Kannan,Viktor Prasanna*

Main category: cs.LG

TL;DR: TIGER通过图嵌入和表示捕获时间信息来增强多智能体强化学习，显式建模智能体间协调结构随时间演化的过程。


<details>
  <summary>Details</summary>
Motivation: 大多数MARL方法依赖静态或每步关系图，忽略了智能体在适应、移动或重组合作策略时自然产生的时间交互演化。捕获这种演化依赖关系对于实现稳健和自适应协调至关重要。

Method: TIGER构建MARL智能体的动态时间图，连接当前和历史交互，使用时序注意力编码器聚合结构和时间邻域信息，生成时间感知的智能体嵌入来指导合作策略学习。

Result: 在两个协调密集型基准测试中，TIGER在任务性能和样本效率方面持续优于各种基于价值分解和图基础的MARL基线方法。

Conclusion: 全面的消融研究揭示了结构和时间因素如何共同塑造MARL中的有效策略学习，证明了捕获时间演化协调结构的重要性。

Abstract: In this paper, we propose capturing and utilizing \textit{Temporal Information through Graph-based Embeddings and Representations} or \textbf{TIGER} to enhance multi-agent reinforcement learning (MARL). We explicitly model how inter-agent coordination structures evolve over time. While most MARL approaches rely on static or per-step relational graphs, they overlook the temporal evolution of interactions that naturally arise as agents adapt, move, or reorganize cooperation strategies. Capturing such evolving dependencies is key to achieving robust and adaptive coordination. To this end, TIGER constructs dynamic temporal graphs of MARL agents, connecting their current and historical interactions. It then employs a temporal attention-based encoder to aggregate information across these structural and temporal neighborhoods, yielding time-aware agent embeddings that guide cooperative policy learning. Through extensive experiments on two coordination-intensive benchmarks, we show that TIGER consistently outperforms diverse value-decomposition and graph-based MARL baselines in task performance and sample efficiency. Furthermore, we conduct comprehensive ablation studies to isolate the impact of key design parameters in TIGER, revealing how structural and temporal factors can jointly shape effective policy learning in MARL. All codes can be found here: https://github.com/Nikunj-Gupta/tiger-marl.

</details>


### [11] [Enhancing DPSGD via Per-Sample Momentum and Low-Pass Filtering](https://arxiv.org/abs/2511.08841)
*Xincheng Xu,Thilina Ranbaduge,Qing Wang,Thierry Rakotoarivelo,David Smith*

Main category: cs.LG

TL;DR: 本文提出DP-PMLF方法，通过结合逐样本动量和低通滤波策略，同时减轻差分隐私随机梯度下降中的噪声和裁剪偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有的差分隐私随机梯度下降方法通常只解决噪声或裁剪偏差中的一个问题，减少DP噪声会加剧裁剪偏差，反之亦然。需要一种能同时缓解这两个问题的方法。

Method: DP-PMLF使用逐样本动量在裁剪前平滑梯度估计以减少采样方差，并采用后处理低通滤波器来衰减高频DP噪声，且不消耗额外隐私预算。

Result: 理论分析显示在严格DP保证下具有改进的收敛速率，实证评估表明DP-PMLF相比现有DPSGD变体显著提升了隐私-效用权衡。

Conclusion: DP-PMLF通过创新性地结合逐样本动量和低通滤波，有效同时缓解了DP噪声和裁剪偏差问题，在保持隐私保护的同时提升了模型性能。

Abstract: Differentially Private Stochastic Gradient Descent (DPSGD) is widely used to train deep neural networks with formal privacy guarantees. However, the addition of differential privacy (DP) often degrades model accuracy by introducing both noise and bias. Existing techniques typically address only one of these issues, as reducing DP noise can exacerbate clipping bias and vice-versa. In this paper, we propose a novel method, \emph{DP-PMLF}, which integrates per-sample momentum with a low-pass filtering strategy to simultaneously mitigate DP noise and clipping bias. Our approach uses per-sample momentum to smooth gradient estimates prior to clipping, thereby reducing sampling variance. It further employs a post-processing low-pass filter to attenuate high-frequency DP noise without consuming additional privacy budget. We provide a theoretical analysis demonstrating an improved convergence rate under rigorous DP guarantees, and our empirical evaluations reveal that DP-PMLF significantly enhances the privacy-utility trade-off compared to several state-of-the-art DPSGD variants.

</details>


### [12] [Decomposition of Small Transformer Models](https://arxiv.org/abs/2511.08854)
*Casper L. Christensen,Logan Riggs*

Main category: cs.LG

TL;DR: 本文扩展了随机参数分解（SPD）方法到Transformer模型，提出了适用于序列数据的因果重要性函数和新损失函数。在玩具模型和GPT-2-small上成功验证了该方法能分解出可解释的概念组件。


<details>
  <summary>Details</summary>
Motivation: 现有机制可解释性方法主要应用于玩具模型，尚未成功扩展到真实模型。本文旨在弥合这一差距，将SPD方法扩展到现代Transformer模型。

Method: 扩展随机参数分解（SPD）到Transformer模型，提出新的因果重要性函数（适用于序列数据）和新的损失函数。

Result: 成功分解了玩具归纳头模型并恢复了预期的2步电路；在GPT-2-small中成功定位了对应"高尔夫"、"篮球"等可解释概念的子组件。

Conclusion: 这是将SPD扩展到现代模型的第一步，表明该方法可用于揭示参数空间中的可解释机制。

Abstract: Recent work in mechanistic interpretability has shown that decomposing models in parameter space may yield clean handles for analysis and intervention. Previous methods have demonstrated successful applications on a wide range of toy models, but the gap to "real models" has not yet been bridged. In this work, we extend Stochastic Parameter Decomposition (SPD) to Transformer models, proposing an updated causal importance function suited for sequential data and a new loss function. We demonstrate that SPD can successfully decompose a toy induction-head model and recover the expected 2-step circuit. We also show that applying SPD to GPT-2-small can successfully locate subcomponents corresponding to interpretable concepts like "golf" and "basketball". These results take the first step in the direction of extending SPD to modern models, and show that we can use the method to surface interpretable parameter-space mechanisms.

</details>


### [13] [Transformer-Based Sleep Stage Classification Enhanced by Clinical Information](https://arxiv.org/abs/2511.08864)
*Woosuk Chung,Seokwoo Hong,Wonhyeok Lee,Sangyoon Bae*

Main category: cs.LG

TL;DR: 提出了一种结合Transformer编码器和1D CNN聚合器的两阶段架构，通过融合临床元数据和专家事件标注等上下文信息，显著提升了睡眠分期准确性。


<details>
  <summary>Details</summary>
Motivation: 传统人工睡眠分期劳动密集且存在评分者间差异，现有深度学习模型大多仅依赖原始PSG信号，忽略了人类专家使用的上下文线索。

Method: 使用两阶段架构：Transformer-based每时段编码器 + 1D CNN聚合器，系统性地整合了受试者临床元数据（年龄、性别、BMI）和每时段专家事件标注（呼吸暂停、血氧饱和度下降、觉醒、周期性呼吸）。

Result: 在SHHS队列（n=8,357）上，上下文融合显著提升分期准确性：相比仅使用PSG的基线（macro-F1 0.7745, micro-F1 0.8774），最终模型达到macro-F1 0.8031和micro-F1 0.9051，其中事件标注贡献最大增益。特征融合优于多任务替代方案。

Conclusion: 将临床有意义特征与学习表示相结合，可在不修改PSG配置或增加额外传感器的情况下，同时提升性能和可解释性，为构建上下文感知、专家对齐的睡眠分期系统提供了实用且可扩展的路径。

Abstract: Manual sleep staging from polysomnography (PSG) is labor-intensive and prone to inter-scorer variability. While recent deep learning models have advanced automated staging, most rely solely on raw PSG signals and neglect contextual cues used by human experts. We propose a two-stage architecture that combines a Transformer-based per-epoch encoder with a 1D CNN aggregator, and systematically investigates the effect of incorporating explicit context: subject-level clinical metadata (age, sex, BMI) and per-epoch expert event annotations (apneas, desaturations, arousals, periodic breathing). Using the Sleep Heart Health Study (SHHS) cohort (n=8,357), we demonstrate that contextual fusion substantially improves staging accuracy. Compared to a PSG-only baseline (macro-F1 0.7745, micro-F1 0.8774), our final model achieves macro-F1 0.8031 and micro-F1 0.9051, with event annotations contributing the largest gains. Notably, feature fusion outperforms multi-task alternatives that predict the same auxiliary labels. These results highlight that augmenting learned representations with clinically meaningful features enhances both performance and interpretability, without modifying the PSG montage or requiring additional sensors. Our findings support a practical and scalable path toward context-aware, expert-aligned sleep staging systems.

</details>


### [14] [Spectral Predictability as a Fast Reliability Indicator for Time Series Forecasting Model Selection](https://arxiv.org/abs/2511.08884)
*Oliver Wang,Pengrui Quan,Kang Yang,Mani Srivastava*

Main category: cs.LG

TL;DR: 本文提出了一种基于频谱可预测性指标Ω的快速模型选择方法，该指标能在几秒内评估数据集是否适合使用大型时间序列基础模型，从而显著降低模型验证成本。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测模型部署面临两难：全面验证数十个模型计算成本过高，但选择错误模型会导致性能不佳。需要一种快速有效的模型选择方法。

Method: 使用频谱可预测性指标Ω来系统性地分层模型家族性能。在四个不同领域进行受控实验，并在GIFT-Eval基准的51个模型和28个数据集上扩展分析。

Result: 研究发现当Ω较高时，大型时间序列基础模型(TSFMs)系统性地优于轻量级任务训练基线，但随着Ω下降，其优势消失。计算Ω仅需每数据集几秒钟。

Conclusion: Ω指标能够可预测地分层模型性能，提供了一个实用的初步筛选工具，既能降低验证成本，又凸显了需要在真正困难(低Ω)问题上表现出色的模型需求。

Abstract: Practitioners deploying time series forecasting models face a dilemma: exhaustively validating dozens of models is computationally prohibitive, yet choosing the wrong model risks poor performance. We show that spectral predictability~$Ω$ -- a simple signal processing metric -- systematically stratifies model family performance, enabling fast model selection. We conduct controlled experiments in four different domains, then further expand our analysis to 51 models and 28 datasets from the GIFT-Eval benchmark. We find that large time series foundation models (TSFMs) systematically outperform lightweight task-trained baselines when $Ω$ is high, while their advantage vanishes as $Ω$ drops. Computing $Ω$ takes seconds per dataset, enabling practitioners to quickly assess whether their data suits TSFM approaches or whether simpler, cheaper models suffice. We demonstrate that $Ω$ stratifies model performance predictably, offering a practical first-pass filter that reduces validation costs while highlighting the need for models that excel on genuinely difficult (low-$Ω$) problems rather than merely optimizing easy ones.

</details>


### [15] [FAST-CAD: A Fairness-Aware Framework for Non-Contact Stroke Diagnosis](https://arxiv.org/abs/2511.08887)
*Tianming Sha,Zechuan Chen,Zhan Cheng,Haotian Zhai,Xuwei Ding,Junnan Li,Haixiang Tang,Zaoting Sun,Yanchuan Tang,Yongzhe Yi,Yanjie Huang,Anhao Li,Yuan Gao,Keze Wang*

Main category: cs.LG

TL;DR: FAST-CAD是一个结合领域对抗训练和组分布鲁棒优化的公平卒中诊断框架，通过理论保证和公平性边界实现跨人口统计学群体的准确诊断。


<details>
  <summary>Details</summary>
Motivation: 现有自动化卒中诊断方法存在跨人口统计学群体的公平性问题，可能加剧医疗不平等，需要开发公平且准确的诊断方法。

Method: 结合领域对抗训练(DAT)和组分布鲁棒优化(Group-DRO)，使用自监督编码器和对抗领域判别学习人口统计学不变表示，同时优化最差组风险。

Result: 在涵盖12个人口统计学子组的多模态数据集上，该方法实现了优越的诊断性能，同时保持了跨人口统计学群体的公平性。

Conclusion: FAST-CAD为公平医疗AI系统提供了实践进展和理论见解，证明了DAT + Group-DRO统一框架的有效性。

Abstract: Stroke is an acute cerebrovascular disease, and timely diagnosis significantly improves patient survival. However, existing automated diagnosis methods suffer from fairness issues across demographic groups, potentially exacerbating healthcare disparities. In this work we propose FAST-CAD, a theoretically grounded framework that combines domain-adversarial training (DAT) with group distributionally robust optimization (Group-DRO) for fair and accurate non-contact stroke diagnosis. Our approach is built on domain adaptation and minimax fairness theory and provides convergence guarantees and fairness bounds. We curate a multimodal dataset covering 12 demographic subgroups defined by age, gender, and posture. FAST-CAD employs self-supervised encoders with adversarial domain discrimination to learn demographic-invariant representations, while Group-DRO optimizes worst-group risk to ensure robust performance across all subgroups. Extensive experiments show that our method achieves superior diagnostic performance while maintaining fairness across demographic groups, and our theoretical analysis supports the effectiveness of the unified DAT + Group-DRO framework. This work provides both practical advances and theoretical insights for fair medical AI systems.

</details>


### [16] [Bayesian Mixture of Experts For Large Language Models](https://arxiv.org/abs/2511.08968)
*Maryam Dialameh,Hossein Rajabzadeh,Weiwei Zhang,Walid Ahmed,Hyock Ju Kwon*

Main category: cs.LG

TL;DR: Bayesian-MoE是一种用于微调后大语言模型的后验不确定性估计框架，基于混合专家架构，通过结构化拉普拉斯近似实现校准的不确定性估计，无需修改原始训练过程或引入新参数。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将贝叶斯推理应用于添加的适配器模块，而Bayesian-MoE直接针对MoE模型中已有的专家路径，利用其模块化设计进行可处理的块级后验估计。

Method: 对每个专家的第二个线性层应用结构化拉普拉斯近似，使用Kronecker分解的低秩近似来建模曲率，并推导可扩展的预测不确定性和边缘似然估计。

Result: 在常识推理基准测试中，使用Qwen1.5-MoE和DeepSeek-MoE的实验表明，Bayesian-MoE在预期校准误差(ECE)和负对数似然(NLL)方面均优于基线方法。

Conclusion: Bayesian-MoE框架有效提升了可靠下游决策的能力，证实了其在不确定性估计方面的有效性。

Abstract: We present Bayesian Mixture of Experts (Bayesian-MoE), a post-hoc uncertainty estimation framework for fine-tuned large language models (LLMs) based on Mixture-of-Experts architectures. Our method applies a structured Laplace approximation to the second linear layer of each expert, enabling calibrated uncertainty estimation without modifying the original training procedure or introducing new parameters. Unlike prior approaches, which apply Bayesian inference to added adapter modules, Bayesian-MoE directly targets the expert pathways already present in MoE models, leveraging their modular design for tractable block-wise posterior estimation. We use Kronecker-factored low-rank approximations to model curvature and derive scalable estimates of predictive uncertainty and marginal likelihood. Experiments on common-sense reasoning benchmarks with Qwen1.5-MoE and DeepSeek-MoE demonstrate that Bayesian-MoE improves both expected calibration error (ECE) and negative log-likelihood (NLL) over baselines, confirming its effectiveness for reliable downstream decision-making.

</details>


### [17] [Fairness-Aware Few-Shot Learning for Audio-Visual Stress Detection](https://arxiv.org/abs/2511.09039)
*Anushka Sanjay Shelke,Aditya Sneh,Arya Adyasha,Haroon R. Lone*

Main category: cs.LG

TL;DR: FairM2S是一个公平感知的元学习框架，用于基于音视频数据的压力检测，通过集成Equalized Odds约束、对抗梯度掩码和公平约束元更新来缓解性别偏见，在低资源场景下实现公平且准确的检测。


<details>
  <summary>Details</summary>
Motivation: 现有AI驱动的压力检测模型在数据稀缺场景下经常表现出性别偏见，这对公平的心理健康护理至关重要，需要开发能够有效缓解偏见的解决方案。

Method: 提出FairM2S框架，在元训练和适应阶段集成Equalized Odds约束，采用对抗梯度掩码和公平约束元更新技术来减轻偏见。

Result: 与五个最先进基线相比，FairM2S达到78.1%的准确率，同时将Equal Opportunity降至0.06，显示出显著的公平性提升。

Conclusion: FairM2S为心理健康AI中公平且可扩展的少样本压力检测提供了最先进的方法，同时发布了带有性别标注的SAVSD数据集以支持公平性研究。

Abstract: Fairness in AI-driven stress detection is critical for equitable mental healthcare, yet existing models frequently exhibit gender bias, particularly in data-scarce scenarios. To address this, we propose FairM2S, a fairness-aware meta-learning framework for stress detection leveraging audio-visual data. FairM2S integrates Equalized Odds constraints during both meta-training and adaptation phases, employing adversarial gradient masking and fairness-constrained meta-updates to effectively mitigate bias. Evaluated against five state-of-the-art baselines, FairM2S achieves 78.1% accuracy while reducing the Equal Opportunity to 0.06, demonstrating substantial fairness gains. We also release SAVSD, a smartphone-captured dataset with gender annotations, designed to support fairness research in low-resource, real-world contexts. Together, these contributions position FairM2S as a state-of-the-art approach for equitable and scalable few-shot stress detection in mental health AI. We release our dataset and FairM2S publicly with this paper.

</details>


### [18] [Break the Tie: Learning Cluster-Customized Category Relationships for Categorical Data Clustering](https://arxiv.org/abs/2511.09049)
*Mingjie Zhao,Zhanpei Huang,Yang Lu,Mengke Li,Yiqun Zhang,Weifeng Su,Yiu-ming Cheung*

Main category: cs.LG

TL;DR: 该论文提出了一种为分类属性学习定制化距离度量的方法，打破了传统方法中类别间固定拓扑关系的限制，从而更灵活准确地揭示各种聚类分布。


<details>
  <summary>Details</summary>
Motivation: 分类属性在聚类分析中普遍存在，但缺乏明确的类别间关系定义，这阻碍了对紧凑分类数据聚类的探索。现有方法通常假设类别间存在固定拓扑关系，限制了其对不同聚类结构的适应性，导致聚类性能不佳。

Method: 打破属性类别的内在关系约束，学习适合灵活准确揭示各种聚类分布的定制化距离度量。学习到的类别关系被证明与欧几里得距离度量兼容，可无缝扩展到包含数值和分类属性的混合数据集。

Result: 在12个真实基准数据集上的比较实验和显著性测试表明，该方法具有优越的聚类准确性，平均排名为1.25，显著高于当前最佳方法的5.21排名。

Conclusion: 通过可学习的类别关系，聚类算法的拟合能力得到显著增强，能够更好地处理分类属性聚类问题，并在混合数据集上表现出色。

Abstract: Categorical attributes with qualitative values are ubiquitous in cluster analysis of real datasets. Unlike the Euclidean distance of numerical attributes, the categorical attributes lack well-defined relationships of their possible values (also called categories interchangeably), which hampers the exploration of compact categorical data clusters. Although most attempts are made for developing appropriate distance metrics, they typically assume a fixed topological relationship between categories when learning distance metrics, which limits their adaptability to varying cluster structures and often leads to suboptimal clustering performance. This paper, therefore, breaks the intrinsic relationship tie of attribute categories and learns customized distance metrics suitable for flexibly and accurately revealing various cluster distributions. As a result, the fitting ability of the clustering algorithm is significantly enhanced, benefiting from the learnable category relationships. Moreover, the learned category relationships are proved to be Euclidean distance metric-compatible, enabling a seamless extension to mixed datasets that include both numerical and categorical attributes. Comparative experiments on 12 real benchmark datasets with significance tests show the superior clustering accuracy of the proposed method with an average ranking of 1.25, which is significantly higher than the 5.21 ranking of the current best-performing method.

</details>


### [19] [Cost-Minimized Label-Flipping Poisoning Attack to LLM Alignment](https://arxiv.org/abs/2511.09105)
*Shigeki Kusaka,Keita Saito,Mikoto Kudo,Takumi Tanabe,Akifumi Wachi,Youhei Akimoto*

Main category: cs.LG

TL;DR: 本文研究了在RLHF/DPO对齐过程中通过翻转偏好标签进行数据投毒攻击的理论基础，提出了最小成本投毒攻击的凸优化问题，并推导了攻击成本的下界和上界。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在实际系统中的部署增加，理解其脆弱性变得至关重要。虽然RLHF/DPO对齐过程中的数据投毒攻击已有实证研究，但其理论基础仍不清楚。

Method: 将最小成本投毒攻击建模为带线性约束的凸优化问题，推导攻击成本的理论界限，并提出一种后处理方法减少标签翻转次数。

Result: 理论分析表明，任何现有的标签翻转攻击都可以通过提出的后处理方法减少所需标签翻转次数，同时保持预期的投毒效果。实证结果显示该方法能显著降低投毒成本。

Conclusion: 这些发现揭示了RLHF/DPO流程中的基本脆弱性，并提供了评估其对低成本投毒攻击鲁棒性的工具。

Abstract: Large language models (LLMs) are increasingly deployed in real-world systems, making it critical to understand their vulnerabilities. While data poisoning attacks during RLHF/DPO alignment have been studied empirically, their theoretical foundations remain unclear. We investigate the minimum-cost poisoning attack required to steer an LLM's policy toward an attacker's target by flipping preference labels during RLHF/DPO, without altering the compared outputs. We formulate this as a convex optimization problem with linear constraints, deriving lower and upper bounds on the minimum attack cost. As a byproduct of this theoretical analysis, we show that any existing label-flipping attack can be post-processed via our proposed method to reduce the number of label flips required while preserving the intended poisoning effect. Empirical results demonstrate that this cost-minimization post-processing can significantly reduce poisoning costs over baselines, particularly when the reward model's feature dimension is small relative to the dataset size. These findings highlight fundamental vulnerabilities in RLHF/DPO pipelines and provide tools to evaluate their robustness against low-cost poisoning attacks.

</details>


### [20] [GuardFed: A Trustworthy Federated Learning Framework Against Dual-Facet Attacks](https://arxiv.org/abs/2511.09294)
*Yanli Li,Yanan Zhou,Zhongliang Guo,Nan Yang,Yuning Zhang,Huaming Chen,Dong Yuan,Weiping Ding,Witold Pedrycz*

Main category: cs.LG

TL;DR: 本文提出了针对联邦学习的双重攻击(DFA)，同时破坏模型效用和公平性，并开发了GuardFed防御框架来有效应对这种威胁。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然能保护隐私，但仍易受对抗性攻击影响。现有研究主要关注攻击效用或公平性的单一目标，而同时破坏两者的攻击策略尚未充分探索。

Method: 提出了两种DFA变体：同步DFA和分割DFA，分别模拟不同的真实世界共谋场景。同时开发了GuardFed防御框架，使用公平感知参考模型和双视角信任评分机制。

Result: 实验表明现有鲁棒联邦学习防御方法无法有效抵抗DFA攻击，而GuardFed在多种非IID和对抗条件下能同时保持准确性和公平性，达到最先进性能。

Conclusion: DFA攻击揭示了联邦学习的新安全威胁，GuardFed提供了一种有效的防御解决方案，为构建更安全的联邦学习系统提供了重要参考。

Abstract: Federated learning (FL) enables privacy-preserving collaborative model training but remains vulnerable to adversarial behaviors that compromise model utility or fairness across sensitive groups. While extensive studies have examined attacks targeting either objective, strategies that simultaneously degrade both utility and fairness remain largely unexplored. To bridge this gap, we introduce the Dual-Facet Attack (DFA), a novel threat model that concurrently undermines predictive accuracy and group fairness. Two variants, Synchronous DFA (S-DFA) and Split DFA (Sp-DFA), are further proposed to capture distinct real-world collusion scenarios. Experimental results show that existing robust FL defenses, including hybrid aggregation schemes, fail to resist DFAs effectively. To counter these threats, we propose GuardFed, a self-adaptive defense framework that maintains a fairness-aware reference model using a small amount of clean server data augmented with synthetic samples. In each training round, GuardFed computes a dual-perspective trust score for every client by jointly evaluating its utility deviation and fairness degradation, thereby enabling selective aggregation of trustworthy updates. Extensive experiments on real-world datasets demonstrate that GuardFed consistently preserves both accuracy and fairness under diverse non-IID and adversarial conditions, achieving state-of-the-art performance compared with existing robust FL methods.

</details>


### [21] [Distribution-Based Feature Attribution for Explaining the Predictions of Any Classifier](https://arxiv.org/abs/2511.09332)
*Xinpeng Li,Kai Ming Ting*

Main category: cs.LG

TL;DR: 本文提出了一个形式化的特征归因问题定义，并开发了DFAX方法，这是首个直接基于数据分布来解释分类器预测的特征归因方法。


<details>
  <summary>Details</summary>
Motivation: 随着复杂黑盒AI模型的普及，需要能够解释其决策的技术。特征归因方法已成为提供事后解释的流行解决方案，但该领域历史上缺乏正式的问题定义。

Method: 提出了分布特征归因解释（DFAX），这是一种新颖的模型无关特征归因方法。DFAX是首个直接基于数据分布来解释分类器预测的特征归因方法。

Result: 通过广泛实验表明，DFAX比最先进的基线方法更有效和高效。

Conclusion: DFAX克服了现有方法的局限性，为特征归因提供了更可靠和有效的解决方案。

Abstract: The proliferation of complex, black-box AI models has intensified the need for techniques that can explain their decisions. Feature attribution methods have become a popular solution for providing post-hoc explanations, yet the field has historically lacked a formal problem definition. This paper addresses this gap by introducing a formal definition for the problem of feature attribution, which stipulates that explanations be supported by an underlying probability distribution represented by the given dataset. Our analysis reveals that many existing model-agnostic methods fail to meet this criterion, while even those that do often possess other limitations. To overcome these challenges, we propose Distributional Feature Attribution eXplanations (DFAX), a novel, model-agnostic method for feature attribution. DFAX is the first feature attribution method to explain classifier predictions directly based on the data distribution. We show through extensive experiments that DFAX is more effective and efficient than state-of-the-art baselines.

</details>


### [22] [Potent but Stealthy: Rethink Profile Pollution against Sequential Recommendation via Bi-level Constrained Reinforcement Paradigm](https://arxiv.org/abs/2511.09392)
*Jiajie Su,Zihan Nan,Yunshan Ma,Xiaobo Xia,Xiaohua Feng,Weiming Liu,Xiaolin Zheng,Chaochao Chen*

Main category: cs.LG

TL;DR: 本文提出了一种新的配置文件污染攻击方法CREAT，通过约束强化学习框架在保持隐蔽性的同时实现有效的目标误导预测。


<details>
  <summary>Details</summary>
Motivation: 现有的序列推荐系统对抗攻击主要依赖数据投毒，需要大规模用户访问或虚假配置文件，缺乏实用性。配置文件污染攻击虽然能通过污染部分用户交互来诱导目标误预测，但现有方法存在两个限制：过度依赖序列水平影响限制了细粒度的项目转换扰动，整体修改导致可检测的分布偏移。

Method: 提出CREAT方法，将双层优化框架与多奖励强化学习相结合，平衡对抗效果和隐蔽性。开发模式平衡奖励策略，整合模式反转奖励和分布一致性奖励；采用约束组相对强化学习范式，通过动态屏障约束和组共享经验回放实现逐步扰动。

Result: 大量实验证明了CREAT的有效性。

Conclusion: CREAT方法能够以最小的可检测性实现目标污染攻击，在对抗效果和隐蔽性之间取得良好平衡。

Abstract: Sequential Recommenders, which exploit dynamic user intents through interaction sequences, is vulnerable to adversarial attacks. While existing attacks primarily rely on data poisoning, they require large-scale user access or fake profiles thus lacking practicality. In this paper, we focus on the Profile Pollution Attack that subtly contaminates partial user interactions to induce targeted mispredictions. Previous PPA methods suffer from two limitations, i.e., i) over-reliance on sequence horizon impact restricts fine-grained perturbations on item transitions, and ii) holistic modifications cause detectable distribution shifts. To address these challenges, we propose a constrained reinforcement driven attack CREAT that synergizes a bi-level optimization framework with multi-reward reinforcement learning to balance adversarial efficacy and stealthiness. We first develop a Pattern Balanced Rewarding Policy, which integrates pattern inversion rewards to invert critical patterns and distribution consistency rewards to minimize detectable shifts via unbalanced co-optimal transport. Then we employ a Constrained Group Relative Reinforcement Learning paradigm, enabling step-wise perturbations through dynamic barrier constraints and group-shared experience replay, achieving targeted pollution with minimal detectability. Extensive experiments demonstrate the effectiveness of CREAT.

</details>


### [23] [Spatio-Temporal Graph Unlearning](https://arxiv.org/abs/2511.09404)
*Qiming Guo,Wenbo Sun,Wenlu Wang*

Main category: cs.LG

TL;DR: CallosumNet是一个受胼胝体启发的时空图遗忘框架，通过增强子图构建和全局神经节桥接技术，实现高效完整的节点级遗忘，仅产生1%-2%的相对MAE损失。


<details>
  <summary>Details</summary>
Motivation: 由于GDPR和CCPA等隐私法规要求完全遗忘未经授权的数据，而现有遗忘方法主要针对静态图和局部数据删除，无法高效擦除时空图中的单个节点，因此需要有效的时空图完全遗忘方法。

Method: 提出CallosumNet框架，包含两个新技术：(1)增强子图构建(ESC)，基于生物启发的虚拟神经节等因素自适应构建多个局部化子图；(2)全局神经节桥接(GGB)，从这些局部子图重建全局时空依赖关系，有效恢复完整图表示。

Result: 在四个不同的真实世界数据集上的实证结果显示，CallosumNet仅产生1%-2%的相对MAE损失即可实现完全遗忘，显著优于最先进的基线方法。消融研究验证了两种提出技术的有效性。

Conclusion: CallosumNet为时空图提供了一种有效的完全遗忘解决方案，能够满足严格的隐私法规要求，同时保持接近黄金模型的性能。

Abstract: Spatio-temporal graphs are widely used in modeling complex dynamic processes such as traffic forecasting, molecular dynamics, and healthcare monitoring. Recently, stringent privacy regulations such as GDPR and CCPA have introduced significant new challenges for existing spatio-temporal graph models, requiring complete unlearning of unauthorized data. Since each node in a spatio-temporal graph diffuses information globally across both spatial and temporal dimensions, existing unlearning methods primarily designed for static graphs and localized data removal cannot efficiently erase a single node without incurring costs nearly equivalent to full model retraining. Therefore, an effective approach for complete spatio-temporal graph unlearning is a pressing need. To address this, we propose CallosumNet, a divide-and-conquer spatio-temporal graph unlearning framework inspired by the corpus callosum structure that facilitates communication between the brain's two hemispheres. CallosumNet incorporates two novel techniques: (1) Enhanced Subgraph Construction (ESC), which adaptively constructs multiple localized subgraphs based on several factors, including biologically-inspired virtual ganglions; and (2) Global Ganglion Bridging (GGB), which reconstructs global spatio-temporal dependencies from these localized subgraphs, effectively restoring the full graph representation. Empirical results on four diverse real-world datasets show that CallosumNet achieves complete unlearning with only 1%-2% relative MAE loss compared to the gold model, significantly outperforming state-of-the-art baselines. Ablation studies verify the effectiveness of both proposed techniques.

</details>


### [24] [LLM-Guided Dynamic-UMAP for Personalized Federated Graph Learning](https://arxiv.org/abs/2511.09438)
*Sai Puppala,Ismail Hossain,Md Jahangir Alam,Tanzim Ahad,Sajedul Talukder*

Main category: cs.LG

TL;DR: 提出一种在个性化和隐私约束下使用大语言模型辅助图机器学习的方法，结合数据增强、提示调优和上下文学习，通过贝叶斯变分目标实现个性化联邦学习。


<details>
  <summary>Details</summary>
Motivation: 解决在个性化和隐私约束下图机器学习面临的稀疏图数据、低资源设置以及语言模型与图结构对齐的挑战。

Method: 使用数据增强处理稀疏图，通过提示和指令调优使基础模型适应图任务，利用上下文学习提供少样本图推理信号，构建动态UMAP流形，并采用贝叶斯变分目标进行个性化联邦学习。

Result: 方法支持节点分类和链接预测任务，通过跨模态正则化器对齐语言模型潜在表示与图结构，并提供了变分聚合过程的收敛性论证和差分隐私威胁模型。

Conclusion: 该方法在知识图谱补全、推荐式链接预测以及引文和产品图等应用中表现出色，为基准测试LLM辅助的图机器学习提供了评估考虑。

Abstract: We propose a method that uses large language models to assist graph machine learning under personalization and privacy constraints. The approach combines data augmentation for sparse graphs, prompt and instruction tuning to adapt foundation models to graph tasks, and in-context learning to supply few-shot graph reasoning signals. These signals parameterize a Dynamic UMAP manifold of client-specific graph embeddings inside a Bayesian variational objective for personalized federated learning. The method supports node classification and link prediction in low-resource settings and aligns language model latent representations with graph structure via a cross-modal regularizer. We outline a convergence argument for the variational aggregation procedure, describe a differential privacy threat model based on a moments accountant, and present applications to knowledge graph completion, recommendation-style link prediction, and citation and product graphs. We also discuss evaluation considerations for benchmarking LLM-assisted graph machine learning.

</details>


### [25] [How does the Performance of the Data-driven Traffic Flow Forecasting Models deteriorate with Increasing Forecasting Horizon? An Extensive Approach Considering Statistical, Machine Learning and Deep Learning Models](https://arxiv.org/abs/2511.09450)
*Amanta Sherfenaz,Nazmul Haque,Protiva Sadhukhan Prova,Md Asif Raihan,Md. Hadiuzzaman*

Main category: cs.LG

TL;DR: 本研究评估了统计、机器学习和深度学习模型在预测交通速度和流量方面的表现，使用加州Harbor Freeway的真实数据。结果显示ANFIS-GP在早期预测窗口表现最佳，而Bi-LSTM在中长期预测中更稳健。


<details>
  <summary>Details</summary>
Motivation: 随着快速城市化，交通拥堵加剧，智能交通系统(ITS)对于在现有基础设施内管理交通变得至关重要。交通预测是ITS的核心功能，能够实现主动措施如匝道计量、信号控制和动态路由。

Method: 使用来自加州Caltrans性能测量系统(PeMS)的真实数据，评估统计、机器学习和深度学习模型在20个预测窗口（最长1小时40分钟）内的性能，使用RMSE、MAE和R-Square指标。

Result: ANFIS-GP在早期窗口表现最佳（RMSE 0.038，MAE 0.0276，R-Square 0.9983），而Bi-LSTM在中长期预测中更稳健（RMSE 0.1863，MAE 0.0833，R-Square 0.987）。通过对数变换量化模型性能退化，Bi-LSTM具有最平坦的斜率（RMSE 0.0454，MAE 0.0545）。

Conclusion: 研究确定了混合模型作为有前景的未来研究方向，能够结合不同模型的优势来提升交通预测性能。

Abstract: With rapid urbanization in recent decades, traffic congestion has intensified due to increased movement of people and goods. As planning shifts from demand-based to supply-oriented strategies, Intelligent Transportation Systems (ITS) have become essential for managing traffic within existing infrastructure. A core ITS function is traffic forecasting, enabling proactive measures like ramp metering, signal control, and dynamic routing through platforms such as Google Maps. This study assesses the performance of statistical, machine learning (ML), and deep learning (DL) models in forecasting traffic speed and flow using real-world data from California's Harbor Freeway, sourced from the Caltrans Performance Measurement System (PeMS). Each model was evaluated over 20 forecasting windows (up to 1 hour 40 minutes) using RMSE, MAE, and R-Square metrics. Results show ANFIS-GP performs best at early windows with RMSE of 0.038, MAE of 0.0276, and R-Square of 0.9983, while Bi-LSTM is more robust for medium-term prediction due to its capacity to model long-range temporal dependencies, achieving RMSE of 0.1863, MAE of 0.0833, and R-Square of 0.987 at a forecasting of 20. The degradation in model performance was quantified using logarithmic transformation, with slope values used to measure robustness. Among DL models, Bi-LSTM had the flattest slope (0.0454 RMSE, 0.0545 MAE for flow), whereas ANFIS-GP had 0.1058 for RMSE and 0.1037 for flow MAE. The study concludes by identifying hybrid models as a promising future direction.

</details>


### [26] [AdaCuRL: Adaptive Curriculum Reinforcement Learning with Invalid Sample Mitigation and Historical Revisiting](https://arxiv.org/abs/2511.09478)
*Renda Li,Hailang Huang,Fei Wei,Feng Xiong,Yong Wang,Xiangxiang Chu*

Main category: cs.LG

TL;DR: AdaCuRL是一个自适应课程强化学习框架，通过粗粒度到细粒度的难度估计和自适应课程调度，解决强化学习中梯度饥饿和策略退化问题，在多种推理基准测试中显著提升LLMs和MLLMs的性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在混合难度样本上训练时存在梯度饥饿和策略退化问题，而传统方法要么依赖人工标注的思维链数据（成本高），要么面临课程学习中的难度不匹配、手动设计课程和灾难性遗忘等挑战。

Method: 提出AdaCuRL框架，整合粗粒度到细粒度的难度估计与自适应课程调度，动态对齐数据难度与模型能力，包含数据重访机制缓解灾难性遗忘，并采用自适应参考和稀疏KL策略防止策略退化。

Result: 在多种推理基准测试上的广泛实验表明，AdaCuRL在大型语言模型和多模态语言模型上均实现了显著的性能提升。

Conclusion: AdaCuRL通过自适应课程强化学习有效解决了现有方法的问题，为增强语言模型的推理能力提供了有效的解决方案。

Abstract: Reinforcement learning (RL) has demonstrated considerable potential for enhancing reasoning in large language models (LLMs). However, existing methods suffer from Gradient Starvation and Policy Degradation when training directly on samples with mixed difficulty. To mitigate this, prior approaches leverage Chain-of-Thought (CoT) data, but the construction of high-quality CoT annotations remains labor-intensive. Alternatively, curriculum learning strategies have been explored but frequently encounter challenges, such as difficulty mismatch, reliance on manual curriculum design, and catastrophic forgetting. To address these issues, we propose AdaCuRL, a Adaptive Curriculum Reinforcement Learning framework that integrates coarse-to-fine difficulty estimation with adaptive curriculum scheduling. This approach dynamically aligns data difficulty with model capability and incorporates a data revisitation mechanism to mitigate catastrophic forgetting. Furthermore, AdaCuRL employs adaptive reference and sparse KL strategies to prevent Policy Degradation. Extensive experiments across diverse reasoning benchmarks demonstrate that AdaCuRL consistently achieves significant performance improvements on both LLMs and MLLMs.

</details>


### [27] [FSampler: Training Free Acceleration of Diffusion Sampling via Epsilon Extrapolation](https://arxiv.org/abs/2511.09180)
*Michael A. Vladimir*

Main category: cs.LG

TL;DR: FSampler是一种无需训练、与采样器无关的执行层，通过减少函数评估次数来加速扩散采样。它通过历史去噪信号预测下一个epsilon，在特定步骤用预测值替代模型调用，同时保持采样器更新规则不变。


<details>
  <summary>Details</summary>
Motivation: 减少扩散模型采样过程中的函数评估次数，从而加速采样过程，同时保持高保真度。

Method: FSampler维护最近真实模型调用的去噪信号历史，使用二阶、三阶或四阶有限差分预测器外推下一个epsilon。在选定步骤用预测epsilon替代模型调用，包含学习稳定器、梯度估计稳定器、保护窗口、周期锚点和连续跳过上限等机制。

Result: 在FLUX.1 dev、Qwen Image和Wan 2.2等模型上，FSampler将时间减少8-22%，模型调用减少15-25%，同时保持高保真度（SSIM 0.95-0.99）。使用激进自适应门时，模型调用减少可达45-50%，但保真度较低（SSIM 0.73-0.74）。

Conclusion: FSampler提供了一种有效的扩散采样加速方法，与多种采样器兼容，在不改变采样器公式的情况下显著减少计算成本。

Abstract: FSampler is a training free, sampler agnostic execution layer that accelerates diffusion sampling by reducing the number of function evaluations (NFE). FSampler maintains a short history of denoising signals (epsilon) from recent real model calls and extrapolates the next epsilon using finite difference predictors at second order, third order, or fourth order, falling back to lower order when history is insufficient. On selected steps the predicted epsilon substitutes the model call while keeping each sampler's update rule unchanged. Predicted epsilons are validated for finiteness and magnitude; a learning stabilizer rescales predictions on skipped steps to correct drift, and an optional gradient estimation stabilizer compensates local curvature. Protected windows, periodic anchors, and a cap on consecutive skips bound deviation over the trajectory. Operating at the sampler level, FSampler integrates with Euler/DDIM, DPM++ 2M/2S, LMS/AB2, and RES family exponential multistep methods and drops into standard workflows. FLUX.1 dev, Qwen Image, and Wan 2.2, FSampler reduces time by 8 to 22% and model calls by 15 to 25% at high fidelity (Structural Similarity Index (SSIM) 0.95 to 0.99), without altering sampler formulas. With an aggressive adaptive gate, reductions can reach 45 to 50% fewer model calls at lower fidelity (SSIM 0.73 to 0.74).

</details>


### [28] [Parameter-Free Clustering via Self-Supervised Consensus Maximization (Extended Version)](https://arxiv.org/abs/2511.09211)
*Lijun Zhang,Suyuan Liu,Siwei Wang,Shengju Yu,Xueling Zhu,Miaomiao Li,Xinwang Liu*

Main category: cs.LG

TL;DR: 提出了一种名为SCMax的完全无参数聚类框架，通过自监督共识最大化来解决传统聚类方法依赖超参数的问题。


<details>
  <summary>Details</summary>
Motivation: 现有聚类方法严重依赖超参数（如聚类数量），限制了在现实场景中的应用，需要开发完全无参数的聚类解决方案。

Method: 采用分层凝聚聚类和聚类评估的集成过程，通过自监督学习创建结构感知数据表示，并引入最近邻共识评分来测量原始表示与自监督表示之间的一致性。

Result: 在多个数据集上的广泛实验表明，该框架在未知聚类数量场景下优于现有的聚类方法。

Conclusion: SCMax框架通过自监督共识最大化成功实现了完全无参数聚类，共识最大化时刻可作为确定最优聚类数量的标准。

Abstract: Clustering is a fundamental task in unsupervised learning, but most existing methods heavily rely on hyperparameters such as the number of clusters or other sensitive settings, limiting their applicability in real-world scenarios. To address this long-standing challenge, we propose a novel and fully parameter-free clustering framework via Self-supervised Consensus Maximization, named SCMax. Our framework performs hierarchical agglomerative clustering and cluster evaluation in a single, integrated process. At each step of agglomeration, it creates a new, structure-aware data representation through a self-supervised learning task guided by the current clustering structure. We then introduce a nearest neighbor consensus score, which measures the agreement between the nearest neighbor-based merge decisions suggested by the original representation and the self-supervised one. The moment at which consensus maximization occurs can serve as a criterion for determining the optimal number of clusters. Extensive experiments on multiple datasets demonstrate that the proposed framework outperforms existing clustering approaches designed for scenarios with an unknown number of clusters.

</details>


### [29] [Planning in Branch-and-Bound: Model-Based Reinforcement Learning for Exact Combinatorial Optimization](https://arxiv.org/abs/2511.09219)
*Paul Strang,Zacharie Alès,Côme Bissuel,Safia Kedad-Sidhoum,Emmanuel Rachelson*

Main category: cs.LG

TL;DR: 本文提出PlanB&B，一种基于模型强化学习的智能体，通过学习的B&B动态内部模型来发现改进的分支策略，在四个标准MILP基准测试中优于现有最先进RL方法。


<details>
  <summary>Details</summary>
Motivation: 传统MILP问题使用分支定界法，变量选择启发式算法影响求解效率。现有静态手工启发式方法有限，希望开发针对特定MILP分布的自适应分支策略。

Method: 结合强化学习和蒙特卡洛树搜索，引入PlanB&B模型强化学习智能体，利用学习的B&B动态内部模型来规划分支决策。

Result: 计算实验验证该方法在四个标准MILP基准测试中表现优于之前最先进的强化学习方法。

Conclusion: 基于模型强化学习能够有效学习分支定界动态，发现改进的分支策略，提升MILP问题求解效率。

Abstract: Mixed-Integer Linear Programming (MILP) lies at the core of many real-world combinatorial optimization (CO) problems, traditionally solved by branch-and-bound (B&B). A key driver influencing B&B solvers efficiency is the variable selection heuristic that guides branching decisions. Looking to move beyond static, hand-crafted heuristics, recent work has explored adapting traditional reinforcement learning (RL) algorithms to the B&B setting, aiming to learn branching strategies tailored to specific MILP distributions. In parallel, RL agents have achieved remarkable success in board games, a very specific type of combinatorial problems, by leveraging environment simulators to plan via Monte Carlo Tree Search (MCTS). Building on these developments, we introduce Plan-and-Branch-and-Bound (PlanB&B), a model-based reinforcement learning (MBRL) agent that leverages a learned internal model of the B&B dynamics to discover improved branching strategies. Computational experiments empirically validate our approach, with our MBRL branching agent outperforming previous state-of-the-art RL methods across four standard MILP benchmarks.

</details>


### [30] [MARBLE: Multi-Armed Restless Bandits in Latent Markovian Environment](https://arxiv.org/abs/2511.09324)
*Mohsen Amiri,Konstantin Avrachenkov,Ibtihal El Mimouni,Sindri Magnússon*

Main category: cs.LG

TL;DR: MARBLE模型扩展了传统RMAB，引入潜在马尔可夫状态来处理非平稳环境，提出了MAI准则和QWI算法，在数字孪生推荐系统中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 传统RMAB假设固定动态，但在非平稳环境中这一假设常被违反，需要开发能适应环境变化的模型。

Method: 引入MARBLE模型，包含潜在马尔可夫环境状态；提出MAI松弛可索引性准则；开发同步Q学习与Whittle索引(QWI)算法。

Result: 理论证明QWI在MAI准则下几乎必然收敛到最优Q函数和Whittle索引；在数字孪生推荐系统实验中，QWI能适应潜在状态变化并收敛到最优策略。

Conclusion: MARBLE框架成功处理了非平稳环境中的RMAB问题，QWI算法在理论和实验上都表现出良好的适应性和收敛性。

Abstract: Restless Multi-Armed Bandits (RMABs) are powerful models for decision-making under uncertainty, yet classical formulations typically assume fixed dynamics, an assumption often violated in nonstationary environments. We introduce MARBLE (Multi-Armed Restless Bandits in a Latent Markovian Environment), which augments RMABs with a latent Markov state that induces nonstationary behavior. In MARBLE, each arm evolves according to a latent environment state that switches over time, making policy learning substantially more challenging. We further introduce the Markov-Averaged Indexability (MAI) criterion as a relaxed indexability assumption and prove that, despite unobserved regime switches, under the MAI criterion, synchronous Q-learning with Whittle Indices (QWI) converges almost surely to the optimal Q-function and the corresponding Whittle indices. We validate MARBLE on a calibrated simulator-embedded (digital twin) recommender system, where QWI consistently adapts to a shifting latent state and converges to an optimal policy, empirically corroborating our theoretical findings.

</details>


### [31] [GAMMA_FLOW: Guided Analysis of Multi-label spectra by MAtrix Factorization for Lightweight Operational Workflows](https://arxiv.org/abs/2511.09326)
*Viola Rädle,Tilman Hartwig,Benjamin Oesen,Emily Alice Kröger,Julius Vogt,Eike Gericke,Martin Baron*

Main category: cs.LG

TL;DR: GAMMA_FLOW是一个开源Python包，用于光谱数据的实时分析，支持分类、去噪、分解和异常检测，采用监督式非负矩阵分解进行降维，实现高效、快速的光谱分析。


<details>
  <summary>Details</summary>
Motivation: 开发一个开源、灵活的光谱分析工具，替代商业软件，降低计算成本，提高分析效率，适用于研究和工业应用。

Method: 使用监督式非负矩阵分解（NMF）进行降维，避免使用计算密集型大模型，实现快速高效的光谱分析。

Result: 分类准确率超过90%，能够实现可靠的光谱自动解释，适用于各种一维光谱数据。

Conclusion: GAMMA_FLOW提供了一个高效、开源的光谱分析解决方案，在保持高准确率的同时显著降低了计算成本，具有广泛的应用前景。

Abstract: GAMMA_FLOW is an open-source Python package for real-time analysis of spectral data. It supports classification, denoising, decomposition, and outlier detection of both single- and multi-component spectra. Instead of relying on large, computationally intensive models, it employs a supervised approach to non-negative matrix factorization (NMF) for dimensionality reduction. This ensures a fast, efficient, and adaptable analysis while reducing computational costs. gamma_flow achieves classification accuracies above 90% and enables reliable automated spectral interpretation. Originally developed for gamma-ray spectra, it is applicable to any type of one-dimensional spectral data. As an open and flexible alternative to proprietary software, it supports various applications in research and industry.

</details>


### [32] [From Decision Trees to Boolean Logic: A Fast and Unified SHAP Algorithm](https://arxiv.org/abs/2511.09376)
*Alexander Nadel,Ron Wettenstein*

Main category: cs.LG

TL;DR: WOODELF是一种新的SHAP算法，通过将决策树、博弈论和布尔逻辑整合到统一框架中，能够在线性时间内计算背景SHAP值，并在CPU和GPU上实现显著加速。


<details>
  <summary>Details</summary>
Motivation: 现有的SHAP计算方法在处理大规模数据集时效率较低，需要开发更高效的算法来支持金融、广告、医疗等领域的实际应用需求。

Method: WOODELF为每个消费者构建伪布尔公式，捕捉特征值、决策树集成结构和整个背景数据集，然后利用这种表示在线性时间内计算背景SHAP值。

Result: 在包含300万行、500万背景样本和127个特征的数据集上，WOODELF在CPU上计算所有背景Shapley值仅需162秒，GPU上仅需16秒，相比现有最佳方法分别实现了16倍和165倍的加速。

Conclusion: WOODELF提供了一种高效、可扩展的SHAP计算方法，支持大规模游戏理论值的计算，并能在不同硬件平台上实现显著性能提升。

Abstract: SHapley Additive exPlanations (SHAP) is a key tool for interpreting decision tree ensembles by assigning contribution values to features. It is widely used in finance, advertising, medicine, and other domains. Two main approaches to SHAP calculation exist: Path-Dependent SHAP, which leverages the tree structure for efficiency, and Background SHAP, which uses a background dataset to estimate feature distributions.
  We introduce WOODELF, a SHAP algorithm that integrates decision trees, game theory, and Boolean logic into a unified framework. For each consumer, WOODELF constructs a pseudo-Boolean formula that captures their feature values, the structure of the decision tree ensemble, and the entire background dataset. It then leverages this representation to compute Background SHAP in linear time. WOODELF can also compute Path-Dependent SHAP, Shapley interaction values, Banzhaf values, and Banzhaf interaction values.
  WOODELF is designed to run efficiently on CPU and GPU hardware alike. Available via the WOODELF Python package, it is implemented using NumPy, SciPy, and CuPy without relying on custom C++ or CUDA code. This design enables fast performance and seamless integration into existing frameworks, supporting large-scale computation of SHAP and other game-theoretic values in practice.
  For example, on a dataset with 3,000,000 rows, 5,000,000 background samples, and 127 features, WOODELF computed all Background Shapley values in 162 seconds on CPU and 16 seconds on GPU - compared to 44 minutes required by the best method on any hardware platform, representing 16x and 165x speedups, respectively.

</details>


### [33] [Abstract Gradient Training: A Unified Certification Framework for Data Poisoning, Unlearning, and Differential Privacy](https://arxiv.org/abs/2511.09400)
*Philip Sosnin,Matthew Wicker,Josh Collyer,Calvin Tsay*

Main category: cs.LG

TL;DR: 本文提出了抽象梯度训练（AGT）框架，用于认证模型对训练数据扰动的鲁棒性，包括有界扰动、数据点移除和新样本添加。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注推理时数据扰动的认证，而对训练数据扰动的认证研究相对不足，这些扰动在对抗性数据投毒、机器遗忘和差分隐私等关键场景中具有重要意义。

Method: 通过边界可达参数集，即建立可证明的参数空间边界，AGT为分析通过一阶优化方法训练的模型行为提供了形式化方法。

Result: AGT提供了一个统一框架，能够认证给定模型和训练程序对训练数据扰动的鲁棒性。

Conclusion: 抽象梯度训练框架为训练数据扰动的鲁棒性认证提供了理论基础和实用工具。

Abstract: The impact of inference-time data perturbation (e.g., adversarial attacks) has been extensively studied in machine learning, leading to well-established certification techniques for adversarial robustness. In contrast, certifying models against training data perturbations remains a relatively under-explored area. These perturbations can arise in three critical contexts: adversarial data poisoning, where an adversary manipulates training samples to corrupt model performance; machine unlearning, which requires certifying model behavior under the removal of specific training data; and differential privacy, where guarantees must be given with respect to substituting individual data points. This work introduces Abstract Gradient Training (AGT), a unified framework for certifying robustness of a given model and training procedure to training data perturbations, including bounded perturbations, the removal of data points, and the addition of new samples. By bounding the reachable set of parameters, i.e., establishing provable parameter-space bounds, AGT provides a formal approach to analyzing the behavior of models trained via first-order optimization methods.

</details>


### [34] [Latent Planning via Embedding Arithmetic: A Contrastive Approach to Strategic Reasoning](https://arxiv.org/abs/2511.09477)
*Andrew Hamara,Greg Hamerly,Pablo Rivas,Andrew C. Freeman*

Main category: cs.LG

TL;DR: SOLIS通过监督对比学习构建评估对齐的嵌入空间，在该空间中结果相似性由距离表示，全局优势向量从输到赢区域定向空间。候选动作根据与该方向的对齐度进行排序，将规划简化为潜在空间中的向量操作。


<details>
  <summary>Details</summary>
Motivation: 研究是否可以直接在评估对齐的嵌入空间中进行规划，而不是训练策略或价值头，为高维决策空间规划提供轻量级替代方案。

Method: 使用监督对比学习构建评估对齐嵌入空间，其中结果相似性由邻近度捕获，单个全局优势向量从输到赢区域定向空间。候选动作根据与该方向的对齐度进行排序。

Result: 在象棋中，SOLIS仅使用浅层搜索和学习的嵌入指导就能在受限条件下达到竞争性强度。

Conclusion: 评估对齐的潜在规划为传统动态模型或策略学习提供了轻量级替代方案，展示了在嵌入空间中直接进行规划的有效性。

Abstract: Planning in high-dimensional decision spaces is increasingly being studied through the lens of learned representations. Rather than training policies or value heads, we investigate whether planning can be carried out directly in an evaluation-aligned embedding space. We introduce SOLIS, which learns such a space using supervised contrastive learning. In this representation, outcome similarity is captured by proximity, and a single global advantage vector orients the space from losing to winning regions. Candidate actions are then ranked according to their alignment with this direction, reducing planning to vector operations in latent space. We demonstrate this approach in chess, where SOLIS uses only a shallow search guided by the learned embedding to reach competitive strength under constrained conditions. More broadly, our results suggest that evaluation-aligned latent planning offers a lightweight alternative to traditional dynamics models or policy learning.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [35] [The Probably Approximately Correct Learning Model in Computational Learning Theory](https://arxiv.org/abs/2511.08791)
*Rocco A. Servedio*

Main category: stat.ML

TL;DR: 这篇综述论文概述了在Valiant的PAC学习模型及其常见变体中学习布尔函数类的各种已知结果。


<details>
  <summary>Details</summary>
Motivation: 旨在系统整理和总结在PAC学习框架下关于布尔函数类学习的已有研究成果，为研究者提供全面的理论参考。

Method: 采用文献综述方法，收集和分析在PAC学习模型及其变体下关于布尔函数类学习的理论结果和算法。

Result: 提供了对各类布尔函数在PAC学习模型中的可学习性、样本复杂度、计算复杂度等方面的系统总结。

Conclusion: 该综述为理解布尔函数在PAC学习理论中的基础性质和算法提供了全面的理论框架和结果汇总。

Abstract: This survey paper gives an overview of various known results on learning classes of Boolean functions in Valiant's Probably Approximately Correct (PAC) learning model and its commonly studied variants.

</details>


### [36] [Effects of label noise on the classification of outlier observations](https://arxiv.org/abs/2511.08808)
*Matheus Vinícius Barreto de Farias,Mario de Castro*

Main category: stat.ML

TL;DR: 本研究探讨了在分类任务中向训练集类别添加噪声对BCOPS算法性能的影响，发现即使少量噪声也会显著影响模型表现。


<details>
  <summary>Details</summary>
Motivation: 验证BCOPS算法在训练集类别存在噪声情况下的鲁棒性，这是之前未测试过的场景。

Method: 使用合成和真实数据集，通过向训练集类别添加噪声，评估异常观测的预测弃权率和模型鲁棒性。

Result: 结果表明，即使添加少量噪声也会对模型性能产生显著影响。

Conclusion: BCOPS算法对训练集类别噪声敏感，噪声添加会显著影响模型性能表现。

Abstract: This study investigates the impact of adding noise to the training set classes in classification tasks using the BCOPS algorithm (Balanced and Conformal Optimized Prediction Sets), proposed by Guan & Tibshirani (2022). The BCOPS algorithm is an application of conformal prediction combined with a machine learning method to construct prediction sets such that the probability of the true class being included in the prediction set for a test observation meets a specified coverage guarantee. An observation is considered an outlier if its true class is not present in the training set. The study employs both synthetic and real datasets and conducts experiments to evaluate the prediction abstention rate for outlier observations and the model's robustness in this previously untested scenario. The results indicate that the addition of noise, even in small amounts, can have a significant effect on model performance.

</details>


### [37] [Robust Sampling for Active Statistical Inference](https://arxiv.org/abs/2511.08991)
*Puheng Li,Tijana Zrnic,Emmanuel Candès*

Main category: stat.ML

TL;DR: 提出了一种用于AI辅助数据收集的稳健主动统计推断方法，通过最优插值均匀采样和主动采样来确保估计器性能不低于均匀采样，同时在不确定性估计可靠时优于标准主动推断。


<details>
  <summary>Details</summary>
Motivation: 传统主动统计推断方法依赖AI预测模型的不确定性估计来优先收集标签，但不准确的不确定性估计会导致结果高度噪声化，甚至比均匀采样更差。

Method: 使用稳健优化思想，根据不确定性评分质量在均匀采样和主动采样之间进行最优插值，确保估计器性能稳健。

Result: 在计算社会科学和调查研究的一系列真实数据集上验证了方法的有效性，稳健采样始终优于或等于均匀采样。

Conclusion: 提出的稳健采样策略为AI辅助数据收集提供了可靠的统计推断方法，在不确定性估计不可靠时保持稳健性，在可靠时提升性能。

Abstract: Active statistical inference is a new method for inference with AI-assisted data collection. Given a budget on the number of labeled data points that can be collected and assuming access to an AI predictive model, the basic idea is to improve estimation accuracy by prioritizing the collection of labels where the model is most uncertain. The drawback, however, is that inaccurate uncertainty estimates can make active sampling produce highly noisy results, potentially worse than those from naive uniform sampling. In this work, we present robust sampling strategies for active statistical inference. Robust sampling ensures that the resulting estimator is never worse than the estimator using uniform sampling. Furthermore, with reliable uncertainty estimates, the estimator usually outperforms standard active inference. This is achieved by optimally interpolating between uniform and active sampling, depending on the quality of the uncertainty scores, and by using ideas from robust optimization. We demonstrate the utility of the method on a series of real datasets from computational social science and survey research.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [38] [Scaling behavioral incentives for low-carbon mobility through digital platforms](https://arxiv.org/abs/2511.09237)
*Bing Liu,Yuan Liao,Sonia Yeh,Oded Cats,Kristian S. Nielsen,Zhenning Dong,Yong Wang,Yi Li,Yanli Liu,Zirui Ni,Xiaolei Ma*

Main category: stat.AP

TL;DR: 该研究评估了北京MaaS平台中的碳激励计划，通过390万参与者和48亿次多模式出行数据发现，该计划使公共交通和自行车出行每月增加20.3%，汽油车使用每日减少1.8%，年碳减排约9.4万吨。


<details>
  <summary>Details</summary>
Motivation: 实现全球碳减排目标需要大规模日常出行行为转变，但关于如何激励这种大规模行为改变的现实证据仍然稀缺。

Method: 使用北京MaaS平台中390万参与者和48亿次多模式出行数据，评估碳激励计划在395天内的效果。

Result: 碳激励计划使公共交通和自行车出行每月增加20.3%，汽油车使用每日减少1.8%，年碳减排约9.4万吨，相当于北京碳市场认证减排量的5.7%。虽然效果随时间减弱，但8个月后参与者每月仍多进行12.8%的绿色出行。

Conclusion: 这些结果提供了碳激励在MaaS中有效性的首个大规模实证证据，突显了其潜力，可为针对性的城市特定干预措施提供信息，支持全球低碳出行转型。

Abstract: Meeting global carbon reduction targets requires large-scale behavioral shifts in everyday travel. Yet, real-world evidence on how to motivate such large-scale behavioral change remains scarce. We evaluate a carbon incentive program embedded in a MaaS platform in Beijing, China, using data from 3.9 million participants and 4.8 billion multimodal trips over 395 days. The program increased reported public transport and bike travel by 20.3% per month and reduced gasoline car use by 1.8% per day, yielding an annual carbon reduction of ~94,000 tons, or 5.7% of certified reductions in Beijing's carbon market. Although effects diminished over time, participants still made 12.8% more green trips per month after eight months, indicating persistence. These results provide the first large-scale empirical evidence of carbon incentives in MaaS and highlight their potential to inform targeted, city-specific interventions that can scale to support global low-carbon mobility transitions.

</details>


### [39] [The trade-off between model flexibility and accuracy of the Expected Threat model in football](https://arxiv.org/abs/2511.09457)
*Koen W. van Arem,Jakob Söhl,Mirjam Bruinsma,Geurt Jongbloed*

Main category: stat.AP

TL;DR: 本文分析了足球预期威胁模型在网格尺寸选择上的权衡问题，通过理论分析和模拟实验提供了误差边界和实用指导原则。


<details>
  <summary>Details</summary>
Motivation: 足球比赛中大量的事件数据需要有效利用，预期威胁模型因其可解释性而受到青睐，但网格尺寸选择面临模型灵活性与准确性之间的权衡挑战。

Method: 从理论角度分析预期威胁模型，基于模型的马尔可夫链进行模拟实验，研究模型在实际应用中的行为。

Result: 理论结果建立了不同灵活性下预期威胁模型误差的上界，模拟实验提供了比理论边界更准确的误差特征描述。

Conclusion: 将研究洞察转化为实用经验法则，帮助从业者在模型灵活性和预期威胁模型所需准确性之间选择适当平衡。

Abstract: With an average football (soccer) match recording over 3,000 on-ball events, effective use of this event data is essential for practitioners at football clubs to obtain meaningful insights. Models can extract more information from this data, and explainable methods can make them more accessible to practitioners. The Expected Threat model has been praised for its explainability and offers an accessible option. However, selecting the grid size is a challenging key design choice that has to be made when applying the Expected Threat model. Using a finer grid leads to a more flexible model that can better distinguish between different situations, but the accuracy of the estimates deteriorates with a more flexible model. Consequently, practitioners face challenges in balancing the trade-off between model flexibility and model accuracy. In this study, the Expected Threat model is analyzed from a theoretical perspective and simulations are performed based on the Markov chain of the model to examine its behavior in practice. Our theoretical results establish an upper bound on the error of the Expected Threat model for different flexibilities. Based on the simulations, a more accurate characterization of the model's error is provided, improving over the theoretical bound. Finally, these insights are converted into a practical rule of thumb to help practitioners choose the right balance between the model flexibility and the desired accuracy of the Expected Threat model.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [40] [Linear-Bias Time Encoding for Low-Rate Quantized Representation of Bandlimited Signals](https://arxiv.org/abs/2511.09007)
*Anshu Arora,Kaluguri Yashaswini,Satish Mulleti*

Main category: eess.SP

TL;DR: 提出线性偏置IF-TEM（LB-IF-TEM），通过动态跟踪输入信号来减少过采样，实现更高效的时基信号编码和重建。


<details>
  <summary>Details</summary>
Motivation: 传统IF-TEM存在过度过采样问题，导致对信息分布平滑的信号编码效率低下。

Method: 引入线性偏置IF-TEM，使偏置动态跟踪输入信号，保持积分器输入接近恒定，从而集中触发间隔分布。

Result: 理论分析建立了可实现的过采样范围界限，实验结果表明在显著降低比特率的情况下达到可比的重建精度。

Conclusion: LB-IF-TEM提供了一个低功耗、通信效率高且分析可处理的时基信号编码和重建框架。

Abstract: Integrate-and-fire time encoding machines (IF-TEMs) provide an efficient framework for asynchronous sampling of bandlimited signals through discrete firing times. However, conventional IF-TEMs often exhibit excessive oversampling, leading to inefficient encoding for signals with smoothly distributed information. This letter introduces a linear-bias IF-TEM (LB-IF-TEM), where the bias dynamically tracks the input signal to maintain a nearly constant integrator input, thereby localizing the firing intervals. The resulting concentrated distribution enables effective non-uniform quantization with reduced distortion. Theoretical analysis establishes explicit bounds on the achievable oversampling range, while experimental results demonstrate that the proposed method attains comparable reconstruction accuracy at significantly lower bitrate than existing IF-TEM variants. The LB-IF-TEM thus provides a low-power, communication-efficient, and analytically tractable framework for time-based signal encoding and reconstruction.

</details>


### [41] [LMMSE-Optimal Pilot Pattern Design Based on Covariance Matrix Approximation for OFDM Channel Estimation in Doubly Dispersive Channel](https://arxiv.org/abs/2511.09140)
*Xuyao Yu,Zijun Gong,Zhilu Lai*

Main category: eess.SP

TL;DR: 本文研究了在双弥散信道中OFDM系统的最优导频模式设计，基于LMMSE估计器。通过将信道协方差矩阵分解为延迟域和多普勒域的Kronecker积，利用Szegö极限定理近似对角化，推导出LMMSE信道估计误差的紧凑解析形式和闭式下界，并建立了实现该下界的格点导频模式条件。


<details>
  <summary>Details</summary>
Motivation: 在双弥散信道中，OFDM系统的信道估计性能受导频模式设计影响。现有方法缺乏对LMMSE估计器下最优导频模式的系统分析，需要建立理论框架来指导实际导频设计。

Method: 将信道协方差矩阵分解为延迟域和多普勒域的Hermitian Toeplitz矩阵的Kronecker积，利用Szegö极限定理证明这些矩阵可由DFT矩阵近似对角化，从而将LMMSE信道估计误差重新表述为紧凑解析形式，并推导闭式下界。

Result: 数值结果表明所提出的矩阵近似引入的误差可忽略不计，给出了所提出的格点设计实例，验证了理论分析的有效性。

Conclusion: 建立了双弥散信道中OFDM系统LMMSE信道估计的理论框架，推导了最优导频模式的闭式下界，并证明了格点导频模式在特定条件下可实现该下界，为实际系统设计提供了理论指导。

Abstract: This paper investigates the optimal pilot pattern design, in the linear minimum mean square error (LMMSE) estimator sense, for OFDM systems in doubly dispersive channels. To enable analytical tractability, the channel covariance matrix is decomposed into the Kronecker product of two Hermitian Toeplitz matrices corresponding to the delay and Doppler domains. By invoking the Szegö limit theorem, these matrices are shown to be approximately diagonalizable by discrete Fourier transform (DFT) matrices. Based on this structure, the LMMSE channel estimation error is reformulated into a compact analytical form, from which a closed-form lower bound is derived. Furthermore, we establish the condition under which this bound is achieved by a lattice-based pilot pattern. Numerical results verify that the proposed matrix approximation introduces negligible error and examples of the proposed lattice design are given.

</details>


### [42] [Mip-NeWRF: Enhanced Wireless Radiance Field with Hybrid Encoding for Channel Prediction](https://arxiv.org/abs/2511.09150)
*Yulin Fu,Jiancun Fan,Shiyu Zhai,Zhibo Duan,Jie Luo*

Main category: eess.SP

TL;DR: Mip-NeWRF是一种基于物理信息的神经框架，通过圆锥截头体采样和尺度一致混合位置编码，结合课程学习策略，显著提高了室内信道预测的准确性和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 现有无线辐射场方法在复杂环境中存在鲁棒性不足、收敛慢和精度有限的问题，需要更精细的建模方法来改进信道预测性能。

Method: 采用基于射线的粗到细重要性采样流程，进行圆锥截头体采样并应用尺度一致混合位置编码，使用共享多层感知器处理，结合课程学习训练策略，在信道合成中整合路径损耗和表面交互衰减模型。

Result: 在典型场景中，与最先进基线相比，归一化均方误差降低了14.3 dB，显著提升了信道预测精度。

Conclusion: Mip-NeWRF框架通过精细的采样策略、混合编码和物理信息整合，有效解决了复杂环境中信道预测的挑战，实现了更高的准确性和更快的收敛速度。

Abstract: Recent work on wireless radiance fields represents a promising deep learning approach for channel prediction, however, in complex environments these methods still exhibit limited robustness, slow convergence, and modest accuracy due to insufficiently refined modeling. To address this issue, we propose Mip-NeWRF, a physics-informed neural framework for accurate indoor channel prediction based on sparse channel measurements. The framework operates in a ray-based pipeline with coarse-to-fine importance sampling: frustum samples are encoded, processed by a shared multilayer perceptron (MLP), and the outputs are synthesized into the channel frequency response (CFR). Prior to MLP input, Mip-NeWRF performs conical-frustum sampling and applies a scale-consistent hybrid positional encoding to each frustum. The scale-consistent normalization aligns positional encodings across scene scales, while the hybrid encoding supplies both scale-robust, low-frequency stability to accelerate convergence and fine spatial detail to improve accuracy. During training, a curriculum learning schedule is applied to stabilize and accelerate convergence of the shared MLP. During channel synthesis, the MLP outputs, including predicted virtual transmitter presence probabilities and amplitudes, are combined with modeled pathloss and surface interaction attenuation to enhance physical fidelity and further improve accuracy. Simulation results demonstrate the effectiveness of the proposed approach: in typical scenarios, the normalized mean square error (NMSE) is reduced by 14.3 dB versus state-of-the-art baselines.

</details>


### [43] [Delay-Multiply-And-Sum Beamforming for Real-Time In-Air Acoustic Imaging](https://arxiv.org/abs/2511.09165)
*Wouter Jansen,Walter Daems,Jan Steckel*

Main category: eess.SP

TL;DR: 本文提出了一种基于延迟-乘法和和（DMAS）技术结合相干因子加权的非线性波束形成方法，用于提高空气声学成像系统的动态范围和空间分辨率，同时保持实时性能。


<details>
  <summary>Details</summary>
Motivation: 传统的延迟求和（DAS）波束形成方法由于高旁瓣、宽主瓣和低对比度而无法满足质量要求，而自适应方法又受限于计算成本和实时操作的单一快照约束。

Method: 采用高阶非线性波束形成方法，结合延迟-乘法和和（DMAS）技术与相干因子加权，专门针对空气超声麦克风阵列进行优化，并通过GPU加速实现嵌入式平台上的实时性能。

Result: 通过仿真和实际声学数据验证，与DAS基线相比，所提方法在图像对比度方面有显著提升。

Conclusion: 高阶非线性波束形成成为空气声学成像中实用且高性能的解决方案。

Abstract: In-air acoustic imaging systems demand beamforming techniques that offer a high dynamic range and spatial resolution while also remaining robust. Conventional Delay-and-Sum (DAS) beamforming fails to meet these quality demands due to high sidelobes, a wide main lobe and the resulting low contrast, whereas advanced adaptive methods are typically precluded by the computational cost and the single-snapshot constraint of real-time field operation. To overcome this trade-off, we propose and detail the implementation of higher-order non-linear beamforming methods using the Delay-Multiply-and-Sum technique, coupled with Coherence Factor weighting, specifically adapted for ultrasonic in-air microphone arrays. Our efficient implementation allows for enabling GPU-accelerated, real-time performance on embedded computing platforms. Through validation against the DAS baseline using simulated and real-world acoustic data, we demonstrate that the proposed method provides significant improvements in image contrast, establishing higher-order non-linear beamforming as a practical, high-performance solution for in-air acoustic imaging.

</details>


### [44] [Two-Dimensional Pinching-Antenna Systems: Modeling and Beamforming Design](https://arxiv.org/abs/2511.09207)
*Yuan Zhong,Yue Xiao,Yijia Li,Hao Chen,Xianfu Lei,Pingzhi Fan*

Main category: eess.SP

TL;DR: 本文提出了一种新型二维夹持天线系统（2D-PASS），将传统的线形结构扩展为连续的介质波导平面，形成可重构的辐射平面，能够在二维空间域中实现动态波束自适应。


<details>
  <summary>Details</summary>
Motivation: 现有的夹持天线系统（PASS）主要采用线形架构，其有限的空间灵活性限制了在多用户和室内场景中的适用性。

Method: 开发了一个优化框架，通过自适应调整夹持天线的空间配置来最大化用户设备的最小接收信噪比，作为动态空间控制的模拟波束形成机制。针对连续位置场景提出了基于粒子群优化的算法，并引入了离散变体以适应实际硬件约束。

Result: 仿真结果表明，与传统的线形PASS和固定位置天线基准相比，所提出的2D-PASS显著提高了最小信噪比，同时在变化的用户分布和距离下保持鲁棒性。

Conclusion: 2D-PASS通过扩展为二维结构，显著提高了空间灵活性和性能，在多用户场景中表现出优越的性能。

Abstract: Recently, the pinching-antenna system (PASS) has emerged as a promising architecture owing to its ability to reconfigure large-scale path loss and signal phase by activating radiation points along a dielectric waveguide. However, existing studies mainly focus on line-shaped PASS architectures, whose limited spatial flexibility constrains their applicability in multiuser and indoor scenarios. In this paper, we propose a novel two-dimensional (2D) pinching-antenna system (2D-PASS) that extends the conventional line-shaped structure into a continuous dielectric waveguide plane, thereby forming a reconfigurable radiating plane capable of dynamic beam adaptation across a 2D spatial domain. An optimization framework is developed to maximize the minimum received signal-to-noise ratio (SNR) among user equipments (UEs) by adaptively adjusting the spatial configuration of pinching antennas (PAs), serving as an analog beamforming mechanism for dynamic spatial control. For the continuous-position scenario, a particle swarm optimization (PSO)-based algorithm is proposed to efficiently explore the nonconvex search space, while a discrete variant is introduced to accommodate practical hardware constraints with limited PA placement resolution. Simulation results demonstrate that the proposed 2D-PASS substantially improves the minimum SNR compared with conventional line-shaped PASS and fixed-position antenna (FPA) benchmarks, while maintaining robustness under varying user distributions and distances.

</details>


### [45] [Positioning via Digital-Twin-Aided Channel Charting with Large-Scale CSI Features](https://arxiv.org/abs/2511.09227)
*José Miguel Mateos-Ramos,Frederik Zumegen,Henk Wymeersch,Christian Häger,Christoph Studer*

Main category: eess.SP

TL;DR: 本文提出了一种利用数字孪生将信道图绘制技术中的任意坐标系转换为真实空间坐标系的新方法，通过提取大规模信道状态信息特征并使用余弦相似度损失函数进行匹配，无需标记数据即可实现精确定位。


<details>
  <summary>Details</summary>
Motivation: 传统信道图绘制技术的主要局限在于估计的位置位于任意坐标系中，无法与真实空间坐标对齐，这限制了其在实际定位应用中的实用性。

Method: 提出新框架：(i) 从估计的信道状态信息和数字孪生中提取大规模CSI特征；(ii) 使用余弦相似度损失函数匹配这些特征，并将该损失函数与传统CC损失结合以学习定位函数。

Result: 在模拟室内场景中，所提框架相比现有技术将相对平均距离误差降低了29%，且对数字孪生建模失配和测试数据分布偏移具有鲁棒性。

Conclusion: 该方法能够在不依赖标记数据的情况下提供真实空间坐标，显著提升了信道图绘制技术的定位精度和实用性。

Abstract: Channel charting (CC) is a self-supervised positioning technique whose main limitation is that the estimated positions lie in an arbitrary coordinate system that is not aligned with true spatial coordinates. In this work, we propose a novel method to produce CC locations in true spatial coordinates with the aid of a digital twin (DT). Our main contribution is a new framework that (i) extracts large-scale channel-state information (CSI) features from estimated CSI and the DT and (ii) matches these features with a cosine-similarity loss function. The DT-aided loss function is then combined with a conventional CC loss to learn a positioning function that provides true spatial coordinates without relying on labeled data. Our results for a simulated indoor scenario demonstrate that the proposed framework reduces the relative mean distance error by 29% compared to the state of the art. We also show that the proposed approach is robust to DT modeling mismatches and a distribution shift in the testing data.

</details>


### [46] [2D Waveguide-Fed Metasurface Antenna Arrays: Modeling and Optimization for Bistatic Sensing](https://arxiv.org/abs/2511.09254)
*Ioannis Gavras,Panagiotis Gavriilidis,George C. Alexandropoulos*

Main category: eess.SP

TL;DR: 本文提出了一个物理一致的框架，用于双基地感知，采用2D波导馈电超表面天线阵列实现超大规模MIMO孔径。提出了耦合偶极子模型捕捉阵列的互耦效应，并提出了磁极化率的无源性约束。通过Neumann级数近似推导了多目标参数估计的Cramer-Rao界，并将其纳入感知优化问题中。


<details>
  <summary>Details</summary>
Motivation: 开发一个物理一致的双基地感知框架，利用超大规模MIMO孔径实现高精度感知，同时考虑阵列的互耦效应和物理约束条件。

Method: 使用耦合偶极子模型捕捉波导和自由空间互耦，提出磁极化率的无源性约束，采用Neumann级数近似阵列响应模型，推导Cramer-Rao界，并基于此进行超表面共振强度配置的优化。

Result: 仿真结果表明，在辐射近场中提出的设计能够量化位置误差界限，揭示了超材料布局在强耦合超表面XL MIMO双基地感知系统中的关键作用。

Conclusion: 该框架为超大规模MIMO双基地感知系统提供了物理一致的设计方法，强调了超材料布局对系统性能的重要性，为高精度感知应用提供了理论和技术支持。

Abstract: This paper presents a physics-consistent framework for bistatic sensing incorporating a 2-Dimensional (2D) waveguide-fed metasurface antenna array capable of realizing eXtremely-Large Multiple-Input Multiple-Output (XL MIMO) apertures. A coupled-dipole model is presented that captures the array's mutual coupling due to both waveguide and free-space interactions, and a novel passivity constraint on the corresponding magnetic polarizabilities is proposed. Focusing on a bistatic sensing setup, we leverage a Neumann-series approximation of the array response model and derive the Cramer-Rao bound for multi-target parameter estimation, which is then incorporated into a sensing optimization formulation with respect to the metasurface's per-element resonance strength configuration. Simulation results on the position error bound in the radiative near field with the proposed design quantify the critical role of metamaterial placement in strongly coupled metasurface-based XL MIMO bistatic sensing systems.

</details>


### [47] [End-to-End Hardware Modeling and Sensitivity Optimization of Photoacoustic Signal Readout Chains](https://arxiv.org/abs/2511.09341)
*Weiran Yang,Yiqi Cai,Handi Deng,Cheng Ma*

Main category: eess.SP

TL;DR: 本文开发了一个基于KLM模型的完整分析模型，用于光声成像系统中系统级灵敏度的端到端优化，考虑了换能器、电缆和接收器之间的耦合效应。


<details>
  <summary>Details</summary>
Motivation: 以往研究往往只关注前端声学组件或后端电子组件，忽视了换能器、电缆和接收器之间的端到端耦合，这影响了光声成像系统的检测灵敏度和图像质量。

Method: 基于线性压电本构方程、一维波动方程和传输线理论，重新推导KLM模型，建立包含电缆和接收器集总参数表示的端到端等效电路，推导系统传递函数的解析表达式。

Result: 实验验证显示模型平均误差低于5%，识别并分析了超出1D振动假设时出现的低频拖尾现象，为伪影抑制提供了潜在途径。

Conclusion: 该工作为优化光声成像系统的检测灵敏度和提高图像保真度提供了一个综合框架。

Abstract: The sensitivity of the acoustic detection subsystem in photoacoustic imaging (PAI) critically affects image quality. However, previous studies often focused only on front-end acoustic components or back-end electronic components, overlooking end-to-end coupling among the transducer, cable, and receiver. This work develops a complete analytical model for system-level sensitivity optimization based on the Krimholtz, Leedom, and Matthaei (KLM) model. The KLM model is rederived from first principles of linear piezoelectric constitutive equations, 1D wave equations and transmission line theory to clarify its physical basis and applicable conditions. By encapsulating the acoustic components into a controlled voltage source and extending the model to include lumped-parameter representations of cable and receiver, an end-to-end equivalent circuit is established. Analytical expressions for the system transfer functions are derived, revealing the coupling effects among key parameters such as transducer element area (EA), cable length (CL), and receiver impedance (RI). Experimental results validate the model with an average error below 5%. Additionally, a low-frequency tailing phenomenon arising from exceeding the 1D vibration assumption is identified and analyzed, illustrating the importance of understanding the model's applicable conditions and providing a potential pathway for artifact suppression. This work offers a comprehensive framework for optimizing detection sensitivity and improving image fidelity in PAI systems.

</details>


### [48] [Reduced-Complexity Model Selection and Rate Allocation for Multiple-Model Electrical Signal Compression](https://arxiv.org/abs/2511.09370)
*Corentin Presvôts,Michel Kieffer,Thibault Prevost*

Main category: eess.SP

TL;DR: 本文提出了一种降低复杂度的多模型编码方法，用于电信号波形压缩，通过联合优化参数模型和比特率分配来满足重构信号质量约束。


<details>
  <summary>Details</summary>
Motivation: 传统多模型编码方法产生恒定比特率但质量变化的输出，需要开发能够满足特定失真约束的更高效压缩方法。

Method: 提出三种方法：穷举搜索作为基准；黄金分割搜索降低第一阶段比特率选择复杂度；利用率失真模型缩小第一阶段模型子集和两阶段比特率搜索区间。

Result: 仿真结果表明，所提出的降低复杂度MMC方法在给定失真约束下，相比现有解决方案实现了更低的比特率。

Conclusion: 该方法在保持等效复杂度的同时，显著提高了电信号压缩的效率。

Abstract: This paper adapts a Multiple-Model Coding (MMC) approach for sampled electrical signal waveforms to satisfy reconstructed signal quality constraints. The baseline MMC approach consists of two stages processing vectors of Voltage and Current Signal (VCS) of constant size and producing bitstreams of constant rate but varying quality. In the proposed approach, the parametric model and the rate allocated to the first stage, as well as the residual compression method of the second stage and its associated rate, are jointly optimized to achieve a target distortion of the reconstructed signal. Three approaches are proposed. An exhaustive search serves as a baseline for comparison. Then, an approach involving a Golden Section search is exploited to determine the rate of the first stage with reduced complexity. Finally, rate-distortion models of the compression efficiency for each model in the first stage are employed to obtain a subset of promising models in the first stage and reduced-size search intervals for the rate selection in both stages. Simulation results demonstrate that the proposed reduced-complexity MMC approach reduces the rate for a given distortion constraint compared to state-of-the-art solutions for VCS with equivalent complexity.

</details>


### [49] [Equivalence of Several 6G Modulation Schemes for Doubly-Selective Channels](https://arxiv.org/abs/2511.09418)
*Nishant Mehrotra,Sandesh Rao Mattu,Robert Calderbank*

Main category: eess.SP

TL;DR: 本文提出了一个分析双选择性信道调制方案的框架，重点关注非选择性和可预测性两个特性，这些特性直接关系到调制方案实现的多样性和频谱效率。


<details>
  <summary>Details</summary>
Motivation: 针对具有大延迟和多普勒扩展的双选择性信道，传统基于时频信号表示的调制方案性能不佳，因此需要设计新的调制方案。

Method: 开发了一个分析框架，使用非选择性和可预测性两个特性来评估调制方案，比较了延迟-多普勒、啁啾和时序域调制与时频调制的差异。

Result: 研究发现延迟-多普勒、啁啾和时序域调制是非选择性、可预测且相互等价的，而时频调制是选择性和不可预测的。

Conclusion: 该框架为双选择性信道中的调制方案设计提供了理论基础，揭示了不同调制域的特性差异及其对系统性能的影响。

Abstract: There is significant recent interest in designing new modulation schemes for doubly-selective channels with large delay and Doppler spreads, where legacy modulation schemes based on time-frequency signal representations do not perform well. In this paper, we develop a framework for analyzing such modulations using two characteristics -- non-selectivity and predictability -- which directly relate to the diversity and spectral efficiency that the modulations achieve. We show that modulations in the delay-Doppler, chirp and time-sequency domains are non-selective, predictable and equivalent to one another, whereas time-frequency modulations are selective and non-predictable.

</details>


### [50] [Scalable Long-Term Beamforming for Massive Multi-User MIMO](https://arxiv.org/abs/2511.09464)
*Ali Rasteh,Amirreza Kiani,Marco Mezzavilla,Sundeep Rangan*

Main category: eess.SP

TL;DR: 提出了一种基于长期波束成形的计算高效、开销低的大规模MIMO接收机设计方法，结合低秩投影和快速多项式矩阵求逆技术，在保持性能的同时显著降低开销和计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO系统（1000+天线）虽然能提供巨大的容量增益，但数字接收机设计面临信道估计开销和计算复杂度的重大挑战，需要找到既能保持性能又降低复杂度的解决方案。

Method: 结合长期空间协方差估计的低秩投影和快速多项式矩阵求逆技术，构建高效的大规模MIMO接收机架构。

Result: 射线追踪仿真表明，与完整的瞬时波束成形相比，该方法性能损失极小，同时显著降低了开销和计算复杂度。

Conclusion: 基于长期波束成形的接收机设计为大规模MIMO系统提供了一种可行的解决方案，在保持性能优势的同时有效解决了计算和开销问题。

Abstract: Fully digital massive MIMO systems with large numbers (1000+) of antennas offer dramatically increased capacity gains from spatial multiplexing and beamforming. Designing digital receivers that can scale to these array dimensions presents significant challenges regarding both channel estimation overhead and digital computation. This paper presents a computationally efficient and low-overhead receiver design based on long-term beamforming. The method combines finding a low-rank projection from the spatial covariance estimate with a fast polynomial matrix inverse. Ray tracing simulations show minimal loss relative to complete instantaneous beamforming while offering significant overhead and computational gains.

</details>
