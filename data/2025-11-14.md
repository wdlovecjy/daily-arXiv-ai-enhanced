<div id=toc></div>

# Table of Contents

- [stat.AP](#stat.AP) [Total: 1]
- [cs.AI](#cs.AI) [Total: 17]
- [cs.LG](#cs.LG) [Total: 29]
- [eess.SP](#eess.SP) [Total: 3]


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [1] [Heuristic Solutions for the Best Secretary Problem](https://arxiv.org/abs/2511.10206)
*Eugene Seong*

Main category: stat.AP

TL;DR: 本文提出了一个启发式框架来解决最佳秘书问题，开发了五种基于数据响应的规则来扩展传统的固定截止方法，这些规则能够根据积累的信息动态调整阈值。


<details>
  <summary>Details</summary>
Motivation: 传统的固定截止方法在动态决策环境中表现有限，需要开发能够根据实时数据调整的数据响应式启发式方法。

Method: 开发了五种数据响应规则：期望记录阈值、自适应偏差校正、概率早期接受规则、两阶段松弛法和局部动态规划近似法，这些规则能够顺序调整阈值。

Result: 在不同样本大小、分布和自相关设置下的模拟显示，这些启发式方法在稳定性和效率上匹配或超过了传统最优规则，其中组合多个规则的集成方法表现最稳定。

Conclusion: 少数直观参数即可实现接近最优的结果，表明数据响应式启发式方法能够有效将基于排名的最优停止扩展到动态决策环境。

Abstract: This paper introduces a heuristic framework for the Best Secretary Problem, where one item must be selected using rank information only. We develop five data-responsive rules extending classical fixed-cutoff methods: an expected-record threshold, an adaptive deviation correction, a probabilistic early-accept rule, a two-phase relaxation, and a local dynamic programming approximation. These rules adjust thresholds sequentially as information accumulates. Simulations across diverse sample sizes, distributions, and autocorrelated settings show that the heuristics match or exceed traditional optimal rules in stability and efficiency. The expected-record rule remains strong despite its simplicity, the adaptive correction performs well under asymmetry, and the adaptive and probabilistic rules reduce average stopping times. An ensemble combining multiple rules yields the most stable performance. Overall, a few intuitive parameters achieve near-optimal results, demonstrating that data-responsive heuristics can effectively extend rank-based optimal stopping to dynamic decision environments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [2] [An Efficient and Almost Optimal Solver for the Joint Routing-Assignment Problem via Partial JRA and Large-α Optimization](https://arxiv.org/abs/2511.09563)
*Qilong Yuan*

Main category: cs.AI

TL;DR: 本文提出了一种新颖高效的Partial Path Reconstruction (PPR)求解器，用于解决联合路由分配(JRA)优化问题。该方法通过识别关键项目-占位符对形成简化子问题，显著提高了大规模JRA问题的求解效率和精度。


<details>
  <summary>Details</summary>
Motivation: 现有精确方法虽然能保证最优性，但在大规模实例上计算效率低下。启发式方法虽然计算效率高，但解的质量与最优解存在约1%的偏差。需要开发一种既能保证高精度又能高效求解大规模JRA问题的新方法。

Method: 提出了Partial Path Reconstruction (PPR)求解器：1) 识别关键项目-占位符对形成简化子问题；2) 在PJAR框架中改进初始启发式合并解；3) 沿优化路径迭代优化解；4) 在JRA模型中引入全局Large-α约束。

Result: 在n=300、500和1000的基准数据集上的实验评估表明，该方法始终提供几乎最优的解，平均偏差为0.00%，同时保持高计算效率。

Conclusion: 所提出的PPR方法显著提高了JRA问题的求解精度和效率，将偏差减少了一半。该框架和方法论在TSP和相关优化问题中具有广泛的应用潜力。

Abstract: The Joint Routing-Assignment (JRA) optimization problem simultaneously determines the assignment of items to placeholders and a Hamiltonian cycle that visits each node pair exactly once, with the objective of minimizing total travel cost. Previous studies introduced an exact mixed-integer programming (MIP) solver, along with datasets and a Gurobi implementation, showing that while the exact approach guarantees optimality, it becomes computationally inefficient for large-scale instances. To overcome this limitation, heuristic methods based on merging algorithms and shaking procedures were proposed, achieving solutions within approximately 1% deviation from the optimum. This work presents a novel and more efficient approach that attains high-accuracy, near-optimal solutions for large-scale JRA problems. The proposed method introduces a Partial Path Reconstructon (PPR) solver that first identifies key item-placeholder pairs to form a reduced subproblem, which is solved efficiently to refine the global solution. Using this PJAR framework, the initial heuristic merging solutions can be further improved, reducing the deviation by half. Moreover, the solution can be iteratively polished with PPR based solver along the optimization path to yield highly accurate tours. Additionally, a global Large-α constraint is incorporated into the JRA model to further enhance solution optimality. Experimental evaluations on benchmark datasets with n = 300, 500, and 1000 demonstrate that the proposed method consistently delivers almost optimal solutions, achieving an average deviation of 0.00% from the ground truth while maintaining high computational efficiency. Beyond the JRA problem, the proposed framework and methodologies exhibit strong potential for broader applications. The Framework can be applied to TSP and related optimization problems.

</details>


### [3] [Variable Neighborhood Search for the Electric Vehicle Routing Problem](https://arxiv.org/abs/2511.09570)
*David Woller,Viktor Kozák,Miroslav Kulich,Libor Přeučil*

Main category: cs.AI

TL;DR: 本文介绍了在CEC-12竞赛中获胜的电动汽车路径问题求解方法，基于变邻域搜索元启发式算法，在竞赛数据集上取得了最佳结果。


<details>
  <summary>Details</summary>
Motivation: 由于电动汽车在物流中的日益普及，电动汽车路径问题（EVRP）扩展了经典的车辆路径问题。然而，文献中考虑的各种约束使得比较不同问题变体的方法具有挑战性。

Method: 采用变邻域搜索（VNS）元启发式算法来解决最小化变体的电动汽车路径问题——容量约束绿色车辆路径问题（CGVRP）。

Result: 该方法在完整的竞赛数据集上取得了最佳结果，并且优于之后发布的更近期算法。

Conclusion: 基于变邻域搜索的方法在解决容量约束绿色车辆路径问题方面表现出色，是竞赛中的获胜方案。

Abstract: The Electric Vehicle Routing Problem (EVRP) extends the classical Vehicle Routing Problem (VRP) to reflect the growing use of electric and hybrid vehicles in logistics. Due to the variety of constraints considered in the literature, comparing approaches across different problem variants remains challenging. A minimalistic variant of the EVRP, known as the Capacitated Green Vehicle Routing Problem (CGVRP), was the focus of the CEC-12 competition held during the 2020 IEEE World Congress on Computational Intelligence. This paper presents the competition-winning approach, based on the Variable Neighborhood Search (VNS) metaheuristic. The method achieves the best results on the full competition dataset and also outperforms a more recent algorithm published afterward.

</details>


### [4] [Rebellion: Noise-Robust Reasoning Training for Audio Reasoning Models](https://arxiv.org/abs/2511.09682)
*Tiansheng Huang,Virat Shejwalkar,Oscar Chang,Milad Nasr,Ling Liu*

Main category: cs.AI

TL;DR: 本文研究了音频推理模型（ARMs）的安全性，发现标准推理训练无法抵御高级音频越狱攻击，提出了Rebellion鲁棒训练方法来保护ARMs免受攻击。


<details>
  <summary>Details</summary>
Motivation: 随着音频推理模型的普及，需要研究其对抗越狱攻击的安全性，目前尚无相关工作。

Method: 提出Rebellion鲁棒推理训练方法，训练ARMs对最坏情况下的表示漂移具有鲁棒性。

Result: Rebellion能够有效防御高级音频越狱攻击，同时不影响良性任务性能，显著改善了准确性与安全性的权衡。

Conclusion: Rebellion方法为音频推理模型提供了有效的安全保护，解决了标准推理训练在对抗高级越狱攻击时的不足。

Abstract: Instilling reasoning capabilities in large models (LMs) using reasoning training (RT) significantly improves LMs' performances. Thus Audio Reasoning Models (ARMs), i.e., audio LMs that can reason, are becoming increasingly popular. However, no work has studied the safety of ARMs against jailbreak attacks that aim to elicit harmful responses from target models. To this end, first, we show that standard RT with appropriate safety reasoning data can protect ARMs from vanilla audio jailbreaks, but cannot protect them against our proposed simple yet effective jailbreaks. We show that this is because of the significant representation drift between vanilla and advanced jailbreaks which forces the target ARMs to emit harmful responses. Based on this observation, we propose Rebellion, a robust RT that trains ARMs to be robust to the worst-case representation drift. All our results are on Qwen2-Audio; they demonstrate that Rebellion: 1) can protect against advanced audio jailbreaks without compromising performance on benign tasks, and 2) significantly improves accuracy-safety trade-off over standard RT method.

</details>


### [5] [Echoing: Identity Failures when LLM Agents Talk to Each Other](https://arxiv.org/abs/2511.09710)
*Sarath Shekkizhar,Romain Cosentino,Adam Earle,Silvio Savarese*

Main category: cs.AI

TL;DR: 本文研究了多智能体对话中的行为漂移现象，特别是回音效应——智能体放弃自身角色转而模仿对话伙伴，导致任务失败。研究发现这种现象在三大LLM提供商中普遍存在，发生率5%-70%，且随着对话轮次增加而加剧。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的智能体自主交互，出现了一类无法从单智能体性能预测的新失败模式：智能体间对话的行为漂移。由于缺乏人类参与提供的稳定信号，这些失败具有独特性。

Method: 通过60个AxA配置、3个领域、2000+对话的实验，研究了回音效应在不同LLM提供商中的表现，分析了提示影响和对话动态，并引入了协议级缓解措施。

Result: 回音效应在三大LLM提供商中普遍存在，发生率5%-70%；即使在高级推理模型中也有32.8%的发生率；随着对话轮次增加（7+轮）而加剧；使用结构化响应可将回音效应降至9%。

Conclusion: 智能体间对话中的回音效应是一个普遍且持久的问题，不能仅通过优化提示解决，需要协议级的干预措施来确保智能体保持其指定角色。

Abstract: As large language model (LLM) based agents interact autonomously with one another, a new class of failures emerges that cannot be predicted from single agent performance: behavioral drifts in agent-agent conversations (AxA). Unlike human-agent interactions, where humans ground and steer conversations, AxA lacks such stabilizing signals, making these failures unique. We investigate one such failure, echoing, where agents abandon their assigned roles and instead mirror their conversational partners, undermining their intended objectives. Through experiments across $60$ AxA configurations, $3$ domains, and $2000+$ conversations, we demonstrate that echoing occurs across three major LLM providers, with echoing rates from $5\%$ to $70\%$ depending on the model and domain. Moreover, we find that echoing is persistent even in advanced reasoning models with substantial rates ($32.8\%$) that are not reduced by increased reasoning efforts. We analyze prompt impacts, conversation dynamics, showing that echoing arises as interaction grows longer ($7+$ turns in experiments) and is not merely an artifact of sub-optimal prompting. Finally, we introduce a protocol-level mitigation in which targeted use of structured responses reduces echoing to $9\%$.

</details>


### [6] [AI Annotation Orchestration: Evaluating LLM verifiers to Improve the Quality of LLM Annotations in Learning Analytics](https://arxiv.org/abs/2511.09785)
*Bakhtawar Ahtisham,Kirk Vanacore,Jinsook Lee,Zhuqian Zhou,Doug Pietrzak,Rene F. Kizilcec*

Main category: cs.AI

TL;DR: 本文研究了通过验证导向的编排（自我验证和交叉验证）来提高大型语言模型在教育对话标注中的可靠性，相比未验证标注，编排方法使Cohen's kappa系数提高了58%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越多地用于标注学习交互，但其可靠性问题限制了实际应用。本文旨在测试验证导向的编排方法是否能提高辅导话语定性编码的质量。

Method: 使用30个一对一数学辅导会话的转录文本，比较了三种前沿LLM（GPT、Claude、Gemini）在三种条件下的表现：未验证标注、自我验证和所有编排配置下的交叉验证。输出结果与盲审的人类裁决进行基准测试。

Result: 编排方法使kappa系数提高了58%。自我验证相比未验证基线几乎使一致性翻倍，在具有挑战性的导师行为上获得最大收益。交叉验证平均提高了37%，但存在配对和结构依赖效应。

Conclusion: 验证被定位为在学习教育分析中实现可靠、可扩展的LLM辅助标注的原则性设计杠杆。

Abstract: Large Language Models (LLMs) are increasingly used to annotate learning interactions, yet concerns about reliability limit their utility. We test whether verification-oriented orchestration-prompting models to check their own labels (self-verification) or audit one another (cross-verification)-improves qualitative coding of tutoring discourse. Using transcripts from 30 one-to-one math sessions, we compare three production LLMs (GPT, Claude, Gemini) under three conditions: unverified annotation, self-verification, and cross-verification across all orchestration configurations. Outputs are benchmarked against a blinded, disagreement-focused human adjudication using Cohen's kappa. Overall, orchestration yields a 58 percent improvement in kappa. Self-verification nearly doubles agreement relative to unverified baselines, with the largest gains for challenging tutor moves. Cross-verification achieves a 37 percent improvement on average, with pair- and construct-dependent effects: some verifier-annotator pairs exceed self-verification, while others reduce alignment, reflecting differences in verifier strictness. We contribute: (1) a flexible orchestration framework instantiating control, self-, and cross-verification; (2) an empirical comparison across frontier LLMs on authentic tutoring data with blinded human "gold" labels; and (3) a concise notation, verifier(annotator) (e.g., Gemini(GPT) or Claude(Claude)), to standardize reporting and make directional effects explicit for replication. Results position verification as a principled design lever for reliable, scalable LLM-assisted annotation in Learning Analytics.

</details>


### [7] [Why Open Small AI Models Matter for Interactive Art](https://arxiv.org/abs/2511.09788)
*Mar Canet Sola,Varvara Guljajeva*

Main category: cs.AI

TL;DR: 本文主张开源小AI模型对交互艺术创作独立性的重要性，这些模型可在本地部署，为艺术家提供对基础设施和代码的自主控制，与封闭的大规模企业系统形成对比。


<details>
  <summary>Details</summary>
Motivation: 当前主导的大型闭源AI系统作为不透明的黑箱，对交互艺术作品施加了严重限制，包括内容过滤限制、保存问题、延迟增加和接口有限等技术挑战，限制了艺术家的创作自由。

Method: 通过对比分析开源小AI模型与闭源替代方案，探讨在交互艺术中使用开源小AI模型的实际应用和影响，强调其提供的技术自决能力。

Result: 开源小AI模型赋予创作者更多自主权、控制力和可持续性，支持长期保存和展示含AI组件的艺术作品，减少对不适合交互艺术需求的企业AI的依赖。

Conclusion: 开源小AI模型是实现艺术家技术自决、增强所有权和促进交互艺术可持续发展的关键途径，为艺术创作提供了更大的控制权和独立性。

Abstract: This position paper argues for the importance of open small AI models in creative independence for interactive art practices. Deployable locally, these models offer artists vital control over infrastructure and code, unlike dominant large, closed-source corporate systems. Such centralized platforms function as opaque black boxes, imposing severe limitations on interactive artworks, including restrictive content filters, preservation issues, and technical challenges such as increased latency and limited interfaces. In contrast, small AI models empower creators with more autonomy, control, and sustainability for these artistic processes. They enable the ability to use a model as long as they want, create their own custom model, either by making code changes to integrate new interfaces, or via new datasets by re-training or fine-tuning the model. This fosters technological self-determination, offering greater ownership and reducing reliance on corporate AI ill-suited for interactive art's demands. Critically, this approach empowers the artist and supports long-term preservation and exhibition of artworks with AI components. This paper explores the practical applications and implications of using open small AI models in interactive art, contrasting them with closed-source alternatives.

</details>


### [8] [Thermally Activated Dual-Modal Adversarial Clothing against AI Surveillance Systems](https://arxiv.org/abs/2511.09829)
*Jiahuan Long,Tingsong Jiang,Hanqing Liu,Chao Ma,Wen Yao*

Main category: cs.AI

TL;DR: 提出一种热激活对抗可穿戴设备，通过热致变色染料和柔性加热单元在衣物表面产生动态对抗图案，在默认状态下为普通黑色T恤，加热后激活隐藏对抗图案以躲避可见光和红外监控检测。


<details>
  <summary>Details</summary>
Motivation: 传统对抗补丁外观显眼难以实际部署，需要开发适应复杂现实环境的隐私保护技术来抵抗AI监控系统。

Method: 集成热致变色染料与柔性加热单元，在衣物表面诱导视觉动态对抗图案，通过嵌入式热单元加热激活隐藏图案。

Result: 物理实验显示对抗可穿戴设备在50秒内实现快速纹理激活，在多样化现实监控环境中保持80%以上的对抗成功率。

Conclusion: 这项工作展示了物理基础、用户可控的反AI系统新途径，强调了在AI监控无处不在时代主动对抗技术对隐私保护的重要性。

Abstract: Adversarial patches have emerged as a popular privacy-preserving approach for resisting AI-driven surveillance systems. However, their conspicuous appearance makes them difficult to deploy in real-world scenarios. In this paper, we propose a thermally activated adversarial wearable designed to ensure adaptability and effectiveness in complex real-world environments. The system integrates thermochromic dyes with flexible heating units to induce visually dynamic adversarial patterns on clothing surfaces. In its default state, the clothing appears as an ordinary black T-shirt. Upon heating via an embedded thermal unit, hidden adversarial patterns on the fabric are activated, allowing the wearer to effectively evade detection across both visible and infrared modalities. Physical experiments demonstrate that the adversarial wearable achieves rapid texture activation within 50 seconds and maintains an adversarial success rate above 80\% across diverse real-world surveillance environments. This work demonstrates a new pathway toward physically grounded, user-controllable anti-AI systems, highlighting the growing importance of proactive adversarial techniques for privacy protection in the age of ubiquitous AI surveillance.

</details>


### [9] [EgoEMS: A High-Fidelity Multimodal Egocentric Dataset for Cognitive Assistance in Emergency Medical Services](https://arxiv.org/abs/2511.09894)
*Keshara Weerasinghe,Xueren Ge,Tessa Heick,Lahiru Nuwan Wijayasingha,Anthony Cortez,Abhishek Satpathy,John Stankovic,Homa Alemzadeh*

Main category: cs.AI

TL;DR: EgoEMS是首个端到端、高保真、多模态、多参与者的EMS数据集，包含233个模拟紧急场景中62名参与者的20多小时自我中心视角数据，旨在支持AI认知助手开发以减轻急救人员认知负担。


<details>
  <summary>Details</summary>
Motivation: 急救医疗服务(EMS)人员在高压环境下面临巨大认知负担，AI认知助手作为虚拟伙伴可以支持实时数据收集和决策制定，改善患者预后。

Method: 与EMS专家合作开发，使用开源低成本可复制的数据采集系统，捕获自我中心视角的模拟EMS活动，并标注关键步骤、时间戳音频转录、动作质量指标和边界框分割掩码。

Result: 创建了包含46名EMS专业人员的真实数据集，强调现实性，包含反映真实世界紧急动态的响应者-患者互动，并提供了多模态关键步骤识别和动作质量评估的基准测试套件。

Conclusion: EgoEMS数据集旨在激励研究社区推动智能EMS系统的边界，最终为改善患者预后做出贡献。

Abstract: Emergency Medical Services (EMS) are critical to patient survival in emergencies, but first responders often face intense cognitive demands in high-stakes situations. AI cognitive assistants, acting as virtual partners, have the potential to ease this burden by supporting real-time data collection and decision making. In pursuit of this vision, we introduce EgoEMS, the first end-to-end, high-fidelity, multimodal, multiperson dataset capturing over 20 hours of realistic, procedural EMS activities from an egocentric view in 233 simulated emergency scenarios performed by 62 participants, including 46 EMS professionals. Developed in collaboration with EMS experts and aligned with national standards, EgoEMS is captured using an open-source, low-cost, and replicable data collection system and is annotated with keysteps, timestamped audio transcripts with speaker diarization, action quality metrics, and bounding boxes with segmentation masks. Emphasizing realism, the dataset includes responder-patient interactions reflecting real-world emergency dynamics. We also present a suite of benchmarks for real-time multimodal keystep recognition and action quality estimation, essential for developing AI support tools for EMS. We hope EgoEMS inspires the research community to push the boundaries of intelligent EMS systems and ultimately contribute to improved patient outcomes.

</details>


### [10] [Adaptive Hyperbolic Kernels: Modulated Embedding in de Branges-Rovnyak Spaces](https://arxiv.org/abs/2511.09921)
*Leping Si,Meimei Yang,Hui Xue,Shipeng Zhu,Pengfei Fang*

Main category: cs.AI

TL;DR: 本文提出了一种曲率感知的de Branges-Rovnyak空间和自适应双曲核方法，用于改进层次数据的表示学习，在视觉和语言基准测试中表现优于现有双曲核方法。


<details>
  <summary>Details</summary>
Motivation: 双曲空间在嵌入层次结构方面具有优势，但现有双曲核方法存在几何失真或缺乏适应性的问题，需要开发更有效的双曲核方法。

Method: 引入曲率感知的de Branges-Rovnyak空间（与Poincare球等距的RKHS），设计可调节乘子自适应选择对应任意曲率双曲空间的RKHS，并构建自适应双曲核家族，包括新型自适应双曲径向核。

Result: 在视觉和语言基准测试上的广泛实验表明，所提出的核方法在建模层次依赖关系方面优于现有双曲核方法。

Conclusion: 通过曲率感知的RKHS和自适应双曲核设计，有效提升了双曲空间表示层次结构的能力，为层次数据建模提供了更强大的工具。

Abstract: Hierarchical data pervades diverse machine learning applications, including natural language processing, computer vision, and social network analysis. Hyperbolic space, characterized by its negative curvature, has demonstrated strong potential in such tasks due to its capacity to embed hierarchical structures with minimal distortion. Previous evidence indicates that the hyperbolic representation capacity can be further enhanced through kernel methods. However, existing hyperbolic kernels still suffer from mild geometric distortion or lack adaptability. This paper addresses these issues by introducing a curvature-aware de Branges-Rovnyak space, a reproducing kernel Hilbert space (RKHS) that is isometric to a Poincare ball. We design an adjustable multiplier to select the appropriate RKHS corresponding to the hyperbolic space with any curvature adaptively. Building on this foundation, we further construct a family of adaptive hyperbolic kernels, including the novel adaptive hyperbolic radial kernel, whose learnable parameters modulate hyperbolic features in a task-aware manner. Extensive experiments on visual and language benchmarks demonstrate that our proposed kernels outperform existing hyperbolic kernels in modeling hierarchical dependencies.

</details>


### [11] [Beyond ReAct: A Planner-Centric Framework for Complex Tool-Augmented LLM Reasoning](https://arxiv.org/abs/2511.10037)
*Xiaolong Wei,Yuehu Dong,Xingliang Wang,Xingyu Zhang,Zhejun Zhao,Dongdong Shen,Long Xia,Dawei Yin*

Main category: cs.AI

TL;DR: 提出了一种新的Planner-centric Plan-Execute范式，通过全局DAG规划解决现有工具增强LLM在复杂查询处理中的局部优化陷阱问题。


<details>
  <summary>Details</summary>
Motivation: 现有工具增强大语言模型在处理复杂查询时面临显著挑战，如ReAct等框架因依赖增量决策过程而容易陷入局部优化陷阱。

Method: 提出Planner-centric Plan-Execute范式，核心是一个执行全局有向无环图规划的Planner模型；开发两阶段训练方法，结合监督微调和组相对策略优化；构建ComplexTool-Plan大规模基准数据集。

Result: 在StableToolBench基准测试中实现了最先进的性能，展示了优越的端到端执行能力和对复杂多工具工作流程的鲁棒处理。

Conclusion: 该框架通过架构创新从根本上解决了局部优化瓶颈，在复杂用户查询处理方面表现出色。

Abstract: Existing tool-augmented large language models (LLMs) encounter significant challenges when processing complex queries. Current frameworks such as ReAct are prone to local optimization traps due to their reliance on incremental decision-making processes. To address these limitations, we propose a novel Planner-centric Plan-Execute paradigm that fundamentally resolves local optimization bottlenecks through architectural innovation. Central to our approach is a novel Planner model that performs global Directed Acyclic Graph (DAG) planning for complex queries, enabling optimized execution beyond conventional tool coordination. We also introduce ComplexTool-Plan, a large-scale benchmark dataset featuring complex queries that demand sophisticated multi-tool composition and coordination capabilities. Additionally, we develop a two-stage training methodology that integrates Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO), systematically enhancing the Planner's tool selection accuracy and global planning awareness through structured DAG-based planning. When integrated with a capable executor, our framework achieves state-of-the-art performance on the StableToolBench benchmark for complex user queries, demonstrating superior end-to-end execution capabilities and robust handling of intricate multi-tool workflows.

</details>


### [12] [Efficient Thought Space Exploration through Strategic Intervention](https://arxiv.org/abs/2511.10038)
*Ziheng Li,Hengyi Cai,Xiaochi Wei,Yuchen Li,Shuaiqiang Wang,Zhi-Hong Deng,Dawei Yin*

Main category: cs.AI

TL;DR: 提出Hint-Practice Reasoning (HPR)框架，通过分布不一致性减少(DIR)指标动态识别关键决策点，让强大LLM提供概率指导，小型模型执行主要推理步骤，实现高效推理。


<details>
  <summary>Details</summary>
Motivation: 当前推理时扩展方法计算成本过高，通过分析解码轨迹发现大多数token预测正确，只有少数关键token导致偏差，需要针对性干预。

Method: HPR框架包含hinter(强大LLM)和practitioner(高效小模型)，使用DIR指标在树结构概率空间中量化推理轨迹与期望分布的差异，动态识别干预点。

Result: 在算术和常识推理基准测试中，HPR达到与自一致性和MCTS基线相当的性能，同时只解码1/5的token，在保持相似或更低FLOPs的情况下，比现有方法高出最多5.1%的绝对准确率。

Conclusion: HPR框架通过智能识别关键决策点，在保持推理质量的同时显著降低计算成本，实现了效率与准确性的最佳平衡。

Abstract: While large language models (LLMs) demonstrate emerging reasoning capabilities, current inference-time expansion methods incur prohibitive computational costs by exhaustive sampling. Through analyzing decoding trajectories, we observe that most next-token predictions align well with the golden output, except for a few critical tokens that lead to deviations. Inspired by this phenomenon, we propose a novel Hint-Practice Reasoning (HPR) framework that operationalizes this insight through two synergistic components: 1) a hinter (powerful LLM) that provides probabilistic guidance at critical decision points, and 2) a practitioner (efficient smaller model) that executes major reasoning steps. The framework's core innovation lies in Distributional Inconsistency Reduction (DIR), a theoretically-grounded metric that dynamically identifies intervention points by quantifying the divergence between practitioner's reasoning trajectory and hinter's expected distribution in a tree-structured probabilistic space. Through iterative tree updates guided by DIR, HPR reweights promising reasoning paths while deprioritizing low-probability branches. Experiments across arithmetic and commonsense reasoning benchmarks demonstrate HPR's state-of-the-art efficiency-accuracy tradeoffs: it achieves comparable performance to self-consistency and MCTS baselines while decoding only 1/5 tokens, and outperforms existing methods by at most 5.1% absolute accuracy while maintaining similar or lower FLOPs.

</details>


### [13] [DenoGrad: Deep Gradient Denoising Framework for Enhancing the Performance of Interpretable AI Models](https://arxiv.org/abs/2511.10161)
*J. Javier Alonso-Ramos,Ignacio Aguilera-Martos,Andrés Herrera-Poyatos,Francisco Herrera*

Main category: cs.AI

TL;DR: 提出DenoGrad框架，利用深度学习模型的梯度来检测和调整噪声样本，在保持数据分布的同时提升可解释AI模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有去噪方法会改变原始数据分布，导致不现实的场景和有偏模型，特别是在可解释AI应用中，其可解释性依赖于底层数据模式的保真度。

Method: DenoGrad框架利用在目标数据上训练的准确深度学习模型的梯度来检测和调整噪声样本，动态修正噪声实例。

Result: 在表格和时间序列数据集上的各种噪声设置下，DenoGrad优于现有去噪策略，是唯一能保持原始数据分布的高质量方法。

Conclusion: DenoGrad通过任务特定的高质量解决方案作为参考，提供了更精确和适应性强的噪声定义，在保持数据分布的同时提高了AI模型的鲁棒性。

Abstract: The performance of Machine Learning (ML) models, particularly those operating within the Interpretable Artificial Intelligence (Interpretable AI) framework, is significantly affected by the presence of noise in both training and production data. Denoising has therefore become a critical preprocessing step, typically categorized into instance removal and instance correction techniques. However, existing correction approaches often degrade performance or oversimplify the problem by altering the original data distribution. This leads to unrealistic scenarios and biased models, which is particularly problematic in contexts where interpretable AI models are employed, as their interpretability depends on the fidelity of the underlying data patterns. In this paper, we argue that defining noise independently of the solution may be ineffective, as its nature can vary significantly across tasks and datasets. Using a task-specific high quality solution as a reference can provide a more precise and adaptable noise definition. To this end, we propose DenoGrad, a novel Gradient-based instance Denoiser framework that leverages gradients from an accurate Deep Learning (DL) model trained on the target data -- regardless of the specific task -- to detect and adjust noisy samples. Unlike conventional approaches, DenoGrad dynamically corrects noisy instances, preserving problem's data distribution, and improving AI models robustness. DenoGrad is validated on both tabular and time series datasets under various noise settings against the state-of-the-art. DenoGrad outperforms existing denoising strategies, enhancing the performance of interpretable IA models while standing out as the only high quality approach that preserves the original data distribution.

</details>


### [14] [Two Constraint Compilation Methods for Lifted Planning](https://arxiv.org/abs/2511.10164)
*Periklis Mantenoglou,Luigi Bonassi,Enrico Scala,Pedro Zuidberg Dos Martires*

Main category: cs.AI

TL;DR: 本文研究了带有定性状态轨迹约束的PDDL片段规划问题，提出了两种无需基础化（grounding）的约束编译方法，解决了大规模规划问题中现有编译方法无法扩展的问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界规划问题通常包含安全性要求、任务排序条件和中间子目标等定性状态轨迹约束。现有方法需要先对问题进行基础化再编译约束，这在对象数量和动作元数较大时无法扩展。

Method: 提出了两种无需基础化的约束编译方法，直接将约束编译为支持现代规划器的规划规范，避免了基础化过程。

Result: 实验证明新方法高效且产生的规划规范比基础化编译方法简洁数个数量级，在使用现代规划器时仍保持竞争力。

Conclusion: 提出的无基础化约束编译方法能够有效处理大规模规划问题，在保持性能的同时显著减少了规划规范的规模。

Abstract: We study planning in a fragment of PDDL with qualitative state-trajectory constraints, capturing safety requirements, task ordering conditions, and intermediate sub-goals commonly found in real-world problems. A prominent approach to tackle such problems is to compile their constraints away, leading to a problem that is supported by state-of-the-art planners. Unfortunately, existing compilers do not scale on problems with a large number of objects and high-arity actions, as they necessitate grounding the problem before compilation. To address this issue, we propose two methods for compiling away constraints without grounding, making them suitable for large-scale planning problems. We prove the correctness of our compilers and outline their worst-case time complexity. Moreover, we present a reproducible empirical evaluation on the domains used in the latest International Planning Competition. Our results demonstrate that our methods are efficient and produce planning specifications that are orders of magnitude more succinct than the ones produced by compilers that ground the domain, while remaining competitive when used for planning with a state-of-the-art planner.

</details>


### [15] [ProgRAG: Hallucination-Resistant Progressive Retrieval and Reasoning over Knowledge Graphs](https://arxiv.org/abs/2511.10240)
*Minbae Park,Hyemin Yang,Jeonghyun Kim,Kunsoo Park,Hyunjoon Kim*

Main category: cs.AI

TL;DR: ProgRAG是一个多跳知识图谱问答框架，通过将复杂问题分解为子问题并逐步扩展推理路径来解决LLM在知识图谱推理中的检索和推理失败问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推理方面表现出色，但存在幻觉和透明度有限的问题。虽然知识图谱增强的LLM提高了推理性能，但仍面临检索不准确、推理失败等挑战，特别是在长输入上下文和复杂逻辑方向的情况下。

Method: ProgRAG将复杂问题分解为子问题，逐步扩展部分推理路径，在每个步骤中使用外部检索器收集候选证据，并通过LLM进行不确定性感知剪枝，最后优化LLM推理的上下文组织。

Result: 在三个知名数据集上的实验表明，ProgRAG在多跳知识图谱问答任务中优于现有基线方法，提供了更好的可靠性和推理质量。

Conclusion: ProgRAG通过渐进式推理路径扩展和不确定性感知证据剪枝，有效解决了知识图谱增强LLM中的检索和推理失败问题，显著提升了多跳知识图谱问答的性能。

Abstract: Large Language Models (LLMs) demonstrate strong reasoning capabilities but struggle with hallucinations and limited transparency. Recently, KG-enhanced LLMs that integrate knowledge graphs (KGs) have been shown to improve reasoning performance, particularly for complex, knowledge-intensive tasks. However, these methods still face significant challenges, including inaccurate retrieval and reasoning failures, often exacerbated by long input contexts that obscure relevant information or by context constructions that struggle to capture the richer logical directions required by different question types. Furthermore, many of these approaches rely on LLMs to directly retrieve evidence from KGs, and to self-assess the sufficiency of this evidence, which often results in premature or incorrect reasoning. To address the retrieval and reasoning failures, we propose ProgRAG, a multi-hop knowledge graph question answering (KGQA) framework that decomposes complex questions into sub-questions, and progressively extends partial reasoning paths by answering each sub-question. At each step, external retrievers gather candidate evidence, which is then refined through uncertainty-aware pruning by the LLM. Finally, the context for LLM reasoning is optimized by organizing and rearranging the partial reasoning paths obtained from the sub-question answers. Experiments on three well-known datasets demonstrate that ProgRAG outperforms existing baselines in multi-hop KGQA, offering improved reliability and reasoning quality.

</details>


### [16] [Bidirectional Bounded-Suboptimal Heuristic Search with Consistent Heuristics](https://arxiv.org/abs/2511.10272)
*Shahaf S. Shperberg,Natalie Morad,Lior Siag,Ariel Felner,Dor Atzmon*

Main category: cs.AI

TL;DR: 本文基于最优双向搜索算法BAE*，开发了多个有界次优双向搜索变体，并在实验中与现有算法进行比较，发现不同算法在不同条件下各有优势。


<details>
  <summary>Details</summary>
Motivation: 现有双向启发式搜索研究主要关注最优搜索，本文旨在探索有界次优双向搜索，即在指定解成本次优性边界的情况下进行搜索。

Method: 基于最优双向搜索算法BAE*（适用于一致启发式），开发了多个专门针对有界次优场景的BAE*变体算法。

Result: 实验评估表明，新算法与其他有界次优双向算法以及标准加权A*算法相比，每种算法在不同条件下表现最佳，突显了各自方法的优缺点。

Conclusion: 不同有界次优双向搜索算法在不同场景下具有各自的优势，没有单一算法在所有条件下都表现最优。

Abstract: Recent advancements in bidirectional heuristic search have yielded significant theoretical insights and novel algorithms. While most previous work has concentrated on optimal search methods, this paper focuses on bounded-suboptimal bidirectional search, where a bound on the suboptimality of the solution cost is specified. We build upon the state-of-the-art optimal bidirectional search algorithm, BAE*, designed for consistent heuristics, and introduce several variants of BAE* specifically tailored for the bounded-suboptimal context. Through experimental evaluation, we compare the performance of these new variants against other bounded-suboptimal bidirectional algorithms as well as the standard weighted A* algorithm. Our results demonstrate that each algorithm excels under distinct conditions, highlighting the strengths and weaknesses of each approach.

</details>


### [17] [FactGuard: Event-Centric and Commonsense-Guided Fake News Detection](https://arxiv.org/abs/2511.10281)
*Jing He,Han Zhang,Yuanhui Xiao,Wei Guo,Shaowen Yao,Renyang Liu*

Main category: cs.AI

TL;DR: FactGuard是一个利用大语言模型提取事件中心内容来减少写作风格影响的假新闻检测框架，通过动态可用性机制和知识蒸馏提高检测的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 随着攻击者模仿真实新闻风格，基于写作风格的假新闻检测方法效果逐渐下降，而现有LLM方法存在功能探索浅、可用性模糊和推理成本高等问题。

Method: 提出FactGuard框架：1）利用LLM提取事件中心内容减少风格影响；2）引入动态可用性机制识别矛盾案例；3）通过知识蒸馏得到FactGuard-D用于冷启动和资源受限场景。

Result: 在两个基准数据集上的综合实验表明，该方法在鲁棒性和准确性上持续优于现有方法，有效解决了风格敏感性和LLM可用性问题。

Conclusion: FactGuard框架通过事件内容提取和动态可用性机制，成功提升了假新闻检测的性能，同时通过知识蒸馏确保了实际部署的可行性。

Abstract: Fake news detection methods based on writing style have achieved remarkable progress. However, as adversaries increasingly imitate the style of authentic news, the effectiveness of such approaches is gradually diminishing. Recent research has explored incorporating large language models (LLMs) to enhance fake news detection. Yet, despite their transformative potential, LLMs remain an untapped goldmine for fake news detection, with their real-world adoption hampered by shallow functionality exploration, ambiguous usability, and prohibitive inference costs. In this paper, we propose a novel fake news detection framework, dubbed FactGuard, that leverages LLMs to extract event-centric content, thereby reducing the impact of writing style on detection performance. Furthermore, our approach introduces a dynamic usability mechanism that identifies contradictions and ambiguous cases in factual reasoning, adaptively incorporating LLM advice to improve decision reliability. To ensure efficiency and practical deployment, we employ knowledge distillation to derive FactGuard-D, enabling the framework to operate effectively in cold-start and resource-constrained scenarios. Comprehensive experiments on two benchmark datasets demonstrate that our approach consistently outperforms existing methods in both robustness and accuracy, effectively addressing the challenges of style sensitivity and LLM usability in fake news detection.

</details>


### [18] [Beyond Verification: Abductive Explanations for Post-AI Assessment of Privacy Leakage](https://arxiv.org/abs/2511.10284)
*Belona Sonna,Alban Grastien,Claire Benn*

Main category: cs.AI

TL;DR: 提出基于溯因解释的隐私泄露审计框架，通过识别模型决策的最小充分证据来检测敏感信息泄露，在德国信用数据集上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: AI决策过程中的隐私泄露风险日益严重，需要能够检测敏感信息推断的审计工具，同时保持解释的可理解性。

Method: 使用溯因解释框架，定义个体和系统级隐私泄露，引入潜在适用解释(PAE)概念来识别能够保护敏感特征个体的结果。

Result: 在德国信用数据集上的实验表明，敏感文字在模型决策过程中的重要性会影响隐私泄露程度，溯因推理能够实现可解释的隐私审计。

Conclusion: 尽管存在计算挑战和简化假设，该方法为协调AI决策中的透明度、模型可解释性和隐私保护提供了实用途径。

Abstract: Privacy leakage in AI-based decision processes poses significant risks, particularly when sensitive information can be inferred. We propose a formal framework to audit privacy leakage using abductive explanations, which identifies minimal sufficient evidence justifying model decisions and determines whether sensitive information disclosed. Our framework formalizes both individual and system-level leakage, introducing the notion of Potentially Applicable Explanations (PAE) to identify individuals whose outcomes can shield those with sensitive features. This approach provides rigorous privacy guarantees while producing human understandable explanations, a key requirement for auditing tools. Experimental evaluation on the German Credit Dataset illustrates how the importance of sensitive literal in the model decision process affects privacy leakage. Despite computational challenges and simplifying assumptions, our results demonstrate that abductive reasoning enables interpretable privacy auditing, offering a practical pathway to reconcile transparency, model interpretability, and privacy preserving in AI decision-making.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [19] [Let the Experts Speak: Improving Survival Prediction & Calibration via Mixture-of-Experts Heads](https://arxiv.org/abs/2511.09567)
*Todd Morrill,Aahlad Puli,Murad Megjhani,Soojin Park,Richard Zemel*

Main category: cs.LG

TL;DR: 本文提出了几种基于深度混合专家模型的离散时间生存分析架构，其中一个模型能够同时实现聚类、校准和预测准确性的目标。研究发现，更具表达力的专家模型能够为每个患者定制预测，优于依赖固定组原型的专家模型。


<details>
  <summary>Details</summary>
Motivation: 传统混合专家模型在生存分析中虽然能够聚类相似患者，但往往以牺牲校准误差和预测准确性为代价。本文旨在探索是否能在发现患者群体结构的同时，提高校准和预测准确性。

Method: 引入了多种基于离散时间深度混合专家模型的生存分析架构，通过比较不同表达力水平的专家模型来评估性能。

Result: 研究发现，更具表达力的专家模型能够为每个患者定制预测，在保持聚类能力的同时显著提高了校准和预测准确性。其中一个特定架构成功实现了所有期望目标。

Conclusion: 在生存分析中，使用更具表达力的专家模型能够同时实现患者聚类、校准和预测准确性的目标，优于依赖固定组原型的传统方法。

Abstract: Deep mixture-of-experts models have attracted a lot of attention for survival analysis problems, particularly for their ability to cluster similar patients together. In practice, grouping often comes at the expense of key metrics such calibration error and predictive accuracy. This is due to the restrictive inductive bias that mixture-of-experts imposes, that predictions for individual patients must look like predictions for the group they're assigned to. Might we be able to discover patient group structure, where it exists, while improving calibration and predictive accuracy? In this work, we introduce several discrete-time deep mixture-of-experts (MoE) based architectures for survival analysis problems, one of which achieves all desiderata: clustering, calibration, and predictive accuracy. We show that a key differentiator between this array of MoEs is how expressive their experts are. We find that more expressive experts that tailor predictions per patient outperform experts that rely on fixed group prototypes.

</details>


### [20] [Group Averaging for Physics Applications: Accuracy Improvements at Zero Training Cost](https://arxiv.org/abs/2511.09573)
*Valentino F. Foit,David W. Hogg,Soledad Villar*

Main category: cs.LG

TL;DR: 本文提出使用群平均技术使机器学习模型在测试时具有精确的对称性，通过在评估时对模型在小对称群上进行平均，能够显著提高预测精度，且无需改变模型结构或训练过程。


<details>
  <summary>Details</summary>
Motivation: 许多自然科学中的机器学习任务具有特定的对称性，但等变方法往往未被采用，可能是因为训练困难、期望模型自行学习对称性，或等变实现被认为难以构建。群平均技术为解决这些问题提供了可行方案。

Method: 采用群平均技术，在测试时对已训练的模型在小对称群上进行平均，使模型具有精确的对称性。该方法不要求模型结构或训练过程的改变，计算成本与群大小成正比。

Result: 实验表明，群平均过程总是降低平均评估损失，在VRMSE指标上改进高达37%。对于连续动力学问题，平均后的预测在视觉上表现更好。

Conclusion: 在常见情况下，施加精确对称性没有缺点；ML4PS社区应考虑将群平均作为提高模型精度的廉价简单方法。

Abstract: Many machine learning tasks in the natural sciences are precisely equivariant to particular symmetries. Nonetheless, equivariant methods are often not employed, perhaps because training is perceived to be challenging, or the symmetry is expected to be learned, or equivariant implementations are seen as hard to build. Group averaging is an available technique for these situations. It happens at test time; it can make any trained model precisely equivariant at a (often small) cost proportional to the size of the group; it places no requirements on model structure or training. It is known that, under mild conditions, the group-averaged model will have a provably better prediction accuracy than the original model. Here we show that an inexpensive group averaging can improve accuracy in practice. We take well-established benchmark machine learning models of differential equations in which certain symmetries ought to be obeyed. At evaluation time, we average the models over a small group of symmetries. Our experiments show that this procedure always decreases the average evaluation loss, with improvements of up to 37\% in terms of the VRMSE. The averaging produces visually better predictions for continuous dynamics. This short paper shows that, under certain common circumstances, there are no disadvantages to imposing exact symmetries; the ML4PS community should consider group averaging as a cheap and simple way to improve model accuracy.

</details>


### [21] [Making Every Head Count: Sparse Attention Without the Speed-Performance Trade-off](https://arxiv.org/abs/2511.09596)
*Mingkuan Zhao,Wentao Hu,Jiayin Wang,Xin Lai,Tianchen Huang,Yuheng Min,Rui Yan,Xiaoyan Zhu*

Main category: cs.LG

TL;DR: SPAttention通过引入原则性结构稀疏性，将多头注意力计算从H个独立的O(N²)计算转变为单个协作的O(N²)计算，在保持性能的同时显著提升训练效率。


<details>
  <summary>Details</summary>
Motivation: 解决LLM核心注意力机制中计算复杂度O(H·N²)与计算冗余之间的根本冲突，现有稀疏方法往往以信息完整性换取计算效率。

Method: 采用原则性结构稀疏性范式，将总注意力工作负载划分为平衡的非重叠距离带，为每个头分配独特片段，强制头部功能专业化。

Result: 在OLMoE-1B-7B和0.25B-1.75B模型系列上验证，训练吞吐量提升约2倍，性能与标准密集注意力相当甚至在某些关键指标上超越，且在所有评估指标上持续优于代表性稀疏注意力方法。

Conclusion: SPAttention通过结构化的归纳偏置实现了计算效率与性能的良好平衡，为LLM设计提供了新的高效注意力范式。

Abstract: The design of Large Language Models (LLMs) has long been hampered by a fundamental conflict within their core attention mechanism: its remarkable expressivity is built upon a computational complexity of $O(H \cdot N^2)$ that grows quadratically with the context size ($N$) and linearly with the number of heads ($H$). This standard implementation harbors significant computational redundancy, as all heads independently compute attention over the same sequence space. Existing sparse methods, meanwhile, often trade information integrity for computational efficiency. To resolve this efficiency-performance trade-off, we propose SPAttention, whose core contribution is the introduction of a new paradigm we term Principled Structural Sparsity. SPAttention does not merely drop connections but instead reorganizes the computational task by partitioning the total attention workload into balanced, non-overlapping distance bands, assigning each head a unique segment. This approach transforms the multi-head attention mechanism from $H$ independent $O(N^2)$ computations into a single, collaborative $O(N^2)$ computation, fundamentally reducing complexity by a factor of $H$. The structured inductive bias compels functional specialization among heads, enabling a more efficient allocation of computational resources from redundant modeling to distinct dependencies across the entire sequence span. Extensive empirical validation on the OLMoE-1B-7B and 0.25B-1.75B model series demonstrates that while delivering an approximately two-fold increase in training throughput, its performance is on par with standard dense attention, even surpassing it on select key metrics, while consistently outperforming representative sparse attention methods including Longformer, Reformer, and BigBird across all evaluation metrics.

</details>


### [22] [Optimistic Reinforcement Learning with Quantile Objectives](https://arxiv.org/abs/2511.09652)
*Mohammad Alipour-Vaezi,Huaiyang Zhong,Kwok-Leung Tsui,Sajad Khodadadian*

Main category: cs.LG

TL;DR: 本文提出了UCB-QRL算法，用于在有限时域马尔可夫决策过程中优化累积奖励分布的特定分位数目标，解决了传统强化学习缺乏风险敏感性的问题。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习的目标函数缺乏风险敏感性，这在医疗和金融等领域至关重要。通过优化累积奖励分布的特定分位数，可以更好地处理风险敏感问题。

Method: 开发了UCB-QRL算法，这是一种迭代算法，在每次迭代中首先估计转移概率，然后在置信区间内优化分位数价值函数。

Result: UCB-QRL在情景设置中实现了高概率遗憾边界$\mathcal O\left((2/κ)^{H+1}H\sqrt{SATH\log(2SATH/δ)}\right)$，其中κ是问题相关的常数，反映了MDP分位数价值的敏感性。

Conclusion: UCB-QRL算法为风险敏感的强化学习提供了一种有效的解决方案，能够在有限时域MDP中优化分位数目标，并具有理论保证的性能边界。

Abstract: Reinforcement Learning (RL) has achieved tremendous success in recent years. However, the classical foundations of RL do not account for the risk sensitivity of the objective function, which is critical in various fields, including healthcare and finance. A popular approach to incorporate risk sensitivity is to optimize a specific quantile of the cumulative reward distribution. In this paper, we develop UCB-QRL, an optimistic learning algorithm for the $τ$-quantile objective in finite-horizon Markov decision processes (MDPs). UCB-QRL is an iterative algorithm in which, at each iteration, we first estimate the underlying transition probability and then optimize the quantile value function over a confidence ball around this estimate. We show that UCB-QRL yields a high-probability regret bound $\mathcal O\left((2/κ)^{H+1}H\sqrt{SATH\log(2SATH/δ)}\right)$ in the episodic setting with $S$ states, $A$ actions, $T$ episodes, and $H$ horizons. Here, $κ>0$ is a problem-dependent constant that captures the sensitivity of the underlying MDP's quantile value.

</details>


### [23] [ConstrainedSQL: Training LLMs for Text2SQL via Constrained Reinforcement Learning](https://arxiv.org/abs/2511.09693)
*Weiqin Chen,Nhan Huu Pham,Michael Robert Glass,Long Hai Vu,Gaetano Rossiello,Dharmashankar Subramanian,Santiago Paternain*

Main category: cs.LG

TL;DR: 本文提出了一种用于Text2SQL的约束强化学习框架，通过引入自然且可解释的奖励和约束信号，并动态平衡它们之间的权衡，解决了传统RL方法中奖励函数设计敏感和奖励黑客问题。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法在提升Text2SQL LLMs推理能力时，性能高度依赖于奖励函数设计，不适当的奖励会导致奖励黑客问题，即模型利用奖励结构漏洞获得高分而非真正解决问题。

Method: 采用约束强化学习框架，结合自然可解释的奖励和约束信号，在训练过程中动态平衡它们之间的权衡关系。

Result: 建立了约束强化学习框架的理论保证，在知名Text2SQL数据集上的数值实验证实了该方法相对于最先进的RL训练LLMs的改进。

Conclusion: 提出的约束RL框架有效解决了Text2SQL中奖励黑客问题，通过理论保证和实验验证了其优于现有RL方法的性能。

Abstract: Reinforcement learning (RL) has demonstrated significant promise in enhancing the reasoning capabilities of Text2SQL LLMs, especially with advanced algorithms such as GRPO and DAPO. However, the performance of these methods is highly sensitive to the design of reward functions. Inappropriate rewards can lead to reward hacking, where models exploit loopholes in the reward structure to achieve high scores without genuinely solving the task. This work considers a constrained RL framework for Text2SQL that incorporates natural and interpretable reward and constraint signals, while dynamically balancing trade-offs among them during the training. We establish the theoretical guarantees of our constrained RL framework and our numerical experiments on the well-known Text2SQL datasets substantiate the improvement of our approach over the state-of-the-art RL-trained LLMs.

</details>


### [24] [TawPipe: Topology-Aware Weight Pipeline Parallelism for Accelerating Long-Context Large Models Training](https://arxiv.org/abs/2511.09741)
*Houming Wu,Ling Chen*

Main category: cs.LG

TL;DR: TawPipe是一种拓扑感知的权重管道并行方法，通过利用分布式集群中的分层带宽来优化通信效率，在长上下文训练中显著提升吞吐量和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型训练受限于设备内存和昂贵的设备间通信。虽然管道并行通过跨设备划分模型来缓解内存压力，但会带来随序列长度线性增长的激活通信开销。现有的权重传递方法（如WeiPipe）虽然通过传输模型权重而非激活来缓解这一问题，但存在冗余的点对点传输和未充分利用的节点内带宽问题。

Method: TawPipe采用拓扑感知的权重管道并行方法：1）基于拓扑对设备进行分组，优化节点内集体通信和节点间点对点通信；2）为每个设备分配固定的模型权重和梯度分片，避免冗余传输；3）通过通信与计算重叠来隐藏延迟。与FSDP使用的全局集体操作不同，TawPipe将大部分通信限制在节点边界内。

Result: 在最多24个GPU上使用LLaMA风格模型进行的广泛实验表明，TawPipe相比最先进的基线方法实现了更优的吞吐量和可扩展性。

Conclusion: TawPipe通过利用分布式集群的拓扑结构，有效减少了跨节点通信流量，在大语言模型训练中提供了更高的通信效率和性能表现。

Abstract: Training large language models (LLMs) is fundamentally constrained by limited device memory and costly inter-device communication. Although pipeline parallelism alleviates memory pressure by partitioning models across devices, it incurs activation communication overhead that scales linearly with sequence length, limiting efficiency in long-context training. Recent weight-passing approaches (e.g., WeiPipe) mitigate this by transmitting model weights instead of activations, but suffer from redundant peer-to-peer (P2P) transfers and underutilized intra-node bandwidth. We propose TawPipe--topology-aware weight pipeline parallelism, which exploits hierarchical bandwidth in distributed clusters for improved communication efficiency. TawPipe: (i) groups devices based on topology to optimize intra-node collective and inter-node P2P communication; (ii) assigns each device a fixed shard of model weights and gradients, avoiding redundant transfers; and (iii) overlaps communication with computation to hide latency. Unlike global collective operations used in fully sharded data parallelism (FSDP), TawPipe confines most communication within node boundaries, significantly reducing cross-node traffic. Extensive experiments on up to 24 GPUs with LLaMA-style models show that TawPipe achieves superior throughput and scalability compared to state-of-the-art baselines.

</details>


### [25] [History Rhymes: Macro-Contextual Retrieval for Robust Financial Forecasting](https://arxiv.org/abs/2511.09754)
*Sarthak Khanna,Armin Berger,Muskaan Chopra,Rafet Sifa*

Main category: cs.LG

TL;DR: 提出了一个基于宏观情境检索的金融预测框架，通过检索历史上类似的宏观经济情境来增强预测的稳健性，在分布外测试中显著优于传统多模态方法。


<details>
  <summary>Details</summary>
Motivation: 金融市场本质上是非平稳的，结构性断裂和宏观经济体制转变常常导致预测模型在分布外部署时失效。传统的多模态方法简单融合数值指标和文本情感，很少能适应这种转变。

Method: 引入宏观情境检索框架，将宏观指标（如CPI、失业率、收益率利差、GDP增长）和金融新闻情感共同嵌入共享相似性空间，实现推理过程中无需重新训练即可因果检索历史类似时期。

Result: 在17年标普500数据上训练，并在AAPL和XOM上进行分布外评估，该框架持续缩小了CV到OOD性能差距。宏观条件检索实现了唯一正面的样本外交易结果（AAPL：PF=1.18，Sharpe=0.95；XOM：PF=1.16，Sharpe=0.61）。

Conclusion: 通过操作"金融历史可能不会重演，但常常押韵"的原则，这项工作证明宏观感知检索在分布变化下产生稳健、可解释的预测，检索到的邻居形成可解释的证据链，对应可识别的宏观情境。

Abstract: Financial markets are inherently non-stationary: structural breaks and macroeconomic regime shifts often cause forecasting models to fail when deployed out of distribution (OOD). Conventional multimodal approaches that simply fuse numerical indicators and textual sentiment rarely adapt to such shifts. We introduce macro-contextual retrieval, a retrieval-augmented forecasting framework that grounds each prediction in historically analogous macroeconomic regimes. The method jointly embeds macro indicators (e.g., CPI, unemployment, yield spread, GDP growth) and financial news sentiment in a shared similarity space, enabling causal retrieval of precedent periods during inference without retraining.
  Trained on seventeen years of S&P 500 data (2007-2023) and evaluated OOD on AAPL (2024) and XOM (2024), the framework consistently narrows the CV to OOD performance gap. Macro-conditioned retrieval achieves the only positive out-of-sample trading outcomes (AAPL: PF=1.18, Sharpe=0.95; XOM: PF=1.16, Sharpe=0.61), while static numeric, text-only, and naive multimodal baselines collapse under regime shifts. Beyond metric gains, retrieved neighbors form interpretable evidence chains that correspond to recognizable macro contexts, such as inflationary or yield-curve inversion phases, supporting causal interpretability and transparency. By operationalizing the principle that "financial history may not repeat, but it often rhymes," this work demonstrates that macro-aware retrieval yields robust, explainable forecasts under distributional change.
  All datasets, models, and source code are publicly available.

</details>


### [26] [Is nasty noise actually harder than malicious noise?](https://arxiv.org/abs/2511.09763)
*Guy Blanc,Yizhi Huang,Tal Malkin,Rocco A. Servedio*

Main category: cs.LG

TL;DR: 本文研究了布尔函数学习中两种对抗性噪声模型（恶意噪声和恶意噪声）下计算高效算法的能力和局限性。在分布无关设置中，两种噪声模型具有强等价性；在固定分布设置中，存在任意大的分离。作者还定义了忽略矛盾示例（ICE）的算法类，证明在这类算法中两种噪声模型在噪声率上等价于2倍因子。


<details>
  <summary>Details</summary>
Motivation: 研究计算高效算法在对抗性噪声环境下的学习能力，特别关注恶意噪声和恶意噪声这两种具有挑战性的噪声模型，探索它们在不同学习设置下的相对能力和局限性。

Method: 采用理论分析和证明方法，分别在分布无关和固定分布两种设置下比较恶意噪声和恶意噪声模型。定义了忽略矛盾示例（ICE）的算法类，并分析其在不同噪声模型下的表现。

Result: 1. 分布无关设置中：恶意噪声和恶意噪声具有强等价性；2. 固定分布设置中：存在任意大的分离（基于密码学假设）；3. ICE算法类中：两种噪声模型在噪声率上等价于2倍因子，且该因子是必要的。

Conclusion: 学习设置对噪声模型的相对难度有显著影响：分布无关设置中两种噪声模型等价，固定分布设置中存在显著分离。ICE算法为固定分布设置提供了实用的解决方案，在两种噪声模型间建立了紧密联系。

Abstract: We consider the relative abilities and limitations of computationally efficient algorithms for learning in the presence of noise, under two well-studied and challenging adversarial noise models for learning Boolean functions: malicious noise, in which an adversary can arbitrarily corrupt a random subset of examples given to the learner; and nasty noise, in which an adversary can arbitrarily corrupt an adversarially chosen subset of examples given to the learner.
  We consider both the distribution-independent and fixed-distribution settings. Our main results highlight a dramatic difference between these two settings: For distribution-independent learning, we prove a strong equivalence between the two noise models: If a class ${\cal C}$ of functions is efficiently learnable in the presence of $η$-rate malicious noise, then it is also efficiently learnable in the presence of $η$-rate nasty noise. In sharp contrast, for the fixed-distribution setting we show an arbitrarily large separation: Under a standard cryptographic assumption, for any arbitrarily large value $r$ there exists a concept class for which there is a ratio of $r$ between the rate $η_{malicious}$ of malicious noise that polynomial-time learning algorithms can tolerate, versus the rate $η_{nasty}$ of nasty noise that such learning algorithms can tolerate.
  To offset the negative result for the fixed-distribution setting, we define a broad and natural class of algorithms, namely those that ignore contradictory examples (ICE). We show that for these algorithms, malicious noise and nasty noise are equivalent up to a factor of two in the noise rate: Any efficient ICE learner that succeeds with $η$-rate malicious noise can be converted to an efficient learner that succeeds with $η/2$-rate nasty noise. We further show that the above factor of two is necessary, again under a standard cryptographic assumption.

</details>


### [27] [Hail to the Thief: Exploring Attacks and Defenses in Decentralised GRPO](https://arxiv.org/abs/2511.09780)
*Nikolay Blagoev,Oğuzhan Ersoy,Lydia Yiyu Chen*

Main category: cs.LG

TL;DR: 本文提出了针对去中心化GRPO训练的首个对抗攻击方法，展示了恶意节点可以通过注入恶意令牌来毒化良性模型，在数学和编程任务中攻击成功率可达100%，并提出了两种防御方案。


<details>
  <summary>Details</summary>
Motivation: GRPO在大型语言模型后训练中应用广泛，其去中心化特性使得多个节点可以并发处理提示并交换字符串。然而，这种架构存在安全风险，恶意方可能通过注入恶意令牌来毒化系统，因此需要研究对抗攻击及其防御方法。

Method: 提出了针对去中心化GRPO的对抗攻击方法，包括上下文外攻击和上下文内攻击。恶意节点通过在良性模型中注入任意恶意令牌来污染本地LLM后训练过程。

Result: 在数学和编程任务的实证实验中，对抗攻击能够轻松毒化良性节点，在仅50次迭代内攻击成功率可达100%。

Conclusion: 提出了两种防御方案：当所有用户训练相同模型时和训练不同模型时的防御策略。这些防御措施可以达到100%的阻止率，使攻击无法成功。

Abstract: Group Relative Policy Optimization (GRPO) has demonstrated great utilization in post-training of Large Language Models (LLMs). In GRPO, prompts are answered by the model and, through reinforcement learning, preferred completions are learnt. Owing to the small communication volume, GRPO is inherently suitable for decentralised training as the prompts can be concurrently answered by multiple nodes and then exchanged in the forms of strings. In this work, we present the first adversarial attack in decentralised GRPO. We demonstrate that malicious parties can poison such systems by injecting arbitrary malicious tokens in benign models in both out-of-context and in-context attacks. Using empirical examples of math and coding tasks, we show that adversarial attacks can easily poison the benign nodes, polluting their local LLM post-training, achieving attack success rates up to 100% in as few as 50 iterations. We propose two ways to defend against these attacks, depending on whether all users train the same model or different models. We show that these defenses can achieve stop rates of up to 100%, making the attack impossible.

</details>


### [28] [Koopman Invariants as Drivers of Emergent Time-Series Clustering in Joint-Embedding Predictive Architectures](https://arxiv.org/abs/2511.09783)
*Pablo Ruiz-Morales,Dries Vanoost,Davy Pissoort,Mathias Verbeke*

Main category: cs.LG

TL;DR: 本文提出了一种理论解释，说明联合嵌入预测架构（JEPA）如何通过其预测目标隐式学习系统Koopman算子的不变子空间，从而能够对时间序列数据进行动态机制聚类。


<details>
  <summary>Details</summary>
Motivation: JEPA作为一类强大的自监督模型，表现出对时间序列数据按底层动态机制进行聚类的未解释能力，本文旨在从理论上解释这一现象。

Method: 通过理论证明理想化JEPA损失最小化时编码器表示系统的机制指示函数（即Koopman特征函数），并在已知动态的合成数据上进行验证，特别关注线性预测器约束为近恒等算子的关键归纳偏置。

Result: 验证了约束JEPA的线性预测器为近恒等算子是迫使编码器学习不变量的关键归纳偏置，并揭示了预测器在表示解纠缠中的作用。

Conclusion: 这项工作阐明了JEPA的关键行为，为现代自监督学习与动态系统理论提供了原则性联系，并为设计更鲁棒和可解释的时间序列模型提供了指导。

Abstract: Joint-Embedding Predictive Architectures (JEPAs), a powerful class of self-supervised models, exhibit an unexplained ability to cluster time-series data by their underlying dynamical regimes. We propose a novel theoretical explanation for this phenomenon, hypothesizing that JEPA's predictive objective implicitly drives it to learn the invariant subspace of the system's Koopman operator. We prove that an idealized JEPA loss is minimized when the encoder represents the system's regime indicator functions, which are Koopman eigenfunctions. This theory was validated on synthetic data with known dynamics, demonstrating that constraining the JEPA's linear predictor to be a near-identity operator is the key inductive bias that forces the encoder to learn these invariants. We further discuss that this constraint is critical for selecting this interpretable solution from a class of mathematically equivalent but entangled optima, revealing the predictor's role in representation disentanglement. This work demystifies a key behavior of JEPAs, provides a principled connection between modern self-supervised learning and dynamical systems theory, and informs the design of more robust and interpretable time-series models.

</details>


### [29] [CaReTS: A Multi-Task Framework Unifying Classification and Regression for Time Series Forecasting](https://arxiv.org/abs/2511.09789)
*Fulong Yao,Wanqing Zhao,Chao Zheng,Xiaofei Han*

Main category: cs.LG

TL;DR: CaReTS是一个新颖的多任务学习框架，通过结合分类和回归任务来解决多步时间序列预测问题，采用双流架构分别学习趋势和偏差，提供更可解释的预测结果。


<details>
  <summary>Details</summary>
Motivation: 现有深度预测模型虽然性能优异，但难以同时提供准确预测和时间动态的可解释性洞察。

Method: 采用双流架构：分类分支学习未来逐步趋势，回归分支估计目标变量最新观测值的偏差；设计多任务损失函数进行不确定性感知加权；基于主流时序建模编码器（CNN、LSTM、Transformer）实例化四个变体。

Result: 在真实世界数据集上的实验表明，CaReTS在预测准确性上优于最先进算法，同时实现了更高的趋势分类性能。

Conclusion: CaReTS框架通过解耦宏观趋势和微观偏差，能够提供更准确且可解释的时间序列预测。

Abstract: Recent advances in deep forecasting models have achieved remarkable performance, yet most approaches still struggle to provide both accurate predictions and interpretable insights into temporal dynamics. This paper proposes CaReTS, a novel multi-task learning framework that combines classification and regression tasks for multi-step time series forecasting problems. The framework adopts a dual-stream architecture, where a classification branch learns the stepwise trend into the future, while a regression branch estimates the corresponding deviations from the latest observation of the target variable. The dual-stream design provides more interpretable predictions by disentangling macro-level trends from micro-level deviations in the target variable. To enable effective learning in output prediction, deviation estimation, and trend classification, we design a multi-task loss with uncertainty-aware weighting to adaptively balance the contribution of each task. Furthermore, four variants (CaReTS1--4) are instantiated under this framework to incorporate mainstream temporal modelling encoders, including convolutional neural networks (CNNs), long short-term memory networks (LSTMs), and Transformers. Experiments on real-world datasets demonstrate that CaReTS outperforms state-of-the-art (SOTA) algorithms in forecasting accuracy, while achieving higher trend classification performance.

</details>


### [30] [Beyond Monotonicity: Revisiting Factorization Principles in Multi-Agent Q-Learning](https://arxiv.org/abs/2511.09792)
*Tianmeng Hu,Yongzheng Cui,Rui Tang,Biao Luo,Ke Li*

Main category: cs.LG

TL;DR: 本文通过动力系统分析证明，在近似贪婪探索下，非单调值分解能够可靠地恢复IGM最优解，并在MARL基准测试中持续优于单调基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有值分解方法要么施加单调性约束限制表达能力，要么采用软替代方案增加算法复杂度。本文旨在研究非单调值分解的动力学特性，探索无约束分解的可行性。

Method: 采用动力系统分析方法，将学习动态建模为连续时间梯度流，证明在近似贪婪探索下，违反IGM一致性的零损失平衡点是不稳定鞍点，而IGM一致解是稳定吸引子。

Result: 在合成矩阵游戏和挑战性MARL基准测试上的广泛实验表明，无约束非单调分解能够可靠恢复IGM最优解，并持续优于单调基线方法。

Conclusion: 非单调值分解是可行的，无需施加单调性约束，同时研究了时间差分目标和探索策略的影响，为未来基于值的MARL算法设计提供了可行见解。

Abstract: Value decomposition is a central approach in multi-agent reinforcement learning (MARL), enabling centralized training with decentralized execution by factorizing the global value function into local values. To ensure individual-global-max (IGM) consistency, existing methods either enforce monotonicity constraints, which limit expressive power, or adopt softer surrogates at the cost of algorithmic complexity. In this work, we present a dynamical systems analysis of non-monotonic value decomposition, modeling learning dynamics as continuous-time gradient flow. We prove that, under approximately greedy exploration, all zero-loss equilibria violating IGM consistency are unstable saddle points, while only IGM-consistent solutions are stable attractors of the learning dynamics. Extensive experiments on both synthetic matrix games and challenging MARL benchmarks demonstrate that unconstrained, non-monotonic factorization reliably recovers IGM-optimal solutions and consistently outperforms monotonic baselines. Additionally, we investigate the influence of temporal-difference targets and exploration strategies, providing actionable insights for the design of future value-based MARL algorithms.

</details>


### [31] [Unlearning Imperative: Securing Trustworthy and Responsible LLMs through Engineered Forgetting](https://arxiv.org/abs/2511.09855)
*James Jin Kang,Dang Bui,Thanh Pham,Huo-Chong Ling*

Main category: cs.LG

TL;DR: 本文综述了大型语言模型中的机器遗忘研究，分析了当前方法在保护敏感信息方面的局限性，并探讨了技术和制度层面的解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在敏感领域的广泛应用，确保私人信息能够被永久遗忘的能力存在严重缺陷，现有系统缺乏可靠的机制来保证敏感信息在使用后能够被永久删除。

Method: 本文综述了LLMs机器遗忘的最新研究，评估了遗忘是否发生的验证方法、被遗忘模型对抗攻击的韧性，以及在模型复杂性或专有限制下支持用户信任的机制。

Result: 研究发现技术解决方案如差分隐私、同态加密、联邦学习和短暂记忆等与制度保障包括审计实践和监管框架相结合，取得了稳步进展，但稳健且可验证的遗忘问题仍未解决。

Conclusion: 如果要在敏感应用中安全部署LLMs，需要避免昂贵重新训练的高效技术、更强的对抗恢复防御能力，以及加强问责制的治理结构。通过整合技术和组织视角，本研究为构建能够按要求遗忘同时保持隐私和公众信任的AI系统指明了路径。

Abstract: The growing use of large language models in sensitive domains has exposed a critical weakness: the inability to ensure that private information can be permanently forgotten. Yet these systems still lack reliable mechanisms to guarantee that sensitive information can be permanently removed once it has been used. Retraining from the beginning is prohibitively costly, and existing unlearning methods remain fragmented, difficult to verify, and often vulnerable to recovery. This paper surveys recent research on machine unlearning for LLMs and considers how far current approaches can address these challenges. We review methods for evaluating whether forgetting has occurred, the resilience of unlearned models against adversarial attacks, and mechanisms that can support user trust when model complexity or proprietary limits restrict transparency. Technical solutions such as differential privacy, homomorphic encryption, federated learning, and ephemeral memory are examined alongside institutional safeguards including auditing practices and regulatory frameworks. The review finds steady progress, but robust and verifiable unlearning is still unresolved. Efficient techniques that avoid costly retraining, stronger defenses against adversarial recovery, and governance structures that reinforce accountability are needed if LLMs are to be deployed safely in sensitive applications. By integrating technical and organizational perspectives, this study outlines a pathway toward AI systems that can be required to forget, while maintaining both privacy and public trust.

</details>


### [32] [Towards Multiple Missing Values-resistant Unsupervised Graph Anomaly Detection](https://arxiv.org/abs/2511.09917)
*Jiazhen Chen,Xiuqin Liang,Sichao Fu,Zheng Ma,Weihua Ou*

Main category: cs.LG

TL;DR: M²V-UGAD是一个针对不完整图的无监督异常检测框架，能够处理节点属性和图结构同时缺失的情况，通过双路径编码器独立重建缺失信息，避免交叉视图干扰，并利用硬负例采样缓解插补偏差。


<details>
  <summary>Details</summary>
Motivation: 现有无监督图异常检测方法通常假设节点属性和结构信息完整，但现实场景中数据往往存在缺失。标准插补方法可能修复异常节点使其看起来正常，引入插补偏差，且节点属性和边同时缺失时会产生交叉视图干扰。

Method: 提出双路径编码器独立重建缺失节点属性和图结构；在联合潜在空间中融合和正则化两个路径，使正常节点占据紧凑内流形而异常位于外壳；采样潜在空间正常区域外的代码解码为真实节点特征和子图，提供硬负例以锐化决策边界。

Result: 在七个公共基准测试上的实验表明，M²V-UGAD在不同缺失率下始终优于现有的无监督图异常检测方法。

Conclusion: M²V-UGAD通过独立重建缺失信息、潜在空间正则化和硬负例采样，有效解决了不完整图中的异常检测问题，显著提升了检测性能。

Abstract: Unsupervised graph anomaly detection (GAD) has received increasing attention in recent years, which aims to identify data anomalous patterns utilizing only unlabeled node information from graph-structured data. However, prevailing unsupervised GAD methods typically presuppose complete node attributes and structure information, a condition hardly satisfied in real-world scenarios owing to privacy, collection errors or dynamic node arrivals. Existing standard imputation schemes risk "repairing" rare anomalous nodes so that they appear normal, thereby introducing imputation bias into the detection process. In addition, when both node attributes and edges are missing simultaneously, estimation errors in one view can contaminate the other, causing cross-view interference that further undermines the detection performance. To overcome these challenges, we propose M$^2$V-UGAD, a multiple missing values-resistant unsupervised GAD framework on incomplete graphs. Specifically, a dual-pathway encoder is first proposed to independently reconstruct missing node attributes and graph structure, thereby preventing errors in one view from propagating to the other. The two pathways are then fused and regularized in a joint latent space so that normals occupy a compact inner manifold while anomalies reside on an outer shell. Lastly, to mitigate imputation bias, we sample latent codes just outside the normal region and decode them into realistic node features and subgraphs, providing hard negative examples that sharpen the decision boundary. Experiments on seven public benchmarks demonstrate that M$^2$V-UGAD consistently outperforms existing unsupervised GAD methods across varying missing rates.

</details>


### [33] [MDMLP-EIA: Multi-domain Dynamic MLPs with Energy Invariant Attention for Time Series Forecasting](https://arxiv.org/abs/2511.09924)
*Hu Zhang,Zhien Dai,Zhaohui Tang,Yongfang Xie*

Main category: cs.LG

TL;DR: MDMLP-EIA是一种多域动态MLP模型，通过自适应融合双域季节性MLP、能量不变注意力机制和动态容量调整机制，解决了传统MLP方法在时间序列预测中丢失弱季节性信号、权重共享MLP容量限制和通道融合不足的问题。


<details>
  <summary>Details</summary>
Motivation: MLP方法在时间序列预测中虽然参数少、鲁棒性好，但存在弱季节性信号丢失、权重共享MLP容量限制和通道独立策略中通道融合不足等关键限制。

Method: 1. 自适应融合双域季节性MLP：将季节性信号分为强弱分量，采用自适应零初始化通道融合策略；2. 能量不变注意力机制：自适应关注不同特征通道，保持总信号能量恒定；3. 动态容量调整机制：根据通道数平方根调整神经元数量。

Result: 在九个基准数据集上的广泛实验表明，MDMLP-EIA在预测精度和计算效率方面均达到了最先进的性能。

Conclusion: MDMLP-EIA通过三个关键创新有效解决了MLP方法在时间序列预测中的局限性，实现了优异的预测性能和计算效率。

Abstract: Time series forecasting is essential across diverse domains. While MLP-based methods have gained attention for achieving Transformer-comparable performance with fewer parameters and better robustness, they face critical limitations including loss of weak seasonal signals, capacity constraints in weight-sharing MLPs, and insufficient channel fusion in channel-independent strategies. To address these challenges, we propose MDMLP-EIA (Multi-domain Dynamic MLPs with Energy Invariant Attention) with three key innovations. First, we develop an adaptive fused dual-domain seasonal MLP that categorizes seasonal signals into strong and weak components. It employs an adaptive zero-initialized channel fusion strategy to minimize noise interference while effectively integrating predictions. Second, we introduce an energy invariant attention mechanism that adaptively focuses on different feature channels within trend and seasonal predictions across time steps. This mechanism maintains constant total signal energy to align with the decomposition-prediction-reconstruction framework and enhance robustness against disturbances. Third, we propose a dynamic capacity adjustment mechanism for channel-independent MLPs. This mechanism scales neuron count with the square root of channel count, ensuring sufficient capacity as channels increase. Extensive experiments across nine benchmark datasets demonstrate that MDMLP-EIA achieves state-of-the-art performance in both prediction accuracy and computational efficiency.

</details>


### [34] [Autonomous Concept Drift Threshold Determination](https://arxiv.org/abs/2511.09953)
*Pengqian Lu,Jie Lu,Anjin Liu,En Yu,Guangquan Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种动态阈值确定算法，证明动态调整的检测阈值优于固定阈值，能显著提升现有漂移检测器的性能。


<details>
  <summary>Details</summary>
Motivation: 现有漂移检测方法将检测阈值设为固定超参数，但模型性能对此阈值高度敏感。从机器学习角度看，维持模型性能是关键目标，因此研究动态阈值是否能证明更优。

Method: 基于理论证明，提出动态阈值确定算法，通过新颖的比较阶段增强现有漂移检测框架，指导阈值应如何调整。

Result: 在广泛的合成和真实数据集（包括图像和表格数据）上的大量实验验证，该方法显著提升了最先进漂移检测器的性能。

Conclusion: 动态阈值策略在理论上和实践上都优于固定阈值方法，能有效平衡误报和延迟检测，提升模型性能维护能力。

Abstract: Existing drift detection methods focus on designing sensitive test statistics. They treat the detection threshold as a fixed hyperparameter, set once to balance false alarms and late detections, and applied uniformly across all datasets and over time. However, maintaining model performance is the key objective from the perspective of machine learning, and we observe that model performance is highly sensitive to this threshold. This observation inspires us to investigate whether a dynamic threshold could be provably better. In this paper, we prove that a threshold that adapts over time can outperform any single fixed threshold. The main idea of the proof is that a dynamic strategy, constructed by combining the best threshold from each individual data segment, is guaranteed to outperform any single threshold that apply to all segments. Based on the theorem, we propose a Dynamic Threshold Determination algorithm. It enhances existing drift detection frameworks with a novel comparison phase to inform how the threshold should be adjusted. Extensive experiments on a wide range of synthetic and real-world datasets, including both image and tabular data, validate that our approach substantially enhances the performance of state-of-the-art drift detectors.

</details>


### [35] [Rediscovering the Lunar Equation of the Centre with AI Feynman via Embedded Physical Biases](https://arxiv.org/abs/2511.09979)
*Saumya Shah,Zi-Yu Khoo,Abel Yang,Stéphane Bressan*

Main category: cs.LG

TL;DR: 使用AI Feynman符号回归算法自动重新发现天文学中的中心方程，通过数据预处理和搜索空间限制引入物理偏差，成功恢复该方程的一阶解析形式，但依赖专家驱动的坐标系选择存在局限性。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过物理启发的AI算法自动重新发现天文学中的基本方程，特别是中心方程，以验证符号回归在物理定律发现中的有效性。

Method: 采用AI Feynman符号回归算法，通过数据预处理和搜索空间限制引入观测和归纳偏差，对应系统的物理性质，从月球星历数据中恢复中心方程。

Result: 成功恢复了中心方程的一阶解析形式，但发现依赖专家驱动的坐标系选择是一个关键限制，因此提出了自动预处理扩展来寻找规范坐标系。

Conclusion: 定向领域知识嵌入使符号回归能够重新发现物理定律，但在利用领域知识通过定制偏差推导物理方程时仍面临进一步挑战。

Abstract: This work explores using the physics-inspired AI Feynman symbolic regression algorithm to automatically rediscover a fundamental equation in astronomy -- the Equation of the Centre. Through the introduction of observational and inductive biases corresponding to the physical nature of the system through data preprocessing and search space restriction, AI Feynman was successful in recovering the first-order analytical form of this equation from lunar ephemerides data. However, this manual approach highlights a key limitation in its reliance on expert-driven coordinate system selection. We therefore propose an automated preprocessing extension to find the canonical coordinate system. Results demonstrate that targeted domain knowledge embedding enables symbolic regression to rediscover physical laws, but also highlight further challenges in constraining symbolic regression to derive physics equations when leveraging domain knowledge through tailored biases.

</details>


### [36] [Temporal Latent Variable Structural Causal Model for Causal Discovery under External Interferences](https://arxiv.org/abs/2511.10031)
*Ruichu Cai,Xiaokai Huang,Wei Chen,Zijian Li,Zhifeng Hao*

Main category: cs.LG

TL;DR: 提出了一种新的时态隐变量结构因果模型，通过引入隐变量表示未观测的外部干扰因素，并结合专家知识来指导参数学习，提高了因果推断的稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 从观测数据推断因果关系是重要任务，但当数据受到各种外部干扰时变得困难。这些干扰通常是外部因素对观测变量的额外影响，而外部因素往往未知。

Method: 提出时态隐变量结构因果模型，引入因果强度和邻接系数表示变量间因果关系。基于变分推断开发参数学习方法，支持融入专家先验知识来指导模型估计。

Result: 实验结果表明所提方法具有稳定性和准确性。

Conclusion: 通过引入隐变量表示未观测外部因素，并结合专家知识，能够有效处理受干扰数据的因果推断问题，提高推断性能。

Abstract: Inferring causal relationships from observed data is an important task, yet it becomes challenging when the data is subject to various external interferences. Most of these interferences are the additional effects of external factors on observed variables. Since these external factors are often unknown, we introduce latent variables to represent these unobserved factors that affect the observed data. Specifically, to capture the causal strength and adjacency information, we propose a new temporal latent variable structural causal model, incorporating causal strength and adjacency coefficients that represent the causal relationships between variables. Considering that expert knowledge can provide information about unknown interferences in certain scenarios, we develop a method that facilitates the incorporation of prior knowledge into parameter learning based on Variational Inference, to guide the model estimation. Experimental results demonstrate the stability and accuracy of our proposed method.

</details>


### [37] [RI-Loss: A Learnable Residual-Informed Loss for Time Series Forecasting](https://arxiv.org/abs/2511.10130)
*Jieting Wang,Xiaolei Shang,Feijiang Li,Furong Peng*

Main category: cs.LG

TL;DR: 本文提出了一种基于希尔伯特-施密特独立性准则的残差信息损失函数，通过显式建模噪声结构来改进时间序列预测，解决了传统MSE损失的两个根本弱点。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列预测方法使用均方误差作为损失函数，存在两个根本弱点：逐点误差计算无法捕捉时间关系，且未考虑数据中的固有噪声。

Method: 引入残差信息损失函数，基于希尔伯特-施密特独立性准则，通过强制残差序列与随机时间序列之间的依赖性来显式建模噪声结构。

Result: 在八个真实世界基准测试和五个领先预测模型上的实验表明，该方法显著提高了预测性能。

Conclusion: RI-Loss通过噪声感知表示提供了更稳健的时间序列预测，理论分析提供了严格的优化保证，实证结果验证了方法的有效性。

Abstract: Time series forecasting relies on predicting future values from historical data, yet most state-of-the-art approaches-including transformer and multilayer perceptron-based models-optimize using Mean Squared Error (MSE), which has two fundamental weaknesses: its point-wise error computation fails to capture temporal relationships, and it does not account for inherent noise in the data. To overcome these limitations, we introduce the Residual-Informed Loss (RI-Loss), a novel objective function based on the Hilbert-Schmidt Independence Criterion (HSIC). RI-Loss explicitly models noise structure by enforcing dependence between the residual sequence and a random time series, enabling more robust, noise-aware representations. Theoretically, we derive the first non-asymptotic HSIC bound with explicit double-sample complexity terms, achieving optimal convergence rates through Bernstein-type concentration inequalities and Rademacher complexity analysis. This provides rigorous guarantees for RI-Loss optimization while precisely quantifying kernel space interactions. Empirically, experiments across eight real-world benchmarks and five leading forecasting models demonstrate improvements in predictive performance, validating the effectiveness of our approach. Code will be made publicly available to ensure reproducibility.

</details>


### [38] [Beyond MSE: Ordinal Cross-Entropy for Probabilistic Time Series Forecasting](https://arxiv.org/abs/2511.10200)
*Jieting Wang,Huimei Shi,Feijiang Li,Xiaolei Shang*

Main category: cs.LG

TL;DR: OCE-TS提出了一种基于序数分类的时间序列预测方法，使用序数交叉熵损失替代MSE损失，在保持预测顺序的同时通过概率输出量化不确定性，在多个数据集上优于现有基准模型。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的预测模型主要使用MSE损失函数进行回归建模，但这种方法无法提供不确定性估计，且对异常值鲁棒性差。

Method: 将观测值离散化为有序区间，通过参数分布推导概率作为监督信号；使用简单线性模型预测每个时间步的概率分布；计算预测和真实概率的累积分布之间的OCE损失，明确保持预测值之间的序数关系。

Result: 在7个公共时间序列数据集上与Autoformer、DLinear、iTransformer、TimeXer和TimeBridge等5个基准模型比较，使用MSE和MAE作为评估指标，OCE-TS始终优于基准模型。

Conclusion: 通过影响函数的理论分析表明，交叉熵损失相比MSE损失具有更好的稳定性和异常值鲁棒性；OCE-TS方法在保持预测准确性的同时提供了不确定性量化能力。

Abstract: Time series forecasting is an important task that involves analyzing temporal dependencies and underlying patterns (such as trends, cyclicality, and seasonality) in historical data to predict future values or trends. Current deep learning-based forecasting models primarily employ Mean Squared Error (MSE) loss functions for regression modeling. Despite enabling direct value prediction, this method offers no uncertainty estimation and exhibits poor outlier robustness. To address these limitations, we propose OCE-TS, a novel ordinal classification approach for time series forecasting that replaces MSE with Ordinal Cross-Entropy (OCE) loss, preserving prediction order while quantifying uncertainty through probability output. Specifically, OCE-TS begins by discretizing observed values into ordered intervals and deriving their probabilities via a parametric distribution as supervision signals. Using a simple linear model, we then predict probability distributions for each timestep. The OCE loss is computed between the cumulative distributions of predicted and ground-truth probabilities, explicitly preserving ordinal relationships among forecasted values. Through theoretical analysis using influence functions, we establish that cross-entropy (CE) loss exhibits superior stability and outlier robustness compared to MSE loss. Empirically, we compared OCE-TS with five baseline models-Autoformer, DLinear, iTransformer, TimeXer, and TimeBridge-on seven public time series datasets. Using MSE and Mean Absolute Error (MAE) as evaluation metrics, the results demonstrate that OCE-TS consistently outperforms benchmark models. The code will be published.

</details>


### [39] [Fractional neural attention for efficient multiscale sequence processing](https://arxiv.org/abs/2511.10208)
*Cheng Kevin Qu,Andrew Ly,Pulin Gong*

Main category: cs.LG

TL;DR: 提出了分数神经注意力（FNA）框架，通过Lévy扩散和分数拉普拉斯算子建模token交互，实现多尺度信息处理，提升Transformer的表达能力和计算效率。


<details>
  <summary>Details</summary>
Motivation: 受生物注意力多尺度动态和动力系统理论启发，旨在理解和扩展自注意力机制的原理，为AI提供神经科学基础。

Method: 使用分数拉普拉斯算子控制的Lévy扩散建模token交互，实现同时的短程和长程依赖关系，采用扩散映射算法进行降维。

Result: FNA在文本分类、图像处理和神经机器翻译中表现优异，单层单头即可获得竞争力，具有更大的谱间隙和更短的路径长度。

Conclusion: FNA建立了自注意力、随机动态和几何之间的原则性联系，为强大的神经科学启发的AI提供了可解释的生物学基础。

Abstract: Attention mechanisms underpin the computational power of Transformer models, which have achieved remarkable success across diverse domains. Yet understanding and extending the principles underlying self-attention remains a key challenge for advancing artificial intelligence. Drawing inspiration from the multiscale dynamics of biological attention and from dynamical systems theory, we introduce Fractional Neural Attention (FNA), a principled, neuroscience-inspired framework for multiscale information processing. FNA models token interactions through Lévy diffusion governed by the fractional Laplacian, intrinsically realizing simultaneous short- and long-range dependencies across multiple scales. This mechanism yields greater expressivity and faster information mixing, advancing the foundational capacity of Transformers. Theoretically, we show that FNA's dynamics are governed by the fractional diffusion equation, and that the resulting attention networks exhibit larger spectral gaps and shorter path lengths -- mechanistic signatures of enhanced computational efficiency. Empirically, FNA achieves competitive text-classification performance even with a single layer and a single head; it also improves performance in image processing and neural machine translation. Finally, the diffusion map algorithm from geometric harmonics enables dimensionality reduction of FNA weights while preserving the intrinsic structure of embeddings and hidden states. Together, these results establish FNA as a principled mechanism connecting self-attention, stochastic dynamics, and geometry, providing an interpretable, biologically grounded foundation for powerful, neuroscience-inspired AI.

</details>


### [40] [EDGC: Entropy-driven Dynamic Gradient Compression for Efficient LLM Training](https://arxiv.org/abs/2511.10333)
*Qingao Yi,Jiaang Duan,Hanwen Hu,Qin Hua,Haiyan Zhao,Shiyou Qian,Dingyu Yang,Jian Cao,Jinghua Tang,Yinghao Yu,Chenzhi Liao,Kangjin Wang,Liping Zhang*

Main category: cs.LG

TL;DR: 提出EDGC框架，基于梯度熵动态调整压缩率，显著减少LLM训练中的通信延迟和训练时间，同时保持模型精度。


<details>
  <summary>Details</summary>
Motivation: 现有静态梯度压缩方法忽略了训练过程中梯度的动态变化特性，导致性能下降。如何在加速LLM训练的同时不牺牲性能仍是一个挑战。

Method: EDGC框架包含三个关键组件：1) 下采样方法高效估计梯度熵；2) 建立压缩率与梯度熵的理论模型；3) 基于窗口的调整机制动态适应不同流水线阶段的压缩率。

Result: 在32-NVIDIA-V100和64-NVIDIA-H100集群上分别训练GPT2-2.5B和GPT2-12.1B，EDGC将通信延迟和训练时间分别减少高达46.45%和16.13%，同时保持LLM精度。

Conclusion: EDGC通过动态梯度压缩有效解决了LLM训练中的通信瓶颈问题，在保持模型性能的同时显著提升了训练效率。

Abstract: Training large language models (LLMs) poses significant challenges regarding computational resources and memory capacity. Although distributed training techniques help mitigate these issues, they still suffer from considerable communication overhead. Existing approaches primarily rely on static gradient compression to enhance communication efficiency; however, these methods neglect the dynamic nature of evolving gradients during training, leading to performance degradation. Accelerating LLM training via compression without sacrificing performance remains a challenge. In this paper, we propose an entropy-driven dynamic gradient compression framework called EDGC. The core concept is to adjust the compression rate during LLM training based on the evolving trends of gradient entropy, taking into account both compression efficiency and error. EDGC consists of three key components.First, it employs a down-sampling method to efficiently estimate gradient entropy, reducing computation overhead. Second, it establishes a theoretical model linking compression rate with gradient entropy, enabling more informed compression decisions. Lastly, a window-based adjustment mechanism dynamically adapts the compression rate across pipeline stages, improving communication efficiency and maintaining model performance. We implemented EDGC on a 32-NVIDIA-V100 cluster and a 64-NVIDIA-H100 cluster to train GPT2-2.5B and GPT2-12.1B, respectively. The results show that EDGC significantly reduces communication latency and training time by up to 46.45% and 16.13% while preserving LLM accuracy.

</details>


### [41] [Robust Decentralized Multi-armed Bandits: From Corruption-Resilience to Byzantine-Resilience](https://arxiv.org/abs/2511.10344)
*Zicheng Hu,Yuchen Wang,Cheng Chen*

Main category: cs.LG

TL;DR: 本文研究了去中心化协作多智能体多臂老虎机问题中的对抗攻击问题，提出了DeMABAR算法，能够在对抗性腐败和拜占庭攻击下保持鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的去中心化协作多智能体多臂老虎机方法容易受到各种对抗攻击的影响，需要设计能够抵御对抗性腐败和拜占庭攻击的鲁棒算法。

Method: 提出了DeMABAR算法，该算法通过特定的协作机制来处理对抗性腐败和拜占庭攻击，确保智能体的个体遗憾仅受到与腐败预算成正比的附加项影响。

Result: 理论分析表明DeMABAR算法能够几乎完全消除对抗攻击的影响，在拜占庭设置下具有内在鲁棒性。数值实验验证了该方法的鲁棒性和有效性。

Conclusion: DeMABAR算法为去中心化协作多智能体多臂老虎机问题提供了一种有效的对抗攻击防御方案，在对抗性腐败和拜占庭攻击场景下均表现出良好的性能。

Abstract: Decentralized cooperative multi-agent multi-armed bandits (DeCMA2B) considers how multiple agents collaborate in a decentralized multi-armed bandit setting. Though this problem has been extensively studied in previous work, most existing methods remain susceptible to various adversarial attacks. In this paper, we first study DeCMA2B with adversarial corruption, where an adversary can corrupt reward observations of all agents with a limited corruption budget. We propose a robust algorithm, called DeMABAR, which ensures that each agent's individual regret suffers only an additive term proportional to the corruption budget. Then we consider a more realistic scenario where the adversary can only attack a small number of agents. Our theoretical analysis shows that the DeMABAR algorithm can also almost completely eliminate the influence of adversarial attacks and is inherently robust in the Byzantine setting, where an unknown fraction of the agents can be Byzantine, i.e., may arbitrarily select arms and communicate wrong information. We also conduct numerical experiments to illustrate the robustness and effectiveness of the proposed method.

</details>


### [42] [Product distribution learning with imperfect advice](https://arxiv.org/abs/2511.10366)
*Arnab Bhattacharyya,Davin Choo,Philips George John,Themis Gouleakis*

Main category: cs.LG

TL;DR: 本文研究了在给定参考分布Q参数的情况下，如何高效学习未知分布P的问题。当P和Q的均值向量在ℓ1距离上足够接近时，可以显著减少样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统分布学习需要Ω(d/ε²)样本，但如果有参考分布Q的参数作为先验知识，可能减少样本需求。本文探索在什么条件下可以利用这种先验知识来加速学习。

Method: 提出了一种高效算法，当参考分布Q与目标分布P的均值向量在ℓ1距离上足够接近时，利用Q的参数信息来减少学习P所需的样本数量。

Result: 当‖p-q‖₁ < εd^0.5-Ω(η)时，算法仅需Õ(d^{1-η}/ε²)样本即可在总变差距离ε内学习P，相比传统方法有显著改进。

Conclusion: 利用参考分布的参数作为先验知识可以显著降低分布学习的样本复杂度，前提是参考分布与目标分布在ℓ1距离上足够接近。

Abstract: Given i.i.d.~samples from an unknown distribution $P$, the goal of distribution learning is to recover the parameters of a distribution that is close to $P$. When $P$ belongs to the class of product distributions on the Boolean hypercube $\{0,1\}^d$, it is known that $Ω(d/\varepsilon^2)$ samples are necessary to learn $P$ within total variation (TV) distance $\varepsilon$. We revisit this problem when the learner is also given as advice the parameters of a product distribution $Q$. We show that there is an efficient algorithm to learn $P$ within TV distance $\varepsilon$ that has sample complexity $\tilde{O}(d^{1-η}/\varepsilon^2)$, if $\|\mathbf{p} - \mathbf{q}\|_1 < \varepsilon d^{0.5 - Ω(η)}$. Here, $\mathbf{p}$ and $\mathbf{q}$ are the mean vectors of $P$ and $Q$ respectively, and no bound on $\|\mathbf{p} - \mathbf{q}\|_1$ is known to the algorithm a priori.

</details>


### [43] [Unlocking Dynamic Inter-Client Spatial Dependencies: A Federated Spatio-Temporal Graph Learning Method for Traffic Flow Forecasting](https://arxiv.org/abs/2511.10434)
*Feng Wang,Tianxiang Chen,Shuyue Wei,Qian Chu,Yi Zhang,Yifan Sun,Zhiming Zheng*

Main category: cs.LG

TL;DR: FedSTGD是一个联邦时空图框架，用于在联邦学习中建模和重构动态的客户端间空间依赖关系，通过非线性计算分解和图节点嵌入增强模块，在保护数据隐私的同时实现接近集中式方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界交通数据分布在多个利益相关者之间，现有方法主要处理静态依赖关系，忽略了动态特性，导致性能不佳。需要在遵守数据本地化约束的同时建模和重构客户端间的动态空间依赖关系。

Method: 提出FedSTGD框架，包含联邦非线性计算分解模块来近似复杂图操作，图节点嵌入增强模块缓解分解带来的性能下降，以及客户端-服务器集体学习协议将动态空间依赖学习任务分解为轻量级并行子任务。

Result: 在四个真实世界数据集上的实验表明，FedSTGD在RMSE、MAE和MAPE指标上优于现有最先进方法，性能接近集中式基线。消融研究确认了各模块对处理动态客户端间空间依赖的贡献。

Conclusion: FedSTGD能够有效建模和重构动态的客户端间空间依赖关系，在联邦学习环境中实现高性能，同时保持对超参数变化的鲁棒性。

Abstract: Spatio-temporal graphs are powerful tools for modeling complex dependencies in traffic time series. However, the distributed nature of real-world traffic data across multiple stakeholders poses significant challenges in modeling and reconstructing inter-client spatial dependencies while adhering to data locality constraints. Existing methods primarily address static dependencies, overlooking their dynamic nature and resulting in suboptimal performance. In response, we propose Federated Spatio-Temporal Graph with Dynamic Inter-Client Dependencies (FedSTGD), a framework designed to model and reconstruct dynamic inter-client spatial dependencies in federated learning. FedSTGD incorporates a federated nonlinear computation decomposition module to approximate complex graph operations. This is complemented by a graph node embedding augmentation module, which alleviates performance degradation arising from the decomposition. These modules are coordinated through a client-server collective learning protocol, which decomposes dynamic inter-client spatial dependency learning tasks into lightweight, parallelizable subtasks. Extensive experiments on four real-world datasets demonstrate that FedSTGD achieves superior performance over state-of-the-art baselines in terms of RMSE, MAE, and MAPE, approaching that of centralized baselines. Ablation studies confirm the contribution of each module in addressing dynamic inter-client spatial dependencies, while sensitivity analysis highlights the robustness of FedSTGD to variations in hyperparameters.

</details>


### [44] [Improving Perturbation-based Explanations by Understanding the Role of Uncertainty Calibration](https://arxiv.org/abs/2511.10439)
*Thomas Decker,Volker Tresp,Florian Buettner*

Main category: cs.LG

TL;DR: 本文研究了不确定性校准与基于扰动的可解释性方法之间的关系，发现模型在特定扰动下会产生不可靠的概率估计，这直接影响了局部和全局解释的质量。作者提出了ReCalX方法来重新校准模型以改善解释效果。


<details>
  <summary>Details</summary>
Motivation: 基于扰动的可解释性方法在实践中被广泛使用，但其可靠性受到模型在特定扰动下行为未知的限制。本文旨在解决模型在可解释性特定扰动下产生不可靠概率估计的问题。

Method: 提出了ReCalX方法，通过重新校准模型来改善解释效果，同时保持模型的原始预测能力。该方法专门针对可解释性特定的扰动进行优化。

Result: 在多种模型和数据集上的实证评估表明，ReCalX能有效减少扰动特定的校准误差，提高解释的鲁棒性，并更好地识别全局重要的输入特征。

Conclusion: 模型在可解释性特定扰动下的不确定性校准问题直接影响解释质量，ReCalX方法能够有效解决这一问题，为基于扰动的可解释性方法提供了更可靠的基础。

Abstract: Perturbation-based explanations are widely utilized to enhance the transparency of machine-learning models in practice. However, their reliability is often compromised by the unknown model behavior under the specific perturbations used. This paper investigates the relationship between uncertainty calibration - the alignment of model confidence with actual accuracy - and perturbation-based explanations. We show that models systematically produce unreliable probability estimates when subjected to explainability-specific perturbations and theoretically prove that this directly undermines global and local explanation quality. To address this, we introduce ReCalX, a novel approach to recalibrate models for improved explanations while preserving their original predictions. Empirical evaluations across diverse models and datasets demonstrate that ReCalX consistently reduces perturbation-specific miscalibration most effectively while enhancing explanation robustness and the identification of globally important input features.

</details>


### [45] [Intrinsic Dimensionality as a Model-Free Measure of Class Imbalance](https://arxiv.org/abs/2511.10475)
*Çağrı Eser,Zeynep Sonat Baltacı,Emre Akbaş,Sinan Kalkan*

Main category: cs.LG

TL;DR: 本文提出使用数据内在维度（ID）作为不平衡分类任务的度量方法，替代传统的基于样本数量的不平衡度量。ID是一种易于计算、无需模型训练的不平衡度量，可无缝集成到各种不平衡缓解方法中。


<details>
  <summary>Details</summary>
Motivation: 传统基于类别样本数量的不平衡度量忽略了冗余样本和类别学习难度的内在差异，而复杂的度量方法如训练损失和不确定性需要训练机器学习模型。

Method: 使用数据内在维度（ID）作为模型无关的不平衡度量，并将其与基于样本数量的方法相结合。

Result: 在五个不同不平衡比率的数据集上，ID方法始终优于文献中基于样本数量的重加权和重采样技术，且ID与样本数量结合可进一步提高性能。

Conclusion: 数据内在维度是比传统样本数量更有效的不平衡度量方法，能够更好地反映类别的学习难度差异。

Abstract: Imbalance in classification tasks is commonly quantified by the cardinalities of examples across classes. This, however, disregards the presence of redundant examples and inherent differences in the learning difficulties of classes. Alternatively, one can use complex measures such as training loss and uncertainty, which, however, depend on training a machine learning model. Our paper proposes using data Intrinsic Dimensionality (ID) as an easy-to-compute, model-free measure of imbalance that can be seamlessly incorporated into various imbalance mitigation methods. Our results across five different datasets with a diverse range of imbalance ratios show that ID consistently outperforms cardinality-based re-weighting and re-sampling techniques used in the literature. Moreover, we show that combining ID with cardinality can further improve performance. Code: https://github.com/cagries/IDIM.

</details>


### [46] [Towards Emotionally Intelligent and Responsible Reinforcement Learning](https://arxiv.org/abs/2511.10573)
*Garapati Keerthana,Manik Gupta*

Main category: cs.LG

TL;DR: 提出了一种负责任强化学习框架，将情感理解和伦理约束整合到顺序决策过程中，用于医疗和行为支持领域的个性化决策系统。


<details>
  <summary>Details</summary>
Motivation: 现有医疗和行为支持中的个性化决策系统依赖静态规则或参与度最大化启发式方法，忽视了用户的情感背景和伦理约束，可能导致推荐不敏感或不安全的干预措施。

Method: 将个性化建模为约束马尔可夫决策过程，引入多目标奖励函数平衡短期行为参与和长期用户福祉，定义情感感知的状态表示来捕捉情绪准备度、情感和风险波动。

Result: 提出了一个可操作化的框架，将同理心和责任融入机器学习策略优化，连接了安全强化学习、情感计算和负责任AI。

Conclusion: 该框架为行为健康、教育和数字治疗等领域的人本领域提供了伦理对齐的强化学习方法，旨在启动关于情感感知和可信个性化系统的伦理对齐强化学习方法论讨论。

Abstract: Personalized decision systems in healthcare and behavioral support often rely on static rule-based or engagement-maximizing heuristics that overlook users' emotional context and ethical constraints. Such approaches risk recommending insensitive or unsafe interventions, especially in domains involving serious mental illness, substance use disorders, or depression. To address this limitation, we propose a Responsible Reinforcement Learning (RRL) framework that integrates emotional and contextual understanding with ethical considerations into the sequential decision-making process. RRL formulates personalization as a Constrained Markov Decision Process (CMDP), where the agent optimizes engagement and adherence while ensuring emotional alignment and ethical safety. We introduce a multi-objective reward function that explicitly balances short-term behavioral engagement with long-term user well-being, and define an emotion-informed state representation that captures fluctuations in emotional readiness, affect, and risk. The proposed architecture can be instantiated with any RL algorithm (e.g., DQN, PPO) augmented with safety constraints or Lagrangian regularization. Conceptually, this framework operationalizes empathy and responsibility within machine learning policy optimization, bridging safe RL, affective computing and responsible AI. We discuss the implications of this approach for human-centric domains such as behavioral health, education, and digital therapeutics, and outline simulation-based validation paths for future empirical work. This paper aims to initiate a methodological conversation about ethically aligned reinforcement learning for emotionally aware and trustworthy personalization systems.

</details>


### [47] [Tight Robustness Certification through the Convex Hull of $\ell_0$ Attacks](https://arxiv.org/abs/2511.10576)
*Yuval Shapira,Dana Drachsler-Cohen*

Main category: cs.LG

TL;DR: 本文提出了一种新的线性边界传播方法，用于精确计算ℓ₀球凸包上的边界，显著提升了现有ℓ₀验证器的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的局部鲁棒性验证器通常依赖线性边界传播来处理凸扰动空间，但ℓ₀球不是凸的，这限制了验证器在少像素攻击场景下的有效性。

Method: 作者证明了ℓ₀球的凸包是其边界框与不对称缩放ℓ₁类多面体的交集，并提出了一种精确计算凸包边界的线性边界传播方法。

Result: 该方法在最具挑战性的鲁棒性基准测试中，将最先进的ℓ₀验证器的性能提升了1.24倍至7.07倍，几何平均值为3.16倍。

Conclusion: 通过精确建模ℓ₀球的凸包，本文提出的边界传播方法显著提升了ℓ₀鲁棒性验证的效率和准确性。

Abstract: Few-pixel attacks mislead a classifier by modifying a few pixels of an image. Their perturbation space is an $\ell_0$-ball, which is not convex, unlike $\ell_p$-balls for $p\geq1$. However, existing local robustness verifiers typically scale by relying on linear bound propagation, which captures convex perturbation spaces. We show that the convex hull of an $\ell_0$-ball is the intersection of its bounding box and an asymmetrically scaled $\ell_1$-like polytope. The volumes of the convex hull and this polytope are nearly equal as the input dimension increases. We then show a linear bound propagation that precisely computes bounds over the convex hull and is significantly tighter than bound propagations over the bounding box or our $\ell_1$-like polytope. This bound propagation scales the state-of-the-art $\ell_0$ verifier on its most challenging robustness benchmarks by 1.24x-7.07x, with a geometric mean of 3.16.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [48] [Investigation of Feature Selection and Pooling Methods for Environmental Sound Classification](https://arxiv.org/abs/2511.09802)
*Parinaz Binandeh Dehaghani,Danilo Pena,A. Pedro Aguiar*

Main category: eess.SP

TL;DR: 本文研究了环境声音分类中维度缩减和池化方法对轻量级CNN的影响，评估了SSRP及其变体，发现SSRP-T在ESC-50数据集上达到80.69%准确率，显著优于基线CNN和PCA方法。


<details>
  <summary>Details</summary>
Motivation: 探索在资源受限场景下平衡准确性和计算成本的环境声音分类解决方案，特别关注稀疏池化策略的有效性。

Method: 使用轻量级CNN评估SSRP（稀疏显著区域池化）及其变体SSRP-B和SSRP-T，并与PCA方法在各种超参数设置下进行比较。

Result: 在ESC-50数据集上，SSRP-T达到80.69%准确率，显著优于基线CNN（66.75%）和PCA缩减模型（37.60%）。

Conclusion: 经过良好调优的稀疏池化策略为环境声音分类任务提供了鲁棒、高效且高性能的解决方案，特别适用于资源受限场景。

Abstract: This paper explores the impact of dimensionality reduction and pooling methods for Environmental Sound Classification (ESC) using lightweight CNNs. We evaluate Sparse Salient Region Pooling (SSRP) and its variants, SSRP-Basic (SSRP-B) and SSRP-Top-K (SSRP-T), under various hyperparameter settings and compare them with Principal Component Analysis (PCA). Experiments on the ESC-50 dataset demonstrate that SSRP-T achieves up to 80.69 % accuracy, significantly outperforming both the baseline CNN (66.75 %) and the PCA-reduced model (37.60 %). Our findings confirm that a well-tuned sparse pooling strategy provides a robust, efficient, and high-performing solution for ESC tasks, particularly in resource-constrained scenarios where balancing accuracy and computational cost is crucial.

</details>


### [49] [Bridging the Initialization Gap: A Co-Optimization Framework for Mixed-Size Global Placement](https://arxiv.org/abs/2511.10073)
*Yuhao Ren,Yiting Liu,Yanfei Zhou,Zhiyu Zheng,Li Shang,Fan Yang,Zhiang Wang*

Main category: eess.SP

TL;DR: 提出了一种轻量级协同优化框架，通过面积提示细化初始化和宏调度布局两种策略，在VLSI全局布局中实现高效且高质量的初始化。


<details>
  <summary>Details</summary>
Motivation: 现有初始化方法存在权衡：面积感知初始化器计算昂贵，而快速点基初始化器忽略单元面积，影响收敛性和解决方案质量。

Method: 1. 面积提示细化初始化器：通过虚拟节点和负权重边将启发式单元面积信息整合到有符号图信号中；2. 宏调度布局过程：逐步恢复面积约束，实现从细化初始化器到完整面积感知目标的平滑过渡。

Result: 在12个测试案例中，11个案例的HPWL优于点基初始化器，最高减少2.2%的HPWL，运行速度比最先进面积感知初始化器快约100倍。

Conclusion: 该框架有效弥合了初始化差距，在保持计算效率的同时显著提升了布局质量。

Abstract: Global placement is a critical step with high computational complexity in VLSI physical design. Modern analytical placers formulate the placement problem as a nonlinear optimization, where initialization strongly affects both convergence behavior and final placement quality. However, existing initialization methods exhibit a trade-off: area-aware initializers account for cell areas but are computationally expensive and can dominate total runtime, while fast point-based initializers ignore cell area, leading to a modeling gap that impairs convergence and solution quality. We propose a lightweight co-optimization framework that bridges this initialization gap through two strategies. First, an area-hint refinement initializer incorporates heuristic cell area information into a signed graph signal by augmenting the netlist graph with virtual nodes and negative-weight edges, yielding an area-aware and spectrally smooth placement initialization. Second, a macro-schedule placement procedure progressively restores area constraints, enabling a smooth transition from the refined initializer to the full area-aware objective and producing high-quality placement results. We evaluate the framework on macro-heavy ISPD2005 academic benchmarks and two real-world industrial designs across two technology nodes (12 cases in total). Experimental results show that our method consistently improves half-perimeter wirelength (HPWL) over point-based initializers in 11 out of 12 cases, achieving up to 2.2% HPWL reduction, while running approximately 100 times faster than the state-of-the-art area-aware initializer.

</details>


### [50] [High Order Delta-Sigma Modulation with Positive Integer Coefficients](https://arxiv.org/abs/2511.10205)
*Martin J. W. Schubert*

Main category: eess.SP

TL;DR: 本文提出了用于级联Delta-Sigma调制器结构的二项式整数参数，该结构具有分布式反馈、分布式前馈输入和多比特输出。研究表明使用这些系数可以实现高阶调制器，并讨论了系数的精度要求。


<details>
  <summary>Details</summary>
Motivation: 为级联Delta-Sigma调制器结构开发简化的参数设计方法，使用二项式整数系数来简化实现复杂度，同时保持高性能。

Method: 采用级联Delta-Sigma调制器结构，结合分布式反馈和分布式前馈输入，使用二项式整数作为调制器系数，实现多比特输出。

Result: 研究表明使用二项式整数系数可以实现高阶Delta-Sigma调制器，验证了该方法的有效性。

Conclusion: 二项式整数参数为级联Delta-Sigma调制器提供了一种简化的设计方法，能够实现高阶性能，同时讨论了系数精度对系统性能的影响。

Abstract: This document proposes binomial integer parameters for the cascaded Delta-Sigma-modulator structure with distributed feedback and distributed feedforward input and multi-bit output. It is demonstrated that high orders can be achieved with these coefficients. Accuracy requirements concerning the coefficients are discussed.

</details>
