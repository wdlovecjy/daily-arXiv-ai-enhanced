<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 21]
- [eess.SP](#eess.SP) [Total: 3]
- [stat.AP](#stat.AP) [Total: 3]
- [cs.AI](#cs.AI) [Total: 10]
- [stat.ML](#stat.ML) [Total: 2]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [What's in Common? Multimodal Models Hallucinate When Reasoning Across Scenes](https://arxiv.org/abs/2511.03768)
*Candace Ross,Florian Bordes,Adina Williams,Polina Kirichenko,Mark Ibrahim*

Main category: cs.LG

TL;DR: 提出了Common-O基准测试，评估多模态语言模型在真实场景中的推理能力，发现即使最佳模型在跨场景推理任务上表现也很差（35%准确率），特别是在复杂场景中仅1%准确率。


<details>
  <summary>Details</summary>
Motivation: 解决多模态语言模型在真实世界场景中存在的幻觉问题，尽管在现有感知基准测试上表现良好，但在实际推理中仍存在明显差距。

Method: 构建包含10,500+个全新图像的Common-O基准测试，避免训练数据污染，通过"共同点是什么"的问题来评估模型跨场景推理能力。

Result: 模型在单图像感知任务上表现良好，但在跨场景推理任务上表现很差，最佳模型准确率仅35%，复杂场景中仅1%。模型在存在相似物体时更容易产生幻觉。

Conclusion: 多模态语言模型在跨场景推理方面存在严重挑战，多图像训练可能提供改进方向，Common-O基准将推动解决场景推理中的幻觉问题研究。

Abstract: Multimodal language models possess a remarkable ability to handle an
open-vocabulary's worth of objects. Yet the best models still suffer from
hallucinations when reasoning about scenes in the real world, revealing a gap
between their seemingly strong performance on existing perception benchmarks
that are saturating and their reasoning in the real world. To address this gap,
we build a novel benchmark of in-the-wild scenes that we call Common-O. With
more than 10.5k examples using exclusively new images not found in web training
data to avoid contamination, Common-O goes beyond just perception, inspired by
cognitive tests for humans, to probe reasoning across scenes by asking "what's
in common?". We evaluate leading multimodal language models, including models
specifically trained to perform chain-of-thought reasoning. We find that
perceiving objects in single images is tractable for most models, yet reasoning
across scenes is very challenging even for the best models, including reasoning
models. Despite saturating many leaderboards focusing on perception, the best
performing model only achieves 35% on Common-O -- and on Common-O Complex,
consisting of more complex scenes, the best model achieves only 1%. Curiously,
we find models are more prone to hallucinate when similar objects are present
in the scene, suggesting models may be relying on object co-occurrence seen
during training. Among the models we evaluated, we found scale can provide
modest improvements while models explicitly trained with multi-image inputs
show bigger improvements, suggesting scaled multi-image training may offer
promise. We make our benchmark publicly available to spur research into the
challenge of hallucination when reasoning across scenes.

</details>


### [2] [Optimizing Reasoning Efficiency through Prompt Difficulty Prediction](https://arxiv.org/abs/2511.03808)
*Bo Zhao,Berkcan Kapusuzoglu,Kartik Balasubramaniam,Sambit Sahu,Supriyo Chakraborty,Genta Indra Winata*

Main category: cs.LG

TL;DR: 提出了一种路由方法，将问题分配给可能解决它的最小模型，在不牺牲准确性的情况下减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 推理语言模型在复杂任务上表现良好，但由于模型规模和长推理轨迹导致部署成本高昂。

Method: 使用s1.1-32B的中间表示训练轻量级预测器，预测问题难度或模型正确性，指导在推理模型池中的路由分配。

Result: 在多样化的数学基准测试中，路由方法比随机分配提高了效率，匹配s1.1-32B的性能同时显著减少计算量。

Conclusion: 难度感知路由对于推理模型的成本高效部署是有效的。

Abstract: Reasoning language models perform well on complex tasks but are costly to
deploy due to their size and long reasoning traces. We propose a routing
approach that assigns each problem to the smallest model likely to solve it,
reducing compute without sacrificing accuracy. Using intermediate
representations from s1.1-32B, we train lightweight predictors of problem
difficulty or model correctness to guide routing across a pool of reasoning
models. On diverse math benchmarks, routing improves efficiency over random
assignment and matches s1.1-32B's performance while using significantly less
compute. Our results demonstrate that difficulty-aware routing is effective for
cost-efficient deployment of reasoning models.

</details>


### [3] [Higher-Order Causal Structure Learning with Additive Models](https://arxiv.org/abs/2511.03831)
*James Enouen,Yujia Zheng,Ignavier Ng,Yan Liu,Kun Zhang*

Main category: cs.LG

TL;DR: 本文扩展了因果加性模型(CAM)以处理高阶交互作用，引入了有向无环超图来表示这种结构，提供了超DAG的可识别性结果，并开发了相应的学习算法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的许多过程都表现出高阶机制，但因果发现中对交互作用的显式处理很少受到关注。本文旨在将因果加性模型扩展到包含高阶交互的加性模型。

Method: 引入有向无环超图来表示高阶交互结构，提供必要的定义和理论工具，扩展贪婪CAM算法来处理更复杂的超DAG搜索空间。

Result: 获得了超DAG的可识别性结果，扩展了典型的马尔可夫等价类。理论分析表明学习更复杂的超图结构可能带来更好的经验结果，特别是更严格的假设对应着更容易学习的超DAG和更好的有限样本复杂度。

Conclusion: 通过将因果加性模型扩展到高阶交互模型，并引入有向无环超图表示，本文为处理复杂因果机制提供了新的理论框架和实用算法，在合成实验中证明了其有效性。

Abstract: Causal structure learning has long been the central task of inferring causal
insights from data. Despite the abundance of real-world processes exhibiting
higher-order mechanisms, however, an explicit treatment of interactions in
causal discovery has received little attention. In this work, we focus on
extending the causal additive model (CAM) to additive models with higher-order
interactions. This second level of modularity we introduce to the structure
learning problem is most easily represented by a directed acyclic hypergraph
which extends the DAG. We introduce the necessary definitions and theoretical
tools to handle the novel structure we introduce and then provide
identifiability results for the hyper DAG, extending the typical Markov
equivalence classes. We next provide insights into why learning the more
complex hypergraph structure may actually lead to better empirical results. In
particular, more restrictive assumptions like CAM correspond to easier-to-learn
hyper DAGs and better finite sample complexity. We finally develop an extension
of the greedy CAM algorithm which can handle the more complex hyper DAG search
space and demonstrate its empirical usefulness in synthetic experiments.

</details>


### [4] [NVIDIA Nemotron Nano V2 VL](https://arxiv.org/abs/2511.03929)
*NVIDIA,:,Amala Sanjay Deshmukh,Kateryna Chumachenko,Tuomas Rintamaki,Matthieu Le,Tyler Poon,Danial Mohseni Taheri,Ilia Karmanov,Guilin Liu,Jarno Seppanen,Guo Chen,Karan Sapra,Zhiding Yu,Adi Renduchintala,Charles Wang,Peter Jin,Arushi Goel,Mike Ranzinger,Lukas Voegtle,Philipp Fischer,Timo Roman,Wei Ping,Boxin Wang,Zhuolin Yang,Nayeon Lee,Shaokun Zhang,Fuxiao Liu,Zhiqi Li,Di Zhang,Greg Heinrich,Hongxu,Yin,Song Han,Pavlo Molchanov,Parth Mannan,Yao Xu,Jane Polak Scowcroft,Tom Balough,Subhashree Radhakrishnan,Paris Zhang,Sean Cha,Ratnesh Kumar,Zaid Pervaiz Bhat,Jian Zhang,Darragh Hanley,Pritam Biswas,Jesse Oliver,Kevin Vasques,Roger Waleffe,Duncan Riach,Oluwatobi Olabiyi,Ameya Sunil Mahabaleshwarkar,Bilal Kartal,Pritam Gundecha,Khanh Nguyen,Alexandre Milesi,Eugene Khvedchenia,Ran Zilberstein,Ofri Masad,Natan Bagrov,Nave Assaf,Tomer Asida,Daniel Afrimi,Amit Zuker,Netanel Haber,Zhiyu Cheng,Jingyu,Xin,Di,Wu,Nik Spirin,Maryam Moosaei,Roman Ageev,Vanshil Atul Shah,Yuting Wu,Daniel Korzekwa,Unnikrishnan Kizhakkemadam Sreekumar,Wanli Jiang,Padmavathy Subramanian,Alejandra Rico,Sandip Bhaskar,Saeid Motiian,Kedi Wu,Annie Surla,Chia-Chih Chen,Hayden Wolff,Matthew Feinberg,Melissa Corpuz,Marek Wawrzos,Eileen Long,Aastha Jhunjhunwala,Paul Hendricks,Farzan Memarian,Benika Hall,Xin-Yu Wang,David Mosallanezhad,Soumye Singhal,Luis Vega,Katherine Cheung,Krzysztof Pawelec,Michael Evans,Katherine Luna,Jie Lou,Erick Galinkin,Akshay Hazare,Kaustubh Purandare,Ann Guan,Anna Warno,Chen Cui,Yoshi Suhara,Shibani Likhite,Seph Mard,Meredith Price,Laya Sleiman,Saori Kaji,Udi Karpas,Kari Briski,Joey Conway,Michael Lightstone,Jan Kautz,Mohammad Shoeybi,Mostofa Patwary,Jonathen Cohen,Oleksii Kuchaiev,Andrew Tao,Bryan Catanzaro*

Main category: cs.LG

TL;DR: Nemotron Nano V2 VL是最新的视觉语言模型，专为文档理解、长视频理解和推理任务设计，相比前代模型在视觉和文本领域都有显著提升，采用混合Mamba-Transformer架构和创新的token减少技术来提高长文档和视频场景的推理吞吐量。


<details>
  <summary>Details</summary>
Motivation: 开发一个在真实世界文档理解、长视频理解和推理任务中表现更强的视觉语言模型，通过改进模型架构、数据集和训练方法来实现性能提升。

Method: 基于Nemotron Nano V2（混合Mamba-Transformer LLM），采用创新的token减少技术，优化模型架构、数据集和训练配方。

Result: 相比前代模型Llama-3.1-Nemotron-Nano-VL-8B，在所有视觉和文本领域都实现了显著改进，在长文档和视频场景中实现了更高的推理吞吐量。

Conclusion: Nemotron Nano V2 VL是一个性能显著提升的视觉语言模型，特别适合文档理解和长视频理解任务，团队将发布BF16、FP8和FP4格式的模型检查点，并分享大部分数据集、配方和训练代码。

Abstract: We introduce Nemotron Nano V2 VL, the latest model of the Nemotron
vision-language series designed for strong real-world document understanding,
long video comprehension, and reasoning tasks. Nemotron Nano V2 VL delivers
significant improvements over our previous model,
Llama-3.1-Nemotron-Nano-VL-8B, across all vision and text domains through major
enhancements in model architecture, datasets, and training recipes. Nemotron
Nano V2 VL builds on Nemotron Nano V2, a hybrid Mamba-Transformer LLM, and
innovative token reduction techniques to achieve higher inference throughput in
long document and video scenarios. We are releasing model checkpoints in BF16,
FP8, and FP4 formats and sharing large parts of our datasets, recipes and
training code.

</details>


### [5] [LogHD: Robust Compression of Hyperdimensional Classifiers via Logarithmic Class-Axis Reduction](https://arxiv.org/abs/2511.03938)
*Sanggeon Yun,Hyunwoo Oh,Ryozo Masukawa,Pietro Mercati,Nathaniel D. Bastian,Mohsen Imani*

Main category: cs.LG

TL;DR: LogHD是一种超维计算压缩方法，通过对类别轴进行对数压缩，将内存需求从O(CD)降低到O(Dlog_k C)，同时保持维度D不变，在保持准确性的同时提高了模型的鲁棒性和能效。


<details>
  <summary>Details</summary>
Motivation: 标准超维计算的"每类一个原型"设计需要O(CD)内存，现有压缩方法主要减少特征维度D，但这会削弱模型的鲁棒性。需要一种既能压缩内存又能保持鲁棒性的新方法。

Method: 使用对数类别轴压缩，用n≈⌈log_k C⌉个捆绑超向量替换C个每类原型，在n维激活空间中进行解码，结合容量感知码本和基于配置文件的解码方法，可与特征轴稀疏化结合使用。

Result: 在各种数据集和注入位翻转的情况下，LogHD以更小的模型实现了竞争性的准确性，在相同内存下比特征轴压缩方法能承受2.5-3.0倍的位翻转率。ASIC实现相比AMD Ryzen 9 9950X实现了498倍能效和62.6倍加速，相比NVIDIA RTX 4090实现了24.3倍/6.58倍提升。

Conclusion: LogHD通过类别轴的对数压缩有效解决了超维计算的内存效率问题，在保持准确性的同时显著提高了鲁棒性和硬件效率，为资源受限系统提供了可行的解决方案。

Abstract: Hyperdimensional computing (HDC) suits memory, energy, and
reliability-constrained systems, yet the standard "one prototype per class"
design requires $O(CD)$ memory (with $C$ classes and dimensionality $D$). Prior
compaction reduces $D$ (feature axis), improving storage/compute but weakening
robustness. We introduce LogHD, a logarithmic class-axis reduction that
replaces the $C$ per-class prototypes with $n\!\approx\!\lceil\log_k C\rceil$
bundle hypervectors (alphabet size $k$) and decodes in an $n$-dimensional
activation space, cutting memory to $O(D\log_k C)$ while preserving $D$. LogHD
uses a capacity-aware codebook and profile-based decoding, and composes with
feature-axis sparsification. Across datasets and injected bit flips, LogHD
attains competitive accuracy with smaller models and higher resilience at
matched memory. Under equal memory, it sustains target accuracy at roughly
$2.5$-$3.0\times$ higher bit-flip rates than feature-axis compression; an ASIC
instantiation delivers $498\times$ energy efficiency and $62.6\times$ speedup
over an AMD Ryzen 9 9950X and $24.3\times$/$6.58\times$ over an NVIDIA RTX
4090, and is $4.06\times$ more energy-efficient and $2.19\times$ faster than a
feature-axis HDC ASIC baseline.

</details>


### [6] [RLHF: A comprehensive Survey for Cultural, Multimodal and Low Latency Alignment Methods](https://arxiv.org/abs/2511.03939)
*Raghav Sharma,Manan Mehta,Sai Tiger Raina*

Main category: cs.LG

TL;DR: 本调查论文系统综述了超越传统文本方法的大语言模型对齐研究新前沿，重点关注多模态对齐、文化公平性和低延迟优化等关键领域。


<details>
  <summary>Details</summary>
Motivation: 传统基于文本的RLHF方法存在局限性，需要解决多模态对齐、文化偏见和效率优化等关键挑战，以构建更鲁棒、高效和公平的AI系统。

Method: 首先回顾基础算法（PPO、DPO、GRPO），然后详细分析最新创新技术，提供比较性综合分析和开放挑战的框架。

Result: 提出了对齐研究的新前沿框架，系统梳理了多模态对齐、文化公平性和低延迟优化等关键领域的技术进展。

Conclusion: 本工作为研究人员构建更鲁棒、高效和公平的AI系统提供了重要的路线图，指出了未来对齐研究的发展方向。

Abstract: Reinforcement Learning from Human Feedback (RLHF) is the standard for
aligning Large Language Models (LLMs), yet recent progress has moved beyond
canonical text-based methods. This survey synthesizes the new frontier of
alignment research by addressing critical gaps in multi-modal alignment,
cultural fairness, and low-latency optimization. To systematically explore
these domains, we first review foundational algo- rithms, including PPO, DPO,
and GRPO, before presenting a detailed analysis of the latest innovations. By
providing a comparative synthesis of these techniques and outlining open
challenges, this work serves as an essential roadmap for researchers building
more robust, efficient, and equitable AI systems.

</details>


### [7] [Structural Priors and Modular Adapters in the Composable Fine-Tuning Algorithm of Large-Scale Models](https://arxiv.org/abs/2511.03981)
*Yuxiao Wang,Di Wu,Feng Liu,Zhimin Qiu,Chenrui Hu*

Main category: cs.LG

TL;DR: 提出了一种可组合的微调方法，通过图结构先验和模块化适配器解决大规模预训练模型在多任务适应中的高计算成本和结构不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 解决大规模预训练模型在多任务适应时面临的高计算成本和结构不稳定问题，提高参数效率和训练稳定性。

Method: 引入关系矩阵建模任务间依赖关系，将节点和路径相关性编码为图结构先验，通过低秩映射和可插拔机制将模块化适配器嵌入不同层，实现高效的跨任务组合和重用。

Result: 显著提高了任务预测精度、适配器权重分配精度和整体计算效率，同时保持模型的轻量化设计。

Conclusion: 图先验和模块化机制在可组合微调中具有协同优势，能够有效缓解多任务场景中的路径冲突和冗余计算问题。

Abstract: This paper proposes a composable fine-tuning method that integrates graph
structural priors with modular adapters to address the high computational cost
and structural instability faced by large-scale pre-trained models in
multi-task adaptation. The method introduces a relation matrix to model
dependencies among tasks, explicitly encoding correlations between nodes and
paths into graph structural priors, which provide unified structural
constraints for adapter weight allocation and path selection. Modular adapters
are embedded into different layers through low-rank mapping and a pluggable
mechanism, enabling efficient cross-task composition and reuse under prior
guidance. This mechanism not only improves parameter efficiency and training
stability but also alleviates path conflicts and redundant computation in
multi-task scenarios. Furthermore, experiments on hyperparameter sensitivity,
environmental sensitivity, and data sensitivity are conducted to systematically
analyze key factors such as routing temperature, gating thresholds, and
relation matrix regularization strength, verifying the consistency and superior
performance of the method under structural constraints. The results demonstrate
that the proposed framework significantly enhances task prediction accuracy,
adapter weight allocation precision, and overall computational efficiency while
maintaining model lightweight design, highlighting the synergistic advantages
of graph priors and modular mechanisms in composable fine-tuning.

</details>


### [8] [DartQuant: Efficient Rotational Distribution Calibration for LLM Quantization](https://arxiv.org/abs/2511.04063)
*Yuantian Shao,Yuanteng Chen,Peisong Wang,Jianlin Yu,Jing Lin,Yiwu Yao,Zhihui Wei,Jian Cheng*

Main category: cs.LG

TL;DR: DartQuant是一种高效的分布感知旋转校准方法，通过约束旋转后激活值的分布来降低旋转优化的复杂度，减少对任务特定损失的依赖，并引入QR-Orth优化方案替代昂贵的交替优化。在70B模型上实现了47倍加速和10倍内存节省，首次在单张3090 GPU上完成70B模型的旋转校准。


<details>
  <summary>Details</summary>
Motivation: 量化在加速大规模模型推理中起关键作用，旋转矩阵能有效改善量化性能但端到端微调计算成本高且容易过拟合。需要解决旋转优化算法的高计算成本和过拟合问题。

Method: 提出分布感知旋转校准方法DartQuant，通过约束旋转后激活值的分布来降低旋转优化复杂度；引入QR-Orth优化方案替代昂贵的交替优化。

Result: 在各种模型量化实验中表现优异，在70B模型上实现47倍加速和10倍内存节省，首次在单张3090 GPU上成功完成70B模型的旋转校准。

Conclusion: DartQuant使大语言模型量化在资源受限环境中变得可行，为大规模模型的高效量化提供了有效解决方案。

Abstract: Quantization plays a crucial role in accelerating the inference of
large-scale models, and rotational matrices have been shown to effectively
improve quantization performance by smoothing outliers. However, end-to-end
fine-tuning of rotational optimization algorithms incurs high computational
costs and is prone to overfitting. To address this challenge, we propose an
efficient distribution-aware rotational calibration method, DartQuant, which
reduces the complexity of rotational optimization by constraining the
distribution of the activations after rotation. This approach also effectively
reduces reliance on task-specific losses, thereby mitigating the risk of
overfitting. Additionally, we introduce the QR-Orth optimization scheme, which
replaces expensive alternating optimization with a more efficient solution. In
a variety of model quantization experiments, DartQuant demonstrates superior
performance. Compared to existing methods, it achieves 47$\times$ acceleration
and 10$\times$ memory savings for rotational optimization on a 70B model.
Furthermore, it is the first to successfully complete rotational calibration
for a 70B model on a single 3090 GPU, making quantization of large language
models feasible in resource-constrained environments. Code is available at
https://github.com/CAS-CLab/DartQuant.git.

</details>


### [9] [KoTaP: A Panel Dataset for Corporate Tax Avoidance, Performance, and Governance in Korea](https://arxiv.org/abs/2511.04094)
*Hyungjong Na,Wonho Song,Seungyong Han,Donghyeon Jo,Sejin Myung,Hyungjoon Kim*

Main category: cs.LG

TL;DR: 本研究介绍了韩国避税面板(KoTaP)，这是一个包含2011-2024年KOSPI和KOSDAQ上市非金融企业的长期面板数据集，包含12,653个公司年度观测值。该数据集将企业避税作为预测变量，与盈余管理、盈利能力、稳定性、增长性和公司治理等多个领域相关联。


<details>
  <summary>Details</summary>
Motivation: 创建标准化的长期面板数据集，用于研究企业避税行为及其与其他公司特征的关系，同时保持国际可比性和反映韩国特有的制度特征。

Method: 构建平衡面板数据集，使用现金有效税率(CETR)、GAAP有效税率(GETR)和账面税收差异(TSTA、TSDA)等多种互补指标来衡量企业避税，并标准化所有变量。

Result: KoTaP数据集具有平衡面板结构，核心指标的分布和相关性与国际文献一致，同时反映了韩国企业特有的集中所有权、高外资持股和高流动性比率等特征。

Conclusion: KoTaP是一个重要的开放资源，支持计量经济学和深度学习模型基准测试、外部有效性检验、可解释AI分析，以及政策评估、审计规划和投资分析等应用。

Abstract: This study introduces the Korean Tax Avoidance Panel (KoTaP), a long-term
panel dataset of non-financial firms listed on KOSPI and KOSDAQ between 2011
and 2024. After excluding financial firms, firms with non-December fiscal year
ends, capital impairment, and negative pre-tax income, the final dataset
consists of 12,653 firm-year observations from 1,754 firms. KoTaP is designed
to treat corporate tax avoidance as a predictor variable and link it to
multiple domains, including earnings management (accrual- and activity-based),
profitability (ROA, ROE, CFO, LOSS), stability (LEV, CUR, SIZE, PPE, AGE,
INVREC), growth (GRW, MB, TQ), and governance (BIG4, FORN, OWN). Tax avoidance
itself is measured using complementary indicators cash effective tax rate
(CETR), GAAP effective tax rate (GETR), and book-tax difference measures (TSTA,
TSDA) with adjustments to ensure interpretability. A key strength of KoTaP is
its balanced panel structure with standardized variables and its consistency
with international literature on the distribution and correlation of core
indicators. At the same time, it reflects distinctive institutional features of
Korean firms, such as concentrated ownership, high foreign shareholding, and
elevated liquidity ratios, providing both international comparability and
contextual uniqueness. KoTaP enables applications in benchmarking econometric
and deep learning models, external validity checks, and explainable AI
analyses. It further supports policy evaluation, audit planning, and investment
analysis, making it a critical open resource for accounting, finance, and
interdisciplinary research.

</details>


### [10] [Block Rotation is All You Need for MXFP4 Quantization](https://arxiv.org/abs/2511.04214)
*Yuantian Shao,Peisong Wang,Yuanteng Chen,Chang Xu,Zhihui Wei,Jian Cheng*

Main category: cs.LG

TL;DR: 本文对MXFP4格式下的后训练量化方法进行了全面基准测试，发现GPTQ等方法表现良好，而基于旋转的方法与MXFP4格式存在严重不兼容问题。作者提出了块旋转策略来适配MXFP4格式，显著提升了量化精度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的快速发展带来了巨大的内存、计算和能源成本，后训练量化是高效部署的解决方案。随着MXFP4这种新型FP4格式的出现，需要评估现有量化方法在新格式下的适用性。

Method: 建立了MXFP4格式下PTQ方法的综合基准测试，通过系统评估发现旋转方法与MXFP4格式的不兼容性，并提出块旋转策略来适配MXFP4的PoT块缩放特性。

Result: GPTQ等方法在MXFP4格式下表现稳定，而旋转方法由于与MXFP4的PoT块缩放不兼容而性能严重下降。提出的块旋转策略显著提升了旋转方法在MXFP4格式下的精度。

Conclusion: 研究为从业者提供了清晰的指导，并为新兴低精度格式下的PTQ研究奠定了基础，展示了适配新硬件格式的重要性。

Abstract: Large language models (LLMs) have achieved remarkable success, but their
rapidly growing scale imposes prohibitive costs in memory, computation, and
energy. Post-training quantization (PTQ) is a promising solution for efficient
deployment, yet achieving accurate W4A4 quantization remains an open challenge.
While most existing methods are designed for INT4 formats, the emergence of
MXFP4 -- a new FP4 format with various hardware support (NVIDIA, AMD, Intel)--
raises questions about the applicability of current techniques. In this work,
we establish a comprehensive benchmark of PTQ methods under the MXFP4 format.
Through systematic evaluation, we find that methods like GPTQ consistently
deliver strong performance, whereas rotation-based approaches, which are almost
used by all state-of-the-art approaches, suffer from severe incompatibility
with MXFP4. We further provide the first in-depth analysis of this conflict,
tracing its root to a fundamental mismatch between MXFP4's PoT (power-of-two)
block scaling and the redistribution of outlier energy via global rotation.
Building on this insight, we propose a simple yet effective block rotation
strategy that adapts rotation-based methods to MXFP4, leading to substantial
accuracy improvements across diverse LLMs. Our findings not only offer clear
guidance for practitioners but also set a foundation for advancing PTQ research
under emerging low-precision formats.

</details>


### [11] [Efficient Reinforcement Learning from Human Feedback via Bayesian Preference Inference](https://arxiv.org/abs/2511.04286)
*Matteo Cercola,Valeria Capretti,Simone Formentin*

Main category: cs.LG

TL;DR: 提出了一种结合RLHF可扩展性和PBO样本效率的混合框架，通过将主动查询模块集成到RLHF流程中，实现更高效的偏好数据收集。


<details>
  <summary>Details</summary>
Motivation: 从人类偏好中学习是使机器学习模型与主观人类判断对齐的关键，但收集偏好数据成本高且耗时，需要更高效的学习范式。

Method: 在RLHF流程中集成主动查询模块，结合RLHF的可扩展性和PBO的样本效率优势。

Result: 在高维偏好优化和LLM微调两个代表性领域的实验结果显示，该方法在样本效率和整体性能上均取得一致提升。

Conclusion: 提出的混合框架成功统一了RLHF的可扩展性和PBO的查询效率，为偏好学习提供了更高效的解决方案。

Abstract: Learning from human preferences is a cornerstone of aligning machine learning
models with subjective human judgments. Yet, collecting such preference data is
often costly and time-consuming, motivating the need for more efficient
learning paradigms. Two established approaches offer complementary advantages:
RLHF scales effectively to high-dimensional tasks such as LLM fine-tuning,
while PBO achieves greater sample efficiency through active querying. We
propose a hybrid framework that unifies RLHF's scalability with PBO's query
efficiency by integrating an acquisition-driven module into the RLHF pipeline,
thereby enabling active and sample-efficient preference gathering. We validate
the proposed approach on two representative domains: (i) high-dimensional
preference optimization and (ii) LLM fine-tuning. Experimental results
demonstrate consistent improvements in both sample efficiency and overall
performance across these tasks.

</details>


### [12] [Differentially Private In-Context Learning with Nearest Neighbor Search](https://arxiv.org/abs/2511.04332)
*Antti Koskela,Tejas Kulkarni,Laith Zumot*

Main category: cs.LG

TL;DR: 本文提出了一种差分隐私上下文学习框架，通过隐私感知的最近邻搜索检索相关示例，在文本分类和文档问答任务上显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的差分隐私上下文学习方法忽视了现代大语言模型流程中的关键组件——用于检索相关上下文数据的相似性搜索，存在隐私风险。

Method: 采用最近邻检索从上下文数据库中获取相关示例，结合隐私过滤器跟踪所选样本的累积隐私成本，确保符合中心差分隐私预算。

Result: 在文本分类和文档问答任务上，该方法在所有评估基准上都显著优于现有基线，实现了更优的隐私-效用权衡。

Conclusion: 提出的差分隐私上下文学习框架通过整合隐私感知的最近邻搜索，有效解决了上下文学习中的隐私保护问题，并取得了显著的性能提升。

Abstract: Differentially private in-context learning (DP-ICL) has recently become an
active research topic due to the inherent privacy risks of in-context learning.
However, existing approaches overlook a critical component of modern large
language model (LLM) pipelines: the similarity search used to retrieve relevant
context data. In this work, we introduce a DP framework for in-context learning
that integrates nearest neighbor search of relevant examples in a privacy-aware
manner. Our method outperforms existing baselines by a substantial margin
across all evaluated benchmarks, achieving more favorable privacy-utility
trade-offs. To achieve this, we employ nearest neighbor retrieval from a
database of context data, combined with a privacy filter that tracks the
cumulative privacy cost of selected samples to ensure adherence to a central
differential privacy budget. Experimental results on text classification and
document question answering show a clear advantage of the proposed method over
existing baselines.

</details>


### [13] [Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness](https://arxiv.org/abs/2511.04401)
*Subeen Park,Joowang Kim,Hakyung Lee,Sunjae Yoo,Kyungwoo Song*

Main category: cs.LG

TL;DR: 提出SCER方法，通过正则化特征表示来抑制虚假相关性，提高模型在最差群体上的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型容易依赖虚假相关性，在分布偏移时表现不佳，特别是在子群体偏移场景中，现有方法缺乏将嵌入空间表示与最差群体错误联系起来的理论框架。

Method: SCER方法直接在特征表示层面施加正则化，通过分析跨域和跨类的群体均值嵌入差异来识别核心方向和虚假方向，并施加理论约束。

Result: 在多个视觉和语言任务上的系统评估表明，SCER在最差群体准确率上优于现有最先进方法。

Conclusion: SCER通过理论驱动的嵌入正则化，有效抑制虚假相关性，提升模型在最差群体上的鲁棒性能。

Abstract: Deep learning models achieve strong performance across various domains but
often rely on spurious correlations, making them vulnerable to distribution
shifts. This issue is particularly severe in subpopulation shift scenarios,
where models struggle in underrepresented groups. While existing methods have
made progress in mitigating this issue, their performance gains are still
constrained. They lack a rigorous theoretical framework connecting the
embedding space representations with worst-group error. To address this
limitation, we propose Spurious Correlation-Aware Embedding Regularization for
Worst-Group Robustness (SCER), a novel approach that directly regularizes
feature representations to suppress spurious cues. We show theoretically that
worst-group error is influenced by how strongly the classifier relies on
spurious versus core directions, identified from differences in group-wise mean
embeddings across domains and classes. By imposing theoretical constraints at
the embedding level, SCER encourages models to focus on core features while
reducing sensitivity to spurious patterns. Through systematic evaluation on
multiple vision and language, we show that SCER outperforms prior
state-of-the-art studies in worst-group accuracy. Our code is available at
\href{https://github.com/MLAI-Yonsei/SCER}{https://github.com/MLAI-Yonsei/SCER}.

</details>


### [14] [The Illusion of Certainty: Uncertainty quantification for LLMs fails under ambiguity](https://arxiv.org/abs/2511.04418)
*Tim Tomov,Dominik Fuchsgruber,Tom Wollschläger,Stephan Günnemann*

Main category: cs.LG

TL;DR: 本文揭示了当前LLM不确定性量化方法在模糊数据上的性能严重下降问题，提出了首个配备真实答案分布的模糊QA数据集，并证明了现有UQ方法在模糊性下的理论局限性。


<details>
  <summary>Details</summary>
Motivation: 现有UQ方法通常在无模糊性假设下评估，但真实语言具有固有的模糊性，需要研究UQ方法在模糊数据上的表现。

Method: 引入MAQA*和AmbigQA*数据集，使用事实共现估计真实答案分布，评估不同UQ范式在模糊数据上的性能。

Result: 当前不确定性估计器在无模糊假设下表现良好，但在模糊数据上性能退化至接近随机水平，且这种现象在不同估计范式中一致存在。

Conclusion: 研究揭示了当前LLM UQ方法的关键缺陷，需要重新思考当前建模范式以应对语言模糊性。

Abstract: Accurate uncertainty quantification (UQ) in Large Language Models (LLMs) is
critical for trustworthy deployment. While real-world language is inherently
ambiguous, reflecting aleatoric uncertainty, existing UQ methods are typically
benchmarked against tasks with no ambiguity. In this work, we demonstrate that
while current uncertainty estimators perform well under the restrictive
assumption of no ambiguity, they degrade to close-to-random performance on
ambiguous data. To this end, we introduce MAQA* and AmbigQA*, the first
ambiguous question-answering (QA) datasets equipped with ground-truth answer
distributions estimated from factual co-occurrence. We find this performance
deterioration to be consistent across different estimation paradigms: using the
predictive distribution itself, internal representations throughout the model,
and an ensemble of models. We show that this phenomenon can be theoretically
explained, revealing that predictive-distribution and ensemble-based estimators
are fundamentally limited under ambiguity. Overall, our study reveals a key
shortcoming of current UQ methods for LLMs and motivates a rethinking of
current modeling paradigms.

</details>


### [15] [Q3R: Quadratic Reweighted Rank Regularizer for Effective Low-Rank Training](https://arxiv.org/abs/2511.04485)
*Ipsita Ghosh,Ethan Nguyen,Christian Kümmerle*

Main category: cs.LG

TL;DR: 提出了一种名为Q3R的二次重加权秩正则化器，用于低秩预训练任务，能够在保持低秩结构的同时实现与密集模型相当的预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效训练方法在低秩预训练任务中表现不佳，难以同时保持低秩结构和模型目标，需要新的低秩诱导训练策略。

Method: 基于迭代重加权最小二乘框架，提出二次正则化项Q3R，该正则化项主要化了一个平滑对数行列式作为秩替代目标。

Result: 在ViT-Tiny模型上能够截断60%和80%的参数，在CIFAR-10上仅分别损失约1.3%和4%的准确率；在图像和语言任务的Transformer模型上均验证了有效性。

Conclusion: Q3R能够以规定的低目标秩训练权重矩阵，计算开销小，与现有架构完全兼容，在低秩微调中也表现出色。

Abstract: Parameter-efficient training, based on low-rank optimization, has become a
highly successful tool for fine-tuning large deep-learning models. However,
these methods fail at low-rank pre-training tasks where maintaining the
low-rank structure and the objective remains a challenging task. We propose the
Quadratic Reweighted Rank Regularizer dubbed Q3R, which leads to a novel
low-rank inducing training strategy inspired by the iteratively reweighted
least squares (IRLS) framework. Q3R is based on a quadratic regularizer term
which majorizes a smoothed log determinant serving as rank surrogate objective.
Unlike other low-rank training techniques, Q3R is able to train weight matrices
with prescribed, low target ranks of models that achieve comparable predictive
performance as dense models, with small computational overhead, while remaining
fully compatible with existing architectures. For example, we demonstrated one
experiment where we are able to truncate $60\%$ and $80\%$ of the parameters of
a ViT-Tiny model with $~1.3\%$ and $~4\%$ accuracy drop in CIFAR-10 performance
respectively. The efficacy of Q3R is confirmed on Transformers across both
image and language tasks, including for low-rank fine-tuning.

</details>


### [16] [Alternative Fairness and Accuracy Optimization in Criminal Justice](https://arxiv.org/abs/2511.04505)
*Shaolong Wu,James Blume,Geshi Yeung*

Main category: cs.LG

TL;DR: 本文提出了一种改进的群体公平性方法，通过在保护群体间保持假阴性率差异在较小容忍度内，同时最小化加权错误损失，来解决算法公平性在刑事司法中的冲突问题。


<details>
  <summary>Details</summary>
Motivation: 算法公平性研究快速发展，但关键概念仍不明确，特别是在刑事司法领域。群体、个体和过程公平性之间存在冲突，需要开发更实用的公平性框架。

Method: 开发了一种改进的群体公平性方法：不是要求保护群体间完全平等，而是最小化加权错误损失，同时将假阴性率差异控制在较小容忍度内。

Result: 该方法使解决方案更容易找到，可以提高预测准确性，并凸显错误成本的伦理选择。在存在偏见和不完整数据、潜在平权行动和子群约束激增的情况下具有优势。

Conclusion: 提出了一个基于三个支柱的实用部署框架：基于需求的决策、透明度和问责制、以及精确定义和解决方案。这些要素将技术设计与合法性联系起来，为使用风险评估工具的机构提供可操作的指导。

Abstract: Algorithmic fairness has grown rapidly as a research area, yet key concepts
remain unsettled, especially in criminal justice. We review group, individual,
and process fairness and map the conditions under which they conflict. We then
develop a simple modification to standard group fairness. Rather than exact
parity across protected groups, we minimize a weighted error loss while keeping
differences in false negative rates within a small tolerance. This makes
solutions easier to find, can raise predictive accuracy, and surfaces the
ethical choice of error costs. We situate this proposal within three classes of
critique: biased and incomplete data, latent affirmative action, and the
explosion of subgroup constraints. Finally, we offer a practical framework for
deployment in public decision systems built on three pillars: need-based
decisions, Transparency and accountability, and narrowly tailored definitions
and solutions. Together, these elements link technical design to legitimacy and
provide actionable guidance for agencies that use risk assessment and related
tools.

</details>


### [17] [Addressing divergent representations from causal interventions on neural networks](https://arxiv.org/abs/2511.04638)
*Satchel Grant,Simon Jerome Han,Alexa Tartaglini,Christopher Potts*

Main category: cs.LG

TL;DR: 本文研究了机制可解释性中因果干预技术是否会产生分布外表示，分析了无害和有害两类分布偏移，并提出了改进的CL损失函数来减少有害偏移。


<details>
  <summary>Details</summary>
Motivation: 研究因果干预技术是否会产生分布外表示，以及这是否影响解释结果对目标模型自然状态的忠实度。

Method: 首先实证验证常见因果干预技术会导致内部表示偏离自然分布，然后理论分析无害和有害两类分布偏移，最后改进CL损失函数以正则化干预。

Result: 发现常见因果干预技术确实会偏移内部表示，理论区分了无害和有害偏移，改进的CL损失能减少有害偏移同时保持解释能力。

Conclusion: 这些结果为开发更可靠的可解释性方法指明了方向。

Abstract: A common approach to mechanistic interpretability is to causally manipulate
model representations via targeted interventions in order to understand what
those representations encode. Here we ask whether such interventions create
out-of-distribution (divergent) representations, and whether this raises
concerns about how faithful their resulting explanations are to the target
model in its natural state. First, we demonstrate empirically that common
causal intervention techniques often do shift internal representations away
from the natural distribution of the target model. Then, we provide a
theoretical analysis of two classes of such divergences: `harmless' divergences
that occur in the null-space of the weights and from covariance within
behavioral decision boundaries, and `pernicious' divergences that activate
hidden network pathways and cause dormant behavioral changes. Finally, in an
effort to mitigate the pernicious cases, we modify the Counterfactual Latent
(CL) loss from Grant (2025) that regularizes interventions to remain closer to
the natural distributions, reducing the likelihood of harmful divergences while
preserving the interpretive power of interventions. Together, these results
highlight a path towards more reliable interpretability methods.

</details>


### [18] [ARETE: an R package for Automated REtrieval from TExt with large language models](https://arxiv.org/abs/2511.04573)
*Vasco V. Branco,Jandó Benedek,Lidia Pivovarova,Luís Correia,Pedro Cardoso*

Main category: cs.LG

TL;DR: ARETE是一个基于大型语言模型的R包，用于自动化提取物种出现数据，显著提高了数据获取效率，在蜘蛛物种研究中将已知分布范围扩大了三个数量级。


<details>
  <summary>Details</summary>
Motivation: 保护生物学面临的关键挑战是缺乏物种出现数据，且现有文献数据难以机器读取，需要大量人工工作来提取。

Method: 开发ARETE R包，利用chatGPT API实现物种出现数据的自动化提取和验证，包括光学字符识别、异常值检测和表格输出。

Result: 对100种蜘蛛的测试显示，新提取数据使已知分布范围平均扩大了三个数量级，揭示了新的历史分布区域。

Conclusion: ARETE能够快速获取未开发的物种出现数据，改变需要此类数据的项目工作流程，使研究人员能更好地分配资源。

Abstract: 1. A hard stop for the implementation of rigorous conservation initiatives is
our lack of key species data, especially occurrence data. Furthermore,
researchers have to contend with an accelerated speed at which new information
must be collected and processed due to anthropogenic activity. Publications
ranging from scientific papers to gray literature contain this crucial
information but their data are often not machine-readable, requiring extensive
human work to be retrieved. 2. We present the ARETE R package, an open-source
software aiming to automate data extraction of species occurrences powered by
large language models, namely using the chatGPT Application Programming
Interface. This R package integrates all steps of the data extraction and
validation process, from Optical Character Recognition to detection of outliers
and output in tabular format. Furthermore, we validate ARETE through systematic
comparison between what is modelled and the work of human annotators. 3. We
demonstrate the usefulness of the approach by comparing range maps produced
using GBIF data and with those automatically extracted for 100 species of
spiders. Newly extracted data allowed to expand the known Extent of Occurrence
by a mean three orders of magnitude, revealing new areas where the species were
found in the past, which mayhave important implications for spatial
conservation planning and extinction risk assessments. 4. ARETE allows faster
access to hitherto untapped occurrence data, a potential game changer in
projects requiring such data. Researchers will be able to better prioritize
resources, manually verifying selected species while maintaining automated
extraction for the majority. This workflow also allows predicting available
bibliographic data during project planning.

</details>


### [19] [Complexity as Advantage: A Regret-Based Perspective on Emergent Structure](https://arxiv.org/abs/2511.04590)
*Oshri Naparstek*

Main category: cs.LG

TL;DR: CAA框架将系统复杂性定义为相对于观察者家族的预测遗憾差异，认为复杂性源于系统对不同观察者建模难度的差异，从而创造信息优势。


<details>
  <summary>Details</summary>
Motivation: 传统复杂性度量将复杂性视为系统内在属性，而CAA框架旨在从观察者依赖的角度重新定义复杂性，强调复杂性如何在不同观察者之间产生预测能力差异。

Method: 通过定义系统相对于观察者家族的预测遗憾，评估系统对不同观察者建模的难度差异，建立复杂性作为信息优势的概念框架。

Result: CAA框架统一了多种涌现行为概念（如多尺度熵、预测信息、观察者依赖结构），表明"有趣"系统是那些能在观察者间产生差异化预测遗憾的系统。

Conclusion: 复杂性可以被功能性地利用，因为它创造了观察者之间的信息不对称，为理解复杂性在学习和进化中的价值提供了量化基础。

Abstract: We introduce Complexity as Advantage (CAA), a framework that defines the
complexity of a system relative to a family of observers. Instead of measuring
complexity as an intrinsic property, we evaluate how much predictive regret a
system induces for different observers attempting to model it. A system is
complex when it is easy for some observers and hard for others, creating an
information advantage. We show that this formulation unifies several notions of
emergent behavior, including multiscale entropy, predictive information, and
observer-dependent structure. The framework suggests that "interesting" systems
are those positioned to create differentiated regret across observers,
providing a quantitative grounding for why complexity can be functionally
valuable. We demonstrate the idea through simple dynamical models and discuss
implications for learning, evolution, and artificial agents.

</details>


### [20] [Regret Lower Bounds for Decentralized Multi-Agent Stochastic Shortest Path Problems](https://arxiv.org/abs/2511.04594)
*Utkarsh U. Chavan,Prashant Trivedi,Nandyala Hemachandra*

Main category: cs.LG

TL;DR: 本文研究了去中心化多智能体随机最短路径问题（Dec-MASSPs），在线性函数逼近框架下分析了最优策略结构，并首次建立了该设置的遗憾下界Ω(√K)。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在群体机器人和交通路由等应用中至关重要，但去中心化多智能体随机最短路径问题的学习问题尚未得到充分探索。

Method: 在线性函数逼近框架下，应用基于对称性的新颖论证来识别最优策略结构，并构建难以学习的实例来建立遗憾下界。

Result: 建立了去中心化多智能体随机最短路径问题的首个遗憾下界Ω(√K)，揭示了该设置中固有的学习难度。

Conclusion: 这些见解阐明了去中心化控制的学习复杂性，可为多智能体系统中高效学习算法的设计提供指导。

Abstract: Multi-agent systems (MAS) are central to applications such as swarm robotics
and traffic routing, where agents must coordinate in a decentralized manner to
achieve a common objective. Stochastic Shortest Path (SSP) problems provide a
natural framework for modeling decentralized control in such settings. While
the problem of learning in SSP has been extensively studied in single-agent
settings, the decentralized multi-agent variant remains largely unexplored. In
this work, we take a step towards addressing that gap. We study decentralized
multi-agent SSPs (Dec-MASSPs) under linear function approximation, where the
transition dynamics and costs are represented using linear models. Applying
novel symmetry-based arguments, we identify the structure of optimal policies.
Our main contribution is the first regret lower bound for this setting based on
the construction of hard-to-learn instances for any number of agents, $n$. Our
regret lower bound of $\Omega(\sqrt{K})$, over $K$ episodes, highlights the
inherent learning difficulty in Dec-MASSPs. These insights clarify the learning
complexity of decentralized control and can further guide the design of
efficient learning algorithms in multi-agent systems.

</details>


### [21] [Multi-Method Analysis of Mathematics Placement Assessments: Classical, Machine Learning, and Clustering Approaches](https://arxiv.org/abs/2511.04667)
*Julian D. Allagan,Dasia A. Singleton,Shanae N. Perry,Gabrielle C. Morgan,Essence A. Morgan*

Main category: cs.LG

TL;DR: 本研究采用经典测验理论、机器学习和无监督聚类相结合的多方法框架，评估了198名学生参加的40项数学分班考试。结果显示55%的项目具有优秀区分度，30%需要替换；第6题是最佳区分项；机器学习算法准确率达97.5%；聚类分析发现42.5%的自然能力边界，建议优化分班标准。


<details>
  <summary>Details</summary>
Motivation: 通过多方法整合为数学分班考试提供实证基础，优化分班决策的准确性和科学性。

Method: 结合经典测验理论、机器学习算法（随机森林、梯度提升）和无监督聚类（K-means），分析40项数学分班考试数据。

Result: 55%项目区分度优秀，30%需要替换；第6题区分度最佳；机器学习准确率97.5%；聚类发现42.5%自然能力边界，与机构55%标准存在差异；两聚类方案稳定性高。

Conclusion: 多方法整合为基于证据的数学分班优化提供了稳健的实证基础，建议替换低区分度项目、实施两阶段评估、整合随机森林预测并确保透明度。

Abstract: This study evaluates a 40-item mathematics placement examination administered
to 198 students using a multi-method framework combining Classical Test Theory,
machine learning, and unsupervised clustering. Classical Test Theory analysis
reveals that 55\% of items achieve excellent discrimination ($D \geq 0.40$)
while 30\% demonstrate poor discrimination ($D < 0.20$) requiring replacement.
Question 6 (Graph Interpretation) emerges as the examination's most powerful
discriminator, achieving perfect discrimination ($D = 1.000$), highest ANOVA
F-statistic ($F = 4609.1$), and maximum Random Forest feature importance
(0.206), accounting for 20.6\% of predictive power. Machine learning algorithms
demonstrate exceptional performance, with Random Forest and Gradient Boosting
achieving 97.5\% and 96.0\% cross-validation accuracy. K-means clustering
identifies a natural binary competency structure with a boundary at 42.5\%,
diverging from the institutional threshold of 55\% and suggesting potential
overclassification into remedial categories. The two-cluster solution exhibits
exceptional stability (bootstrap ARI = 0.855) with perfect lower-cluster
purity. Convergent evidence across methods supports specific refinements:
replace poorly discriminating items, implement a two-stage assessment, and
integrate Random Forest predictions with transparency mechanisms. These
findings demonstrate that multi-method integration provides a robust empirical
foundation for evidence-based mathematics placement optimization.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [22] [Score-Based Quickest Change Detection and Fault Identification for Multi-Stream Signals](https://arxiv.org/abs/2511.03967)
*Wuxia Chen,Sean Moushegian,Vahid Tarokh,Taposh Banerjee*

Main category: eess.SP

TL;DR: 该论文提出了一种基于Hyvarinen分数的min-SCUSUM方法，用于多流快速变化检测和故障隔离，替代传统需要显式分布计算似然比的方法。


<details>
  <summary>Details</summary>
Motivation: 传统快速变化检测算法需要显式的前后变化分布来计算观测值的似然比，对于高维数据和复杂机器学习模型计算成本高甚至不可行。

Method: 提出min-SCUSUM方法，使用Hyvarinen分数函数差异替代对数似然比计算，适用于未归一化和基于分数的统计模型。

Result: 算法延迟和误报分析表明其渐近性能取决于前后变化分布之间的Fisher散度，并建立了故障误识别概率的上界。

Conclusion: 该方法为复杂模型的高维数据变化检测提供了可行的替代方案，无需显式分布假设。

Abstract: This paper introduces an approach to multi-stream quickest change detection
and fault isolation for unnormalized and score-based statistical models.
Traditional optimal algorithms in the quickest change detection literature
require explicit pre-change and post-change distributions to calculate the
likelihood ratio of the observations, which can be computationally expensive
for higher-dimensional data and sometimes even infeasible for complex machine
learning models. To address these challenges, we propose the min-SCUSUM method,
a Hyvarinen score-based algorithm that computes the difference of score
functions in place of log-likelihood ratios. We provide a delay and false alarm
analysis of the proposed algorithm, showing that its asymptotic performance
depends on the Fisher divergence between the pre- and post-change
distributions. Furthermore, we establish an upper bound on the probability of
fault misidentification in distinguishing the affected stream from the
unaffected ones.

</details>


### [23] [Optimal RIS Placement in a Multi-User MISO System with User Randomness](https://arxiv.org/abs/2511.03998)
*Abhishek Rajasekaran,Mehdi Karbalayghareh,Xiaoyan Ma,David J. Love,Christopher G. Brinton*

Main category: eess.SP

TL;DR: 本文提出了一种递归粗到细的方法来优化可重构智能表面(RIS)的放置位置，考虑用户随机性和障碍物配置，以最大化系统的最小信干噪比(SINR)。


<details>
  <summary>Details</summary>
Motivation: 现有RIS辅助系统研究大多假设用户位置已知，但实际部署时通常只知道用户密度分布和障碍物配置。因此需要开发在用户位置不确定情况下的RIS放置优化方法。

Method: 采用递归粗到细搜索方法：基于障碍物配置构建候选位置集合，通过多次用户分布实例评估这些位置，并在每个阶段识别的最优区域内递归细化搜索，最终确定RIS部署的最佳区域。

Result: 数值结果验证了所提方法的有效性，能够找到在用户位置随机情况下的最优RIS部署位置。

Conclusion: 提出的递归粗到细方法能够有效解决用户位置不确定情况下的RIS放置优化问题，为实际系统部署提供了可行的解决方案。

Abstract: It is well established that the performance of reconfigurable intelligent
surface (RIS)-assisted systems critically depends on the optimal placement of
the RIS. Previous works consider either simple coverage maximization or
simultaneous optimization of the placement of the RIS along with the
beamforming and reflection coefficients, most of which assume that the location
of the RIS, base station (BS), and users are known. However, in practice, only
the spatial variation of user density and obstacle configuration are likely to
be known prior to deployment of the system. Thus, we formulate a non-convex
problem that optimizes the position of the RIS over the expected minimum
signal-to-interference-plus-noise ratio (SINR) of the system with user
randomness, assuming that the system employs joint beamforming after
deployment. To solve this problem, we propose a recursive coarse-to-fine
methodology that constructs a set of candidate locations for RIS placement
based on the obstacle configuration and evaluates them over multiple
instantiations from the user distribution. The search is recursively refined
within the optimal region identified in each stage to determine the final
optimal region for RIS deployment. Numerical results are presented to
corroborate our findings.

</details>


### [24] [High-Resolution Forest Mapping from L-Band Interferometric SAR Time Series using Deep Learning over Northern Spain](https://arxiv.org/abs/2511.04362)
*Chiara Telli,Oleg Antropov,Anne Lönnqvist,Marco Lavalle*

Main category: eess.SP

TL;DR: 本研究探讨了使用L波段干涉时间序列数据和深度学习模型进行高分辨率森林制图的潜力，通过比较不同UNet架构和输入特征组合，发现结合强度数据和干涉相干性特征能显著提高森林高度反演精度。


<details>
  <summary>Details</summary>
Motivation: 利用L波段干涉时间序列数据和深度学习技术改进高分辨率森林制图，为NISAR和未来ROSE-L任务提供有效的森林高度反演方法。

Method: 使用9幅ALOS-2 PALSAR-2双极化SAR图像的时间序列数据，比较了Vanilla UNet、带注意力机制的SeU-Net和嵌套结构UNet等深度学习模型，结合不同极化、干涉特征组合进行森林高度反演。

Result: 仅使用强度数据时，20米分辨率的森林高度反演精度为3.1-3.8米（R2=0.45-0.55）；结合强度与干涉相干性特征后，精度提高至小于2.8米。在60米分辨率下，仅使用强度的最佳RMSE为2.2米，使用所有合适输入特征时误差降至1.95米。

Conclusion: 建议采用这种结合强度数据和干涉相干性特征的混合方法进行L波段SAR反演，该方法也适用于NISAR和未来ROSE-L任务。

Abstract: In this study, we examine the potential of high-resolution forest mapping
using L-band interferometric time series datasets and deep learning modeling.
Our SAR data are represented by a time series of nine ALOS-2 PALSAR-2 dual-pol
SAR images acquired at near-zero spatial baseline over a study site in
Asturias, Northern Spain. Reference data are collected using airborne laser
scanning. We examine the performance of several candidate deep learning models
from UNet-family with various combinations of input polarimetric and
interferometric features. In addition to basic Vanilla UNet, attention
reinforced UNet model with squeeze-excitation blocks (SeU-Net) and advanced
UNet model with nested structure and skip pathways are used. Studied features
include dual pol interferometric observables additionally incorporating
model-based derived measures. Results show that adding model-based inverted
InSAR features or InSAR coherence layers improves retrieval accuracy compared
to using backscatter intensity only. Use of attention mechanisms and nested
connection fusion provides better predictions than using Vanilla UNet or
traditional machine learning methods. Forest height retrieval accuracies range
between 3.1-3.8 m (R2 = 0.45--0.55) at 20 m resolution when only intensity data
are used, and improve to less than 2.8 m when both intensity and
interferometric coherence features are included. At 40 m and 60 m resolution,
retrieval performance further improves, primarily due to higher SNR in both the
intensity and interferometric layers. When using intensity at 60 m resolution,
best achieved RMSE is 2.2 m, while when using all suitable input features the
achieved error is 1.95 m. We recommend this hybrid approach for L-band SAR
retrievals also suitable for NISAR and future ROSE-L missions.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [25] [Transportability of Prognostic Markers: Rethinking Common Practices through a Sufficient-Component-Cause Perspective](https://arxiv.org/abs/2511.04065)
*Mohsen Sadatsafavi,Gavin Pereira,Wenjia Chen*

Main category: stat.AP

TL;DR: 本文通过充分成分原因(SCC)框架重新审视预后标志物的可移植性，挑战了传统的可移植性假设和实践，提出了基于病因分布变化的新运输算法。


<details>
  <summary>Details</summary>
Motivation: 预后标志物在不同人群中往往表现出不同的性能，需要可移植性。传统方法要么假设预测值可移植，要么通过患病率调整转移可移植性到准确性指标，但这些方法都依赖于强假设。

Method: 使用最小化的充分成分原因(SCC)框架，将风险预测分解为其因果成分，分析不同运输方法所依赖的假设，并提出基于病因分布变化的新运输算法。

Result: 数值实验表明，不同的可移植性假设会导致不同程度的信息损失，具体取决于人群在病因分布上的差异。在没有外部信息的情况下，采用原因中性视角可以推导出新的标志物运输形式。

Conclusion: SCC视角挑战了标志物可移植性的常见假设和实践，提出了反映我们对病因在人群间变化知识或假设的运输算法，使运输假设更加透明。

Abstract: Transportability, the ability to maintain performance across populations, is
a desirable property of of markers of clinical outcomes. However, empirical
findings indicate that markers often exhibit varying performances across
populations. For prognostic markers whose results are used to quantify of the
risk of an outcome, oftentimes a form of updating is required when the marker
is transported to populations with different disease prevalences. Here, we
revisit transportability of prognostic markers through the lens of the
foundational framework of sufficient component causes (SCC). We argue that
transporting a marker "as is" implicitly assumes predictive values are
transportable, whereas conventional prevalence-adjustment shifts the locus of
transportability to accuracy metrics (sensitivity and specificity). Using a
minimalist SCC framework that decomposes risk prediction into its causal
constituents, we show that both approaches rely on strong assumptions about the
stability of cause distributions across populations. A SCC framework instead
invites making transparent assumptions about how different causes vary across
populations, leading to different transportation methods. For example, in the
absence of any external information other than disease prevalence, a
cause-neutral perspective can assume all causes are responsible for change in
prevalence, leading to a new form of marker transportation. Numerical
experiments demonstrate that different transportability assumptions lead to
varying degrees of information loss, depending on how population differ from
each other in the distribution of causes. A SCC perspective challenges common
assumptions and practices for marker transportability, and proposes
transportation algorithms that reflect our knowledge or assumptions about how
causes vary across populations.

</details>


### [26] [Nonparametric Safety Stock Dimensioning: A Data-Driven Approach for Supply Chains of Hardware OEMs](https://arxiv.org/abs/2511.04616)
*Elvis Agbenyega,Cody Quick*

Main category: stat.AP

TL;DR: 本文提出了一种数据驱动的方法来优化安全库存配置，通过核密度估计放松了对需求正态分布的假设，并考虑了预测需求变异性，在模拟和优化模型中显示出优于传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 传统安全库存计算方法严重假设需求服从正态分布，忽略了未来需求变异性，在制造业中需求通常是非正态、间歇性和高度偏态的情况下适用性有限。

Method: 使用核密度估计分析确定每个库存项目的需求分布，将分析从历史需求变异性扩展到预测需求变异性，通过近真实库存补货模拟和线性优化模型评估方法性能。

Result: 模拟和线性优化模型结果显示，数据驱动方法优于传统方法，在较低的安全库存水平下实现了期望的服务水平。

Conclusion: 数据驱动方法能够更有效地配置安全库存，在保证服务水平的同时降低库存成本，特别适用于需求分布非正态的制造业环境。

Abstract: Resilient supply chains are critical, especially for Original Equipment
Manufacturers (OEMs) that power today's digital economy. Safety Stock
dimensioning-the computation of the appropriate safety stock quantity-is one of
several mechanisms to ensure supply chain resiliency, as it protects the supply
chain against demand and supply uncertainties. Unfortunately, the major
approaches to dimensioning safety stock heavily assume that demand is normally
distributed and ignore future demand variability, limiting their applicability
in manufacturing contexts where demand is non-normal, intermittent, and highly
skewed. In this paper, we propose a data-driven approach that relaxes the
assumption of normality, enabling the demand distribution of each inventory
item to be analytically determined using Kernel Density Estimation. Also, we
extended the analysis from historical demand variability to forecasted demand
variability. We evaluated the proposed approach against a normal distribution
model in a near-world inventory replenishment simulation. Afterwards, we used a
linear optimization model to determine the optimal safety stock configuration.
The results from the simulation and linear optimization models showed that the
data-driven approach outperformed traditional approaches. In particular, the
data-driven approach achieved the desired service levels at lower safety stock
levels than the conventional approaches.

</details>


### [27] [Dynamic causal discovery in Alzheimer's disease through latent pseudotime modelling](https://arxiv.org/abs/2511.04619)
*Natalia Glazman,Jyoti Mangal,Pedro Borges,Sebastien Ourselin,M. Jorge Cardoso*

Main category: stat.AP

TL;DR: 本研究提出了一种动态因果发现框架，通过推断疾病伪时间轨迹来分析阿尔茨海默病的演化病理生理学，克服了传统静态图方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统因果发现方法假设静态图结构，无法捕捉阿尔茨海默病等疾病的动态演化病理生理过程，特别是受潜在疾病伪时间调制的因果关系变化。

Method: 应用现有潜变量模型推断独立于实际年龄的疾病伪时间，将患者沿数据驱动的疾病轨迹排序，然后学习因果关系的演化过程，并融入最小化疾病无关的背景知识。

Result: 伪时间在预测诊断方面优于实际年龄（AUC 0.82 vs 0.59），结合背景知识显著提高了图准确性和方向性，揭示了新型标志物与已确立AD标志物之间的动态相互作用。

Conclusion: 该框架能够在假设被违反的情况下实现实用的因果发现，为理解阿尔茨海默病的动态病理过程提供了新视角。

Abstract: The application of causal discovery to diseases like Alzheimer's (AD) is
limited by the static graph assumptions of most methods; such models cannot
account for an evolving pathophysiology, modulated by a latent disease
pseudotime. We propose to apply an existing latent variable model to real-world
AD data, inferring a pseudotime that orders patients along a data-driven
disease trajectory independent of chronological age, then learning how causal
relationships evolve. Pseudotime outperformed age in predicting diagnosis (AUC
0.82 vs 0.59). Incorporating minimal, disease-agnostic background knowledge
substantially improved graph accuracy and orientation. Our framework reveals
dynamic interactions between novel (NfL, GFAP) and established AD markers,
enabling practical causal discovery despite violated assumptions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [28] [How Different Tokenization Algorithms Impact LLMs and Transformer Models for Binary Code Analysis](https://arxiv.org/abs/2511.03825)
*Ahmed Mostafa,Raisul Arefin Nahid,Samuel Mulder*

Main category: cs.AI

TL;DR: 该研究评估了NLP分词模型在汇编代码分析中的内在特性，包括词汇量大小、语义覆盖等，并探讨了预处理定制和预分词规则对下游任务（如函数签名预测）的影响。


<details>
  <summary>Details</summary>
Motivation: 汇编代码分词在代码分析中至关重要，但该领域研究不足，需要系统评估分词模型的内在特性和参数选择对下游任务的影响。

Method: 使用多种分词模型（包括Llama 3.2、BERT、BART等预训练模型），通过内在评估比较分词效率、词汇压缩和表示保真度，并评估其在函数签名预测等下游任务中的效果。

Result: 初步发现表明分词器选择显著影响下游性能，内在指标只能部分预测外在评估结果，揭示了内在分词器特性与实际应用之间的复杂权衡。

Conclusion: 该研究为低级代码分析中的分词模型优化提供了宝贵见解，有助于提升基于自然语言模型的二进制分析工作流程的鲁棒性和可扩展性。

Abstract: Tokenization is fundamental in assembly code analysis, impacting intrinsic
characteristics like vocabulary size, semantic coverage, and extrinsic
performance in downstream tasks. Despite its significance, tokenization in the
context of assembly code remains an underexplored area. This study aims to
address this gap by evaluating the intrinsic properties of Natural Language
Processing (NLP) tokenization models and parameter choices, such as vocabulary
size. We explore preprocessing customization options and pre-tokenization rules
tailored to the unique characteristics of assembly code. Additionally, we
assess their impact on downstream tasks like function signature prediction -- a
critical problem in binary code analysis.
  To this end, we conduct a thorough study on various tokenization models,
systematically analyzing their efficiency in encoding assembly instructions and
capturing semantic nuances. Through intrinsic evaluations, we compare
tokenizers based on tokenization efficiency, vocabulary compression, and
representational fidelity for assembly code. Using state-of-the-art pre-trained
models such as the decoder-only Large Language Model (LLM) Llama 3.2, the
encoder-only transformer BERT, and the encoder-decoder model BART, we evaluate
the effectiveness of these tokenizers across multiple performance metrics.
Preliminary findings indicate that tokenizer choice significantly influences
downstream performance, with intrinsic metrics providing partial but incomplete
predictability of extrinsic evaluation outcomes. These results reveal complex
trade-offs between intrinsic tokenizer properties and their utility in
practical assembly code tasks. Ultimately, this study provides valuable
insights into optimizing tokenization models for low-level code analysis,
contributing to the robustness and scalability of Natural Language Model
(NLM)-based binary analysis workflows.

</details>


### [29] [Extracting Causal Relations in Deep Knowledge Tracing](https://arxiv.org/abs/2511.03948)
*Kevin Hong,Kia Karbasi,Gregory Pottie*

Main category: cs.AI

TL;DR: 本文挑战了关于深度知识追踪(DKT)性能优势的普遍解释，证明DKT的优势在于其隐式建模先决条件关系作为因果结构的能力，而非双向关系。


<details>
  <summary>Details</summary>
Motivation: 长期以来，计算教育研究的目标是开发可解释的知识追踪模型。DKT被认为比传统KT方法有重大进步，但对其性能来源的解释存在争议。

Method: 通过将练习关系图修剪为有向无环图(DAGs)，并在Assistments数据集的因果子集上训练DKT，分析其预测能力与因果结构的对齐程度。

Result: 实验表明DKT的预测能力与因果结构高度一致，并提出了基于DKT学习表示提取练习关系DAGs的替代方法。

Conclusion: DKT的有效性主要源于其近似知识组件间因果依赖关系的能力，而非简单的关系映射。

Abstract: A longstanding goal in computational educational research is to develop
explainable knowledge tracing (KT) models. Deep Knowledge Tracing (DKT), which
leverages a Recurrent Neural Network (RNN) to predict student knowledge and
performance on exercises, has been proposed as a major advancement over
traditional KT methods. Several studies suggest that its performance gains stem
from its ability to model bidirectional relationships between different
knowledge components (KCs) within a course, enabling the inference of a
student's understanding of one KC from their performance on others. In this
paper, we challenge this prevailing explanation and demonstrate that DKT's
strength lies in its implicit ability to model prerequisite relationships as a
causal structure, rather than bidirectional relationships. By pruning exercise
relation graphs into Directed Acyclic Graphs (DAGs) and training DKT on causal
subsets of the Assistments dataset, we show that DKT's predictive capabilities
align strongly with these causal structures. Furthermore, we propose an
alternative method for extracting exercise relation DAGs using DKT's learned
representations and provide empirical evidence supporting our claim. Our
findings suggest that DKT's effectiveness is largely driven by its capacity to
approximate causal dependencies between KCs rather than simple relational
mappings.

</details>


### [30] [LLMs and Cultural Values: the Impact of Prompt Language and Explicit Cultural Framing](https://arxiv.org/abs/2511.03980)
*Bram Bulté,Ayla Rigouts Terryn*

Main category: cs.AI

TL;DR: 本研究探讨大型语言模型（LLMs）在文化价值观表达方面的局限性，发现虽然提示语言和文化框架会影响模型输出，但LLMs存在系统性偏见，倾向于荷兰、德国、美国和日本等少数国家的价值观，无法充分代表文化多样性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在全球范围内被不同语言的用户广泛使用，研究其是否能代表用户群体的文化多样性成为重要问题。现有研究表明训练数据和优化目标存在不平衡，引发了对LLMs文化代表性的质疑。

Method: 使用63个来自Hofstede价值观调查模块和世界价值观调查的项目，翻译成11种语言，以有/无明确文化视角的提示形式测试10个LLMs。

Result: 提示语言和文化视角都会导致LLM输出变化，但无法克服模型对荷兰、德国、美国和日本等少数国家价值观的系统性偏见。所有模型都表现出相似模式：在大多数话题上保持中立，在社交宽容等议题上持选择性进步立场。

Conclusion: LLMs处于尴尬的中间地带：对提示变化足够敏感以产生变化，但又过于固守特定文化默认值，无法充分代表文化多样性。明确的文化视角比针对性提示语言更能改善与人类受访者文化价值观的一致性。

Abstract: Large Language Models (LLMs) are rapidly being adopted by users across the
globe, who interact with them in a diverse range of languages. At the same
time, there are well-documented imbalances in the training data and
optimisation objectives of this technology, raising doubts as to whether LLMs
can represent the cultural diversity of their broad user base. In this study,
we look at LLMs and cultural values and examine how prompt language and
cultural framing influence model responses and their alignment with human
values in different countries. We probe 10 LLMs with 63 items from the Hofstede
Values Survey Module and World Values Survey, translated into 11 languages, and
formulated as prompts with and without different explicit cultural
perspectives. Our study confirms that both prompt language and cultural
perspective produce variation in LLM outputs, but with an important caveat:
While targeted prompting can, to a certain extent, steer LLM responses in the
direction of the predominant values of the corresponding countries, it does not
overcome the models' systematic bias toward the values associated with a
restricted set of countries in our dataset: the Netherlands, Germany, the US,
and Japan. All tested models, regardless of their origin, exhibit remarkably
similar patterns: They produce fairly neutral responses on most topics, with
selective progressive stances on issues such as social tolerance. Alignment
with cultural values of human respondents is improved more with an explicit
cultural perspective than with a targeted prompt language. Unexpectedly,
combining both approaches is no more effective than cultural framing with an
English prompt. These findings reveal that LLMs occupy an uncomfortable middle
ground: They are responsive enough to changes in prompts to produce variation,
but too firmly anchored to specific cultural defaults to adequately represent
cultural diversity.

</details>


### [31] [Detecting Silent Failures in Multi-Agentic AI Trajectories](https://arxiv.org/abs/2511.04032)
*Divya Pathak,Harshit Kumar,Anuska Roy,Felix George,Mudit Verma,Pratibha Moogi*

Main category: cs.AI

TL;DR: 该论文提出了多智能体AI系统中的异常检测任务，构建了两个包含4,275和894条轨迹的数据集，并评估了监督和半监督方法，最高准确率达98%。


<details>
  <summary>Details</summary>
Motivation: 多智能体AI系统具有非确定性，容易出现漂移、循环和输出细节缺失等静默故障，这些故障难以检测。

Method: 开发了一个数据集构建流程，捕捉用户行为、智能体非确定性和LLM变化，并创建了两个基准数据集。使用XGBoost（监督）和SVDD（半监督）方法进行异常检测。

Result: 监督方法（XGBoost）和半监督方法（SVDD）表现相当，分别达到98%和96%的准确率。

Conclusion: 这是对多智能体AI系统中异常检测的首次系统性研究，提供了数据集、基准和见解，为未来研究提供指导。

Abstract: Multi-Agentic AI systems, powered by large language models (LLMs), are
inherently non-deterministic and prone to silent failures such as drift,
cycles, and missing details in outputs, which are difficult to detect. We
introduce the task of anomaly detection in agentic trajectories to identify
these failures and present a dataset curation pipeline that captures user
behavior, agent non-determinism, and LLM variation. Using this pipeline, we
curate and label two benchmark datasets comprising \textbf{4,275 and 894}
trajectories from Multi-Agentic AI systems. Benchmarking anomaly detection
methods on these datasets, we show that supervised (XGBoost) and
semi-supervised (SVDD) approaches perform comparably, achieving accuracies up
to 98% and 96%, respectively. This work provides the first systematic study of
anomaly detection in Multi-Agentic AI systems, offering datasets, benchmarks,
and insights to guide future research.

</details>


### [32] [Interpreting Multi-Attribute Confounding through Numerical Attributes in Large Language Models](https://arxiv.org/abs/2511.04053)
*Hirohane Takagi,Gouki Minegishi,Shota Kizawa,Issey Sukeda,Hitomi Yanaka*

Main category: cs.AI

TL;DR: 该研究探讨了大语言模型在数值推理中的内部表示机制，发现LLMs会编码现实世界的数值相关性但系统性地放大它们，无关的数值上下文会导致表示偏移，这些发现揭示了LLM决策中的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 尽管行为研究已记录了大语言模型在数值推理中的错误，但潜在的表示机制仍不清楚。研究者假设数值属性占据共享的潜在子空间，并探讨LLMs如何内部整合单个实体的多个数值属性，以及无关数值上下文如何干扰这些表示及其下游输出。

Method: 结合线性探测与偏相关分析，以及在不同规模模型上进行基于提示的脆弱性测试。

Result: 结果显示LLMs编码了现实世界的数值相关性但倾向于系统性地放大它们。此外，无关上下文会导致幅度表示的一致偏移，其下游影响因模型规模而异。

Conclusion: 这些发现揭示了LLM决策中的脆弱性，并为在多属性纠缠下实现更公平、表示感知的控制奠定了基础。

Abstract: Although behavioral studies have documented numerical reasoning errors in
large language models (LLMs), the underlying representational mechanisms remain
unclear. We hypothesize that numerical attributes occupy shared latent
subspaces and investigate two questions:(1) How do LLMs internally integrate
multiple numerical attributes of a single entity? (2)How does irrelevant
numerical context perturb these representations and their downstream outputs?
To address these questions, we combine linear probing with partial correlation
analysis and prompt-based vulnerability tests across models of varying sizes.
Our results show that LLMs encode real-world numerical correlations but tend to
systematically amplify them. Moreover, irrelevant context induces consistent
shifts in magnitude representations, with downstream effects that vary by model
size. These findings reveal a vulnerability in LLM decision-making and lay the
groundwork for fairer, representation-aware control under multi-attribute
entanglement.

</details>


### [33] [Opus: A Quantitative Framework for Workflow Evaluation](https://arxiv.org/abs/2511.04220)
*Alan Seroul,Théo Fagnoni,Inès Adnani,Dana O. Mohamed,Phillip Kingston*

Main category: cs.AI

TL;DR: 本文介绍了Opus工作流评估框架，这是一个概率-规范化的数学框架，用于量化工作流质量和效率，结合了正确性、可靠性和成本评估。


<details>
  <summary>Details</summary>
Motivation: 需要一种系统性的方法来评估和优化工作流的质量和效率，支持自动化工作流评估、排名和优化。

Method: 结合Opus工作流奖励（概率函数估计预期性能）和Opus工作流规范惩罚（测量结构信息质量），形成统一的数学模型。

Result: 提出了一个支持工作流自动评估、排名和优化的框架，可集成到强化学习循环中指导工作流发现和优化。

Conclusion: 该框架为工作流质量评估和优化提供了统一的数学基础，支持在奖励-惩罚权衡下识别和排名最优工作流。

Abstract: This paper introduces the Opus Workflow Evaluation Framework, a
probabilistic-normative formulation for quantifying Workflow quality and
efficiency. It integrates notions of correctness, reliability, and cost into a
coherent mathematical model that enables direct comparison, scoring, and
optimization of Workflows. The framework combines the Opus Workflow Reward, a
probabilistic function estimating expected performance through success
likelihood, resource usage, and output gain, with the Opus Workflow Normative
Penalties, a set of measurable functions capturing structural and informational
quality across Cohesion, Coupling, Observability, and Information Hygiene. It
supports automated Workflow assessment, ranking, and optimization within modern
automation systems such as Opus and can be integrated into Reinforcement
Learning loops to guide Workflow discovery and refinement. In this paper, we
introduce the Opus Workflow Reward model that formalizes Workflow success as a
probabilistic expectation over costs and outcomes. We define measurable Opus
Workflow Normative Penalties capturing structural, semantic, and signal-related
properties of Workflows. Finally, we propose a unified optimization formulation
for identifying and ranking optimal Workflows under joint Reward-Penalty
trade-offs.

</details>


### [34] [Shared Spatial Memory Through Predictive Coding](https://arxiv.org/abs/2511.04235)
*Zhengru Fang,Yu Guo,Jingjing Wang,Yuang Zhang,Haonan An,Yinhai Wang,Yuguang Fang*

Main category: cs.AI

TL;DR: 提出了一种多智能体预测编码框架，通过最小化智能体间的互不确定性来解决协调问题。该框架基于网格细胞状的空间编码，自发产生社交位置细胞，在带宽受限环境下表现出卓越的协调能力。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，部分可观测性和有限带宽常常导致协调失败，需要开发能够有效共享和重建一致空间记忆的方法。

Method: 采用多智能体预测编码框架，将协调问题公式化为互不确定性最小化，使用信息瓶颈目标让智能体学习何时、与谁、以及如何通信。基于自监督运动预测产生的网格细胞状空间编码，智能体逐步发展出带宽高效的通信机制和社交位置细胞。

Result: 在Memory-Maze基准测试中，该方法对带宽限制表现出卓越的韧性：当带宽从128位/步缩减到4位/步时，成功率从73.5%优雅下降到64.4%，而全广播基线从67.6%崩溃到28.6%。

Conclusion: 研究为复杂社交表征如何从统一的预测驱动中涌现提供了理论原则和生物学上合理的基础，从而实现了社交集体智能。

Abstract: Sharing and reconstructing a consistent spatial memory is a critical
challenge in multi-agent systems, where partial observability and limited
bandwidth often lead to catastrophic failures in coordination. We introduce a
multi-agent predictive coding framework that formulate coordination as the
minimization of mutual uncertainty among agents. Instantiated as an information
bottleneck objective, it prompts agents to learn not only who and what to
communicate but also when. At the foundation of this framework lies a
grid-cell-like metric as internal spatial coding for self-localization,
emerging spontaneously from self-supervised motion prediction. Building upon
this internal spatial code, agents gradually develop a bandwidth-efficient
communication mechanism and specialized neural populations that encode
partners' locations: an artificial analogue of hippocampal social place cells
(SPCs). These social representations are further enacted by a hierarchical
reinforcement learning policy that actively explores to reduce joint
uncertainty. On the Memory-Maze benchmark, our approach shows exceptional
resilience to bandwidth constraints: success degrades gracefully from 73.5% to
64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast
baseline collapses from 67.6% to 28.6%. Our findings establish a theoretically
principled and biologically plausible basis for how complex social
representations emerge from a unified predictive drive, leading to social
collective intelligence.

</details>


### [35] [Probing the Probes: Methods and Metrics for Concept Alignment](https://arxiv.org/abs/2511.04312)
*Jacob Lysnæs-Larsen,Marte Eggen,Inga Strümke*

Main category: cs.AI

TL;DR: 论文指出在可解释AI中，仅凭概念激活向量（CAV）探针的分类准确率不能可靠衡量概念对齐度，因为探针更容易捕捉虚假相关性而非真正概念。作者提出了基于空间线性归因的新概念定位方法，并提出了三类定量评估概念对齐的指标。


<details>
  <summary>Details</summary>
Motivation: 当前CAV方法仅依赖探针分类准确率来评估概念对齐度，但这种方法不可靠，因为探针可能捕捉虚假相关性而非真正概念。需要更可靠的评估方法来确保CAV真正代表目标概念。

Method: 1）分析标准探针与故意错位探针的性能差异；2）提出基于空间线性归因的新概念定位方法；3）引入三类概念对齐评估指标：硬准确率、分割分数和增强鲁棒性；4）比较现有特征可视化技术。

Result: 故意错位探针利用虚假相关性也能达到接近标准探针的准确率，证明仅凭准确率不可靠。具有平移不变性和空间对齐的探针能持续提高概念对齐度。新提出的评估指标能更可靠地检测概念对齐。

Conclusion: 需要基于对齐度的评估指标而非探针准确率，探针设计应考虑模型架构和目标概念特性。空间对齐和平移不变性对提高概念对齐度至关重要。

Abstract: In explainable AI, Concept Activation Vectors (CAVs) are typically obtained
by training linear classifier probes to detect human-understandable concepts as
directions in the activation space of deep neural networks. It is widely
assumed that a high probe accuracy indicates a CAV faithfully representing its
target concept. However, we show that the probe's classification accuracy alone
is an unreliable measure of concept alignment, i.e., the degree to which a CAV
captures the intended concept. In fact, we argue that probes are more likely to
capture spurious correlations than they are to represent only the intended
concept. As part of our analysis, we demonstrate that deliberately misaligned
probes constructed to exploit spurious correlations, achieve an accuracy close
to that of standard probes. To address this severe problem, we introduce a
novel concept localization method based on spatial linear attribution, and
provide a comprehensive comparison of it to existing feature visualization
techniques for detecting and mitigating concept misalignment. We further
propose three classes of metrics for quantitatively assessing concept
alignment: hard accuracy, segmentation scores, and augmentation robustness. Our
analysis shows that probes with translation invariance and spatial alignment
consistently increase concept alignment. These findings highlight the need for
alignment-based evaluation metrics rather than probe accuracy, and the
importance of tailoring probes to both the model architecture and the nature of
the target concept.

</details>


### [36] [AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research](https://arxiv.org/abs/2511.04316)
*Tim Beyer,Jonas Dornbusch,Jakob Steimle,Moritz Ladenburger,Leo Schwinn,Stephan Günnemann*

Main category: cs.AI

TL;DR: AdversariaLLM是一个用于LLM越狱鲁棒性研究的工具箱，旨在解决当前LLM安全研究生态系统中的碎片化、可复现性差等问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM安全和鲁棒性研究生态系统存在碎片化、bug多、实现不一致的问题，导致研究结果难以复现和比较，阻碍了该领域的实质性进展。

Method: 设计了一个以可复现性、正确性和可扩展性为核心的工具箱，实现了12种对抗攻击算法，集成了7个基准数据集，涵盖有害性、过度拒绝和效用评估，并通过Hugging Face提供对多种开源LLM的访问。

Result: 框架提供了计算资源跟踪、确定性结果和分布评估技术等高级功能，确保可比性和可复现性，并与JudgeZoo集成进行评判。

Conclusion: AdversariaLLM为LLM安全研究建立了透明、可比和可复现的坚实基础，解决了当前研究生态系统中的关键问题。

Abstract: The rapid expansion of research on Large Language Model (LLM) safety and
robustness has produced a fragmented and oftentimes buggy ecosystem of
implementations, datasets, and evaluation methods. This fragmentation makes
reproducibility and comparability across studies challenging, hindering
meaningful progress. To address these issues, we introduce AdversariaLLM, a
toolbox for conducting LLM jailbreak robustness research. Its design centers on
reproducibility, correctness, and extensibility. The framework implements
twelve adversarial attack algorithms, integrates seven benchmark datasets
spanning harmfulness, over-refusal, and utility evaluation, and provides access
to a wide range of open-weight LLMs via Hugging Face. The implementation
includes advanced features for comparability and reproducibility such as
compute-resource tracking, deterministic results, and distributional evaluation
techniques. \name also integrates judging through the companion package
JudgeZoo, which can also be used independently. Together, these components aim
to establish a robust foundation for transparent, comparable, and reproducible
research in LLM safety.

</details>


### [37] [VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical Consistency Checks](https://arxiv.org/abs/2511.04662)
*Yu Feng,Nathaniel Weir,Kaj Bostrom,Sam Bayless,Darion Cassel,Sapana Chaudhary,Benjamin Kiesl-Reiter,Huzefa Rangwala*

Main category: cs.AI

TL;DR: VeriCoT是一种神经符号方法，从思维链推理中提取和验证形式逻辑论证，通过一阶逻辑形式化推理步骤，使用自动求解器验证逻辑有效性。


<details>
  <summary>Details</summary>
Motivation: LLMs通过思维链进行多步推理，但无法可靠验证自身逻辑，即使在正确答案下，底层推理可能存在缺陷，影响高风险场景的可信度。

Method: 将每个思维链推理步骤形式化为一级逻辑，识别基于源上下文、常识知识或先前推理步骤的前提，使用符号表示实现自动验证。

Result: 在ProofWriter、LegalBench和BioASQ数据集上的实验显示，VeriCoT能有效识别有缺陷的推理，并作为最终答案正确性的强预测器。

Conclusion: VeriCoT的验证信号可用于推理时自我反思、监督微调和偏好微调，进一步提高推理有效性和准确性。

Abstract: LLMs can perform multi-step reasoning through Chain-of-Thought (CoT), but
they cannot reliably verify their own logic. Even when they reach correct
answers, the underlying reasoning may be flawed, undermining trust in
high-stakes scenarios. To mitigate this issue, we introduce VeriCoT, a
neuro-symbolic method that extracts and verifies formal logical arguments from
CoT reasoning. VeriCoT formalizes each CoT reasoning step into first-order
logic and identifies premises that ground the argument in source context,
commonsense knowledge, or prior reasoning steps. The symbolic representation
enables automated solvers to verify logical validity while the NL premises
allow humans and systems to identify ungrounded or fallacious reasoning steps.
Experiments on the ProofWriter, LegalBench, and BioASQ datasets show VeriCoT
effectively identifies flawed reasoning, and serves as a strong predictor of
final answer correctness. We also leverage VeriCoT's verification signal for
(1) inference-time self-reflection, (2) supervised fine-tuning (SFT) on
VeriCoT-distilled datasets and (3) preference fine-tuning (PFT) with direct
preference optimization (DPO) using verification-based pairwise rewards,
further improving reasoning validity and accuracy.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [38] [Learning Paths for Dynamic Measure Transport: A Control Perspective](https://arxiv.org/abs/2511.03797)
*Aimee Maurais,Bamdad Hosseini,Youssef Marzouk*

Main category: stat.ML

TL;DR: 本文从控制论视角研究动态测度传输中的测度路径识别问题，提出基于均值场博弈的优化方法，通过高斯过程求解偏微分方程来获得更平滑高效的传输模型。


<details>
  <summary>Details</summary>
Motivation: 现有动态测度传输方法中常用的测度路径选择不佳，需要寻找更优的倾斜路径来提高采样效率。

Method: 提出基于均值场博弈连接的优化问题族，使用鼓励速度平滑性的目标项，采用高斯过程方法求解偏微分方程。

Result: 相比未倾斜参考路径，该方法能够恢复更高效和平滑的传输模型。

Conclusion: 控制论视角为动态测度传输提供了有效的路径优化方法，倾斜路径选择显著提升了传输效率和平滑性。

Abstract: We bring a control perspective to the problem of identifying paths of
measures for sampling via dynamic measure transport (DMT). We highlight the
fact that commonly used paths may be poor choices for DMT and connect existing
methods for learning alternate paths to mean-field games. Based on these
connections we pose a flexible family of optimization problems for identifying
tilted paths of measures for DMT and advocate for the use of objective terms
which encourage smoothness of the corresponding velocities. We present a
numerical algorithm for solving these problems based on recent Gaussian process
methods for solution of partial differential equations and demonstrate the
ability of our method to recover more efficient and smooth transport models
compared to those which use an untilted reference path.

</details>


### [39] [High-dimensional limit theorems for SGD: Momentum and Adaptive Step-sizes](https://arxiv.org/abs/2511.03952)
*Aukosh Jagannath,Taj Jones-McCormick,Varnan Sarangian*

Main category: stat.ML

TL;DR: 本文开发了带Polyak动量的随机梯度下降(SGD-M)的高维缩放极限，并与在线SGD进行比较。研究发现SGD-M在适当时间重缩放和特定步长选择下与在线SGD具有相同缩放极限，但若步长相同，SGD-M会放大高维效应。在张量PCA和单指标模型上的实验表明，基于归一化梯度的自适应步长算法具有更好性能。


<details>
  <summary>Details</summary>
Motivation: 动机是严格比较在线SGD及其流行变体，特别是SGD-M算法，理解它们在优化过程中的高维行为差异，并为早期预条件器如何稳定和改进动态提供理论依据。

Method: 开发了SGD-M的高维缩放极限理论框架，在张量PCA和单指标模型上进行实验验证，比较了在线SGD、SGD-M和基于归一化梯度的自适应步长算法。

Result: SGD-M在适当时间重缩放和特定步长下与在线SGD有相同缩放极限，但相同步长时会放大高维效应。基于归一化梯度的自适应步长算法能产生更接近总体最小值的固定点，并扩大收敛步长范围。

Conclusion: 早期预条件器可以在在线SGD失败的设置中稳定和改进动态，基于归一化梯度的自适应步长算法在高维情况下具有多重优势，为经验动机提供了严格的理论解释。

Abstract: We develop a high-dimensional scaling limit for Stochastic Gradient Descent
with Polyak Momentum (SGD-M) and adaptive step-sizes. This provides a framework
to rigourously compare online SGD with some of its popular variants. We show
that the scaling limits of SGD-M coincide with those of online SGD after an
appropriate time rescaling and a specific choice of step-size. However, if the
step-size is kept the same between the two algorithms, SGD-M will amplify
high-dimensional effects, potentially degrading performance relative to online
SGD. We demonstrate our framework on two popular learning problems: Spiked
Tensor PCA and Single Index Models. In both cases, we also examine online SGD
with an adaptive step-size based on normalized gradients. In the
high-dimensional regime, this algorithm yields multiple benefits: its dynamics
admit fixed points closer to the population minimum and widens the range of
admissible step-sizes for which the iterates converge to such solutions. These
examples provide a rigorous account, aligning with empirical motivation, of how
early preconditioners can stabilize and improve dynamics in settings where
online SGD fails.

</details>
