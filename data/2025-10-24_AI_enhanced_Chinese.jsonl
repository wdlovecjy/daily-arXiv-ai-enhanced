{"id": "2510.19836", "categories": ["cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.19836", "abs": "https://arxiv.org/abs/2510.19836", "authors": ["Eliseo Curcio"], "title": "Benchmarking Reasoning Reliability in Artificial Intelligence Models for Energy-System Analysis", "comment": null, "summary": "Artificial intelligence and machine learning are increasingly used for\nforecasting, optimization, and policy design in the energy sector, yet no\nstandardized framework exists to evaluate whether these systems reason\ncorrectly. Current validation practices focus on predictive accuracy or\ncomputational efficiency, leaving the logical integrity of analytical\nconclusions untested. This study introduces the Analytical Reliability\nBenchmark (ARB), a reproducible framework that quantifies reasoning reliability\nin large language models applied to energy system analysis. The benchmark\nintegrates five submetrics: accuracy, reasoning reliability, uncertainty\ndiscipline, policy consistency, and transparency, and evaluates model\nperformance across deterministic, probabilistic, and epistemic scenarios using\nopen technoeconomic datasets (NREL ATB 2024, DOE H2A/H2New, IEA WEO 2024). Four\nfrontier models (GPT-4/5, Claude 4.5 Sonnet, Gemini 2.5 Pro, Llama 3 70B) were\ntested under identical factual and regulatory conditions. Results show that\nreasoning reliability can be objectively measured. GPT-4/5 and Claude 4.5\nSonnet achieved consistent and policy-compliant reasoning (Analytical\nReliability Index greater than 90), Gemini 2.5 Pro demonstrated moderate\nstability, and Llama 3 70B remained below professional thresholds. Statistical\nvalidation confirmed that these differences are significant and reproducible.\nThe ARB establishes the first quantitative method in the energy literature for\nverifying causal, probabilistic, and policy-driven reasoning in artificial\nintelligence systems, providing a reference framework for trustworthy and\ntransparent analytical applications in the global energy transition.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u5206\u6790\u53ef\u9760\u6027\u57fa\u51c6\uff08ARB\uff09\uff0c\u7528\u4e8e\u91cf\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u80fd\u6e90\u7cfb\u7edf\u5206\u6790\u4e2d\u7684\u63a8\u7406\u53ef\u9760\u6027\uff0c\u901a\u8fc7\u4e94\u4e2a\u5b50\u6307\u6807\u8bc4\u4f30\u6a21\u578b\u5728\u786e\u5b9a\u6027\u3001\u6982\u7387\u6027\u548c\u8ba4\u77e5\u6027\u573a\u666f\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u6d4b\u8bd5\u4e86\u56db\u4e2a\u524d\u6cbf\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u5728\u80fd\u6e90\u9886\u57df\u7684\u5e94\u7528\u7f3a\u4e4f\u6807\u51c6\u5316\u6846\u67b6\u6765\u8bc4\u4f30\u7cfb\u7edf\u63a8\u7406\u7684\u6b63\u786e\u6027\uff0c\u73b0\u6709\u9a8c\u8bc1\u5b9e\u8df5\u4e3b\u8981\u5173\u6ce8\u9884\u6d4b\u51c6\u786e\u6027\u6216\u8ba1\u7b97\u6548\u7387\uff0c\u800c\u5ffd\u7565\u4e86\u5206\u6790\u7ed3\u8bba\u7684\u903b\u8f91\u5b8c\u6574\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u5206\u6790\u53ef\u9760\u6027\u57fa\u51c6\uff08ARB\uff09\uff0c\u6574\u5408\u51c6\u786e\u6027\u3001\u63a8\u7406\u53ef\u9760\u6027\u3001\u4e0d\u786e\u5b9a\u6027\u7eaa\u5f8b\u3001\u653f\u7b56\u4e00\u81f4\u6027\u548c\u900f\u660e\u5ea6\u4e94\u4e2a\u5b50\u6307\u6807\uff0c\u4f7f\u7528\u5f00\u653e\u6280\u672f\u7ecf\u6d4e\u6570\u636e\u96c6\uff08NREL ATB 2024\u3001DOE H2A/H2New\u3001IEA WEO 2024\uff09\u5728\u786e\u5b9a\u6027\u3001\u6982\u7387\u6027\u548c\u8ba4\u77e5\u6027\u573a\u666f\u4e0b\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "GPT-4/5\u548cClaude 4.5 Sonnet\u5b9e\u73b0\u4e86\u6301\u7eed\u4e14\u7b26\u5408\u653f\u7b56\u7684\u63a8\u7406\uff08\u5206\u6790\u53ef\u9760\u6027\u6307\u6570\u5927\u4e8e90\uff09\uff0cGemini 2.5 Pro\u8868\u73b0\u51fa\u4e2d\u7b49\u7a33\u5b9a\u6027\uff0c\u800cLlama 3 70B\u4f4e\u4e8e\u4e13\u4e1a\u9608\u503c\u3002\u7edf\u8ba1\u9a8c\u8bc1\u786e\u8ba4\u8fd9\u4e9b\u5dee\u5f02\u663e\u8457\u4e14\u53ef\u91cd\u73b0\u3002", "conclusion": "ARB\u5efa\u7acb\u4e86\u80fd\u6e90\u6587\u732e\u4e2d\u9996\u4e2a\u5b9a\u91cf\u65b9\u6cd5\u6765\u9a8c\u8bc1\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u4e2d\u7684\u56e0\u679c\u3001\u6982\u7387\u548c\u653f\u7b56\u9a71\u52a8\u63a8\u7406\uff0c\u4e3a\u5168\u7403\u80fd\u6e90\u8f6c\u578b\u4e2d\u53ef\u4fe1\u8d56\u548c\u900f\u660e\u7684\u5206\u6790\u5e94\u7528\u63d0\u4f9b\u4e86\u53c2\u8003\u6846\u67b6\u3002"}}
{"id": "2510.20078", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.20078", "abs": "https://arxiv.org/abs/2510.20078", "authors": ["Rina Friedberg", "Richard Mudd", "Patrick Johnstone", "Melissa Pothen", "Vishal Vaingankar", "Vishwanath Sangale", "Abbas Zaidi"], "title": "Treatment Effect Learning Under Sequential Randomization", "comment": null, "summary": "Sequential treatment assignments in online experiments lead to complex\ndependency structures, often rendering identification, estimation and inference\nover treatments a challenge. Treatments in one session (e.g., a user logging\non) can have an effect that persists into subsequent sessions, leading to\ncumulative effects on outcomes measured at a later stage. This can render\nstandard methods for identification and inference trivially misspecified. We\npropose T-Learners layered into the G-Formula for this setting, building on\nliterature from causal machine learning and identification in sequential\nsettings. In a simple simulation, this approach prevents decaying accuracy in\nthe presence of carry-over effects, highlighting the importance of\nidentification and inference strategies tailored to the nature of systems often\nseen in the tech domain.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408T-Learner\u548cG-Formula\u7684\u65b9\u6cd5\u6765\u5904\u7406\u5728\u7ebf\u5b9e\u9a8c\u4e2d\u987a\u5e8f\u6cbb\u7597\u5206\u914d\u5e26\u6765\u7684\u590d\u6742\u4f9d\u8d56\u7ed3\u6784\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u6301\u7eed\u6548\u5e94\u7684\u60c5\u51b5\u4e0b\u3002", "motivation": "\u5728\u7ebf\u5b9e\u9a8c\u4e2d\u7684\u987a\u5e8f\u6cbb\u7597\u5206\u914d\u4f1a\u4ea7\u751f\u590d\u6742\u7684\u4f9d\u8d56\u7ed3\u6784\uff0c\u5bfc\u81f4\u6cbb\u7597\u5728\u540e\u7eed\u4f1a\u8bdd\u4e2d\u4ea7\u751f\u6301\u7eed\u6548\u5e94\uff0c\u8fd9\u4f7f\u5f97\u6807\u51c6\u8bc6\u522b\u548c\u63a8\u65ad\u65b9\u6cd5\u5bb9\u6613\u4ea7\u751f\u9519\u8bef\u3002", "method": "\u5c06T-Learner\u5206\u5c42\u5d4c\u5165\u5230G-Formula\u4e2d\uff0c\u57fa\u4e8e\u56e0\u679c\u673a\u5668\u5b66\u4e60\u548c\u987a\u5e8f\u8bbe\u7f6e\u4e2d\u7684\u8bc6\u522b\u6587\u732e\u3002", "result": "\u5728\u7b80\u5355\u6a21\u62df\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u5b58\u5728\u6301\u7eed\u6548\u5e94\u7684\u60c5\u51b5\u4e0b\u9632\u6b62\u4e86\u51c6\u786e\u6027\u8870\u51cf\u3002", "conclusion": "\u9488\u5bf9\u6280\u672f\u9886\u57df\u5e38\u89c1\u7cfb\u7edf\u6027\u8d28\u5b9a\u5236\u7684\u8bc6\u522b\u548c\u63a8\u65ad\u7b56\u7565\u975e\u5e38\u91cd\u8981\u3002"}}
{"id": "2510.20038", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20038", "abs": "https://arxiv.org/abs/2510.20038", "authors": ["Cristian Cioflan", "Jose Fonseca", "Xiaying Wang", "Luca Benini"], "title": "NanoHydra: Energy-Efficient Time-Series Classification at the Edge", "comment": "7 pages, 2 figures, 5 tables. Accepted at International Joint\n  Conference on Neural Networks (IJCNN) 2025", "summary": "Time series classification (TSC) on extreme edge devices represents a\nstepping stone towards intelligent sensor nodes that preserve user privacy and\noffer real-time predictions. Resource-constrained devices require efficient\nTinyML algorithms that prolong the device lifetime of battery-operated devices\nwithout compromising the classification accuracy. We introduce NanoHydra, a\nTinyML TSC methodology relying on lightweight binary random convolutional\nkernels to extract meaningful features from data streams. We demonstrate our\nsystem on the ultra-low-power GAP9 microcontroller, exploiting its eight-core\ncluster for the parallel execution of computationally intensive tasks. We\nachieve a classification accuracy of up to 94.47% on ECG5000 dataset,\ncomparable with state-of-the-art works. Our efficient NanoHydra requires only\n0.33 ms to accurately classify a 1-second long ECG signal. With a modest energy\nconsumption of 7.69 uJ per inference, 18x more efficient than the\nstate-of-the-art, NanoHydra is suitable for smart wearable devices, enabling a\ndevice lifetime of over four years.", "AI": {"tldr": "NanoHydra\u662f\u4e00\u79cd\u7528\u4e8e\u6781\u8fb9\u7f18\u8bbe\u5907\u7684\u8f7b\u91cf\u7ea7\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u65b9\u6cd5\uff0c\u4f7f\u7528\u4e8c\u8fdb\u5236\u968f\u673a\u5377\u79ef\u6838\u63d0\u53d6\u7279\u5f81\uff0c\u5728GAP9\u5fae\u63a7\u5236\u5668\u4e0a\u5b9e\u73b0\u9ad8\u6548\u5e76\u884c\u5904\u7406\uff0c\u5728ECG5000\u6570\u636e\u96c6\u4e0a\u8fbe\u523094.47%\u51c6\u786e\u7387\uff0c\u6bcf\u63a8\u7406\u4ec5\u6d88\u80177.69\u5fae\u7126\u80fd\u91cf\uff0c\u6bd4\u73b0\u6709\u6280\u672f\u9ad8\u654818\u500d\u3002", "motivation": "\u5f00\u53d1\u9002\u7528\u4e8e\u6781\u8fb9\u7f18\u8bbe\u5907\u7684\u9ad8\u6548\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u65b9\u6cd5\uff0c\u5ef6\u957f\u7535\u6c60\u4f9b\u7535\u8bbe\u5907\u7684\u5bff\u547d\uff0c\u540c\u65f6\u4fdd\u6301\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u5b9e\u73b0\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u548c\u63d0\u4f9b\u5b9e\u65f6\u9884\u6d4b\u7684\u667a\u80fd\u4f20\u611f\u5668\u8282\u70b9\u3002", "method": "\u91c7\u7528\u8f7b\u91cf\u7ea7\u4e8c\u8fdb\u5236\u968f\u673a\u5377\u79ef\u6838\u4ece\u6570\u636e\u6d41\u4e2d\u63d0\u53d6\u6709\u610f\u4e49\u7684\u7279\u5f81\uff0c\u5728\u8d85\u4f4e\u529f\u8017GAP9\u5fae\u63a7\u5236\u5668\u4e0a\u5229\u7528\u5176\u516b\u6838\u96c6\u7fa4\u5e76\u884c\u6267\u884c\u8ba1\u7b97\u5bc6\u96c6\u578b\u4efb\u52a1\u3002", "result": "\u5728ECG5000\u6570\u636e\u96c6\u4e0a\u8fbe\u523094.47%\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u4ec5\u97000.33\u6beb\u79d2\u5373\u53ef\u51c6\u786e\u5206\u7c7b1\u79d2\u957f\u7684ECG\u4fe1\u53f7\uff0c\u6bcf\u63a8\u7406\u80fd\u8017\u4e3a7.69\u5fae\u7126\uff0c\u6bd4\u73b0\u6709\u6280\u672f\u9ad8\u654818\u500d\u3002", "conclusion": "NanoHydra\u9002\u7528\u4e8e\u667a\u80fd\u53ef\u7a7f\u6234\u8bbe\u5907\uff0c\u80fd\u591f\u5b9e\u73b0\u8d85\u8fc7\u56db\u5e74\u7684\u8bbe\u5907\u5bff\u547d\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20653", "categories": ["stat.ML", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20653", "abs": "https://arxiv.org/abs/2510.20653", "authors": ["Jack Butler", "Nikita Kozodoi", "Zainab Afolabi", "Brian Tyacke", "Gaiar Baimuratov"], "title": "Finding the Sweet Spot: Trading Quality, Cost, and Speed During Inference-Time LLM Reflection", "comment": null, "summary": "As Large Language Models (LLMs) continue to evolve, practitioners face\nincreasing options for enhancing inference-time performance without model\nretraining, including budget tuning and multi-step techniques like\nself-reflection. While these methods improve output quality, they create\ncomplex trade-offs among accuracy, cost, and latency that remain poorly\nunderstood across different domains. This paper systematically compares\nself-reflection and budget tuning across mathematical reasoning and translation\ntasks. We evaluate prominent LLMs, including Anthropic Claude, Amazon Nova, and\nMistral families, along with other models under varying reflection depths and\ncompute budgets to derive Pareto optimal performance frontiers. Our analysis\nreveals substantial domain dependent variation in self-reflection\neffectiveness, with performance gains up to 220\\% in mathematical reasoning. We\nfurther investigate how reflection round depth and feedback mechanism quality\ninfluence performance across model families. To validate our findings in a\nreal-world setting, we deploy a self-reflection enhanced marketing content\nlocalisation system at Lounge by Zalando, where it shows market-dependent\neffectiveness, reinforcing the importance of domain specific evaluation when\ndeploying these techniques. Our results provide actionable guidance for\nselecting optimal inference strategies given specific domains and resource\nconstraints. We open source our self-reflection implementation for\nreproducibility at\nhttps://github.com/aws-samples/sample-genai-reflection-for-bedrock.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86\u81ea\u53cd\u601d\u548c\u9884\u7b97\u8c03\u4f18\u4e24\u79cd\u63a8\u7406\u4f18\u5316\u6280\u672f\u5728\u6570\u5b66\u63a8\u7406\u548c\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u81ea\u53cd\u601d\u5728\u4e0d\u540c\u9886\u57df\u7684\u6548\u679c\u5dee\u5f02\u663e\u8457\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u6027\u80fd\u63d0\u5347\u53ef\u8fbe220%\u3002\u7814\u7a76\u8fd8\u5206\u6790\u4e86\u53cd\u601d\u8f6e\u6b21\u6df1\u5ea6\u548c\u53cd\u9988\u673a\u5236\u8d28\u91cf\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u9a8c\u8bc1\u4e86\u53d1\u73b0\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e0d\u65ad\u53d1\u5c55\uff0c\u4ece\u4e1a\u8005\u9762\u4e34\u66f4\u591a\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u5373\u53ef\u63d0\u5347\u63a8\u7406\u6027\u80fd\u7684\u9009\u62e9\uff0c\u5305\u62ec\u9884\u7b97\u8c03\u4f18\u548c\u591a\u6b65\u6280\u672f\u5982\u81ea\u53cd\u601d\u3002\u8fd9\u4e9b\u65b9\u6cd5\u867d\u7136\u80fd\u63d0\u9ad8\u8f93\u51fa\u8d28\u91cf\uff0c\u4f46\u5728\u51c6\u786e\u6027\u3001\u6210\u672c\u548c\u5ef6\u8fdf\u4e4b\u95f4\u4ea7\u751f\u4e86\u590d\u6742\u7684\u6743\u8861\u5173\u7cfb\uff0c\u4e14\u5728\u4e0d\u540c\u9886\u57df\u4e2d\u7684\u8868\u73b0\u5c1a\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002", "method": "\u7cfb\u7edf\u6bd4\u8f83\u81ea\u53cd\u601d\u548c\u9884\u7b97\u8c03\u4f18\u5728\u6570\u5b66\u63a8\u7406\u548c\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u8bc4\u4f30\u5305\u62ecAnthropic Claude\u3001Amazon Nova\u548cMistral\u7cfb\u5217\u5728\u5185\u7684\u4e3b\u8981LLMs\uff0c\u5728\u4e0d\u540c\u53cd\u601d\u6df1\u5ea6\u548c\u8ba1\u7b97\u9884\u7b97\u4e0b\u63a8\u5bfc\u5e15\u7d2f\u6258\u6700\u4f18\u6027\u80fd\u8fb9\u754c\uff0c\u5e76\u5206\u6790\u53cd\u601d\u8f6e\u6b21\u6df1\u5ea6\u548c\u53cd\u9988\u673a\u5236\u8d28\u91cf\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5206\u6790\u663e\u793a\u81ea\u53cd\u601d\u6548\u679c\u5b58\u5728\u663e\u8457\u7684\u9886\u57df\u4f9d\u8d56\u6027\uff0c\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u6027\u80fd\u63d0\u5347\u53ef\u8fbe220%\u3002\u5728Zalando Lounge\u90e8\u7f72\u7684\u81ea\u53cd\u601d\u589e\u5f3a\u8425\u9500\u5185\u5bb9\u672c\u5730\u5316\u7cfb\u7edf\u663e\u793a\u51fa\u5e02\u573a\u4f9d\u8d56\u7684\u6709\u6548\u6027\uff0c\u5f3a\u8c03\u4e86\u90e8\u7f72\u8fd9\u4e9b\u6280\u672f\u65f6\u8fdb\u884c\u9886\u57df\u7279\u5b9a\u8bc4\u4f30\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5728\u7279\u5b9a\u9886\u57df\u548c\u8d44\u6e90\u7ea6\u675f\u4e0b\u9009\u62e9\u6700\u4f18\u63a8\u7406\u7b56\u7565\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\uff0c\u5e76\u5f00\u6e90\u4e86\u81ea\u53cd\u601d\u5b9e\u73b0\u4ee5\u786e\u4fdd\u53ef\u590d\u73b0\u6027\u3002"}}
{"id": "2510.19934", "categories": ["cs.LG", "cs.CR", "math.ST", "stat.ME", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.19934", "abs": "https://arxiv.org/abs/2510.19934", "authors": ["Xiang Li", "Buxin Su", "Chendi Wang", "Qi Long", "Weijie J. Su"], "title": "Mitigating Privacy-Utility Trade-off in Decentralized Federated Learning via $f$-Differential Privacy", "comment": "NeurIPS 2025 (Spotlight)", "summary": "Differentially private (DP) decentralized Federated Learning (FL) allows\nlocal users to collaborate without sharing their data with a central server.\nHowever, accurately quantifying the privacy budget of private FL algorithms is\nchallenging due to the co-existence of complex algorithmic components such as\ndecentralized communication and local updates. This paper addresses privacy\naccounting for two decentralized FL algorithms within the $f$-differential\nprivacy ($f$-DP) framework. We develop two new $f$-DP-based accounting methods\ntailored to decentralized settings: Pairwise Network $f$-DP (PN-$f$-DP), which\nquantifies privacy leakage between user pairs under random-walk communication,\nand Secret-based $f$-Local DP (Sec-$f$-LDP), which supports structured noise\ninjection via shared secrets. By combining tools from $f$-DP theory and Markov\nchain concentration, our accounting framework captures privacy amplification\narising from sparse communication, local iterations, and correlated noise.\nExperiments on synthetic and real datasets demonstrate that our methods yield\nconsistently tighter $(\\epsilon,\\delta)$ bounds and improved utility compared\nto R\\'enyi DP-based approaches, illustrating the benefits of $f$-DP in\ndecentralized privacy accounting.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u9690\u79c1\u9884\u7b97\u91cf\u5316\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u57fa\u4e8ef-\u5dee\u5206\u9690\u79c1\u7684\u9690\u79c1\u6838\u7b97\u65b9\u6cd5\uff1aPN-f-DP\u548cSec-f-LDP\uff0c\u901a\u8fc7\u7ed3\u5408f-DP\u7406\u8bba\u548c\u9a6c\u5c14\u53ef\u592b\u94fe\u96c6\u4e2d\u6027\u5de5\u5177\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9690\u79c1\u8fb9\u754c\u7d27\u5bc6\u5ea6\u548c\u7b97\u6cd5\u6548\u7528\u3002", "motivation": "\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u5141\u8bb8\u7528\u6237\u5728\u4e0d\u4e0e\u4e2d\u592e\u670d\u52a1\u5668\u5171\u4eab\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u534f\u4f5c\uff0c\u4f46\u7531\u4e8e\u590d\u6742\u7684\u7b97\u6cd5\u7ec4\u4ef6\uff08\u5982\u53bb\u4e2d\u5fc3\u5316\u901a\u4fe1\u548c\u672c\u5730\u66f4\u65b0\uff09\u5171\u5b58\uff0c\u51c6\u786e\u91cf\u5316\u9690\u79c1\u9884\u7b97\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e24\u79cd\u65b0\u7684f-DP\u6838\u7b97\u65b9\u6cd5\uff1aPN-f-DP\uff08\u91cf\u5316\u968f\u673a\u6e38\u8d70\u901a\u4fe1\u4e0b\u7528\u6237\u5bf9\u4e4b\u95f4\u7684\u9690\u79c1\u6cc4\u6f0f\uff09\u548cSec-f-LDP\uff08\u901a\u8fc7\u5171\u4eab\u79d8\u5bc6\u652f\u6301\u7ed3\u6784\u5316\u566a\u58f0\u6ce8\u5165\uff09\uff0c\u7ed3\u5408f-DP\u7406\u8bba\u548c\u9a6c\u5c14\u53ef\u592b\u94fe\u96c6\u4e2d\u6027\u5de5\u5177\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4R\u00e9nyi DP\u65b9\u6cd5\uff0c\u672c\u6587\u65b9\u6cd5\u80fd\u4ea7\u751f\u66f4\u7d27\u7684(\u03b5,\u03b4)\u8fb9\u754c\u548c\u66f4\u597d\u7684\u6548\u7528\u3002", "conclusion": "f-DP\u6846\u67b6\u5728\u53bb\u4e2d\u5fc3\u5316\u9690\u79c1\u6838\u7b97\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u80fd\u591f\u6709\u6548\u6355\u6349\u7a00\u758f\u901a\u4fe1\u3001\u672c\u5730\u8fed\u4ee3\u548c\u76f8\u5173\u566a\u58f0\u5e26\u6765\u7684\u9690\u79c1\u653e\u5927\u6548\u5e94\u3002"}}
{"id": "2510.20242", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.20242", "abs": "https://arxiv.org/abs/2510.20242", "authors": ["Stephan Rabanser", "Nicolas Papernot"], "title": "What Does It Take to Build a Performant Selective Classifier?", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025)", "summary": "Selective classifiers improve model reliability by abstaining on inputs the\nmodel deems uncertain. However, few practical approaches achieve the\ngold-standard performance of a perfect-ordering oracle that accepts examples\nexactly in order of correctness. Our work formalizes this shortfall as the\nselective-classification gap and present the first finite-sample decomposition\nof this gap to five distinct sources of looseness: Bayes noise, approximation\nerror, ranking error, statistical noise, and implementation- or shift-induced\nslack. Crucially, our analysis reveals that monotone post-hoc calibration --\noften believed to strengthen selective classifiers -- has limited impact on\nclosing this gap, since it rarely alters the model's underlying score ranking.\nBridging the gap therefore requires scoring mechanisms that can effectively\nreorder predictions rather than merely rescale them. We validate our\ndecomposition on synthetic two-moons data and on real-world vision and language\nbenchmarks, isolating each error component through controlled experiments. Our\nresults confirm that (i) Bayes noise and limited model capacity can account for\nsubstantial gaps, (ii) only richer, feature-aware calibrators meaningfully\nimprove score ordering, and (iii) data shift introduces a separate slack that\ndemands distributionally robust training. Together, our decomposition yields a\nquantitative error budget as well as actionable design guidelines that\npractitioners can use to build selective classifiers which approximate ideal\noracle behavior more closely.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9009\u62e9\u6027\u5206\u7c7b\u5dee\u8ddd\u7684\u6982\u5ff5\uff0c\u5c06\u7406\u60f3oracle\u6027\u80fd\u4e0e\u5b9e\u9645\u9009\u62e9\u6027\u5206\u7c7b\u5668\u6027\u80fd\u4e4b\u95f4\u7684\u5dee\u8ddd\u5206\u89e3\u4e3a\u4e94\u4e2a\u6765\u6e90\uff1a\u8d1d\u53f6\u65af\u566a\u58f0\u3001\u8fd1\u4f3c\u8bef\u5dee\u3001\u6392\u5e8f\u8bef\u5dee\u3001\u7edf\u8ba1\u566a\u58f0\u548c\u5b9e\u73b0/\u5206\u5e03\u504f\u79fb\u5bfc\u81f4\u7684\u677e\u5f1b\u3002\u7814\u7a76\u53d1\u73b0\u5355\u8c03\u540e\u6821\u51c6\u5bf9\u7f29\u5c0f\u5dee\u8ddd\u4f5c\u7528\u6709\u9650\uff0c\u9700\u8981\u80fd\u91cd\u65b0\u6392\u5e8f\u9884\u6d4b\u7684\u8bc4\u5206\u673a\u5236\u3002", "motivation": "\u5f53\u524d\u9009\u62e9\u6027\u5206\u7c7b\u5668\u96be\u4ee5\u8fbe\u5230\u5b8c\u7f8e\u6392\u5e8foracle\u7684\u6027\u80fd\u6c34\u5e73\uff0c\u9700\u8981\u7cfb\u7edf\u5206\u6790\u6027\u80fd\u5dee\u8ddd\u7684\u6765\u6e90\uff0c\u4e3a\u6784\u5efa\u66f4\u63a5\u8fd1\u7406\u60f3oracle\u884c\u4e3a\u7684\u9009\u62e9\u6027\u5206\u7c7b\u5668\u63d0\u4f9b\u7406\u8bba\u6307\u5bfc\u548c\u5b9e\u8df5\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u9009\u62e9\u6027\u5206\u7c7b\u5dee\u8ddd\u7684\u6709\u9650\u6837\u672c\u5206\u89e3\u6846\u67b6\uff0c\u5c06\u5dee\u8ddd\u5206\u89e3\u4e3a\u4e94\u4e2a\u5177\u4f53\u6765\u6e90\uff0c\u5e76\u901a\u8fc7\u5408\u6210\u6570\u636e\uff08\u53cc\u6708\u6570\u636e\u96c6\uff09\u548c\u771f\u5b9e\u4e16\u754c\u89c6\u89c9\u3001\u8bed\u8a00\u57fa\u51c6\u8fdb\u884c\u9a8c\u8bc1\uff0c\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u5206\u79bb\u5404\u8bef\u5dee\u5206\u91cf\u3002", "result": "\u9a8c\u8bc1\u7ed3\u679c\u8868\u660e\uff1a(1)\u8d1d\u53f6\u65af\u566a\u58f0\u548c\u6709\u9650\u6a21\u578b\u5bb9\u91cf\u53ef\u89e3\u91ca\u663e\u8457\u5dee\u8ddd\uff1b(2)\u53ea\u6709\u66f4\u4e30\u5bcc\u7684\u7279\u5f81\u611f\u77e5\u6821\u51c6\u5668\u80fd\u663e\u8457\u6539\u5584\u8bc4\u5206\u6392\u5e8f\uff1b(3)\u6570\u636e\u504f\u79fb\u5f15\u5165\u7684\u677e\u5f1b\u9700\u8981\u5206\u5e03\u9c81\u68d2\u8bad\u7ec3\u3002", "conclusion": "\u8be5\u5206\u89e3\u63d0\u4f9b\u4e86\u5b9a\u91cf\u8bef\u5dee\u9884\u7b97\u548c\u53ef\u64cd\u4f5c\u7684\u8bbe\u8ba1\u6307\u5357\uff0c\u5e2e\u52a9\u4ece\u4e1a\u8005\u6784\u5efa\u66f4\u63a5\u8fd1\u7406\u60f3oracle\u884c\u4e3a\u7684\u9009\u62e9\u6027\u5206\u7c7b\u5668\uff0c\u5f3a\u8c03\u9700\u8981\u80fd\u6709\u6548\u91cd\u65b0\u6392\u5e8f\u9884\u6d4b\u800c\u975e\u4ec5\u91cd\u65b0\u7f29\u653e\u8bc4\u5206\u7684\u673a\u5236\u3002"}}
{"id": "2510.19964", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19964", "abs": "https://arxiv.org/abs/2510.19964", "authors": ["Nitsa J Herzog", "Rejwan Bin Sulaiman", "David J Herzog", "Rose Fong"], "title": "AI-Driven Personalized Learning: Predicting Academic Per-formance Through Leadership Personality Traits", "comment": "20 pages, 6 figures, research article", "summary": "The study explores the potential of AI technologies in personalized learning,\nsuggesting the prediction of academic success through leadership personality\ntraits and machine learning modelling. The primary data were obtained from 129\nmaster's students in the Environmental Engineering Department, who underwent\nfive leadership personality tests with 23 characteristics. Students used\nself-assessment tools that included Personality Insight, Workplace Culture,\nMotivation at Work, Management Skills, and Emotion Control tests. The test\nresults were combined with the average grade obtained from academic reports.\nThe study employed exploratory data analysis and correlation analysis. Feature\nselection utilized Pearson correlation coefficients of personality traits. The\naverage grades were separated into three categories: fail, pass, and excellent.\nThe modelling process was performed by tuning seven ML algorithms, such as SVM,\nLR, KNN, DT, GB, RF, XGBoost and LightGBM. The highest predictive performance\nwas achieved with the RF classifier, which yielded an accuracy of 87.50% for\nthe model incorporating 17 personality trait features and the leadership mark\nfeature, and an accuracy of 85.71% for the model excluding this feature. In\nthis way, the study offers an additional opportunity to identify students'\nstrengths and weaknesses at an early stage of their education process and\nselect the most suitable strategies for personalized learning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86AI\u6280\u672f\u5728\u4e2a\u6027\u5316\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u9886\u5bfc\u529b\u4eba\u683c\u7279\u8d28\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u5b66\u4e1a\u6210\u529f\u3002\u4f7f\u7528129\u540d\u73af\u5883\u5de5\u7a0b\u7855\u58eb\u751f\u7684\u9886\u5bfc\u529b\u4eba\u683c\u6d4b\u8bd5\u6570\u636e\u548c\u5b66\u4e1a\u6210\u7ee9\uff0c\u901a\u8fc7\u7279\u5f81\u9009\u62e9\u548c7\u79cdML\u7b97\u6cd5\u5efa\u6a21\uff0c\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u5728\u5305\u542b17\u4e2a\u4eba\u683c\u7279\u5f81\u548c\u9886\u5bfc\u529b\u6807\u8bb0\u7684\u6a21\u578b\u4e2d\u8fbe\u523087.50%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u63a2\u7d22AI\u6280\u672f\u5728\u4e2a\u6027\u5316\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u901a\u8fc7\u9884\u6d4b\u5b66\u4e1a\u6210\u529f\u6765\u65e9\u671f\u8bc6\u522b\u5b66\u751f\u7684\u4f18\u52bf\u548c\u52a3\u52bf\uff0c\u4e3a\u4e2a\u6027\u5316\u5b66\u4e60\u7b56\u7565\u9009\u62e9\u63d0\u4f9b\u652f\u6301\u3002", "method": "\u6536\u96c6129\u540d\u7855\u58eb\u751f\u7684\u9886\u5bfc\u529b\u4eba\u683c\u6d4b\u8bd5\u6570\u636e\uff0823\u4e2a\u7279\u5f81\uff09\u548c\u5e73\u5747\u6210\u7ee9\uff0c\u4f7f\u7528\u63a2\u7d22\u6027\u6570\u636e\u5206\u6790\u548c\u76f8\u5173\u6027\u5206\u6790\uff0c\u901a\u8fc7\u76ae\u5c14\u900a\u76f8\u5173\u7cfb\u6570\u8fdb\u884c\u7279\u5f81\u9009\u62e9\uff0c\u91c7\u75287\u79cdML\u7b97\u6cd5\uff08SVM\u3001LR\u3001KNN\u3001DT\u3001GB\u3001RF\u3001XGBoost\u3001LightGBM\uff09\u8fdb\u884c\u5efa\u6a21\u3002", "result": "\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u8868\u73b0\u6700\u4f73\uff0c\u5305\u542b17\u4e2a\u4eba\u683c\u7279\u5f81\u548c\u9886\u5bfc\u529b\u6807\u8bb0\u7684\u6a21\u578b\u51c6\u786e\u7387\u8fbe87.50%\uff0c\u4e0d\u5305\u542b\u8be5\u7279\u5f81\u7684\u6a21\u578b\u51c6\u786e\u7387\u4e3a85.71%\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5728\u6559\u80b2\u8fc7\u7a0b\u65e9\u671f\u8bc6\u522b\u5b66\u751f\u4f18\u52a3\u52bf\u63d0\u4f9b\u4e86\u989d\u5916\u673a\u4f1a\uff0c\u6709\u52a9\u4e8e\u9009\u62e9\u6700\u9002\u5408\u7684\u4e2a\u6027\u5316\u5b66\u4e60\u7b56\u7565\u3002"}}
{"id": "2510.20075", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20075", "abs": "https://arxiv.org/abs/2510.20075", "authors": ["Antonio Norelli", "Michael Bronstein"], "title": "LLMs can hide text in other text of the same length.ipynb", "comment": "21 pages, main paper 9 pages", "summary": "A meaningful text can be hidden inside another, completely different yet\nstill coherent and plausible, text of the same length. For example, a tweet\ncontaining a harsh political critique could be embedded in a tweet that\ncelebrates the same political leader, or an ordinary product review could\nconceal a secret manuscript. This uncanny state of affairs is now possible\nthanks to Large Language Models, and in this paper we present a simple and\nefficient protocol to achieve it. We show that even modest 8-billion-parameter\nopen-source LLMs are sufficient to obtain high-quality results, and a message\nas long as this abstract can be encoded and decoded locally on a laptop in\nseconds. The existence of such a protocol demonstrates a radical decoupling of\ntext from authorial intent, further eroding trust in written communication,\nalready shaken by the rise of LLM chatbots. We illustrate this with a concrete\nscenario: a company could covertly deploy an unfiltered LLM by encoding its\nanswers within the compliant responses of a safe model. This possibility raises\nurgent questions for AI safety and challenges our understanding of what it\nmeans for a Large Language Model to know something.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.20140", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20140", "abs": "https://arxiv.org/abs/2510.20140", "authors": ["Jiangong Chen", "Xia Lei", "Kaitao Meng", "Kawon Han", "Yuchen Zhang", "Christos Masouros", "Athina P. Petropulu"], "title": "Sensing Security in Near-Field ISAC: Exploiting Scatterers for Eavesdropper Deception", "comment": null, "summary": "In this paper, we explore sensing security in near-field (NF) integrated\nsensing and communication (ISAC) scenarios by exploiting known scatterers in\nthe sensing scene. We propose a location deception (LD) scheme where scatterers\nare deliberately illuminated with probing power that is higher than that\ndirected toward targets of interest, with the goal of deceiving potential\neavesdroppers (Eves) with sensing capability into misidentifying scatterers as\ntargets. While the known scatterers can be removed at the legitimate sensing\nreceiver, our LD approach causes Eves to misdetect targets. Notably, this\ndeception is achieved without requiring any prior information about the Eves'\ncharacteristics or locations. To strike a flexible three-way tradeoff among\ncommunication, sensing, and sensing-security performance, the sum rate and\npower allocated to scatterers are weighted and maximized under a legitimate\nradar signal-to-interference-plus-noise ratio (SINR) constraint. We employ the\nfractional programming (FP) framework and semidefinite relaxation (SDR) to\nsolve this problem. To evaluate the security of the proposed LD scheme, the\nCramer-Rao Bound (CRB) and mean squared error (MSE) metrics are employed.\nAdditionally, we introduce the Kullback-Leibler Divergence (KLD) gap between\ntargets and scatterers at Eve to quantify the impact of the proposed LD\nframework on Eve's sensing performance from an information-theoretical\nperspective. Simulation results demonstrate that the proposed LD scheme can\nflexibly adjust the beamforming strategy according to performance requirements,\nthereby achieving the desired three-way tradeoff. In particular, in terms of\nsensing security, the proposed scheme significantly enhances the clutter signal\nstrength at Eve's side, leading to confusion or even missed detection of the\nactual target.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5229\u7528\u5df2\u77e5\u6563\u5c04\u4f53\u8fdb\u884c\u4f4d\u7f6e\u6b3a\u9a97\u7684\u611f\u77e5\u5b89\u5168\u65b9\u6848\uff0c\u901a\u8fc7\u5728\u8fd1\u573aISAC\u573a\u666f\u4e2d\u5411\u6563\u5c04\u4f53\u5206\u914d\u66f4\u591a\u63a2\u6d4b\u529f\u7387\u6765\u6b3a\u9a97\u7a83\u542c\u8005\uff0c\u4f7f\u5176\u8bef\u5c06\u6563\u5c04\u4f53\u8bc6\u522b\u4e3a\u76ee\u6807", "motivation": "\u5728\u8fd1\u573a\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u573a\u666f\u4e2d\uff0c\u5229\u7528\u5df2\u77e5\u6563\u5c04\u4f53\u63d0\u5347\u611f\u77e5\u5b89\u5168\u6027\uff0c\u65e0\u9700\u7a83\u542c\u8005\u7684\u5148\u9a8c\u4fe1\u606f\u5373\u53ef\u5b9e\u73b0\u4f4d\u7f6e\u6b3a\u9a97", "method": "\u91c7\u7528\u5206\u6570\u89c4\u5212\u548c\u534a\u5b9a\u677e\u5f1b\u65b9\u6cd5\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u7b56\u7565\uff0c\u5728\u5408\u6cd5\u96f7\u8fbeSINR\u7ea6\u675f\u4e0b\u6700\u5927\u5316\u52a0\u6743\u548c\u901f\u7387\u548c\u6563\u5c04\u4f53\u5206\u914d\u529f\u7387\uff0c\u4f7f\u7528CRB\u3001MSE\u548cKLD\u6307\u6807\u8bc4\u4f30\u5b89\u5168\u6027\u80fd", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6848\u80fd\u7075\u6d3b\u8c03\u6574\u6ce2\u675f\u6210\u5f62\u7b56\u7565\uff0c\u663e\u8457\u589e\u5f3a\u7a83\u542c\u7aef\u7684\u6742\u6ce2\u4fe1\u53f7\u5f3a\u5ea6\uff0c\u5bfc\u81f4\u5b9e\u9645\u76ee\u6807\u88ab\u6df7\u6dc6\u751a\u81f3\u6f0f\u68c0", "conclusion": "\u6240\u63d0\u51fa\u7684\u4f4d\u7f6e\u6b3a\u9a97\u65b9\u6848\u80fd\u6709\u6548\u5b9e\u73b0\u901a\u4fe1\u3001\u611f\u77e5\u548c\u611f\u77e5\u5b89\u5168\u6027\u80fd\u4e4b\u95f4\u7684\u4e09\u5411\u6743\u8861\uff0c\u663e\u8457\u63d0\u5347\u8fd1\u573aISAC\u7cfb\u7edf\u7684\u611f\u77e5\u5b89\u5168\u6027"}}
{"id": "2510.19953", "categories": ["cs.LG", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.19953", "abs": "https://arxiv.org/abs/2510.19953", "authors": ["Shaocong Ma", "Heng Huang"], "title": "On the Optimal Construction of Unbiased Gradient Estimators for Zeroth-Order Optimization", "comment": null, "summary": "Zeroth-order optimization (ZOO) is an important framework for stochastic\noptimization when gradients are unavailable or expensive to compute. A\npotential limitation of existing ZOO methods is the bias inherent in most\ngradient estimators unless the perturbation stepsize vanishes. In this paper,\nwe overcome this biasedness issue by proposing a novel family of unbiased\ngradient estimators based solely on function evaluations. By reformulating\ndirectional derivatives as a telescoping series and sampling from carefully\ndesigned distributions, we construct estimators that eliminate bias while\nmaintaining favorable variance. We analyze their theoretical properties, derive\noptimal scaling distributions and perturbation stepsizes of four specific\nconstructions, and prove that SGD using the proposed estimators achieves\noptimal complexity for smooth non-convex objectives. Experiments on synthetic\ntasks and language model fine-tuning confirm the superior accuracy and\nconvergence of our approach compared to standard methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u51fd\u6570\u8bc4\u4f30\u7684\u65e0\u504f\u68af\u5ea6\u4f30\u8ba1\u5668\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u65b9\u5411\u5bfc\u6570\u91cd\u6784\u4e3a\u4f38\u7f29\u7ea7\u6570\u5e76\u91c7\u6837\u7279\u5b9a\u5206\u5e03\uff0c\u89e3\u51b3\u4e86\u96f6\u9636\u4f18\u5316\u4e2d\u68af\u5ea6\u4f30\u8ba1\u5668\u7684\u504f\u5dee\u95ee\u9898\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e2d\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u5b58\u5728\u68af\u5ea6\u4f30\u8ba1\u5668\u504f\u5dee\u95ee\u9898\uff0c\u9664\u975e\u6270\u52a8\u6b65\u957f\u8d8b\u8fd1\u4e8e\u96f6\uff0c\u8fd9\u9650\u5236\u4e86\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u548c\u6536\u655b\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u5c06\u65b9\u5411\u5bfc\u6570\u91cd\u6784\u4e3a\u4f38\u7f29\u7ea7\u6570\uff0c\u4ece\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5206\u5e03\u4e2d\u91c7\u6837\uff0c\u6784\u5efa\u65e0\u504f\u68af\u5ea6\u4f30\u8ba1\u5668\uff0c\u5e76\u5206\u6790\u4e86\u56db\u79cd\u5177\u4f53\u6784\u9020\u7684\u6700\u4f18\u7f29\u653e\u5206\u5e03\u548c\u6270\u52a8\u6b65\u957f\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4f7f\u7528\u8be5\u4f30\u8ba1\u5668\u7684SGD\u5728\u5149\u6ed1\u975e\u51f8\u76ee\u6807\u4e0a\u8fbe\u5230\u6700\u4f18\u590d\u6742\u5ea6\uff0c\u5b9e\u9a8c\u5728\u5408\u6210\u4efb\u52a1\u548c\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4e2d\u9a8c\u8bc1\u4e86\u76f8\u6bd4\u6807\u51c6\u65b9\u6cd5\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u6536\u655b\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65e0\u504f\u68af\u5ea6\u4f30\u8ba1\u5668\u5bb6\u65cf\u6709\u6548\u89e3\u51b3\u4e86\u96f6\u9636\u4f18\u5316\u4e2d\u7684\u504f\u5dee\u95ee\u9898\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e2d\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u4e3a\u68af\u5ea6\u4e0d\u53ef\u5f97\u6216\u8ba1\u7b97\u6602\u8d35\u7684\u573a\u666f\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2510.20265", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20265", "abs": "https://arxiv.org/abs/2510.20265", "authors": ["Burak Ahmet Ozden", "Erdogan Aydin", "Emir Aslandogan", "Haci Ilhan", "Ertugrul Basar", "Miaowen Wen", "Marco Di Renzo", "Vincent Poor"], "title": "A Survey of OTFS-Based Index Modulation Techniques: Challenges, Benefits, and Future Directions for 6G and Beyond", "comment": "34 pages, 13 figures, 8 Tables", "summary": "Orthogonal time frequency space (OTFS) is a two-dimensional modulation\ntechnique that uses the delay-Doppler (DD) domain and is a candidate for\nproviding robust, high-capacity wireless communications for envisioned 6G and\nbeyond networks. The OTFS technique maps data to the DD domain instead of the\ntraditional time-frequency domain, enabling it to fully utilize channel\ndiversity and transform fast time-varying channels into nearly static channels.\nIndex modulation (IM) is a communication paradigm that conveys information not\nonly through conventional modulation symbols but also by encoding data bits in\nthe indices of the selected communication resources to improve error\nperformance, spectral efficiency, and energy efficiency. In this survey, a\ncomprehensive review of work on OTFS-based wireless communication systems is\npresented. In particular, the existing OTFS-IM schemes are reviewed and\nsystematically categorized according to their system architectures, detection\nmethods, and performance aspects such as capacity, peak-to-average power ratio,\ndiversity, complexity, imperfect channel state information, spectral\nefficiency, and outage probability. Furthermore, the operating principles and\nsystem models of OTFS-IM variants-including OTFS-based space shift keying,\nOTFS-based spatial modulation, OTFS-based quadrature spatial modulation,\nOTFS-based media-based modulation, and OTFS-based code index modulation-are\ndescribed, followed by a comparative performance analysis in terms of\ncomputational complexity, error performance, capacity, energy saving, spectral\nefficiency, and throughput. Finally, the challenges, benefits, and future\ndirections for OTFS-IM systems are discussed, covering key aspects such as\ncomplexity, efficiency, latency, channel estimation, hardware constraints,\nsynchronization, security, and potential integration with other advanced\nwireless communication techniques.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u6b63\u4ea4\u65f6\u9891\u7a7a\u95f4(OTFS)\u548c\u7d22\u5f15\u8c03\u5236(IM)\u7684\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\uff0c\u7cfb\u7edf\u6027\u5730\u5206\u7c7b\u4e86OTFS-IM\u65b9\u6848\uff0c\u6bd4\u8f83\u4e86\u5404\u79cd\u53d8\u4f53\u7684\u6027\u80fd\uff0c\u5e76\u8ba8\u8bba\u4e86\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "OTFS\u6280\u672f\u5728\u5ef6\u8fdf\u591a\u666e\u52d2\u57df\u8fdb\u884c\u8c03\u5236\uff0c\u80fd\u591f\u5145\u5206\u5229\u7528\u4fe1\u9053\u5206\u96c6\u5e76\u5c06\u5feb\u901f\u65f6\u53d8\u4fe1\u9053\u8f6c\u5316\u4e3a\u8fd1\u4f3c\u9759\u6001\u4fe1\u9053\uff0c\u800cIM\u6280\u672f\u901a\u8fc7\u901a\u4fe1\u8d44\u6e90\u7d22\u5f15\u7f16\u7801\u6570\u636e\u4f4d\u6765\u63d0\u9ad8\u6027\u80fd\u3002\u7ed3\u5408\u4e24\u8005\u53ef\u63d0\u4f9b\u66f4\u7a33\u5065\u3001\u9ad8\u6548\u80fd\u7684\u65e0\u7ebf\u901a\u4fe1\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5bf9\u73b0\u6709OTFS-IM\u65b9\u6848\u8fdb\u884c\u7cfb\u7edf\u6027\u7efc\u8ff0\u548c\u5206\u7c7b\uff0c\u5305\u62ec\u7cfb\u7edf\u67b6\u6784\u3001\u68c0\u6d4b\u65b9\u6cd5\u3001\u6027\u80fd\u6307\u6807\u5206\u6790\uff0c\u5e76\u8be6\u7ec6\u63cf\u8ff0\u5404\u79cdOTFS-IM\u53d8\u4f53\u7684\u5de5\u4f5c\u539f\u7406\u548c\u7cfb\u7edf\u6a21\u578b\u3002", "result": "\u63d0\u4f9b\u4e86OTFS-IM\u65b9\u6848\u7684\u5168\u9762\u6027\u80fd\u6bd4\u8f83\u5206\u6790\uff0c\u5305\u62ec\u8ba1\u7b97\u590d\u6742\u5ea6\u3001\u8bef\u7801\u6027\u80fd\u3001\u5bb9\u91cf\u3001\u8282\u80fd\u3001\u9891\u8c31\u6548\u7387\u548c\u541e\u5410\u91cf\u7b49\u65b9\u9762\u3002", "conclusion": "OTFS-IM\u7cfb\u7edf\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4f46\u9762\u4e34\u590d\u6742\u5ea6\u3001\u6548\u7387\u3001\u5ef6\u8fdf\u3001\u4fe1\u9053\u4f30\u8ba1\u7b49\u6311\u6218\uff0c\u672a\u6765\u9700\u8981\u4e0e\u5176\u4ed6\u5148\u8fdb\u65e0\u7ebf\u901a\u4fe1\u6280\u672f\u96c6\u6210\u53d1\u5c55\u3002"}}
{"id": "2510.19975", "categories": ["cs.LG", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.19975", "abs": "https://arxiv.org/abs/2510.19975", "authors": ["Shaocong Ma", "Heng Huang"], "title": "Revisiting Zeroth-Order Optimization: Minimum-Variance Two-Point Estimators and Directionally Aligned Perturbations", "comment": null, "summary": "In this paper, we explore the two-point zeroth-order gradient estimator and\nidentify the distribution of random perturbations that minimizes the\nestimator's asymptotic variance as the perturbation stepsize tends to zero. We\nformulate it as a constrained functional optimization problem over the space of\nperturbation distributions. Our findings reveal that such desired perturbations\ncan align directionally with the true gradient, instead of maintaining a fixed\nlength. While existing research has largely focused on fixed-length\nperturbations, the potential advantages of directional alignment have been\noverlooked. To address this gap, we delve into the theoretical and empirical\nproperties of the directionally aligned perturbation (DAP) scheme, which\nadaptively offers higher accuracy along critical directions. Additionally, we\nprovide a convergence analysis for stochastic gradient descent using\n$\\delta$-unbiased random perturbations, extending existing complexity bounds to\na wider range of perturbations. Through empirical evaluations on both synthetic\nproblems and practical tasks, we demonstrate that DAPs outperform traditional\nmethods under specific conditions.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e24\u70b9\u96f6\u9636\u68af\u5ea6\u4f30\u8ba1\u5668\uff0c\u53d1\u73b0\u5f53\u6270\u52a8\u6b65\u957f\u8d8b\u8fd1\u4e8e\u96f6\u65f6\uff0c\u6700\u5c0f\u5316\u4f30\u8ba1\u5668\u6e10\u8fd1\u65b9\u5dee\u7684\u6270\u52a8\u5206\u5e03\u53ef\u4ee5\u6cbf\u68af\u5ea6\u65b9\u5411\u5bf9\u9f50\uff0c\u800c\u975e\u4fdd\u6301\u56fa\u5b9a\u957f\u5ea6\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u65b9\u5411\u5bf9\u9f50\u6270\u52a8\u65b9\u6848\uff0c\u5e76\u5728\u7406\u8bba\u548c\u5b9e\u8bc1\u4e0a\u8bc1\u660e\u5176\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u56fa\u5b9a\u957f\u5ea6\u7684\u968f\u673a\u6270\u52a8\uff0c\u4f46\u5ffd\u7565\u4e86\u6270\u52a8\u65b9\u5411\u4e0e\u771f\u5b9e\u68af\u5ea6\u5bf9\u9f50\u53ef\u80fd\u5e26\u6765\u7684\u4f18\u52bf\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u8fd9\u79cd\u65b9\u5411\u5bf9\u9f50\u6270\u52a8\u7684\u6f5c\u529b\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u6270\u52a8\u5206\u5e03\u7a7a\u95f4\u4e0a\u7684\u7ea6\u675f\u51fd\u6570\u4f18\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u65b9\u5411\u5bf9\u9f50\u6270\u52a8\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u81ea\u9002\u5e94\u5730\u5728\u5173\u952e\u65b9\u5411\u4e0a\u63d0\u4f9b\u66f4\u9ad8\u7cbe\u5ea6\u3002\u540c\u65f6\u63d0\u4f9b\u4e86\u4f7f\u7528\u03b4-\u65e0\u504f\u968f\u673a\u6270\u52a8\u7684\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6536\u655b\u6027\u5206\u6790\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u65b9\u5411\u5bf9\u9f50\u6270\u52a8\u65b9\u6848\u5728\u6e10\u8fd1\u65b9\u5dee\u6700\u5c0f\u5316\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff0c\u5728\u5408\u6210\u95ee\u9898\u548c\u5b9e\u9645\u4efb\u52a1\u4e2d\uff0c\u65b9\u5411\u5bf9\u9f50\u6270\u52a8\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u65b9\u5411\u5bf9\u9f50\u6270\u52a8\u65b9\u6848\u4e3a\u968f\u673a\u6270\u52a8\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5730\u6cbf\u5173\u952e\u65b9\u5411\u63d0\u4f9b\u66f4\u9ad8\u7cbe\u5ea6\uff0c\u5728\u7279\u5b9a\u573a\u666f\u4e0b\u80fd\u591f\u63d0\u5347\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2510.20274", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20274", "abs": "https://arxiv.org/abs/2510.20274", "authors": ["Kangda Zhi", "Tianyu Yang", "Songyan Xue", "Giuseppe Caire"], "title": "Near-Field 3D Localization and MIMO Channel Estimation with Sub-Connected Planar Arrays", "comment": "Accepted by GLOBECOM 2025", "summary": "This paper investigates the design of channel estimation and 3D localization\nalgorithms in a challenging scenario, where a sub-connected planar extremely\nlarge-scale multiple-input multiple-output (XL-MIMO) communicates with\nmulti-antenna users. In the near field, the uplink MIMO channel is of full\ncolumn rank and therefore can not be estimated effectively by applying existing\ncodebooks that are designed for the far-field case or for the near-field case\nbut limited to single antenna users. To solve this problem, we propose a\nthree-stage algorithm aided by orthogonal matching pursuit (OMP) and sparse\nBayesian learning (SBL). Specifically, we firstly partition the XL-MIMO into\nsubarrays and use OMP to solve the compressed sensing (CS) problem about\nsubarray channel estimation with the Discrete Fourier Transform (DFT)-based\ndictionary matrix. Secondly, exploiting the estimated subarray channels and\nemploying one-dimensional multiple signal classification (MUSIC), we estimate\nthe central location of the user array under the Least Squares (LS) criterion.\nFinally, we utilize the estimated central location to construct a refined\nlocation-aided dictionary matrix and obtain the MIMO channel estimation using\nSBL. Results exhibit the significant superiority of the proposed algorithm\ncompared with several benchmarks, in terms of both the pilot overhead and\nestimation accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u8fd1\u573aXL-MIMO\u7cfb\u7edf\u4e2d\u4fe1\u9053\u4f30\u8ba1\u548c3D\u5b9a\u4f4d\u7684\u4e09\u9636\u6bb5\u7b97\u6cd5\uff0c\u7ed3\u5408OMP\u548cSBL\u6280\u672f\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5bfc\u9891\u5f00\u9500\u5e76\u63d0\u9ad8\u4e86\u4f30\u8ba1\u7cbe\u5ea6\u3002", "motivation": "\u5728\u8fd1\u573aXL-MIMO\u7cfb\u7edf\u4e2d\uff0c\u73b0\u6709\u7801\u672c\u8bbe\u8ba1\u4e0d\u9002\u7528\u4e8e\u591a\u5929\u7ebf\u7528\u6237\u573a\u666f\uff0c\u5bfc\u81f4\u4fe1\u9053\u4f30\u8ba1\u6548\u679c\u4e0d\u4f73\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u6709\u6548\u7b97\u6cd5\u3002", "method": "\u4e09\u9636\u6bb5\u7b97\u6cd5\uff1a1\uff09\u4f7f\u7528OMP\u548cDFT\u5b57\u5178\u8fdb\u884c\u5b50\u9635\u5217\u4fe1\u9053\u4f30\u8ba1\uff1b2\uff09\u5229\u7528MUSIC\u548cLS\u51c6\u5219\u4f30\u8ba1\u7528\u6237\u9635\u5217\u4e2d\u5fc3\u4f4d\u7f6e\uff1b3\uff09\u57fa\u4e8e\u4f30\u8ba1\u4f4d\u7f6e\u6784\u5efa\u4f4d\u7f6e\u8f85\u52a9\u5b57\u5178\uff0c\u4f7f\u7528SBL\u8fdb\u884cMIMO\u4fe1\u9053\u4f30\u8ba1\u3002", "result": "\u4e0e\u591a\u4e2a\u57fa\u51c6\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u7b97\u6cd5\u5728\u5bfc\u9891\u5f00\u9500\u548c\u4f30\u8ba1\u7cbe\u5ea6\u65b9\u9762\u5747\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "\u8be5\u4e09\u9636\u6bb5\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8fd1\u573aXL-MIMO\u7cfb\u7edf\u4e2d\u591a\u5929\u7ebf\u7528\u6237\u7684\u4fe1\u9053\u4f30\u8ba1\u548c3D\u5b9a\u4f4d\u95ee\u9898\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.19980", "categories": ["cs.LG", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.19980", "abs": "https://arxiv.org/abs/2510.19980", "authors": ["Renzhao Liang", "Sizhe Xu", "Chenggang Xie", "Jingru Chen", "Feiyang Ren", "Shu Yang", "Takahiro Yabe"], "title": "Abstain Mask Retain Core: Time Series Prediction by Adaptive Masking Loss with Representation Consistency", "comment": "20 pages, 4 figures. Accepted as Spotlight poster in NeurIPS 2025", "summary": "Time series forecasting plays a pivotal role in critical domains such as\nenergy management and financial markets. Although deep learning-based\napproaches (e.g., MLP, RNN, Transformer) have achieved remarkable progress, the\nprevailing \"long-sequence information gain hypothesis\" exhibits inherent\nlimitations. Through systematic experimentation, this study reveals a\ncounterintuitive phenomenon: appropriately truncating historical data can\nparadoxically enhance prediction accuracy, indicating that existing models\nlearn substantial redundant features (e.g., noise or irrelevant fluctuations)\nduring training, thereby compromising effective signal extraction. Building\nupon information bottleneck theory, we propose an innovative solution termed\nAdaptive Masking Loss with Representation Consistency (AMRC), which features\ntwo core components: 1) Dynamic masking loss, which adaptively identified\nhighly discriminative temporal segments to guide gradient descent during model\ntraining; 2) Representation consistency constraint, which stabilized the\nmapping relationships among inputs, labels, and predictions. Experimental\nresults demonstrate that AMRC effectively suppresses redundant feature learning\nwhile significantly improving model performance. This work not only challenges\nconventional assumptions in temporal modeling but also provides novel\ntheoretical insights and methodological breakthroughs for developing efficient\nand robust forecasting models.", "AI": {"tldr": "\u672c\u6587\u6311\u6218\u4e86\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\"\u957f\u5e8f\u5217\u4fe1\u606f\u589e\u76ca\u5047\u8bbe\"\uff0c\u53d1\u73b0\u9002\u5f53\u622a\u65ad\u5386\u53f2\u6570\u636e\u53cd\u800c\u80fd\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5e76\u63d0\u51faAMRC\u65b9\u6cd5\u901a\u8fc7\u52a8\u6001\u63a9\u7801\u635f\u5931\u548c\u8868\u793a\u4e00\u81f4\u6027\u7ea6\u675f\u6765\u6291\u5236\u5197\u4f59\u7279\u5f81\u5b66\u4e60\u3002", "motivation": "\u4f20\u7edf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u57fa\u4e8e\"\u957f\u5e8f\u5217\u4fe1\u606f\u589e\u76ca\u5047\u8bbe\"\uff0c\u4f46\u8be5\u5047\u8bbe\u5b58\u5728\u56fa\u6709\u5c40\u9650\u6027\u3002\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5b66\u4e60\u5927\u91cf\u5197\u4f59\u7279\u5f81\uff08\u5982\u566a\u58f0\u6216\u4e0d\u76f8\u5173\u6ce2\u52a8\uff09\uff0c\u4ece\u800c\u5f71\u54cd\u6709\u6548\u4fe1\u53f7\u63d0\u53d6\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u63a9\u7801\u635f\u5931\u4e0e\u8868\u793a\u4e00\u81f4\u6027\uff08AMRC\uff09\u65b9\u6cd5\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09\u52a8\u6001\u63a9\u7801\u635f\u5931\uff0c\u81ea\u9002\u5e94\u8bc6\u522b\u9ad8\u533a\u5206\u5ea6\u65f6\u95f4\u7247\u6bb5\u6765\u6307\u5bfc\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u68af\u5ea6\u4e0b\u964d\uff1b2\uff09\u8868\u793a\u4e00\u81f4\u6027\u7ea6\u675f\uff0c\u7a33\u5b9a\u8f93\u5165\u3001\u6807\u7b7e\u548c\u9884\u6d4b\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eAMRC\u80fd\u6709\u6548\u6291\u5236\u5197\u4f59\u7279\u5f81\u5b66\u4e60\uff0c\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e0d\u4ec5\u6311\u6218\u4e86\u65f6\u95f4\u5efa\u6a21\u4e2d\u7684\u4f20\u7edf\u5047\u8bbe\uff0c\u8fd8\u4e3a\u5f00\u53d1\u9ad8\u6548\u9c81\u68d2\u7684\u9884\u6d4b\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89c1\u89e3\u548c\u65b9\u6cd5\u7a81\u7834\u3002"}}
{"id": "2510.20363", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20363", "abs": "https://arxiv.org/abs/2510.20363", "authors": ["Andr\u00e1s R\u00e1cz", "Tam\u00e1s Borsos", "Andr\u00e1s Veres", "Benedek Csala"], "title": "A Transformer Inspired AI-based MIMO receiver", "comment": null, "summary": "We present AttDet, a Transformer-inspired MIMO (Multiple Input Multiple\nOutput) detection method that treats each transmit layer as a token and learns\ninter-stream interference via a lightweight self-attention mechanism. Queries\nand keys are derived directly from the estimated channel matrix, so attention\nscores quantify channel correlation. Values are initialized by matched-filter\noutputs and iteratively refined. The AttDet design combines model-based\ninterpretability with data-driven flexibility. We demonstrate through\nlink-level simulations under realistic 5G channel models and high-order, mixed\nQAM modulation and coding schemes, that AttDet can approach near-optimal\nBER/BLER (Bit Error Rate/Block Error Rate) performance while maintaining\npredictable, polynomial complexity.", "AI": {"tldr": "AttDet\u662f\u4e00\u79cd\u57fa\u4e8eTransformer\u7684MIMO\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5c06\u6bcf\u4e2a\u4f20\u8f93\u5c42\u89c6\u4e3atoken\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5b66\u4e60\u6d41\u95f4\u5e72\u6270\uff0c\u7ed3\u5408\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u548c\u6570\u636e\u9a71\u52a8\u7075\u6d3b\u6027\uff0c\u57285G\u4fe1\u9053\u4e0b\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684BER/BLER\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3MIMO\u7cfb\u7edf\u4e2d\u590d\u6742\u7684\u6d41\u95f4\u5e72\u6270\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u68c0\u6d4b\u7b97\u6cd5\u7684\u53ef\u89e3\u91ca\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u7ed3\u5408\u6a21\u578b\u9a71\u52a8\u548c\u6570\u636e\u9a71\u52a8\u4f18\u52bf\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u5c06\u6bcf\u4e2a\u4f20\u8f93\u5c42\u4f5c\u4e3atoken\uff0c\u76f4\u63a5\u4ece\u4f30\u8ba1\u7684\u4fe1\u9053\u77e9\u9635\u63a8\u5bfc\u67e5\u8be2\u548c\u952e\u5411\u91cf\uff0c\u6ce8\u610f\u529b\u5206\u6570\u91cf\u5316\u4fe1\u9053\u76f8\u5173\u6027\uff0c\u503c\u5411\u91cf\u7531\u5339\u914d\u6ee4\u6ce2\u5668\u8f93\u51fa\u521d\u59cb\u5316\u5e76\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5728\u73b0\u5b9e\u76845G\u4fe1\u9053\u6a21\u578b\u548c\u9ad8\u9636\u6df7\u5408QAM\u8c03\u5236\u7f16\u7801\u65b9\u6848\u4e0b\uff0cAttDet\u80fd\u591f\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684BER/BLER\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u591a\u9879\u5f0f\u590d\u6742\u5ea6\u3002", "conclusion": "AttDet\u6210\u529f\u5730\u5c06Transformer\u67b6\u6784\u5e94\u7528\u4e8eMIMO\u68c0\u6d4b\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u7684\u540c\u65f6\u63d0\u4f9b\u4e86\u6570\u636e\u9a71\u52a8\u7684\u7075\u6d3b\u6027\uff0c\u4e3a\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u53ef\u9760\u7684\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20019", "categories": ["cs.LG", "cs.CR", "2020: Primary 68T05, Secondary 68T10", "I.2.6; I.6.4; C.3"], "pdf": "https://arxiv.org/pdf/2510.20019", "abs": "https://arxiv.org/abs/2510.20019", "authors": ["Curtis Lee Shull", "Merrick Green"], "title": "Machine Learning-Based Localization Accuracy of RFID Sensor Networks via RSSI Decision Trees and CAD Modeling for Defense Applications", "comment": "10 pages, 5 figures. Submitted to the Journal of Defense Modeling and\n  Simulation (JDMS) for the Special Issue Integrating AI/ML Into Modeling and\n  Simulation (J22-4). This work evaluates machine learning-based RFID\n  localization for defense logistics environments using CAD-modeled simulations\n  and RSSI-driven decision tree classification", "summary": "Radio Frequency Identification (RFID) tracking may be a viable solution for\ndefense assets that must be stored in accordance with security guidelines.\nHowever, poor sensor specificity (vulnerabilities include long range detection,\nspoofing, and counterfeiting) can lead to erroneous detection and operational\nsecurity events. We present a supervised learning simulation with realistic\nReceived Signal Strength Indicator (RSSI) data and Decision Tree classification\nin a Computer Assisted Design (CAD)-modeled floor plan that encapsulates some\nof the challenges encountered in defense storage. In this work, we focused on\nclassifying 12 lab zones (LabZoneA-L) to perform location inference. The raw\ndataset had approximately 980,000 reads. Class frequencies were imbalanced, and\nclass weights were calculated to account for class imbalance in this\nmulti-class setting. The model, trained on stratified subsamples to 5,000\nbalanced observations, yielded an overall accuracy of 34.2% and F1-scores\ngreater than 0.40 for multiple zones (Zones F, G, H, etc.). However, rare\nclasses (most notably LabZoneC) were often misclassified, even with the use of\nclass weights. An adjacency-aware confusion matrix was calculated to allow\nbetter interpretation of physically adjacent zones. These results suggest that\nRSSI-based decision trees can be applied in realistic simulations to enable\nzone-level anomaly detection or misplacement monitoring for defense supply\nlogistics. Reliable classification performance in low-coverage and low-signal\nzones could be improved with better antenna placement or additional sensors and\nsensor fusion with other modalities.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u76d1\u7763\u5b66\u4e60\u548c\u51b3\u7b56\u6811\u5206\u7c7b\u5668\uff0c\u5728CAD\u5efa\u6a21\u7684\u5e73\u9762\u56fe\u4e2d\u57fa\u4e8eRSSI\u6570\u636e\u8fdb\u884cRFID\u4f4d\u7f6e\u63a8\u65ad\uff0c\u65e8\u5728\u89e3\u51b3\u56fd\u9632\u8d44\u4ea7\u5b58\u50a8\u4e2d\u7684\u5b89\u5168\u76d1\u63a7\u95ee\u9898\u3002", "motivation": "RFID\u8ddf\u8e2a\u6280\u672f\u5b58\u5728\u4f20\u611f\u5668\u7279\u5f02\u6027\u5dee\u7684\u95ee\u9898\uff08\u5982\u8fdc\u8ddd\u79bb\u68c0\u6d4b\u3001\u6b3a\u9a97\u548c\u4f2a\u9020\u6f0f\u6d1e\uff09\uff0c\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u68c0\u6d4b\u548c\u64cd\u4f5c\u5b89\u5168\u4e8b\u4ef6\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u66f4\u53ef\u9760\u7684\u4f4d\u7f6e\u63a8\u65ad\u65b9\u6cd5\u7528\u4e8e\u56fd\u9632\u8d44\u4ea7\u5b58\u50a8\u5b89\u5168\u3002", "method": "\u91c7\u7528\u76d1\u7763\u5b66\u4e60\u6a21\u62df\uff0c\u4f7f\u7528\u771f\u5b9e\u7684RSSI\u6570\u636e\u548c\u51b3\u7b56\u6811\u5206\u7c7b\u5668\uff0c\u5728CAD\u5efa\u6a21\u7684\u5e73\u9762\u56fe\u4e2d\u5bf912\u4e2a\u5b9e\u9a8c\u5ba4\u533a\u57df\u8fdb\u884c\u5206\u7c7b\uff0c\u901a\u8fc7\u5206\u5c42\u62bd\u6837\u5e73\u8861\u6570\u636e\u96c6\uff085000\u4e2a\u5e73\u8861\u89c2\u6d4b\u503c\uff09\uff0c\u5e76\u8ba1\u7b97\u7c7b\u522b\u6743\u91cd\u6765\u5904\u7406\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "\u6a21\u578b\u6574\u4f53\u51c6\u786e\u7387\u4e3a34.2%\uff0c\u591a\u4e2a\u533a\u57df\uff08F\u3001G\u3001H\u7b49\uff09\u7684F1\u5206\u6570\u8d85\u8fc70.40\uff0c\u4f46\u7a00\u6709\u7c7b\u522b\uff08\u7279\u522b\u662fLabZoneC\uff09\u7ecf\u5e38\u88ab\u9519\u8bef\u5206\u7c7b\u3002\u8ba1\u7b97\u4e86\u90bb\u63a5\u611f\u77e5\u6df7\u6dc6\u77e9\u9635\u4ee5\u66f4\u597d\u5730\u89e3\u91ca\u7269\u7406\u76f8\u90bb\u533a\u57df\u7684\u5206\u7c7b\u7ed3\u679c\u3002", "conclusion": "\u57fa\u4e8eRSSI\u7684\u51b3\u7b56\u6811\u53ef\u4ee5\u5728\u73b0\u5b9e\u6a21\u62df\u4e2d\u5e94\u7528\u4e8e\u533a\u57df\u7ea7\u5f02\u5e38\u68c0\u6d4b\u6216\u9519\u4f4d\u76d1\u63a7\uff0c\u4f46\u5728\u4f4e\u8986\u76d6\u548c\u4f4e\u4fe1\u53f7\u533a\u57df\u7684\u53ef\u9760\u5206\u7c7b\u6027\u80fd\u53ef\u4ee5\u901a\u8fc7\u6539\u8fdb\u5929\u7ebf\u5e03\u5c40\u6216\u589e\u52a0\u4f20\u611f\u5668\u53ca\u591a\u6a21\u6001\u4f20\u611f\u5668\u878d\u5408\u6765\u63d0\u5347\u3002"}}
{"id": "2510.20022", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20022", "abs": "https://arxiv.org/abs/2510.20022", "authors": ["Jiazheng Li", "Yawei Wang", "David Yan", "Yijun Tian", "Zhichao Xu", "Huan Song", "Panpan Xu", "Lin Lee Cheong"], "title": "SALT: Step-level Advantage Assignment for Long-horizon Agents via Trajectory Graph", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities,\nenabling language agents to excel at single-turn tasks. However, their\napplication to complex, multi-step, and long-horizon tasks remains challenging.\nWhile reinforcement learning (RL) offers a promising avenue for addressing\nthese challenges, mainstream approaches typically rely solely on sparse,\noutcome-based rewards, a limitation that becomes especially problematic for\ngroup-based RL algorithms lacking critic models, such as Group Relative Policy\nOptimization (GRPO). In such methods, uniformly rewarding or penalizing all\nactions within a trajectory can lead to training instability and suboptimal\npolicies, because beneficial and detrimental actions are often entangled across\nmulti-step interactions. To address this challenge, we propose SALT, a novel\nand lightweight framework that provides a finer-grained advantage assignment,\nderived solely from outcome rewards. We achieve this by constructing a graph\nfrom trajectories of the same prompt, which allows us to quantify the quality\nof each step and assign advantages accordingly. Crucially, SALT is designed as\na plug-and-play module that seamlessly integrates with existing group-based RL\nalgorithms, requiring no modifications to the rollout procedure and introducing\nnegligible computational overhead. Extensive experiments on the WebShop,\nALFWorld, and AppWorld benchmarks with various model sizes demonstrate that\nSALT consistently improves performance. We also conduct a thorough analysis to\nvalidate the design choices behind SALT and offer actionable insights.", "AI": {"tldr": "SALT\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u8f68\u8ff9\u56fe\u6765\u63d0\u4f9b\u66f4\u7ec6\u7c92\u5ea6\u7684\u4f18\u52bf\u5206\u914d\uff0c\u89e3\u51b3\u4e86\u57fa\u4e8e\u7fa4\u4f53\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u4e2d\u7a00\u758f\u5956\u52b1\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u6b21\u4f18\u7b56\u7565\u7684\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5355\u8f6e\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u590d\u6742\u3001\u591a\u6b65\u9aa4\u3001\u957f\u89c6\u91ce\u4efb\u52a1\u4e2d\u9762\u4e34\u6311\u6218\u3002\u57fa\u4e8e\u7fa4\u4f53\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5982GRPO\u4ec5\u4f9d\u8d56\u7a00\u758f\u7ed3\u679c\u5956\u52b1\uff0c\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u6b21\u4f18\u7b56\u7565\u3002", "method": "\u63d0\u51faSALT\u6846\u67b6\uff0c\u4ece\u76f8\u540c\u63d0\u793a\u7684\u8f68\u8ff9\u6784\u5efa\u56fe\uff0c\u91cf\u5316\u6bcf\u4e2a\u6b65\u9aa4\u7684\u8d28\u91cf\u5e76\u76f8\u5e94\u5206\u914d\u4f18\u52bf\u3002\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u6a21\u5757\uff0c\u65e0\u9700\u4fee\u6539rollout\u8fc7\u7a0b\uff0c\u8ba1\u7b97\u5f00\u9500\u53ef\u5ffd\u7565\u3002", "result": "\u5728WebShop\u3001ALFWorld\u548cAppWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSALT\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0b\u5747\u80fd\u6301\u7eed\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "SALT\u901a\u8fc7\u7ec6\u7c92\u5ea6\u4f18\u52bf\u5206\u914d\u6709\u6548\u89e3\u51b3\u4e86\u57fa\u4e8e\u7fa4\u4f53RL\u7b97\u6cd5\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u53ef\u4f5c\u4e3a\u73b0\u6709\u7b97\u6cd5\u7684\u589e\u5f3a\u6a21\u5757\u3002"}}
{"id": "2510.20275", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20275", "abs": "https://arxiv.org/abs/2510.20275", "authors": ["Yunzhi Liu", "Haokai Tan", "Rushi Kanjaria", "Lihuan Li", "Flora D. Salim"], "title": "Classical Feature Embeddings Help in BERT-Based Human Mobility Prediction", "comment": "This paper has been accepted by ACM SIGSPATIAL 2025 as a short paper", "summary": "Human mobility forecasting is crucial for disaster relief, city planning, and\npublic health. However, existing models either only model location sequences or\ninclude time information merely as auxiliary input, thereby failing to leverage\nthe rich semantic context provided by points of interest (POIs). To address\nthis, we enrich a BERT-based mobility model with derived temporal descriptors\nand POI embeddings to better capture the semantics underlying human movement.\nWe propose STaBERT (Semantic-Temporal aware BERT), which integrates both POI\nand temporal information at each location to construct a unified, semantically\nenriched representation of mobility. Experimental results show that STaBERT\nsignificantly improves prediction accuracy: for single-city prediction, the\nGEO-BLEU score improved from 0.34 to 0.75; for multi-city prediction, from 0.34\nto 0.56.", "AI": {"tldr": "STaBERT\u6a21\u578b\u901a\u8fc7\u6574\u5408POI\u4fe1\u606f\u548c\u65f6\u95f4\u63cf\u8ff0\u7b26\u6765\u589e\u5f3aBERT\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4eba\u7c7b\u79fb\u52a8\u6027\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u8981\u4e48\u53ea\u5efa\u6a21\u4f4d\u7f6e\u5e8f\u5217\uff0c\u8981\u4e48\u4ec5\u5c06\u65f6\u95f4\u4fe1\u606f\u4f5c\u4e3a\u8f85\u52a9\u8f93\u5165\uff0c\u672a\u80fd\u5145\u5206\u5229\u7528\u5174\u8da3\u70b9(POI)\u63d0\u4f9b\u7684\u4e30\u5bcc\u8bed\u4e49\u4e0a\u4e0b\u6587\u3002", "method": "\u63d0\u51faSTaBERT\u6a21\u578b\uff0c\u5728\u6bcf\u4e2a\u4f4d\u7f6e\u6574\u5408POI\u548c\u65f6\u95f4\u4fe1\u606f\uff0c\u6784\u5efa\u7edf\u4e00\u7684\u8bed\u4e49\u589e\u5f3a\u79fb\u52a8\u6027\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aSTaBERT\u663e\u8457\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\uff1a\u5355\u57ce\u5e02\u9884\u6d4b\u7684GEO-BLEU\u5f97\u5206\u4ece0.34\u63d0\u5347\u52300.75\uff1b\u591a\u57ce\u5e02\u9884\u6d4b\u4ece0.34\u63d0\u5347\u52300.56\u3002", "conclusion": "\u6574\u5408POI\u548c\u65f6\u95f4\u4fe1\u606f\u80fd\u591f\u6709\u6548\u6355\u6349\u4eba\u7c7b\u79fb\u52a8\u7684\u8bed\u4e49\u57fa\u7840\uff0c\u663e\u8457\u6539\u8fdb\u79fb\u52a8\u6027\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2510.20507", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20507", "abs": "https://arxiv.org/abs/2510.20507", "authors": ["Xi Gao", "Akang Wang", "Junkai Zhang", "Qihong Duan", "Jiang Xue"], "title": "An Accelerated Mixed Weighted-Unweighted MMSE Approach for MU-MIMO Beamforming", "comment": null, "summary": "Precoding design based on weighted sum-rate (WSR) maximization is a\nfundamental problem in downlink multi-user multiple-input multiple-output\n(MU-MIMO) systems. While the weighted minimum mean-square error (WMMSE)\nalgorithm is a standard solution, its high computational complexity--cubic in\nthe number of base station antennas due to matrix inversions--hinders its\napplication in latency-sensitive scenarios. To address this limitation, we\npropose a highly parallel algorithm based on a block coordinate descent\nframework. Our key innovation lies in updating the precoding matrix via block\ncoordinate gradient descent, which avoids matrix inversions and relies solely\non matrix multiplications, making it exceptionally amenable to GPU\nacceleration. We prove that the proposed algorithm converges to a stationary\npoint of the WSR maximization problem. Furthermore, we introduce a two-stage\nwarm-start strategy grounded in the sum mean-square error (MSE) minimization\nproblem to accelerate convergence. We refer to our method as the Accelerated\nMixed weighted-unweighted sum-MSE minimization (A-MMMSE) algorithm. Simulation\nresults demonstrate that A-MMMSE matches the WSR performance of both\nconventional WMMSE and its enhanced variant, reduced-WMMSE, while achieving a\nsubstantial reduction in computational time across diverse system\nconfigurations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5757\u5750\u6807\u4e0b\u964d\u6846\u67b6\u7684\u9ad8\u5e76\u884c\u7b97\u6cd5A-MMMSE\uff0c\u7528\u4e8e\u591a\u7528\u6237MIMO\u7cfb\u7edf\u7684\u9884\u7f16\u7801\u8bbe\u8ba1\uff0c\u907f\u514d\u4e86\u4f20\u7edfWMMSE\u7b97\u6cd5\u4e2d\u7684\u77e9\u9635\u6c42\u9006\u64cd\u4f5c\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u5e76\u9002\u5408GPU\u52a0\u901f\u3002", "motivation": "\u4f20\u7edfWMMSE\u7b97\u6cd5\u5728\u57fa\u7ad9\u5929\u7ebf\u6570\u91cf\u8f83\u591a\u65f6\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff08\u7acb\u65b9\u7ea7\uff09\uff0c\u9650\u5236\u4e86\u5176\u5728\u5ef6\u8fdf\u654f\u611f\u573a\u666f\u4e2d\u7684\u5e94\u7528\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u7b97\u6cd5\u3002", "method": "\u91c7\u7528\u5757\u5750\u6807\u68af\u5ea6\u4e0b\u964d\u66f4\u65b0\u9884\u7f16\u7801\u77e9\u9635\uff0c\u907f\u514d\u77e9\u9635\u6c42\u9006\uff0c\u4ec5\u4f7f\u7528\u77e9\u9635\u4e58\u6cd5\uff1b\u5f15\u5165\u57fa\u4e8e\u548c\u5747\u65b9\u8bef\u5dee\u6700\u5c0f\u5316\u95ee\u9898\u7684\u4e24\u9636\u6bb5\u70ed\u542f\u52a8\u7b56\u7565\u52a0\u901f\u6536\u655b\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660eA-MMMSE\u5728\u52a0\u6743\u548c\u901f\u7387\u6027\u80fd\u4e0a\u4e0eWMMSE\u53ca\u5176\u589e\u5f3a\u53d8\u4f53reduced-WMMSE\u76f8\u5f53\uff0c\u540c\u65f6\u5728\u5404\u79cd\u7cfb\u7edf\u914d\u7f6e\u4e0b\u663e\u8457\u51cf\u5c11\u4e86\u8ba1\u7b97\u65f6\u95f4\u3002", "conclusion": "A-MMMSE\u7b97\u6cd5\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u7279\u522b\u9002\u5408GPU\u52a0\u901f\uff0c\u4e3a\u5ef6\u8fdf\u654f\u611f\u7684\u591a\u7528\u6237MIMO\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u9884\u7f16\u7801\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20337", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20337", "abs": "https://arxiv.org/abs/2510.20337", "authors": ["Clara Maathuis", "Kasper Cools"], "title": "Collateral Damage Assessment Model for AI System Target Engagement in Military Operations", "comment": "Accepted at MILCOM 2025 WS07", "summary": "In an era where AI (Artificial Intelligence) systems play an increasing role\nin the battlefield, ensuring responsible targeting demands rigorous assessment\nof potential collateral effects. In this context, a novel collateral damage\nassessment model for target engagement of AI systems in military operations is\nintroduced. The model integrates temporal, spatial, and force dimensions within\na unified Knowledge Representation and Reasoning (KRR) architecture following a\ndesign science methodological approach. Its layered structure captures the\ncategories and architectural components of the AI systems to be engaged\ntogether with corresponding engaging vectors and contextual aspects. At the\nsame time, spreading, severity, likelihood, and evaluation metrics are\nconsidered in order to provide a clear representation enhanced by transparent\nreasoning mechanisms. Further, the model is demonstrated and evaluated through\ninstantiation which serves as a basis for further dedicated efforts that aim at\nbuilding responsible and trustworthy intelligent systems for assessing the\neffects produced by engaging AI systems in military operations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u519b\u4e8b\u884c\u52a8\u4e2dAI\u7cfb\u7edf\u76ee\u6807\u6253\u51fb\u7684\u9644\u5e26\u635f\u5bb3\u8bc4\u4f30\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5c06\u65f6\u95f4\u3001\u7a7a\u95f4\u548c\u529b\u91cf\u7ef4\u5ea6\u6574\u5408\u5230\u7edf\u4e00\u7684\u77e5\u8bc6\u8868\u793a\u4e0e\u63a8\u7406\u67b6\u6784\u4e2d\uff0c\u901a\u8fc7\u5206\u5c42\u7ed3\u6784\u6355\u83b7AI\u7cfb\u7edf\u7684\u7c7b\u522b\u3001\u67b6\u6784\u7ec4\u4ef6\u3001\u6253\u51fb\u5411\u91cf\u548c\u4e0a\u4e0b\u6587\u65b9\u9762\u3002", "motivation": "\u5728AI\u7cfb\u7edf\u5728\u6218\u573a\u4e2d\u626e\u6f14\u65e5\u76ca\u91cd\u8981\u89d2\u8272\u7684\u65f6\u4ee3\uff0c\u786e\u4fdd\u8d1f\u8d23\u4efb\u7684\u6253\u51fb\u9700\u8981\u5bf9\u6f5c\u5728\u9644\u5e26\u6548\u5e94\u8fdb\u884c\u4e25\u683c\u8bc4\u4f30\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u65b9\u6cd5\u8bba\uff0c\u6784\u5efa\u4e86\u96c6\u6210\u65f6\u95f4\u3001\u7a7a\u95f4\u548c\u529b\u91cf\u7ef4\u5ea6\u7684\u7edf\u4e00\u77e5\u8bc6\u8868\u793a\u4e0e\u63a8\u7406\u67b6\u6784\uff0c\u6a21\u578b\u5305\u542b\u5206\u5c42\u7ed3\u6784\u6765\u6355\u83b7AI\u7cfb\u7edf\u7c7b\u522b\u3001\u67b6\u6784\u7ec4\u4ef6\u3001\u6253\u51fb\u5411\u91cf\u548c\u4e0a\u4e0b\u6587\u65b9\u9762\uff0c\u5e76\u8003\u8651\u4f20\u64ad\u3001\u4e25\u91cd\u6027\u3001\u53ef\u80fd\u6027\u548c\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u901a\u8fc7\u5b9e\u4f8b\u5316\u6f14\u793a\u548c\u8bc4\u4f30\u4e86\u8be5\u6a21\u578b\uff0c\u4e3a\u6784\u5efa\u8d1f\u8d23\u4efb\u548c\u53ef\u4fe1\u8d56\u7684\u667a\u80fd\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u8bc4\u4f30\u519b\u4e8b\u884c\u52a8\u4e2d\u6253\u51fbAI\u7cfb\u7edf\u4ea7\u751f\u7684\u6548\u5e94\u63d0\u4f9b\u4e86\u900f\u660e\u63a8\u7406\u673a\u5236\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u8d1f\u8d23\u4efb\u7684\u667a\u80fd\u7cfb\u7edf\u3002"}}
{"id": "2510.20068", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20068", "abs": "https://arxiv.org/abs/2510.20068", "authors": ["Ram Dyuthi Sristi", "Sowmya Manojna Narasimha", "Jingya Huang", "Alice Despatin", "Simon Musall", "Vikash Gilja", "Gal Mishne"], "title": "Coupled Transformer Autoencoder for Disentangling Multi-Region Neural Latent Dynamics", "comment": null, "summary": "Simultaneous recordings from thousands of neurons across multiple brain areas\nreveal rich mixtures of activity that are shared between regions and dynamics\nthat are unique to each region. Existing alignment or multi-view methods\nneglect temporal structure, whereas dynamical latent variable models capture\ntemporal dependencies but are usually restricted to a single area, assume\nlinear read-outs, or conflate shared and private signals. We introduce the\nCoupled Transformer Autoencoder (CTAE) - a sequence model that addresses both\n(i) non-stationary, non-linear dynamics and (ii) separation of shared versus\nregion-specific structure in a single framework. CTAE employs transformer\nencoders and decoders to capture long-range neural dynamics and explicitly\npartitions each region's latent space into orthogonal shared and private\nsubspaces. We demonstrate the effectiveness of CTAE on two high-density\nelectrophysiology datasets with simultaneous recordings from multiple regions,\none from motor cortical areas and the other from sensory areas. CTAE extracts\nmeaningful representations that better decode behavioral variables compared to\nexisting approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8026\u5408Transformer\u81ea\u7f16\u7801\u5668\uff08CTAE\uff09\uff0c\u7528\u4e8e\u540c\u65f6\u5904\u7406\u591a\u8111\u533a\u795e\u7ecf\u8bb0\u5f55\u4e2d\u7684\u975e\u5e73\u7a33\u975e\u7ebf\u6027\u52a8\u6001\uff0c\u5e76\u5206\u79bb\u5171\u4eab\u4e0e\u533a\u57df\u7279\u5f02\u6027\u7ed3\u6784\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u5ffd\u7565\u65f6\u95f4\u7ed3\u6784\uff0c\u8981\u4e48\u5c40\u9650\u4e8e\u5355\u4e00\u8111\u533a\u3001\u5047\u8bbe\u7ebf\u6027\u8bfb\u51fa\uff0c\u6216\u6df7\u6dc6\u5171\u4eab\u548c\u79c1\u6709\u4fe1\u53f7\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u591a\u8111\u533a\u540c\u65f6\u8bb0\u5f55\u4e2d\u7684\u590d\u6742\u795e\u7ecf\u52a8\u6001\u3002", "method": "CTAE\u91c7\u7528Transformer\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u6355\u83b7\u957f\u7a0b\u795e\u7ecf\u52a8\u6001\uff0c\u5e76\u660e\u786e\u5c06\u6bcf\u4e2a\u8111\u533a\u7684\u6f5c\u5728\u7a7a\u95f4\u5212\u5206\u4e3a\u6b63\u4ea4\u7684\u5171\u4eab\u548c\u79c1\u6709\u5b50\u7a7a\u95f4\u3002", "result": "\u5728\u4e24\u4e2a\u9ad8\u5bc6\u5ea6\u7535\u751f\u7406\u6570\u636e\u96c6\uff08\u8fd0\u52a8\u76ae\u5c42\u548c\u611f\u89c9\u533a\u57df\uff09\u4e0a\uff0cCTAE\u63d0\u53d6\u7684\u8868\u5f81\u6bd4\u73b0\u6709\u65b9\u6cd5\u80fd\u66f4\u597d\u5730\u89e3\u7801\u884c\u4e3a\u53d8\u91cf\u3002", "conclusion": "CTAE\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u80fd\u591f\u540c\u65f6\u5904\u7406\u591a\u8111\u533a\u795e\u7ecf\u8bb0\u5f55\u4e2d\u7684\u975e\u5e73\u7a33\u975e\u7ebf\u6027\u52a8\u6001\u548c\u5171\u4eab-\u79c1\u6709\u4fe1\u53f7\u5206\u79bb\u95ee\u9898\u3002"}}
{"id": "2510.20084", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20084", "abs": "https://arxiv.org/abs/2510.20084", "authors": ["Bosong Huang", "Ming Jin", "Yuxuan Liang", "Johan Barthelemy", "Debo Cheng", "Qingsong Wen", "Chenghao Liu", "Shirui Pan"], "title": "ShapeX: Shapelet-Driven Post Hoc Explanations for Time Series Classification Models", "comment": null, "summary": "Explaining time series classification models is crucial, particularly in\nhigh-stakes applications such as healthcare and finance, where transparency and\ntrust play a critical role. Although numerous time series classification\nmethods have identified key subsequences, known as shapelets, as core features\nfor achieving state-of-the-art performance and validating their pivotal role in\nclassification outcomes, existing post-hoc time series explanation (PHTSE)\nmethods primarily focus on timestep-level feature attribution. These\nexplanation methods overlook the fundamental prior that classification outcomes\nare predominantly driven by key shapelets. To bridge this gap, we present\nShapeX, an innovative framework that segments time series into meaningful\nshapelet-driven segments and employs Shapley values to assess their saliency.\nAt the core of ShapeX lies the Shapelet Describe-and-Detect (SDD) framework,\nwhich effectively learns a diverse set of shapelets essential for\nclassification. We further demonstrate that ShapeX produces explanations which\nreveal causal relationships instead of just correlations, owing to the\natomicity properties of shapelets. Experimental results on both synthetic and\nreal-world datasets demonstrate that ShapeX outperforms existing methods in\nidentifying the most relevant subsequences, enhancing both the precision and\ncausal fidelity of time series explanations.", "AI": {"tldr": "ShapeX\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u89e3\u91ca\u6846\u67b6\uff0c\u901a\u8fc7\u8bc6\u522b\u5173\u952e\u5f62\u72b6\u7247\u6bb5\uff08shapelets\uff09\u5e76\u4f7f\u7528Shapley\u503c\u8bc4\u4f30\u5176\u91cd\u8981\u6027\uff0c\u63d0\u4f9b\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u7cbe\u786e\u548c\u5177\u6709\u56e0\u679c\u4fdd\u771f\u5ea6\u7684\u89e3\u91ca\u3002", "motivation": "\u5728\u533b\u7597\u548c\u91d1\u878d\u7b49\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\uff0c\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u6a21\u578b\u7684\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7684\u4e8b\u540e\u89e3\u91ca\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u65f6\u95f4\u6b65\u7ea7\u522b\u7684\u7279\u5f81\u5f52\u56e0\uff0c\u5ffd\u7565\u4e86\u5206\u7c7b\u7ed3\u679c\u4e3b\u8981\u7531\u5173\u952e\u5f62\u72b6\u7247\u6bb5\u9a71\u52a8\u7684\u57fa\u672c\u524d\u63d0\u3002", "method": "ShapeX\u6846\u67b6\u5305\u542bShapelet\u63cf\u8ff0\u4e0e\u68c0\u6d4b\uff08SDD\uff09\u6846\u67b6\uff0c\u80fd\u591f\u5b66\u4e60\u5bf9\u5206\u7c7b\u81f3\u5173\u91cd\u8981\u7684\u591a\u6837\u5316\u5f62\u72b6\u7247\u6bb5\uff0c\u5e76\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u5272\u4e3a\u6709\u610f\u4e49\u7684\u5f62\u72b6\u7247\u6bb5\u9a71\u52a8\u6bb5\uff0c\u4f7f\u7528Shapley\u503c\u8bc4\u4f30\u5176\u663e\u8457\u6027\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cShapeX\u5728\u8bc6\u522b\u6700\u76f8\u5173\u5b50\u5e8f\u5217\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u65f6\u95f4\u5e8f\u5217\u89e3\u91ca\u7684\u7cbe\u5ea6\u548c\u56e0\u679c\u4fdd\u771f\u5ea6\u3002", "conclusion": "ShapeX\u901a\u8fc7\u5229\u7528\u5f62\u72b6\u7247\u6bb5\u7684\u539f\u5b50\u6027\u7279\u6027\uff0c\u80fd\u591f\u4ea7\u751f\u63ed\u793a\u56e0\u679c\u5173\u7cfb\u800c\u4e0d\u4ec5\u4ec5\u662f\u76f8\u5173\u6027\u7684\u89e3\u91ca\uff0c\u4e3a\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u900f\u660e\u5ea6\u3002"}}
{"id": "2510.20457", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20457", "abs": "https://arxiv.org/abs/2510.20457", "authors": ["Louis Mozart Kamdem Teyou", "Luke Friedrichs", "N'Dah Jean Kouagou", "Caglar Demir", "Yasir Mahmood", "Stefan Heindorf", "Axel-Cyrille Ngonga Ngomo"], "title": "Neural Reasoning for Robust Instance Retrieval in $\\mathcal{SHOIQ}$", "comment": "Accepted as a full research paper at K-CAP 2025", "summary": "Concept learning exploits background knowledge in the form of description\nlogic axioms to learn explainable classification models from knowledge bases.\nDespite recent breakthroughs in neuro-symbolic concept learning, most\napproaches still cannot be deployed on real-world knowledge bases. This is due\nto their use of description logic reasoners, which are not robust against\ninconsistencies nor erroneous data. We address this challenge by presenting a\nnovel neural reasoner dubbed EBR. Our reasoner relies on embeddings to\napproximate the results of a symbolic reasoner. We show that EBR solely\nrequires retrieving instances for atomic concepts and existential restrictions\nto retrieve or approximate the set of instances of any concept in the\ndescription logic $\\mathcal{SHOIQ}$. In our experiments, we compare EBR with\nstate-of-the-art reasoners. Our results suggest that EBR is robust against\nmissing and erroneous data in contrast to existing reasoners.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEBR\u7684\u65b0\u578b\u795e\u7ecf\u63a8\u7406\u5668\uff0c\u4f7f\u7528\u5d4c\u5165\u6765\u8fd1\u4f3c\u7b26\u53f7\u63a8\u7406\u5668\u7684\u7ed3\u679c\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u63cf\u8ff0\u903b\u8f91\u63a8\u7406\u5668\u5728\u9762\u5bf9\u4e0d\u4e00\u81f4\u548c\u9519\u8bef\u6570\u636e\u65f6\u7f3a\u4e4f\u9c81\u68d2\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u795e\u7ecf\u7b26\u53f7\u6982\u5ff5\u5b66\u4e60\u65b9\u6cd5\u5728\u771f\u5b9e\u77e5\u8bc6\u5e93\u4e0a\u90e8\u7f72\u56f0\u96be\uff0c\u56e0\u4e3a\u4f7f\u7528\u7684\u63cf\u8ff0\u903b\u8f91\u63a8\u7406\u5668\u5bf9\u4e0d\u4e00\u81f4\u548c\u9519\u8bef\u6570\u636e\u7f3a\u4e4f\u9c81\u68d2\u6027\u3002", "method": "EBR\u63a8\u7406\u5668\u4f9d\u8d56\u5d4c\u5165\u6765\u8fd1\u4f3c\u7b26\u53f7\u63a8\u7406\u5668\u7684\u7ed3\u679c\uff0c\u4ec5\u9700\u8981\u68c0\u7d22\u539f\u5b50\u6982\u5ff5\u548c\u5b58\u5728\u9650\u5236\u7684\u5b9e\u4f8b\uff0c\u5c31\u80fd\u68c0\u7d22\u6216\u8fd1\u4f3cSHOIQ\u63cf\u8ff0\u903b\u8f91\u4e2d\u4efb\u4f55\u6982\u5ff5\u7684\u5b9e\u4f8b\u96c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cEBR\u4e0e\u6700\u5148\u8fdb\u7684\u63a8\u7406\u5668\u76f8\u6bd4\uff0c\u5728\u9762\u5bf9\u7f3a\u5931\u548c\u9519\u8bef\u6570\u636e\u65f6\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "EBR\u795e\u7ecf\u63a8\u7406\u5668\u4e3a\u6982\u5ff5\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u79cd\u5bf9\u6570\u636e\u9519\u8bef\u5177\u6709\u9c81\u68d2\u6027\u7684\u63a8\u7406\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7b26\u53f7\u63a8\u7406\u5668\u5728\u771f\u5b9e\u77e5\u8bc6\u5e93\u5e94\u7528\u4e2d\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2510.20467", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.20467", "abs": "https://arxiv.org/abs/2510.20467", "authors": ["Yiwen Peng", "Thomas Bonald", "Fabian M. Suchanek"], "title": "FLORA: Unsupervised Knowledge Graph Alignment by Fuzzy Logic", "comment": null, "summary": "Knowledge graph alignment is the task of matching equivalent entities (that\nis, instances and classes) and relations across two knowledge graphs. Most\nexisting methods focus on pure entity-level alignment, computing the similarity\nof entities in some embedding space. They lack interpretable reasoning and need\ntraining data to work. In this paper, we propose FLORA, a simple yet effective\nmethod that (1) is unsupervised, i.e., does not require training data, (2)\nprovides a holistic alignment for entities and relations iteratively, (3) is\nbased on fuzzy logic and thus delivers interpretable results, (4) provably\nconverges, (5) allows dangling entities, i.e., entities without a counterpart\nin the other KG, and (6) achieves state-of-the-art results on major benchmarks.", "AI": {"tldr": "FLORA\u662f\u4e00\u79cd\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\u7684\u77e5\u8bc6\u56fe\u8c31\u5bf9\u9f50\u65b9\u6cd5\uff0c\u65e0\u9700\u8bad\u7ec3\u6570\u636e\uff0c\u53ef\u540c\u65f6\u5bf9\u9f50\u5b9e\u4f53\u548c\u5173\u7cfb\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u7ed3\u679c\uff0c\u5e76\u5728\u4e3b\u8981\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u5bf9\u9f50\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5b9e\u4f53\u7ea7\u5bf9\u9f50\uff0c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u63a8\u7406\u4e14\u9700\u8981\u8bad\u7ec3\u6570\u636e\u3002FLORA\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u4f9b\u65e0\u76d1\u7763\u3001\u53ef\u89e3\u91ca\u7684\u5168\u9762\u5bf9\u9f50\u65b9\u6848\u3002", "method": "FLORA\u57fa\u4e8e\u6a21\u7cca\u903b\u8f91\uff0c\u901a\u8fc7\u8fed\u4ee3\u65b9\u5f0f\u540c\u65f6\u5bf9\u9f50\u5b9e\u4f53\u548c\u5173\u7cfb\uff0c\u5141\u8bb8\u5b58\u5728\u60ac\u7a7a\u5b9e\u4f53\uff08\u6ca1\u6709\u5bf9\u5e94\u5b9e\u4f53\u7684\u5b9e\u4f53\uff09\uff0c\u5e76\u4fdd\u8bc1\u6536\u655b\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e3b\u8981\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "FLORA\u662f\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u77e5\u8bc6\u56fe\u8c31\u5bf9\u9f50\u65b9\u6cd5\uff0c\u5177\u6709\u65e0\u76d1\u7763\u3001\u53ef\u89e3\u91ca\u3001\u5168\u9762\u5bf9\u9f50\u7b49\u4f18\u52bf\uff0c\u4e3a\u77e5\u8bc6\u56fe\u8c31\u5bf9\u9f50\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20106", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20106", "abs": "https://arxiv.org/abs/2510.20106", "authors": ["Amartya Roy", "Souvik Chakraborty"], "title": "Competition is the key: A Game Theoretic Causal Discovery Approach", "comment": null, "summary": "Causal discovery remains a central challenge in machine learning, yet\nexisting methods face a fundamental gap: algorithms like GES and GraN-DAG\nachieve strong empirical performance but lack finite-sample guarantees, while\ntheoretically principled approaches fail to scale. We close this gap by\nintroducing a game-theoretic reinforcement learning framework for causal\ndiscovery, where a DDQN agent directly competes against a strong baseline (GES\nor GraN-DAG), always warm-starting from the opponent's solution. This design\nyields three provable guarantees: the learned graph is never worse than the\nopponent, warm-starting strictly accelerates convergence, and most importantly,\nwith high probability the algorithm selects the true best candidate graph. To\nthe best of our knowledge, our result makes a first-of-its-kind progress in\nexplaining such finite-sample guarantees in causal discovery: on synthetic SEMs\n(30 nodes), the observed error probability decays with n, tightly matching\ntheory. On real-world benchmarks including Sachs, Asia, Alarm, Child, Hepar2,\nDream, and Andes, our method consistently improves upon GES and GraN-DAG while\nremaining theoretically safe. Remarkably, it scales to large graphs such as\nHepar2 (70 nodes), Dream (100 nodes), and Andes (220 nodes). Together, these\nresults establish a new class of RL-based causal discovery algorithms that are\nsimultaneously provably consistent, sample-efficient, and practically scalable,\nmarking a decisive step toward unifying empirical performance with rigorous\nfinite-sample theory.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u535a\u5f08\u8bba\u5f3a\u5316\u5b66\u4e60\u7684\u56e0\u679c\u53d1\u73b0\u6846\u67b6\uff0c\u901a\u8fc7DDQN\u667a\u80fd\u4f53\u4e0e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff08GES\u6216GraN-DAG\uff09\u7ade\u4e89\uff0c\u5b9e\u73b0\u7406\u8bba\u4fdd\u8bc1\u4e0e\u53ef\u6269\u5c55\u6027\u7684\u7edf\u4e00\u3002", "motivation": "\u89e3\u51b3\u56e0\u679c\u53d1\u73b0\u9886\u57df\u5b58\u5728\u7684\u6838\u5fc3\u77db\u76fe\uff1a\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u6709\u5f3a\u5b9e\u8bc1\u6027\u80fd\u4f46\u7f3a\u4e4f\u6709\u9650\u6837\u672c\u4fdd\u8bc1\uff0c\u8981\u4e48\u6709\u7406\u8bba\u4fdd\u8bc1\u4f46\u65e0\u6cd5\u6269\u5c55\u5230\u5927\u89c4\u6a21\u95ee\u9898\u3002", "method": "\u4f7f\u7528DDQN\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u76f4\u63a5\u4e0eGES\u6216GraN-DAG\u7b49\u57fa\u7ebf\u65b9\u6cd5\u7ade\u4e89\uff0c\u603b\u662f\u4ece\u5bf9\u624b\u7684\u89e3\u8fdb\u884c\u70ed\u542f\u52a8\uff0c\u6784\u5efa\u535a\u5f08\u8bba\u6846\u67b6\u3002", "result": "\u5728\u5408\u6210SEM\uff0830\u8282\u70b9\uff09\u4e0a\u89c2\u5bdf\u5230\u7684\u9519\u8bef\u6982\u7387\u968f\u6837\u672c\u91cfn\u8870\u51cf\uff0c\u4e0e\u7406\u8bba\u7d27\u5bc6\u5339\u914d\uff1b\u5728\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6570\u636e\u96c6\uff08Sachs\u3001Asia\u3001Alarm\u7b49\uff09\u4e0a\u6301\u7eed\u6539\u8fdbGES\u548cGraN-DAG\uff0c\u53ef\u6269\u5c55\u5230Hepar2\uff0870\u8282\u70b9\uff09\u3001Dream\uff08100\u8282\u70b9\uff09\u3001Andes\uff08220\u8282\u70b9\uff09\u7b49\u5927\u89c4\u6a21\u56fe\u3002", "conclusion": "\u5efa\u7acb\u4e86\u4e00\u7c7b\u65b0\u7684\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5\uff0c\u540c\u65f6\u5177\u5907\u53ef\u8bc1\u660e\u7684\u4e00\u81f4\u6027\u3001\u6837\u672c\u6548\u7387\u548c\u5b9e\u9645\u53ef\u6269\u5c55\u6027\uff0c\u6807\u5fd7\u7740\u5c06\u5b9e\u8bc1\u6027\u80fd\u4e0e\u4e25\u683c\u6709\u9650\u6837\u672c\u7406\u8bba\u7edf\u4e00\u7684\u5173\u952e\u8fdb\u5c55\u3002"}}
{"id": "2510.20108", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20108", "abs": "https://arxiv.org/abs/2510.20108", "authors": ["Gabriel Y. Arteaga", "Marius Aasan", "Rwiddhi Chakraborty", "Martine Hjelkrem-Tan", "Thalles Silva", "Michael Kampffmeyer", "Ad\u00edn Ram\u00edrez Rivera"], "title": "Why Prototypes Collapse: Diagnosing and Preventing Partial Collapse in Prototypical Self-Supervised Learning", "comment": null, "summary": "Prototypical self-supervised learning methods consistently suffer from\npartial prototype collapse, where multiple prototypes converge to nearly\nidentical representations. This undermines their central purpose -- providing\ndiverse and informative targets to guide encoders toward rich representations\n-- and has led practitioners to over-parameterize prototype sets or add ad-hoc\nregularizers, which mitigate symptoms rather than address the root cause. We\nempirically trace the collapse to the joint optimization of encoders and\nprototypes, which encourages a type of shortcut learning: early in training\nprototypes drift toward redundant representations that minimize loss without\nnecessarily enhancing representation diversity. To break the joint\noptimization, we introduce a fully decoupled training strategy that learns\nprototypes and encoders under separate objectives. Concretely, we model\nprototypes as a Gaussian mixture updated with an online EM-style procedure,\nindependent of the encoder's loss. This simple yet principled decoupling\neliminates prototype collapse without explicit regularization and yields\nconsistently diverse prototypes and stronger downstream performance.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u89e3\u8026\u7684\u8bad\u7ec3\u7b56\u7565\u6765\u89e3\u51b3\u539f\u578b\u81ea\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u539f\u578b\u5d29\u6e83\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u539f\u578b\u548c\u7f16\u7801\u5668\u7684\u5b66\u4e60\u5206\u79bb\uff0c\u4f7f\u7528\u5728\u7ebfEM\u98ce\u683c\u8fc7\u7a0b\u66f4\u65b0\u539f\u578b\uff0c\u4ece\u800c\u6d88\u9664\u539f\u578b\u5d29\u6e83\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u539f\u578b\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u666e\u904d\u5b58\u5728\u90e8\u5206\u539f\u578b\u5d29\u6e83\u95ee\u9898\uff0c\u5373\u591a\u4e2a\u539f\u578b\u6536\u655b\u5230\u51e0\u4e4e\u76f8\u540c\u7684\u8868\u793a\uff0c\u8fd9\u524a\u5f31\u4e86\u63d0\u4f9b\u591a\u6837\u5316\u548c\u4fe1\u606f\u4e30\u5bcc\u76ee\u6807\u7684\u6838\u5fc3\u76ee\u7684\u3002\u5f53\u524d\u65b9\u6cd5\u901a\u5e38\u901a\u8fc7\u8fc7\u5ea6\u53c2\u6570\u5316\u539f\u578b\u96c6\u6216\u6dfb\u52a0\u4e34\u65f6\u6b63\u5219\u5316\u6765\u7f13\u89e3\u75c7\u72b6\uff0c\u800c\u975e\u89e3\u51b3\u6839\u672c\u539f\u56e0\u3002", "method": "\u5f15\u5165\u5b8c\u5168\u89e3\u8026\u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u5c06\u539f\u578b\u548c\u7f16\u7801\u5668\u7684\u5b66\u4e60\u5206\u79bb\u3002\u5177\u4f53\u800c\u8a00\uff0c\u5c06\u539f\u578b\u5efa\u6a21\u4e3a\u9ad8\u65af\u6df7\u5408\u6a21\u578b\uff0c\u4f7f\u7528\u5728\u7ebfEM\u98ce\u683c\u8fc7\u7a0b\u72ec\u7acb\u4e8e\u7f16\u7801\u5668\u635f\u5931\u8fdb\u884c\u66f4\u65b0\u3002", "result": "\u8fd9\u79cd\u7b80\u5355\u800c\u539f\u5219\u6027\u7684\u89e3\u8026\u65b9\u6cd5\u65e0\u9700\u663e\u5f0f\u6b63\u5219\u5316\u5373\u53ef\u6d88\u9664\u539f\u578b\u5d29\u6e83\uff0c\u4ea7\u751f\u6301\u7eed\u591a\u6837\u5316\u7684\u539f\u578b\u548c\u66f4\u5f3a\u7684\u4e0b\u6e38\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u6253\u7834\u539f\u578b\u548c\u7f16\u7801\u5668\u7684\u8054\u5408\u4f18\u5316\uff0c\u89e3\u51b3\u4e86\u539f\u578b\u5d29\u6e83\u7684\u6839\u672c\u539f\u56e0\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u6709\u6548\u7684\u539f\u578b\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2510.20157", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.20157", "abs": "https://arxiv.org/abs/2510.20157", "authors": ["Xiaoming Wu", "Teng Liu", "Xin Wang", "Ming Yang", "Jiguo Yu"], "title": "ADP-VRSGP: Decentralized Learning with Adaptive Differential Privacy via Variance-Reduced Stochastic Gradient Push", "comment": null, "summary": "Differential privacy is widely employed in decentralized learning to\nsafeguard sensitive data by introducing noise into model updates. However,\nexisting approaches that use fixed-variance noise often degrade model\nperformance and reduce training efficiency. To address these limitations, we\npropose a novel approach called decentralized learning with adaptive\ndifferential privacy via variance-reduced stochastic gradient push (ADP-VRSGP).\nThis method dynamically adjusts both the noise variance and the learning rate\nusing a stepwise-decaying schedule, which accelerates training and enhances\nfinal model performance while providing node-level personalized privacy\nguarantees. To counteract the slowed convergence caused by large-variance noise\nin early iterations, we introduce a progressive gradient fusion strategy that\nleverages historical gradients. Furthermore, ADP-VRSGP incorporates\ndecentralized push-sum and aggregation techniques, making it particularly\nsuitable for time-varying communication topologies. Through rigorous\ntheoretical analysis, we demonstrate that ADP-VRSGP achieves robust convergence\nwith an appropriate learning rate, significantly improving training stability\nand speed. Experimental results validate that our method outperforms existing\nbaselines across multiple scenarios, highlighting its efficacy in addressing\nthe challenges of privacy-preserving decentralized learning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aADP-VRSGP\u7684\u81ea\u9002\u5e94\u5dee\u5206\u9690\u79c1\u53bb\u4e2d\u5fc3\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u566a\u58f0\u65b9\u5dee\u548c\u5b66\u4e60\u7387\uff0c\u7ed3\u5408\u6e10\u8fdb\u68af\u5ea6\u878d\u5408\u7b56\u7565\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u4f7f\u7528\u56fa\u5b9a\u65b9\u5dee\u566a\u58f0\u7684\u5dee\u5206\u9690\u79c1\u65b9\u6cd5\u4f1a\u964d\u4f4e\u6a21\u578b\u6027\u80fd\u548c\u8bad\u7ec3\u6548\u7387\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u52a8\u6001\u8c03\u6574\u9690\u79c1\u4fdd\u62a4\u5f3a\u5ea6\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u6b65\u8fdb\u8870\u51cf\u8c03\u5ea6\u52a8\u6001\u8c03\u6574\u566a\u58f0\u65b9\u5dee\u548c\u5b66\u4e60\u7387\uff0c\u5f15\u5165\u6e10\u8fdb\u68af\u5ea6\u878d\u5408\u7b56\u7565\u5229\u7528\u5386\u53f2\u68af\u5ea6\uff0c\u7ed3\u5408\u53bb\u4e2d\u5fc3\u5316push-sum\u548c\u805a\u5408\u6280\u672f\uff0c\u9002\u7528\u4e8e\u65f6\u53d8\u901a\u4fe1\u62d3\u6251\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660eADP-VRSGP\u5728\u9002\u5f53\u5b66\u4e60\u7387\u4e0b\u5b9e\u73b0\u9c81\u68d2\u6536\u655b\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u591a\u79cd\u573a\u666f\u4e0b\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "ADP-VRSGP\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u9690\u79c1\u4fdd\u62a4\u53bb\u4e2d\u5fc3\u5316\u5b66\u4e60\u4e2d\u7684\u6311\u6218\uff0c\u5728\u4fdd\u8bc1\u9690\u79c1\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u901f\u5ea6\u3002"}}
{"id": "2510.20187", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20187", "abs": "https://arxiv.org/abs/2510.20187", "authors": ["Dian Yu", "Yulai Zhao", "Kishan Panaganti", "Linfeng Song", "Haitao Mi", "Dong Yu"], "title": "Every Question Has Its Own Value: Reinforcement Learning with Explicit Human Values", "comment": "15 pages, 4 figures", "summary": "We propose Reinforcement Learning with Explicit Human Values (RLEV), a method\nthat aligns Large Language Model (LLM) optimization directly with quantifiable\nhuman value signals. While Reinforcement Learning with Verifiable Rewards\n(RLVR) effectively trains models in objective domains using binary correctness\nrewards, it overlooks that not all tasks are equally significant. RLEV extends\nthis framework by incorporating human-defined value signals directly into the\nreward function. Using exam-style data with explicit ground-truth value labels,\nRLEV consistently outperforms correctness-only baselines across multiple RL\nalgorithms and model scales. Crucially, RLEV policies not only improve\nvalue-weighted accuracy but also learn a value-sensitive termination policy:\nconcise for low-value prompts, thorough for high-value ones. We demonstrate\nthis behavior stems from value-weighted gradient amplification on\nend-of-sequence tokens. Ablation studies confirm the gain is causally linked to\nvalue alignment. RLEV remains robust under noisy value signals, such as\ndifficulty-based labels, demonstrating that optimizing for an explicit utility\nfunction offers a practical path to aligning LLMs with human priorities.", "AI": {"tldr": "RLEV\u65b9\u6cd5\u901a\u8fc7\u5c06\u4eba\u7c7b\u5b9a\u4e49\u7684\u4ef7\u503c\u4fe1\u53f7\u76f4\u63a5\u6574\u5408\u5230\u5956\u52b1\u51fd\u6570\u4e2d\uff0c\u6269\u5c55\u4e86RLVR\u6846\u67b6\uff0c\u4f7fLLM\u4f18\u5316\u4e0e\u53ef\u91cf\u5316\u7684\u4eba\u7c7b\u4ef7\u503c\u4fe1\u53f7\u5bf9\u9f50\u3002", "motivation": "\u867d\u7136RLVR\u5728\u5ba2\u89c2\u9886\u57df\u4f7f\u7528\u4e8c\u5143\u6b63\u786e\u6027\u5956\u52b1\u6709\u6548\u8bad\u7ec3\u6a21\u578b\uff0c\u4f46\u5b83\u5ffd\u7565\u4e86\u5e76\u975e\u6240\u6709\u4efb\u52a1\u90fd\u540c\u7b49\u91cd\u8981\u7684\u95ee\u9898\u3002RLEV\u65e8\u5728\u901a\u8fc7\u76f4\u63a5\u6574\u5408\u4eba\u7c7b\u5b9a\u4e49\u7684\u4ef7\u503c\u4fe1\u53f7\u6765\u89e3\u51b3\u8fd9\u4e00\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528\u5e26\u6709\u660e\u786e\u771f\u5b9e\u4ef7\u503c\u6807\u7b7e\u7684\u8003\u8bd5\u98ce\u683c\u6570\u636e\uff0c\u5c06\u4eba\u7c7b\u5b9a\u4e49\u7684\u4ef7\u503c\u4fe1\u53f7\u76f4\u63a5\u6574\u5408\u5230\u5956\u52b1\u51fd\u6570\u4e2d\u3002\u901a\u8fc7\u4ef7\u503c\u52a0\u6743\u68af\u5ea6\u653e\u5927\u5728\u5e8f\u5217\u7ed3\u675f\u6807\u8bb0\u4e0a\u7684\u673a\u5236\uff0c\u5b9e\u73b0\u4ef7\u503c\u654f\u611f\u7684\u7ec8\u6b62\u7b56\u7565\u3002", "result": "RLEV\u5728\u591a\u4e2aRL\u7b97\u6cd5\u548c\u6a21\u578b\u89c4\u6a21\u4e0a\u6301\u7eed\u4f18\u4e8e\u4ec5\u57fa\u4e8e\u6b63\u786e\u6027\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002RLEV\u7b56\u7565\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u4ef7\u503c\u52a0\u6743\u51c6\u786e\u6027\uff0c\u8fd8\u5b66\u4f1a\u4e86\u4ef7\u503c\u654f\u611f\u7684\u7ec8\u6b62\u7b56\u7565\uff1a\u5bf9\u4f4e\u4ef7\u503c\u63d0\u793a\u7b80\u6d01\uff0c\u5bf9\u9ad8\u4ef7\u503c\u63d0\u793a\u8be6\u5c3d\u3002", "conclusion": "RLEV\u901a\u8fc7\u4f18\u5316\u660e\u786e\u7684\u6548\u7528\u51fd\u6570\uff0c\u4e3a\u5c06LLM\u4e0e\u4eba\u7c7b\u4f18\u5148\u7ea7\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e00\u6761\u5b9e\u7528\u8def\u5f84\uff0c\u5373\u4f7f\u5728\u566a\u58f0\u4ef7\u503c\u4fe1\u53f7\u4e0b\u4e5f\u4fdd\u6301\u7a33\u5065\u3002"}}
{"id": "2510.20200", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20200", "abs": "https://arxiv.org/abs/2510.20200", "authors": ["Max Hopkins", "Russell Impagliazzo", "Christopher Ye"], "title": "Approximate Replicability in Learning", "comment": "51 pages, 1 figure", "summary": "Replicability, introduced by (Impagliazzo et al. STOC '22), is the notion\nthat algorithms should remain stable under a resampling of their inputs (given\naccess to shared randomness). While a strong and interesting notion of\nstability, the cost of replicability can be prohibitive: there is no replicable\nalgorithm, for instance, for tasks as simple as threshold learning (Bun et al.\nSTOC '23). Given such strong impossibility results we ask: under what\napproximate notions of replicability is learning possible?\n  In this work, we propose three natural relaxations of replicability in the\ncontext of PAC learning: (1) Pointwise: the learner must be consistent on any\nfixed input, but not across all inputs simultaneously, (2) Approximate: the\nlearner must output hypotheses that classify most of the distribution\nconsistently, (3) Semi: the algorithm is fully replicable, but may additionally\nuse shared unlabeled samples. In all three cases, for constant replicability\nparameters, we obtain sample-optimal agnostic PAC learners: (1) and (2) are\nachievable for ``free\" using $\\Theta(d/\\alpha^2)$ samples, while (3) requires\n$\\Theta(d^2/\\alpha^2)$ labeled samples.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e09\u79cd\u53ef\u590d\u5236\u6027\u7684\u677e\u5f1b\u6982\u5ff5\uff1a\u70b9\u6001\u53ef\u590d\u5236\u6027\u3001\u8fd1\u4f3c\u53ef\u590d\u5236\u6027\u548c\u534a\u53ef\u590d\u5236\u6027\uff0c\u5e76\u5728\u8fd9\u4e9b\u677e\u5f1b\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u6837\u672c\u6700\u4f18\u7684\u4e0d\u53ef\u77e5PAC\u5b66\u4e60\u3002", "motivation": "\u7531\u4e8e\u5b8c\u5168\u53ef\u590d\u5236\u6027\u5728\u67d0\u4e9b\u7b80\u5355\u4efb\u52a1\uff08\u5982\u9608\u503c\u5b66\u4e60\uff09\u4e2d\u65e0\u6cd5\u5b9e\u73b0\uff0c\u4f5c\u8005\u63a2\u7d22\u5728\u4f55\u79cd\u8fd1\u4f3c\u53ef\u590d\u5236\u6027\u6982\u5ff5\u4e0b\u5b66\u4e60\u662f\u53ef\u884c\u7684\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u53ef\u590d\u5236\u6027\u677e\u5f1b\uff1a(1)\u70b9\u6001\u53ef\u590d\u5236\u6027\uff1a\u5bf9\u56fa\u5b9a\u8f93\u5165\u4fdd\u6301\u4e00\u81f4\u6027\uff1b(2)\u8fd1\u4f3c\u53ef\u590d\u5236\u6027\uff1a\u5bf9\u5927\u90e8\u5206\u5206\u5e03\u8f93\u51fa\u4e00\u81f4\u7684\u5047\u8bbe\uff1b(3)\u534a\u53ef\u590d\u5236\u6027\uff1a\u5b8c\u5168\u53ef\u590d\u5236\u4f46\u53ef\u4f7f\u7528\u5171\u4eab\u65e0\u6807\u7b7e\u6837\u672c\u3002", "result": "\u5728\u5e38\u6570\u53ef\u590d\u5236\u6027\u53c2\u6570\u4e0b\uff0c\u83b7\u5f97\u4e86\u6837\u672c\u6700\u4f18\u7684\u4e0d\u53ef\u77e5PAC\u5b66\u4e60\u5668\uff1a\u524d\u4e24\u79cd\u677e\u5f1b\u4f7f\u7528\u0398(d/\u03b1\u00b2)\u6837\u672c\u5373\u53ef\u5b9e\u73b0\uff0c\u7b2c\u4e09\u79cd\u9700\u8981\u0398(d\u00b2/\u03b1\u00b2)\u6807\u8bb0\u6837\u672c\u3002", "conclusion": "\u901a\u8fc7\u9002\u5f53\u7684\u53ef\u590d\u5236\u6027\u677e\u5f1b\uff0c\u53ef\u4ee5\u5728\u4e0d\u663e\u8457\u589e\u52a0\u6837\u672c\u590d\u6742\u5ea6\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u7a33\u5b9a\u7684\u5b66\u4e60\u7b97\u6cd5\u3002"}}
{"id": "2510.20209", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20209", "abs": "https://arxiv.org/abs/2510.20209", "authors": ["Shumin Li"], "title": "Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset", "comment": null, "summary": "The development of accessible screening tools for early cancer detection in\ndogs represents a significant challenge in veterinary medicine. Routine\nlaboratory data offer a promising, low-cost source for such tools, but their\nutility is hampered by the non-specificity of individual biomarkers and the\nsevere class imbalance inherent in screening populations. This study assesses\nthe feasibility of cancer risk classification using the Golden Retriever\nLifetime Study (GRLS) cohort under real-world constraints, including the\ngrouping of diverse cancer types and the inclusion of post-diagnosis samples. A\ncomprehensive benchmark evaluation was conducted, systematically comparing 126\nanalytical pipelines that comprised various machine learning models, feature\nselection methods, and data balancing techniques. Data were partitioned at the\npatient level to prevent leakage. The optimal model, a Logistic Regression\nclassifier with class weighting and recursive feature elimination, demonstrated\nmoderate ranking ability (AUROC = 0.815; 95% CI: 0.793-0.836) but poor clinical\nclassification performance (F1-score = 0.25, Positive Predictive Value = 0.15).\nWhile a high Negative Predictive Value (0.98) was achieved, insufficient recall\n(0.79) precludes its use as a reliable rule-out test. Interpretability analysis\nwith SHapley Additive exPlanations (SHAP) revealed that predictions were driven\nby non-specific features like age and markers of inflammation and anemia. It is\nconcluded that while a statistically detectable cancer signal exists in routine\nlab data, it is too weak and confounded for clinically reliable discrimination\nfrom normal aging or other inflammatory conditions. This work establishes a\ncritical performance ceiling for this data modality in isolation and\nunderscores that meaningful progress in computational veterinary oncology will\nrequire integration of multi-modal data sources.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u4f7f\u7528\u91d1\u6bdb\u730e\u72ac\u5bff\u547d\u7814\u7a76\u961f\u5217\u7684\u5e38\u89c4\u5b9e\u9a8c\u5ba4\u6570\u636e\u8fdb\u884c\u764c\u75c7\u98ce\u9669\u5206\u7c7b\u7684\u53ef\u884c\u6027\uff0c\u53d1\u73b0\u867d\u7136\u5b58\u5728\u53ef\u68c0\u6d4b\u7684\u764c\u75c7\u4fe1\u53f7\uff0c\u4f46\u7531\u4e8e\u4fe1\u53f7\u592a\u5f31\u4e14\u4e0e\u6b63\u5e38\u8870\u8001\u6216\u5176\u4ed6\u708e\u75c7\u72b6\u51b5\u6df7\u6dc6\uff0c\u65e0\u6cd5\u5b9e\u73b0\u53ef\u9760\u7684\u4e34\u5e8a\u5206\u7c7b\u3002", "motivation": "\u5f00\u53d1\u7528\u4e8e\u72ac\u7c7b\u65e9\u671f\u764c\u75c7\u68c0\u6d4b\u7684\u65e0\u521b\u7b5b\u67e5\u5de5\u5177\u662f\u517d\u533b\u533b\u5b66\u7684\u91cd\u8981\u6311\u6218\uff0c\u5e38\u89c4\u5b9e\u9a8c\u5ba4\u6570\u636e\u63d0\u4f9b\u4e86\u4f4e\u6210\u672c\u6765\u6e90\uff0c\u4f46\u53d7\u5230\u4e2a\u4f53\u751f\u7269\u6807\u5fd7\u7269\u975e\u7279\u5f02\u6027\u548c\u7b5b\u67e5\u4eba\u7fa4\u4e2d\u4e25\u91cd\u7c7b\u522b\u4e0d\u5e73\u8861\u7684\u9650\u5236\u3002", "method": "\u5728\u771f\u5b9e\u4e16\u754c\u7ea6\u675f\u4e0b\uff0c\u7cfb\u7edf\u6bd4\u8f83\u4e86126\u4e2a\u5206\u6790\u6d41\u7a0b\uff0c\u5305\u62ec\u5404\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3001\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u548c\u6570\u636e\u5e73\u8861\u6280\u672f\uff0c\u4f7f\u7528\u60a3\u8005\u7ea7\u6570\u636e\u5206\u533a\u9632\u6b62\u6cc4\u6f0f\uff0c\u5e76\u91c7\u7528SHAP\u8fdb\u884c\u53ef\u89e3\u91ca\u6027\u5206\u6790\u3002", "result": "\u6700\u4f73\u6a21\u578b\uff08\u903b\u8f91\u56de\u5f52\u5206\u7c7b\u5668\uff09\u663e\u793a\u51fa\u4e2d\u7b49\u6392\u540d\u80fd\u529b\uff08AUROC=0.815\uff09\uff0c\u4f46\u4e34\u5e8a\u5206\u7c7b\u6027\u80fd\u8f83\u5dee\uff08F1\u5206\u6570=0.25\uff0c\u9633\u6027\u9884\u6d4b\u503c=0.15\uff09\uff0c\u9ad8\u9634\u6027\u9884\u6d4b\u503c\uff080.98\uff09\u4f46\u53ec\u56de\u7387\u4e0d\u8db3\uff080.79\uff09\u3002", "conclusion": "\u5e38\u89c4\u5b9e\u9a8c\u5ba4\u6570\u636e\u4e2d\u867d\u7136\u5b58\u5728\u7edf\u8ba1\u4e0a\u53ef\u68c0\u6d4b\u7684\u764c\u75c7\u4fe1\u53f7\uff0c\u4f46\u592a\u5f31\u4e14\u6df7\u6dc6\uff0c\u65e0\u6cd5\u4e0e\u6b63\u5e38\u8870\u8001\u6216\u5176\u4ed6\u708e\u75c7\u72b6\u51b5\u8fdb\u884c\u53ef\u9760\u7684\u4e34\u5e8a\u533a\u5206\uff0c\u9700\u8981\u6574\u5408\u591a\u6a21\u6001\u6570\u636e\u6e90\u624d\u80fd\u53d6\u5f97\u6709\u610f\u4e49\u7684\u8fdb\u5c55\u3002"}}
{"id": "2510.20222", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20222", "abs": "https://arxiv.org/abs/2510.20222", "authors": ["Hao Wang", "Baojun Ma"], "title": "QKCV Attention: Enhancing Time Series Forecasting with Static Categorical Embeddings for Both Lightweight and Pre-trained Foundation Models", "comment": "10 pages, 5 figures", "summary": "In real-world time series forecasting tasks, category information plays a\npivotal role in capturing inherent data patterns. This paper introduces QKCV\n(Query-Key-Category-Value) attention, an extension of the traditional QKV\nframework that incorporates a static categorical embedding C to emphasize\ncategory-specific information. As a versatile plug-in module, QKCV enhances the\nforecasting accuracy of attention-based models (e.g., Vanilla Transformer,\nInformer, PatchTST, TFT) across diverse real-world datasets. Furthermore, QKCV\ndemonstrates remarkable adaptability in fine-tuning univariate time series\nfoundation model by solely updating the static embedding C while preserving\npretrained weights, thereby reducing computational overhead and achieving\nsuperior fine-tuning performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faQKCV\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u4f20\u7edfQKV\u6846\u67b6\u4e2d\u52a0\u5165\u9759\u6001\u7c7b\u522b\u5d4c\u5165C\u6765\u5f3a\u8c03\u7c7b\u522b\u7279\u5b9a\u4fe1\u606f\uff0c\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u6a21\u5757\u63d0\u5347\u591a\u79cd\u6ce8\u610f\u529b\u6a21\u578b\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5e76\u80fd\u5728\u5fae\u8c03\u5355\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u65f6\u4ec5\u66f4\u65b0C\u5d4c\u5165\u800c\u4fdd\u6301\u9884\u8bad\u7ec3\u6743\u91cd\uff0c\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0c\u7c7b\u522b\u4fe1\u606f\u5bf9\u4e8e\u6355\u6349\u5185\u5728\u6570\u636e\u6a21\u5f0f\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u6ce8\u610f\u529b\u673a\u5236\u672a\u80fd\u5145\u5206\u5229\u7528\u6b64\u7c7b\u4fe1\u606f\u3002", "method": "\u63d0\u51faQKCV\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728QKV\u6846\u67b6\u4e2d\u5f15\u5165\u9759\u6001\u7c7b\u522b\u5d4c\u5165C\uff0c\u5f62\u6210Query-Key-Category-Value\u7ed3\u6784\uff0c\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u6a21\u5757\u96c6\u6210\u5230\u591a\u79cd\u6ce8\u610f\u529b\u6a21\u578b\u4e2d\u3002", "result": "QKCV\u663e\u8457\u63d0\u5347\u4e86Vanilla Transformer\u3001Informer\u3001PatchTST\u3001TFT\u7b49\u6ce8\u610f\u529b\u6a21\u578b\u5728\u591a\u6837\u5316\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5e76\u5728\u5fae\u8c03\u5355\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u65f6\u4ec5\u901a\u8fc7\u66f4\u65b0C\u5d4c\u5165\u5c31\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u5fae\u8c03\u6027\u80fd\u3002", "conclusion": "QKCV\u662f\u4e00\u79cd\u6709\u6548\u6574\u5408\u7c7b\u522b\u4fe1\u606f\u7684\u6ce8\u610f\u529b\u673a\u5236\u6269\u5c55\uff0c\u65e2\u80fd\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u53c8\u80fd\u9ad8\u6548\u5fae\u8c03\u57fa\u7840\u6a21\u578b\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.20235", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20235", "abs": "https://arxiv.org/abs/2510.20235", "authors": ["Woohyeon Byeon", "Giseung Park", "Jongseong Chae", "Amir Leshem", "Youngchul Sung"], "title": "Multi-Objective Reinforcement Learning with Max-Min Criterion: A Game-Theoretic Approach", "comment": "Accepted to NeurIPS 2025", "summary": "In this paper, we propose a provably convergent and practical framework for\nmulti-objective reinforcement learning with max-min criterion. From a\ngame-theoretic perspective, we reformulate max-min multi-objective\nreinforcement learning as a two-player zero-sum regularized continuous game and\nintroduce an efficient algorithm based on mirror descent. Our approach\nsimplifies the policy update while ensuring global last-iterate convergence. We\nprovide a comprehensive theoretical analysis on our algorithm, including\niteration complexity under both exact and approximate policy evaluations, as\nwell as sample complexity bounds. To further enhance performance, we modify the\nproposed algorithm with adaptive regularization. Our experiments demonstrate\nthe convergence behavior of the proposed algorithm in tabular settings, and our\nimplementation for deep reinforcement learning significantly outperforms\nprevious baselines in many MORL environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u8bc1\u660e\u6536\u655b\u4e14\u5b9e\u7528\u7684\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u91c7\u7528max-min\u51c6\u5219\uff0c\u901a\u8fc7\u535a\u5f08\u8bba\u89c6\u89d2\u5c06\u5176\u91cd\u6784\u4e3a\u4e24\u4eba\u96f6\u548c\u6b63\u5219\u5316\u8fde\u7eed\u535a\u5f08\uff0c\u5e76\u57fa\u4e8e\u955c\u50cf\u4e0b\u964d\u8bbe\u8ba1\u9ad8\u6548\u7b97\u6cd5\u3002", "motivation": "\u89e3\u51b3\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u4e2dmax-min\u51c6\u5219\u7684\u6536\u655b\u6027\u548c\u5b9e\u7528\u6027\u95ee\u9898\uff0c\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u7684\u540c\u65f6\u63d0\u5347\u7b97\u6cd5\u6027\u80fd\u3002", "method": "\u5c06max-min\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u91cd\u6784\u4e3a\u4e24\u4eba\u96f6\u548c\u6b63\u5219\u5316\u8fde\u7eed\u535a\u5f08\uff0c\u91c7\u7528\u955c\u50cf\u4e0b\u964d\u7b97\u6cd5\u8fdb\u884c\u7b56\u7565\u66f4\u65b0\uff0c\u5e76\u5f15\u5165\u81ea\u9002\u5e94\u6b63\u5219\u5316\u4ee5\u589e\u5f3a\u6027\u80fd\u3002", "result": "\u7b97\u6cd5\u5728\u8868\u683c\u8bbe\u7f6e\u4e2d\u5c55\u793a\u4e86\u6536\u655b\u884c\u4e3a\uff0c\u5728\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u4e2d\u663e\u8457\u4f18\u4e8e\u5148\u524d\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u591a\u4e2aMORL\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u7528\u7b97\u6cd5\uff0c\u5728\u6536\u655b\u6027\u548c\u6027\u80fd\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2510.20264", "categories": ["cs.LG", "I.2.6; I.2.8; I.2.9"], "pdf": "https://arxiv.org/pdf/2510.20264", "abs": "https://arxiv.org/abs/2510.20264", "authors": ["Thomas Rupf", "Marco Bagatella", "Marin Vlastelica", "Andreas Krause"], "title": "Optimistic Task Inference for Behavior Foundation Models", "comment": null, "summary": "Behavior Foundation Models (BFMs) are capable of retrieving high-performing\npolicy for any reward function specified directly at test-time, commonly\nreferred to as zero-shot reinforcement learning (RL). While this is a very\nefficient process in terms of compute, it can be less so in terms of data: as a\nstandard assumption, BFMs require computing rewards over a non-negligible\ninference dataset, assuming either access to a functional form of rewards, or\nsignificant labeling efforts. To alleviate these limitations, we tackle the\nproblem of task inference purely through interaction with the environment at\ntest-time. We propose OpTI-BFM, an optimistic decision criterion that directly\nmodels uncertainty over reward functions and guides BFMs in data collection for\ntask inference. Formally, we provide a regret bound for well-trained BFMs\nthrough a direct connection to upper-confidence algorithms for linear bandits.\nEmpirically, we evaluate OpTI-BFM on established zero-shot benchmarks, and\nobserve that it enables successor-features-based BFMs to identify and optimize\nan unseen reward function in a handful of episodes with minimal compute\noverhead. Code is available at https://github.com/ThomasRupf/opti-bfm.", "AI": {"tldr": "OpTI-BFM\u662f\u4e00\u79cd\u4e50\u89c2\u51b3\u7b56\u6807\u51c6\uff0c\u901a\u8fc7\u76f4\u63a5\u5efa\u6a21\u5956\u52b1\u51fd\u6570\u7684\u4e0d\u786e\u5b9a\u6027\u6765\u6307\u5bfc\u884c\u4e3a\u57fa\u7840\u6a21\u578b\u5728\u6d4b\u8bd5\u65f6\u8fdb\u884c\u4efb\u52a1\u63a8\u65ad\uff0c\u51cf\u5c11\u4e86\u5bf9\u9884\u8ba1\u7b97\u5956\u52b1\u6570\u636e\u7684\u9700\u6c42\u3002", "motivation": "\u4f20\u7edf\u884c\u4e3a\u57fa\u7840\u6a21\u578b\u9700\u8981\u8ba1\u7b97\u5927\u91cf\u63a8\u7406\u6570\u636e\u96c6\u7684\u5956\u52b1\uff0c\u8fd9\u9700\u8981\u8bbf\u95ee\u5956\u52b1\u51fd\u6570\u7684\u5f62\u5f0f\u6216\u5927\u91cf\u6807\u6ce8\u5de5\u4f5c\u3002\u4e3a\u4e86\u7f13\u89e3\u8fd9\u4e9b\u9650\u5236\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u4e0e\u73af\u5883\u4ea4\u4e92\u6765\u7eaf\u7cb9\u8fdb\u884c\u4efb\u52a1\u63a8\u65ad\u3002", "method": "\u63d0\u51faOpTI-BFM\u4e50\u89c2\u51b3\u7b56\u6807\u51c6\uff0c\u76f4\u63a5\u5efa\u6a21\u5956\u52b1\u51fd\u6570\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u6307\u5bfc\u884c\u4e3a\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u6570\u636e\u6536\u96c6\u4ee5\u8fdb\u884c\u4efb\u52a1\u63a8\u65ad\u3002\u8be5\u65b9\u6cd5\u4e0e\u7ebf\u6027bandits\u7684\u4e0a\u7f6e\u4fe1\u754c\u7b97\u6cd5\u6709\u76f4\u63a5\u8054\u7cfb\u3002", "result": "\u5728\u5df2\u5efa\u7acb\u7684\u96f6\u6837\u672c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cOpTI-BFM\u4f7f\u57fa\u4e8e\u540e\u7ee7\u7279\u5f81\u7684\u884c\u4e3a\u57fa\u7840\u6a21\u578b\u80fd\u591f\u5728\u5c11\u91cfepisode\u4e2d\u8bc6\u522b\u548c\u4f18\u5316\u672a\u89c1\u8fc7\u7684\u5956\u52b1\u51fd\u6570\uff0c\u4e14\u8ba1\u7b97\u5f00\u9500\u6700\u5c0f\u3002", "conclusion": "OpTI-BFM\u4e3a\u884c\u4e3a\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u4efb\u52a1\u63a8\u65ad\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e50\u89c2\u51b3\u7b56\u6807\u51c6\u51cf\u5c11\u4e86\u5bf9\u9884\u8ba1\u7b97\u5956\u52b1\u6570\u636e\u7684\u9700\u6c42\uff0c\u5728\u5c11\u91cf\u4ea4\u4e92\u4e2d\u5b9e\u73b0\u9ad8\u6027\u80fd\u7b56\u7565\u68c0\u7d22\u3002"}}
{"id": "2510.20271", "categories": ["cs.LG", "I.2.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2510.20271", "abs": "https://arxiv.org/abs/2510.20271", "authors": ["Udit Saxena"], "title": "Scalable GPU-Accelerated Euler Characteristic Curves: Optimization and Differentiable Learning for PyTorch", "comment": "Extended Abstract: Accepted to the NeurReps 2025 workshop at NeurIPS\n  2025. 4 pages, 3 figures", "summary": "Topological features capture global geometric structure in imaging data, but\npractical adoption in deep learning requires both computational efficiency and\ndifferentiability. We present optimized GPU kernels for the Euler\nCharacteristic Curve (ECC) computation achieving 16-2000\\\"O speedups over prior\nGPU implementations on synthetic grids, and introduce a differentiable PyTorch\nlayer enabling end-to-end learning. Our CUDA kernels, optimized for Ampere GPUs\nuse 128B-coalesced access and hierarchical shared-memory accumulation. Our\nPyTorch layer learns thresholds in a single direction via a Differentiable\nEuler Characteristic Transform-style sigmoid relaxation. We discuss downstream\nrelevance, including applications highlighted by prior ECC work, and outline\nbatching/multi-GPU extensions to broaden adoption.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u6b27\u62c9\u7279\u5f81\u66f2\u7ebf\uff08ECC\uff09\u8ba1\u7b97\u7684\u4f18\u5316GPU\u5185\u6838\uff0c\u5b9e\u73b0\u4e8616-2000\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u5e76\u5f15\u5165\u4e86\u53ef\u5fae\u5206\u7684PyTorch\u5c42\u652f\u6301\u7aef\u5230\u7aef\u5b66\u4e60\u3002", "motivation": "\u62d3\u6251\u7279\u5f81\u80fd\u6355\u6349\u6210\u50cf\u6570\u636e\u4e2d\u7684\u5168\u5c40\u51e0\u4f55\u7ed3\u6784\uff0c\u4f46\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u9700\u8981\u8ba1\u7b97\u6548\u7387\u548c\u53ef\u5fae\u5206\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u9488\u5bf9Ampere GPU\u4f18\u5316\u7684CUDA\u5185\u6838\uff0c\u4f7f\u7528128B\u5408\u5e76\u8bbf\u95ee\u548c\u5206\u5c42\u5171\u4eab\u5185\u5b58\u7d2f\u52a0\uff1b\u521b\u5efa\u4e86\u53ef\u5fae\u5206PyTorch\u5c42\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u6b27\u62c9\u7279\u5f81\u53d8\u6362\u98ce\u683c\u7684sigmoid\u677e\u5f1b\u5b66\u4e60\u5355\u65b9\u5411\u9608\u503c\u3002", "result": "\u5728\u5408\u6210\u7f51\u683c\u4e0a\u76f8\u6bd4\u4e4b\u524d\u7684GPU\u5b9e\u73b0\u5b9e\u73b0\u4e8616-2000\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u5e76\u6210\u529f\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u5b66\u4e60\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u62d3\u6251\u7279\u5f81\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u63d0\u4f9b\u4e86\u8ba1\u7b97\u9ad8\u6548\u548c\u53ef\u5fae\u5206\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u8ba8\u8bba\u4e86\u6279\u5904\u7406\u548c\u591aGPU\u6269\u5c55\u4ee5\u6269\u5927\u91c7\u7528\u8303\u56f4\u3002"}}
{"id": "2510.20273", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20273", "abs": "https://arxiv.org/abs/2510.20273", "authors": ["Qitai Tan", "Yiyun Chen", "Mo Li", "Ruiwen Gu", "Yilin Su", "Xiao-Ping Zhang"], "title": "SynTSBench: Rethinking Temporal Pattern Learning in Deep Learning Models for Time Series", "comment": "NeurIPS 2025", "summary": "Recent advances in deep learning have driven rapid progress in time series\nforecasting, yet many state-of-the-art models continue to struggle with robust\nperformance in real-world applications, even when they achieve strong results\non standard benchmark datasets. This persistent gap can be attributed to the\nblack-box nature of deep learning architectures and the inherent limitations of\ncurrent evaluation frameworks, which frequently lack the capacity to provide\nclear, quantitative insights into the specific strengths and weaknesses of\ndifferent models, thereby complicating the selection of appropriate models for\nparticular forecasting scenarios. To address these issues, we propose a\nsynthetic data-driven evaluation paradigm, SynTSBench, that systematically\nassesses fundamental modeling capabilities of time series forecasting models\nthrough programmable feature configuration. Our framework isolates confounding\nfactors and establishes an interpretable evaluation system with three core\nanalytical dimensions: (1) temporal feature decomposition and capability\nmapping, which enables systematic evaluation of model capacities to learn\nspecific pattern types; (2) robustness analysis under data irregularities,\nwhich quantifies noise tolerance thresholds and anomaly recovery capabilities;\nand (3) theoretical optimum benchmarking, which establishes performance\nboundaries for each pattern type-enabling direct comparison between model\npredictions and mathematical optima. Our experiments show that current deep\nlearning models do not universally approach optimal baselines across all types\nof temporal features.The code is available at\nhttps://github.com/TanQitai/SynTSBench", "AI": {"tldr": "\u63d0\u51fa\u4e86SynTSBench\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u7f16\u7a0b\u7279\u5f81\u914d\u7f6e\u7cfb\u7edf\u8bc4\u4f30\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u7684\u57fa\u672c\u5efa\u6a21\u80fd\u529b\uff0c\u5305\u62ec\u65f6\u95f4\u7279\u5f81\u5206\u89e3\u3001\u9c81\u68d2\u6027\u5206\u6790\u548c\u7406\u8bba\u6700\u4f18\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u771f\u5b9e\u5e94\u7528\u4e2d\u6027\u80fd\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u4ee5\u53ca\u73b0\u6709\u8bc4\u4f30\u6846\u67b6\u7f3a\u4e4f\u5bf9\u6a21\u578b\u5177\u4f53\u4f18\u7f3a\u70b9\u7684\u5b9a\u91cf\u6d1e\u5bdf\uff0c\u5bfc\u81f4\u96be\u4ee5\u9488\u5bf9\u7279\u5b9a\u9884\u6d4b\u573a\u666f\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u3002", "method": "\u91c7\u7528\u5408\u6210\u6570\u636e\u9a71\u52a8\u7684\u8bc4\u4f30\u8303\u5f0f\uff0c\u901a\u8fc7\u4e09\u4e2a\u6838\u5fc3\u5206\u6790\u7ef4\u5ea6\uff1a\u65f6\u95f4\u7279\u5f81\u5206\u89e3\u4e0e\u80fd\u529b\u6620\u5c04\u3001\u6570\u636e\u4e0d\u89c4\u5219\u6027\u4e0b\u7684\u9c81\u68d2\u6027\u5206\u6790\u3001\u7406\u8bba\u6700\u4f18\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u6240\u6709\u7c7b\u578b\u7684\u65f6\u95f4\u7279\u5f81\u4e0a\u5e76\u672a\u666e\u904d\u63a5\u8fd1\u6700\u4f18\u57fa\u7ebf\u3002", "conclusion": "SynTSBench\u6846\u67b6\u80fd\u591f\u7cfb\u7edf\u8bc4\u4f30\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u7684\u57fa\u672c\u80fd\u529b\uff0c\u4e3a\u6a21\u578b\u9009\u62e9\u63d0\u4f9b\u66f4\u6e05\u6670\u7684\u6307\u5bfc\u3002"}}
{"id": "2510.20278", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20278", "abs": "https://arxiv.org/abs/2510.20278", "authors": ["Guangyu Dai", "Siliang Tang", "Yueting Zhuang"], "title": "KCM: KAN-Based Collaboration Models Enhance Pretrained Large Models", "comment": null, "summary": "In recent years, Pretrained Large Models(PLMs) researchers proposed\nlarge-small model collaboration frameworks, leveraged easily trainable small\nmodels to assist large models, aim to(1) significantly reduce computational\nresource consumption while maintaining comparable accuracy, and (2) enhance\nlarge model performance in specialized domain tasks. However, this\ncollaborative paradigm suffers from issues such as significant accuracy\ndegradation, exacerbated catastrophic forgetting, and amplified hallucination\nproblems induced by small model knowledge. To address these challenges, we\npropose a KAN-based Collaborative Model (KCM) as an improved approach to\nlarge-small model collaboration. The KAN utilized in KCM represents an\nalternative neural network architecture distinct from conventional MLPs.\nCompared to MLPs, KAN offers superior visualizability and interpretability\nwhile mitigating catastrophic forgetting. We deployed KCM in large-small model\ncollaborative systems across three scenarios: language, vision, and\nvision-language cross-modal tasks. The experimental results demonstrate that,\ncompared with pure large model approaches, the large-small model collaboration\nframework utilizing KCM as the collaborative model significantly reduces the\nnumber of large model inference calls while maintaining near-identical task\naccuracy, thereby substantially lowering computational resource consumption.\nConcurrently, the KAN-based small collaborative model markedly mitigates\ncatastrophic forgetting, leading to significant accuracy improvements for\nlong-tail data. The results reveal that KCM demonstrates superior performance\nacross all metrics compared to MLP-based small collaborative models (MCM).", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eKAN\u7684\u534f\u4f5c\u6a21\u578b(KCM)\u6765\u89e3\u51b3\u5927-\u5c0f\u6a21\u578b\u534f\u4f5c\u4e2d\u7684\u7cbe\u5ea6\u4e0b\u964d\u3001\u707e\u96be\u6027\u9057\u5fd8\u548c\u5e7b\u89c9\u95ee\u9898\uff0c\u76f8\u6bd4MLP\u65b9\u6cd5\u5728\u8bed\u8a00\u3001\u89c6\u89c9\u548c\u8de8\u6a21\u6001\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u5927-\u5c0f\u6a21\u578b\u534f\u4f5c\u6846\u67b6\u5b58\u5728\u7684\u7cbe\u5ea6\u663e\u8457\u4e0b\u964d\u3001\u707e\u96be\u6027\u9057\u5fd8\u52a0\u5267\u4ee5\u53ca\u5c0f\u6a21\u578b\u77e5\u8bc6\u5f15\u53d1\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u540c\u65f6\u964d\u4f4e\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u3002", "method": "\u4f7f\u7528KAN\uff08Kolmogorov-Arnold Networks\uff09\u4f5c\u4e3a\u534f\u4f5c\u6a21\u578b\u67b6\u6784\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684MLP\uff0c\u5229\u7528KAN\u66f4\u597d\u7684\u53ef\u89c6\u5316\u548c\u53ef\u89e3\u91ca\u6027\u7279\u6027\uff0c\u5728\u5927-\u5c0f\u6a21\u578b\u534f\u4f5c\u7cfb\u7edf\u4e2d\u90e8\u7f72\u4e8e\u8bed\u8a00\u3001\u89c6\u89c9\u548c\u89c6\u89c9-\u8bed\u8a00\u8de8\u6a21\u6001\u4efb\u52a1\u3002", "result": "\u76f8\u6bd4\u7eaf\u5927\u6a21\u578b\u65b9\u6cd5\uff0c\u4f7f\u7528KCM\u4f5c\u4e3a\u534f\u4f5c\u6a21\u578b\u7684\u5927-\u5c0f\u6a21\u578b\u534f\u4f5c\u6846\u67b6\u663e\u8457\u51cf\u5c11\u4e86\u5927\u6a21\u578b\u63a8\u7406\u8c03\u7528\u6b21\u6570\uff0c\u540c\u65f6\u4fdd\u6301\u8fd1\u4e4e\u76f8\u540c\u7684\u4efb\u52a1\u7cbe\u5ea6\uff1bKAN\u57fa\u7840\u7684\u5c0f\u534f\u4f5c\u6a21\u578b\u663e\u8457\u7f13\u89e3\u4e86\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5bf9\u957f\u5c3e\u6570\u636e\u5e26\u6765\u663e\u8457\u7cbe\u5ea6\u63d0\u5347\uff1b\u5728\u6240\u6709\u6307\u6807\u4e0a\u4f18\u4e8e\u57fa\u4e8eMLP\u7684\u5c0f\u534f\u4f5c\u6a21\u578b(MCM)\u3002", "conclusion": "KCM\u5728\u5927-\u5c0f\u6a21\u578b\u534f\u4f5c\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u65e2\u80fd\u6709\u6548\u964d\u4f4e\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\uff0c\u53c8\u80fd\u7f13\u89e3\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\uff0c\u5728\u591a\u79cd\u4efb\u52a1\u573a\u666f\u4e0b\u5747\u4f18\u4e8e\u4f20\u7edfMLP\u65b9\u6cd5\u3002"}}
{"id": "2510.20327", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20327", "abs": "https://arxiv.org/abs/2510.20327", "authors": ["Fengyuan Yu", "Yuyuan Li", "Xiaohua Feng", "Junjie Fang", "Tao Wang", "Chaochao Chen"], "title": "LEGO: A Lightweight and Efficient Multiple-Attribute Unlearning Framework for Recommender Systems", "comment": "Accepted by ACM Multimedia 2025", "summary": "With the growing demand for safeguarding sensitive user information in\nrecommender systems, recommendation attribute unlearning is receiving\nincreasing attention. Existing studies predominantly focus on single-attribute\nunlearning. However, privacy protection requirements in the real world often\ninvolve multiple sensitive attributes and are dynamic. Existing\nsingle-attribute unlearning methods cannot meet these real-world requirements\ndue to i) CH1: the inability to handle multiple unlearning requests\nsimultaneously, and ii) CH2: the lack of efficient adaptability to dynamic\nunlearning needs. To address these challenges, we propose LEGO, a lightweight\nand efficient multiple-attribute unlearning framework. Specifically, we divide\nthe multiple-attribute unlearning process into two steps: i) Embedding\nCalibration removes information related to a specific attribute from user\nembedding, and ii) Flexible Combination combines these embeddings into a single\nembedding, protecting all sensitive attributes. We frame the unlearning process\nas a mutual information minimization problem, providing LEGO a theoretical\nguarantee of simultaneous unlearning, thereby addressing CH1. With the two-step\nframework, where Embedding Calibration can be performed in parallel and\nFlexible Combination is flexible and efficient, we address CH2. Extensive\nexperiments on three real-world datasets across three representative\nrecommendation models demonstrate the effectiveness and efficiency of our\nproposed framework. Our code and appendix are available at\nhttps://github.com/anonymifish/lego-rec-multiple-attribute-unlearning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLEGO\u6846\u67b6\uff0c\u7528\u4e8e\u63a8\u8350\u7cfb\u7edf\u4e2d\u591a\u5c5e\u6027\u9057\u5fd8\uff0c\u89e3\u51b3\u73b0\u6709\u5355\u5c5e\u6027\u9057\u5fd8\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u5904\u7406\u591a\u4e2a\u9057\u5fd8\u8bf7\u6c42\u548c\u7f3a\u4e4f\u52a8\u6001\u9002\u5e94\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u63a8\u8350\u7cfb\u7edf\u4e2d\u4fdd\u62a4\u7528\u6237\u654f\u611f\u4fe1\u606f\u9700\u6c42\u7684\u589e\u957f\uff0c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5355\u5c5e\u6027\u9057\u5fd8\uff0c\u4f46\u73b0\u5b9e\u4e16\u754c\u7684\u9690\u79c1\u4fdd\u62a4\u9700\u6c42\u5f80\u5f80\u6d89\u53ca\u591a\u4e2a\u654f\u611f\u5c5e\u6027\u4e14\u5177\u6709\u52a8\u6001\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6ee1\u8db3\u8fd9\u4e9b\u9700\u6c42\u3002", "method": "\u63d0\u51faLEGO\u6846\u67b6\uff0c\u5c06\u591a\u5c5e\u6027\u9057\u5fd8\u8fc7\u7a0b\u5206\u4e3a\u4e24\u4e2a\u6b65\u9aa4\uff1a\u5d4c\u5165\u6821\u51c6\uff08\u4ece\u7528\u6237\u5d4c\u5165\u4e2d\u79fb\u9664\u7279\u5b9a\u5c5e\u6027\u4fe1\u606f\uff09\u548c\u7075\u6d3b\u7ec4\u5408\uff08\u5c06\u8fd9\u4e9b\u5d4c\u5165\u7ec4\u5408\u6210\u5355\u4e00\u5d4c\u5165\u4ee5\u4fdd\u62a4\u6240\u6709\u654f\u611f\u5c5e\u6027\uff09\uff0c\u5e76\u5c06\u9057\u5fd8\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u4e92\u4fe1\u606f\u6700\u5c0f\u5316\u95ee\u9898\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u548c\u4e09\u4e2a\u4ee3\u8868\u6027\u63a8\u8350\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86\u6240\u63d0\u6846\u67b6\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "conclusion": "LEGO\u6846\u67b6\u901a\u8fc7\u4e24\u6b65\u9aa4\u8bbe\u8ba1\u89e3\u51b3\u4e86\u591a\u5c5e\u6027\u9057\u5fd8\u7684\u6311\u6218\uff0c\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2510.20387", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20387", "abs": "https://arxiv.org/abs/2510.20387", "authors": ["Baoqing Yue", "Jinyuan Zhou", "Zixi Wei", "Jingtao Zhan", "Qingyao Ai", "Yiqun Liu"], "title": "Relative-Based Scaling Law for Neural Language Models", "comment": null, "summary": "Scaling laws aim to accurately predict model performance across different\nscales. Existing scaling-law studies almost exclusively rely on cross-entropy\nas the evaluation metric. However, cross-entropy provides only a partial view\nof performance: it measures the absolute probability assigned to the correct\ntoken, but ignores the relative ordering between correct and incorrect tokens.\nYet, relative ordering is crucial for language models, such as in\ngreedy-sampling scenario. To address this limitation, we investigate scaling\nfrom the perspective of relative ordering. We first propose the Relative-Based\nProbability (RBP) metric, which quantifies the probability that the correct\ntoken is ranked among the top predictions. Building on this metric, we\nestablish the Relative-Based Scaling Law, which characterizes how RBP improves\nwith increasing model size. Through extensive experiments on four datasets and\nfour model families spanning five orders of magnitude, we demonstrate the\nrobustness and accuracy of this law. Finally, we illustrate the broad\napplication of this law with two examples, namely providing a deeper\nexplanation of emergence phenomena and facilitating finding fundamental\ntheories of scaling laws. In summary, the Relative-Based Scaling Law\ncomplements the cross-entropy perspective and contributes to a more complete\nunderstanding of scaling large language models. Thus, it offers valuable\ninsights for both practical development and theoretical exploration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u76f8\u5bf9\u6392\u5e8f\u7684\u7f29\u653e\u5b9a\u5f8b\uff0c\u901a\u8fc7\u5f15\u5165\u76f8\u5bf9\u6982\u7387\u6307\u6807\u6765\u8865\u5145\u4f20\u7edf\u7684\u4ea4\u53c9\u71b5\u6307\u6807\uff0c\u4ece\u76f8\u5bf9\u6392\u5e8f\u89d2\u5ea6\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u7684\u7f29\u653e\u89c4\u5f8b\u3002", "motivation": "\u73b0\u6709\u7f29\u653e\u5b9a\u5f8b\u7814\u7a76\u4e3b\u8981\u4f9d\u8d56\u4ea4\u53c9\u71b5\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\uff0c\u4f46\u4ea4\u53c9\u71b5\u53ea\u5173\u6ce8\u6b63\u786etoken\u7684\u7edd\u5bf9\u6982\u7387\uff0c\u5ffd\u7565\u4e86\u6b63\u786e\u4e0e\u9519\u8beftoken\u4e4b\u95f4\u7684\u76f8\u5bf9\u6392\u5e8f\u5173\u7cfb\uff0c\u800c\u76f8\u5bf9\u6392\u5e8f\u5728\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u76f8\u5bf9\u6982\u7387\u6307\u6807(RBP)\uff0c\u91cf\u5316\u6b63\u786etoken\u5728top\u9884\u6d4b\u4e2d\u7684\u6392\u540d\u6982\u7387\uff0c\u5e76\u57fa\u4e8e\u6b64\u5efa\u7acb\u4e86\u76f8\u5bf9\u7f29\u653e\u5b9a\u5f8b\uff0c\u901a\u8fc7\u56db\u4e2a\u6570\u636e\u96c6\u548c\u56db\u4e2a\u6a21\u578b\u5bb6\u65cf\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u5b9a\u5f8b\u7684\u9c81\u68d2\u6027\u548c\u51c6\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u76f8\u5bf9\u7f29\u653e\u5b9a\u5f8b\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u6a21\u578b\u6027\u80fd\u968f\u89c4\u6a21\u589e\u957f\u7684\u53d8\u5316\uff0c\u5e76\u5c55\u793a\u4e86\u8be5\u5b9a\u5f8b\u5728\u89e3\u91ca\u6d8c\u73b0\u73b0\u8c61\u548c\u5bfb\u627e\u7f29\u653e\u5b9a\u5f8b\u57fa\u7840\u7406\u8bba\u65b9\u9762\u7684\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u76f8\u5bf9\u7f29\u653e\u5b9a\u5f8b\u8865\u5145\u4e86\u4ea4\u53c9\u71b5\u89c6\u89d2\uff0c\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u7f29\u653e\u63d0\u4f9b\u4e86\u66f4\u5b8c\u6574\u7684\u7406\u89e3\uff0c\u5bf9\u5b9e\u9645\u5f00\u53d1\u548c\u7406\u8bba\u63a2\u7d22\u90fd\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2510.20302", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20302", "abs": "https://arxiv.org/abs/2510.20302", "authors": ["Yuhang Wang"], "title": "InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling", "comment": "23pages, 3 figures", "summary": "Multivariate time series forecasting requires simultaneously modeling\ntemporal patterns and cross-variate dependencies. Channel-independent methods\nsuch as PatchTST excel at temporal modeling but ignore variable correlations,\nwhile pure variate-attention approaches such as iTransformer sacrifice temporal\nencoding. We proposeInvDec (Inverted Decoder), a hybrid architecture that\nachieves principled separation between temporal encoding and variate-level\ndecoding. InvDec combines a patch-based temporal encoder with an inverted\ndecoder operating on the variate dimension through variate-wise self-attention.\nWe introduce delayed variate embeddings that enrich variable-specific\nrepresentations only after temporal encoding, preserving temporal feature\nintegrity. An adaptive residual fusion mechanism dynamically balances temporal\nand variate information across datasets of varying dimensions. Instantiating\nInvDec with PatchTST yields InvDec-PatchTST. Extensive experiments on seven\nbenchmarks demonstrate significant gains on high-dimensional datasets: 20.9%\nMSE reduction on Electricity (321 variables), 4.3% improvement on Weather, and\n2.7% gain on Traffic compared to PatchTST, while maintaining competitive\nperformance on low-dimensional ETT datasets. Ablation studies validate each\ncomponent, and analysis reveals that InvDec's advantage grows with dataset\ndimensionality, confirming that cross-variate modeling becomes critical as the\nnumber of variables increases.", "AI": {"tldr": "\u63d0\u51faInvDec\u6df7\u5408\u67b6\u6784\uff0c\u901a\u8fc7\u5012\u7f6e\u89e3\u7801\u5668\u5b9e\u73b0\u65f6\u95f4\u7f16\u7801\u548c\u53d8\u91cf\u7ea7\u89e3\u7801\u7684\u5206\u79bb\uff0c\u5728\u4fdd\u6301\u65f6\u95f4\u5efa\u6a21\u80fd\u529b\u7684\u540c\u65f6\u6709\u6548\u5904\u7406\u591a\u53d8\u91cf\u76f8\u5173\u6027\uff0c\u7279\u522b\u5728\u9ad8\u7ef4\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u901a\u9053\u72ec\u7acb\u65b9\u6cd5\u5982PatchTST\u64c5\u957f\u65f6\u95f4\u5efa\u6a21\u4f46\u5ffd\u7565\u53d8\u91cf\u76f8\u5173\u6027\uff0c\u800c\u7eaf\u53d8\u91cf\u6ce8\u610f\u529b\u65b9\u6cd5\u5982iTransformer\u727a\u7272\u4e86\u65f6\u95f4\u7f16\u7801\u80fd\u529b\u3002\u9700\u8981\u4e00\u79cd\u80fd\u540c\u65f6\u5efa\u6a21\u65f6\u95f4\u6a21\u5f0f\u548c\u8de8\u53d8\u91cf\u4f9d\u8d56\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u57fa\u4e8e\u8865\u4e01\u7684\u65f6\u95f4\u7f16\u7801\u5668\u548c\u5728\u53d8\u91cf\u7ef4\u5ea6\u4e0a\u901a\u8fc7\u53d8\u91cf\u81ea\u6ce8\u610f\u529b\u64cd\u4f5c\u7684\u5012\u7f6e\u89e3\u7801\u5668\u3002\u5f15\u5165\u5ef6\u8fdf\u53d8\u91cf\u5d4c\u5165\uff0c\u5728\u65f6\u95f4\u7f16\u7801\u540e\u4e30\u5bcc\u53d8\u91cf\u7279\u5b9a\u8868\u793a\uff1b\u91c7\u7528\u81ea\u9002\u5e94\u6b8b\u5dee\u878d\u5408\u673a\u5236\u52a8\u6001\u5e73\u8861\u65f6\u95f4\u548c\u53d8\u91cf\u4fe1\u606f\u3002", "result": "\u5728\u4e03\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u663e\u793a\uff0c\u5728\u9ad8\u7ef4\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff1a\u7535\u529b\u6570\u636e\u96c6\uff08321\u53d8\u91cf\uff09MSE\u964d\u4f4e20.9%\uff0c\u5929\u6c14\u6570\u636e\u96c6\u63d0\u53474.3%\uff0c\u4ea4\u901a\u6570\u636e\u96c6\u63d0\u53472.7%\uff0c\u540c\u65f6\u5728\u4f4e\u7ef4ETT\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "InvDec\u901a\u8fc7\u5206\u79bb\u65f6\u95f4\u7f16\u7801\u548c\u53d8\u91cf\u7ea7\u89e3\u7801\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5173\u952e\u6311\u6218\u3002\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u5404\u7ec4\u4ef6\u6709\u6548\u6027\uff0c\u5206\u6790\u8868\u660e\u968f\u7740\u6570\u636e\u96c6\u7ef4\u5ea6\u589e\u52a0\uff0c\u8de8\u53d8\u91cf\u5efa\u6a21\u53d8\u5f97\u6108\u53d1\u91cd\u8981\uff0cInvDec\u7684\u4f18\u52bf\u4e5f\u968f\u4e4b\u589e\u957f\u3002"}}
{"id": "2510.20414", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20414", "abs": "https://arxiv.org/abs/2510.20414", "authors": ["Sishun Liu", "Ke Deng", "Xiuzhen Zhang", "Yongli Ren", "Yan Wang"], "title": "Addressing Mark Imbalance in Integration-free Neural Marked Temporal Point Processes", "comment": "NeurIPS 2025 poster", "summary": "Marked Temporal Point Process (MTPP) has been well studied to model the event\ndistribution in marked event streams, which can be used to predict the mark and\narrival time of the next event. However, existing studies overlook that the\ndistribution of event marks is highly imbalanced in many real-world\napplications, with some marks being frequent but others rare. The imbalance\nposes a significant challenge to the performance of the next event prediction,\nespecially for events of rare marks. To address this issue, we propose a\nthresholding method, which learns thresholds to tune the mark probability\nnormalized by the mark's prior probability to optimize mark prediction, rather\nthan predicting the mark directly based on the mark probability as in existing\nstudies. In conjunction with this method, we predict the mark first and then\nthe time. In particular, we develop a novel neural MTPP model to support\neffective time sampling and estimation of mark probability without\ncomputationally expensive numerical improper integration. Extensive experiments\non real-world datasets demonstrate the superior performance of our solution\nagainst various baselines for the next event mark and time prediction. The code\nis available at https://github.com/undes1red/IFNMTPP.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u6807\u8bb0\u65f6\u95f4\u70b9\u8fc7\u7a0b\u4e2d\u4e8b\u4ef6\u6807\u8bb0\u5206\u5e03\u4e0d\u5e73\u8861\u95ee\u9898\u7684\u9608\u503c\u65b9\u6cd5\uff0c\u901a\u8fc7\u8c03\u6574\u6807\u8bb0\u6982\u7387\u6765\u4f18\u5316\u6807\u8bb0\u9884\u6d4b\uff0c\u5e76\u5f00\u53d1\u4e86\u65b0\u7684\u795e\u7ecfMTPP\u6a21\u578b\u6765\u652f\u6301\u6709\u6548\u7684\u65f6\u95f4\u91c7\u6837\u548c\u6807\u8bb0\u6982\u7387\u4f30\u8ba1\u3002", "motivation": "\u73b0\u5b9e\u5e94\u7528\u4e2d\u4e8b\u4ef6\u6807\u8bb0\u5206\u5e03\u9ad8\u5ea6\u4e0d\u5e73\u8861\uff0c\u4e00\u4e9b\u6807\u8bb0\u9891\u7e41\u800c\u5176\u4ed6\u6807\u8bb0\u7f55\u89c1\uff0c\u8fd9\u5bf9\u4e0b\u4e00\u4e2a\u4e8b\u4ef6\u9884\u6d4b\u6027\u80fd\uff08\u7279\u522b\u662f\u7f55\u89c1\u6807\u8bb0\u4e8b\u4ef6\uff09\u6784\u6210\u4e86\u91cd\u5927\u6311\u6218\u3002", "method": "\u63d0\u51fa\u9608\u503c\u65b9\u6cd5\u5b66\u4e60\u9608\u503c\u6765\u8c03\u6574\u7531\u6807\u8bb0\u5148\u9a8c\u6982\u7387\u5f52\u4e00\u5316\u7684\u6807\u8bb0\u6982\u7387\uff0c\u4ee5\u4f18\u5316\u6807\u8bb0\u9884\u6d4b\uff1b\u5f00\u53d1\u65b0\u7684\u795e\u7ecfMTPP\u6a21\u578b\u652f\u6301\u6709\u6548\u65f6\u95f4\u91c7\u6837\u548c\u6807\u8bb0\u6982\u7387\u4f30\u8ba1\uff0c\u65e0\u9700\u8ba1\u7b97\u6602\u8d35\u7684\u6570\u503c\u4e0d\u5f53\u79ef\u5206\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0b\u4e00\u4e2a\u4e8b\u4ef6\u6807\u8bb0\u548c\u65f6\u95f4\u9884\u6d4b\u65b9\u9762\u4f18\u4e8e\u5404\u79cd\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\u901a\u8fc7\u5904\u7406\u6807\u8bb0\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86MTPP\u6a21\u578b\u5728\u4e0b\u4e00\u4e2a\u4e8b\u4ef6\u9884\u6d4b\u4e2d\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u7f55\u89c1\u6807\u8bb0\u4e8b\u4ef6\u4e0a\u3002"}}
{"id": "2510.20477", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20477", "abs": "https://arxiv.org/abs/2510.20477", "authors": ["Rui Zhu", "Song-Lin Lv", "Zi-Kang Wang", "Lan-Zhe Guo"], "title": "Bi-CoG: Bi-Consistency-Guided Self-Training for Vision-Language Models", "comment": null, "summary": "Exploiting unlabeled data through semi-supervised learning (SSL) or\nleveraging pre-trained models via fine-tuning are two prevailing paradigms for\naddressing label-scarce scenarios. Recently, growing attention has been given\nto combining fine-tuning of pre-trained vision-language models (VLMs) with SSL,\nforming the emerging paradigm of semi-supervised fine-tuning. However, existing\nmethods often suffer from model bias and hyperparameter sensitivity, due to\nreliance on prediction consistency or pre-defined confidence thresholds. To\naddress these limitations, we propose a simple yet effective plug-and-play\nmethodology named\n$\\underline{\\textbf{Bi-Co}}$nsistency-$\\underline{\\textbf{G}}$uided\nSelf-Training (Bi-CoG), which assigns high-quality and low-bias pseudo-labels,\nby simultaneously exploiting inter-model and intra-model consistency, along\nwith an error-aware dynamic pseudo-label assignment strategy. Both theoretical\nanalysis and extensive experiments over 14 datasets demonstrate the\neffectiveness of Bi-CoG, which consistently and significantly improves the\nperformance of existing methods.", "AI": {"tldr": "\u63d0\u51faBi-CoG\u65b9\u6cd5\uff0c\u901a\u8fc7\u540c\u65f6\u5229\u7528\u6a21\u578b\u95f4\u548c\u6a21\u578b\u5185\u4e00\u81f4\u6027\u4ee5\u53ca\u9519\u8bef\u611f\u77e5\u52a8\u6001\u4f2a\u6807\u7b7e\u5206\u914d\u7b56\u7565\uff0c\u89e3\u51b3\u534a\u76d1\u7763\u5fae\u8c03\u4e2d\u7684\u6a21\u578b\u504f\u5dee\u548c\u8d85\u53c2\u6570\u654f\u611f\u6027\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u534a\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u5b58\u5728\u6a21\u578b\u504f\u5dee\u548c\u8d85\u53c2\u6570\u654f\u611f\u6027\u95ee\u9898\uff0c\u4e3b\u8981\u4f9d\u8d56\u9884\u6d4b\u4e00\u81f4\u6027\u6216\u9884\u5b9a\u4e49\u7f6e\u4fe1\u5ea6\u9608\u503c\u3002", "method": "\u63d0\u51faBi-CoG\u65b9\u6cd5\uff0c\u5229\u7528\u6a21\u578b\u95f4\u548c\u6a21\u578b\u5185\u4e00\u81f4\u6027\uff0c\u7ed3\u5408\u9519\u8bef\u611f\u77e5\u52a8\u6001\u4f2a\u6807\u7b7e\u5206\u914d\u7b56\u7565\u6765\u5206\u914d\u9ad8\u8d28\u91cf\u3001\u4f4e\u504f\u5dee\u7684\u4f2a\u6807\u7b7e\u3002", "result": "\u572814\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cBi-CoG\u80fd\u6301\u7eed\u663e\u8457\u63d0\u5347\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "Bi-CoG\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u5373\u63d2\u5373\u7528\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u534a\u76d1\u7763\u5fae\u8c03\u4e2d\u7684\u5173\u952e\u95ee\u9898\u3002"}}
{"id": "2510.20800", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20800", "abs": "https://arxiv.org/abs/2510.20800", "authors": ["Shiva Sreeram", "Alaa Maalouf", "Pratyusha Sharma", "Daniela Rus"], "title": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples", "comment": null, "summary": "Recently, Sharma et al. suggested a method called Layer-SElective-Rank\nreduction (LASER) which demonstrated that pruning high-order components of\ncarefully chosen LLM's weight matrices can boost downstream accuracy -- without\nany gradient-based fine-tuning. Yet LASER's exhaustive, per-matrix search (each\nrequiring full-dataset forward passes) makes it impractical for rapid\ndeployment. We demonstrate that this overhead can be removed and find that: (i)\nOnly a small, carefully chosen subset of matrices needs to be inspected --\neliminating the layer-by-layer sweep, (ii) The gradient of each matrix's\nsingular values pinpoints which matrices merit reduction, (iii) Increasing the\nfactorization search space by allowing matrices rows to cluster around multiple\nsubspaces and then decomposing each cluster separately further reduces\noverfitting on the original training data and further lifts accuracy by up to\n24.6 percentage points, and finally, (iv) we discover that evaluating on just\n100 samples rather than the full training data -- both for computing the\nindicative gradients and for measuring the final accuracy -- suffices to\nfurther reduce the search time; we explain that as adaptation to downstream\ntasks is dominated by prompting style, not dataset size. As a result, we show\nthat combining these findings yields a fast and robust adaptation algorithm for\ndownstream tasks. Overall, with a single gradient step on 100 examples and a\nquick scan of the top candidate layers and factorization techniques, we can\nadapt LLMs to new datasets -- entirely without fine-tuning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5feb\u901f\u4e14\u65e0\u9700\u5fae\u8c03\u7684LLM\u9002\u5e94\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u77e9\u9635\u964d\u7ef4\u548c\u68af\u5ea6\u5206\u6790\u6765\u63d0\u5347\u4e0b\u6e38\u4efb\u52a1\u51c6\u786e\u7387\uff0c\u76f8\u6bd4\u4e4b\u524d\u7684LASER\u65b9\u6cd5\u5927\u5e45\u51cf\u5c11\u4e86\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "LASER\u65b9\u6cd5\u867d\u7136\u80fd\u901a\u8fc7\u526a\u679d\u63d0\u5347LLM\u4e0b\u6e38\u4efb\u52a1\u51c6\u786e\u7387\uff0c\u4f46\u5176\u9010\u5c42\u641c\u7d22\u548c\u5168\u6570\u636e\u96c6\u524d\u5411\u4f20\u64ad\u7684\u8ba1\u7b97\u5f00\u9500\u4f7f\u5176\u96be\u4ee5\u5feb\u901f\u90e8\u7f72\u3002\u672c\u6587\u65e8\u5728\u6d88\u9664\u8fd9\u79cd\u5f00\u9500\u3002", "method": "\u4f7f\u7528\u68af\u5ea6\u5206\u6790\u8bc6\u522b\u5173\u952e\u77e9\u9635\uff0c\u4ec5\u68c0\u67e5\u5c11\u91cf\u9009\u5b9a\u77e9\u9635\uff1b\u6269\u5c55\u5206\u89e3\u641c\u7d22\u7a7a\u95f4\uff0c\u5141\u8bb8\u77e9\u9635\u884c\u56f4\u7ed5\u591a\u4e2a\u5b50\u7a7a\u95f4\u805a\u7c7b\uff1b\u4ec5\u4f7f\u7528100\u4e2a\u6837\u672c\u8ba1\u7b97\u68af\u5ea6\u548c\u8bc4\u4f30\u51c6\u786e\u7387\u3002", "result": "\u65b9\u6cd5\u5c06\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe24.6\u4e2a\u767e\u5206\u70b9\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u641c\u7d22\u65f6\u95f4\uff0c\u4ec5\u9700\u5355\u6b21\u68af\u5ea6\u6b65\u548c\u5feb\u901f\u626b\u63cf\u5c31\u80fd\u9002\u5e94\u65b0\u6570\u636e\u96c6\u3002", "conclusion": "\u7ed3\u5408\u8fd9\u4e9b\u53d1\u73b0\u53ef\u5f97\u5230\u5feb\u901f\u7a33\u5065\u7684\u4e0b\u6e38\u4efb\u52a1\u9002\u5e94\u7b97\u6cd5\uff0c\u5b8c\u5168\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u6709\u6548\u9002\u5e94LLM\u5230\u65b0\u6570\u636e\u96c6\u3002"}}
{"id": "2510.20590", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20590", "abs": "https://arxiv.org/abs/2510.20590", "authors": ["Simon Schindler", "Christoph Binder", "Lukas L\u00fcrzer", "Stefan Huber"], "title": "Embedding the MLOps Lifecycle into OT Reference Models", "comment": null, "summary": "Machine Learning Operations (MLOps) practices are increas- ingly adopted in\nindustrial settings, yet their integration with Opera- tional Technology (OT)\nsystems presents significant challenges. This pa- per analyzes the fundamental\nobstacles in combining MLOps with OT en- vironments and proposes a systematic\napproach to embed MLOps prac- tices into established OT reference models. We\nevaluate the suitability of the Reference Architectural Model for Industry 4.0\n(RAMI 4.0) and the International Society of Automation Standard 95 (ISA-95) for\nMLOps integration and present a detailed mapping of MLOps lifecycle compo-\nnents to RAMI 4.0 exemplified by a real-world use case. Our findings\ndemonstrate that while standard MLOps practices cannot be directly transplanted\nto OT environments, structured adaptation using existing reference models can\nprovide a pathway for successful integration.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5c06MLOps\u5b9e\u8df5\u96c6\u6210\u5230\u64cd\u4f5c\u6280\u672f\uff08OT\uff09\u7cfb\u7edf\u4e2d\u7684\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06MLOps\u5d4c\u5165\u5230\u73b0\u6709OT\u53c2\u8003\u6a21\u578b\u4e2d\u7684\u7cfb\u7edf\u65b9\u6cd5\u3002\u901a\u8fc7\u8bc4\u4f30RAMI 4.0\u548cISA-95\u6807\u51c6\u5bf9MLOps\u7684\u9002\u7528\u6027\uff0c\u5e76\u5c55\u793aMLOps\u751f\u547d\u5468\u671f\u7ec4\u4ef6\u5230RAMI 4.0\u7684\u6620\u5c04\uff0c\u8bc1\u660e\u4e86\u7ed3\u6784\u5316\u9002\u914d\u73b0\u6709\u53c2\u8003\u6a21\u578b\u53ef\u4ee5\u5b9e\u73b0\u6210\u529f\u96c6\u6210\u3002", "motivation": "\u968f\u7740MLOps\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u5c06\u5176\u4e0e\u64cd\u4f5c\u6280\u672f\uff08OT\uff09\u7cfb\u7edf\u96c6\u6210\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3MLOps\u4e0eOT\u73af\u5883\u7ed3\u5408\u7684\u57fa\u672c\u969c\u788d\uff0c\u63a2\u7d22\u5982\u4f55\u5c06MLOps\u5b9e\u8df5\u6709\u6548\u5d4c\u5165\u5230\u5df2\u5efa\u7acb\u7684OT\u53c2\u8003\u6a21\u578b\u4e2d\u3002", "method": "\u8bc4\u4f30RAMI 4.0\u548cISA-95\u6807\u51c6\u5bf9MLOps\u96c6\u6210\u7684\u9002\u7528\u6027\uff0c\u63d0\u51fa\u7cfb\u7edf\u5316\u7684MLOps\u96c6\u6210\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u771f\u5b9e\u6848\u4f8b\u5c55\u793aMLOps\u751f\u547d\u5468\u671f\u7ec4\u4ef6\u5230RAMI 4.0\u7684\u8be6\u7ec6\u6620\u5c04\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6807\u51c6MLOps\u5b9e\u8df5\u4e0d\u80fd\u76f4\u63a5\u79fb\u690d\u5230OT\u73af\u5883\u4e2d\uff0c\u4f46\u901a\u8fc7\u4f7f\u7528\u73b0\u6709\u53c2\u8003\u6a21\u578b\u8fdb\u884c\u7ed3\u6784\u5316\u9002\u914d\uff0c\u53ef\u4ee5\u4e3a\u6210\u529f\u96c6\u6210\u63d0\u4f9b\u53ef\u884c\u8def\u5f84\u3002", "conclusion": "\u867d\u7136MLOps\u5b9e\u8df5\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u4e8eOT\u73af\u5883\uff0c\u4f46\u901a\u8fc7\u57fa\u4e8e\u73b0\u6709\u53c2\u8003\u6a21\u578b\uff08\u5982RAMI 4.0\u548cISA-95\uff09\u7684\u7ed3\u6784\u5316\u9002\u914d\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5b9e\u73b0MLOps\u4e0eOT\u7cfb\u7edf\u7684\u6709\u6548\u96c6\u6210\u3002"}}
{"id": "2510.20616", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20616", "abs": "https://arxiv.org/abs/2510.20616", "authors": ["Aki Rehn", "Linzh Zhao", "Mikko A. Heikkil\u00e4", "Antti Honkela"], "title": "On Optimal Hyperparameters for Differentially Private Deep Transfer Learning", "comment": "25 pages, 30 figures", "summary": "Differentially private (DP) transfer learning, i.e., fine-tuning a pretrained\nmodel on private data, is the current state-of-the-art approach for training\nlarge models under privacy constraints. We focus on two key hyperparameters in\nthis setting: the clipping bound $C$ and batch size $B$. We show a clear\nmismatch between the current theoretical understanding of how to choose an\noptimal $C$ (stronger privacy requires smaller $C$) and empirical outcomes\n(larger $C$ performs better under strong privacy), caused by changes in the\ngradient distributions. Assuming a limited compute budget (fixed epochs), we\ndemonstrate that the existing heuristics for tuning $B$ do not work, while\ncumulative DP noise better explains whether smaller or larger batches perform\nbetter. We also highlight how the common practice of using a single $(C,B)$\nsetting across tasks can lead to suboptimal performance. We find that\nperformance drops especially when moving between loose and tight privacy and\nbetween plentiful and limited compute, which we explain by analyzing clipping\nas a form of gradient re-weighting and examining cumulative DP noise.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5dee\u5206\u9690\u79c1\u8fc1\u79fb\u5b66\u4e60\u4e2d\u7684\u4e24\u4e2a\u5173\u952e\u8d85\u53c2\u6570\uff1a\u88c1\u526a\u8fb9\u754cC\u548c\u6279\u6b21\u5927\u5c0fB\u3002\u7814\u7a76\u53d1\u73b0\u7406\u8bba\u6307\u5bfc\u4e0e\u5b9e\u8bc1\u7ed3\u679c\u5b58\u5728\u77db\u76fe\uff0c\u5e76\u63ed\u793a\u4e86\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u5728\u6709\u9650\u8ba1\u7b97\u9884\u7b97\u4e0b\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524d\u5dee\u5206\u9690\u79c1\u8fc1\u79fb\u5b66\u4e60\u5b9e\u8df5\u4e2d\uff0c\u88c1\u526a\u8fb9\u754cC\u548c\u6279\u6b21\u5927\u5c0fB\u7684\u9009\u62e9\u5b58\u5728\u7406\u8bba\u6307\u5bfc\u4e0e\u5b9e\u8bc1\u7ed3\u679c\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u8fd9\u5f71\u54cd\u4e86\u6a21\u578b\u5728\u9690\u79c1\u7ea6\u675f\u4e0b\u7684\u6027\u80fd\u4f18\u5316\u3002", "method": "\u901a\u8fc7\u5206\u6790\u68af\u5ea6\u5206\u5e03\u53d8\u5316\uff0c\u7814\u7a76\u5728\u6709\u9650\u8ba1\u7b97\u9884\u7b97\u4e0b\u88c1\u526a\u8fb9\u754cC\u548c\u6279\u6b21\u5927\u5c0fB\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u63a2\u8ba8\u7d2f\u79efDP\u566a\u58f0\u7684\u4f5c\u7528\u673a\u5236\u3002", "result": "\u53d1\u73b0\u5f3a\u9690\u79c1\u6761\u4ef6\u4e0b\u7406\u8bba\u4e0a\u5e94\u9009\u62e9\u8f83\u5c0fC\uff0c\u4f46\u5b9e\u8bc1\u4e2d\u8f83\u5927C\u8868\u73b0\u66f4\u597d\uff1b\u73b0\u6709\u6279\u6b21\u5927\u5c0f\u8c03\u4f18\u542f\u53d1\u5f0f\u65b9\u6cd5\u5728\u6709\u9650\u8ba1\u7b97\u9884\u7b97\u4e0b\u5931\u6548\uff1b\u8de8\u4efb\u52a1\u4f7f\u7528\u5355\u4e00(C,B)\u8bbe\u7f6e\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\u5dee\u5206\u9690\u79c1\u8fc1\u79fb\u5b66\u4e60\u4e2d\u7684\u8d85\u53c2\u6570\u9009\u62e9\u7b56\u7565\uff0c\u8003\u8651\u68af\u5ea6\u91cd\u52a0\u6743\u548c\u7d2f\u79efDP\u566a\u58f0\u7684\u5f71\u54cd\uff0c\u9488\u5bf9\u4e0d\u540c\u9690\u79c1\u7ea6\u675f\u548c\u8ba1\u7b97\u8d44\u6e90\u8fdb\u884c\u4e2a\u6027\u5316\u8c03\u4f18\u3002"}}
{"id": "2510.20627", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20627", "abs": "https://arxiv.org/abs/2510.20627", "authors": ["Lukas Miklautz", "Chengzhi Shi", "Andrii Shkabrii", "Theodoros Thirimachos Davarakis", "Prudence Lam", "Claudia Plant", "Jennifer Dy", "Stratis Ioannidis"], "title": "H-SPLID: HSIC-based Saliency Preserving Latent Information Decomposition", "comment": "Accepted at NeurIPS 2025", "summary": "We introduce H-SPLID, a novel algorithm for learning salient feature\nrepresentations through the explicit decomposition of salient and non-salient\nfeatures into separate spaces. We show that H-SPLID promotes learning\nlow-dimensional, task-relevant features. We prove that the expected prediction\ndeviation under input perturbations is upper-bounded by the dimension of the\nsalient subspace and the Hilbert-Schmidt Independence Criterion (HSIC) between\ninputs and representations. This establishes a link between robustness and\nlatent representation compression in terms of the dimensionality and\ninformation preserved. Empirical evaluations on image classification tasks show\nthat models trained with H-SPLID primarily rely on salient input components, as\nindicated by reduced sensitivity to perturbations affecting non-salient\nfeatures, such as image backgrounds. Our code is available at\nhttps://github.com/neu-spiral/H-SPLID.", "AI": {"tldr": "H-SPLID\u662f\u4e00\u79cd\u65b0\u9896\u7b97\u6cd5\uff0c\u901a\u8fc7\u5c06\u663e\u8457\u548c\u975e\u663e\u8457\u7279\u5f81\u663e\u5f0f\u5206\u89e3\u5230\u4e0d\u540c\u7a7a\u95f4\u6765\u5b66\u4e60\u663e\u8457\u7279\u5f81\u8868\u793a\uff0c\u4fc3\u8fdb\u5b66\u4e60\u4f4e\u7ef4\u3001\u4efb\u52a1\u76f8\u5173\u7279\u5f81\uff0c\u5e76\u5efa\u7acb\u9c81\u68d2\u6027\u4e0e\u6f5c\u5728\u8868\u793a\u538b\u7f29\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "motivation": "\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u660e\u786e\u5206\u79bb\u663e\u8457\u548c\u975e\u663e\u8457\u7279\u5f81\u7684\u7b97\u6cd5\uff0c\u4ee5\u4fc3\u8fdb\u5b66\u4e60\u66f4\u5177\u9c81\u68d2\u6027\u548c\u4efb\u52a1\u76f8\u5173\u6027\u7684\u4f4e\u7ef4\u7279\u5f81\u8868\u793a\u3002", "method": "\u63d0\u51faH-SPLID\u7b97\u6cd5\uff0c\u5c06\u8f93\u5165\u7279\u5f81\u663e\u5f0f\u5206\u89e3\u4e3a\u663e\u8457\u548c\u975e\u663e\u8457\u5b50\u7a7a\u95f4\uff0c\u5229\u7528Hilbert-Schmidt\u72ec\u7acb\u6027\u51c6\u5219(HSIC)\u5efa\u7acb\u9c81\u68d2\u6027\u4e0e\u8868\u793a\u538b\u7f29\u7684\u7406\u8bba\u8054\u7cfb\u3002", "result": "\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0c\u4f7f\u7528H-SPLID\u8bad\u7ec3\u7684\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u663e\u8457\u8f93\u5165\u7ec4\u4ef6\uff0c\u5bf9\u5f71\u54cd\u975e\u663e\u8457\u7279\u5f81\uff08\u5982\u56fe\u50cf\u80cc\u666f\uff09\u7684\u6270\u52a8\u654f\u611f\u6027\u964d\u4f4e\u3002", "conclusion": "H-SPLID\u901a\u8fc7\u7279\u5f81\u7a7a\u95f4\u5206\u89e3\u6709\u6548\u4fc3\u8fdb\u4e86\u9c81\u68d2\u7279\u5f81\u5b66\u4e60\uff0c\u5efa\u7acb\u4e86\u8868\u793a\u7ef4\u5ea6\u4e0e\u9884\u6d4b\u9c81\u68d2\u6027\u4e4b\u95f4\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u4e3a\u5b66\u4e60\u538b\u7f29\u4e14\u4efb\u52a1\u76f8\u5173\u7684\u7279\u5f81\u8868\u793a\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2510.20651", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20651", "abs": "https://arxiv.org/abs/2510.20651", "authors": ["Quan Li", "Wenchao Yu", "Suhang Wang", "Minhua Lin", "Lingwei Chen", "Wei Cheng", "Haifeng Chen"], "title": "xTime: Extreme Event Prediction with Hierarchical Knowledge Distillation and Expert Fusion", "comment": null, "summary": "Extreme events frequently occur in real-world time series and often carry\nsignificant practical implications. In domains such as climate and healthcare,\nthese events, such as floods, heatwaves, or acute medical episodes, can lead to\nserious consequences. Accurate forecasting of such events is therefore of\nsubstantial importance. Most existing time series forecasting models are\noptimized for overall performance within the prediction window, but often\nstruggle to accurately predict extreme events, such as high temperatures or\nheart rate spikes. The main challenges are data imbalance and the neglect of\nvaluable information contained in intermediate events that precede extreme\nevents. In this paper, we propose xTime, a novel framework for extreme event\nforecasting in time series. xTime leverages knowledge distillation to transfer\ninformation from models trained on lower-rarity events, thereby improving\nprediction performance on rarer ones. In addition, we introduce a mixture of\nexperts (MoE) mechanism that dynamically selects and fuses outputs from expert\nmodels across different rarity levels, which further improves the forecasting\nperformance for extreme events. Experiments on multiple datasets show that\nxTime achieves consistent improvements, with forecasting accuracy on extreme\nevents improving from 3% to 78%.", "AI": {"tldr": "xTime\u662f\u4e00\u4e2a\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u6781\u7aef\u4e8b\u4ef6\u9884\u6d4b\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u548c\u4e13\u5bb6\u6df7\u5408\u673a\u5236\u89e3\u51b3\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u6781\u7aef\u4e8b\u4ef6\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u6781\u7aef\u4e8b\u4ef6\uff08\u5982\u6d2a\u6c34\u3001\u70ed\u6d6a\u3001\u533b\u7597\u7d27\u6025\u60c5\u51b5\uff09\u5177\u6709\u91cd\u5927\u5b9e\u9645\u5f71\u54cd\uff0c\u4f46\u73b0\u6709\u9884\u6d4b\u6a21\u578b\u5f80\u5f80\u56e0\u6570\u636e\u4e0d\u5e73\u8861\u548c\u5ffd\u7565\u4e2d\u95f4\u4e8b\u4ef6\u4fe1\u606f\u800c\u96be\u4ee5\u51c6\u786e\u9884\u6d4b\u8fd9\u4e9b\u4e8b\u4ef6\u3002", "method": "\u63d0\u51faxTime\u6846\u67b6\uff0c\u5229\u7528\u77e5\u8bc6\u84b8\u998f\u4ece\u8bad\u7ec3\u5728\u8f83\u4f4e\u7a00\u6709\u5ea6\u4e8b\u4ef6\u4e0a\u7684\u6a21\u578b\u8f6c\u79fb\u4fe1\u606f\uff0c\u5e76\u5f15\u5165\u4e13\u5bb6\u6df7\u5408\u673a\u5236\u52a8\u6001\u9009\u62e9\u548c\u878d\u5408\u4e0d\u540c\u7a00\u6709\u5ea6\u7ea7\u522b\u7684\u4e13\u5bb6\u6a21\u578b\u8f93\u51fa\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cxTime\u5b9e\u73b0\u4e86\u6301\u7eed\u7684\u6539\u8fdb\uff0c\u6781\u7aef\u4e8b\u4ef6\u7684\u9884\u6d4b\u51c6\u786e\u7387\u4ece3%\u63d0\u5347\u523078%\u3002", "conclusion": "xTime\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u548c\u4e13\u5bb6\u6df7\u5408\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u6781\u7aef\u4e8b\u4ef6\u9884\u6d4b\u4e2d\u7684\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2510.20714", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20714", "abs": "https://arxiv.org/abs/2510.20714", "authors": ["Fardin Ganjkhanloo", "Emmett Springer", "Erik H. Hoyer", "Daniel L. Young", "Kimia Ghobadi"], "title": "Optimizing Clinical Fall Risk Prediction: A Data-Driven Integration of EHR Variables with the Johns Hopkins Fall Risk Assessment Tool", "comment": "19 pages, 7 figures, 4 tables", "summary": "In this study we aim to better align fall risk prediction from the Johns\nHopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically\nmeaningful measures via a data-driven modelling approach. We conducted a\nretrospective analysis of 54,209 inpatient admissions from three Johns Hopkins\nHealth System hospitals between March 2022 and October 2023. A total of 20,208\nadmissions were included as high fall risk encounters, and 13,941 were included\nas low fall risk encounters. To incorporate clinical knowledge and maintain\ninterpretability, we employed constrained score optimization (CSO) models on\nJHFRAT assessment data and additional electronic health record (EHR) variables.\nThe model demonstrated significant improvements in predictive performance over\nthe current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). The constrained\nscore optimization models performed similarly with and without the EHR\nvariables. Although the benchmark black-box model (XGBoost), improves upon the\nperformance metrics of the knowledge-based constrained logistic regression\n(AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk\nlabelling. This evidence-based approach provides a robust foundation for health\nsystems to systematically enhance inpatient fall prevention protocols and\npatient safety using data-driven optimization techniques, contributing to\nimproved risk assessment and resource allocation in healthcare settings.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u5efa\u6a21\u65b9\u6cd5\u4f18\u5316\u7ea6\u7ff0\u970d\u666e\u91d1\u65af\u8dcc\u5012\u98ce\u9669\u8bc4\u4f30\u5de5\u5177(JHFRAT)\uff0c\u7ed3\u5408\u4e34\u5e8a\u77e5\u8bc6\u548c\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8dcc\u5012\u98ce\u9669\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5c06JHFRAT\u8dcc\u5012\u98ce\u9669\u9884\u6d4b\u4e0e\u66f4\u591a\u4e34\u5e8a\u6709\u610f\u4e49\u6307\u6807\u5bf9\u9f50\uff0c\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u548c\u4e34\u5e8a\u5b9e\u7528\u6027\u3002", "method": "\u56de\u987e\u6027\u5206\u679054,209\u4f8b\u4f4f\u9662\u60a3\u8005\u6570\u636e\uff0c\u4f7f\u7528\u7ea6\u675f\u8bc4\u5206\u4f18\u5316(CSO)\u6a21\u578b\u7ed3\u5408JHFRAT\u8bc4\u4f30\u6570\u636e\u548c\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u53d8\u91cf\uff0c\u5e76\u4e0e\u5f53\u524dJHFRAT\u548cXGBoost\u57fa\u51c6\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "CSO\u6a21\u578b\u9884\u6d4b\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u5f53\u524dJHFRAT(AUC-ROC=0.91 vs 0.86)\uff0c\u4e0eXGBoost\u6027\u80fd\u76f8\u5f53(AUC-ROC=0.94)\u4f46\u66f4\u5177\u9c81\u68d2\u6027\uff0c\u4e14EHR\u53d8\u91cf\u7684\u52a0\u5165\u5bf9\u6027\u80fd\u5f71\u54cd\u4e0d\u5927\u3002", "conclusion": "\u8fd9\u79cd\u5faa\u8bc1\u65b9\u6cd5\u4e3a\u533b\u7597\u7cfb\u7edf\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u53ef\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u4f18\u5316\u6280\u672f\u7cfb\u7edf\u6027\u5730\u589e\u5f3a\u4f4f\u9662\u60a3\u8005\u8dcc\u5012\u9884\u9632\u65b9\u6848\u548c\u60a3\u8005\u5b89\u5168\uff0c\u6539\u5584\u98ce\u9669\u8bc4\u4f30\u548c\u8d44\u6e90\u5206\u914d\u3002"}}
{"id": "2510.20725", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20725", "abs": "https://arxiv.org/abs/2510.20725", "authors": ["Jasmine Bayrooti", "Sattar Vakili", "Amanda Prorok", "Carl Henrik Ek"], "title": "No-Regret Thompson Sampling for Finite-Horizon Markov Decision Processes with Gaussian Processes", "comment": "Appearing in NeurIPS, 2025", "summary": "Thompson sampling (TS) is a powerful and widely used strategy for sequential\ndecision-making, with applications ranging from Bayesian optimization to\nreinforcement learning (RL). Despite its success, the theoretical foundations\nof TS remain limited, particularly in settings with complex temporal structure\nsuch as RL. We address this gap by establishing no-regret guarantees for TS\nusing models with Gaussian marginal distributions. Specifically, we consider TS\nin episodic RL with joint Gaussian process (GP) priors over rewards and\ntransitions. We prove a regret bound of\n$\\mathcal{\\tilde{O}}(\\sqrt{KH\\Gamma(KH)})$ over $K$ episodes of horizon $H$,\nwhere $\\Gamma(\\cdot)$ captures the complexity of the GP model. Our analysis\naddresses several challenges, including the non-Gaussian nature of value\nfunctions and the recursive structure of Bellman updates, and extends classical\ntools such as the elliptical potential lemma to multi-output settings. This\nwork advances the understanding of TS in RL and highlights how structural\nassumptions and model uncertainty shape its performance in finite-horizon\nMarkov Decision Processes.", "AI": {"tldr": "\u672c\u6587\u4e3aThompson\u91c7\u6837\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u7406\u8bba\u5206\u6790\uff0c\u5efa\u7acb\u4e86\u5177\u6709\u9ad8\u65af\u8fb9\u9645\u5206\u5e03\u7684\u6a21\u578b\u5728\u5e8f\u5217\u51b3\u7b56\u4e2d\u7684\u65e0\u9057\u61be\u4fdd\u8bc1\uff0c\u8bc1\u660e\u4e86\u5728\u5177\u6709\u8054\u5408\u9ad8\u65af\u8fc7\u7a0b\u5148\u9a8c\u7684episodic\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u9057\u61be\u8fb9\u754c\u3002", "motivation": "Thompson\u91c7\u6837\u5728\u5e8f\u5217\u51b3\u7b56\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5728\u5177\u6709\u590d\u6742\u65f6\u95f4\u7ed3\u6784\u7684\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u4e2d\u7406\u8bba\u57fa\u7840\u6709\u9650\uff0c\u7279\u522b\u662f\u5728\u6709\u9650\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u3002", "method": "\u4f7f\u7528\u5177\u6709\u9ad8\u65af\u8fb9\u9645\u5206\u5e03\u7684\u6a21\u578b\uff0c\u8003\u8651\u5177\u6709\u8054\u5408\u9ad8\u65af\u8fc7\u7a0b\u5148\u9a8c\u7684episodic\u5f3a\u5316\u5b66\u4e60\uff0c\u5206\u6790\u975e\u9ad8\u65af\u4ef7\u503c\u51fd\u6570\u548cBellman\u66f4\u65b0\u7684\u9012\u5f52\u7ed3\u6784\uff0c\u6269\u5c55\u692d\u5706\u52bf\u5f15\u7406\u5230\u591a\u8f93\u51fa\u8bbe\u7f6e\u3002", "result": "\u8bc1\u660e\u4e86\u5728K\u4e2aepisode\u3001\u6bcf\u4e2ahorizon\u4e3aH\u7684\u60c5\u51b5\u4e0b\uff0c\u9057\u61be\u8fb9\u754c\u4e3a$\\mathcal{\\tilde{O}}(\\sqrt{KH\\Gamma(KH)})$\uff0c\u5176\u4e2d$\\Gamma(\\cdot)$\u6355\u83b7\u9ad8\u65af\u8fc7\u7a0b\u6a21\u578b\u7684\u590d\u6742\u5ea6\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63a8\u8fdb\u4e86\u5bf9Thompson\u91c7\u6837\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7406\u89e3\uff0c\u5f3a\u8c03\u4e86\u7ed3\u6784\u5047\u8bbe\u548c\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u5982\u4f55\u5f71\u54cd\u5176\u5728\u6709\u9650\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2510.20736", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20736", "abs": "https://arxiv.org/abs/2510.20736", "authors": ["Tsai Hor Chan", "Feng Wu", "Yihang Chen", "Guosheng Yin", "Lequan Yu"], "title": "Amplifying Prominent Representations in Multimodal Learning via Variational Dirichlet Process", "comment": "Accepted by NeruIPS 2025", "summary": "Developing effective multimodal fusion approaches has become increasingly\nessential in many real-world scenarios, such as health care and finance. The\nkey challenge is how to preserve the feature expressiveness in each modality\nwhile learning cross-modal interactions. Previous approaches primarily focus on\nthe cross-modal alignment, while over-emphasis on the alignment of marginal\ndistributions of modalities may impose excess regularization and obstruct\nmeaningful representations within each modality. The Dirichlet process (DP)\nmixture model is a powerful Bayesian non-parametric method that can amplify the\nmost prominent features by its richer-gets-richer property, which allocates\nincreasing weights to them. Inspired by this unique characteristic of DP, we\npropose a new DP-driven multimodal learning framework that automatically\nachieves an optimal balance between prominent intra-modal representation\nlearning and cross-modal alignment. Specifically, we assume that each modality\nfollows a mixture of multivariate Gaussian distributions and further adopt DP\nto calculate the mixture weights for all the components. This paradigm allows\nDP to dynamically allocate the contributions of features and select the most\nprominent ones, leveraging its richer-gets-richer property, thus facilitating\nmultimodal feature fusion. Extensive experiments on several multimodal datasets\ndemonstrate the superior performance of our model over other competitors.\nAblation analysis further validates the effectiveness of DP in aligning\nmodality distributions and its robustness to changes in key hyperparameters.\nCode is anonymously available at https://github.com/HKU-MedAI/DPMM.git", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u72c4\u5229\u514b\u96f7\u8fc7\u7a0b\u7684\u591a\u6a21\u6001\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7DP\u7684\u5bcc\u8005\u6108\u5bcc\u7279\u6027\u81ea\u52a8\u5e73\u8861\u6a21\u6001\u5185\u663e\u8457\u7279\u5f81\u5b66\u4e60\u548c\u8de8\u6a21\u6001\u5bf9\u9f50\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u591a\u6a21\u6001\u878d\u5408\u4e2d\u5982\u4f55\u5728\u4fdd\u6301\u5404\u6a21\u6001\u7279\u5f81\u8868\u8fbe\u80fd\u529b\u7684\u540c\u65f6\u5b66\u4e60\u8de8\u6a21\u6001\u4ea4\u4e92\u7684\u5173\u952e\u6311\u6218\uff0c\u907f\u514d\u8fc7\u5ea6\u5f3a\u8c03\u6a21\u6001\u8fb9\u9645\u5206\u5e03\u5bf9\u9f50\u5bfc\u81f4\u7684\u8fc7\u5ea6\u6b63\u5219\u5316\u95ee\u9898\u3002", "method": "\u5047\u8bbe\u6bcf\u4e2a\u6a21\u6001\u9075\u5faa\u591a\u5143\u9ad8\u65af\u6df7\u5408\u5206\u5e03\uff0c\u91c7\u7528\u72c4\u5229\u514b\u96f7\u8fc7\u7a0b\u8ba1\u7b97\u5404\u5206\u91cf\u7684\u6df7\u5408\u6743\u91cd\uff0c\u5229\u7528DP\u7684\u5bcc\u8005\u6108\u5bcc\u7279\u6027\u52a8\u6001\u5206\u914d\u7279\u5f81\u8d21\u732e\u5e76\u9009\u62e9\u6700\u663e\u8457\u7279\u5f81\u3002", "result": "\u5728\u591a\u4e2a\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u4f18\u4e8e\u5176\u4ed6\u7ade\u4e89\u65b9\u6cd5\uff0c\u6d88\u878d\u5206\u6790\u9a8c\u8bc1\u4e86DP\u5728\u6a21\u6001\u5206\u5e03\u5bf9\u9f50\u4e2d\u7684\u6709\u6548\u6027\u53ca\u5176\u5bf9\u5173\u952e\u8d85\u53c2\u6570\u53d8\u5316\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684DP\u9a71\u52a8\u591a\u6a21\u6001\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u81ea\u52a8\u5b9e\u73b0\u6a21\u6001\u5185\u663e\u8457\u8868\u793a\u5b66\u4e60\u548c\u8de8\u6a21\u6001\u5bf9\u9f50\u4e4b\u95f4\u7684\u6700\u4f18\u5e73\u8861\uff0c\u4e3a\u591a\u6a21\u6001\u878d\u5408\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20762", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20762", "abs": "https://arxiv.org/abs/2510.20762", "authors": ["Jan Sobotka", "Luca Baroni", "J\u00e1n Antol\u00edk"], "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging Most Exciting Inputs", "comment": "Accepted to NeurIPS 2025", "summary": "Decoding visual stimuli from neural population activity is crucial for\nunderstanding the brain and for applications in brain-machine interfaces.\nHowever, such biological data is often scarce, particularly in primates or\nhumans, where high-throughput recording techniques, such as two-photon imaging,\nremain challenging or impossible to apply. This, in turn, poses a challenge for\ndeep learning decoding techniques. To overcome this, we introduce MEIcoder, a\nbiologically informed decoding method that leverages neuron-specific most\nexciting inputs (MEIs), a structural similarity index measure loss, and\nadversarial training. MEIcoder achieves state-of-the-art performance in\nreconstructing visual stimuli from single-cell activity in primary visual\ncortex (V1), especially excelling on small datasets with fewer recorded\nneurons. Using ablation studies, we demonstrate that MEIs are the main drivers\nof the performance, and in scaling experiments, we show that MEIcoder can\nreconstruct high-fidelity natural-looking images from as few as 1,000-2,500\nneurons and less than 1,000 training data points. We also propose a unified\nbenchmark with over 160,000 samples to foster future research. Our results\ndemonstrate the feasibility of reliable decoding in early visual system and\nprovide practical insights for neuroscience and neuroengineering applications.", "AI": {"tldr": "MEIcoder\u662f\u4e00\u79cd\u751f\u7269\u4fe1\u606f\u89e3\u7801\u65b9\u6cd5\uff0c\u5229\u7528\u795e\u7ecf\u5143\u7279\u5f02\u6027\u6700\u5174\u594b\u8f93\u5165(MEIs)\u3001\u7ed3\u6784\u76f8\u4f3c\u6027\u6307\u6570\u635f\u5931\u548c\u5bf9\u6297\u8bad\u7ec3\uff0c\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u89c6\u89c9\u523a\u6fc0\u91cd\u5efa\u6027\u80fd\u3002", "motivation": "\u7075\u957f\u7c7b\u6216\u4eba\u7c7b\u7b49\u751f\u7269\u6570\u636e\u5f80\u5f80\u7a00\u7f3a\uff0c\u8fd9\u5bf9\u6df1\u5ea6\u5b66\u4e60\u89e3\u7801\u6280\u672f\u6784\u6210\u6311\u6218\uff0c\u9700\u8981\u514b\u670d\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165MEIcoder\u65b9\u6cd5\uff0c\u7ed3\u5408\u795e\u7ecf\u5143\u7279\u5f02\u6027\u6700\u5174\u594b\u8f93\u5165(MEIs)\u3001\u7ed3\u6784\u76f8\u4f3c\u6027\u6307\u6570\u635f\u5931\u548c\u5bf9\u6297\u8bad\u7ec3\u3002", "result": "\u5728\u521d\u7ea7\u89c6\u89c9\u76ae\u5c42\u5355\u7ec6\u80de\u6d3b\u52a8\u91cd\u5efa\u89c6\u89c9\u523a\u6fc0\u65b9\u9762\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u7279\u522b\u662f\u5bf9\u5c0f\u6570\u636e\u96c6\u8868\u73b0\u4f18\u5f02\uff0c\u4ec5\u97001,000-2,500\u4e2a\u795e\u7ecf\u5143\u548c\u5c11\u4e8e1,000\u4e2a\u8bad\u7ec3\u6570\u636e\u70b9\u5373\u53ef\u91cd\u5efa\u9ad8\u4fdd\u771f\u81ea\u7136\u56fe\u50cf\u3002", "conclusion": "\u8bc1\u660e\u4e86\u65e9\u671f\u89c6\u89c9\u7cfb\u7edf\u4e2d\u53ef\u9760\u89e3\u7801\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u795e\u7ecf\u79d1\u5b66\u548c\u795e\u7ecf\u5de5\u7a0b\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2510.20817", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20817", "abs": "https://arxiv.org/abs/2510.20817", "authors": ["Anthony GX-Chen", "Jatin Prakash", "Jeff Guo", "Rob Fergus", "Rajesh Ranganath"], "title": "KL-Regularized Reinforcement Learning is Designed to Mode Collapse", "comment": null, "summary": "It is commonly believed that optimizing the reverse KL divergence results in\n\"mode seeking\", while optimizing forward KL results in \"mass covering\", with\nthe latter being preferred if the goal is to sample from multiple diverse\nmodes. We show -- mathematically and empirically -- that this intuition does\nnot necessarily transfer well to doing reinforcement learning with\nreverse/forward KL regularization (e.g. as commonly used with language models).\nInstead, the choice of reverse/forward KL determines the family of optimal\ntarget distributions, parameterized by the regularization coefficient. Mode\ncoverage depends primarily on other factors, such as regularization strength,\nand relative scales between rewards and reference probabilities. Further, we\nshow commonly used settings such as low regularization strength and equal\nverifiable rewards tend to specify unimodal target distributions, meaning the\noptimization objective is, by construction, non-diverse. We leverage these\ninsights to construct a simple, scalable, and theoretically justified\nalgorithm. It makes minimal changes to reward magnitudes, yet optimizes for a\ntarget distribution which puts high probability over all high-quality sampling\nmodes. In experiments, this simple modification works to post-train both Large\nLanguage Models and Chemical Language Models to have higher solution quality\nand diversity, without any external signals of diversity, and works with both\nforward and reverse KL when using either naively fails.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6311\u6218\u4e86\u5173\u4e8e\u53cd\u5411KL\u6563\u5ea6\u548c\u524d\u5411KL\u6563\u5ea6\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4f20\u7edf\u76f4\u89c9\uff0c\u53d1\u73b0\u6a21\u5f0f\u8986\u76d6\u4e3b\u8981\u53d6\u51b3\u4e8e\u6b63\u5219\u5316\u5f3a\u5ea6\u7b49\u56e0\u7d20\uff0c\u800c\u975eKL\u6563\u5ea6\u7684\u9009\u62e9\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u7b97\u6cd5\uff0c\u901a\u8fc7\u8c03\u6574\u5956\u52b1\u5e45\u5ea6\u6765\u4f18\u5316\u76ee\u6807\u5206\u5e03\uff0c\u5728\u8bed\u8a00\u6a21\u578b\u548c\u5316\u5b66\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u9a8c\u4e2d\u63d0\u9ad8\u4e86\u89e3\u51b3\u65b9\u6848\u7684\u8d28\u91cf\u548c\u591a\u6837\u6027\u3002", "motivation": "\u4f20\u7edf\u89c2\u70b9\u8ba4\u4e3a\u4f18\u5316\u53cd\u5411KL\u6563\u5ea6\u4f1a\u5bfc\u81f4\"\u6a21\u5f0f\u5bfb\u6c42\"\uff0c\u800c\u4f18\u5316\u524d\u5411KL\u6563\u5ea6\u4f1a\u5bfc\u81f4\"\u8d28\u91cf\u8986\u76d6\"\uff0c\u540e\u8005\u5728\u9700\u8981\u4ece\u591a\u4e2a\u4e0d\u540c\u6a21\u5f0f\u91c7\u6837\u65f6\u66f4\u53d7\u9752\u7750\u3002\u4f46\u4f5c\u8005\u53d1\u73b0\u8fd9\u79cd\u76f4\u89c9\u5728\u5f3a\u5316\u5b66\u4e60\u4e0eKL\u6b63\u5219\u5316\uff08\u5982\u8bed\u8a00\u6a21\u578b\u4e2d\u5e38\u7528\uff09\u7684\u60c5\u51b5\u4e0b\u5e76\u4e0d\u4e00\u5b9a\u9002\u7528\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u6570\u5b66\u5206\u6790\u548c\u5b9e\u8bc1\u7814\u7a76\uff0c\u63ed\u793a\u4e86\u53cd\u5411/\u524d\u5411KL\u7684\u9009\u62e9\u51b3\u5b9a\u4e86\u6700\u4f18\u76ee\u6807\u5206\u5e03\u7684\u65cf\u7cfb\uff0c\u800c\u6a21\u5f0f\u8986\u76d6\u4e3b\u8981\u53d6\u51b3\u4e8e\u6b63\u5219\u5316\u5f3a\u5ea6\u3001\u5956\u52b1\u4e0e\u53c2\u8003\u6982\u7387\u7684\u76f8\u5bf9\u5c3a\u5ea6\u7b49\u56e0\u7d20\u3002\u57fa\u4e8e\u8fd9\u4e9b\u6d1e\u5bdf\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u7b80\u5355\u3001\u53ef\u6269\u5c55\u4e14\u7406\u8bba\u4e0a\u6709\u4f9d\u636e\u7684\u7b97\u6cd5\uff0c\u53ea\u9700\u5bf9\u5956\u52b1\u5e45\u5ea6\u8fdb\u884c\u6700\u5c0f\u4fee\u6539\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7b80\u5355\u4fee\u6539\u80fd\u591f\u5728\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u5316\u5b66\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u540e\u8bad\u7ec3\u65f6\uff0c\u63d0\u9ad8\u89e3\u51b3\u65b9\u6848\u7684\u8d28\u91cf\u548c\u591a\u6837\u6027\uff0c\u65e0\u9700\u4efb\u4f55\u5916\u90e8\u591a\u6837\u6027\u4fe1\u53f7\uff0c\u5e76\u4e14\u5728\u5355\u72ec\u4f7f\u7528\u524d\u5411\u6216\u53cd\u5411KL\u5931\u8d25\u7684\u60c5\u51b5\u4e0b\u90fd\u80fd\u5de5\u4f5c\u3002", "conclusion": "\u8bba\u6587\u7ed3\u8bba\u662f\u6a21\u5f0f\u8986\u76d6\u4e0d\u4e3b\u8981\u53d6\u51b3\u4e8eKL\u6563\u5ea6\u7684\u9009\u62e9\uff0c\u800c\u662f\u5176\u4ed6\u56e0\u7d20\u5982\u6b63\u5219\u5316\u5f3a\u5ea6\u3002\u63d0\u51fa\u7684\u7b97\u6cd5\u901a\u8fc7\u6700\u5c0f\u5316\u5956\u52b1\u5e45\u5ea6\u8c03\u6574\uff0c\u80fd\u591f\u4f18\u5316\u76ee\u6807\u5206\u5e03\u4ee5\u8986\u76d6\u6240\u6709\u9ad8\u8d28\u91cf\u91c7\u6837\u6a21\u5f0f\uff0c\u5728\u5b9e\u8df5\u4e2d\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u7684\u591a\u6837\u6027\u548c\u8d28\u91cf\u3002"}}
