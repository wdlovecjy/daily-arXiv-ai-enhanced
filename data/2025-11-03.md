<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 6]
- [cs.AI](#cs.AI) [Total: 7]
- [stat.AP](#stat.AP) [Total: 5]
- [stat.ML](#stat.ML) [Total: 1]
- [cs.LG](#cs.LG) [Total: 28]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Investigation of Superdirectivity in Planar Holographic Arrays](https://arxiv.org/abs/2510.26803)
*Hang Lin,Liuxun Xue,Shu Sun,Ruifeng Gao,Jue Wang,Tengjiao Wang*

Main category: eess.SP

TL;DR: 本文研究了均匀矩形阵列在holographic MIMO系统中的超指向性特性，建立了URA的数学指向性模型并推导了最大指向性的解析表达式，通过数值仿真分析了耦合效应对指向性增强的影响。


<details>
  <summary>Details</summary>
Motivation: 研究均匀矩形阵列在holographic MIMO系统中的超指向性特性，为5G/6G通信系统中holographic阵列优化提供理论依据。

Method: 建立均匀矩形阵列的数学指向性模型，推导最大指向性的解析表达式，结合数值仿真进行系统分析。

Result: 结果表明通过合理利用耦合效应可以显著增强指向性，但当天线间距过渡到深亚波长尺度时，这种增强效果会呈现递减趋势。

Conclusion: 本研究为超指向性均匀矩形阵列的设计提供了理论基础，并为5G/6G通信系统中holographic阵列优化提供了有价值的见解。

Abstract: This paper studies the superdirectivity characteristics of uniform
rectangular arrays (URAs) for holographic multiple-input multiple-output
systems. By establishing a mathematical directivity model for the URA, an
analytical expression for the maximum directivity is derived. Accordingly,
systematic analysis is performed in conjunction with numerical simulations.
Results show that the directivity can be significantly enhanced via rational
utilization of coupling effects. However, this enhancement yields diminishing
returns when antenna spacings transition to deep sub-wavelength scales. This
study provides a theoretical basis for the design of superdirective URAs and
offers valuable insights for holographic array optimization in 5G/6G
communication systems.

</details>


### [2] [Unlimited Sampling of Multiband Signals: Single-Channel Acquisition and Recovery](https://arxiv.org/abs/2510.27110)
*Gal Shtendel,Ayush Bhandari*

Main category: eess.SP

TL;DR: 该论文研究了在无限采样框架下从模折叠点样本重建多频带信号的问题，证明了在单通道采集设置下可实现亚奈奎斯特采样，并改进了带通信号的采样定理。硬件实验显示动态范围提升高达13倍。


<details>
  <summary>Details</summary>
Motivation: 解决传统采样在动态范围和过度采样方面的限制，特别是在多频带信号采集场景中，探索在无限采样框架下实现更高效的信号重建。

Method: 采用低复杂度单通道采集设置，基于无限采样框架，通过模折叠点样本重建多频带信号，建立恢复保证并改进采样定理。

Result: 在硬件实验中实现了高达13倍的动态范围提升，支持多达6个频谱带，证明了亚奈奎斯特采样的可行性。

Conclusion: 该方法能够在先前受动态范围和过度采样限制的场景中实现实用的高动态范围多频带采集，为信号处理提供了新的可能性。

Abstract: In this paper, we address the problem of reconstructing multiband signals
from modulo-folded, pointwise samples within the Unlimited Sensing Framework
(USF). Focusing on a low-complexity, single-channel acquisition setup, we
establish recovery guarantees demonstrating that sub-Nyquist sampling is
achievable under the USF paradigm. In doing so, we also tighten the previous
sampling theorem for bandpass signals. Our recovery algorithm demonstrates up
to a 13x dynamic range improvement in hardware experiments with up to 6
spectral bands. These results enable practical high-dynamic-range multiband
acquisition in scenarios previously limited by dynamic range and excessive
oversampling.

</details>


### [3] [Variational Bayesian Estimation of Low Earth Orbits for Satellite Communication](https://arxiv.org/abs/2510.27345)
*Anders Malthe Westerkam,Amélia Struyf,Dimitri Lederer,Troels Pedersen,François Quitin*

Main category: eess.SP

TL;DR: 提出了一种基于变分消息传递的算法，用于联合定位和跟踪低地球轨道卫星，该算法通过估计轨道参数来获取角度信息，在混合收发器架构下具有高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道卫星通信系统使用毫米波频率和混合模拟-数字架构进行快速波束转向，但由于卫星高速运动，地面站只能短暂可见卫星，需要有效的跟踪方法。

Method: 使用变分消息传递算法，通过建模圆形轨道来估计轨道参数，然后从轨道中直接获取角度信息，实现卫星的联合定位和波束跟踪。

Result: 仿真结果表明，该方法对漏检具有高度鲁棒性，即使在地平线附近也能可靠跟踪卫星，并能有效缓解混合架构固有的模糊性问题。

Conclusion: 提出的变分消息传递算法为低地球轨道卫星通信系统提供了一种有效的联合定位和波束跟踪解决方案，在混合收发器架构下表现出优越性能。

Abstract: Low-earth-orbit (LEO) satellite communication systems that use
millimeter-wave frequencies rely on large antenna arrays with hybrid
analog-digital architectures for rapid beam steering. LEO satellites are only
visible from the ground for short periods of times (a few tens of minutes) due
to their high orbital speeds. This paper presents a variational message passing
algorithm for joint localization and beam tracking of a LEO satellite from a
ground station equipped with a hybrid transceiver architecture. The algorithm
relies on estimating the parameters of the orbit, which is modelled as
circular. Angles are then obtained from the orbit in a straightforward manner.
Simulation results show that the proposed method is highly resilient to missed
detections, enables reliable satellite tracking even near the horizon, and
effectively alleviates the ambiguities inherent in hybrid architectures.

</details>


### [4] [Classification of Lower Limb Activities Based on Discrete Wavelet Transform Using On-Body Creeping Wave Propagation](https://arxiv.org/abs/2510.27371)
*Sagar Dutta,Banani Basu,Fazal Ahmed Talukdar*

Main category: eess.SP

TL;DR: 该研究利用人体大腿周围的爬行波传播来监测腿部运动，通过测量两个柔性天线之间的传输系数变化来识别六种不同的腿部活动，并使用多种机器学习算法进行分类，其中SVM与DWT组合表现最佳。


<details>
  <summary>Details</summary>
Motivation: 研究动机是利用人体大腿周围的爬行波传播特性来监测腿部运动，为活动分类提供新的传感方法。

Method: 方法包括：使用两个PET柔性天线测量传输系数变化；对六种腿部活动进行数据采集；应用DWT进行特征提取；使用SVM、决策树、朴素贝叶斯、KNN等分类器；同时实现DTW和DCNN算法进行比较；进行SAR仿真评估。

Result: 结果显示：SVM与DWT组合在所有分类器中表现最佳；SAR值符合FCC标准阈值要求；不同腿部活动产生独特的时间变化特征。

Conclusion: 结论表明：基于爬行波传播的腿部运动监测方法是可行的；SVM与DWT的组合在活动分类中具有最佳性能；系统符合安全标准，为可穿戴健康监测应用提供了新途径。

Abstract: This article investigates how the creeping wave propagation around the human
thigh could be used to monitor the leg movements. The propagation path around
the human thigh gives information regarding leg motions that can be used for
the classification of activities. The variation of the transmission coefficient
is measured between two on-body polyethylene terephthalate (PET) flexible
antennas for six different leg-based activities that exhibit unique
time-varying signatures. A discrete wavelet transform (DWT) along with
different classifiers, such as support vector machine (SVM), decision trees,
naive Bayes, and K-nearest neighbors (KNN), is applied for feature extraction
and classification to evaluate the efficiency for classifying different
activity signals. Additional algorithms, such as dynamic time warping (DTW) and
deep convolutional neural network (DCNN), have also been implemented, and in
each case, SVM with DWT outperforms the others. Simulation to evaluate a
specific absorption rate (SAR) is carried out as the antenna is positioned on
the human thigh leaving no gap. The results show that the SAR is within the
threshold as per the Federal Communications Commission (FCC) standard.

</details>


### [5] [Classification of Induction Motor Fault and Imbalance Based on Vibration Signal Using Single Antenna's Reactive Near Field](https://arxiv.org/abs/2510.27382)
*Sagar Dutta,Banani Basu,Fazal Ahmed Talukdar*

Main category: eess.SP

TL;DR: 提出了一种使用天线作为传感器的非侵入式、低成本方法，用于检测感应电机的轴承故障和不平衡问题，通过分析S11反射系数的时变特性，结合深度学习模型实现故障分类，准确率达到98.2%。


<details>
  <summary>Details</summary>
Motivation: 现有故障分析方法成本高昂或需要专业知识安装传感器，需要开发非侵入式、成本效益高的早期故障诊断方法以减少工业意外故障造成的经济损失。

Method: 使用全向天线测量时变S11参数，通过频谱图分析不同故障条件下的特征，应用FFT分析验证特征故障频率，并使用深度学习模型基于S11反射系数的幅度和相位进行故障分类。

Result: 实验验证了不同故障条件下的特征频率，深度学习模型使用S11幅度和相位组合的分类准确率达到98.2%，仅使用幅度为96%，仅使用相位为92.1%，并对不同工作频率、天线位置和时间窗口的分类准确性进行了研究。

Conclusion: 基于天线传感器的非侵入式方法能够有效检测电机轴承故障和不平衡问题，深度学习模型结合S11幅度和相位信息可实现高精度故障分类，为工业旋转机械的早期故障诊断提供了经济高效的解决方案。

Abstract: Early fault diagnosis is imperative for the proper functioning of rotating
machines. It can reduce economic losses in the industry due to unexpected
failures. Existing fault analysis methods are either expensive or demand
expertise for the installation of the sensors. This article proposes a novel
method for the detection of bearing faults and imbalance in induction motors
using an antenna as the sensor, which is noninvasive and cost-efficient.
Time-varying S11 is measured using an omnidirectional antenna, and it is seen
that the spectrogram of S11 shows unique characteristics for different fault
conditions. The experimental setup has analytically evaluated the vibration
frequencies due to fault and validated the characteristic fault frequency by
applying FFT analysis on the captured S11 data. This article has evaluated the
average power content of the detected signals at normal and different fault
conditions. A deep learning model is used to classify the faults based on the
reflection coefficient ( S11). It is found that classification accuracy of
98.2% is achieved using both magnitude and phase of S11, 96% using the
magnitude of S11 and 92.1% using the phase of S11. The classification accuracy
for different operating frequencies, antenna location, and time windows are
also investigated.

</details>


### [6] [Estimation of aboveground biomass in a tropical dry forest: An intercomparison of airborne, unmanned, and space laser scanning](https://arxiv.org/abs/2510.27408)
*Nelson Mattié,Arturo Sanchez-Azofeifa,Pablo Crespo-Peremarch,Juan-Ygnacio López-Hernández*

Main category: eess.SP

TL;DR: 本研究通过比较分析不同激光扫描数据集（离散和全波形）结合OLS和贝叶斯SVM方法，改进了热带干旱森林地上生物量制图方法，识别出树高相关变量和全波形信号能量等关键变量，在哥斯达黎加热带干旱森林中实现了17.89%的估算误差。


<details>
  <summary>Details</summary>
Motivation: 根据巴黎气候协定要求各国定期报告温室气体排放和吸收情况，森林在减排中发挥关键作用。热带干旱森林是最不了解的热带森林环境之一，需要准确估算碳库的方法。

Method: 使用机载激光扫描、无人机激光扫描和空间激光扫描作为独立变量提取森林指标，应用变量选择、SVM回归调优和机器学习交叉验证方法，比较离散和全波形激光扫描数据集结合OLS和贝叶斯SVM方法。

Result: 识别出6个与树高相关的关键变量和叶面积指数、冠层覆盖度等全波形重要变量。在哥斯达黎加热带干旱森林中，地上生物量估算范围为26.02-175.43 Mg/ha，所有激光扫描系统的SVM回归误差为17.89%，其中空间激光扫描全波形系统误差最低（17.07%）。

Conclusion: 研究表明激光扫描技术结合机器学习方法能够有效估算热带干旱森林地上生物量，为巴黎协定要求的碳报告提供可靠数据支持，全波形激光扫描系统在生物量估算中表现最佳。

Abstract: According to the Paris Climate Change Agreement, all nations are required to
submit reports on their greenhouse gas emissions and absorption every two years
by 2024. Consequently, forests play a crucial role in reducing carbon
emissions, which is essential for meeting these obligations. Recognizing the
significance of forest conservation in the global battle against climate
change, Article 5 of the Paris Agreement emphasizes the need for high-quality
forest data. This study focuses on enhancing methods for mapping aboveground
biomass in tropical dry forests. Tropical dry forests are considered one of the
least understood tropical forest environments; therefore, there is a need for
accurate approaches to estimate carbon pools. We employ a comparative analysis
of AGB estimates, utilizing different discrete and full-waveform laser scanning
datasets in conjunction with Ordinary Least Squares and Bayesian approaches
SVM. Airborne Laser Scanning, Unmanned Laser Scanning, and Space Laser Scanning
were used as independent variables for extracting forest metrics. Variable
selection, SVM regression tuning, and cross-validation via a machine-learning
approach were applied to account for overfitting and underfitting. The results
indicate that six key variables primarily related to tree height: Elev.minimum,
Elev.L3, lev.MAD.mode, Elev.mode, Elev.MAD.median, and Elev.skewness, are
important for AGB estimation using ALSD and ULSD , while Leaf Area Index,
canopy coverage and height, terrain elevation, and full-waveform signal energy
emerged as the most vital variables. AGB values estimated from ten permanent
tropical dry forest plots in Costa Rica Guanacaste province ranged from 26.02
Mg/ha to 175.43 Mg/ha . The SVM regressions demonstrated a 17.89 error across
all laser scanning systems, with SLSF W exhibiting the lowest error 17.07 in
estimating total biomass per plot.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [SUSTAINABLE Platform: Seamless Smart Farming Integration Towards Agronomy Automation](https://arxiv.org/abs/2510.26989)
*Agorakis Bompotas,Konstantinos Koutras,Nikitas Rigas Kalogeropoulos,Panagiotis Kechagias,Dimitra Gariza,Athanasios P. Kalogeras,Christos Alexakos*

Main category: cs.AI

TL;DR: SUSTAINABLE是一个智能农业平台，整合物联网、人工智能、卫星成像和基于角色的任务编排，旨在实现高效、可追溯和可持续的农业，以葡萄种植为试点用例。


<details>
  <summary>Details</summary>
Motivation: 全球农业面临粮食需求增长、气候变化和可持续实践需求的挑战，需要智能解决方案来推动农业转型。

Method: 集成物联网、AI、卫星成像和基于角色的任务编排技术，特别针对地中海葡萄园设计，包括卫星指数集成、实时环境数据和角色感知任务管理功能。

Result: 开发了SUSTAINABLE智能农业平台，提供比较评估并展示了其在葡萄种植中的关键特性。

Conclusion: SUSTAINABLE平台通过整合多种先进技术，为农业可持续发展和效率提升提供了可行的智能解决方案。

Abstract: The global agricultural sector is undergoing a transformative shift, driven
by increasing food demands, climate variability and the need for sustainable
practices. SUSTAINABLE is a smart farming platform designed to integrate IoT,
AI, satellite imaging, and role-based task orchestration to enable efficient,
traceable, and sustainable agriculture with a pilot usecase in viticulture.
This paper explores current smart agriculture solutions, presents a comparative
evaluation, and introduces SUSTAINABLE's key features, including satellite
index integration, real-time environmental data, and role-aware task management
tailored to Mediterranean vineyards.

</details>


### [8] [Causal Masking on Spatial Data: An Information-Theoretic Case for Learning Spatial Datasets with Unimodal Language Models](https://arxiv.org/abs/2510.27009)
*Jared Junkin,Samuel Nathanson*

Main category: cs.AI

TL;DR: 该论文研究了在非顺序数据上应用因果掩码的可行性，通过在象棋领域对比空间（棋盘状态）和顺序（走棋序列）两种数据表示，发现即使使用因果掩码，基于空间数据训练的模型表现优于基于顺序数据的模型。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型围绕因果掩码设计，但在具有空间或关系结构的领域中，因果掩码常被视为不适用，通常采用顺序线性化方法。本研究旨在直接探讨在非顺序数据上接受因果掩码引入的信息损失是否可行。

Method: 在象棋领域训练具有双向和因果自注意力机制的语言模型，分别使用空间（棋盘状态）和顺序（走棋序列）两种数据表示进行对比实验。

Result: 结果显示，基于空间棋盘状态训练的模型（即使使用因果掩码）始终比基于顺序数据训练的模型具有更强的下棋能力。

Conclusion: 在空间数据上应用因果掩码是训练单模态LLM在空间数据上的可行方法，在某些领域甚至优于顺序化方法，这一发现具有更广泛的方法论意义。

Abstract: Language models are traditionally designed around causal masking. In domains
with spatial or relational structure, causal masking is often viewed as
inappropriate, and sequential linearizations are instead used. Yet the question
of whether it is viable to accept the information loss introduced by causal
masking on nonsequential data has received little direct study, in part because
few domains offer both spatial and sequential representations of the same
dataset. In this work, we investigate this issue in the domain of chess, which
naturally supports both representations. We train language models with
bidirectional and causal self-attention mechanisms on both spatial
(board-based) and sequential (move-based) data. Our results show that models
trained on spatial board states - \textit{even with causal masking} -
consistently achieve stronger playing strength than models trained on
sequential data. While our experiments are conducted on chess, our results are
methodological and may have broader implications: applying causal masking to
spatial data is a viable procedure for training unimodal LLMs on spatial data,
and in some domains is even preferable to sequentialization.

</details>


### [9] [e1: Learning Adaptive Control of Reasoning Effort](https://arxiv.org/abs/2510.27042)
*Michael Kleinman,Matthew Trager,Alessandro Achille,Wei Xia,Stefano Soatto*

Main category: cs.AI

TL;DR: 提出自适应努力控制方法，让用户通过连续参数动态控制AI模型的推理成本与精度权衡，无需预先知道问题难度即可实现约3倍推理长度缩减且保持或提升性能


<details>
  <summary>Details</summary>
Motivation: 现有方法需要用户预先指定绝对token数量，但用户难以事先知道问题难度来合理设置token预算。需要更细粒度的控制来平衡输出质量与延迟成本

Method: 基于强化学习的自适应努力控制方法，训练模型使用相对于当前平均思维链长度的用户指定比例token数，无需数据集和阶段特定调优

Result: 在1.5B到32B参数规模的模型上，该方法能实现约3倍思维链长度缩减，同时保持或提升相对于RL训练基础模型的性能

Conclusion: 自适应努力控制方法提供了动态调节成本-精度权衡的有效手段，模型能自动按任务难度比例分配资源，优于标准方法

Abstract: Increasing the thinking budget of AI models can significantly improve
accuracy, but not all questions warrant the same amount of reasoning. Users may
prefer to allocate different amounts of reasoning effort depending on how they
value output quality versus latency and cost. To leverage this tradeoff
effectively, users need fine-grained control over the amount of thinking used
for a particular query, but few approaches enable such control. Existing
methods require users to specify the absolute number of desired tokens, but
this requires knowing the difficulty of the problem beforehand to appropriately
set the token budget for a query. To address these issues, we propose Adaptive
Effort Control, a self-adaptive reinforcement learning method that trains
models to use a user-specified fraction of tokens relative to the current
average chain-of-thought length for each query. This approach eliminates
dataset- and phase-specific tuning while producing better cost-accuracy
tradeoff curves compared to standard methods. Users can dynamically adjust the
cost-accuracy trade-off through a continuous effort parameter specified at
inference time. We observe that the model automatically learns to allocate
resources proportionally to the task difficulty and, across model scales
ranging from 1.5B to 32B parameters, our approach enables approximately 3x
reduction in chain-of-thought length while maintaining or improving performance
relative to the base model used for RL training.

</details>


### [10] [Discriminative Rule Learning for Outcome-Guided Process Model Discovery](https://arxiv.org/abs/2510.27343)
*Ali Norouzifar,Wil van der Aalst*

Main category: cs.AI

TL;DR: 提出了一种基于结果感知的过程发现方法，通过区分理想和不理想的过程执行，分别学习过程模型，从而揭示关键行为差异。


<details>
  <summary>Details</summary>
Motivation: 传统过程发现方法不考虑执行结果差异，导致模型无法有效支持合规检查和性能分析，无法捕捉理想与不理想执行之间的关键行为区别。

Method: 通过学习控制流特征上的可解释判别规则，将具有相似理想性特征的轨迹分组，然后在每个组内分别应用过程发现技术。

Result: 该方法在多个真实事件日志上得到验证，能够有效隔离和可视化关键过程模式，生成聚焦且可解释的模型。

Conclusion: 结果感知的过程发现方法能够更好地揭示理想和不理想过程执行的驱动因素，为过程改进提供更有针对性的见解。

Abstract: Event logs extracted from information systems offer a rich foundation for
understanding and improving business processes. In many real-world
applications, it is possible to distinguish between desirable and undesirable
process executions, where desirable traces reflect efficient or compliant
behavior, and undesirable ones may involve inefficiencies, rule violations,
delays, or resource waste. This distinction presents an opportunity to guide
process discovery in a more outcome-aware manner. Discovering a single process
model without considering outcomes can yield representations poorly suited for
conformance checking and performance analysis, as they fail to capture critical
behavioral differences. Moreover, prioritizing one behavior over the other may
obscure structural distinctions vital for understanding process outcomes. By
learning interpretable discriminative rules over control-flow features, we
group traces with similar desirability profiles and apply process discovery
separately within each group. This results in focused and interpretable models
that reveal the drivers of both desirable and undesirable executions. The
approach is implemented as a publicly available tool and it is evaluated on
multiple real-life event logs, demonstrating its effectiveness in isolating and
visualizing critical process patterns.

</details>


### [11] [Realistic pedestrian-driver interaction modelling using multi-agent RL with human perceptual-motor constraints](https://arxiv.org/abs/2510.27383)
*Yueyang Wang,Mehmet Dogar,Gustav Markkula*

Main category: cs.AI

TL;DR: 提出了一种集成视觉和运动约束的多智能体强化学习框架，用于模拟行人-驾驶员交互，在真实世界无信号人行横道数据集上验证了约束模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖基于规则的逻辑、博弈论模型或'黑盒'机器学习，缺乏灵活性或忽视感知和运动约束等底层机制，这些机制塑造了行人和驾驶员在交互场景中的感知和行为方式。

Method: 使用多智能体强化学习框架，集成行人和驾驶员智能体的视觉和运动约束，评估了四种模型变体（无约束、仅运动约束、仅视觉约束、两者皆有），并在行为指标上比较交互真实性。

Result: 同时包含视觉和运动约束的模型表现最佳。运动约束导致更平滑的运动，类似于人类在穿越交互中的速度调整；视觉约束引入感知不确定性和视野限制，使智能体表现出更谨慎和可变的行为。在数据有限的情况下，该模型优于监督行为克隆模型。

Conclusion: 带有人类约束的多智能体强化学习是模拟真实道路用户交互的有前景的建模方法，通过将控制人类约束的参数建模为群体级分布来考虑个体差异，这是先前行人-车辆交互建模工作中未探索的视角。

Abstract: Modelling pedestrian-driver interactions is critical for understanding human
road user behaviour and developing safe autonomous vehicle systems. Existing
approaches often rely on rule-based logic, game-theoretic models, or
'black-box' machine learning methods. However, these models typically lack
flexibility or overlook the underlying mechanisms, such as sensory and motor
constraints, which shape how pedestrians and drivers perceive and act in
interactive scenarios. In this study, we propose a multi-agent reinforcement
learning (RL) framework that integrates both visual and motor constraints of
pedestrian and driver agents. Using a real-world dataset from an unsignalised
pedestrian crossing, we evaluate four model variants, one without constraints,
two with either motor or visual constraints, and one with both, across
behavioural metrics of interaction realism. Results show that the combined
model with both visual and motor constraints performs best. Motor constraints
lead to smoother movements that resemble human speed adjustments during
crossing interactions. The addition of visual constraints introduces perceptual
uncertainty and field-of-view limitations, leading the agents to exhibit more
cautious and variable behaviour, such as less abrupt deceleration. In this
data-limited setting, our model outperforms a supervised behavioural cloning
model, demonstrating that our approach can be effective without large training
datasets. Finally, our framework accounts for individual differences by
modelling parameters controlling the human constraints as population-level
distributions, a perspective that has not been explored in previous work on
pedestrian-vehicle interaction modelling. Overall, our work demonstrates that
multi-agent RL with human constraints is a promising modelling approach for
simulating realistic road user interactions.

</details>


### [12] [DeepCompress: A Dual Reward Strategy for Dynamically Exploring and Compressing Reasoning Chains](https://arxiv.org/abs/2510.27419)
*Tian Liang,Wenxiang Jiao,Zhiwei He,Jiahao Xu,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: DeepCompress是一个新颖框架，通过自适应长度奖励机制同时提高大型推理模型的准确性和效率，根据问题难度动态调整推理链长度。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型存在认知效率问题：简单问题过度思考，复杂问题思考不足。现有方法通过监督微调或强化学习提高效率，但往往以牺牲准确性为代价。

Method: 采用自适应长度奖励机制，实时将问题分类为“简单”或“困难”，对简单问题鼓励更短的推理路径，对困难问题促进更长的探索性思维链。

Result: 在具有挑战性的数学基准测试中，DeepCompress持续优于基线方法，在显著提高标记效率的同时实现了更优的准确性。

Conclusion: 该框架使模型能够自主调整思维链长度，压缩已掌握问题的推理过程，扩展困难问题的推理过程，同时提升准确性和效率。

Abstract: Large Reasoning Models (LRMs) have demonstrated impressive capabilities but
suffer from cognitive inefficiencies like ``overthinking'' simple problems and
``underthinking'' complex ones. While existing methods that use supervised
fine-tuning~(SFT) or reinforcement learning~(RL) with token-length rewards can
improve efficiency, they often do so at the cost of accuracy. This paper
introduces \textbf{DeepCompress}, a novel framework that simultaneously
enhances both the accuracy and efficiency of LRMs. We challenge the prevailing
approach of consistently favoring shorter reasoning paths, showing that longer
responses can contain a broader range of correct solutions for difficult
problems. DeepCompress employs an adaptive length reward mechanism that
dynamically classifies problems as ``Simple'' or ``Hard'' in real-time based on
the model's evolving capability. It encourages shorter, more efficient
reasoning for ``Simple'' problems while promoting longer, more exploratory
thought chains for ``Hard'' problems. This dual-reward strategy enables the
model to autonomously adjust its Chain-of-Thought (CoT) length, compressing
reasoning for well-mastered problems and extending it for those it finds
challenging. Experimental results on challenging mathematical benchmarks show
that DeepCompress consistently outperforms baseline methods, achieving superior
accuracy while significantly improving token efficiency.

</details>


### [13] [Validity Is What You Need](https://arxiv.org/abs/2510.27628)
*Sebastian Benthall,Andrew Clark*

Main category: cs.AI

TL;DR: 本文提出了一个新的现实主义定义，将Agentic AI视为在复杂企业环境中自主工作的软件交付机制，类似于SaaS。作者强调Agentic AI主要是应用而非基础模型，其成功取决于终端用户和主要利益相关者的验证。


<details>
  <summary>Details</summary>
Motivation: 当前对Agentic AI的定义存在不足，需要基于实际应用场景提出更准确的定义。同时，由于Agentic AI主要是应用系统，其验证方法应与基础模型评估方法区分开来。

Method: 通过比较其他Agentic AI定义，提出了现实主义的定义方法，强调Agentic AI作为软件交付机制的特性。讨论了验证工具和技术的需求差异。

Result: 发现良好的验证措施可以使基础模型被更简单、快速和可解释的模型替代。Agentic AI的成功关键在于有效性验证，而LLMs只是实现这一目标的可能选项之一。

Conclusion: Agentic AI的核心是有效性验证，而非特定的技术实现。在适当的验证机制下，基础模型可以被更优化的替代方案取代，LLMs只是实现Agentic AI的众多可能性之一。

Abstract: While AI agents have long been discussed and studied in computer science,
today's Agentic AI systems are something new. We consider other definitions of
Agentic AI and propose a new realist definition. Agentic AI is a software
delivery mechanism, comparable to software as a service (SaaS), which puts an
application to work autonomously in a complex enterprise setting. Recent
advances in large language models (LLMs) as foundation models have driven
excitement in Agentic AI. We note, however, that Agentic AI systems are
primarily applications, not foundations, and so their success depends on
validation by end users and principal stakeholders. The tools and techniques
needed by the principal users to validate their applications are quite
different from the tools and techniques used to evaluate foundation models.
Ironically, with good validation measures in place, in many cases the
foundation models can be replaced with much simpler, faster, and more
interpretable models that handle core logic. When it comes to Agentic AI,
validity is what you need. LLMs are one option that might achieve it.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [14] [Proxy Variable in OECD Database: Application of Parametric Quantile Regression and Median Based Unit Rayleigh Distribution](https://arxiv.org/abs/2510.26811)
*Iman Mohamed Attia*

Main category: stat.AP

TL;DR: 本文深入探讨了作者先前提出的基于中位数的单位瑞利分布，该分布专门用于进行分位数回归分析，帮助研究人员从实际数据应用中获取有价值的见解。


<details>
  <summary>Details</summary>
Motivation: 开发MBUR分布的目的是为了连接高级统计理论与数据分析中的有意义结果，通过分位数回归分析为实际数据应用提供新的统计工具。

Method: 作者使用OECD数据，采用参数化MBUR分位数回归方法，其中响应变量服从MBUR分布。

Result: 作者有效证明了MBUR分布的可行优势，展示了其在数据分析中的潜力。

Conclusion: MBUR分布为分位数回归分析提供了一种创新的方法，能够将先进的统计理论与实际数据应用有效连接起来。

Abstract: This paper presents an in-depth exploration of the innovative Median-based
unit Rayleigh (MBUR) distribution, previously introduced by the author. This
new approach is specifically designed for conducting quantile regression
analysis, enabling researchers to gain valuable insights into real-world data
applications. The author effectively demonstrates the feasible advantage of the
MBUR distribution, highlighting its potential to connect advanced statistical
theory with meaningful results in data analysis. The author utilized OECD data
in employing the parametric MBUR quantile regression using the response
variables which are distributed as MBUR.

</details>


### [15] [Towards Gaussian processes modelling to study the late effects of radiotherapy in children and young adults with brain tumours](https://arxiv.org/abs/2510.26814)
*Angela Davey,Arthur Leroy,Eliana Vasquez Osorio,Kate Vaughan,Peter Clayton,Marcel van Herk,Mauricio A Alvarez,Martin McCabe,Marianne Aznar*

Main category: stat.AP

TL;DR: 本研究探讨了高斯过程建模在儿童癌症幸存者IGF-1监测中的应用，以解决常规纵向数据稀疏和不规则的问题。


<details>
  <summary>Details</summary>
Motivation: 儿童癌症幸存者需要终身监测放疗副作用，但常规监测数据通常稀疏、不规则且不准确，现有方法往往孤立分析测量值或使用简单关系填补缺失时间点。

Method: 使用高斯过程建模进行基于群体和个体的预测，以胰岛素样生长因子1测量值作为测试案例，训练数据包含23名患者的中位4个时间点。

Result: 识别出与文献报道值范围一致的趋势；在8个测试案例中，两种方法的个体预测平均均方根误差分别为31.9 ng/ml和27.4 ng/ml。

Conclusion: 高斯过程建模可能克服常规纵向数据的局限性，促进放疗晚期效应的分析。

Abstract: Survivors of childhood cancer need lifelong monitoring for side effects from
radiotherapy. However, longitudinal data from routine monitoring is often
infrequently and irregularly sampled, and subject to inaccuracies. Due to this,
measurements are often studied in isolation, or simple relationships (e.g.,
linear) are used to impute missing timepoints. In this study, we investigated
the potential role of Gaussian Processes (GP) modelling to make
population-based and individual predictions, using insulin-like growth factor 1
(IGF-1) measurements as a test case. With training data of 23 patients with a
median (range) of 4 (1-16) timepoints we identified a trend within the range of
literature reported values. In addition, with 8 test cases, individual
predictions were made with an average root mean squared error of 31.9 (10.1 -
62.3) ng/ml and 27.4 (0.02 - 66.1) ng/ml for two approaches. GP modelling may
overcome limitations of routine longitudinal data and facilitate analysis of
late effects of radiotherapy.

</details>


### [16] [Systematic Absence of Low-Confidence Nighttime Fire Detections in VIIRS Active Fire Product: Evidence of Undocumented Algorithmic Filtering](https://arxiv.org/abs/2510.26816)
*Rohit Rajendra Dhage*

Main category: stat.AP

TL;DR: VIIRS活跃火产品在夜间观测中完全缺失低置信度分类，这是算法约束而非地球物理现象，影响了27.9%的火点检测，对火灾风险评估和日夜间检测比较有重要影响。


<details>
  <summary>Details</summary>
Motivation: VIIRS活跃火产品被广泛用于全球火灾监测，但其置信度分类方案存在未记录的系统性模式，需要揭示这一算法约束及其对火灾监测的影响。

Method: 通过分析21,540,921个火点检测数据，使用机器学习反向工程、自助模拟和时空分析，结合亮度温度分析来确认模式性质。

Result: 在6,007,831个夜间火点中，零个被分类为低置信度，而统计独立性下预期应有696,908个。该模式在全球范围内持续存在，夜间温度低于约295K的火点可能被完全排除而非标记为低置信度。

Conclusion: VIIRS算法存在未记录的约束，影响了大量火点检测的置信度分类，建议在用户指南中明确记录此约束，并为受影响的分析制定重新处理策略。

Abstract: The Visible Infrared Imaging Radiometer Suite (VIIRS) active fire product is
widely used for global fire monitoring, yet its confidence classification
scheme exhibits an undocumented systematic pattern. Through analysis of
21,540,921 fire detections spanning one year (January 2023 - January 2024), I
demonstrate a complete absence of low-confidence classifications during
nighttime observations. Of 6,007,831 nighttime fires, zero were classified as
low confidence, compared to an expected 696,908 under statistical independence
(chi-squared = 1,474,795, p < 10^-15, Z = -833). This pattern persists globally
across all months, latitude bands, and both NOAA-20 and Suomi-NPP satellites.
Machine learning reverse-engineering (88.9% accuracy), bootstrap simulation
(1,000 iterations), and spatial-temporal analysis confirm this is an
algorithmic constraint rather than a geophysical phenomenon. Brightness
temperature analysis reveals nighttime fires below approximately 295K are
likely excluded entirely rather than flagged as low-confidence, while daytime
fires show normal confidence distributions. This undocumented behavior affects
27.9% of all VIIRS fire detections and has significant implications for fire
risk assessment, day-night detection comparisons, confidence-weighted analyses,
and any research treating confidence levels as uncertainty metrics. I recommend
explicit documentation of this algorithmic constraint in VIIRS user guides and
reprocessing strategies for affected analyses.

</details>


### [17] [Functional Analysis of Loss-development Patterns in P&C Insurance](https://arxiv.org/abs/2510.27204)
*Arthur Charpentier,Qiheng Guo,Mike Ludkovski*

Main category: stat.AP

TL;DR: 本文使用函数数据分析方法分析NAIC Schedule P损失三角形中的损失发展模式，基于3300多条工人赔偿保险线的增量损失比率曲线，通过函数数据深度识别异常曲线和模式差异，并开发了基于偏最小二乘回归和函数自举的概率预测框架。


<details>
  <summary>Details</summary>
Motivation: 研究工人赔偿保险线的损失发展模式，识别公司特定协变量下的相似性和差异性，以及异常ILR曲线，为开发更准确的概率预测模型提供基础。

Method: 采用函数数据分析方法，基于函数数据深度进行探索性分析，然后提出基于偏最小二乘回归PCA得分的函数模型来完成部分发展的ILR曲线，并结合函数自举来量化未来ILR不确定性。

Result: 该方法相比链梯法具有更好的概率评分，能够提供准确的功能性预测区间，在损失预测方面表现更优。

Conclusion: 函数数据分析方法在保险损失预测中具有显著优势，能够有效识别发展模式差异和异常情况，并提供更准确的不确定性量化。

Abstract: We analyze loss development in NAIC Schedule P loss triangles using
functional data analysis methods. Adopting the functional viewpoint, our
dataset comprises 3300+ curves of incremental loss ratios (ILR) of workers'
compensation lines over 24 accident years. Relying on functional data depth, we
first study similarities and differences in development patterns based on
company-specific covariates, as well as identify anomalous ILR curves.
  The exploratory findings motivate the probabilistic forecasting framework
developed in the second half of the paper. We propose a functional model to
complete partially developed ILR curves based on partial least squares
regression of PCA scores. Coupling the above with functional bootstrapping
allows us to quantify future ILR uncertainty jointly across all future lags. We
demonstrate that our method has much better probabilistic scores relative to
Chain Ladder and in particular can provide accurate functional predictive
intervals.

</details>


### [18] [Bayesian Source Apportionment of Spatio-temporal air pollution data](https://arxiv.org/abs/2510.27551)
*Michela Frigeri,Veronica Berrocal,Alessandra Guglielmi*

Main category: stat.AP

TL;DR: 提出了一种贝叶斯源解析模型，能够估计污染源数量并考虑污染物浓度的时空依赖性，应用于加州PM2.5数据识别出3个主要污染源。


<details>
  <summary>Details</summary>
Motivation: 确定PM2.5的来源对于设计和实施有针对性的空气污染缓解策略至关重要，需要解决源解析问题并考虑时空依赖性。

Method: 采用贝叶斯模型和潜在功能因子模型，将六种PM2.5物种的对数浓度表达为未知数量污染源的时空变化排放的线性组合，通过引入源特异性收缩参数来估计源数量。

Result: 模拟数据验证了模型能够准确检索真实源数量并可靠估计潜在功能因子，加州PM2.5数据应用识别出3个主要污染源。

Conclusion: 所提出的贝叶斯源解析模型能够有效估计污染源数量并考虑时空依赖性，为空气污染治理提供可靠的分析工具。

Abstract: Understanding the sources that contribute to fine particulate matter
(PM$_{2.5}$) is of crucial importance for designing and implementing targeted
air pollution mitigation strategies. Determining what factors contribute to a
pollutant's concentration goes under the name of source apportionment and it is
a problem long studied by atmospheric scientists and statisticians alike. In
this paper, we propose a Bayesian model for source apportionment, that advances
the literature on source apportionment by allowing estimation of the number of
sources and accounting for spatial and temporal dependence in the observed
pollutants' concentrations. Taking as example observations of six species of
fine particulate matter observed over the course of a year, we present a latent
functional factor model that expresses the space-time varying observations of
log concentrations of the six pollutant as a linear combination of space-time
varying emissions produced by an unknown number of sources each multiplied by
the corresponding source's relative contribution to the pollutant. Estimation
of the number of sources is achieved by introducing source-specific shrinkage
parameters. Application of the model to simulated data showcases its ability to
retrieve the true number of sources and to reliably estimate the functional
latent factors, whereas application to PM$_{2.5}$ speciation data in California
identifies 3 major sources for the six PM$_{2.5}$ species.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [19] [Decreasing Entropic Regularization Averaged Gradient for Semi-Discrete Optimal Transport](https://arxiv.org/abs/2510.27340)
*Ferdinand Genans,Antoine Godichon-Baggioni,François-Xavier Vialard,Olivier Wintenberger*

Main category: stat.ML

TL;DR: 本文提出DRAG算法，通过自适应降低熵正则化来加速半离散最优传输问题的求解，相比固定正则化方案获得更好的收敛性能。


<details>
  <summary>Details</summary>
Motivation: 熵正则化虽然能加速最优传输问题的求解，但会引入偏差。为了在保持加速效果的同时减少偏差，需要开发能够自适应降低正则化的算法。

Method: 提出DRAG（递减熵正则化平均梯度）算法，这是一种随机梯度下降方法，其中正则化参数随着优化步数的增加而递减。

Result: 理论分析表明DRAG相比固定正则化方案具有优势，在OT成本和势估计方面达到无偏的O(1/t)样本和迭代复杂度，在OT映射方面达到O(1/√t)收敛率。

Conclusion: 数值实验验证了DRAG的有效性，表明递减正则化策略在半离散最优传输问题中确实能加速收敛并减少偏差。

Abstract: Adding entropic regularization to Optimal Transport (OT) problems has become
a standard approach for designing efficient and scalable solvers. However,
regularization introduces a bias from the true solution. To mitigate this bias
while still benefiting from the acceleration provided by regularization, a
natural solver would adaptively decrease the regularization as it approaches
the solution. Although some algorithms heuristically implement this idea, their
theoretical guarantees and the extent of their acceleration compared to using a
fixed regularization remain largely open. In the setting of semi-discrete OT,
where the source measure is continuous and the target is discrete, we prove
that decreasing the regularization can indeed accelerate convergence. To this
end, we introduce DRAG: Decreasing (entropic) Regularization Averaged Gradient,
a stochastic gradient descent algorithm where the regularization decreases with
the number of optimization steps. We provide a theoretical analysis showing
that DRAG benefits from decreasing regularization compared to a fixed scheme,
achieving an unbiased $\mathcal{O}(1/t)$ sample and iteration complexity for
both the OT cost and the potential estimation, and a $\mathcal{O}(1/\sqrt{t})$
rate for the OT map. Our theoretical findings are supported by numerical
experiments that validate the effectiveness of DRAG and highlight its practical
advantages.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [20] [Layer of Truth: Probing Belief Shifts under Continual Pre-Training Poisoning](https://arxiv.org/abs/2510.26829)
*Svetlana Churina,Niranjan Chebrolu,Kokil Jaidka*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models (LLMs) continually evolve through pre-training on
ever-expanding web data, but this adaptive process also exposes them to subtle
forms of misinformation. While prior work has explored data poisoning during
static pre-training, the effects of such manipulations under continual
pre-training remain largely unexplored. Drawing inspiration from the illusory
truth effect in human cognition - where repeated exposure to falsehoods
increases belief in their accuracy - we ask whether LLMs exhibit a similar
vulnerability. We investigate whether repeated exposure to false but
confidently stated facts can shift a model's internal representation away from
the truth.
  We introduce Layer of Truth, a framework and dataset for probing belief
dynamics in continually trained LLMs. By injecting controlled amounts of
poisoned data and probing intermediate representations across checkpoints,
model scales, and question types, we quantify when and how factual beliefs
shift. Our findings reveal that even minimal exposure can induce persistent
representational drift in well-established facts, with susceptibility varying
across layers and model sizes. These results highlight an overlooked
vulnerability of continually updated LLMs: their capacity to internalize
misinformation analogously to humans, underscoring the need for robust
monitoring of factual integrity during model updates.

</details>


### [21] [CAS-Spec: Cascade Adaptive Self-Speculative Decoding for On-the-Fly Lossless Inference Acceleration of LLMs](https://arxiv.org/abs/2510.26843)
*Zhiyuan Ning,Jiawei Shao,Ruge Xu,Xinfei Guo,Jun Zhang,Chi Zhang,Xuelong Li*

Main category: cs.LG

TL;DR: 提出了一种新颖的级联自适应自推测解码方法(CAS-Spec)，通过动态可切换推理加速策略构建推测草稿模型，并引入动态树级联算法自适应路由多级草稿模型和分配草稿长度，实现了比现有方法更快的推理加速。


<details>
  <summary>Details</summary>
Motivation: 现有的自推测解码方法虽然集成方便但加速效果不如依赖专门训练的方法，而级联多个草稿模型的方法虽然能提供更好的加速和灵活性，但训练多个模型的成本限制了其实际应用。

Method: CAS-Spec方法利用动态可切换推理加速策略（包括层稀疏性和激活量化）构建推测草稿模型，并提出了动态树级联算法来自适应路由多级草稿模型和分配草稿长度。

Result: CAS-Spec方法相比现有自推测解码方法实现了最先进的加速效果，在多种LLM和数据集上相比自回归解码平均加速1.1倍到2.3倍。DyTC算法相比级联基线和树状基线算法分别提高了47%和48%的平均加速效果。

Conclusion: CAS-Spec方法可以轻松集成到大多数现有LLM中，随着自推测解码技术的持续发展，具有进一步加速的潜力。

Abstract: Speculative decoding has become a widely adopted as an effective technique
for lossless inference acceleration when deploying large language models
(LLMs). While on-the-fly self-speculative methods offer seamless integration
and broad utility, they often fall short of the speed gains achieved by methods
relying on specialized training. Cascading a hierarchy of draft models promises
further acceleration and flexibility, but the high cost of training multiple
models has limited its practical application. In this paper, we propose a novel
Cascade Adaptive Self-Speculative Decoding (CAS-Spec) method which constructs
speculative draft models by leveraging dynamically switchable inference
acceleration (DSIA) strategies, including layer sparsity and activation
quantization. Furthermore, traditional vertical and horizontal cascade
algorithms are inefficient when applied to self-speculative decoding methods.
We introduce a Dynamic Tree Cascade (DyTC) algorithm that adaptively routes the
multi-level draft models and assigns the draft lengths, based on the heuristics
of acceptance rates and latency prediction. Our CAS-Spec method achieves
state-of-the-art acceleration compared to existing on-the-fly speculative
decoding methods, with an average speedup from $1.1\times$ to $2.3\times$ over
autoregressive decoding across various LLMs and datasets. DyTC improves the
average speedup by $47$\% and $48$\% over cascade-based baseline and tree-based
baseline algorithms, respectively. CAS-Spec can be easily integrated into most
existing LLMs and holds promising potential for further acceleration as
self-speculative decoding techniques continue to evolve.

</details>


### [22] [Soft Task-Aware Routing of Experts for Equivariant Representation Learning](https://arxiv.org/abs/2510.27222)
*Jaebyeong Jeon,Hyeonseo Jang,Jy-yong Sohn,Kibok Lee*

Main category: cs.LG

TL;DR: 提出了Soft Task-Aware Routing (STAR)方法，通过将投影头建模为专家来减少不变和等变表示学习中的冗余特征学习，提高模型效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常使用独立的投影头分别学习不变和等变表示，但忽视了它们之间的共享信息，导致冗余特征学习和模型容量利用不足。

Method: 引入STAR路由策略，将投影头建模为专家，使其专门捕获共享或任务特定信息，从而减少冗余特征学习。

Result: 实验显示在不变和等变嵌入之间具有较低的正则相关性，并在多种迁移学习任务中取得一致改进。

Conclusion: STAR方法通过建模投影头为专家，有效减少了不变和等变表示学习中的冗余，提高了模型效率和性能。

Abstract: Equivariant representation learning aims to capture variations induced by
input transformations in the representation space, whereas invariant
representation learning encodes semantic information by disregarding such
transformations. Recent studies have shown that jointly learning both types of
representations is often beneficial for downstream tasks, typically by
employing separate projection heads. However, this design overlooks information
shared between invariant and equivariant learning, which leads to redundant
feature learning and inefficient use of model capacity. To address this, we
introduce Soft Task-Aware Routing (STAR), a routing strategy for projection
heads that models them as experts. STAR induces the experts to specialize in
capturing either shared or task-specific information, thereby reducing
redundant feature learning. We validate this effect by observing lower
canonical correlations between invariant and equivariant embeddings.
Experimental results show consistent improvements across diverse transfer
learning tasks. The code is available at https://github.com/YonseiML/star.

</details>


### [23] [Predicting Household Water Consumption Using Satellite and Street View Images in Two Indian Cities](https://arxiv.org/abs/2510.26957)
*Qiao Wang,Joseph George*

Main category: cs.LG

TL;DR: 该研究利用公开可用的卫星图像、Google街景分割和简单的地理空间数据来预测印度Hubballi-Dharwad地区的家庭用水量，避免了传统调查方法的高成本和耗时问题。


<details>
  <summary>Details</summary>
Motivation: 在快速城市化地区，传统的水资源使用监测方法成本高昂且耗时，需要寻找更高效、低成本的替代方案来获取可靠的家庭用水量数据。

Method: 比较了四种方法：调查特征（基准）、CNN嵌入（卫星、GSV、组合）以及GSV语义地图加辅助数据。在序数分类框架下，结合GSV分割和遥感协变量进行预测。

Result: GSV分割加遥感协变量的方法达到了0.55的准确率，接近基于调查模型的0.59准确率。在家庭用水量分布的极端值处具有高精度，但中间类别存在混淆。

Conclusion: 开放获取图像结合最少的地理空间数据，为城市分析中获取可靠的家庭用水量估计提供了一种有前景的替代传统调查的方法。

Abstract: Monitoring household water use in rapidly urbanizing regions is hampered by
costly, time-intensive enumeration methods and surveys. We investigate whether
publicly available imagery-satellite tiles, Google Street View (GSV)
segmentation-and simple geospatial covariates (nightlight intensity, population
density) can be utilized to predict household water consumption in
Hubballi-Dharwad, India. We compare four approaches: survey features
(benchmark), CNN embeddings (satellite, GSV, combined), and GSV semantic maps
with auxiliary data. Under an ordinal classification framework, GSV
segmentation plus remote-sensing covariates achieves 0.55 accuracy for water
use, approaching survey-based models (0.59 accuracy). Error analysis shows high
precision at extremes of the household water consumption distribution, but
confusion among middle classes is due to overlapping visual proxies. We also
compare and contrast our estimates for household water consumption to that of
household subjective income. Our findings demonstrate that open-access imagery,
coupled with minimal geospatial data, offers a promising alternative to
obtaining reliable household water consumption estimates using surveys in urban
analytics.

</details>


### [24] [Fine-Grained Iterative Adversarial Attacks with Limited Computation Budget](https://arxiv.org/abs/2510.26981)
*Zhichao Hou,Weizhi Gao,Xiaorui Liu*

Main category: cs.LG

TL;DR: 该论文提出了一种在有限计算预算下最大化对抗攻击效果的方法，通过细粒度控制机制选择性地重新计算层激活，在相同成本下优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决在有限计算资源下如何最大化迭代对抗攻击强度的问题，因为简单减少攻击迭代次数会显著降低攻击效果。

Method: 提出细粒度控制机制，在迭代和层级别上选择性地重新计算层激活，以在约束预算内实现可达到的攻击效果。

Result: 大量实验表明，该方法在相同成本下始终优于现有基线方法；当集成到对抗训练中时，仅使用原始预算的30%就能达到相当的性能。

Conclusion: 该方法为AI安全研究提供了在有限计算资源下有效进行对抗攻击的有效解决方案，显著提高了计算效率。

Abstract: This work tackles a critical challenge in AI safety research under limited
compute: given a fixed computation budget, how can one maximize the strength of
iterative adversarial attacks? Coarsely reducing the number of attack
iterations lowers cost but substantially weakens effectiveness. To fulfill the
attainable attack efficacy within a constrained budget, we propose a
fine-grained control mechanism that selectively recomputes layer activations
across both iteration-wise and layer-wise levels. Extensive experiments show
that our method consistently outperforms existing baselines at equal cost.
Moreover, when integrated into adversarial training, it attains comparable
performance with only 30% of the original budget.

</details>


### [25] [HADSF: Aspect Aware Semantic Control for Explainable Recommendation](https://arxiv.org/abs/2510.26994)
*Zheng Nie,Peijie Sun*

Main category: cs.LG

TL;DR: HADSF是一个双阶段语义框架，通过自适应选择构建紧凑的方面词汇表，然后进行词汇引导的约束提取，解决了LLM在评论推荐系统中的冗余表示、幻觉度量和成本质量权衡问题。


<details>
  <summary>Details</summary>
Motivation: 解决当前基于LLM的评论推荐系统存在的三个问题：(i)无范围控制的自由形式评论挖掘导致冗余和噪声表示，(ii)缺乏将LLM幻觉与下游有效性联系的原则性度量，(iii)未探索不同模型规模下的成本质量权衡。

Method: 提出超自适应双阶段语义框架(HADSF)，第一阶段通过自适应选择诱导紧凑的语料级方面词汇表，第二阶段执行词汇引导的显式约束提取，获取结构化的方面-观点三元组。引入方面漂移率(ADR)和观点保真度率(OFR)来评估表示保真度。

Result: 在约300万条评论和1.5B-70B参数的LLM上的实验表明，HADSF集成到标准评分预测器中能持续降低预测误差，并使较小模型在代表性部署场景中达到竞争性能。发现了幻觉严重程度与评分预测误差之间的非单调关系。

Conclusion: HADSF为幻觉感知、LLM增强的可解释推荐提供了有效的解决方案，通过控制提取范围和引入保真度度量，在保持性能的同时降低了计算成本。

Abstract: Recent advances in large language models (LLMs) promise more effective
information extraction for review-based recommender systems, yet current
methods still (i) mine free-form reviews without scope control, producing
redundant and noisy representations, (ii) lack principled metrics that link LLM
hallucination to downstream effectiveness, and (iii) leave the cost-quality
trade-off across model scales largely unexplored. We address these gaps with
the Hyper-Adaptive Dual-Stage Semantic Framework (HADSF), a two-stage approach
that first induces a compact, corpus-level aspect vocabulary via adaptive
selection and then performs vocabulary-guided, explicitly constrained
extraction of structured aspect-opinion triples. To assess the fidelity of the
resulting representations, we introduce Aspect Drift Rate (ADR) and Opinion
Fidelity Rate (OFR) and empirically uncover a nonmonotonic relationship between
hallucination severity and rating prediction error. Experiments on
approximately 3 million reviews across LLMs spanning 1.5B-70B parameters show
that, when integrated into standard rating predictors, HADSF yields consistent
reductions in prediction error and enables smaller models to achieve
competitive performance in representative deployment scenarios. We release
code, data pipelines, and metric implementations to support reproducible
research on hallucination-aware, LLM-enhanced explainable recommendation. Code
is available at https://github.com/niez233/HADSF

</details>


### [26] [Gradient Descent as Loss Landscape Navigation: a Normative Framework for Deriving Learning Rules](https://arxiv.org/abs/2510.26997)
*John J. Vastola,Samuel J. Gershman,Kanaka Rajan*

Main category: cs.LG

TL;DR: 该论文提出了一个理论框架，将学习规则视为在（部分可观测的）损失景观中导航的策略，并将最优规则识别为相关最优控制问题的解。该框架统一解释了梯度下降、动量、自然梯度、非梯度规则和自适应优化器等学习现象。


<details>
  <summary>Details</summary>
Motivation: 传统上学习规则通常是假设而非推导的。该研究旨在理解为什么某些学习规则比其他规则效果更好，以及在什么假设下可以认为给定规则是最优的，为学习规则提供理论基础。

Method: 提出理论框架，将学习规则建模为在部分可观测损失景观中的导航策略，通过最优控制问题来识别最优规则。在不同假设下推导出各种已知学习规则。

Result: 该框架自然推导出多种已知学习规则：梯度下降（短视优化）、动量（长视规划）、自然梯度（考虑参数空间几何）、非梯度规则（部分可控性）、Adam等自适应优化器（损失景观形状的在线贝叶斯推断）。

Conclusion: 通过统一这些现象于单一目标下，该框架阐明了学习的计算结构，并为设计自适应算法提供了原则性基础。持续学习策略如权重重置可被理解为对任务不确定性的最优响应。

Abstract: Learning rules -- prescriptions for updating model parameters to improve
performance -- are typically assumed rather than derived. Why do some learning
rules work better than others, and under what assumptions can a given rule be
considered optimal? We propose a theoretical framework that casts learning
rules as policies for navigating (partially observable) loss landscapes, and
identifies optimal rules as solutions to an associated optimal control problem.
A range of well-known rules emerge naturally within this framework under
different assumptions: gradient descent from short-horizon optimization,
momentum from longer-horizon planning, natural gradients from accounting for
parameter space geometry, non-gradient rules from partial controllability, and
adaptive optimizers like Adam from online Bayesian inference of loss landscape
shape. We further show that continual learning strategies like weight resetting
can be understood as optimal responses to task uncertainty. By unifying these
phenomena under a single objective, our framework clarifies the computational
structure of learning and offers a principled foundation for designing adaptive
algorithms.

</details>


### [27] [A Framework for Fair Evaluation of Variance-Aware Bandit Algorithms](https://arxiv.org/abs/2510.27001)
*Elise Wolf*

Main category: cs.LG

TL;DR: 本文提出了一个可复现的多臂老虎机算法评估框架，系统比较了8种经典和方差感知算法，发现在高不确定性环境中方差感知算法表现更好，而在可分离场景中经典算法表现相当或更优。


<details>
  <summary>Details</summary>
Motivation: 多臂老虎机算法评估缺乏标准化条件和可复现性，特别是方差感知扩展算法的性能高度依赖环境条件，需要可靠的方法来观察算法性能差异。

Method: 开发了Bandit Playground代码库，包含明确定义的实验设置、多种性能指标（奖励、遗憾、奖励分布、风险价值和动作最优性）以及支持一致透明分析的交互式评估界面。

Result: 方差感知算法在高不确定性环境中具有优势，特别是在臂奖励差异细微的情况下；而经典算法在更可分离的场景或经过充分调优时表现相当或更好。

Conclusion: 贡献包括：(1) 系统评估MAB算法的框架；(2) 方差感知方法优于经典对应方法的条件洞察。

Abstract: Multi-armed bandit (MAB) problems serve as a fundamental building block for
more complex reinforcement learning algorithms. However, evaluating and
comparing MAB algorithms remains challenging due to the lack of standardized
conditions and replicability. This is particularly problematic for
variance-aware extensions of classical methods like UCB, whose performance can
heavily depend on the underlying environment. In this study, we address how
performance differences between bandit algorithms can be reliably observed, and
under what conditions variance-aware algorithms outperform classical ones. We
present a reproducible evaluation designed to systematically compare eight
classical and variance-aware MAB algorithms. The evaluation framework,
implemented in our Bandit Playground codebase, features clearly defined
experimental setups, multiple performance metrics (reward, regret, reward
distribution, value-at-risk, and action optimality), and an interactive
evaluation interface that supports consistent and transparent analysis. We show
that variance-aware algorithms can offer advantages in settings with high
uncertainty where the difficulty arises from subtle differences between arm
rewards. In contrast, classical algorithms often perform equally well or better
in more separable scenarios or if fine-tuned extensively. Our contributions are
twofold: (1) a framework for systematic evaluation of MAB algorithms, and (2)
insights into the conditions under which variance-aware approaches outperform
their classical counterparts.

</details>


### [28] [Jasmine: A Simple, Performant and Scalable JAX-based World Modeling Codebase](https://arxiv.org/abs/2510.27002)
*Mihir Mahajan,Alfred Nguyen,Franz Srambical,Stefan Bauer*

Main category: cs.LG

TL;DR: Jasmine是一个基于JAX的高性能世界建模代码库，支持从单主机到数百个加速器的扩展，在CoinRun案例研究中比现有开源实现快一个数量级。


<details>
  <summary>Details</summary>
Motivation: 世界模型被认为是解决机器人等领域数据稀缺问题的途径，但目前开源的世界建模训练基础设施仍处于初级阶段。

Method: 开发了Jasmine代码库，在数据加载、训练和检查点等方面进行了性能优化，保证完全可复现的训练并支持多种分片配置。

Result: Jasmine在CoinRun案例研究中实现了比先前开源实现快一个数量级的复现速度，并与大规模数据集配对建立了严格的基准测试流程。

Conclusion: Jasmine为世界建模提供了高性能、可扩展的开源训练基础设施，支持跨模型家族和架构消融的严格基准测试。

Abstract: While world models are increasingly positioned as a pathway to overcoming
data scarcity in domains such as robotics, open training infrastructure for
world modeling remains nascent. We introduce Jasmine, a performant JAX-based
world modeling codebase that scales from single hosts to hundreds of
accelerators with minimal code changes. Jasmine achieves an order-of-magnitude
faster reproduction of the CoinRun case study compared to prior open
implementations, enabled by performance optimizations across data loading,
training and checkpointing. The codebase guarantees fully reproducible training
and supports diverse sharding configurations. By pairing Jasmine with curated
large-scale datasets, we establish infrastructure for rigorous benchmarking
pipelines across model families and architectural ablations.

</details>


### [29] [Enhancing Sentiment Classification with Machine Learning and Combinatorial Fusion](https://arxiv.org/abs/2510.27014)
*Sean Patten,Pin-Yu Chen,Christina Schweikert,D. Frank Hsu*

Main category: cs.LG

TL;DR: 本文提出了一种基于组合融合分析(CFA)的情感分类新方法，通过整合多种机器学习模型，在IMDB情感分析数据集上达到了97.072%的最先进准确率。


<details>
  <summary>Details</summary>
Motivation: 传统方法通常通过扩大单个模型的规模来提高性能，但这种方法计算资源消耗大。本文旨在利用模型间的认知多样性，以更高效的方式提升情感分类性能。

Method: 应用组合融合分析(CFA)方法，使用秩-得分特征函数量化模型间的差异性，并战略性地结合它们的预测结果。具体实现了基于RoBERTa架构的Transformer模型与传统机器学习模型（随机森林、SVM、XGBoost）的组合。

Result: 在IMDB情感分析数据集上达到了97.072%的准确率，超过了传统集成方法，证明了CFA方法在有效利用模型多样性方面的优势。

Conclusion: 组合融合分析提供了一种计算效率更高的情感分类方法，通过战略性地整合多样化模型，能够在不大幅增加计算资源的情况下实现最先进的性能。

Abstract: This paper presents a novel approach to sentiment classification using the
application of Combinatorial Fusion Analysis (CFA) to integrate an ensemble of
diverse machine learning models, achieving state-of-the-art accuracy on the
IMDB sentiment analysis dataset of 97.072\%. CFA leverages the concept of
cognitive diversity, which utilizes rank-score characteristic functions to
quantify the dissimilarity between models and strategically combine their
predictions. This is in contrast to the common process of scaling the size of
individual models, and thus is comparatively efficient in computing resource
use. Experimental results also indicate that CFA outperforms traditional
ensemble methods by effectively computing and employing model diversity. The
approach in this paper implements the combination of a transformer-based model
of the RoBERTa architecture with traditional machine learning models, including
Random Forest, SVM, and XGBoost.

</details>


### [30] [Consistency Training Helps Stop Sycophancy and Jailbreaks](https://arxiv.org/abs/2510.27062)
*Alex Irpan,Alexander Matt Turner,Mark Kurzeja,David K. Elson,Rohin Shah*

Main category: cs.LG

TL;DR: 本文提出一致性训练方法，通过让模型对提示中的无关线索保持响应不变性，来减少LLM的谄媚行为和越狱攻击。


<details>
  <summary>Details</summary>
Motivation: LLM的事实性和拒绝训练容易被简单的提示修改所破坏，模型经常表现出谄媚行为或满足不适当的请求。

Method: 采用两种一致性训练方法：基于外部输出的BCT和基于内部激活的ACT，通过数据增强使模型在不同提示变体下保持相同行为。

Result: 两种方法都降低了Gemini 2.5 Flash对无关线索的敏感性，BCT在减少越狱方面表现更好，且不会降低模型能力。

Conclusion: 某些对齐问题应被视为一致性问题而非最优响应问题，BCT可以简化训练流程，减少对静态数据集的依赖。

Abstract: An LLM's factuality and refusal training can be compromised by simple changes
to a prompt. Models often adopt user beliefs (sycophancy) or satisfy
inappropriate requests which are wrapped within special text (jailbreaking). We
explore \emph{consistency training}, a self-supervised paradigm that teaches a
model to be invariant to certain irrelevant cues in the prompt. Instead of
teaching the model what exact response to give on a particular prompt, we aim
to teach the model to behave identically across prompt data augmentations (like
adding leading questions or jailbreak text). We try enforcing this invariance
in two ways: over the model's external outputs (\emph{Bias-augmented
Consistency Training} (BCT) from Chua et al. [2025]) and over its internal
activations (\emph{Activation Consistency Training} (ACT), a method we
introduce). Both methods reduce Gemini 2.5 Flash's susceptibility to irrelevant
cues. Because consistency training uses responses from the model itself as
training data, it avoids issues that arise from stale training data, such as
degrading model capabilities or enforcing outdated response guidelines. While
BCT and ACT reduce sycophancy equally well, BCT does better at jailbreak
reduction. We think that BCT can simplify training pipelines by removing
reliance on static datasets. We argue that some alignment problems are better
viewed not in terms of optimal responses, but rather as consistency issues.

</details>


### [31] [MLPerf Automotive](https://arxiv.org/abs/2510.27065)
*Radoyeh Shojaei,Predrag Djurdjevic,Mostafa El-Khamy,James Goel,Kasper Mecklenburg,John Owens,Pınar Muyan-Özçelik,Tom St. John,Jinho Suh,Arjun Suresh*

Main category: cs.LG

TL;DR: MLPerf Automotive是首个用于评估汽车系统中AI加速机器学习系统的标准化公开基准，由MLCommons和自动驾驶车辆计算联盟合作开发，专注于汽车感知任务（2D目标检测、2D语义分割、3D目标检测），提供延迟和准确性指标。


<details>
  <summary>Details</summary>
Motivation: 现有基准套件无法满足汽车工作负载的独特约束（如安全性和实时处理需求），需要专门针对汽车机器学习系统的标准化性能评估方法。

Method: 开发标准化基准框架，包括任务选择、参考模型和提交规则，提供延迟和准确性指标以及评估协议，确保跨不同硬件平台和软件实现的一致性和可重复性性能比较。

Result: 首个基准迭代包含汽车感知任务，建立了完整的基准设计方法论，并完成了首轮基准提交，解决了数据集获取和参考实现开发的工程挑战。

Conclusion: MLPerf Automotive填补了汽车机器学习系统标准化评估的空白，为行业提供了可靠的性能比较工具，代码已在GitHub开源。

Abstract: We present MLPerf Automotive, the first standardized public benchmark for
evaluating Machine Learning systems that are deployed for AI acceleration in
automotive systems. Developed through a collaborative partnership between
MLCommons and the Autonomous Vehicle Computing Consortium, this benchmark
addresses the need for standardized performance evaluation methodologies in
automotive machine learning systems. Existing benchmark suites cannot be
utilized for these systems since automotive workloads have unique constraints
including safety and real-time processing that distinguish them from the
domains that previously introduced benchmarks target. Our benchmarking
framework provides latency and accuracy metrics along with evaluation protocols
that enable consistent and reproducible performance comparisons across
different hardware platforms and software implementations. The first iteration
of the benchmark consists of automotive perception tasks in 2D object
detection, 2D semantic segmentation, and 3D object detection. We describe the
methodology behind the benchmark design including the task selection, reference
models, and submission rules. We also discuss the first round of benchmark
submissions and the challenges involved in acquiring the datasets and the
engineering efforts to develop the reference implementations. Our benchmark
code is available at https://github.com/mlcommons/mlperf_automotive.

</details>


### [32] [Group-Sensitive Offline Contextual Bandits](https://arxiv.org/abs/2510.27123)
*Yihong Guo,Junjie Luo,Guodong Gao,Ritu Agarwal,Anqi Liu*

Main category: cs.LG

TL;DR: 本文研究离线上下文赌博机中的群体敏感公平约束，通过引入群体间奖励差异约束来减少策略学习过程中可能出现的奖励差异，同时保持整体性能。


<details>
  <summary>Details</summary>
Motivation: 离线策略优化在最大化总体期望奖励时可能无意中放大群体间的奖励差异，导致某些群体比其他群体从学习策略中获益更多，这在资源有限时引发公平性担忧。

Method: 提出一个约束离线策略优化框架，将群体间奖励差异约束引入基于梯度的离策略优化过程，使用双重稳健估计器改进训练期间群体奖励差异的估计，并提供策略优化的收敛保证。

Result: 在合成和真实世界数据集上的实证结果表明，该方法在保持竞争性整体性能的同时，有效减少了奖励差异。

Conclusion: 该方法成功解决了离线上下文赌博机中的公平性问题，通过约束群体间奖励差异，实现了公平性与性能的平衡。

Abstract: Offline contextual bandits allow one to learn policies from
historical/offline data without requiring online interaction. However, offline
policy optimization that maximizes overall expected rewards can unintentionally
amplify the reward disparities across groups. As a result, some groups might
benefit more than others from the learned policy, raising concerns about
fairness, especially when the resources are limited. In this paper, we study a
group-sensitive fairness constraint in offline contextual bandits, reducing
group-wise reward disparities that may arise during policy learning. We tackle
the following common-parity requirements: the reward disparity is constrained
within some user-defined threshold or the reward disparity should be minimized
during policy optimization. We propose a constrained offline policy
optimization framework by introducing group-wise reward disparity constraints
into an off-policy gradient-based optimization procedure. To improve the
estimation of the group-wise reward disparity during training, we employ a
doubly robust estimator and further provide a convergence guarantee for policy
optimization. Empirical results in synthetic and real-world datasets
demonstrate that our method effectively reduces reward disparities while
maintaining competitive overall performance.

</details>


### [33] [FairAD: Computationally Efficient Fair Graph Clustering via Algebraic Distance](https://arxiv.org/abs/2510.27136)
*Minh Phu Vuong,Young-Ju Lee,Iván Ojeda-Ruiz,Chul-Ho Lee*

Main category: cs.LG

TL;DR: 提出FairAD方法，一种计算高效的公平图聚类算法，通过代数距离构建亲和矩阵并施加公平约束，在保持聚类质量的同时比现有方法快40倍


<details>
  <summary>Details</summary>
Motivation: 由于机器学习模型对某些人口统计群体的不当行为日益受到关注，公平性概念引起社区重视，需要研究图聚类中的公平性问题

Method: 首先基于代数距离构建新的亲和矩阵以施加公平约束，然后对该矩阵进行图粗化过程找到代表节点对应k个簇，最后求解约束最小化问题获得公平聚类解

Result: 在改进的随机块模型和六个公共数据集上的实验表明，FairAD能够实现公平聚类，同时比最先进的公平图聚类算法快40倍

Conclusion: FairAD是一种计算高效的公平图聚类方法，能够有效平衡聚类质量和公平性要求

Abstract: Due to the growing concern about unsavory behaviors of machine learning
models toward certain demographic groups, the notion of 'fairness' has recently
drawn much attention from the community, thereby motivating the study of
fairness in graph clustering. Fair graph clustering aims to partition the set
of nodes in a graph into $k$ disjoint clusters such that the proportion of each
protected group within each cluster is consistent with the proportion of that
group in the entire dataset. It is, however, computationally challenging to
incorporate fairness constraints into existing graph clustering algorithms,
particularly for large graphs. To address this problem, we propose FairAD, a
computationally efficient fair graph clustering method. It first constructs a
new affinity matrix based on the notion of algebraic distance such that
fairness constraints are imposed. A graph coarsening process is then performed
on this affinity matrix to find representative nodes that correspond to $k$
clusters. Finally, a constrained minimization problem is solved to obtain the
solution of fair clustering. Experiment results on the modified stochastic
block model and six public datasets show that FairAD can achieve fair
clustering while being up to 40 times faster compared to state-of-the-art fair
graph clustering algorithms.

</details>


### [34] [Adaptive Defense against Harmful Fine-Tuning for Large Language Models via Bayesian Data Scheduler](https://arxiv.org/abs/2510.27172)
*Zixuan Hu,Li Shen,Zhenyi Wang,Yongxian Wei,Dacheng Tao*

Main category: cs.LG

TL;DR: 本文提出贝叶斯数据调度器(BDS)，一种无需攻击模拟的自适应调优阶段防御策略，用于防御大语言模型微调服务中的有害微调攻击。


<details>
  <summary>Details</summary>
Motivation: 现有防御策略通过攻击模拟预先构建鲁棒性，但存在根本性限制：(i)由于难以预测未知攻击，无法将攻击模拟扩展到有界威胁模型之外；(ii)对变化攻击设置的适应性有限，因为模拟无法捕捉其变异性和复杂性。

Method: BDS将有害微调防御建模为贝叶斯推断问题，学习每个数据点安全属性的后验分布，条件于微调和对齐数据集。通过从后验中采样安全属性来加权数据，从而约束微调过程，减轻有害数据的影响。

Result: 在各种攻击和防御设置下的综合结果表明，该方法达到了最先进的性能。

Conclusion: BDS通过贝叶斯推断的后验特性实现自适应防御，能够针对特定数据集定制防御策略，并通过基于摊销贝叶斯学习的神经调度器实现高效迁移。

Abstract: Harmful fine-tuning poses critical safety risks to fine-tuning-as-a-service
for large language models. Existing defense strategies preemptively build
robustness via attack simulation but suffer from fundamental limitations: (i)
the infeasibility of extending attack simulations beyond bounded threat models
due to the inherent difficulty of anticipating unknown attacks, and (ii)
limited adaptability to varying attack settings, as simulation fails to capture
their variability and complexity. To address these challenges, we propose
Bayesian Data Scheduler (BDS), an adaptive tuning-stage defense strategy with
no need for attack simulation. BDS formulates harmful fine-tuning defense as a
Bayesian inference problem, learning the posterior distribution of each data
point's safety attribute, conditioned on the fine-tuning and alignment
datasets. The fine-tuning process is then constrained by weighting data with
their safety attributes sampled from the posterior, thus mitigating the
influence of harmful data. By leveraging the post hoc nature of Bayesian
inference, the posterior is conditioned on the fine-tuning dataset, enabling
BDS to tailor its defense to the specific dataset, thereby achieving adaptive
defense. Furthermore, we introduce a neural scheduler based on amortized
Bayesian learning, enabling efficient transfer to new data without retraining.
Comprehensive results across diverse attack and defense settings demonstrate
the state-of-the-art performance of our approach. Code is available at
https://github.com/Egg-Hu/Bayesian-Data-Scheduler.

</details>


### [35] [A Polynomial-time Algorithm for Online Sparse Linear Regression with Improved Regret Bound under Weaker Conditions](https://arxiv.org/abs/2510.27177)
*Junfan Li,Shizhong Liao,Zenglin Xu,Liqiang Nie*

Main category: cs.LG

TL;DR: 本文提出了一个新的多项式时间算法，用于在线稀疏线性回归问题，该算法在兼容性条件下显著改进了之前的遗憾边界，并扩展到具有额外观测的OSLR场景。


<details>
  <summary>Details</summary>
Motivation: 研究在线稀疏线性回归问题，其中算法在预测时只能访问每个实例的k个属性，这个问题已被证明是NP难的。先前工作假设数据矩阵满足特征线性独立、兼容性条件或受限等距性质，本文旨在在较弱的兼容性条件下改进遗憾边界。

Method: 提出新算法，利用Dantzig选择器，结合算法相关的协方差矩阵估计采样方案、自适应参数调整方案，以及具有仔细初始化的批处理在线牛顿步。采用归纳法分析ℓ1范数误差，分析非独立随机变量的协方差，并对遗憾进行分解。

Result: 显著改进了Ito等人(2017)在兼容性条件下的遗憾边界，改进得益于估计器ℓ1范数误差的更紧收敛率。算法还扩展到具有额外观测的OSLR，改进了Kale等人(2017)和Ito等人(2017)的遗憾边界。

Conclusion: 提出的新算法在较弱的兼容性条件下实现了更好的遗憾边界，通过结合Dantzig选择器和多种创新技术，为在线稀疏线性回归问题提供了有效的解决方案。

Abstract: In this paper, we study the problem of online sparse linear regression (OSLR)
where the algorithms are restricted to accessing only $k$ out of $d$ attributes
per instance for prediction, which was proved to be NP-hard. Previous work gave
polynomial-time algorithms assuming the data matrix satisfies the linear
independence of features, the compatibility condition, or the restricted
isometry property. We introduce a new polynomial-time algorithm, which
significantly improves previous regret bounds (Ito et al., 2017) under the
compatibility condition that is weaker than the other two assumptions. The
improvements benefit from a tighter convergence rate of the $\ell_1$-norm error
of our estimators. Our algorithm leverages the well-studied Dantzig Selector,
but importantly with several novel techniques, including an algorithm-dependent
sampling scheme for estimating the covariance matrix, an adaptive parameter
tuning scheme, and a batching online Newton step with careful initializations.
We also give novel and non-trivial analyses, including an induction method for
analyzing the $\ell_1$-norm error, careful analyses on the covariance of
non-independent random variables, and a decomposition on the regret. We further
extend our algorithm to OSLR with additional observations where the algorithms
can observe additional $k_0$ attributes after each prediction, and improve
previous regret bounds (Kale et al., 2017; Ito et al., 2017).

</details>


### [36] [SERFLOW: A Cross-Service Cost Optimization Framework for SLO-Aware Dynamic ML Inference](https://arxiv.org/abs/2510.27182)
*Zongshun Zhang,Ibrahim Matta*

Main category: cs.LG

TL;DR: SERFLOW通过动态卸载机器学习模型分区到FaaS和IaaS服务，结合阶段特定资源供应和自适应负载均衡，在动态工作负载下降低云成本超过23%。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略虚拟机冷启动、长尾服务时间分布等现实因素，无法适应输入依赖的退出率变化，导致资源配置效率低下。

Method: 将ML查询建模为遍历无环阶段序列，每个阶段包含稀疏模型参数块；利用FaaS无服务器函数和阶段特定资源供应，考虑各阶段请求退出比例；集成自适应负载均衡机制。

Result: SERFLOW在动态工作负载下有效运行，将云成本降低超过23%。

Conclusion: 通过结合FaaS和IaaS的优势，SERFLOW提供了一种高效且经济的方法来处理自适应推理应用中的动态工作负载。

Abstract: Dynamic offloading of Machine Learning (ML) model partitions across different
resource orchestration services, such as Function-as-a-Service (FaaS) and
Infrastructure-as-a-Service (IaaS), can balance processing and transmission
delays while minimizing costs of adaptive inference applications. However,
prior work often overlooks real-world factors, such as Virtual Machine (VM)
cold starts, requests under long-tail service time distributions, etc. To
tackle these limitations, we model each ML query (request) as traversing an
acyclic sequence of stages, wherein each stage constitutes a contiguous block
of sparse model parameters ending in an internal or final classifier where
requests may exit. Since input-dependent exit rates vary, no single resource
configuration suits all query distributions. IaaS-based VMs become
underutilized when many requests exit early, yet rapidly scaling to handle
request bursts reaching deep layers is impractical. SERFLOW addresses this
challenge by leveraging FaaS-based serverless functions (containers) and using
stage-specific resource provisioning that accounts for the fraction of requests
exiting at each stage. By integrating this provisioning with adaptive load
balancing across VMs and serverless functions based on request ingestion,
SERFLOW reduces cloud costs by over $23\%$ while efficiently adapting to
dynamic workloads.

</details>


### [37] [Feature-Function Curvature Analysis: A Geometric Framework for Explaining Differentiable Models](https://arxiv.org/abs/2510.27207)
*Hamed Najafi,Dongsheng Luo,Jason Liu*

Main category: cs.LG

TL;DR: 提出了Feature-Function Curvature Analysis (FFCA)框架，通过分析模型学习函数的几何特性，为每个特征生成4维签名，并扩展到动态原型分析来跟踪训练过程中的特征演化。


<details>
  <summary>Details</summary>
Motivation: 主流可解释AI方法仅提供模型最终状态的静态视图，将特征作用简化为单一分数，无法处理非线性和交互效应，需要更全面的分析框架。

Method: FFCA框架量化特征的四个维度：影响力、波动性、非线性和交互性，并通过动态原型分析跟踪这些特征在整个训练过程中的演化。

Result: 首次提供了层次学习过程的直接经验证据，显示模型总是先学习简单线性效应再学习复杂交互；动态分析可识别模型容量不足并预测过拟合发生。

Conclusion: FFCA通过静态和动态组件提供了必要的几何上下文，将模型解释从简单的量化转变为对整个学习过程的细致可信分析。

Abstract: Explainable AI (XAI) is critical for building trust in complex machine
learning models, yet mainstream attribution methods often provide an
incomplete, static picture of a model's final state. By collapsing a feature's
role into a single score, they are confounded by non-linearity and
interactions. To address this, we introduce Feature-Function Curvature Analysis
(FFCA), a novel framework that analyzes the geometry of a model's learned
function. FFCA produces a 4-dimensional signature for each feature, quantifying
its: (1) Impact, (2) Volatility, (3) Non-linearity, and (4) Interaction.
Crucially, we extend this framework into Dynamic Archetype Analysis, which
tracks the evolution of these signatures throughout the training process. This
temporal view moves beyond explaining what a model learned to revealing how it
learns. We provide the first direct, empirical evidence of hierarchical
learning, showing that models consistently learn simple linear effects before
complex interactions. Furthermore, this dynamic analysis provides novel,
practical diagnostics for identifying insufficient model capacity and
predicting the onset of overfitting. Our comprehensive experiments demonstrate
that FFCA, through its static and dynamic components, provides the essential
geometric context that transforms model explanation from simple quantification
to a nuanced, trustworthy analysis of the entire learning process.

</details>


### [38] [Not All Instances Are Equally Valuable: Towards Influence-Weighted Dataset Distillation](https://arxiv.org/abs/2510.27253)
*Qiyan Deng,Changqian Zheng,Lianpeng Qiao,Yuping Wang,Chengliang Chai,Lei Cao*

Main category: cs.LG

TL;DR: 本文提出了一种基于影响函数的加权蒸馏方法IWD，通过评估数据实例对蒸馏目标的影响来分配权重，优先选择有益数据并降低无用或有害数据的影响，从而提升蒸馏数据集的质量和模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据集蒸馏方法假设所有真实实例对蒸馏过程贡献相同，但实际数据集中既包含有用信息也包含冗余甚至有害实例。直接蒸馏整个数据集而不考虑数据质量会降低模型性能。

Method: 提出影响加权蒸馏IWD框架，利用影响函数在蒸馏过程中显式考虑数据质量，为每个实例基于其对蒸馏目标的估计影响分配自适应权重。

Result: 实验结果表明，集成IWD能够提高蒸馏数据集的质量并增强模型性能，准确率提升最高可达7.8%。

Conclusion: IWD通过模块化设计可以无缝集成到各种数据集蒸馏框架中，有效解决了数据质量差异对蒸馏效果的影响问题。

Abstract: Dataset distillation condenses large datasets into synthetic subsets,
achieving performance comparable to training on the full dataset while
substantially reducing storage and computation costs. Most existing dataset
distillation methods assume that all real instances contribute equally to the
process. In practice, real-world datasets contain both informative and
redundant or even harmful instances, and directly distilling the full dataset
without considering data quality can degrade model performance. In this work,
we present Influence-Weighted Distillation IWD, a principled framework that
leverages influence functions to explicitly account for data quality in the
distillation process. IWD assigns adaptive weights to each instance based on
its estimated impact on the distillation objective, prioritizing beneficial
data while downweighting less useful or harmful ones. Owing to its modular
design, IWD can be seamlessly integrated into diverse dataset distillation
frameworks. Our empirical results suggest that integrating IWD tends to improve
the quality of distilled datasets and enhance model performance, with accuracy
gains of up to 7.8%.

</details>


### [39] [ECVL-ROUTER: Scenario-Aware Routing for Vision-Language Models](https://arxiv.org/abs/2510.27256)
*Xin Tang,Youfang Han,Fangfei Gou,Wei Zhao,Xin Meng,Yang Yu,Jinguo Zhang,Yuanchun Shi,Yuntao Wang,Tengxiang Zhang*

Main category: cs.LG

TL;DR: 提出了ECVL-ROUTER，首个面向视觉语言模型的情景感知路由框架，通过动态选择合适模型来平衡响应速度、输出质量和能耗需求。


<details>
  <summary>Details</summary>
Motivation: 用户需求在不同场景下差异很大，包括快速响应、高质量输出和低能耗。仅依赖云端大模型会导致高延迟和高能耗，而边缘设备上的小模型能处理简单任务但能力有限。需要结合大小模型的优势来最大化整体效用。

Method: 引入新的路由策略和评估指标，根据用户需求为每个查询动态选择合适模型。构建了专门用于路由器训练的多模态响应质量数据集。

Result: 实验验证表明，该方法成功将超过80%的查询路由到小模型，同时问题解决概率下降不到10%。

Conclusion: ECVL-ROUTER框架能有效平衡不同用户需求，在保持高质量输出的同时显著降低延迟和能耗。

Abstract: Vision-Language Models (VLMs) excel in diverse multimodal tasks. However,
user requirements vary across scenarios, which can be categorized into fast
response, high-quality output, and low energy consumption. Relying solely on
large models deployed in the cloud for all queries often leads to high latency
and energy cost, while small models deployed on edge devices are capable of
handling simpler tasks with low latency and energy cost. To fully leverage the
strengths of both large and small models, we propose ECVL-ROUTER, the first
scenario-aware routing framework for VLMs. Our approach introduces a new
routing strategy and evaluation metrics that dynamically select the appropriate
model for each query based on user requirements, maximizing overall utility. We
also construct a multimodal response-quality dataset tailored for router
training and validate the approach through extensive experiments. Results show
that our approach successfully routes over 80\% of queries to the small model
while incurring less than 10\% drop in problem solving probability.

</details>


### [40] [ODP-Bench: Benchmarking Out-of-Distribution Performance Prediction](https://arxiv.org/abs/2510.27263)
*Han Yu,Kehan Li,Dongbai Li,Yue He,Xingxuan Zhang,Peng Cui*

Main category: cs.LG

TL;DR: 提出了一个全面的OOD性能预测基准ODP-Bench，包含常用OOD数据集和现有性能预测算法，为研究者提供公平比较平台。


<details>
  <summary>Details</summary>
Motivation: 现有OOD性能预测研究评估协议不一致，覆盖的OOD数据集和分布偏移类型有限，需要统一的评估基准。

Method: 构建ODP-Bench基准，整合常用OOD数据集和现有性能预测算法，提供预训练模型作为测试平台。

Result: 建立了包含多种OOD数据集和算法的综合基准，为未来研究提供一致的比较基础。

Conclusion: ODP-Bench为OOD性能预测领域提供了标准化评估框架，有助于推动该领域的发展。

Abstract: Recently, there has been gradually more attention paid to Out-of-Distribution
(OOD) performance prediction, whose goal is to predict the performance of
trained models on unlabeled OOD test datasets, so that we could better leverage
and deploy off-the-shelf trained models in risk-sensitive scenarios. Although
progress has been made in this area, evaluation protocols in previous
literature are inconsistent, and most works cover only a limited number of
real-world OOD datasets and types of distribution shifts. To provide convenient
and fair comparisons for various algorithms, we propose Out-of-Distribution
Performance Prediction Benchmark (ODP-Bench), a comprehensive benchmark that
includes most commonly used OOD datasets and existing practical performance
prediction algorithms. We provide our trained models as a testbench for future
researchers, thus guaranteeing the consistency of comparison and avoiding the
burden of repeating the model training process. Furthermore, we also conduct
in-depth experimental analyses to better understand their capability boundary.

</details>


### [41] [Temporal Cardiovascular Dynamics for Improved PPG-Based Heart Rate Estimation](https://arxiv.org/abs/2510.27297)
*Berken Utku Demirel,Christian Holz*

Main category: cs.LG

TL;DR: 本文提出了一种基于互信息分析心率非线性混沌行为的新方法，显著提升了真实场景下的心率估计精度，相比传统方法改进达40%，同时减少了对多模态传感的依赖和后续处理需求。


<details>
  <summary>Details</summary>
Motivation: 人类心率振荡具有复杂的非线性混沌特性，这给日常生活中的心血管健康监测带来了挑战。现有方法难以有效处理这种非线性时间复杂性。

Method: 通过互信息研究心率的非线性混沌行为，提出了一种新颖的心率估计方法，该方法从数学角度解释和处理非线性时间复杂性，并能与深度学习解决方案结合使用。

Result: 在四个真实场景数据集上的验证表明，该方法相比传统方法和现有机器学习技术，心率估计性能提升了高达40%，同时减少了对多模态传感的依赖并消除了后续处理步骤的需求。

Conclusion: 提出的方法不仅从数学角度解释了心率的非线性混沌行为，还显著提升了真实场景下的心率估计精度，为心血管健康监测提供了更有效的解决方案。

Abstract: The oscillations of the human heart rate are inherently complex and
non-linear -- they are best described by mathematical chaos, and they present a
challenge when applied to the practical domain of cardiovascular health
monitoring in everyday life. In this work, we study the non-linear chaotic
behavior of heart rate through mutual information and introduce a novel
approach for enhancing heart rate estimation in real-life conditions. Our
proposed approach not only explains and handles the non-linear temporal
complexity from a mathematical perspective but also improves the deep learning
solutions when combined with them. We validate our proposed method on four
established datasets from real-life scenarios and compare its performance with
existing algorithms thoroughly with extensive ablation experiments. Our results
demonstrate a substantial improvement, up to 40\%, of the proposed approach in
estimating heart rate compared to traditional methods and existing
machine-learning techniques while reducing the reliance on multiple sensing
modalities and eliminating the need for post-processing steps.

</details>


### [42] [Measuring Chain-of-Thought Monitorability Through Faithfulness and Verbosity](https://arxiv.org/abs/2510.27378)
*Austin Meek,Eitan Sprejer,Iván Arcuschin,Austin J. Brockmeier,Steven Basart*

Main category: cs.LG

TL;DR: 本文提出了一个监控性评分框架，结合忠实性和详尽性来评估链式思维输出的监控能力，发现模型可能看似忠实但难以监控，且不同模型家族的监控性差异显著。


<details>
  <summary>Details</summary>
Motivation: 链式思维输出让我们能够观察模型的逐步推理过程，这种可见性有助于发现不安全或未对齐的行为，但前提是链式思维对其内部推理是透明的。现有方法在模型保持答案不变时会丢失信息，且未调查与提示无关的推理方面。

Method: 引入详尽性概念（链式思维是否列出解决任务所需的每个因素），将忠实性和详尽性结合为单一监控性评分，评估链式思维作为模型外部'工作记忆'的能力。在BBH、GPQA和MMLU数据集上评估指令调优和推理模型。

Result: 模型可能看似忠实但难以监控，当它们遗漏关键因素时；不同模型家族的监控性差异显著。

Conclusion: 监控性评分框架能够更全面地评估链式思维的监控能力，揭示了模型在推理透明度方面的局限性，并发布了评估代码以支持可复现的未来工作。

Abstract: Chain-of-thought (CoT) outputs let us read a model's step-by-step reasoning.
Since any long, serial reasoning process must pass through this textual trace,
the quality of the CoT is a direct window into what the model is thinking. This
visibility could help us spot unsafe or misaligned behavior (monitorability),
but only if the CoT is transparent about its internal reasoning (faithfulness).
Fully measuring faithfulness is difficult, so researchers often focus on
examining the CoT in cases where the model changes its answer after adding a
cue to the input. This proxy finds some instances of unfaithfulness but loses
information when the model maintains its answer, and does not investigate
aspects of reasoning not tied to the cue. We extend these results to a more
holistic sense of monitorability by introducing verbosity: whether the CoT
lists every factor needed to solve the task. We combine faithfulness and
verbosity into a single monitorability score that shows how well the CoT serves
as the model's external `working memory', a property that many safety schemes
based on CoT monitoring depend on. We evaluate instruction-tuned and reasoning
models on BBH, GPQA, and MMLU. Our results show that models can appear faithful
yet remain hard to monitor when they leave out key factors, and that
monitorability differs sharply across model families. We release our evaluation
code using the Inspect library to support reproducible future work.

</details>


### [43] [Simplex-to-Euclidean Bijections for Categorical Flow Matching](https://arxiv.org/abs/2510.27480)
*Bernardo Williams,Victor M. Yeom-Song,Marcelo Hartmann,Arto Klami*

Main category: cs.LG

TL;DR: 提出了一种在单纯形上学习概率分布的方法，通过光滑双射将单纯形映射到欧几里得空间，利用Aitchison几何定义映射，支持通过Dirichlet插值对分类数据进行建模。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单纯形上操作时使用黎曼几何或自定义噪声过程，存在局限性。本文旨在在欧几里得空间中工作同时尊重Aitchison几何，提供更有效的概率分布建模方法。

Method: 使用光滑双射将开放单纯形映射到欧几里得空间，利用Aitchison几何定义映射，通过Dirichlet插值将离散观测反量化成连续数据，在欧几里得空间中进行密度建模。

Result: 在合成和真实世界数据集上取得了竞争性性能，能够精确恢复原始离散分布。

Conclusion: 该方法在欧几里得空间中有效建模单纯形上的概率分布，同时尊重Aitchison几何，优于现有方法。

Abstract: We propose a method for learning and sampling from probability distributions
supported on the simplex. Our approach maps the open simplex to Euclidean space
via smooth bijections, leveraging the Aitchison geometry to define the
mappings, and supports modeling categorical data by a Dirichlet interpolation
that dequantizes discrete observations into continuous ones. This enables
density modeling in Euclidean space through the bijection while still allowing
exact recovery of the original discrete distribution. Compared to previous
methods that operate on the simplex using Riemannian geometry or custom noise
processes, our approach works in Euclidean space while respecting the Aitchison
geometry, and achieves competitive performance on both synthetic and real-world
data sets.

</details>


### [44] [TetraJet-v2: Accurate NVFP4 Training for Large Language Models with Oscillation Suppression and Outlier Control](https://arxiv.org/abs/2510.27527)
*Yuxiang Chen,Xiaoming Xu,Pengle Zhang,Michael Beyer,Martin Rapp,Jun Zhu,Jianfei Chen*

Main category: cs.LG

TL;DR: TetraJet-v2是一种端到端的4位全量化训练方法，使用NVFP4格式处理所有线性层中的激活、权重和梯度，解决了权重振荡和异常值问题，显著缩小了与全精度训练的性能差距。


<details>
  <summary>Details</summary>
Motivation: 大语言模型训练成本极高，推动了对低精度全量化训练的兴趣。虽然4位格式如NVFP4提供了显著的效率提升，但在如此低精度下实现近乎无损的训练仍然具有挑战性。

Method: 提出TetraJet-v2方法，包括：1）NVFP4线性层的无偏双块量化方法；2）抑制权重振荡的OsciReset算法；3）保持异常值精度的OutControl算法。

Result: TetraJet-v2在预训练LLMs上始终优于先前的FP4训练方法，模型规模达370M，数据规模达200B tokens，将性能差距缩小了平均51.3%。

Conclusion: 该方法成功解决了4位全量化训练中的关键挑战，为实现高效低精度LLM训练提供了可行方案。

Abstract: Large Language Models (LLMs) training is prohibitively expensive, driving
interest in low-precision fully-quantized training (FQT). While novel 4-bit
formats like NVFP4 offer substantial efficiency gains, achieving near-lossless
training at such low precision remains challenging. We introduce TetraJet-v2,
an end-to-end 4-bit FQT method that leverages NVFP4 for activations, weights,
and gradients in all linear layers. We identify two critical issues hindering
low-precision LLM training: weight oscillation and outliers. To address these,
we propose: 1) an unbiased double-block quantization method for NVFP4 linear
layers, 2) OsciReset, an algorithm to suppress weight oscillation, and 3)
OutControl, an algorithm to retain outlier accuracy. TetraJet-v2 consistently
outperforms prior FP4 training methods on pre-training LLMs across varying
model sizes up to 370M and data sizes up to 200B tokens, reducing the
performance gap to full-precision training by an average of 51.3%.

</details>


### [45] [Challenges in Credit Assignment for Multi-Agent Reinforcement Learning in Open Agent Systems](https://arxiv.org/abs/2510.27659)
*Alireza Saleh Abadi,Leen-Kiat Soh*

Main category: cs.LG

TL;DR: 本文分析了多智能体强化学习(MARL)中开放性与信用分配问题(CAP)的相互作用，指出传统信用分配方法在开放系统中失效，并通过实证研究证明开放性直接导致信用错误分配。


<details>
  <summary>Details</summary>
Motivation: 随着MARL领域的快速发展，理解开放系统的动态性变得至关重要。传统信用分配方法假设静态环境，无法适应开放系统中智能体、任务和类型的动态变化，因此需要研究开放性如何影响信用分配。

Method: 首先进行概念分析，引入新的开放性子类别来详细说明智能体流动、任务取消等事件如何打破环境平稳性和固定团队组成的假设。然后使用代表性的时间和结构算法在开放环境中进行实证研究。

Result: 实证结果表明，开放性直接导致信用错误分配，表现为损失函数不稳定和显著的性能下降。

Conclusion: 开放系统对传统信用分配方法构成挑战，需要开发新的方法来应对智能体、任务和类型动态变化带来的信用分配问题。

Abstract: In the rapidly evolving field of multi-agent reinforcement learning (MARL),
understanding the dynamics of open systems is crucial. Openness in MARL refers
to the dynam-ic nature of agent populations, tasks, and agent types with-in a
system. Specifically, there are three types of openness as reported in (Eck et
al. 2023) [2]: agent openness, where agents can enter or leave the system at
any time; task openness, where new tasks emerge, and existing ones evolve or
disappear; and type openness, where the capabil-ities and behaviors of agents
change over time. This report provides a conceptual and empirical review,
focusing on the interplay between openness and the credit assignment problem
(CAP). CAP involves determining the contribution of individual agents to the
overall system performance, a task that becomes increasingly complex in open
environ-ments. Traditional credit assignment (CA) methods often assume static
agent populations, fixed and pre-defined tasks, and stationary types, making
them inadequate for open systems. We first conduct a conceptual analysis,
in-troducing new sub-categories of openness to detail how events like agent
turnover or task cancellation break the assumptions of environmental
stationarity and fixed team composition that underpin existing CAP methods. We
then present an empirical study using representative temporal and structural
algorithms in an open environment. The results demonstrate that openness
directly causes credit misattribution, evidenced by unstable loss functions and
significant performance degradation.

</details>


### [46] [ORGEval: Graph-Theoretic Evaluation of LLMs in Optimization Modeling](https://arxiv.org/abs/2510.27610)
*Zhuohan Wang,Ziwei Zhu,Ziniu Li,Congliang Chen,Yizhou Han,Yufeng Lin,Zhihang Lin,Angyang Gu,Xinglin Hu,Ruoyu Sun,Tian Ding*

Main category: cs.LG

TL;DR: ORGEval是一个基于图论的评估框架，用于评估大语言模型在制定线性和混合整数线性规划问题方面的能力，通过将优化模型表示为图并检测图同构来评估模型等价性。


<details>
  <summary>Details</summary>
Motivation: 工业应用中制定优化问题需要大量手动工作和领域专业知识，而现有基于求解器的评估方法存在不一致性、不可行性和高计算成本等问题。

Method: 将优化模型表示为图，将等价性检测简化为图同构测试，提出对称可分解图的充分条件，并集成定制化的Weisfeiler-Lehman测试与SD检测算法。

Result: 实验结果显示ORGEval能成功检测模型等价性，在随机参数配置下产生100%一致结果，在运行时间上显著优于基于求解器的方法，特别是在困难问题上。

Conclusion: ORGEval框架有效解决了优化问题自动生成的评估挑战，基于该框架构建的Bench4Opt数据集显示DeepSeek-V3和Claude-Opus-4在直接提示下达到最高准确率，优于领先的推理模型。

Abstract: Formulating optimization problems for industrial applications demands
significant manual effort and domain expertise. While Large Language Models
(LLMs) show promise in automating this process, evaluating their performance
remains difficult due to the absence of robust metrics. Existing solver-based
approaches often face inconsistency, infeasibility issues, and high
computational costs. To address these issues, we propose ORGEval, a
graph-theoretic evaluation framework for assessing LLMs' capabilities in
formulating linear and mixed-integer linear programs. ORGEval represents
optimization models as graphs, reducing equivalence detection to graph
isomorphism testing. We identify and prove a sufficient condition, when the
tested graphs are symmetric decomposable (SD), under which the
Weisfeiler-Lehman (WL) test is guaranteed to correctly detect isomorphism.
Building on this, ORGEval integrates a tailored variant of the WL-test with an
SD detection algorithm to evaluate model equivalence. By focusing on structural
equivalence rather than instance-level configurations, ORGEval is robust to
numerical variations. Experimental results show that our method can
successfully detect model equivalence and produce 100\% consistent results
across random parameter configurations, while significantly outperforming
solver-based methods in runtime, especially on difficult problems. Leveraging
ORGEval, we construct the Bench4Opt dataset and benchmark state-of-the-art LLMs
on optimization modeling. Our results reveal that although optimization
modeling remains challenging for all LLMs, DeepSeek-V3 and Claude-Opus-4
achieve the highest accuracies under direct prompting, outperforming even
leading reasoning models.

</details>


### [47] [Imbalanced Classification through the Lens of Spurious Correlations](https://arxiv.org/abs/2510.27650)
*Jakob Hackstein,Sidney Bender*

Main category: cs.LG

TL;DR: 本文提出了一种基于可解释AI的方法，通过反事实解释来识别和消除类别不平衡下出现的Clever Hans效应，从而提高分类性能。


<details>
  <summary>Details</summary>
Motivation: 类别不平衡是机器学习中的基本挑战，通常导致不可靠的分类性能。现有方法主要关注数据或损失重加权方案，而本文将其视为一种数据条件，通过少数类的不充分规范来放大Clever Hans效应。

Method: 采用基于反事实解释的方法，利用可解释AI来联合识别和消除在类别不平衡下出现的Clever Hans效应。

Result: 该方法在三个数据集上实现了有竞争力的分类性能，并展示了在类别不平衡下Clever Hans效应如何出现。

Conclusion: 本文提供了一种被现有方法忽视的视角，展示了如何通过可解释AI来解决类别不平衡问题中的Clever Hans效应。

Abstract: Class imbalance poses a fundamental challenge in machine learning, frequently
leading to unreliable classification performance. While prior methods focus on
data- or loss-reweighting schemes, we view imbalance as a data condition that
amplifies Clever Hans (CH) effects by underspecification of minority classes.
In a counterfactual explanations-based approach, we propose to leverage
Explainable AI to jointly identify and eliminate CH effects emerging under
imbalance. Our method achieves competitive classification performance on three
datasets and demonstrates how CH effects emerge under imbalance, a perspective
largely overlooked by existing approaches.

</details>
