{"id": "2511.08873", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08873", "abs": "https://arxiv.org/abs/2511.08873", "authors": ["Shouang Wei", "Min Zhang", "Xin Lin", "Bo Jiang", "Kun Kuang", "Zhongxiang Dai"], "title": "UCO: A Multi-Turn Interactive Reinforcement Learning Method for Adaptive Teaching with Large Language Models", "comment": null, "summary": "Large language models (LLMs) are shifting from answer providers to intelligent tutors in educational settings, yet current supervised fine-tuning methods only learn surface teaching patterns without dynamic adaptation capabilities. Recent reinforcement learning approaches address this limitation but face two critical challenges. First, they evaluate teaching effectiveness solely based on whether students produce correct outputs, unable to distinguish whether students genuinely understand or echo teacher-provided answers during interaction. Second, they cannot perceive students' evolving cognitive states in real time through interactive dialogue, thus failing to adapt teaching strategies to match students' cognitive levels dynamically. We propose the Unidirectional Cognitive Optimization (UCO) method to address these challenges. UCO uses a multi-turn interactive reinforcement learning paradigm where the innovation lies in two synergistic reward functions: the Progress Reward captures students' cognitive advancement, evaluating whether students truly transition from confusion to comprehension, while the Scaffold Reward dynamically identifies each student's Zone of Proximal Development (ZPD), encouraging teachers to maintain productive teaching within this zone. We evaluate UCO by comparing it against 11 baseline models on BigMath and MathTutorBench benchmarks. Experimental results demonstrate that our UCO model outperforms all models of equivalent scale and achieves performance comparable to advanced closed-source models. The code and data are available at https://github.com/Mind-Lab-ECNU/UCO.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5355\u5411\u8ba4\u77e5\u4f18\u5316\uff08UCO\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u8f6e\u4ea4\u4e92\u5f0f\u5f3a\u5316\u5b66\u4e60\u89e3\u51b3LLM\u4f5c\u4e3a\u667a\u80fd\u5bfc\u5e08\u65f6\u7684\u52a8\u6001\u9002\u5e94\u95ee\u9898\uff0c\u5305\u542b\u4e24\u4e2a\u534f\u540c\u5956\u52b1\u51fd\u6570\u6765\u8bc4\u4f30\u5b66\u751f\u8ba4\u77e5\u8fdb\u6b65\u548c\u8bc6\u522b\u6700\u8fd1\u53d1\u5c55\u533a\u3002", "motivation": "\u5f53\u524dLLM\u5728\u6559\u5b66\u4e2d\u4ec5\u5b66\u4e60\u8868\u9762\u6559\u5b66\u6a21\u5f0f\uff0c\u7f3a\u4e4f\u52a8\u6001\u9002\u5e94\u80fd\u529b\uff1b\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u65e0\u6cd5\u533a\u5206\u5b66\u751f\u771f\u5b9e\u7406\u89e3\u4e0e\u7b80\u5355\u590d\u8ff0\uff0c\u4e5f\u65e0\u6cd5\u611f\u77e5\u5b66\u751f\u5b9e\u65f6\u8ba4\u77e5\u72b6\u6001\u3002", "method": "UCO\u91c7\u7528\u591a\u8f6e\u4ea4\u4e92\u5f0f\u5f3a\u5316\u5b66\u4e60\u8303\u5f0f\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u5956\u52b1\u51fd\u6570\uff1a\u8fdb\u6b65\u5956\u52b1\u6355\u6349\u5b66\u751f\u8ba4\u77e5\u8fdb\u6b65\uff0c\u652f\u67b6\u5956\u52b1\u52a8\u6001\u8bc6\u522b\u5b66\u751f\u6700\u8fd1\u53d1\u5c55\u533a\u3002", "result": "\u5728BigMath\u548cMathTutorBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cUCO\u6a21\u578b\u4f18\u4e8e\u6240\u6709\u540c\u7b49\u89c4\u6a21\u6a21\u578b\uff0c\u6027\u80fd\u4e0e\u5148\u8fdb\u95ed\u6e90\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "UCO\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86LLM\u4f5c\u4e3a\u667a\u80fd\u5bfc\u5e08\u65f6\u7684\u52a8\u6001\u9002\u5e94\u95ee\u9898\uff0c\u901a\u8fc7\u8ba4\u77e5\u5bfc\u5411\u7684\u5956\u52b1\u673a\u5236\u63d0\u5347\u4e86\u6559\u5b66\u6548\u679c\u3002"}}
{"id": "2511.08791", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08791", "abs": "https://arxiv.org/abs/2511.08791", "authors": ["Rocco A. Servedio"], "title": "The Probably Approximately Correct Learning Model in Computational Learning Theory", "comment": "45 pages, 4 figures", "summary": "This survey paper gives an overview of various known results on learning classes of Boolean functions in Valiant's Probably Approximately Correct (PAC) learning model and its commonly studied variants.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u8bba\u6587\u6982\u8ff0\u4e86\u5728Valiant\u7684PAC\u5b66\u4e60\u6a21\u578b\u53ca\u5176\u5e38\u89c1\u53d8\u4f53\u4e2d\u5b66\u4e60\u5e03\u5c14\u51fd\u6570\u7c7b\u7684\u5404\u79cd\u5df2\u77e5\u7ed3\u679c\u3002", "motivation": "\u65e8\u5728\u7cfb\u7edf\u6574\u7406\u548c\u603b\u7ed3\u5728PAC\u5b66\u4e60\u6846\u67b6\u4e0b\u5173\u4e8e\u5e03\u5c14\u51fd\u6570\u7c7b\u5b66\u4e60\u7684\u5df2\u6709\u7814\u7a76\u6210\u679c\uff0c\u4e3a\u7814\u7a76\u8005\u63d0\u4f9b\u5168\u9762\u7684\u7406\u8bba\u53c2\u8003\u3002", "method": "\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u6536\u96c6\u548c\u5206\u6790\u5728PAC\u5b66\u4e60\u6a21\u578b\u53ca\u5176\u53d8\u4f53\u4e0b\u5173\u4e8e\u5e03\u5c14\u51fd\u6570\u7c7b\u5b66\u4e60\u7684\u7406\u8bba\u7ed3\u679c\u548c\u7b97\u6cd5\u3002", "result": "\u63d0\u4f9b\u4e86\u5bf9\u5404\u7c7b\u5e03\u5c14\u51fd\u6570\u5728PAC\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u53ef\u5b66\u4e60\u6027\u3001\u6837\u672c\u590d\u6742\u5ea6\u3001\u8ba1\u7b97\u590d\u6742\u5ea6\u7b49\u65b9\u9762\u7684\u7cfb\u7edf\u603b\u7ed3\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u4e3a\u7406\u89e3\u5e03\u5c14\u51fd\u6570\u5728PAC\u5b66\u4e60\u7406\u8bba\u4e2d\u7684\u57fa\u7840\u6027\u8d28\u548c\u7b97\u6cd5\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u7406\u8bba\u6846\u67b6\u548c\u7ed3\u679c\u6c47\u603b\u3002"}}
{"id": "2511.08653", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.NE"], "pdf": "https://arxiv.org/pdf/2511.08653", "abs": "https://arxiv.org/abs/2511.08653", "authors": ["Kaleem Ullah Qasim", "Jiashu Zhang"], "title": "Accelerating Training Speed of Tiny Recursive Models via Curriculum Guided Adaptive Recursion", "comment": null, "summary": "Recursive reasoning models achieve remarkable performance on complex reasoning tasks through iterative refinement, enabling tiny networks to match large language models thousands of times their size. However, training remains computationally expensive, prior work reporting approximately 36 GPU-hours per dataset, limiting broader adoption and research. We propose CGAR, a novel training methodology that applies curriculum learning to architectural depth rather than traditional data ordering. CGAR introduces two synergistic components: Progressive Depth Curriculum dynamically adjusts recursion depth from shallow to deep configurations during training, preventing early overfitting while reducing computational cost, and Hierarchical Supervision Weighting applies exponentially decaying importance to supervision steps, aligning loss weighting with observed gradient magnitude decay. On Sudoku-Extreme with 423,168 test puzzles, CGAR achieves 1.71x training speedup (10.93 to 6.38 hours, 42% cost reduction) with only 0.63% accuracy drop (86.65% to 86.02%). Systematic ablations reveal Progressive Depth Curriculum alone achieves 2.26x speedup with 85.47% accuracy, demonstrating a rare Pareto improvement where architectural curriculum simultaneously enhances training efficiency and solution quality. CGAR-trained models exhibit superior inference efficiency with 100% halting accuracy and 11% fewer reasoning steps. Our work demonstrates that principled curriculum on architectural depth enables efficient training of recursive reasoning models on modest hardware. Code and models: https://github.com/Kaleemullahqasim/CGAR and https://huggingface.co/Kaleemullah/trm-cgar-sudoku", "AI": {"tldr": "CGAR\u662f\u4e00\u79cd\u65b0\u7684\u9012\u5f52\u63a8\u7406\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u6e10\u8fdb\u6df1\u5ea6\u8bfe\u7a0b\u5b66\u4e60\u548c\u5206\u5c42\u76d1\u7763\u52a0\u6743\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bad\u7ec3\u8ba1\u7b97\u6210\u672c\uff0842%\u6210\u672c\u51cf\u5c11\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u3002", "motivation": "\u9012\u5f52\u63a8\u7406\u6a21\u578b\u867d\u7136\u6027\u80fd\u4f18\u5f02\uff0c\u4f46\u8bad\u7ec3\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff08\u7ea636 GPU\u5c0f\u65f6/\u6570\u636e\u96c6\uff09\uff0c\u9650\u5236\u4e86\u5e7f\u6cdb\u5e94\u7528\u548c\u7814\u7a76\u3002", "method": "\u63d0\u51faCGAR\u65b9\u6cd5\uff1a1\uff09\u6e10\u8fdb\u6df1\u5ea6\u8bfe\u7a0b\u5b66\u4e60 - \u52a8\u6001\u8c03\u6574\u9012\u5f52\u6df1\u5ea6\u4ece\u6d45\u5230\u6df1\uff1b2\uff09\u5206\u5c42\u76d1\u7763\u52a0\u6743 - \u5bf9\u76d1\u7763\u6b65\u9aa4\u5e94\u7528\u6307\u6570\u8870\u51cf\u91cd\u8981\u6027\u6743\u91cd\u3002", "result": "\u5728Sudoku-Extreme\u6570\u636e\u96c6\u4e0a\uff0cCGAR\u5b9e\u73b01.71\u500d\u8bad\u7ec3\u52a0\u901f\uff0810.93\u52306.38\u5c0f\u65f6\uff09\uff0c\u7cbe\u5ea6\u4ec5\u4e0b\u964d0.63%\uff0886.65%\u523086.02%\uff09\u3002\u63a8\u7406\u6548\u7387\u63d0\u5347\uff0c100%\u505c\u6b62\u7cbe\u5ea6\u548c11%\u66f4\u5c11\u63a8\u7406\u6b65\u9aa4\u3002", "conclusion": "\u57fa\u4e8e\u67b6\u6784\u6df1\u5ea6\u7684\u539f\u5219\u6027\u8bfe\u7a0b\u5b66\u4e60\u80fd\u591f\u6709\u6548\u8bad\u7ec3\u9012\u5f52\u63a8\u7406\u6a21\u578b\uff0c\u5728\u6709\u9650\u786c\u4ef6\u4e0a\u5b9e\u73b0\u6548\u7387\u548c\u8d28\u91cf\u7684\u53cc\u91cd\u63d0\u5347\u3002"}}
{"id": "2511.08808", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08808", "abs": "https://arxiv.org/abs/2511.08808", "authors": ["Matheus Vin\u00edcius Barreto de Farias", "Mario de Castro"], "title": "Effects of label noise on the classification of outlier observations", "comment": "10 pages, 8 figures", "summary": "This study investigates the impact of adding noise to the training set classes in classification tasks using the BCOPS algorithm (Balanced and Conformal Optimized Prediction Sets), proposed by Guan & Tibshirani (2022). The BCOPS algorithm is an application of conformal prediction combined with a machine learning method to construct prediction sets such that the probability of the true class being included in the prediction set for a test observation meets a specified coverage guarantee. An observation is considered an outlier if its true class is not present in the training set. The study employs both synthetic and real datasets and conducts experiments to evaluate the prediction abstention rate for outlier observations and the model's robustness in this previously untested scenario. The results indicate that the addition of noise, even in small amounts, can have a significant effect on model performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u5206\u7c7b\u4efb\u52a1\u4e2d\u5411\u8bad\u7ec3\u96c6\u7c7b\u522b\u6dfb\u52a0\u566a\u58f0\u5bf9BCOPS\u7b97\u6cd5\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5373\u4f7f\u5c11\u91cf\u566a\u58f0\u4e5f\u4f1a\u663e\u8457\u5f71\u54cd\u6a21\u578b\u8868\u73b0\u3002", "motivation": "\u9a8c\u8bc1BCOPS\u7b97\u6cd5\u5728\u8bad\u7ec3\u96c6\u7c7b\u522b\u5b58\u5728\u566a\u58f0\u60c5\u51b5\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u8fd9\u662f\u4e4b\u524d\u672a\u6d4b\u8bd5\u8fc7\u7684\u573a\u666f\u3002", "method": "\u4f7f\u7528\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5411\u8bad\u7ec3\u96c6\u7c7b\u522b\u6dfb\u52a0\u566a\u58f0\uff0c\u8bc4\u4f30\u5f02\u5e38\u89c2\u6d4b\u7684\u9884\u6d4b\u5f03\u6743\u7387\u548c\u6a21\u578b\u9c81\u68d2\u6027\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5373\u4f7f\u6dfb\u52a0\u5c11\u91cf\u566a\u58f0\u4e5f\u4f1a\u5bf9\u6a21\u578b\u6027\u80fd\u4ea7\u751f\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "BCOPS\u7b97\u6cd5\u5bf9\u8bad\u7ec3\u96c6\u7c7b\u522b\u566a\u58f0\u654f\u611f\uff0c\u566a\u58f0\u6dfb\u52a0\u4f1a\u663e\u8457\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2511.08991", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08991", "abs": "https://arxiv.org/abs/2511.08991", "authors": ["Puheng Li", "Tijana Zrnic", "Emmanuel Cand\u00e8s"], "title": "Robust Sampling for Active Statistical Inference", "comment": "NeurIPS 2025", "summary": "Active statistical inference is a new method for inference with AI-assisted data collection. Given a budget on the number of labeled data points that can be collected and assuming access to an AI predictive model, the basic idea is to improve estimation accuracy by prioritizing the collection of labels where the model is most uncertain. The drawback, however, is that inaccurate uncertainty estimates can make active sampling produce highly noisy results, potentially worse than those from naive uniform sampling. In this work, we present robust sampling strategies for active statistical inference. Robust sampling ensures that the resulting estimator is never worse than the estimator using uniform sampling. Furthermore, with reliable uncertainty estimates, the estimator usually outperforms standard active inference. This is achieved by optimally interpolating between uniform and active sampling, depending on the quality of the uncertainty scores, and by using ideas from robust optimization. We demonstrate the utility of the method on a series of real datasets from computational social science and survey research.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8eAI\u8f85\u52a9\u6570\u636e\u6536\u96c6\u7684\u7a33\u5065\u4e3b\u52a8\u7edf\u8ba1\u63a8\u65ad\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u4f18\u63d2\u503c\u5747\u5300\u91c7\u6837\u548c\u4e3b\u52a8\u91c7\u6837\u6765\u786e\u4fdd\u4f30\u8ba1\u5668\u6027\u80fd\u4e0d\u4f4e\u4e8e\u5747\u5300\u91c7\u6837\uff0c\u540c\u65f6\u5728\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u53ef\u9760\u65f6\u4f18\u4e8e\u6807\u51c6\u4e3b\u52a8\u63a8\u65ad\u3002", "motivation": "\u4f20\u7edf\u4e3b\u52a8\u7edf\u8ba1\u63a8\u65ad\u65b9\u6cd5\u4f9d\u8d56AI\u9884\u6d4b\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u6765\u4f18\u5148\u6536\u96c6\u6807\u7b7e\uff0c\u4f46\u4e0d\u51c6\u786e\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u4f1a\u5bfc\u81f4\u7ed3\u679c\u9ad8\u5ea6\u566a\u58f0\u5316\uff0c\u751a\u81f3\u6bd4\u5747\u5300\u91c7\u6837\u66f4\u5dee\u3002", "method": "\u4f7f\u7528\u7a33\u5065\u4f18\u5316\u601d\u60f3\uff0c\u6839\u636e\u4e0d\u786e\u5b9a\u6027\u8bc4\u5206\u8d28\u91cf\u5728\u5747\u5300\u91c7\u6837\u548c\u4e3b\u52a8\u91c7\u6837\u4e4b\u95f4\u8fdb\u884c\u6700\u4f18\u63d2\u503c\uff0c\u786e\u4fdd\u4f30\u8ba1\u5668\u6027\u80fd\u7a33\u5065\u3002", "result": "\u5728\u8ba1\u7b97\u793e\u4f1a\u79d1\u5b66\u548c\u8c03\u67e5\u7814\u7a76\u7684\u4e00\u7cfb\u5217\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u7a33\u5065\u91c7\u6837\u59cb\u7ec8\u4f18\u4e8e\u6216\u7b49\u4e8e\u5747\u5300\u91c7\u6837\u3002", "conclusion": "\u63d0\u51fa\u7684\u7a33\u5065\u91c7\u6837\u7b56\u7565\u4e3aAI\u8f85\u52a9\u6570\u636e\u6536\u96c6\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u7edf\u8ba1\u63a8\u65ad\u65b9\u6cd5\uff0c\u5728\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u4e0d\u53ef\u9760\u65f6\u4fdd\u6301\u7a33\u5065\u6027\uff0c\u5728\u53ef\u9760\u65f6\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2511.08934", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08934", "abs": "https://arxiv.org/abs/2511.08934", "authors": ["Di Liao", "Ruijia Liang", "Ziyi Ye"], "title": "A Research on Business Process Optimisation Model Integrating AI and Big Data Analytics", "comment": null, "summary": "With the deepening of digital transformation, business process optimisation has become the key to improve the competitiveness of enterprises. This study constructs a business process optimisation model integrating artificial intelligence and big data to achieve intelligent management of the whole life cycle of processes. The model adopts a three-layer architecture incorporating data processing, AI algorithms, and business logic to enable real-time process monitoring and optimization. Through distributed computing and deep learning techniques, the system can handle complex business scenarios while maintaining high performance and reliability. Experimental validation across multiple enterprise scenarios shows that the model shortens process processing time by 42%, improves resource utilisation by 28%, and reduces operating costs by 35%. The system maintained 99.9% availability under high concurrent loads. The research results have important theoretical and practical value for promoting the digital transformation of enterprises, and provide new ideas for improving the operational efficiency of enterprises.", "AI": {"tldr": "\u6784\u5efa\u4e86\u878d\u5408\u4eba\u5de5\u667a\u80fd\u4e0e\u5927\u6570\u636e\u7684\u4e1a\u52a1\u6d41\u7a0b\u4f18\u5316\u6a21\u578b\uff0c\u91c7\u7528\u4e09\u5c42\u67b6\u6784\u5b9e\u73b0\u6d41\u7a0b\u5168\u751f\u547d\u5468\u671f\u667a\u80fd\u7ba1\u7406\uff0c\u663e\u8457\u63d0\u5347\u4f01\u4e1a\u8fd0\u8425\u6548\u7387\u3002", "motivation": "\u968f\u7740\u6570\u5b57\u5316\u8f6c\u578b\u6df1\u5165\uff0c\u4e1a\u52a1\u6d41\u7a0b\u4f18\u5316\u6210\u4e3a\u63d0\u5347\u4f01\u4e1a\u7ade\u4e89\u529b\u7684\u5173\u952e\uff0c\u9700\u8981\u667a\u80fd\u5316\u7684\u5168\u751f\u547d\u5468\u671f\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5305\u542b\u6570\u636e\u5904\u7406\u3001AI\u7b97\u6cd5\u548c\u4e1a\u52a1\u903b\u8f91\u7684\u4e09\u5c42\u67b6\u6784\uff0c\u7ed3\u5408\u5206\u5e03\u5f0f\u8ba1\u7b97\u548c\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\uff0c\u5b9e\u73b0\u5b9e\u65f6\u6d41\u7a0b\u76d1\u63a7\u4e0e\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\uff1a\u6d41\u7a0b\u5904\u7406\u65f6\u95f4\u7f29\u77ed42%\uff0c\u8d44\u6e90\u5229\u7528\u7387\u63d0\u534728%\uff0c\u8fd0\u8425\u6210\u672c\u964d\u4f4e35%\uff0c\u9ad8\u5e76\u53d1\u8d1f\u8f7d\u4e0b\u4fdd\u630199.9%\u53ef\u7528\u6027\u3002", "conclusion": "\u7814\u7a76\u6210\u679c\u5bf9\u4f01\u4e1a\u6570\u5b57\u5316\u8f6c\u578b\u5177\u6709\u91cd\u8981\u7406\u8bba\u4e0e\u5b9e\u8df5\u4ef7\u503c\uff0c\u4e3a\u63d0\u5347\u4f01\u4e1a\u8fd0\u8425\u6548\u7387\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.09007", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09007", "abs": "https://arxiv.org/abs/2511.09007", "authors": ["Anshu Arora", "Kaluguri Yashaswini", "Satish Mulleti"], "title": "Linear-Bias Time Encoding for Low-Rate Quantized Representation of Bandlimited Signals", "comment": "5 pages", "summary": "Integrate-and-fire time encoding machines (IF-TEMs) provide an efficient framework for asynchronous sampling of bandlimited signals through discrete firing times. However, conventional IF-TEMs often exhibit excessive oversampling, leading to inefficient encoding for signals with smoothly distributed information. This letter introduces a linear-bias IF-TEM (LB-IF-TEM), where the bias dynamically tracks the input signal to maintain a nearly constant integrator input, thereby localizing the firing intervals. The resulting concentrated distribution enables effective non-uniform quantization with reduced distortion. Theoretical analysis establishes explicit bounds on the achievable oversampling range, while experimental results demonstrate that the proposed method attains comparable reconstruction accuracy at significantly lower bitrate than existing IF-TEM variants. The LB-IF-TEM thus provides a low-power, communication-efficient, and analytically tractable framework for time-based signal encoding and reconstruction.", "AI": {"tldr": "\u63d0\u51fa\u7ebf\u6027\u504f\u7f6eIF-TEM\uff08LB-IF-TEM\uff09\uff0c\u901a\u8fc7\u52a8\u6001\u8ddf\u8e2a\u8f93\u5165\u4fe1\u53f7\u6765\u51cf\u5c11\u8fc7\u91c7\u6837\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u65f6\u57fa\u4fe1\u53f7\u7f16\u7801\u548c\u91cd\u5efa\u3002", "motivation": "\u4f20\u7edfIF-TEM\u5b58\u5728\u8fc7\u5ea6\u8fc7\u91c7\u6837\u95ee\u9898\uff0c\u5bfc\u81f4\u5bf9\u4fe1\u606f\u5206\u5e03\u5e73\u6ed1\u7684\u4fe1\u53f7\u7f16\u7801\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u5f15\u5165\u7ebf\u6027\u504f\u7f6eIF-TEM\uff0c\u4f7f\u504f\u7f6e\u52a8\u6001\u8ddf\u8e2a\u8f93\u5165\u4fe1\u53f7\uff0c\u4fdd\u6301\u79ef\u5206\u5668\u8f93\u5165\u63a5\u8fd1\u6052\u5b9a\uff0c\u4ece\u800c\u96c6\u4e2d\u89e6\u53d1\u95f4\u9694\u5206\u5e03\u3002", "result": "\u7406\u8bba\u5206\u6790\u5efa\u7acb\u4e86\u53ef\u5b9e\u73b0\u7684\u8fc7\u91c7\u6837\u8303\u56f4\u754c\u9650\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5728\u663e\u8457\u964d\u4f4e\u6bd4\u7279\u7387\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u53ef\u6bd4\u7684\u91cd\u5efa\u7cbe\u5ea6\u3002", "conclusion": "LB-IF-TEM\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4f4e\u529f\u8017\u3001\u901a\u4fe1\u6548\u7387\u9ad8\u4e14\u5206\u6790\u53ef\u5904\u7406\u7684\u65f6\u57fa\u4fe1\u53f7\u7f16\u7801\u548c\u91cd\u5efa\u6846\u67b6\u3002"}}
{"id": "2511.09237", "categories": ["stat.AP"], "pdf": "https://arxiv.org/pdf/2511.09237", "abs": "https://arxiv.org/abs/2511.09237", "authors": ["Bing Liu", "Yuan Liao", "Sonia Yeh", "Oded Cats", "Kristian S. Nielsen", "Zhenning Dong", "Yong Wang", "Yi Li", "Yanli Liu", "Zirui Ni", "Xiaolei Ma"], "title": "Scaling behavioral incentives for low-carbon mobility through digital platforms", "comment": "18 pages, 5 Figures", "summary": "Meeting global carbon reduction targets requires large-scale behavioral shifts in everyday travel. Yet, real-world evidence on how to motivate such large-scale behavioral change remains scarce. We evaluate a carbon incentive program embedded in a MaaS platform in Beijing, China, using data from 3.9 million participants and 4.8 billion multimodal trips over 395 days. The program increased reported public transport and bike travel by 20.3% per month and reduced gasoline car use by 1.8% per day, yielding an annual carbon reduction of ~94,000 tons, or 5.7% of certified reductions in Beijing's carbon market. Although effects diminished over time, participants still made 12.8% more green trips per month after eight months, indicating persistence. These results provide the first large-scale empirical evidence of carbon incentives in MaaS and highlight their potential to inform targeted, city-specific interventions that can scale to support global low-carbon mobility transitions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u5317\u4eacMaaS\u5e73\u53f0\u4e2d\u7684\u78b3\u6fc0\u52b1\u8ba1\u5212\uff0c\u901a\u8fc7390\u4e07\u53c2\u4e0e\u8005\u548c48\u4ebf\u6b21\u591a\u6a21\u5f0f\u51fa\u884c\u6570\u636e\u53d1\u73b0\uff0c\u8be5\u8ba1\u5212\u4f7f\u516c\u5171\u4ea4\u901a\u548c\u81ea\u884c\u8f66\u51fa\u884c\u6bcf\u6708\u589e\u52a020.3%\uff0c\u6c7d\u6cb9\u8f66\u4f7f\u7528\u6bcf\u65e5\u51cf\u5c111.8%\uff0c\u5e74\u78b3\u51cf\u6392\u7ea69.4\u4e07\u5428\u3002", "motivation": "\u5b9e\u73b0\u5168\u7403\u78b3\u51cf\u6392\u76ee\u6807\u9700\u8981\u5927\u89c4\u6a21\u65e5\u5e38\u51fa\u884c\u884c\u4e3a\u8f6c\u53d8\uff0c\u4f46\u5173\u4e8e\u5982\u4f55\u6fc0\u52b1\u8fd9\u79cd\u5927\u89c4\u6a21\u884c\u4e3a\u6539\u53d8\u7684\u73b0\u5b9e\u8bc1\u636e\u4ecd\u7136\u7a00\u7f3a\u3002", "method": "\u4f7f\u7528\u5317\u4eacMaaS\u5e73\u53f0\u4e2d390\u4e07\u53c2\u4e0e\u8005\u548c48\u4ebf\u6b21\u591a\u6a21\u5f0f\u51fa\u884c\u6570\u636e\uff0c\u8bc4\u4f30\u78b3\u6fc0\u52b1\u8ba1\u5212\u5728395\u5929\u5185\u7684\u6548\u679c\u3002", "result": "\u78b3\u6fc0\u52b1\u8ba1\u5212\u4f7f\u516c\u5171\u4ea4\u901a\u548c\u81ea\u884c\u8f66\u51fa\u884c\u6bcf\u6708\u589e\u52a020.3%\uff0c\u6c7d\u6cb9\u8f66\u4f7f\u7528\u6bcf\u65e5\u51cf\u5c111.8%\uff0c\u5e74\u78b3\u51cf\u6392\u7ea69.4\u4e07\u5428\uff0c\u76f8\u5f53\u4e8e\u5317\u4eac\u78b3\u5e02\u573a\u8ba4\u8bc1\u51cf\u6392\u91cf\u76845.7%\u3002\u867d\u7136\u6548\u679c\u968f\u65f6\u95f4\u51cf\u5f31\uff0c\u4f468\u4e2a\u6708\u540e\u53c2\u4e0e\u8005\u6bcf\u6708\u4ecd\u591a\u8fdb\u884c12.8%\u7684\u7eff\u8272\u51fa\u884c\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u63d0\u4f9b\u4e86\u78b3\u6fc0\u52b1\u5728MaaS\u4e2d\u6709\u6548\u6027\u7684\u9996\u4e2a\u5927\u89c4\u6a21\u5b9e\u8bc1\u8bc1\u636e\uff0c\u7a81\u663e\u4e86\u5176\u6f5c\u529b\uff0c\u53ef\u4e3a\u9488\u5bf9\u6027\u7684\u57ce\u5e02\u7279\u5b9a\u5e72\u9884\u63aa\u65bd\u63d0\u4f9b\u4fe1\u606f\uff0c\u652f\u6301\u5168\u7403\u4f4e\u78b3\u51fa\u884c\u8f6c\u578b\u3002"}}
{"id": "2511.09457", "categories": ["stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.09457", "abs": "https://arxiv.org/abs/2511.09457", "authors": ["Koen W. van Arem", "Jakob S\u00f6hl", "Mirjam Bruinsma", "Geurt Jongbloed"], "title": "The trade-off between model flexibility and accuracy of the Expected Threat model in football", "comment": "In Conference Proceedings MathSport International 2025 (pp. 150-155)", "summary": "With an average football (soccer) match recording over 3,000 on-ball events, effective use of this event data is essential for practitioners at football clubs to obtain meaningful insights. Models can extract more information from this data, and explainable methods can make them more accessible to practitioners. The Expected Threat model has been praised for its explainability and offers an accessible option. However, selecting the grid size is a challenging key design choice that has to be made when applying the Expected Threat model. Using a finer grid leads to a more flexible model that can better distinguish between different situations, but the accuracy of the estimates deteriorates with a more flexible model. Consequently, practitioners face challenges in balancing the trade-off between model flexibility and model accuracy. In this study, the Expected Threat model is analyzed from a theoretical perspective and simulations are performed based on the Markov chain of the model to examine its behavior in practice. Our theoretical results establish an upper bound on the error of the Expected Threat model for different flexibilities. Based on the simulations, a more accurate characterization of the model's error is provided, improving over the theoretical bound. Finally, these insights are converted into a practical rule of thumb to help practitioners choose the right balance between the model flexibility and the desired accuracy of the Expected Threat model.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u8db3\u7403\u9884\u671f\u5a01\u80c1\u6a21\u578b\u5728\u7f51\u683c\u5c3a\u5bf8\u9009\u62e9\u4e0a\u7684\u6743\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6a21\u62df\u5b9e\u9a8c\u63d0\u4f9b\u4e86\u8bef\u5dee\u8fb9\u754c\u548c\u5b9e\u7528\u6307\u5bfc\u539f\u5219\u3002", "motivation": "\u8db3\u7403\u6bd4\u8d5b\u4e2d\u5927\u91cf\u7684\u4e8b\u4ef6\u6570\u636e\u9700\u8981\u6709\u6548\u5229\u7528\uff0c\u9884\u671f\u5a01\u80c1\u6a21\u578b\u56e0\u5176\u53ef\u89e3\u91ca\u6027\u800c\u53d7\u5230\u9752\u7750\uff0c\u4f46\u7f51\u683c\u5c3a\u5bf8\u9009\u62e9\u9762\u4e34\u6a21\u578b\u7075\u6d3b\u6027\u4e0e\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u6743\u8861\u6311\u6218\u3002", "method": "\u4ece\u7406\u8bba\u89d2\u5ea6\u5206\u6790\u9884\u671f\u5a01\u80c1\u6a21\u578b\uff0c\u57fa\u4e8e\u6a21\u578b\u7684\u9a6c\u5c14\u53ef\u592b\u94fe\u8fdb\u884c\u6a21\u62df\u5b9e\u9a8c\uff0c\u7814\u7a76\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u884c\u4e3a\u3002", "result": "\u7406\u8bba\u7ed3\u679c\u5efa\u7acb\u4e86\u4e0d\u540c\u7075\u6d3b\u6027\u4e0b\u9884\u671f\u5a01\u80c1\u6a21\u578b\u8bef\u5dee\u7684\u4e0a\u754c\uff0c\u6a21\u62df\u5b9e\u9a8c\u63d0\u4f9b\u4e86\u6bd4\u7406\u8bba\u8fb9\u754c\u66f4\u51c6\u786e\u7684\u8bef\u5dee\u7279\u5f81\u63cf\u8ff0\u3002", "conclusion": "\u5c06\u7814\u7a76\u6d1e\u5bdf\u8f6c\u5316\u4e3a\u5b9e\u7528\u7ecf\u9a8c\u6cd5\u5219\uff0c\u5e2e\u52a9\u4ece\u4e1a\u8005\u5728\u6a21\u578b\u7075\u6d3b\u6027\u548c\u9884\u671f\u5a01\u80c1\u6a21\u578b\u6240\u9700\u51c6\u786e\u6027\u4e4b\u95f4\u9009\u62e9\u9002\u5f53\u5e73\u8861\u3002"}}
{"id": "2511.08856", "categories": ["cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.08856", "abs": "https://arxiv.org/abs/2511.08856", "authors": ["Krishu K Thapa", "Supriya Savalkar", "Bhupinderjeet Singh", "Trong Nghia Hoang", "Kirti Rajagopalan", "Ananth Kalyanaraman"], "title": "ForeSWE: Forecasting Snow-Water Equivalent with an Uncertainty-Aware Attention Model", "comment": "Accepted for publication at the 2026 AAAI conference", "summary": "Various complex water management decisions are made in snow-dominant watersheds with the knowledge of Snow-Water Equivalent (SWE) -- a key measure widely used to estimate the water content of a snowpack. However, forecasting SWE is challenging because SWE is influenced by various factors including topography and an array of environmental conditions, and has therefore been observed to be spatio-temporally variable. Classical approaches to SWE forecasting have not adequately utilized these spatial/temporal correlations, nor do they provide uncertainty estimates -- which can be of significant value to the decision maker. In this paper, we present ForeSWE, a new probabilistic spatio-temporal forecasting model that integrates deep learning and classical probabilistic techniques. The resulting model features a combination of an attention mechanism to integrate spatiotemporal features and interactions, alongside a Gaussian process module that provides principled quantification of prediction uncertainty. We evaluate the model on data from 512 Snow Telemetry (SNOTEL) stations in the Western US. The results show significant improvements in both forecasting accuracy and prediction interval compared to existing approaches. The results also serve to highlight the efficacy in uncertainty estimates between different approaches. Collectively, these findings have provided a platform for deployment and feedback by the water management community.", "AI": {"tldr": "ForeSWE\u662f\u4e00\u4e2a\u65b0\u7684\u6982\u7387\u65f6\u7a7a\u9884\u6d4b\u6a21\u578b\uff0c\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u548c\u7ecf\u5178\u6982\u7387\u6280\u672f\uff0c\u7528\u4e8e\u9884\u6d4b\u96ea\u6c34\u5f53\u91cf(SWE)\uff0c\u5728\u51c6\u786e\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edfSWE\u9884\u6d4b\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u5229\u7528\u65f6\u7a7a\u76f8\u5173\u6027\uff0c\u4e5f\u4e0d\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u800c\u8fd9\u5bf9\u6c34\u8d44\u6e90\u7ba1\u7406\u51b3\u7b56\u8005\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002", "method": "\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236\u6574\u5408\u65f6\u7a7a\u7279\u5f81\u548c\u4ea4\u4e92\uff0c\u4ee5\u53ca\u9ad8\u65af\u8fc7\u7a0b\u6a21\u5757\u63d0\u4f9b\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u539f\u5219\u6027\u91cf\u5316\u3002", "result": "\u5728\u897f\u90e8\u7f8e\u56fd512\u4e2aSNOTEL\u7ad9\u70b9\u6570\u636e\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u9884\u6d4b\u533a\u95f4\u65b9\u9762\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u6c34\u8d44\u6e90\u7ba1\u7406\u793e\u533a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u90e8\u7f72\u548c\u53cd\u9988\u7684\u5e73\u53f0\uff0c\u7a81\u51fa\u4e86\u4e0d\u540c\u65b9\u6cd5\u5728\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.08733", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08733", "abs": "https://arxiv.org/abs/2511.08733", "authors": ["Carlos A. Taveras", "Santiago Segarra", "C\u00e9sar A. Uribe"], "title": "Gromov-Wasserstein Graph Coarsening", "comment": "11 pages, 2 figures", "summary": "We study the problem of graph coarsening within the Gromov-Wasserstein geometry. Specifically, we propose two algorithms that leverage a novel representation of the distortion induced by merging pairs of nodes. The first method, termed Greedy Pair Coarsening (GPC), iteratively merges pairs of nodes that locally minimize a measure of distortion until the desired size is achieved. The second method, termed $k$-means Greedy Pair Coarsening (KGPC), leverages clustering based on pairwise distortion metrics to directly merge clusters of nodes. We provide conditions guaranteeing optimal coarsening for our methods and validate their performance on six large-scale datasets and a downstream clustering task. Results show that the proposed methods outperform existing approaches on a wide range of parameters and scenarios.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u57fa\u4e8eGromov-Wasserstein\u51e0\u4f55\u7684\u56fe\u7c97\u5316\u7b97\u6cd5\uff1aGPC\u548cKGPC\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u8282\u70b9\u5408\u5e76\u5f15\u8d77\u7684\u5931\u771f\u6765\u4f18\u5316\u56fe\u7ed3\u6784\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u56fe\u7c97\u5316\u95ee\u9898\u5728Gromov-Wasserstein\u51e0\u4f55\u6846\u67b6\u4e0b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u65e8\u5728\u5f00\u53d1\u80fd\u591f\u6709\u6548\u51cf\u5c11\u56fe\u89c4\u6a21\u540c\u65f6\u4fdd\u6301\u7ed3\u6784\u7279\u5f81\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u7b97\u6cd5\uff1aGPC\uff08\u8d2a\u5a6a\u5bf9\u7c97\u5316\uff09\u8fed\u4ee3\u5408\u5e76\u6700\u5c0f\u5316\u5c40\u90e8\u5931\u771f\u7684\u8282\u70b9\u5bf9\uff1bKGPC\uff08k\u5747\u503c\u8d2a\u5a6a\u5bf9\u7c97\u5316\uff09\u57fa\u4e8e\u6210\u5bf9\u5931\u771f\u5ea6\u91cf\u7684\u805a\u7c7b\u76f4\u63a5\u5408\u5e76\u8282\u70b9\u7c07\u3002", "result": "\u5728\u516d\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548c\u4e0b\u6e38\u805a\u7c7b\u4efb\u52a1\u4e0a\u7684\u9a8c\u8bc1\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u5e7f\u6cdb\u53c2\u6570\u548c\u573a\u666f\u4e0b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8eGromov-Wasserstein\u51e0\u4f55\u7684\u56fe\u7c97\u5316\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u4fdd\u6301\u56fe\u7ed3\u6784\u7279\u5f81\uff0c\u5728\u591a\u79cd\u5e94\u7528\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2504.03359", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2504.03359", "abs": "https://arxiv.org/abs/2504.03359", "authors": ["Samuel Bilson", "Maurice Cox", "Anna Pustogvar", "Andrew Thompson"], "title": "A metrological framework for uncertainty evaluation in machine learning classification models", "comment": "51 pages, 5 figures", "summary": "Machine learning (ML) classification models are increasingly being used in a wide range of applications where it is important that predictions are accompanied by uncertainties, including in climate and earth observation, medical diagnosis and bioaerosol monitoring. The output of an ML classification model is a type of categorical variable known as a nominal property in the International Vocabulary of Metrology (VIM). However, concepts related to uncertainty evaluation for nominal properties are not defined in the VIM, nor is such evaluation addressed by the Guide to the Expression of Uncertainty in Measurement (GUM). In this paper we propose a metrological conceptual uncertainty evaluation framework for nominal properties. This framework is based on probability mass functions and summary statistics thereof, and it is applicable to ML classification. We also illustrate its use in the context of two applications that exemplify the issues and have significant societal impact, namely, climate and earth observation and medical diagnosis. Our framework would enable an extension of the GUM to uncertainty for nominal properties, which would make both applicable to ML classification models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u540d\u4e49\u5c5e\u6027\u7684\u8ba1\u91cf\u5b66\u6982\u5ff5\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u57fa\u4e8e\u6982\u7387\u8d28\u91cf\u51fd\u6570\u53ca\u5176\u6c47\u603b\u7edf\u8ba1\u91cf\uff0c\u9002\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u6a21\u578b\u5728\u6c14\u5019\u89c2\u6d4b\u3001\u533b\u7597\u8bca\u65ad\u7b49\u5173\u952e\u5e94\u7528\u4e2d\u9700\u8981\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u4fe1\u606f\uff0c\u4f46\u73b0\u6709\u56fd\u9645\u8ba1\u91cf\u5b66\u8bcd\u6c47\u548c\u6d4b\u91cf\u4e0d\u786e\u5b9a\u5ea6\u8868\u8fbe\u6307\u5357\u672a\u5b9a\u4e49\u540d\u4e49\u5c5e\u6027\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u6982\u5ff5\u3002", "method": "\u57fa\u4e8e\u6982\u7387\u8d28\u91cf\u51fd\u6570\u53ca\u5176\u6c47\u603b\u7edf\u8ba1\u91cf\u6784\u5efa\u8ba1\u91cf\u5b66\u6982\u5ff5\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u5728\u6c14\u5019\u4e0e\u5730\u7403\u89c2\u6d4b\u3001\u533b\u7597\u8bca\u65ad\u4e24\u4e2a\u5e94\u7528\u573a\u666f\u4e2d\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u4e3a\u540d\u4e49\u5c5e\u6027\u63d0\u4f9b\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\uff0c\u4f7f\u6d4b\u91cf\u4e0d\u786e\u5b9a\u5ea6\u8868\u8fbe\u6307\u5357\u53ef\u6269\u5c55\u5230\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u6a21\u578b\u3002", "conclusion": "\u8be5\u6846\u67b6\u586b\u8865\u4e86\u540d\u4e49\u5c5e\u6027\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u7684\u7a7a\u767d\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u6a21\u578b\u5728\u5173\u952e\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u4f7f\u7528\u63d0\u4f9b\u4e86\u8ba1\u91cf\u5b66\u57fa\u7840\u3002"}}
{"id": "2511.09140", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09140", "abs": "https://arxiv.org/abs/2511.09140", "authors": ["Xuyao Yu", "Zijun Gong", "Zhilu Lai"], "title": "LMMSE-Optimal Pilot Pattern Design Based on Covariance Matrix Approximation for OFDM Channel Estimation in Doubly Dispersive Channel", "comment": "This manuscript was submitted to IEEE International Conference on Communications (ICC) 2026", "summary": "This paper investigates the optimal pilot pattern design, in the linear minimum mean square error (LMMSE) estimator sense, for OFDM systems in doubly dispersive channels. To enable analytical tractability, the channel covariance matrix is decomposed into the Kronecker product of two Hermitian Toeplitz matrices corresponding to the delay and Doppler domains. By invoking the Szeg\u00f6 limit theorem, these matrices are shown to be approximately diagonalizable by discrete Fourier transform (DFT) matrices. Based on this structure, the LMMSE channel estimation error is reformulated into a compact analytical form, from which a closed-form lower bound is derived. Furthermore, we establish the condition under which this bound is achieved by a lattice-based pilot pattern. Numerical results verify that the proposed matrix approximation introduces negligible error and examples of the proposed lattice design are given.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u53cc\u5f25\u6563\u4fe1\u9053\u4e2dOFDM\u7cfb\u7edf\u7684\u6700\u4f18\u5bfc\u9891\u6a21\u5f0f\u8bbe\u8ba1\uff0c\u57fa\u4e8eLMMSE\u4f30\u8ba1\u5668\u3002\u901a\u8fc7\u5c06\u4fe1\u9053\u534f\u65b9\u5dee\u77e9\u9635\u5206\u89e3\u4e3a\u5ef6\u8fdf\u57df\u548c\u591a\u666e\u52d2\u57df\u7684Kronecker\u79ef\uff0c\u5229\u7528Szeg\u00f6\u6781\u9650\u5b9a\u7406\u8fd1\u4f3c\u5bf9\u89d2\u5316\uff0c\u63a8\u5bfc\u51faLMMSE\u4fe1\u9053\u4f30\u8ba1\u8bef\u5dee\u7684\u7d27\u51d1\u89e3\u6790\u5f62\u5f0f\u548c\u95ed\u5f0f\u4e0b\u754c\uff0c\u5e76\u5efa\u7acb\u4e86\u5b9e\u73b0\u8be5\u4e0b\u754c\u7684\u683c\u70b9\u5bfc\u9891\u6a21\u5f0f\u6761\u4ef6\u3002", "motivation": "\u5728\u53cc\u5f25\u6563\u4fe1\u9053\u4e2d\uff0cOFDM\u7cfb\u7edf\u7684\u4fe1\u9053\u4f30\u8ba1\u6027\u80fd\u53d7\u5bfc\u9891\u6a21\u5f0f\u8bbe\u8ba1\u5f71\u54cd\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5bf9LMMSE\u4f30\u8ba1\u5668\u4e0b\u6700\u4f18\u5bfc\u9891\u6a21\u5f0f\u7684\u7cfb\u7edf\u5206\u6790\uff0c\u9700\u8981\u5efa\u7acb\u7406\u8bba\u6846\u67b6\u6765\u6307\u5bfc\u5b9e\u9645\u5bfc\u9891\u8bbe\u8ba1\u3002", "method": "\u5c06\u4fe1\u9053\u534f\u65b9\u5dee\u77e9\u9635\u5206\u89e3\u4e3a\u5ef6\u8fdf\u57df\u548c\u591a\u666e\u52d2\u57df\u7684Hermitian Toeplitz\u77e9\u9635\u7684Kronecker\u79ef\uff0c\u5229\u7528Szeg\u00f6\u6781\u9650\u5b9a\u7406\u8bc1\u660e\u8fd9\u4e9b\u77e9\u9635\u53ef\u7531DFT\u77e9\u9635\u8fd1\u4f3c\u5bf9\u89d2\u5316\uff0c\u4ece\u800c\u5c06LMMSE\u4fe1\u9053\u4f30\u8ba1\u8bef\u5dee\u91cd\u65b0\u8868\u8ff0\u4e3a\u7d27\u51d1\u89e3\u6790\u5f62\u5f0f\uff0c\u5e76\u63a8\u5bfc\u95ed\u5f0f\u4e0b\u754c\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u51fa\u7684\u77e9\u9635\u8fd1\u4f3c\u5f15\u5165\u7684\u8bef\u5dee\u53ef\u5ffd\u7565\u4e0d\u8ba1\uff0c\u7ed9\u51fa\u4e86\u6240\u63d0\u51fa\u7684\u683c\u70b9\u8bbe\u8ba1\u5b9e\u4f8b\uff0c\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u5efa\u7acb\u4e86\u53cc\u5f25\u6563\u4fe1\u9053\u4e2dOFDM\u7cfb\u7edfLMMSE\u4fe1\u9053\u4f30\u8ba1\u7684\u7406\u8bba\u6846\u67b6\uff0c\u63a8\u5bfc\u4e86\u6700\u4f18\u5bfc\u9891\u6a21\u5f0f\u7684\u95ed\u5f0f\u4e0b\u754c\uff0c\u5e76\u8bc1\u660e\u4e86\u683c\u70b9\u5bfc\u9891\u6a21\u5f0f\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u53ef\u5b9e\u73b0\u8be5\u4e0b\u754c\uff0c\u4e3a\u5b9e\u9645\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2511.09150", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09150", "abs": "https://arxiv.org/abs/2511.09150", "authors": ["Yulin Fu", "Jiancun Fan", "Shiyu Zhai", "Zhibo Duan", "Jie Luo"], "title": "Mip-NeWRF: Enhanced Wireless Radiance Field with Hybrid Encoding for Channel Prediction", "comment": "13 pages, 12 figures", "summary": "Recent work on wireless radiance fields represents a promising deep learning approach for channel prediction, however, in complex environments these methods still exhibit limited robustness, slow convergence, and modest accuracy due to insufficiently refined modeling. To address this issue, we propose Mip-NeWRF, a physics-informed neural framework for accurate indoor channel prediction based on sparse channel measurements. The framework operates in a ray-based pipeline with coarse-to-fine importance sampling: frustum samples are encoded, processed by a shared multilayer perceptron (MLP), and the outputs are synthesized into the channel frequency response (CFR). Prior to MLP input, Mip-NeWRF performs conical-frustum sampling and applies a scale-consistent hybrid positional encoding to each frustum. The scale-consistent normalization aligns positional encodings across scene scales, while the hybrid encoding supplies both scale-robust, low-frequency stability to accelerate convergence and fine spatial detail to improve accuracy. During training, a curriculum learning schedule is applied to stabilize and accelerate convergence of the shared MLP. During channel synthesis, the MLP outputs, including predicted virtual transmitter presence probabilities and amplitudes, are combined with modeled pathloss and surface interaction attenuation to enhance physical fidelity and further improve accuracy. Simulation results demonstrate the effectiveness of the proposed approach: in typical scenarios, the normalized mean square error (NMSE) is reduced by 14.3 dB versus state-of-the-art baselines.", "AI": {"tldr": "Mip-NeWRF\u662f\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u7684\u795e\u7ecf\u6846\u67b6\uff0c\u901a\u8fc7\u5706\u9525\u622a\u5934\u4f53\u91c7\u6837\u548c\u5c3a\u5ea6\u4e00\u81f4\u6df7\u5408\u4f4d\u7f6e\u7f16\u7801\uff0c\u7ed3\u5408\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5ba4\u5185\u4fe1\u9053\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u73b0\u6709\u65e0\u7ebf\u8f90\u5c04\u573a\u65b9\u6cd5\u5728\u590d\u6742\u73af\u5883\u4e2d\u5b58\u5728\u9c81\u68d2\u6027\u4e0d\u8db3\u3001\u6536\u655b\u6162\u548c\u7cbe\u5ea6\u6709\u9650\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u5efa\u6a21\u65b9\u6cd5\u6765\u6539\u8fdb\u4fe1\u9053\u9884\u6d4b\u6027\u80fd\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5c04\u7ebf\u7684\u7c97\u5230\u7ec6\u91cd\u8981\u6027\u91c7\u6837\u6d41\u7a0b\uff0c\u8fdb\u884c\u5706\u9525\u622a\u5934\u4f53\u91c7\u6837\u5e76\u5e94\u7528\u5c3a\u5ea6\u4e00\u81f4\u6df7\u5408\u4f4d\u7f6e\u7f16\u7801\uff0c\u4f7f\u7528\u5171\u4eab\u591a\u5c42\u611f\u77e5\u5668\u5904\u7406\uff0c\u7ed3\u5408\u8bfe\u7a0b\u5b66\u4e60\u8bad\u7ec3\u7b56\u7565\uff0c\u5728\u4fe1\u9053\u5408\u6210\u4e2d\u6574\u5408\u8def\u5f84\u635f\u8017\u548c\u8868\u9762\u4ea4\u4e92\u8870\u51cf\u6a21\u578b\u3002", "result": "\u5728\u5178\u578b\u573a\u666f\u4e2d\uff0c\u4e0e\u6700\u5148\u8fdb\u57fa\u7ebf\u76f8\u6bd4\uff0c\u5f52\u4e00\u5316\u5747\u65b9\u8bef\u5dee\u964d\u4f4e\u4e8614.3 dB\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fe1\u9053\u9884\u6d4b\u7cbe\u5ea6\u3002", "conclusion": "Mip-NeWRF\u6846\u67b6\u901a\u8fc7\u7cbe\u7ec6\u7684\u91c7\u6837\u7b56\u7565\u3001\u6df7\u5408\u7f16\u7801\u548c\u7269\u7406\u4fe1\u606f\u6574\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u73af\u5883\u4e2d\u4fe1\u9053\u9884\u6d4b\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3002"}}
{"id": "2511.09165", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09165", "abs": "https://arxiv.org/abs/2511.09165", "authors": ["Wouter Jansen", "Walter Daems", "Jan Steckel"], "title": "Delay-Multiply-And-Sum Beamforming for Real-Time In-Air Acoustic Imaging", "comment": null, "summary": "In-air acoustic imaging systems demand beamforming techniques that offer a high dynamic range and spatial resolution while also remaining robust. Conventional Delay-and-Sum (DAS) beamforming fails to meet these quality demands due to high sidelobes, a wide main lobe and the resulting low contrast, whereas advanced adaptive methods are typically precluded by the computational cost and the single-snapshot constraint of real-time field operation. To overcome this trade-off, we propose and detail the implementation of higher-order non-linear beamforming methods using the Delay-Multiply-and-Sum technique, coupled with Coherence Factor weighting, specifically adapted for ultrasonic in-air microphone arrays. Our efficient implementation allows for enabling GPU-accelerated, real-time performance on embedded computing platforms. Through validation against the DAS baseline using simulated and real-world acoustic data, we demonstrate that the proposed method provides significant improvements in image contrast, establishing higher-order non-linear beamforming as a practical, high-performance solution for in-air acoustic imaging.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5ef6\u8fdf-\u4e58\u6cd5\u548c\u548c\uff08DMAS\uff09\u6280\u672f\u7ed3\u5408\u76f8\u5e72\u56e0\u5b50\u52a0\u6743\u7684\u975e\u7ebf\u6027\u6ce2\u675f\u5f62\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u9ad8\u7a7a\u6c14\u58f0\u5b66\u6210\u50cf\u7cfb\u7edf\u7684\u52a8\u6001\u8303\u56f4\u548c\u7a7a\u95f4\u5206\u8fa8\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u5b9e\u65f6\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u5ef6\u8fdf\u6c42\u548c\uff08DAS\uff09\u6ce2\u675f\u5f62\u6210\u65b9\u6cd5\u7531\u4e8e\u9ad8\u65c1\u74e3\u3001\u5bbd\u4e3b\u74e3\u548c\u4f4e\u5bf9\u6bd4\u5ea6\u800c\u65e0\u6cd5\u6ee1\u8db3\u8d28\u91cf\u8981\u6c42\uff0c\u800c\u81ea\u9002\u5e94\u65b9\u6cd5\u53c8\u53d7\u9650\u4e8e\u8ba1\u7b97\u6210\u672c\u548c\u5b9e\u65f6\u64cd\u4f5c\u7684\u5355\u4e00\u5feb\u7167\u7ea6\u675f\u3002", "method": "\u91c7\u7528\u9ad8\u9636\u975e\u7ebf\u6027\u6ce2\u675f\u5f62\u6210\u65b9\u6cd5\uff0c\u7ed3\u5408\u5ef6\u8fdf-\u4e58\u6cd5\u548c\u548c\uff08DMAS\uff09\u6280\u672f\u4e0e\u76f8\u5e72\u56e0\u5b50\u52a0\u6743\uff0c\u4e13\u95e8\u9488\u5bf9\u7a7a\u6c14\u8d85\u58f0\u9ea6\u514b\u98ce\u9635\u5217\u8fdb\u884c\u4f18\u5316\uff0c\u5e76\u901a\u8fc7GPU\u52a0\u901f\u5b9e\u73b0\u5d4c\u5165\u5f0f\u5e73\u53f0\u4e0a\u7684\u5b9e\u65f6\u6027\u80fd\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u548c\u5b9e\u9645\u58f0\u5b66\u6570\u636e\u9a8c\u8bc1\uff0c\u4e0eDAS\u57fa\u7ebf\u76f8\u6bd4\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u56fe\u50cf\u5bf9\u6bd4\u5ea6\u65b9\u9762\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u9ad8\u9636\u975e\u7ebf\u6027\u6ce2\u675f\u5f62\u6210\u6210\u4e3a\u7a7a\u6c14\u58f0\u5b66\u6210\u50cf\u4e2d\u5b9e\u7528\u4e14\u9ad8\u6027\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.08831", "categories": ["cs.LG", "eess.SY", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.08831", "abs": "https://arxiv.org/abs/2511.08831", "authors": ["Tomoki Koike", "Elizabeth Qian"], "title": "Physics-Informed Machine Learning for Characterizing System Stability", "comment": null, "summary": "In the design and operation of complex dynamical systems, it is essential to ensure that all state trajectories of the dynamical system converge to a desired equilibrium within a guaranteed stability region. Yet, for many practical systems -- especially in aerospace -- this region cannot be determined a priori and is often challenging to compute. One of the most common methods for computing the stability region is to identify a Lyapunov function. A Lyapunov function is a positive function whose time derivative along system trajectories is non-positive, which provides a sufficient condition for stability and characterizes an estimated stability region. However, existing methods of characterizing a stability region via a Lyapunov function often rely on explicit knowledge of the system governing equations. In this work, we present a new physics-informed machine learning method of characterizing an estimated stability region by inferring a Lyapunov function from system trajectory data that treats the dynamical system as a black box and does not require explicit knowledge of the system governing equations. In our presented Lyapunov function Inference method (LyapInf), we propose a quadratic form for the unknown Lyapunov function and fit the unknown quadratic operator to system trajectory data by minimizing the average residual of the Zubov equation, a first-order partial differential equation whose solution yields a Lyapunov function. The inferred quadratic Lyapunov function can then characterize an ellipsoidal estimate of the stability region. Numerical results on benchmark examples demonstrate that our physics-informed stability analysis method successfully characterizes a near-maximal ellipsoid of the system stability region associated with the inferred Lyapunov function without requiring knowledge of the system governing equations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u7684Lyapunov\u51fd\u6570\u63a8\u65ad\u65b9\u6cd5\uff08LyapInf\uff09\uff0c\u901a\u8fc7\u7cfb\u7edf\u8f68\u8ff9\u6570\u636e\u63a8\u65adLyapunov\u51fd\u6570\u6765\u4f30\u8ba1\u7a33\u5b9a\u6027\u533a\u57df\uff0c\u65e0\u9700\u7cfb\u7edf\u63a7\u5236\u65b9\u7a0b\u7684\u663e\u5f0f\u77e5\u8bc6\u3002", "motivation": "\u5728\u590d\u6742\u52a8\u529b\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\uff0c\u786e\u4fdd\u72b6\u6001\u8f68\u8ff9\u6536\u655b\u5230\u671f\u671b\u5e73\u8861\u70b9\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7a33\u5b9a\u6027\u533a\u57df\u5f80\u5f80\u96be\u4ee5\u8ba1\u7b97\u3002\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u7cfb\u7edf\u63a7\u5236\u65b9\u7a0b\u7684\u663e\u5f0f\u77e5\u8bc6\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u63d0\u51faLyapInf\u65b9\u6cd5\uff0c\u5047\u8bbeLyapunov\u51fd\u6570\u4e3a\u4e8c\u6b21\u578b\uff0c\u901a\u8fc7\u6700\u5c0f\u5316Zubov\u65b9\u7a0b\u7684\u5e73\u5747\u6b8b\u5dee\u6765\u62df\u5408\u672a\u77e5\u7684\u4e8c\u6b21\u7b97\u5b50\uff0c\u4ece\u800c\u4ece\u8f68\u8ff9\u6570\u636e\u4e2d\u63a8\u65adLyapunov\u51fd\u6570\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u6210\u529f\u63a8\u65ad\u51fa\u63a5\u8fd1\u6700\u5927\u692d\u7403\u5f62\u7684\u7a33\u5b9a\u6027\u533a\u57df\u4f30\u8ba1\uff0c\u65e0\u9700\u7cfb\u7edf\u63a7\u5236\u65b9\u7a0b\u77e5\u8bc6\u3002", "conclusion": "LyapInf\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u636e\u9a71\u52a8\u7684\u7a33\u5b9a\u6027\u5206\u6790\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u4f30\u8ba1\u52a8\u529b\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u533a\u57df\uff0c\u9002\u7528\u4e8e\u9ed1\u76d2\u7cfb\u7edf\u5206\u6790\u3002"}}
{"id": "2511.09207", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09207", "abs": "https://arxiv.org/abs/2511.09207", "authors": ["Yuan Zhong", "Yue Xiao", "Yijia Li", "Hao Chen", "Xianfu Lei", "Pingzhi Fan"], "title": "Two-Dimensional Pinching-Antenna Systems: Modeling and Beamforming Design", "comment": "32 pages, 10 figures, 2 tables, pinching-antenna system (PASS)", "summary": "Recently, the pinching-antenna system (PASS) has emerged as a promising architecture owing to its ability to reconfigure large-scale path loss and signal phase by activating radiation points along a dielectric waveguide. However, existing studies mainly focus on line-shaped PASS architectures, whose limited spatial flexibility constrains their applicability in multiuser and indoor scenarios. In this paper, we propose a novel two-dimensional (2D) pinching-antenna system (2D-PASS) that extends the conventional line-shaped structure into a continuous dielectric waveguide plane, thereby forming a reconfigurable radiating plane capable of dynamic beam adaptation across a 2D spatial domain. An optimization framework is developed to maximize the minimum received signal-to-noise ratio (SNR) among user equipments (UEs) by adaptively adjusting the spatial configuration of pinching antennas (PAs), serving as an analog beamforming mechanism for dynamic spatial control. For the continuous-position scenario, a particle swarm optimization (PSO)-based algorithm is proposed to efficiently explore the nonconvex search space, while a discrete variant is introduced to accommodate practical hardware constraints with limited PA placement resolution. Simulation results demonstrate that the proposed 2D-PASS substantially improves the minimum SNR compared with conventional line-shaped PASS and fixed-position antenna (FPA) benchmarks, while maintaining robustness under varying user distributions and distances.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u4e8c\u7ef4\u5939\u6301\u5929\u7ebf\u7cfb\u7edf\uff082D-PASS\uff09\uff0c\u5c06\u4f20\u7edf\u7684\u7ebf\u5f62\u7ed3\u6784\u6269\u5c55\u4e3a\u8fde\u7eed\u7684\u4ecb\u8d28\u6ce2\u5bfc\u5e73\u9762\uff0c\u5f62\u6210\u53ef\u91cd\u6784\u7684\u8f90\u5c04\u5e73\u9762\uff0c\u80fd\u591f\u5728\u4e8c\u7ef4\u7a7a\u95f4\u57df\u4e2d\u5b9e\u73b0\u52a8\u6001\u6ce2\u675f\u81ea\u9002\u5e94\u3002", "motivation": "\u73b0\u6709\u7684\u5939\u6301\u5929\u7ebf\u7cfb\u7edf\uff08PASS\uff09\u4e3b\u8981\u91c7\u7528\u7ebf\u5f62\u67b6\u6784\uff0c\u5176\u6709\u9650\u7684\u7a7a\u95f4\u7075\u6d3b\u6027\u9650\u5236\u4e86\u5728\u591a\u7528\u6237\u548c\u5ba4\u5185\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u6574\u5939\u6301\u5929\u7ebf\u7684\u7a7a\u95f4\u914d\u7f6e\u6765\u6700\u5927\u5316\u7528\u6237\u8bbe\u5907\u7684\u6700\u5c0f\u63a5\u6536\u4fe1\u566a\u6bd4\uff0c\u4f5c\u4e3a\u52a8\u6001\u7a7a\u95f4\u63a7\u5236\u7684\u6a21\u62df\u6ce2\u675f\u5f62\u6210\u673a\u5236\u3002\u9488\u5bf9\u8fde\u7eed\u4f4d\u7f6e\u573a\u666f\u63d0\u51fa\u4e86\u57fa\u4e8e\u7c92\u5b50\u7fa4\u4f18\u5316\u7684\u7b97\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86\u79bb\u6563\u53d8\u4f53\u4ee5\u9002\u5e94\u5b9e\u9645\u786c\u4ef6\u7ea6\u675f\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u7684\u7ebf\u5f62PASS\u548c\u56fa\u5b9a\u4f4d\u7f6e\u5929\u7ebf\u57fa\u51c6\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u76842D-PASS\u663e\u8457\u63d0\u9ad8\u4e86\u6700\u5c0f\u4fe1\u566a\u6bd4\uff0c\u540c\u65f6\u5728\u53d8\u5316\u7684\u7528\u6237\u5206\u5e03\u548c\u8ddd\u79bb\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "2D-PASS\u901a\u8fc7\u6269\u5c55\u4e3a\u4e8c\u7ef4\u7ed3\u6784\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7a7a\u95f4\u7075\u6d3b\u6027\u548c\u6027\u80fd\uff0c\u5728\u591a\u7528\u6237\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2511.08832", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08832", "abs": "https://arxiv.org/abs/2511.08832", "authors": ["Nikunj Gupta", "Ludwika Twardecka", "James Zachary Hare", "Jesse Milzman", "Rajgopal Kannan", "Viktor Prasanna"], "title": "TIGER-MARL: Enhancing Multi-Agent Reinforcement Learning with Temporal Information through Graph-based Embeddings and Representations", "comment": null, "summary": "In this paper, we propose capturing and utilizing \\textit{Temporal Information through Graph-based Embeddings and Representations} or \\textbf{TIGER} to enhance multi-agent reinforcement learning (MARL). We explicitly model how inter-agent coordination structures evolve over time. While most MARL approaches rely on static or per-step relational graphs, they overlook the temporal evolution of interactions that naturally arise as agents adapt, move, or reorganize cooperation strategies. Capturing such evolving dependencies is key to achieving robust and adaptive coordination. To this end, TIGER constructs dynamic temporal graphs of MARL agents, connecting their current and historical interactions. It then employs a temporal attention-based encoder to aggregate information across these structural and temporal neighborhoods, yielding time-aware agent embeddings that guide cooperative policy learning. Through extensive experiments on two coordination-intensive benchmarks, we show that TIGER consistently outperforms diverse value-decomposition and graph-based MARL baselines in task performance and sample efficiency. Furthermore, we conduct comprehensive ablation studies to isolate the impact of key design parameters in TIGER, revealing how structural and temporal factors can jointly shape effective policy learning in MARL. All codes can be found here: https://github.com/Nikunj-Gupta/tiger-marl.", "AI": {"tldr": "TIGER\u901a\u8fc7\u56fe\u5d4c\u5165\u548c\u8868\u793a\u6355\u83b7\u65f6\u95f4\u4fe1\u606f\u6765\u589e\u5f3a\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff0c\u663e\u5f0f\u5efa\u6a21\u667a\u80fd\u4f53\u95f4\u534f\u8c03\u7ed3\u6784\u968f\u65f6\u95f4\u6f14\u5316\u7684\u8fc7\u7a0b\u3002", "motivation": "\u5927\u591a\u6570MARL\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u6216\u6bcf\u6b65\u5173\u7cfb\u56fe\uff0c\u5ffd\u7565\u4e86\u667a\u80fd\u4f53\u5728\u9002\u5e94\u3001\u79fb\u52a8\u6216\u91cd\u7ec4\u5408\u4f5c\u7b56\u7565\u65f6\u81ea\u7136\u4ea7\u751f\u7684\u65f6\u95f4\u4ea4\u4e92\u6f14\u5316\u3002\u6355\u83b7\u8fd9\u79cd\u6f14\u5316\u4f9d\u8d56\u5173\u7cfb\u5bf9\u4e8e\u5b9e\u73b0\u7a33\u5065\u548c\u81ea\u9002\u5e94\u534f\u8c03\u81f3\u5173\u91cd\u8981\u3002", "method": "TIGER\u6784\u5efaMARL\u667a\u80fd\u4f53\u7684\u52a8\u6001\u65f6\u95f4\u56fe\uff0c\u8fde\u63a5\u5f53\u524d\u548c\u5386\u53f2\u4ea4\u4e92\uff0c\u4f7f\u7528\u65f6\u5e8f\u6ce8\u610f\u529b\u7f16\u7801\u5668\u805a\u5408\u7ed3\u6784\u548c\u65f6\u95f4\u90bb\u57df\u4fe1\u606f\uff0c\u751f\u6210\u65f6\u95f4\u611f\u77e5\u7684\u667a\u80fd\u4f53\u5d4c\u5165\u6765\u6307\u5bfc\u5408\u4f5c\u7b56\u7565\u5b66\u4e60\u3002", "result": "\u5728\u4e24\u4e2a\u534f\u8c03\u5bc6\u96c6\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTIGER\u5728\u4efb\u52a1\u6027\u80fd\u548c\u6837\u672c\u6548\u7387\u65b9\u9762\u6301\u7eed\u4f18\u4e8e\u5404\u79cd\u57fa\u4e8e\u4ef7\u503c\u5206\u89e3\u548c\u56fe\u57fa\u7840\u7684MARL\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u5168\u9762\u7684\u6d88\u878d\u7814\u7a76\u63ed\u793a\u4e86\u7ed3\u6784\u548c\u65f6\u95f4\u56e0\u7d20\u5982\u4f55\u5171\u540c\u5851\u9020MARL\u4e2d\u7684\u6709\u6548\u7b56\u7565\u5b66\u4e60\uff0c\u8bc1\u660e\u4e86\u6355\u83b7\u65f6\u95f4\u6f14\u5316\u534f\u8c03\u7ed3\u6784\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.09227", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09227", "abs": "https://arxiv.org/abs/2511.09227", "authors": ["Jos\u00e9 Miguel Mateos-Ramos", "Frederik Zumegen", "Henk Wymeersch", "Christian H\u00e4ger", "Christoph Studer"], "title": "Positioning via Digital-Twin-Aided Channel Charting with Large-Scale CSI Features", "comment": "12 pages, 4 figures. Submitted to an IEEE journal", "summary": "Channel charting (CC) is a self-supervised positioning technique whose main limitation is that the estimated positions lie in an arbitrary coordinate system that is not aligned with true spatial coordinates. In this work, we propose a novel method to produce CC locations in true spatial coordinates with the aid of a digital twin (DT). Our main contribution is a new framework that (i) extracts large-scale channel-state information (CSI) features from estimated CSI and the DT and (ii) matches these features with a cosine-similarity loss function. The DT-aided loss function is then combined with a conventional CC loss to learn a positioning function that provides true spatial coordinates without relying on labeled data. Our results for a simulated indoor scenario demonstrate that the proposed framework reduces the relative mean distance error by 29% compared to the state of the art. We also show that the proposed approach is robust to DT modeling mismatches and a distribution shift in the testing data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u6570\u5b57\u5b6a\u751f\u5c06\u4fe1\u9053\u56fe\u7ed8\u5236\u6280\u672f\u4e2d\u7684\u4efb\u610f\u5750\u6807\u7cfb\u8f6c\u6362\u4e3a\u771f\u5b9e\u7a7a\u95f4\u5750\u6807\u7cfb\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u5927\u89c4\u6a21\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u7279\u5f81\u5e76\u4f7f\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u635f\u5931\u51fd\u6570\u8fdb\u884c\u5339\u914d\uff0c\u65e0\u9700\u6807\u8bb0\u6570\u636e\u5373\u53ef\u5b9e\u73b0\u7cbe\u786e\u5b9a\u4f4d\u3002", "motivation": "\u4f20\u7edf\u4fe1\u9053\u56fe\u7ed8\u5236\u6280\u672f\u7684\u4e3b\u8981\u5c40\u9650\u5728\u4e8e\u4f30\u8ba1\u7684\u4f4d\u7f6e\u4f4d\u4e8e\u4efb\u610f\u5750\u6807\u7cfb\u4e2d\uff0c\u65e0\u6cd5\u4e0e\u771f\u5b9e\u7a7a\u95f4\u5750\u6807\u5bf9\u9f50\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u5b9a\u4f4d\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51fa\u65b0\u6846\u67b6\uff1a(i) \u4ece\u4f30\u8ba1\u7684\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u548c\u6570\u5b57\u5b6a\u751f\u4e2d\u63d0\u53d6\u5927\u89c4\u6a21CSI\u7279\u5f81\uff1b(ii) \u4f7f\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u635f\u5931\u51fd\u6570\u5339\u914d\u8fd9\u4e9b\u7279\u5f81\uff0c\u5e76\u5c06\u8be5\u635f\u5931\u51fd\u6570\u4e0e\u4f20\u7edfCC\u635f\u5931\u7ed3\u5408\u4ee5\u5b66\u4e60\u5b9a\u4f4d\u51fd\u6570\u3002", "result": "\u5728\u6a21\u62df\u5ba4\u5185\u573a\u666f\u4e2d\uff0c\u6240\u63d0\u6846\u67b6\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u5c06\u76f8\u5bf9\u5e73\u5747\u8ddd\u79bb\u8bef\u5dee\u964d\u4f4e\u4e8629%\uff0c\u4e14\u5bf9\u6570\u5b57\u5b6a\u751f\u5efa\u6a21\u5931\u914d\u548c\u6d4b\u8bd5\u6570\u636e\u5206\u5e03\u504f\u79fb\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u6807\u8bb0\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u63d0\u4f9b\u771f\u5b9e\u7a7a\u95f4\u5750\u6807\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fe1\u9053\u56fe\u7ed8\u5236\u6280\u672f\u7684\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2511.08841", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.08841", "abs": "https://arxiv.org/abs/2511.08841", "authors": ["Xincheng Xu", "Thilina Ranbaduge", "Qing Wang", "Thierry Rakotoarivelo", "David Smith"], "title": "Enhancing DPSGD via Per-Sample Momentum and Low-Pass Filtering", "comment": "To appear in AAAI 2026", "summary": "Differentially Private Stochastic Gradient Descent (DPSGD) is widely used to train deep neural networks with formal privacy guarantees. However, the addition of differential privacy (DP) often degrades model accuracy by introducing both noise and bias. Existing techniques typically address only one of these issues, as reducing DP noise can exacerbate clipping bias and vice-versa. In this paper, we propose a novel method, \\emph{DP-PMLF}, which integrates per-sample momentum with a low-pass filtering strategy to simultaneously mitigate DP noise and clipping bias. Our approach uses per-sample momentum to smooth gradient estimates prior to clipping, thereby reducing sampling variance. It further employs a post-processing low-pass filter to attenuate high-frequency DP noise without consuming additional privacy budget. We provide a theoretical analysis demonstrating an improved convergence rate under rigorous DP guarantees, and our empirical evaluations reveal that DP-PMLF significantly enhances the privacy-utility trade-off compared to several state-of-the-art DPSGD variants.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDP-PMLF\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u9010\u6837\u672c\u52a8\u91cf\u548c\u4f4e\u901a\u6ee4\u6ce2\u7b56\u7565\uff0c\u540c\u65f6\u51cf\u8f7b\u5dee\u5206\u9690\u79c1\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u4e2d\u7684\u566a\u58f0\u548c\u88c1\u526a\u504f\u5dee\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u5dee\u5206\u9690\u79c1\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u65b9\u6cd5\u901a\u5e38\u53ea\u89e3\u51b3\u566a\u58f0\u6216\u88c1\u526a\u504f\u5dee\u4e2d\u7684\u4e00\u4e2a\u95ee\u9898\uff0c\u51cf\u5c11DP\u566a\u58f0\u4f1a\u52a0\u5267\u88c1\u526a\u504f\u5dee\uff0c\u53cd\u4e4b\u4ea6\u7136\u3002\u9700\u8981\u4e00\u79cd\u80fd\u540c\u65f6\u7f13\u89e3\u8fd9\u4e24\u4e2a\u95ee\u9898\u7684\u65b9\u6cd5\u3002", "method": "DP-PMLF\u4f7f\u7528\u9010\u6837\u672c\u52a8\u91cf\u5728\u88c1\u526a\u524d\u5e73\u6ed1\u68af\u5ea6\u4f30\u8ba1\u4ee5\u51cf\u5c11\u91c7\u6837\u65b9\u5dee\uff0c\u5e76\u91c7\u7528\u540e\u5904\u7406\u4f4e\u901a\u6ee4\u6ce2\u5668\u6765\u8870\u51cf\u9ad8\u9891DP\u566a\u58f0\uff0c\u4e14\u4e0d\u6d88\u8017\u989d\u5916\u9690\u79c1\u9884\u7b97\u3002", "result": "\u7406\u8bba\u5206\u6790\u663e\u793a\u5728\u4e25\u683cDP\u4fdd\u8bc1\u4e0b\u5177\u6709\u6539\u8fdb\u7684\u6536\u655b\u901f\u7387\uff0c\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660eDP-PMLF\u76f8\u6bd4\u73b0\u6709DPSGD\u53d8\u4f53\u663e\u8457\u63d0\u5347\u4e86\u9690\u79c1-\u6548\u7528\u6743\u8861\u3002", "conclusion": "DP-PMLF\u901a\u8fc7\u521b\u65b0\u6027\u5730\u7ed3\u5408\u9010\u6837\u672c\u52a8\u91cf\u548c\u4f4e\u901a\u6ee4\u6ce2\uff0c\u6709\u6548\u540c\u65f6\u7f13\u89e3\u4e86DP\u566a\u58f0\u548c\u88c1\u526a\u504f\u5dee\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9690\u79c1\u4fdd\u62a4\u7684\u540c\u65f6\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2511.09275", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09275", "abs": "https://arxiv.org/abs/2511.09275", "authors": ["Minlan Shao", "Zijian Zhang", "Yili Wang", "Yiwei Dai", "Xu Shen", "Xin Wang"], "title": "HyperD: Hybrid Periodicity Decoupling Framework for Traffic Forecasting", "comment": null, "summary": "Accurate traffic forecasting plays a vital role in intelligent transportation systems, enabling applications such as congestion control, route planning, and urban mobility optimization.However, traffic forecasting remains challenging due to two key factors: (1) complex spatial dependencies arising from dynamic interactions between road segments and traffic sensors across the network, and (2) the coexistence of multi-scale periodic patterns (e.g., daily and weekly periodic patterns driven by human routines) with irregular fluctuations caused by unpredictable events (e.g., accidents, weather, or construction). To tackle these challenges, we propose HyperD (Hybrid Periodic Decoupling), a novel framework that decouples traffic data into periodic and residual components. The periodic component is handled by the Hybrid Periodic Representation Module, which extracts fine-grained daily and weekly patterns using learnable periodic embeddings and spatial-temporal attention. The residual component, which captures non-periodic, high-frequency fluctuations, is modeled by the Frequency-Aware Residual Representation Module, leveraging complex-valued MLP in frequency domain. To enforce semantic separation between the two components, we further introduce a Dual-View Alignment Loss, which aligns low-frequency information with the periodic branch and high-frequency information with the residual branch. Extensive experiments on four real-world traffic datasets demonstrate that HyperD achieves state-of-the-art prediction accuracy, while offering superior robustness under disturbances and improved computational efficiency compared to existing methods.", "AI": {"tldr": "HyperD\u662f\u4e00\u4e2a\u7528\u4e8e\u4ea4\u901a\u9884\u6d4b\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u4ea4\u901a\u6570\u636e\u89e3\u8026\u4e3a\u5468\u671f\u6027\u548c\u6b8b\u5dee\u5206\u91cf\u6765\u5904\u7406\u590d\u6742\u7684\u65f6\u7a7a\u4f9d\u8d56\u6027\u548c\u591a\u5c3a\u5ea6\u6a21\u5f0f\u3002", "motivation": "\u4ea4\u901a\u9884\u6d4b\u9762\u4e34\u590d\u6742\u7a7a\u95f4\u4f9d\u8d56\u6027\u548c\u591a\u5c3a\u5ea6\u5468\u671f\u6027\u6a21\u5f0f\u4e0e\u4e0d\u89c4\u5219\u6ce2\u52a8\u5171\u5b58\u7684\u6311\u6218\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u63d0\u51faHyperD\u6846\u67b6\uff0c\u5305\u542b\u6df7\u5408\u5468\u671f\u6027\u8868\u793a\u6a21\u5757\u5904\u7406\u5468\u671f\u6027\u5206\u91cf\uff0c\u9891\u7387\u611f\u77e5\u6b8b\u5dee\u8868\u793a\u6a21\u5757\u5904\u7406\u975e\u5468\u671f\u6027\u6ce2\u52a8\uff0c\u5e76\u4f7f\u7528\u53cc\u89c6\u56fe\u5bf9\u9f50\u635f\u5931\u786e\u4fdd\u8bed\u4e49\u5206\u79bb\u3002", "result": "\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u4ea4\u901a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHyperD\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u540c\u65f6\u5177\u6709\u66f4\u597d\u7684\u6297\u5e72\u6270\u9c81\u68d2\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "HyperD\u901a\u8fc7\u89e3\u8026\u5468\u671f\u6027\u6a21\u5f0f\u548c\u6b8b\u5dee\u6ce2\u52a8\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4ea4\u901a\u9884\u6d4b\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u9884\u6d4b\u5de5\u5177\u3002"}}
{"id": "2511.09254", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09254", "abs": "https://arxiv.org/abs/2511.09254", "authors": ["Ioannis Gavras", "Panagiotis Gavriilidis", "George C. Alexandropoulos"], "title": "2D Waveguide-Fed Metasurface Antenna Arrays: Modeling and Optimization for Bistatic Sensing", "comment": "5 pages, 1 figure", "summary": "This paper presents a physics-consistent framework for bistatic sensing incorporating a 2-Dimensional (2D) waveguide-fed metasurface antenna array capable of realizing eXtremely-Large Multiple-Input Multiple-Output (XL MIMO) apertures. A coupled-dipole model is presented that captures the array's mutual coupling due to both waveguide and free-space interactions, and a novel passivity constraint on the corresponding magnetic polarizabilities is proposed. Focusing on a bistatic sensing setup, we leverage a Neumann-series approximation of the array response model and derive the Cramer-Rao bound for multi-target parameter estimation, which is then incorporated into a sensing optimization formulation with respect to the metasurface's per-element resonance strength configuration. Simulation results on the position error bound in the radiative near field with the proposed design quantify the critical role of metamaterial placement in strongly coupled metasurface-based XL MIMO bistatic sensing systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7269\u7406\u4e00\u81f4\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u53cc\u57fa\u5730\u611f\u77e5\uff0c\u91c7\u75282D\u6ce2\u5bfc\u9988\u7535\u8d85\u8868\u9762\u5929\u7ebf\u9635\u5217\u5b9e\u73b0\u8d85\u5927\u89c4\u6a21MIMO\u5b54\u5f84\u3002\u63d0\u51fa\u4e86\u8026\u5408\u5076\u6781\u5b50\u6a21\u578b\u6355\u6349\u9635\u5217\u7684\u4e92\u8026\u6548\u5e94\uff0c\u5e76\u63d0\u51fa\u4e86\u78c1\u6781\u5316\u7387\u7684\u65e0\u6e90\u6027\u7ea6\u675f\u3002\u901a\u8fc7Neumann\u7ea7\u6570\u8fd1\u4f3c\u63a8\u5bfc\u4e86\u591a\u76ee\u6807\u53c2\u6570\u4f30\u8ba1\u7684Cramer-Rao\u754c\uff0c\u5e76\u5c06\u5176\u7eb3\u5165\u611f\u77e5\u4f18\u5316\u95ee\u9898\u4e2d\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u7269\u7406\u4e00\u81f4\u7684\u53cc\u57fa\u5730\u611f\u77e5\u6846\u67b6\uff0c\u5229\u7528\u8d85\u5927\u89c4\u6a21MIMO\u5b54\u5f84\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u611f\u77e5\uff0c\u540c\u65f6\u8003\u8651\u9635\u5217\u7684\u4e92\u8026\u6548\u5e94\u548c\u7269\u7406\u7ea6\u675f\u6761\u4ef6\u3002", "method": "\u4f7f\u7528\u8026\u5408\u5076\u6781\u5b50\u6a21\u578b\u6355\u6349\u6ce2\u5bfc\u548c\u81ea\u7531\u7a7a\u95f4\u4e92\u8026\uff0c\u63d0\u51fa\u78c1\u6781\u5316\u7387\u7684\u65e0\u6e90\u6027\u7ea6\u675f\uff0c\u91c7\u7528Neumann\u7ea7\u6570\u8fd1\u4f3c\u9635\u5217\u54cd\u5e94\u6a21\u578b\uff0c\u63a8\u5bfcCramer-Rao\u754c\uff0c\u5e76\u57fa\u4e8e\u6b64\u8fdb\u884c\u8d85\u8868\u9762\u5171\u632f\u5f3a\u5ea6\u914d\u7f6e\u7684\u4f18\u5316\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u5728\u8f90\u5c04\u8fd1\u573a\u4e2d\u63d0\u51fa\u7684\u8bbe\u8ba1\u80fd\u591f\u91cf\u5316\u4f4d\u7f6e\u8bef\u5dee\u754c\u9650\uff0c\u63ed\u793a\u4e86\u8d85\u6750\u6599\u5e03\u5c40\u5728\u5f3a\u8026\u5408\u8d85\u8868\u9762XL MIMO\u53cc\u57fa\u5730\u611f\u77e5\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8d85\u5927\u89c4\u6a21MIMO\u53cc\u57fa\u5730\u611f\u77e5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7269\u7406\u4e00\u81f4\u7684\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4e86\u8d85\u6750\u6599\u5e03\u5c40\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u9ad8\u7cbe\u5ea6\u611f\u77e5\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u6280\u672f\u652f\u6301\u3002"}}
{"id": "2511.08854", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08854", "abs": "https://arxiv.org/abs/2511.08854", "authors": ["Casper L. Christensen", "Logan Riggs"], "title": "Decomposition of Small Transformer Models", "comment": "Accepted at Neurips 2025 Workshop on Mechanistic Interpretability", "summary": "Recent work in mechanistic interpretability has shown that decomposing models in parameter space may yield clean handles for analysis and intervention. Previous methods have demonstrated successful applications on a wide range of toy models, but the gap to \"real models\" has not yet been bridged. In this work, we extend Stochastic Parameter Decomposition (SPD) to Transformer models, proposing an updated causal importance function suited for sequential data and a new loss function. We demonstrate that SPD can successfully decompose a toy induction-head model and recover the expected 2-step circuit. We also show that applying SPD to GPT-2-small can successfully locate subcomponents corresponding to interpretable concepts like \"golf\" and \"basketball\". These results take the first step in the direction of extending SPD to modern models, and show that we can use the method to surface interpretable parameter-space mechanisms.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u968f\u673a\u53c2\u6570\u5206\u89e3\uff08SPD\uff09\u65b9\u6cd5\u5230Transformer\u6a21\u578b\uff0c\u63d0\u51fa\u4e86\u9002\u7528\u4e8e\u5e8f\u5217\u6570\u636e\u7684\u56e0\u679c\u91cd\u8981\u6027\u51fd\u6570\u548c\u65b0\u635f\u5931\u51fd\u6570\u3002\u5728\u73a9\u5177\u6a21\u578b\u548cGPT-2-small\u4e0a\u6210\u529f\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u80fd\u5206\u89e3\u51fa\u53ef\u89e3\u91ca\u7684\u6982\u5ff5\u7ec4\u4ef6\u3002", "motivation": "\u73b0\u6709\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u4e3b\u8981\u5e94\u7528\u4e8e\u73a9\u5177\u6a21\u578b\uff0c\u5c1a\u672a\u6210\u529f\u6269\u5c55\u5230\u771f\u5b9e\u6a21\u578b\u3002\u672c\u6587\u65e8\u5728\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u5c06SPD\u65b9\u6cd5\u6269\u5c55\u5230\u73b0\u4ee3Transformer\u6a21\u578b\u3002", "method": "\u6269\u5c55\u968f\u673a\u53c2\u6570\u5206\u89e3\uff08SPD\uff09\u5230Transformer\u6a21\u578b\uff0c\u63d0\u51fa\u65b0\u7684\u56e0\u679c\u91cd\u8981\u6027\u51fd\u6570\uff08\u9002\u7528\u4e8e\u5e8f\u5217\u6570\u636e\uff09\u548c\u65b0\u7684\u635f\u5931\u51fd\u6570\u3002", "result": "\u6210\u529f\u5206\u89e3\u4e86\u73a9\u5177\u5f52\u7eb3\u5934\u6a21\u578b\u5e76\u6062\u590d\u4e86\u9884\u671f\u76842\u6b65\u7535\u8def\uff1b\u5728GPT-2-small\u4e2d\u6210\u529f\u5b9a\u4f4d\u4e86\u5bf9\u5e94\"\u9ad8\u5c14\u592b\"\u3001\"\u7bee\u7403\"\u7b49\u53ef\u89e3\u91ca\u6982\u5ff5\u7684\u5b50\u7ec4\u4ef6\u3002", "conclusion": "\u8fd9\u662f\u5c06SPD\u6269\u5c55\u5230\u73b0\u4ee3\u6a21\u578b\u7684\u7b2c\u4e00\u6b65\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u53ef\u7528\u4e8e\u63ed\u793a\u53c2\u6570\u7a7a\u95f4\u4e2d\u7684\u53ef\u89e3\u91ca\u673a\u5236\u3002"}}
{"id": "2511.09287", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09287", "abs": "https://arxiv.org/abs/2511.09287", "authors": ["Roland Aydin", "Christian Cyron", "Steve Bachelor", "Ashton Anderson", "Robert West"], "title": "From Model Training to Model Raising - A call to reform AI model training paradigms from post-hoc alignment to intrinsic, identity-based development", "comment": "Accepted for publication in Communications of the ACM (CACM), Opinion section", "summary": "Current AI training methods align models with human values only after their core capabilities have been established, resulting in models that are easily misaligned and lack deep-rooted value systems. We propose a paradigm shift from \"model training\" to \"model raising\", in which alignment is woven into a model's development from the start. We identify several key components for this paradigm, all centered around redesigning the training corpus: reframing training data from a first-person perspective, recontextualizing information as lived experience, simulating social interactions, and scaffolding the ordering of training data. We expect that this redesign of the training corpus will lead to an early commitment to values from the first training token onward, such that knowledge, skills, and values are intrinsically much harder to separate. In an ecosystem in which large language model capabilities start overtaking human capabilities in many tasks, this seems to us like a critical need.", "AI": {"tldr": "\u63d0\u51fa\u4ece\"\u6a21\u578b\u8bad\u7ec3\"\u5230\"\u6a21\u578b\u57f9\u517b\"\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u5c06\u4ef7\u503c\u89c2\u5bf9\u9f50\u4ece\u6a21\u578b\u5f00\u53d1\u4e4b\u521d\u5c31\u878d\u5165\u5176\u4e2d\uff0c\u901a\u8fc7\u91cd\u65b0\u8bbe\u8ba1\u8bad\u7ec3\u8bed\u6599\u5e93\u6765\u5b9e\u73b0\u65e9\u671f\u4ef7\u503c\u627f\u8bfa\u3002", "motivation": "\u5f53\u524dAI\u8bad\u7ec3\u65b9\u6cd5\u53ea\u5728\u6838\u5fc3\u80fd\u529b\u5efa\u7acb\u540e\u624d\u8fdb\u884c\u4ef7\u503c\u89c2\u5bf9\u9f50\uff0c\u5bfc\u81f4\u6a21\u578b\u5bb9\u6613\u88ab\u8bef\u5bfc\u4e14\u7f3a\u4e4f\u6df1\u5c42\u4ef7\u503c\u4f53\u7cfb\u3002\u5728LLM\u80fd\u529b\u5f00\u59cb\u8d85\u8d8a\u4eba\u7c7b\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u8bad\u7ec3\u8303\u5f0f\u3002", "method": "\u91cd\u65b0\u8bbe\u8ba1\u8bad\u7ec3\u8bed\u6599\u5e93\uff1a\u91c7\u7528\u7b2c\u4e00\u4eba\u79f0\u89c6\u89d2\u91cd\u6784\u8bad\u7ec3\u6570\u636e\u3001\u5c06\u4fe1\u606f\u91cd\u65b0\u60c5\u5883\u5316\u4e3a\u751f\u6d3b\u7ecf\u9a8c\u3001\u6a21\u62df\u793e\u4f1a\u4e92\u52a8\u3001\u642d\u5efa\u8bad\u7ec3\u6570\u636e\u6392\u5e8f\u7684\u811a\u624b\u67b6\u3002", "result": "\u9884\u671f\u8fd9\u79cd\u8bad\u7ec3\u8bed\u6599\u5e93\u7684\u91cd\u65b0\u8bbe\u8ba1\u5c06\u5bfc\u81f4\u4ece\u7b2c\u4e00\u4e2a\u8bad\u7ec3\u6807\u8bb0\u5f00\u59cb\u5c31\u5f62\u6210\u65e9\u671f\u4ef7\u503c\u627f\u8bfa\uff0c\u4f7f\u77e5\u8bc6\u3001\u6280\u80fd\u548c\u4ef7\u503c\u89c2\u5185\u5728\u66f4\u96be\u5206\u79bb\u3002", "conclusion": "\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u5f00\u59cb\u8d85\u8d8a\u4eba\u7c7b\u7684\u751f\u6001\u7cfb\u7edf\u4e2d\uff0c\u8fd9\u79cd\u4ece\u6a21\u578b\u8bad\u7ec3\u5230\u6a21\u578b\u57f9\u517b\u7684\u8303\u5f0f\u8f6c\u53d8\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2511.09341", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09341", "abs": "https://arxiv.org/abs/2511.09341", "authors": ["Weiran Yang", "Yiqi Cai", "Handi Deng", "Cheng Ma"], "title": "End-to-End Hardware Modeling and Sensitivity Optimization of Photoacoustic Signal Readout Chains", "comment": "10 pages, 9 figures, 1 table", "summary": "The sensitivity of the acoustic detection subsystem in photoacoustic imaging (PAI) critically affects image quality. However, previous studies often focused only on front-end acoustic components or back-end electronic components, overlooking end-to-end coupling among the transducer, cable, and receiver. This work develops a complete analytical model for system-level sensitivity optimization based on the Krimholtz, Leedom, and Matthaei (KLM) model. The KLM model is rederived from first principles of linear piezoelectric constitutive equations, 1D wave equations and transmission line theory to clarify its physical basis and applicable conditions. By encapsulating the acoustic components into a controlled voltage source and extending the model to include lumped-parameter representations of cable and receiver, an end-to-end equivalent circuit is established. Analytical expressions for the system transfer functions are derived, revealing the coupling effects among key parameters such as transducer element area (EA), cable length (CL), and receiver impedance (RI). Experimental results validate the model with an average error below 5%. Additionally, a low-frequency tailing phenomenon arising from exceeding the 1D vibration assumption is identified and analyzed, illustrating the importance of understanding the model's applicable conditions and providing a potential pathway for artifact suppression. This work offers a comprehensive framework for optimizing detection sensitivity and improving image fidelity in PAI systems.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eKLM\u6a21\u578b\u7684\u5b8c\u6574\u5206\u6790\u6a21\u578b\uff0c\u7528\u4e8e\u5149\u58f0\u6210\u50cf\u7cfb\u7edf\u4e2d\u7cfb\u7edf\u7ea7\u7075\u654f\u5ea6\u7684\u7aef\u5230\u7aef\u4f18\u5316\uff0c\u8003\u8651\u4e86\u6362\u80fd\u5668\u3001\u7535\u7f06\u548c\u63a5\u6536\u5668\u4e4b\u95f4\u7684\u8026\u5408\u6548\u5e94\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u5f80\u5f80\u53ea\u5173\u6ce8\u524d\u7aef\u58f0\u5b66\u7ec4\u4ef6\u6216\u540e\u7aef\u7535\u5b50\u7ec4\u4ef6\uff0c\u5ffd\u89c6\u4e86\u6362\u80fd\u5668\u3001\u7535\u7f06\u548c\u63a5\u6536\u5668\u4e4b\u95f4\u7684\u7aef\u5230\u7aef\u8026\u5408\uff0c\u8fd9\u5f71\u54cd\u4e86\u5149\u58f0\u6210\u50cf\u7cfb\u7edf\u7684\u68c0\u6d4b\u7075\u654f\u5ea6\u548c\u56fe\u50cf\u8d28\u91cf\u3002", "method": "\u57fa\u4e8e\u7ebf\u6027\u538b\u7535\u672c\u6784\u65b9\u7a0b\u3001\u4e00\u7ef4\u6ce2\u52a8\u65b9\u7a0b\u548c\u4f20\u8f93\u7ebf\u7406\u8bba\uff0c\u91cd\u65b0\u63a8\u5bfcKLM\u6a21\u578b\uff0c\u5efa\u7acb\u5305\u542b\u7535\u7f06\u548c\u63a5\u6536\u5668\u96c6\u603b\u53c2\u6570\u8868\u793a\u7684\u7aef\u5230\u7aef\u7b49\u6548\u7535\u8def\uff0c\u63a8\u5bfc\u7cfb\u7edf\u4f20\u9012\u51fd\u6570\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u663e\u793a\u6a21\u578b\u5e73\u5747\u8bef\u5dee\u4f4e\u4e8e5%\uff0c\u8bc6\u522b\u5e76\u5206\u6790\u4e86\u8d85\u51fa1D\u632f\u52a8\u5047\u8bbe\u65f6\u51fa\u73b0\u7684\u4f4e\u9891\u62d6\u5c3e\u73b0\u8c61\uff0c\u4e3a\u4f2a\u5f71\u6291\u5236\u63d0\u4f9b\u4e86\u6f5c\u5728\u9014\u5f84\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u4f18\u5316\u5149\u58f0\u6210\u50cf\u7cfb\u7edf\u7684\u68c0\u6d4b\u7075\u654f\u5ea6\u548c\u63d0\u9ad8\u56fe\u50cf\u4fdd\u771f\u5ea6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7efc\u5408\u6846\u67b6\u3002"}}
{"id": "2511.09370", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09370", "abs": "https://arxiv.org/abs/2511.09370", "authors": ["Corentin Presv\u00f4ts", "Michel Kieffer", "Thibault Prevost"], "title": "Reduced-Complexity Model Selection and Rate Allocation for Multiple-Model Electrical Signal Compression", "comment": "This paper has been submitted for review to the IEEE Transactions on Power Delivery", "summary": "This paper adapts a Multiple-Model Coding (MMC) approach for sampled electrical signal waveforms to satisfy reconstructed signal quality constraints. The baseline MMC approach consists of two stages processing vectors of Voltage and Current Signal (VCS) of constant size and producing bitstreams of constant rate but varying quality. In the proposed approach, the parametric model and the rate allocated to the first stage, as well as the residual compression method of the second stage and its associated rate, are jointly optimized to achieve a target distortion of the reconstructed signal. Three approaches are proposed. An exhaustive search serves as a baseline for comparison. Then, an approach involving a Golden Section search is exploited to determine the rate of the first stage with reduced complexity. Finally, rate-distortion models of the compression efficiency for each model in the first stage are employed to obtain a subset of promising models in the first stage and reduced-size search intervals for the rate selection in both stages. Simulation results demonstrate that the proposed reduced-complexity MMC approach reduces the rate for a given distortion constraint compared to state-of-the-art solutions for VCS with equivalent complexity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u964d\u4f4e\u590d\u6742\u5ea6\u7684\u591a\u6a21\u578b\u7f16\u7801\u65b9\u6cd5\uff0c\u7528\u4e8e\u7535\u4fe1\u53f7\u6ce2\u5f62\u538b\u7f29\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u53c2\u6570\u6a21\u578b\u548c\u6bd4\u7279\u7387\u5206\u914d\u6765\u6ee1\u8db3\u91cd\u6784\u4fe1\u53f7\u8d28\u91cf\u7ea6\u675f\u3002", "motivation": "\u4f20\u7edf\u591a\u6a21\u578b\u7f16\u7801\u65b9\u6cd5\u4ea7\u751f\u6052\u5b9a\u6bd4\u7279\u7387\u4f46\u8d28\u91cf\u53d8\u5316\u7684\u8f93\u51fa\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6ee1\u8db3\u7279\u5b9a\u5931\u771f\u7ea6\u675f\u7684\u66f4\u9ad8\u6548\u538b\u7f29\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e09\u79cd\u65b9\u6cd5\uff1a\u7a77\u4e3e\u641c\u7d22\u4f5c\u4e3a\u57fa\u51c6\uff1b\u9ec4\u91d1\u5206\u5272\u641c\u7d22\u964d\u4f4e\u7b2c\u4e00\u9636\u6bb5\u6bd4\u7279\u7387\u9009\u62e9\u590d\u6742\u5ea6\uff1b\u5229\u7528\u7387\u5931\u771f\u6a21\u578b\u7f29\u5c0f\u7b2c\u4e00\u9636\u6bb5\u6a21\u578b\u5b50\u96c6\u548c\u4e24\u9636\u6bb5\u6bd4\u7279\u7387\u641c\u7d22\u533a\u95f4\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u964d\u4f4e\u590d\u6742\u5ea6MMC\u65b9\u6cd5\u5728\u7ed9\u5b9a\u5931\u771f\u7ea6\u675f\u4e0b\uff0c\u76f8\u6bd4\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u6bd4\u7279\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u7b49\u6548\u590d\u6742\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7535\u4fe1\u53f7\u538b\u7f29\u7684\u6548\u7387\u3002"}}
{"id": "2511.08864", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08864", "abs": "https://arxiv.org/abs/2511.08864", "authors": ["Woosuk Chung", "Seokwoo Hong", "Wonhyeok Lee", "Sangyoon Bae"], "title": "Transformer-Based Sleep Stage Classification Enhanced by Clinical Information", "comment": null, "summary": "Manual sleep staging from polysomnography (PSG) is labor-intensive and prone to inter-scorer variability. While recent deep learning models have advanced automated staging, most rely solely on raw PSG signals and neglect contextual cues used by human experts. We propose a two-stage architecture that combines a Transformer-based per-epoch encoder with a 1D CNN aggregator, and systematically investigates the effect of incorporating explicit context: subject-level clinical metadata (age, sex, BMI) and per-epoch expert event annotations (apneas, desaturations, arousals, periodic breathing). Using the Sleep Heart Health Study (SHHS) cohort (n=8,357), we demonstrate that contextual fusion substantially improves staging accuracy. Compared to a PSG-only baseline (macro-F1 0.7745, micro-F1 0.8774), our final model achieves macro-F1 0.8031 and micro-F1 0.9051, with event annotations contributing the largest gains. Notably, feature fusion outperforms multi-task alternatives that predict the same auxiliary labels. These results highlight that augmenting learned representations with clinically meaningful features enhances both performance and interpretability, without modifying the PSG montage or requiring additional sensors. Our findings support a practical and scalable path toward context-aware, expert-aligned sleep staging systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408Transformer\u7f16\u7801\u5668\u548c1D CNN\u805a\u5408\u5668\u7684\u4e24\u9636\u6bb5\u67b6\u6784\uff0c\u901a\u8fc7\u878d\u5408\u4e34\u5e8a\u5143\u6570\u636e\u548c\u4e13\u5bb6\u4e8b\u4ef6\u6807\u6ce8\u7b49\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7761\u7720\u5206\u671f\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u4eba\u5de5\u7761\u7720\u5206\u671f\u52b3\u52a8\u5bc6\u96c6\u4e14\u5b58\u5728\u8bc4\u5206\u8005\u95f4\u5dee\u5f02\uff0c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5927\u591a\u4ec5\u4f9d\u8d56\u539f\u59cbPSG\u4fe1\u53f7\uff0c\u5ffd\u7565\u4e86\u4eba\u7c7b\u4e13\u5bb6\u4f7f\u7528\u7684\u4e0a\u4e0b\u6587\u7ebf\u7d22\u3002", "method": "\u4f7f\u7528\u4e24\u9636\u6bb5\u67b6\u6784\uff1aTransformer-based\u6bcf\u65f6\u6bb5\u7f16\u7801\u5668 + 1D CNN\u805a\u5408\u5668\uff0c\u7cfb\u7edf\u6027\u5730\u6574\u5408\u4e86\u53d7\u8bd5\u8005\u4e34\u5e8a\u5143\u6570\u636e\uff08\u5e74\u9f84\u3001\u6027\u522b\u3001BMI\uff09\u548c\u6bcf\u65f6\u6bb5\u4e13\u5bb6\u4e8b\u4ef6\u6807\u6ce8\uff08\u547c\u5438\u6682\u505c\u3001\u8840\u6c27\u9971\u548c\u5ea6\u4e0b\u964d\u3001\u89c9\u9192\u3001\u5468\u671f\u6027\u547c\u5438\uff09\u3002", "result": "\u5728SHHS\u961f\u5217\uff08n=8,357\uff09\u4e0a\uff0c\u4e0a\u4e0b\u6587\u878d\u5408\u663e\u8457\u63d0\u5347\u5206\u671f\u51c6\u786e\u6027\uff1a\u76f8\u6bd4\u4ec5\u4f7f\u7528PSG\u7684\u57fa\u7ebf\uff08macro-F1 0.7745, micro-F1 0.8774\uff09\uff0c\u6700\u7ec8\u6a21\u578b\u8fbe\u5230macro-F1 0.8031\u548cmicro-F1 0.9051\uff0c\u5176\u4e2d\u4e8b\u4ef6\u6807\u6ce8\u8d21\u732e\u6700\u5927\u589e\u76ca\u3002\u7279\u5f81\u878d\u5408\u4f18\u4e8e\u591a\u4efb\u52a1\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "\u5c06\u4e34\u5e8a\u6709\u610f\u4e49\u7279\u5f81\u4e0e\u5b66\u4e60\u8868\u793a\u76f8\u7ed3\u5408\uff0c\u53ef\u5728\u4e0d\u4fee\u6539PSG\u914d\u7f6e\u6216\u589e\u52a0\u989d\u5916\u4f20\u611f\u5668\u7684\u60c5\u51b5\u4e0b\uff0c\u540c\u65f6\u63d0\u5347\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u6784\u5efa\u4e0a\u4e0b\u6587\u611f\u77e5\u3001\u4e13\u5bb6\u5bf9\u9f50\u7684\u7761\u7720\u5206\u671f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u8def\u5f84\u3002"}}
{"id": "2511.09418", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.09418", "abs": "https://arxiv.org/abs/2511.09418", "authors": ["Nishant Mehrotra", "Sandesh Rao Mattu", "Robert Calderbank"], "title": "Equivalence of Several 6G Modulation Schemes for Doubly-Selective Channels", "comment": "6 pages, 2 figures, to be submitted to IEEE for possible publication", "summary": "There is significant recent interest in designing new modulation schemes for doubly-selective channels with large delay and Doppler spreads, where legacy modulation schemes based on time-frequency signal representations do not perform well. In this paper, we develop a framework for analyzing such modulations using two characteristics -- non-selectivity and predictability -- which directly relate to the diversity and spectral efficiency that the modulations achieve. We show that modulations in the delay-Doppler, chirp and time-sequency domains are non-selective, predictable and equivalent to one another, whereas time-frequency modulations are selective and non-predictable.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u6790\u53cc\u9009\u62e9\u6027\u4fe1\u9053\u8c03\u5236\u65b9\u6848\u7684\u6846\u67b6\uff0c\u91cd\u70b9\u5173\u6ce8\u975e\u9009\u62e9\u6027\u548c\u53ef\u9884\u6d4b\u6027\u4e24\u4e2a\u7279\u6027\uff0c\u8fd9\u4e9b\u7279\u6027\u76f4\u63a5\u5173\u7cfb\u5230\u8c03\u5236\u65b9\u6848\u5b9e\u73b0\u7684\u591a\u6837\u6027\u548c\u9891\u8c31\u6548\u7387\u3002", "motivation": "\u9488\u5bf9\u5177\u6709\u5927\u5ef6\u8fdf\u548c\u591a\u666e\u52d2\u6269\u5c55\u7684\u53cc\u9009\u62e9\u6027\u4fe1\u9053\uff0c\u4f20\u7edf\u57fa\u4e8e\u65f6\u9891\u4fe1\u53f7\u8868\u793a\u7684\u8c03\u5236\u65b9\u6848\u6027\u80fd\u4e0d\u4f73\uff0c\u56e0\u6b64\u9700\u8981\u8bbe\u8ba1\u65b0\u7684\u8c03\u5236\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5206\u6790\u6846\u67b6\uff0c\u4f7f\u7528\u975e\u9009\u62e9\u6027\u548c\u53ef\u9884\u6d4b\u6027\u4e24\u4e2a\u7279\u6027\u6765\u8bc4\u4f30\u8c03\u5236\u65b9\u6848\uff0c\u6bd4\u8f83\u4e86\u5ef6\u8fdf-\u591a\u666e\u52d2\u3001\u5541\u557e\u548c\u65f6\u5e8f\u57df\u8c03\u5236\u4e0e\u65f6\u9891\u8c03\u5236\u7684\u5dee\u5f02\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5ef6\u8fdf-\u591a\u666e\u52d2\u3001\u5541\u557e\u548c\u65f6\u5e8f\u57df\u8c03\u5236\u662f\u975e\u9009\u62e9\u6027\u3001\u53ef\u9884\u6d4b\u4e14\u76f8\u4e92\u7b49\u4ef7\u7684\uff0c\u800c\u65f6\u9891\u8c03\u5236\u662f\u9009\u62e9\u6027\u548c\u4e0d\u53ef\u9884\u6d4b\u7684\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u53cc\u9009\u62e9\u6027\u4fe1\u9053\u4e2d\u7684\u8c03\u5236\u65b9\u6848\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u8c03\u5236\u57df\u7684\u7279\u6027\u5dee\u5f02\u53ca\u5176\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u3002"}}
{"id": "2511.08884", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08884", "abs": "https://arxiv.org/abs/2511.08884", "authors": ["Oliver Wang", "Pengrui Quan", "Kang Yang", "Mani Srivastava"], "title": "Spectral Predictability as a Fast Reliability Indicator for Time Series Forecasting Model Selection", "comment": null, "summary": "Practitioners deploying time series forecasting models face a dilemma: exhaustively validating dozens of models is computationally prohibitive, yet choosing the wrong model risks poor performance. We show that spectral predictability~$\u03a9$ -- a simple signal processing metric -- systematically stratifies model family performance, enabling fast model selection. We conduct controlled experiments in four different domains, then further expand our analysis to 51 models and 28 datasets from the GIFT-Eval benchmark. We find that large time series foundation models (TSFMs) systematically outperform lightweight task-trained baselines when $\u03a9$ is high, while their advantage vanishes as $\u03a9$ drops. Computing $\u03a9$ takes seconds per dataset, enabling practitioners to quickly assess whether their data suits TSFM approaches or whether simpler, cheaper models suffice. We demonstrate that $\u03a9$ stratifies model performance predictably, offering a practical first-pass filter that reduces validation costs while highlighting the need for models that excel on genuinely difficult (low-$\u03a9$) problems rather than merely optimizing easy ones.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9891\u8c31\u53ef\u9884\u6d4b\u6027\u6307\u6807\u03a9\u7684\u5feb\u901f\u6a21\u578b\u9009\u62e9\u65b9\u6cd5\uff0c\u8be5\u6307\u6807\u80fd\u5728\u51e0\u79d2\u5185\u8bc4\u4f30\u6570\u636e\u96c6\u662f\u5426\u9002\u5408\u4f7f\u7528\u5927\u578b\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff0c\u4ece\u800c\u663e\u8457\u964d\u4f4e\u6a21\u578b\u9a8c\u8bc1\u6210\u672c\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u90e8\u7f72\u9762\u4e34\u4e24\u96be\uff1a\u5168\u9762\u9a8c\u8bc1\u6570\u5341\u4e2a\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u4f46\u9009\u62e9\u9519\u8bef\u6a21\u578b\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002\u9700\u8981\u4e00\u79cd\u5feb\u901f\u6709\u6548\u7684\u6a21\u578b\u9009\u62e9\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u9891\u8c31\u53ef\u9884\u6d4b\u6027\u6307\u6807\u03a9\u6765\u7cfb\u7edf\u6027\u5730\u5206\u5c42\u6a21\u578b\u5bb6\u65cf\u6027\u80fd\u3002\u5728\u56db\u4e2a\u4e0d\u540c\u9886\u57df\u8fdb\u884c\u53d7\u63a7\u5b9e\u9a8c\uff0c\u5e76\u5728GIFT-Eval\u57fa\u51c6\u768451\u4e2a\u6a21\u578b\u548c28\u4e2a\u6570\u636e\u96c6\u4e0a\u6269\u5c55\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5f53\u03a9\u8f83\u9ad8\u65f6\uff0c\u5927\u578b\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b(TSFMs)\u7cfb\u7edf\u6027\u5730\u4f18\u4e8e\u8f7b\u91cf\u7ea7\u4efb\u52a1\u8bad\u7ec3\u57fa\u7ebf\uff0c\u4f46\u968f\u7740\u03a9\u4e0b\u964d\uff0c\u5176\u4f18\u52bf\u6d88\u5931\u3002\u8ba1\u7b97\u03a9\u4ec5\u9700\u6bcf\u6570\u636e\u96c6\u51e0\u79d2\u949f\u3002", "conclusion": "\u03a9\u6307\u6807\u80fd\u591f\u53ef\u9884\u6d4b\u5730\u5206\u5c42\u6a21\u578b\u6027\u80fd\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u521d\u6b65\u7b5b\u9009\u5de5\u5177\uff0c\u65e2\u80fd\u964d\u4f4e\u9a8c\u8bc1\u6210\u672c\uff0c\u53c8\u51f8\u663e\u4e86\u9700\u8981\u5728\u771f\u6b63\u56f0\u96be(\u4f4e\u03a9)\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\u7684\u6a21\u578b\u9700\u6c42\u3002"}}
{"id": "2511.08887", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08887", "abs": "https://arxiv.org/abs/2511.08887", "authors": ["Tianming Sha", "Zechuan Chen", "Zhan Cheng", "Haotian Zhai", "Xuwei Ding", "Junnan Li", "Haixiang Tang", "Zaoting Sun", "Yanchuan Tang", "Yongzhe Yi", "Yanjie Huang", "Anhao Li", "Yuan Gao", "Keze Wang"], "title": "FAST-CAD: A Fairness-Aware Framework for Non-Contact Stroke Diagnosis", "comment": null, "summary": "Stroke is an acute cerebrovascular disease, and timely diagnosis significantly improves patient survival. However, existing automated diagnosis methods suffer from fairness issues across demographic groups, potentially exacerbating healthcare disparities. In this work we propose FAST-CAD, a theoretically grounded framework that combines domain-adversarial training (DAT) with group distributionally robust optimization (Group-DRO) for fair and accurate non-contact stroke diagnosis. Our approach is built on domain adaptation and minimax fairness theory and provides convergence guarantees and fairness bounds. We curate a multimodal dataset covering 12 demographic subgroups defined by age, gender, and posture. FAST-CAD employs self-supervised encoders with adversarial domain discrimination to learn demographic-invariant representations, while Group-DRO optimizes worst-group risk to ensure robust performance across all subgroups. Extensive experiments show that our method achieves superior diagnostic performance while maintaining fairness across demographic groups, and our theoretical analysis supports the effectiveness of the unified DAT + Group-DRO framework. This work provides both practical advances and theoretical insights for fair medical AI systems.", "AI": {"tldr": "FAST-CAD\u662f\u4e00\u4e2a\u7ed3\u5408\u9886\u57df\u5bf9\u6297\u8bad\u7ec3\u548c\u7ec4\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u7684\u516c\u5e73\u5352\u4e2d\u8bca\u65ad\u6846\u67b6\uff0c\u901a\u8fc7\u7406\u8bba\u4fdd\u8bc1\u548c\u516c\u5e73\u6027\u8fb9\u754c\u5b9e\u73b0\u8de8\u4eba\u53e3\u7edf\u8ba1\u5b66\u7fa4\u4f53\u7684\u51c6\u786e\u8bca\u65ad\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u5352\u4e2d\u8bca\u65ad\u65b9\u6cd5\u5b58\u5728\u8de8\u4eba\u53e3\u7edf\u8ba1\u5b66\u7fa4\u4f53\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u53ef\u80fd\u52a0\u5267\u533b\u7597\u4e0d\u5e73\u7b49\uff0c\u9700\u8981\u5f00\u53d1\u516c\u5e73\u4e14\u51c6\u786e\u7684\u8bca\u65ad\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u9886\u57df\u5bf9\u6297\u8bad\u7ec3(DAT)\u548c\u7ec4\u5206\u5e03\u9c81\u68d2\u4f18\u5316(Group-DRO)\uff0c\u4f7f\u7528\u81ea\u76d1\u7763\u7f16\u7801\u5668\u548c\u5bf9\u6297\u9886\u57df\u5224\u522b\u5b66\u4e60\u4eba\u53e3\u7edf\u8ba1\u5b66\u4e0d\u53d8\u8868\u793a\uff0c\u540c\u65f6\u4f18\u5316\u6700\u5dee\u7ec4\u98ce\u9669\u3002", "result": "\u5728\u6db5\u76d612\u4e2a\u4eba\u53e3\u7edf\u8ba1\u5b66\u5b50\u7ec4\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u8bca\u65ad\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8de8\u4eba\u53e3\u7edf\u8ba1\u5b66\u7fa4\u4f53\u7684\u516c\u5e73\u6027\u3002", "conclusion": "FAST-CAD\u4e3a\u516c\u5e73\u533b\u7597AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u8df5\u8fdb\u5c55\u548c\u7406\u8bba\u89c1\u89e3\uff0c\u8bc1\u660e\u4e86DAT + Group-DRO\u7edf\u4e00\u6846\u67b6\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.09464", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09464", "abs": "https://arxiv.org/abs/2511.09464", "authors": ["Ali Rasteh", "Amirreza Kiani", "Marco Mezzavilla", "Sundeep Rangan"], "title": "Scalable Long-Term Beamforming for Massive Multi-User MIMO", "comment": "6 pages, submitted to the IEEE International Conference on Communications (ICC) 2026", "summary": "Fully digital massive MIMO systems with large numbers (1000+) of antennas offer dramatically increased capacity gains from spatial multiplexing and beamforming. Designing digital receivers that can scale to these array dimensions presents significant challenges regarding both channel estimation overhead and digital computation. This paper presents a computationally efficient and low-overhead receiver design based on long-term beamforming. The method combines finding a low-rank projection from the spatial covariance estimate with a fast polynomial matrix inverse. Ray tracing simulations show minimal loss relative to complete instantaneous beamforming while offering significant overhead and computational gains.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u957f\u671f\u6ce2\u675f\u6210\u5f62\u7684\u8ba1\u7b97\u9ad8\u6548\u3001\u5f00\u9500\u4f4e\u7684\u5927\u89c4\u6a21MIMO\u63a5\u6536\u673a\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u7ed3\u5408\u4f4e\u79e9\u6295\u5f71\u548c\u5feb\u901f\u591a\u9879\u5f0f\u77e9\u9635\u6c42\u9006\u6280\u672f\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5f00\u9500\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\uff081000+\u5929\u7ebf\uff09\u867d\u7136\u80fd\u63d0\u4f9b\u5de8\u5927\u7684\u5bb9\u91cf\u589e\u76ca\uff0c\u4f46\u6570\u5b57\u63a5\u6536\u673a\u8bbe\u8ba1\u9762\u4e34\u4fe1\u9053\u4f30\u8ba1\u5f00\u9500\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u627e\u5230\u65e2\u80fd\u4fdd\u6301\u6027\u80fd\u53c8\u964d\u4f4e\u590d\u6742\u5ea6\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408\u957f\u671f\u7a7a\u95f4\u534f\u65b9\u5dee\u4f30\u8ba1\u7684\u4f4e\u79e9\u6295\u5f71\u548c\u5feb\u901f\u591a\u9879\u5f0f\u77e9\u9635\u6c42\u9006\u6280\u672f\uff0c\u6784\u5efa\u9ad8\u6548\u7684\u5927\u89c4\u6a21MIMO\u63a5\u6536\u673a\u67b6\u6784\u3002", "result": "\u5c04\u7ebf\u8ffd\u8e2a\u4eff\u771f\u8868\u660e\uff0c\u4e0e\u5b8c\u6574\u7684\u77ac\u65f6\u6ce2\u675f\u6210\u5f62\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u6027\u80fd\u635f\u5931\u6781\u5c0f\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u5f00\u9500\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "conclusion": "\u57fa\u4e8e\u957f\u671f\u6ce2\u675f\u6210\u5f62\u7684\u63a5\u6536\u673a\u8bbe\u8ba1\u4e3a\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u4f18\u52bf\u7684\u540c\u65f6\u6709\u6548\u89e3\u51b3\u4e86\u8ba1\u7b97\u548c\u5f00\u9500\u95ee\u9898\u3002"}}
{"id": "2511.08968", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.08968", "abs": "https://arxiv.org/abs/2511.08968", "authors": ["Maryam Dialameh", "Hossein Rajabzadeh", "Weiwei Zhang", "Walid Ahmed", "Hyock Ju Kwon"], "title": "Bayesian Mixture of Experts For Large Language Models", "comment": null, "summary": "We present Bayesian Mixture of Experts (Bayesian-MoE), a post-hoc uncertainty estimation framework for fine-tuned large language models (LLMs) based on Mixture-of-Experts architectures. Our method applies a structured Laplace approximation to the second linear layer of each expert, enabling calibrated uncertainty estimation without modifying the original training procedure or introducing new parameters. Unlike prior approaches, which apply Bayesian inference to added adapter modules, Bayesian-MoE directly targets the expert pathways already present in MoE models, leveraging their modular design for tractable block-wise posterior estimation. We use Kronecker-factored low-rank approximations to model curvature and derive scalable estimates of predictive uncertainty and marginal likelihood. Experiments on common-sense reasoning benchmarks with Qwen1.5-MoE and DeepSeek-MoE demonstrate that Bayesian-MoE improves both expected calibration error (ECE) and negative log-likelihood (NLL) over baselines, confirming its effectiveness for reliable downstream decision-making.", "AI": {"tldr": "Bayesian-MoE\u662f\u4e00\u79cd\u7528\u4e8e\u5fae\u8c03\u540e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u540e\u9a8c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u6846\u67b6\uff0c\u57fa\u4e8e\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u62c9\u666e\u62c9\u65af\u8fd1\u4f3c\u5b9e\u73b0\u6821\u51c6\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u65e0\u9700\u4fee\u6539\u539f\u59cb\u8bad\u7ec3\u8fc7\u7a0b\u6216\u5f15\u5165\u65b0\u53c2\u6570\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5c06\u8d1d\u53f6\u65af\u63a8\u7406\u5e94\u7528\u4e8e\u6dfb\u52a0\u7684\u9002\u914d\u5668\u6a21\u5757\uff0c\u800cBayesian-MoE\u76f4\u63a5\u9488\u5bf9MoE\u6a21\u578b\u4e2d\u5df2\u6709\u7684\u4e13\u5bb6\u8def\u5f84\uff0c\u5229\u7528\u5176\u6a21\u5757\u5316\u8bbe\u8ba1\u8fdb\u884c\u53ef\u5904\u7406\u7684\u5757\u7ea7\u540e\u9a8c\u4f30\u8ba1\u3002", "method": "\u5bf9\u6bcf\u4e2a\u4e13\u5bb6\u7684\u7b2c\u4e8c\u4e2a\u7ebf\u6027\u5c42\u5e94\u7528\u7ed3\u6784\u5316\u62c9\u666e\u62c9\u65af\u8fd1\u4f3c\uff0c\u4f7f\u7528Kronecker\u5206\u89e3\u7684\u4f4e\u79e9\u8fd1\u4f3c\u6765\u5efa\u6a21\u66f2\u7387\uff0c\u5e76\u63a8\u5bfc\u53ef\u6269\u5c55\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u548c\u8fb9\u7f18\u4f3c\u7136\u4f30\u8ba1\u3002", "result": "\u5728\u5e38\u8bc6\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528Qwen1.5-MoE\u548cDeepSeek-MoE\u7684\u5b9e\u9a8c\u8868\u660e\uff0cBayesian-MoE\u5728\u9884\u671f\u6821\u51c6\u8bef\u5dee(ECE)\u548c\u8d1f\u5bf9\u6570\u4f3c\u7136(NLL)\u65b9\u9762\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "Bayesian-MoE\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u53ef\u9760\u4e0b\u6e38\u51b3\u7b56\u7684\u80fd\u529b\uff0c\u8bc1\u5b9e\u4e86\u5176\u5728\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.09039", "categories": ["cs.LG", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.09039", "abs": "https://arxiv.org/abs/2511.09039", "authors": ["Anushka Sanjay Shelke", "Aditya Sneh", "Arya Adyasha", "Haroon R. Lone"], "title": "Fairness-Aware Few-Shot Learning for Audio-Visual Stress Detection", "comment": null, "summary": "Fairness in AI-driven stress detection is critical for equitable mental healthcare, yet existing models frequently exhibit gender bias, particularly in data-scarce scenarios. To address this, we propose FairM2S, a fairness-aware meta-learning framework for stress detection leveraging audio-visual data. FairM2S integrates Equalized Odds constraints during both meta-training and adaptation phases, employing adversarial gradient masking and fairness-constrained meta-updates to effectively mitigate bias. Evaluated against five state-of-the-art baselines, FairM2S achieves 78.1% accuracy while reducing the Equal Opportunity to 0.06, demonstrating substantial fairness gains. We also release SAVSD, a smartphone-captured dataset with gender annotations, designed to support fairness research in low-resource, real-world contexts. Together, these contributions position FairM2S as a state-of-the-art approach for equitable and scalable few-shot stress detection in mental health AI. We release our dataset and FairM2S publicly with this paper.", "AI": {"tldr": "FairM2S\u662f\u4e00\u4e2a\u516c\u5e73\u611f\u77e5\u7684\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u57fa\u4e8e\u97f3\u89c6\u9891\u6570\u636e\u7684\u538b\u529b\u68c0\u6d4b\uff0c\u901a\u8fc7\u96c6\u6210Equalized Odds\u7ea6\u675f\u3001\u5bf9\u6297\u68af\u5ea6\u63a9\u7801\u548c\u516c\u5e73\u7ea6\u675f\u5143\u66f4\u65b0\u6765\u7f13\u89e3\u6027\u522b\u504f\u89c1\uff0c\u5728\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\u5b9e\u73b0\u516c\u5e73\u4e14\u51c6\u786e\u7684\u68c0\u6d4b\u3002", "motivation": "\u73b0\u6709AI\u9a71\u52a8\u7684\u538b\u529b\u68c0\u6d4b\u6a21\u578b\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u7ecf\u5e38\u8868\u73b0\u51fa\u6027\u522b\u504f\u89c1\uff0c\u8fd9\u5bf9\u516c\u5e73\u7684\u5fc3\u7406\u5065\u5eb7\u62a4\u7406\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6709\u6548\u7f13\u89e3\u504f\u89c1\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faFairM2S\u6846\u67b6\uff0c\u5728\u5143\u8bad\u7ec3\u548c\u9002\u5e94\u9636\u6bb5\u96c6\u6210Equalized Odds\u7ea6\u675f\uff0c\u91c7\u7528\u5bf9\u6297\u68af\u5ea6\u63a9\u7801\u548c\u516c\u5e73\u7ea6\u675f\u5143\u66f4\u65b0\u6280\u672f\u6765\u51cf\u8f7b\u504f\u89c1\u3002", "result": "\u4e0e\u4e94\u4e2a\u6700\u5148\u8fdb\u57fa\u7ebf\u76f8\u6bd4\uff0cFairM2S\u8fbe\u523078.1%\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u5c06Equal Opportunity\u964d\u81f30.06\uff0c\u663e\u793a\u51fa\u663e\u8457\u7684\u516c\u5e73\u6027\u63d0\u5347\u3002", "conclusion": "FairM2S\u4e3a\u5fc3\u7406\u5065\u5eb7AI\u4e2d\u516c\u5e73\u4e14\u53ef\u6269\u5c55\u7684\u5c11\u6837\u672c\u538b\u529b\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u53d1\u5e03\u4e86\u5e26\u6709\u6027\u522b\u6807\u6ce8\u7684SAVSD\u6570\u636e\u96c6\u4ee5\u652f\u6301\u516c\u5e73\u6027\u7814\u7a76\u3002"}}
{"id": "2511.09049", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09049", "abs": "https://arxiv.org/abs/2511.09049", "authors": ["Mingjie Zhao", "Zhanpei Huang", "Yang Lu", "Mengke Li", "Yiqun Zhang", "Weifeng Su", "Yiu-ming Cheung"], "title": "Break the Tie: Learning Cluster-Customized Category Relationships for Categorical Data Clustering", "comment": "Aeecpted to AAAI 2026", "summary": "Categorical attributes with qualitative values are ubiquitous in cluster analysis of real datasets. Unlike the Euclidean distance of numerical attributes, the categorical attributes lack well-defined relationships of their possible values (also called categories interchangeably), which hampers the exploration of compact categorical data clusters. Although most attempts are made for developing appropriate distance metrics, they typically assume a fixed topological relationship between categories when learning distance metrics, which limits their adaptability to varying cluster structures and often leads to suboptimal clustering performance. This paper, therefore, breaks the intrinsic relationship tie of attribute categories and learns customized distance metrics suitable for flexibly and accurately revealing various cluster distributions. As a result, the fitting ability of the clustering algorithm is significantly enhanced, benefiting from the learnable category relationships. Moreover, the learned category relationships are proved to be Euclidean distance metric-compatible, enabling a seamless extension to mixed datasets that include both numerical and categorical attributes. Comparative experiments on 12 real benchmark datasets with significance tests show the superior clustering accuracy of the proposed method with an average ranking of 1.25, which is significantly higher than the 5.21 ranking of the current best-performing method.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e3a\u5206\u7c7b\u5c5e\u6027\u5b66\u4e60\u5b9a\u5236\u5316\u8ddd\u79bb\u5ea6\u91cf\u7684\u65b9\u6cd5\uff0c\u6253\u7834\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7c7b\u522b\u95f4\u56fa\u5b9a\u62d3\u6251\u5173\u7cfb\u7684\u9650\u5236\uff0c\u4ece\u800c\u66f4\u7075\u6d3b\u51c6\u786e\u5730\u63ed\u793a\u5404\u79cd\u805a\u7c7b\u5206\u5e03\u3002", "motivation": "\u5206\u7c7b\u5c5e\u6027\u5728\u805a\u7c7b\u5206\u6790\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u4f46\u7f3a\u4e4f\u660e\u786e\u7684\u7c7b\u522b\u95f4\u5173\u7cfb\u5b9a\u4e49\uff0c\u8fd9\u963b\u788d\u4e86\u5bf9\u7d27\u51d1\u5206\u7c7b\u6570\u636e\u805a\u7c7b\u7684\u63a2\u7d22\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u7c7b\u522b\u95f4\u5b58\u5728\u56fa\u5b9a\u62d3\u6251\u5173\u7cfb\uff0c\u9650\u5236\u4e86\u5176\u5bf9\u4e0d\u540c\u805a\u7c7b\u7ed3\u6784\u7684\u9002\u5e94\u6027\uff0c\u5bfc\u81f4\u805a\u7c7b\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u6253\u7834\u5c5e\u6027\u7c7b\u522b\u7684\u5185\u5728\u5173\u7cfb\u7ea6\u675f\uff0c\u5b66\u4e60\u9002\u5408\u7075\u6d3b\u51c6\u786e\u63ed\u793a\u5404\u79cd\u805a\u7c7b\u5206\u5e03\u7684\u5b9a\u5236\u5316\u8ddd\u79bb\u5ea6\u91cf\u3002\u5b66\u4e60\u5230\u7684\u7c7b\u522b\u5173\u7cfb\u88ab\u8bc1\u660e\u4e0e\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb\u5ea6\u91cf\u517c\u5bb9\uff0c\u53ef\u65e0\u7f1d\u6269\u5c55\u5230\u5305\u542b\u6570\u503c\u548c\u5206\u7c7b\u5c5e\u6027\u7684\u6df7\u5408\u6570\u636e\u96c6\u3002", "result": "\u572812\u4e2a\u771f\u5b9e\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u6bd4\u8f83\u5b9e\u9a8c\u548c\u663e\u8457\u6027\u6d4b\u8bd5\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u4f18\u8d8a\u7684\u805a\u7c7b\u51c6\u786e\u6027\uff0c\u5e73\u5747\u6392\u540d\u4e3a1.25\uff0c\u663e\u8457\u9ad8\u4e8e\u5f53\u524d\u6700\u4f73\u65b9\u6cd5\u76845.21\u6392\u540d\u3002", "conclusion": "\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u7c7b\u522b\u5173\u7cfb\uff0c\u805a\u7c7b\u7b97\u6cd5\u7684\u62df\u5408\u80fd\u529b\u5f97\u5230\u663e\u8457\u589e\u5f3a\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u5206\u7c7b\u5c5e\u6027\u805a\u7c7b\u95ee\u9898\uff0c\u5e76\u5728\u6df7\u5408\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.09105", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09105", "abs": "https://arxiv.org/abs/2511.09105", "authors": ["Shigeki Kusaka", "Keita Saito", "Mikoto Kudo", "Takumi Tanabe", "Akifumi Wachi", "Youhei Akimoto"], "title": "Cost-Minimized Label-Flipping Poisoning Attack to LLM Alignment", "comment": "accepted for AAAI 2026 Special Track on AI Alignment", "summary": "Large language models (LLMs) are increasingly deployed in real-world systems, making it critical to understand their vulnerabilities. While data poisoning attacks during RLHF/DPO alignment have been studied empirically, their theoretical foundations remain unclear. We investigate the minimum-cost poisoning attack required to steer an LLM's policy toward an attacker's target by flipping preference labels during RLHF/DPO, without altering the compared outputs. We formulate this as a convex optimization problem with linear constraints, deriving lower and upper bounds on the minimum attack cost. As a byproduct of this theoretical analysis, we show that any existing label-flipping attack can be post-processed via our proposed method to reduce the number of label flips required while preserving the intended poisoning effect. Empirical results demonstrate that this cost-minimization post-processing can significantly reduce poisoning costs over baselines, particularly when the reward model's feature dimension is small relative to the dataset size. These findings highlight fundamental vulnerabilities in RLHF/DPO pipelines and provide tools to evaluate their robustness against low-cost poisoning attacks.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728RLHF/DPO\u5bf9\u9f50\u8fc7\u7a0b\u4e2d\u901a\u8fc7\u7ffb\u8f6c\u504f\u597d\u6807\u7b7e\u8fdb\u884c\u6570\u636e\u6295\u6bd2\u653b\u51fb\u7684\u7406\u8bba\u57fa\u7840\uff0c\u63d0\u51fa\u4e86\u6700\u5c0f\u6210\u672c\u6295\u6bd2\u653b\u51fb\u7684\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u63a8\u5bfc\u4e86\u653b\u51fb\u6210\u672c\u7684\u4e0b\u754c\u548c\u4e0a\u754c\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u9645\u7cfb\u7edf\u4e2d\u7684\u90e8\u7f72\u589e\u52a0\uff0c\u7406\u89e3\u5176\u8106\u5f31\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136RLHF/DPO\u5bf9\u9f50\u8fc7\u7a0b\u4e2d\u7684\u6570\u636e\u6295\u6bd2\u653b\u51fb\u5df2\u6709\u5b9e\u8bc1\u7814\u7a76\uff0c\u4f46\u5176\u7406\u8bba\u57fa\u7840\u4ecd\u4e0d\u6e05\u695a\u3002", "method": "\u5c06\u6700\u5c0f\u6210\u672c\u6295\u6bd2\u653b\u51fb\u5efa\u6a21\u4e3a\u5e26\u7ebf\u6027\u7ea6\u675f\u7684\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u63a8\u5bfc\u653b\u51fb\u6210\u672c\u7684\u7406\u8bba\u754c\u9650\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u540e\u5904\u7406\u65b9\u6cd5\u51cf\u5c11\u6807\u7b7e\u7ffb\u8f6c\u6b21\u6570\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u4efb\u4f55\u73b0\u6709\u7684\u6807\u7b7e\u7ffb\u8f6c\u653b\u51fb\u90fd\u53ef\u4ee5\u901a\u8fc7\u63d0\u51fa\u7684\u540e\u5904\u7406\u65b9\u6cd5\u51cf\u5c11\u6240\u9700\u6807\u7b7e\u7ffb\u8f6c\u6b21\u6570\uff0c\u540c\u65f6\u4fdd\u6301\u9884\u671f\u7684\u6295\u6bd2\u6548\u679c\u3002\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u964d\u4f4e\u6295\u6bd2\u6210\u672c\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u63ed\u793a\u4e86RLHF/DPO\u6d41\u7a0b\u4e2d\u7684\u57fa\u672c\u8106\u5f31\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u8bc4\u4f30\u5176\u5bf9\u4f4e\u6210\u672c\u6295\u6bd2\u653b\u51fb\u9c81\u68d2\u6027\u7684\u5de5\u5177\u3002"}}
{"id": "2511.09294", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09294", "abs": "https://arxiv.org/abs/2511.09294", "authors": ["Yanli Li", "Yanan Zhou", "Zhongliang Guo", "Nan Yang", "Yuning Zhang", "Huaming Chen", "Dong Yuan", "Weiping Ding", "Witold Pedrycz"], "title": "GuardFed: A Trustworthy Federated Learning Framework Against Dual-Facet Attacks", "comment": null, "summary": "Federated learning (FL) enables privacy-preserving collaborative model training but remains vulnerable to adversarial behaviors that compromise model utility or fairness across sensitive groups. While extensive studies have examined attacks targeting either objective, strategies that simultaneously degrade both utility and fairness remain largely unexplored. To bridge this gap, we introduce the Dual-Facet Attack (DFA), a novel threat model that concurrently undermines predictive accuracy and group fairness. Two variants, Synchronous DFA (S-DFA) and Split DFA (Sp-DFA), are further proposed to capture distinct real-world collusion scenarios. Experimental results show that existing robust FL defenses, including hybrid aggregation schemes, fail to resist DFAs effectively. To counter these threats, we propose GuardFed, a self-adaptive defense framework that maintains a fairness-aware reference model using a small amount of clean server data augmented with synthetic samples. In each training round, GuardFed computes a dual-perspective trust score for every client by jointly evaluating its utility deviation and fairness degradation, thereby enabling selective aggregation of trustworthy updates. Extensive experiments on real-world datasets demonstrate that GuardFed consistently preserves both accuracy and fairness under diverse non-IID and adversarial conditions, achieving state-of-the-art performance compared with existing robust FL methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u8054\u90a6\u5b66\u4e60\u7684\u53cc\u91cd\u653b\u51fb(DFA)\uff0c\u540c\u65f6\u7834\u574f\u6a21\u578b\u6548\u7528\u548c\u516c\u5e73\u6027\uff0c\u5e76\u5f00\u53d1\u4e86GuardFed\u9632\u5fa1\u6846\u67b6\u6765\u6709\u6548\u5e94\u5bf9\u8fd9\u79cd\u5a01\u80c1\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u867d\u7136\u80fd\u4fdd\u62a4\u9690\u79c1\uff0c\u4f46\u4ecd\u6613\u53d7\u5bf9\u6297\u6027\u653b\u51fb\u5f71\u54cd\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u653b\u51fb\u6548\u7528\u6216\u516c\u5e73\u6027\u7684\u5355\u4e00\u76ee\u6807\uff0c\u800c\u540c\u65f6\u7834\u574f\u4e24\u8005\u7684\u653b\u51fb\u7b56\u7565\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cdDFA\u53d8\u4f53\uff1a\u540c\u6b65DFA\u548c\u5206\u5272DFA\uff0c\u5206\u522b\u6a21\u62df\u4e0d\u540c\u7684\u771f\u5b9e\u4e16\u754c\u5171\u8c0b\u573a\u666f\u3002\u540c\u65f6\u5f00\u53d1\u4e86GuardFed\u9632\u5fa1\u6846\u67b6\uff0c\u4f7f\u7528\u516c\u5e73\u611f\u77e5\u53c2\u8003\u6a21\u578b\u548c\u53cc\u89c6\u89d2\u4fe1\u4efb\u8bc4\u5206\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u73b0\u6709\u9c81\u68d2\u8054\u90a6\u5b66\u4e60\u9632\u5fa1\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u62b5\u6297DFA\u653b\u51fb\uff0c\u800cGuardFed\u5728\u591a\u79cd\u975eIID\u548c\u5bf9\u6297\u6761\u4ef6\u4e0b\u80fd\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u548c\u516c\u5e73\u6027\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "DFA\u653b\u51fb\u63ed\u793a\u4e86\u8054\u90a6\u5b66\u4e60\u7684\u65b0\u5b89\u5168\u5a01\u80c1\uff0cGuardFed\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u9632\u5fa1\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u6784\u5efa\u66f4\u5b89\u5168\u7684\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2511.09332", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09332", "abs": "https://arxiv.org/abs/2511.09332", "authors": ["Xinpeng Li", "Kai Ming Ting"], "title": "Distribution-Based Feature Attribution for Explaining the Predictions of Any Classifier", "comment": "Accepted for an oral presentation at the 40th Annual AAAI Conference on Artificial Intelligence (AAAI-26). This document is the extended version which includes the appendix", "summary": "The proliferation of complex, black-box AI models has intensified the need for techniques that can explain their decisions. Feature attribution methods have become a popular solution for providing post-hoc explanations, yet the field has historically lacked a formal problem definition. This paper addresses this gap by introducing a formal definition for the problem of feature attribution, which stipulates that explanations be supported by an underlying probability distribution represented by the given dataset. Our analysis reveals that many existing model-agnostic methods fail to meet this criterion, while even those that do often possess other limitations. To overcome these challenges, we propose Distributional Feature Attribution eXplanations (DFAX), a novel, model-agnostic method for feature attribution. DFAX is the first feature attribution method to explain classifier predictions directly based on the data distribution. We show through extensive experiments that DFAX is more effective and efficient than state-of-the-art baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f62\u5f0f\u5316\u7684\u7279\u5f81\u5f52\u56e0\u95ee\u9898\u5b9a\u4e49\uff0c\u5e76\u5f00\u53d1\u4e86DFAX\u65b9\u6cd5\uff0c\u8fd9\u662f\u9996\u4e2a\u76f4\u63a5\u57fa\u4e8e\u6570\u636e\u5206\u5e03\u6765\u89e3\u91ca\u5206\u7c7b\u5668\u9884\u6d4b\u7684\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u590d\u6742\u9ed1\u76d2AI\u6a21\u578b\u7684\u666e\u53ca\uff0c\u9700\u8981\u80fd\u591f\u89e3\u91ca\u5176\u51b3\u7b56\u7684\u6280\u672f\u3002\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\u5df2\u6210\u4e3a\u63d0\u4f9b\u4e8b\u540e\u89e3\u91ca\u7684\u6d41\u884c\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u8be5\u9886\u57df\u5386\u53f2\u4e0a\u7f3a\u4e4f\u6b63\u5f0f\u7684\u95ee\u9898\u5b9a\u4e49\u3002", "method": "\u63d0\u51fa\u4e86\u5206\u5e03\u7279\u5f81\u5f52\u56e0\u89e3\u91ca\uff08DFAX\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u6a21\u578b\u65e0\u5173\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\u3002DFAX\u662f\u9996\u4e2a\u76f4\u63a5\u57fa\u4e8e\u6570\u636e\u5206\u5e03\u6765\u89e3\u91ca\u5206\u7c7b\u5668\u9884\u6d4b\u7684\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cDFAX\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u66f4\u6709\u6548\u548c\u9ad8\u6548\u3002", "conclusion": "DFAX\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u7279\u5f81\u5f52\u56e0\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u548c\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.09392", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09392", "abs": "https://arxiv.org/abs/2511.09392", "authors": ["Jiajie Su", "Zihan Nan", "Yunshan Ma", "Xiaobo Xia", "Xiaohua Feng", "Weiming Liu", "Xiaolin Zheng", "Chaochao Chen"], "title": "Potent but Stealthy: Rethink Profile Pollution against Sequential Recommendation via Bi-level Constrained Reinforcement Paradigm", "comment": null, "summary": "Sequential Recommenders, which exploit dynamic user intents through interaction sequences, is vulnerable to adversarial attacks. While existing attacks primarily rely on data poisoning, they require large-scale user access or fake profiles thus lacking practicality. In this paper, we focus on the Profile Pollution Attack that subtly contaminates partial user interactions to induce targeted mispredictions. Previous PPA methods suffer from two limitations, i.e., i) over-reliance on sequence horizon impact restricts fine-grained perturbations on item transitions, and ii) holistic modifications cause detectable distribution shifts. To address these challenges, we propose a constrained reinforcement driven attack CREAT that synergizes a bi-level optimization framework with multi-reward reinforcement learning to balance adversarial efficacy and stealthiness. We first develop a Pattern Balanced Rewarding Policy, which integrates pattern inversion rewards to invert critical patterns and distribution consistency rewards to minimize detectable shifts via unbalanced co-optimal transport. Then we employ a Constrained Group Relative Reinforcement Learning paradigm, enabling step-wise perturbations through dynamic barrier constraints and group-shared experience replay, achieving targeted pollution with minimal detectability. Extensive experiments demonstrate the effectiveness of CREAT.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u914d\u7f6e\u6587\u4ef6\u6c61\u67d3\u653b\u51fb\u65b9\u6cd5CREAT\uff0c\u901a\u8fc7\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u5728\u4fdd\u6301\u9690\u853d\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u6709\u6548\u7684\u76ee\u6807\u8bef\u5bfc\u9884\u6d4b\u3002", "motivation": "\u73b0\u6709\u7684\u5e8f\u5217\u63a8\u8350\u7cfb\u7edf\u5bf9\u6297\u653b\u51fb\u4e3b\u8981\u4f9d\u8d56\u6570\u636e\u6295\u6bd2\uff0c\u9700\u8981\u5927\u89c4\u6a21\u7528\u6237\u8bbf\u95ee\u6216\u865a\u5047\u914d\u7f6e\u6587\u4ef6\uff0c\u7f3a\u4e4f\u5b9e\u7528\u6027\u3002\u914d\u7f6e\u6587\u4ef6\u6c61\u67d3\u653b\u51fb\u867d\u7136\u80fd\u901a\u8fc7\u6c61\u67d3\u90e8\u5206\u7528\u6237\u4ea4\u4e92\u6765\u8bf1\u5bfc\u76ee\u6807\u8bef\u9884\u6d4b\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u9650\u5236\uff1a\u8fc7\u5ea6\u4f9d\u8d56\u5e8f\u5217\u6c34\u5e73\u5f71\u54cd\u9650\u5236\u4e86\u7ec6\u7c92\u5ea6\u7684\u9879\u76ee\u8f6c\u6362\u6270\u52a8\uff0c\u6574\u4f53\u4fee\u6539\u5bfc\u81f4\u53ef\u68c0\u6d4b\u7684\u5206\u5e03\u504f\u79fb\u3002", "method": "\u63d0\u51faCREAT\u65b9\u6cd5\uff0c\u5c06\u53cc\u5c42\u4f18\u5316\u6846\u67b6\u4e0e\u591a\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u5e73\u8861\u5bf9\u6297\u6548\u679c\u548c\u9690\u853d\u6027\u3002\u5f00\u53d1\u6a21\u5f0f\u5e73\u8861\u5956\u52b1\u7b56\u7565\uff0c\u6574\u5408\u6a21\u5f0f\u53cd\u8f6c\u5956\u52b1\u548c\u5206\u5e03\u4e00\u81f4\u6027\u5956\u52b1\uff1b\u91c7\u7528\u7ea6\u675f\u7ec4\u76f8\u5bf9\u5f3a\u5316\u5b66\u4e60\u8303\u5f0f\uff0c\u901a\u8fc7\u52a8\u6001\u5c4f\u969c\u7ea6\u675f\u548c\u7ec4\u5171\u4eab\u7ecf\u9a8c\u56de\u653e\u5b9e\u73b0\u9010\u6b65\u6270\u52a8\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u4e86CREAT\u7684\u6709\u6548\u6027\u3002", "conclusion": "CREAT\u65b9\u6cd5\u80fd\u591f\u4ee5\u6700\u5c0f\u7684\u53ef\u68c0\u6d4b\u6027\u5b9e\u73b0\u76ee\u6807\u6c61\u67d3\u653b\u51fb\uff0c\u5728\u5bf9\u6297\u6548\u679c\u548c\u9690\u853d\u6027\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2511.09404", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09404", "abs": "https://arxiv.org/abs/2511.09404", "authors": ["Qiming Guo", "Wenbo Sun", "Wenlu Wang"], "title": "Spatio-Temporal Graph Unlearning", "comment": "13 pages, 4 figures, 4 tables", "summary": "Spatio-temporal graphs are widely used in modeling complex dynamic processes such as traffic forecasting, molecular dynamics, and healthcare monitoring. Recently, stringent privacy regulations such as GDPR and CCPA have introduced significant new challenges for existing spatio-temporal graph models, requiring complete unlearning of unauthorized data. Since each node in a spatio-temporal graph diffuses information globally across both spatial and temporal dimensions, existing unlearning methods primarily designed for static graphs and localized data removal cannot efficiently erase a single node without incurring costs nearly equivalent to full model retraining. Therefore, an effective approach for complete spatio-temporal graph unlearning is a pressing need. To address this, we propose CallosumNet, a divide-and-conquer spatio-temporal graph unlearning framework inspired by the corpus callosum structure that facilitates communication between the brain's two hemispheres. CallosumNet incorporates two novel techniques: (1) Enhanced Subgraph Construction (ESC), which adaptively constructs multiple localized subgraphs based on several factors, including biologically-inspired virtual ganglions; and (2) Global Ganglion Bridging (GGB), which reconstructs global spatio-temporal dependencies from these localized subgraphs, effectively restoring the full graph representation. Empirical results on four diverse real-world datasets show that CallosumNet achieves complete unlearning with only 1%-2% relative MAE loss compared to the gold model, significantly outperforming state-of-the-art baselines. Ablation studies verify the effectiveness of both proposed techniques.", "AI": {"tldr": "CallosumNet\u662f\u4e00\u4e2a\u53d7\u80fc\u80dd\u4f53\u542f\u53d1\u7684\u65f6\u7a7a\u56fe\u9057\u5fd8\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u5f3a\u5b50\u56fe\u6784\u5efa\u548c\u5168\u5c40\u795e\u7ecf\u8282\u6865\u63a5\u6280\u672f\uff0c\u5b9e\u73b0\u9ad8\u6548\u5b8c\u6574\u7684\u8282\u70b9\u7ea7\u9057\u5fd8\uff0c\u4ec5\u4ea7\u751f1%-2%\u7684\u76f8\u5bf9MAE\u635f\u5931\u3002", "motivation": "\u7531\u4e8eGDPR\u548cCCPA\u7b49\u9690\u79c1\u6cd5\u89c4\u8981\u6c42\u5b8c\u5168\u9057\u5fd8\u672a\u7ecf\u6388\u6743\u7684\u6570\u636e\uff0c\u800c\u73b0\u6709\u9057\u5fd8\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u9759\u6001\u56fe\u548c\u5c40\u90e8\u6570\u636e\u5220\u9664\uff0c\u65e0\u6cd5\u9ad8\u6548\u64e6\u9664\u65f6\u7a7a\u56fe\u4e2d\u7684\u5355\u4e2a\u8282\u70b9\uff0c\u56e0\u6b64\u9700\u8981\u6709\u6548\u7684\u65f6\u7a7a\u56fe\u5b8c\u5168\u9057\u5fd8\u65b9\u6cd5\u3002", "method": "\u63d0\u51faCallosumNet\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u65b0\u6280\u672f\uff1a(1)\u589e\u5f3a\u5b50\u56fe\u6784\u5efa(ESC)\uff0c\u57fa\u4e8e\u751f\u7269\u542f\u53d1\u7684\u865a\u62df\u795e\u7ecf\u8282\u7b49\u56e0\u7d20\u81ea\u9002\u5e94\u6784\u5efa\u591a\u4e2a\u5c40\u90e8\u5316\u5b50\u56fe\uff1b(2)\u5168\u5c40\u795e\u7ecf\u8282\u6865\u63a5(GGB)\uff0c\u4ece\u8fd9\u4e9b\u5c40\u90e8\u5b50\u56fe\u91cd\u5efa\u5168\u5c40\u65f6\u7a7a\u4f9d\u8d56\u5173\u7cfb\uff0c\u6709\u6548\u6062\u590d\u5b8c\u6574\u56fe\u8868\u793a\u3002", "result": "\u5728\u56db\u4e2a\u4e0d\u540c\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0cCallosumNet\u4ec5\u4ea7\u751f1%-2%\u7684\u76f8\u5bf9MAE\u635f\u5931\u5373\u53ef\u5b9e\u73b0\u5b8c\u5168\u9057\u5fd8\uff0c\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86\u4e24\u79cd\u63d0\u51fa\u6280\u672f\u7684\u6709\u6548\u6027\u3002", "conclusion": "CallosumNet\u4e3a\u65f6\u7a7a\u56fe\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5b8c\u5168\u9057\u5fd8\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6ee1\u8db3\u4e25\u683c\u7684\u9690\u79c1\u6cd5\u89c4\u8981\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u63a5\u8fd1\u9ec4\u91d1\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2511.09438", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09438", "abs": "https://arxiv.org/abs/2511.09438", "authors": ["Sai Puppala", "Ismail Hossain", "Md Jahangir Alam", "Tanzim Ahad", "Sajedul Talukder"], "title": "LLM-Guided Dynamic-UMAP for Personalized Federated Graph Learning", "comment": null, "summary": "We propose a method that uses large language models to assist graph machine learning under personalization and privacy constraints. The approach combines data augmentation for sparse graphs, prompt and instruction tuning to adapt foundation models to graph tasks, and in-context learning to supply few-shot graph reasoning signals. These signals parameterize a Dynamic UMAP manifold of client-specific graph embeddings inside a Bayesian variational objective for personalized federated learning. The method supports node classification and link prediction in low-resource settings and aligns language model latent representations with graph structure via a cross-modal regularizer. We outline a convergence argument for the variational aggregation procedure, describe a differential privacy threat model based on a moments accountant, and present applications to knowledge graph completion, recommendation-style link prediction, and citation and product graphs. We also discuss evaluation considerations for benchmarking LLM-assisted graph machine learning.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u4e2a\u6027\u5316\u548c\u9690\u79c1\u7ea6\u675f\u4e0b\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u56fe\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u7ed3\u5408\u6570\u636e\u589e\u5f3a\u3001\u63d0\u793a\u8c03\u4f18\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u53d8\u5206\u76ee\u6807\u5b9e\u73b0\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u3002", "motivation": "\u89e3\u51b3\u5728\u4e2a\u6027\u5316\u548c\u9690\u79c1\u7ea6\u675f\u4e0b\u56fe\u673a\u5668\u5b66\u4e60\u9762\u4e34\u7684\u7a00\u758f\u56fe\u6570\u636e\u3001\u4f4e\u8d44\u6e90\u8bbe\u7f6e\u4ee5\u53ca\u8bed\u8a00\u6a21\u578b\u4e0e\u56fe\u7ed3\u6784\u5bf9\u9f50\u7684\u6311\u6218\u3002", "method": "\u4f7f\u7528\u6570\u636e\u589e\u5f3a\u5904\u7406\u7a00\u758f\u56fe\uff0c\u901a\u8fc7\u63d0\u793a\u548c\u6307\u4ee4\u8c03\u4f18\u4f7f\u57fa\u7840\u6a21\u578b\u9002\u5e94\u56fe\u4efb\u52a1\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u5b66\u4e60\u63d0\u4f9b\u5c11\u6837\u672c\u56fe\u63a8\u7406\u4fe1\u53f7\uff0c\u6784\u5efa\u52a8\u6001UMAP\u6d41\u5f62\uff0c\u5e76\u91c7\u7528\u8d1d\u53f6\u65af\u53d8\u5206\u76ee\u6807\u8fdb\u884c\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u3002", "result": "\u65b9\u6cd5\u652f\u6301\u8282\u70b9\u5206\u7c7b\u548c\u94fe\u63a5\u9884\u6d4b\u4efb\u52a1\uff0c\u901a\u8fc7\u8de8\u6a21\u6001\u6b63\u5219\u5316\u5668\u5bf9\u9f50\u8bed\u8a00\u6a21\u578b\u6f5c\u5728\u8868\u793a\u4e0e\u56fe\u7ed3\u6784\uff0c\u5e76\u63d0\u4f9b\u4e86\u53d8\u5206\u805a\u5408\u8fc7\u7a0b\u7684\u6536\u655b\u6027\u8bba\u8bc1\u548c\u5dee\u5206\u9690\u79c1\u5a01\u80c1\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u3001\u63a8\u8350\u5f0f\u94fe\u63a5\u9884\u6d4b\u4ee5\u53ca\u5f15\u6587\u548c\u4ea7\u54c1\u56fe\u7b49\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u57fa\u51c6\u6d4b\u8bd5LLM\u8f85\u52a9\u7684\u56fe\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u8bc4\u4f30\u8003\u8651\u3002"}}
{"id": "2511.09450", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09450", "abs": "https://arxiv.org/abs/2511.09450", "authors": ["Amanta Sherfenaz", "Nazmul Haque", "Protiva Sadhukhan Prova", "Md Asif Raihan", "Md. Hadiuzzaman"], "title": "How does the Performance of the Data-driven Traffic Flow Forecasting Models deteriorate with Increasing Forecasting Horizon? An Extensive Approach Considering Statistical, Machine Learning and Deep Learning Models", "comment": "6,227 words text + 2*250 (2 tables) = 6,727 words", "summary": "With rapid urbanization in recent decades, traffic congestion has intensified due to increased movement of people and goods. As planning shifts from demand-based to supply-oriented strategies, Intelligent Transportation Systems (ITS) have become essential for managing traffic within existing infrastructure. A core ITS function is traffic forecasting, enabling proactive measures like ramp metering, signal control, and dynamic routing through platforms such as Google Maps. This study assesses the performance of statistical, machine learning (ML), and deep learning (DL) models in forecasting traffic speed and flow using real-world data from California's Harbor Freeway, sourced from the Caltrans Performance Measurement System (PeMS). Each model was evaluated over 20 forecasting windows (up to 1 hour 40 minutes) using RMSE, MAE, and R-Square metrics. Results show ANFIS-GP performs best at early windows with RMSE of 0.038, MAE of 0.0276, and R-Square of 0.9983, while Bi-LSTM is more robust for medium-term prediction due to its capacity to model long-range temporal dependencies, achieving RMSE of 0.1863, MAE of 0.0833, and R-Square of 0.987 at a forecasting of 20. The degradation in model performance was quantified using logarithmic transformation, with slope values used to measure robustness. Among DL models, Bi-LSTM had the flattest slope (0.0454 RMSE, 0.0545 MAE for flow), whereas ANFIS-GP had 0.1058 for RMSE and 0.1037 for flow MAE. The study concludes by identifying hybrid models as a promising future direction.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u7edf\u8ba1\u3001\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u9884\u6d4b\u4ea4\u901a\u901f\u5ea6\u548c\u6d41\u91cf\u65b9\u9762\u7684\u8868\u73b0\uff0c\u4f7f\u7528\u52a0\u5ddeHarbor Freeway\u7684\u771f\u5b9e\u6570\u636e\u3002\u7ed3\u679c\u663e\u793aANFIS-GP\u5728\u65e9\u671f\u9884\u6d4b\u7a97\u53e3\u8868\u73b0\u6700\u4f73\uff0c\u800cBi-LSTM\u5728\u4e2d\u957f\u671f\u9884\u6d4b\u4e2d\u66f4\u7a33\u5065\u3002", "motivation": "\u968f\u7740\u5feb\u901f\u57ce\u5e02\u5316\uff0c\u4ea4\u901a\u62e5\u5835\u52a0\u5267\uff0c\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf(ITS)\u5bf9\u4e8e\u5728\u73b0\u6709\u57fa\u7840\u8bbe\u65bd\u5185\u7ba1\u7406\u4ea4\u901a\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u4ea4\u901a\u9884\u6d4b\u662fITS\u7684\u6838\u5fc3\u529f\u80fd\uff0c\u80fd\u591f\u5b9e\u73b0\u4e3b\u52a8\u63aa\u65bd\u5982\u531d\u9053\u8ba1\u91cf\u3001\u4fe1\u53f7\u63a7\u5236\u548c\u52a8\u6001\u8def\u7531\u3002", "method": "\u4f7f\u7528\u6765\u81ea\u52a0\u5ddeCaltrans\u6027\u80fd\u6d4b\u91cf\u7cfb\u7edf(PeMS)\u7684\u771f\u5b9e\u6570\u636e\uff0c\u8bc4\u4f30\u7edf\u8ba1\u3001\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u572820\u4e2a\u9884\u6d4b\u7a97\u53e3\uff08\u6700\u957f1\u5c0f\u65f640\u5206\u949f\uff09\u5185\u7684\u6027\u80fd\uff0c\u4f7f\u7528RMSE\u3001MAE\u548cR-Square\u6307\u6807\u3002", "result": "ANFIS-GP\u5728\u65e9\u671f\u7a97\u53e3\u8868\u73b0\u6700\u4f73\uff08RMSE 0.038\uff0cMAE 0.0276\uff0cR-Square 0.9983\uff09\uff0c\u800cBi-LSTM\u5728\u4e2d\u957f\u671f\u9884\u6d4b\u4e2d\u66f4\u7a33\u5065\uff08RMSE 0.1863\uff0cMAE 0.0833\uff0cR-Square 0.987\uff09\u3002\u901a\u8fc7\u5bf9\u6570\u53d8\u6362\u91cf\u5316\u6a21\u578b\u6027\u80fd\u9000\u5316\uff0cBi-LSTM\u5177\u6709\u6700\u5e73\u5766\u7684\u659c\u7387\uff08RMSE 0.0454\uff0cMAE 0.0545\uff09\u3002", "conclusion": "\u7814\u7a76\u786e\u5b9a\u4e86\u6df7\u5408\u6a21\u578b\u4f5c\u4e3a\u6709\u524d\u666f\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u80fd\u591f\u7ed3\u5408\u4e0d\u540c\u6a21\u578b\u7684\u4f18\u52bf\u6765\u63d0\u5347\u4ea4\u901a\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2511.09478", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.09478", "abs": "https://arxiv.org/abs/2511.09478", "authors": ["Renda Li", "Hailang Huang", "Fei Wei", "Feng Xiong", "Yong Wang", "Xiangxiang Chu"], "title": "AdaCuRL: Adaptive Curriculum Reinforcement Learning with Invalid Sample Mitigation and Historical Revisiting", "comment": null, "summary": "Reinforcement learning (RL) has demonstrated considerable potential for enhancing reasoning in large language models (LLMs). However, existing methods suffer from Gradient Starvation and Policy Degradation when training directly on samples with mixed difficulty. To mitigate this, prior approaches leverage Chain-of-Thought (CoT) data, but the construction of high-quality CoT annotations remains labor-intensive. Alternatively, curriculum learning strategies have been explored but frequently encounter challenges, such as difficulty mismatch, reliance on manual curriculum design, and catastrophic forgetting. To address these issues, we propose AdaCuRL, a Adaptive Curriculum Reinforcement Learning framework that integrates coarse-to-fine difficulty estimation with adaptive curriculum scheduling. This approach dynamically aligns data difficulty with model capability and incorporates a data revisitation mechanism to mitigate catastrophic forgetting. Furthermore, AdaCuRL employs adaptive reference and sparse KL strategies to prevent Policy Degradation. Extensive experiments across diverse reasoning benchmarks demonstrate that AdaCuRL consistently achieves significant performance improvements on both LLMs and MLLMs.", "AI": {"tldr": "AdaCuRL\u662f\u4e00\u4e2a\u81ea\u9002\u5e94\u8bfe\u7a0b\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u7c97\u7c92\u5ea6\u5230\u7ec6\u7c92\u5ea6\u7684\u96be\u5ea6\u4f30\u8ba1\u548c\u81ea\u9002\u5e94\u8bfe\u7a0b\u8c03\u5ea6\uff0c\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u68af\u5ea6\u9965\u997f\u548c\u7b56\u7565\u9000\u5316\u95ee\u9898\uff0c\u5728\u591a\u79cd\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347LLMs\u548cMLLMs\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u6df7\u5408\u96be\u5ea6\u6837\u672c\u4e0a\u8bad\u7ec3\u65f6\u5b58\u5728\u68af\u5ea6\u9965\u997f\u548c\u7b56\u7565\u9000\u5316\u95ee\u9898\uff0c\u800c\u4f20\u7edf\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u7684\u601d\u7ef4\u94fe\u6570\u636e\uff08\u6210\u672c\u9ad8\uff09\uff0c\u8981\u4e48\u9762\u4e34\u8bfe\u7a0b\u5b66\u4e60\u4e2d\u7684\u96be\u5ea6\u4e0d\u5339\u914d\u3001\u624b\u52a8\u8bbe\u8ba1\u8bfe\u7a0b\u548c\u707e\u96be\u6027\u9057\u5fd8\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51faAdaCuRL\u6846\u67b6\uff0c\u6574\u5408\u7c97\u7c92\u5ea6\u5230\u7ec6\u7c92\u5ea6\u7684\u96be\u5ea6\u4f30\u8ba1\u4e0e\u81ea\u9002\u5e94\u8bfe\u7a0b\u8c03\u5ea6\uff0c\u52a8\u6001\u5bf9\u9f50\u6570\u636e\u96be\u5ea6\u4e0e\u6a21\u578b\u80fd\u529b\uff0c\u5305\u542b\u6570\u636e\u91cd\u8bbf\u673a\u5236\u7f13\u89e3\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5e76\u91c7\u7528\u81ea\u9002\u5e94\u53c2\u8003\u548c\u7a00\u758fKL\u7b56\u7565\u9632\u6b62\u7b56\u7565\u9000\u5316\u3002", "result": "\u5728\u591a\u79cd\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cAdaCuRL\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u4e0a\u5747\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "AdaCuRL\u901a\u8fc7\u81ea\u9002\u5e94\u8bfe\u7a0b\u5f3a\u5316\u5b66\u4e60\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u4e3a\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.09180", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.09180", "abs": "https://arxiv.org/abs/2511.09180", "authors": ["Michael A. Vladimir"], "title": "FSampler: Training Free Acceleration of Diffusion Sampling via Epsilon Extrapolation", "comment": "10 pages; diffusion models; accelerated sampling; ODE solvers; epsilon extrapolation; training free inference", "summary": "FSampler is a training free, sampler agnostic execution layer that accelerates diffusion sampling by reducing the number of function evaluations (NFE). FSampler maintains a short history of denoising signals (epsilon) from recent real model calls and extrapolates the next epsilon using finite difference predictors at second order, third order, or fourth order, falling back to lower order when history is insufficient. On selected steps the predicted epsilon substitutes the model call while keeping each sampler's update rule unchanged. Predicted epsilons are validated for finiteness and magnitude; a learning stabilizer rescales predictions on skipped steps to correct drift, and an optional gradient estimation stabilizer compensates local curvature. Protected windows, periodic anchors, and a cap on consecutive skips bound deviation over the trajectory. Operating at the sampler level, FSampler integrates with Euler/DDIM, DPM++ 2M/2S, LMS/AB2, and RES family exponential multistep methods and drops into standard workflows. FLUX.1 dev, Qwen Image, and Wan 2.2, FSampler reduces time by 8 to 22% and model calls by 15 to 25% at high fidelity (Structural Similarity Index (SSIM) 0.95 to 0.99), without altering sampler formulas. With an aggressive adaptive gate, reductions can reach 45 to 50% fewer model calls at lower fidelity (SSIM 0.73 to 0.74).", "AI": {"tldr": "FSampler\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u4e0e\u91c7\u6837\u5668\u65e0\u5173\u7684\u6267\u884c\u5c42\uff0c\u901a\u8fc7\u51cf\u5c11\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\u6765\u52a0\u901f\u6269\u6563\u91c7\u6837\u3002\u5b83\u901a\u8fc7\u5386\u53f2\u53bb\u566a\u4fe1\u53f7\u9884\u6d4b\u4e0b\u4e00\u4e2aepsilon\uff0c\u5728\u7279\u5b9a\u6b65\u9aa4\u7528\u9884\u6d4b\u503c\u66ff\u4ee3\u6a21\u578b\u8c03\u7528\uff0c\u540c\u65f6\u4fdd\u6301\u91c7\u6837\u5668\u66f4\u65b0\u89c4\u5219\u4e0d\u53d8\u3002", "motivation": "\u51cf\u5c11\u6269\u6563\u6a21\u578b\u91c7\u6837\u8fc7\u7a0b\u4e2d\u7684\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\uff0c\u4ece\u800c\u52a0\u901f\u91c7\u6837\u8fc7\u7a0b\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u4fdd\u771f\u5ea6\u3002", "method": "FSampler\u7ef4\u62a4\u6700\u8fd1\u771f\u5b9e\u6a21\u578b\u8c03\u7528\u7684\u53bb\u566a\u4fe1\u53f7\u5386\u53f2\uff0c\u4f7f\u7528\u4e8c\u9636\u3001\u4e09\u9636\u6216\u56db\u9636\u6709\u9650\u5dee\u5206\u9884\u6d4b\u5668\u5916\u63a8\u4e0b\u4e00\u4e2aepsilon\u3002\u5728\u9009\u5b9a\u6b65\u9aa4\u7528\u9884\u6d4bepsilon\u66ff\u4ee3\u6a21\u578b\u8c03\u7528\uff0c\u5305\u542b\u5b66\u4e60\u7a33\u5b9a\u5668\u3001\u68af\u5ea6\u4f30\u8ba1\u7a33\u5b9a\u5668\u3001\u4fdd\u62a4\u7a97\u53e3\u3001\u5468\u671f\u951a\u70b9\u548c\u8fde\u7eed\u8df3\u8fc7\u4e0a\u9650\u7b49\u673a\u5236\u3002", "result": "\u5728FLUX.1 dev\u3001Qwen Image\u548cWan 2.2\u7b49\u6a21\u578b\u4e0a\uff0cFSampler\u5c06\u65f6\u95f4\u51cf\u5c118-22%\uff0c\u6a21\u578b\u8c03\u7528\u51cf\u5c1115-25%\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u4fdd\u771f\u5ea6\uff08SSIM 0.95-0.99\uff09\u3002\u4f7f\u7528\u6fc0\u8fdb\u81ea\u9002\u5e94\u95e8\u65f6\uff0c\u6a21\u578b\u8c03\u7528\u51cf\u5c11\u53ef\u8fbe45-50%\uff0c\u4f46\u4fdd\u771f\u5ea6\u8f83\u4f4e\uff08SSIM 0.73-0.74\uff09\u3002", "conclusion": "FSampler\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6269\u6563\u91c7\u6837\u52a0\u901f\u65b9\u6cd5\uff0c\u4e0e\u591a\u79cd\u91c7\u6837\u5668\u517c\u5bb9\uff0c\u5728\u4e0d\u6539\u53d8\u91c7\u6837\u5668\u516c\u5f0f\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2511.09211", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09211", "abs": "https://arxiv.org/abs/2511.09211", "authors": ["Lijun Zhang", "Suyuan Liu", "Siwei Wang", "Shengju Yu", "Xueling Zhu", "Miaomiao Li", "Xinwang Liu"], "title": "Parameter-Free Clustering via Self-Supervised Consensus Maximization (Extended Version)", "comment": null, "summary": "Clustering is a fundamental task in unsupervised learning, but most existing methods heavily rely on hyperparameters such as the number of clusters or other sensitive settings, limiting their applicability in real-world scenarios. To address this long-standing challenge, we propose a novel and fully parameter-free clustering framework via Self-supervised Consensus Maximization, named SCMax. Our framework performs hierarchical agglomerative clustering and cluster evaluation in a single, integrated process. At each step of agglomeration, it creates a new, structure-aware data representation through a self-supervised learning task guided by the current clustering structure. We then introduce a nearest neighbor consensus score, which measures the agreement between the nearest neighbor-based merge decisions suggested by the original representation and the self-supervised one. The moment at which consensus maximization occurs can serve as a criterion for determining the optimal number of clusters. Extensive experiments on multiple datasets demonstrate that the proposed framework outperforms existing clustering approaches designed for scenarios with an unknown number of clusters.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSCMax\u7684\u5b8c\u5168\u65e0\u53c2\u6570\u805a\u7c7b\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u5171\u8bc6\u6700\u5927\u5316\u6765\u89e3\u51b3\u4f20\u7edf\u805a\u7c7b\u65b9\u6cd5\u4f9d\u8d56\u8d85\u53c2\u6570\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u805a\u7c7b\u65b9\u6cd5\u4e25\u91cd\u4f9d\u8d56\u8d85\u53c2\u6570\uff08\u5982\u805a\u7c7b\u6570\u91cf\uff09\uff0c\u9650\u5236\u4e86\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u5e94\u7528\uff0c\u9700\u8981\u5f00\u53d1\u5b8c\u5168\u65e0\u53c2\u6570\u7684\u805a\u7c7b\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5206\u5c42\u51dd\u805a\u805a\u7c7b\u548c\u805a\u7c7b\u8bc4\u4f30\u7684\u96c6\u6210\u8fc7\u7a0b\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u5b66\u4e60\u521b\u5efa\u7ed3\u6784\u611f\u77e5\u6570\u636e\u8868\u793a\uff0c\u5e76\u5f15\u5165\u6700\u8fd1\u90bb\u5171\u8bc6\u8bc4\u5206\u6765\u6d4b\u91cf\u539f\u59cb\u8868\u793a\u4e0e\u81ea\u76d1\u7763\u8868\u793a\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u672a\u77e5\u805a\u7c7b\u6570\u91cf\u573a\u666f\u4e0b\u4f18\u4e8e\u73b0\u6709\u7684\u805a\u7c7b\u65b9\u6cd5\u3002", "conclusion": "SCMax\u6846\u67b6\u901a\u8fc7\u81ea\u76d1\u7763\u5171\u8bc6\u6700\u5927\u5316\u6210\u529f\u5b9e\u73b0\u4e86\u5b8c\u5168\u65e0\u53c2\u6570\u805a\u7c7b\uff0c\u5171\u8bc6\u6700\u5927\u5316\u65f6\u523b\u53ef\u4f5c\u4e3a\u786e\u5b9a\u6700\u4f18\u805a\u7c7b\u6570\u91cf\u7684\u6807\u51c6\u3002"}}
{"id": "2511.09219", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09219", "abs": "https://arxiv.org/abs/2511.09219", "authors": ["Paul Strang", "Zacharie Al\u00e8s", "C\u00f4me Bissuel", "Safia Kedad-Sidhoum", "Emmanuel Rachelson"], "title": "Planning in Branch-and-Bound: Model-Based Reinforcement Learning for Exact Combinatorial Optimization", "comment": "arXiv admin note: text overlap with arXiv:2510.19348", "summary": "Mixed-Integer Linear Programming (MILP) lies at the core of many real-world combinatorial optimization (CO) problems, traditionally solved by branch-and-bound (B&B). A key driver influencing B&B solvers efficiency is the variable selection heuristic that guides branching decisions. Looking to move beyond static, hand-crafted heuristics, recent work has explored adapting traditional reinforcement learning (RL) algorithms to the B&B setting, aiming to learn branching strategies tailored to specific MILP distributions. In parallel, RL agents have achieved remarkable success in board games, a very specific type of combinatorial problems, by leveraging environment simulators to plan via Monte Carlo Tree Search (MCTS). Building on these developments, we introduce Plan-and-Branch-and-Bound (PlanB&B), a model-based reinforcement learning (MBRL) agent that leverages a learned internal model of the B&B dynamics to discover improved branching strategies. Computational experiments empirically validate our approach, with our MBRL branching agent outperforming previous state-of-the-art RL methods across four standard MILP benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPlanB&B\uff0c\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7684\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u5b66\u4e60\u7684B&B\u52a8\u6001\u5185\u90e8\u6a21\u578b\u6765\u53d1\u73b0\u6539\u8fdb\u7684\u5206\u652f\u7b56\u7565\uff0c\u5728\u56db\u4e2a\u6807\u51c6MILP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdbRL\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edfMILP\u95ee\u9898\u4f7f\u7528\u5206\u652f\u5b9a\u754c\u6cd5\uff0c\u53d8\u91cf\u9009\u62e9\u542f\u53d1\u5f0f\u7b97\u6cd5\u5f71\u54cd\u6c42\u89e3\u6548\u7387\u3002\u73b0\u6709\u9759\u6001\u624b\u5de5\u542f\u53d1\u5f0f\u65b9\u6cd5\u6709\u9650\uff0c\u5e0c\u671b\u5f00\u53d1\u9488\u5bf9\u7279\u5b9aMILP\u5206\u5e03\u7684\u81ea\u9002\u5e94\u5206\u652f\u7b56\u7565\u3002", "method": "\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff0c\u5f15\u5165PlanB&B\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\uff0c\u5229\u7528\u5b66\u4e60\u7684B&B\u52a8\u6001\u5185\u90e8\u6a21\u578b\u6765\u89c4\u5212\u5206\u652f\u51b3\u7b56\u3002", "result": "\u8ba1\u7b97\u5b9e\u9a8c\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u5728\u56db\u4e2a\u6807\u51c6MILP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u4e4b\u524d\u6700\u5148\u8fdb\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8e\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u80fd\u591f\u6709\u6548\u5b66\u4e60\u5206\u652f\u5b9a\u754c\u52a8\u6001\uff0c\u53d1\u73b0\u6539\u8fdb\u7684\u5206\u652f\u7b56\u7565\uff0c\u63d0\u5347MILP\u95ee\u9898\u6c42\u89e3\u6548\u7387\u3002"}}
{"id": "2511.09324", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09324", "abs": "https://arxiv.org/abs/2511.09324", "authors": ["Mohsen Amiri", "Konstantin Avrachenkov", "Ibtihal El Mimouni", "Sindri Magn\u00fasson"], "title": "MARBLE: Multi-Armed Restless Bandits in Latent Markovian Environment", "comment": null, "summary": "Restless Multi-Armed Bandits (RMABs) are powerful models for decision-making under uncertainty, yet classical formulations typically assume fixed dynamics, an assumption often violated in nonstationary environments. We introduce MARBLE (Multi-Armed Restless Bandits in a Latent Markovian Environment), which augments RMABs with a latent Markov state that induces nonstationary behavior. In MARBLE, each arm evolves according to a latent environment state that switches over time, making policy learning substantially more challenging. We further introduce the Markov-Averaged Indexability (MAI) criterion as a relaxed indexability assumption and prove that, despite unobserved regime switches, under the MAI criterion, synchronous Q-learning with Whittle Indices (QWI) converges almost surely to the optimal Q-function and the corresponding Whittle indices. We validate MARBLE on a calibrated simulator-embedded (digital twin) recommender system, where QWI consistently adapts to a shifting latent state and converges to an optimal policy, empirically corroborating our theoretical findings.", "AI": {"tldr": "MARBLE\u6a21\u578b\u6269\u5c55\u4e86\u4f20\u7edfRMAB\uff0c\u5f15\u5165\u6f5c\u5728\u9a6c\u5c14\u53ef\u592b\u72b6\u6001\u6765\u5904\u7406\u975e\u5e73\u7a33\u73af\u5883\uff0c\u63d0\u51fa\u4e86MAI\u51c6\u5219\u548cQWI\u7b97\u6cd5\uff0c\u5728\u6570\u5b57\u5b6a\u751f\u63a8\u8350\u7cfb\u7edf\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edfRMAB\u5047\u8bbe\u56fa\u5b9a\u52a8\u6001\uff0c\u4f46\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u8fd9\u4e00\u5047\u8bbe\u5e38\u88ab\u8fdd\u53cd\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u9002\u5e94\u73af\u5883\u53d8\u5316\u7684\u6a21\u578b\u3002", "method": "\u5f15\u5165MARBLE\u6a21\u578b\uff0c\u5305\u542b\u6f5c\u5728\u9a6c\u5c14\u53ef\u592b\u73af\u5883\u72b6\u6001\uff1b\u63d0\u51faMAI\u677e\u5f1b\u53ef\u7d22\u5f15\u6027\u51c6\u5219\uff1b\u5f00\u53d1\u540c\u6b65Q\u5b66\u4e60\u4e0eWhittle\u7d22\u5f15(QWI)\u7b97\u6cd5\u3002", "result": "\u7406\u8bba\u8bc1\u660eQWI\u5728MAI\u51c6\u5219\u4e0b\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\u5230\u6700\u4f18Q\u51fd\u6570\u548cWhittle\u7d22\u5f15\uff1b\u5728\u6570\u5b57\u5b6a\u751f\u63a8\u8350\u7cfb\u7edf\u5b9e\u9a8c\u4e2d\uff0cQWI\u80fd\u9002\u5e94\u6f5c\u5728\u72b6\u6001\u53d8\u5316\u5e76\u6536\u655b\u5230\u6700\u4f18\u7b56\u7565\u3002", "conclusion": "MARBLE\u6846\u67b6\u6210\u529f\u5904\u7406\u4e86\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u7684RMAB\u95ee\u9898\uff0cQWI\u7b97\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u90fd\u8868\u73b0\u51fa\u826f\u597d\u7684\u9002\u5e94\u6027\u548c\u6536\u655b\u6027\u3002"}}
{"id": "2511.09326", "categories": ["cs.LG", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2511.09326", "abs": "https://arxiv.org/abs/2511.09326", "authors": ["Viola R\u00e4dle", "Tilman Hartwig", "Benjamin Oesen", "Emily Alice Kr\u00f6ger", "Julius Vogt", "Eike Gericke", "Martin Baron"], "title": "GAMMA_FLOW: Guided Analysis of Multi-label spectra by MAtrix Factorization for Lightweight Operational Workflows", "comment": null, "summary": "GAMMA_FLOW is an open-source Python package for real-time analysis of spectral data. It supports classification, denoising, decomposition, and outlier detection of both single- and multi-component spectra. Instead of relying on large, computationally intensive models, it employs a supervised approach to non-negative matrix factorization (NMF) for dimensionality reduction. This ensures a fast, efficient, and adaptable analysis while reducing computational costs. gamma_flow achieves classification accuracies above 90% and enables reliable automated spectral interpretation. Originally developed for gamma-ray spectra, it is applicable to any type of one-dimensional spectral data. As an open and flexible alternative to proprietary software, it supports various applications in research and industry.", "AI": {"tldr": "GAMMA_FLOW\u662f\u4e00\u4e2a\u5f00\u6e90Python\u5305\uff0c\u7528\u4e8e\u5149\u8c31\u6570\u636e\u7684\u5b9e\u65f6\u5206\u6790\uff0c\u652f\u6301\u5206\u7c7b\u3001\u53bb\u566a\u3001\u5206\u89e3\u548c\u5f02\u5e38\u68c0\u6d4b\uff0c\u91c7\u7528\u76d1\u7763\u5f0f\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u8fdb\u884c\u964d\u7ef4\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u5feb\u901f\u7684\u5149\u8c31\u5206\u6790\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u5f00\u6e90\u3001\u7075\u6d3b\u7684\u5149\u8c31\u5206\u6790\u5de5\u5177\uff0c\u66ff\u4ee3\u5546\u4e1a\u8f6f\u4ef6\uff0c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u63d0\u9ad8\u5206\u6790\u6548\u7387\uff0c\u9002\u7528\u4e8e\u7814\u7a76\u548c\u5de5\u4e1a\u5e94\u7528\u3002", "method": "\u4f7f\u7528\u76d1\u7763\u5f0f\u975e\u8d1f\u77e9\u9635\u5206\u89e3\uff08NMF\uff09\u8fdb\u884c\u964d\u7ef4\uff0c\u907f\u514d\u4f7f\u7528\u8ba1\u7b97\u5bc6\u96c6\u578b\u5927\u6a21\u578b\uff0c\u5b9e\u73b0\u5feb\u901f\u9ad8\u6548\u7684\u5149\u8c31\u5206\u6790\u3002", "result": "\u5206\u7c7b\u51c6\u786e\u7387\u8d85\u8fc790%\uff0c\u80fd\u591f\u5b9e\u73b0\u53ef\u9760\u7684\u5149\u8c31\u81ea\u52a8\u89e3\u91ca\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u4e00\u7ef4\u5149\u8c31\u6570\u636e\u3002", "conclusion": "GAMMA_FLOW\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u3001\u5f00\u6e90\u7684\u5149\u8c31\u5206\u6790\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2511.09376", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09376", "abs": "https://arxiv.org/abs/2511.09376", "authors": ["Alexander Nadel", "Ron Wettenstein"], "title": "From Decision Trees to Boolean Logic: A Fast and Unified SHAP Algorithm", "comment": "Accepted to AAAI 2026", "summary": "SHapley Additive exPlanations (SHAP) is a key tool for interpreting decision tree ensembles by assigning contribution values to features. It is widely used in finance, advertising, medicine, and other domains. Two main approaches to SHAP calculation exist: Path-Dependent SHAP, which leverages the tree structure for efficiency, and Background SHAP, which uses a background dataset to estimate feature distributions.\n  We introduce WOODELF, a SHAP algorithm that integrates decision trees, game theory, and Boolean logic into a unified framework. For each consumer, WOODELF constructs a pseudo-Boolean formula that captures their feature values, the structure of the decision tree ensemble, and the entire background dataset. It then leverages this representation to compute Background SHAP in linear time. WOODELF can also compute Path-Dependent SHAP, Shapley interaction values, Banzhaf values, and Banzhaf interaction values.\n  WOODELF is designed to run efficiently on CPU and GPU hardware alike. Available via the WOODELF Python package, it is implemented using NumPy, SciPy, and CuPy without relying on custom C++ or CUDA code. This design enables fast performance and seamless integration into existing frameworks, supporting large-scale computation of SHAP and other game-theoretic values in practice.\n  For example, on a dataset with 3,000,000 rows, 5,000,000 background samples, and 127 features, WOODELF computed all Background Shapley values in 162 seconds on CPU and 16 seconds on GPU - compared to 44 minutes required by the best method on any hardware platform, representing 16x and 165x speedups, respectively.", "AI": {"tldr": "WOODELF\u662f\u4e00\u79cd\u65b0\u7684SHAP\u7b97\u6cd5\uff0c\u901a\u8fc7\u5c06\u51b3\u7b56\u6811\u3001\u535a\u5f08\u8bba\u548c\u5e03\u5c14\u903b\u8f91\u6574\u5408\u5230\u7edf\u4e00\u6846\u67b6\u4e2d\uff0c\u80fd\u591f\u5728\u7ebf\u6027\u65f6\u95f4\u5185\u8ba1\u7b97\u80cc\u666fSHAP\u503c\uff0c\u5e76\u5728CPU\u548cGPU\u4e0a\u5b9e\u73b0\u663e\u8457\u52a0\u901f\u3002", "motivation": "\u73b0\u6709\u7684SHAP\u8ba1\u7b97\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u96c6\u65f6\u6548\u7387\u8f83\u4f4e\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u7b97\u6cd5\u6765\u652f\u6301\u91d1\u878d\u3001\u5e7f\u544a\u3001\u533b\u7597\u7b49\u9886\u57df\u7684\u5b9e\u9645\u5e94\u7528\u9700\u6c42\u3002", "method": "WOODELF\u4e3a\u6bcf\u4e2a\u6d88\u8d39\u8005\u6784\u5efa\u4f2a\u5e03\u5c14\u516c\u5f0f\uff0c\u6355\u6349\u7279\u5f81\u503c\u3001\u51b3\u7b56\u6811\u96c6\u6210\u7ed3\u6784\u548c\u6574\u4e2a\u80cc\u666f\u6570\u636e\u96c6\uff0c\u7136\u540e\u5229\u7528\u8fd9\u79cd\u8868\u793a\u5728\u7ebf\u6027\u65f6\u95f4\u5185\u8ba1\u7b97\u80cc\u666fSHAP\u503c\u3002", "result": "\u5728\u5305\u542b300\u4e07\u884c\u3001500\u4e07\u80cc\u666f\u6837\u672c\u548c127\u4e2a\u7279\u5f81\u7684\u6570\u636e\u96c6\u4e0a\uff0cWOODELF\u5728CPU\u4e0a\u8ba1\u7b97\u6240\u6709\u80cc\u666fShapley\u503c\u4ec5\u9700162\u79d2\uff0cGPU\u4e0a\u4ec5\u970016\u79d2\uff0c\u76f8\u6bd4\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u5206\u522b\u5b9e\u73b0\u4e8616\u500d\u548c165\u500d\u7684\u52a0\u901f\u3002", "conclusion": "WOODELF\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684SHAP\u8ba1\u7b97\u65b9\u6cd5\uff0c\u652f\u6301\u5927\u89c4\u6a21\u6e38\u620f\u7406\u8bba\u503c\u7684\u8ba1\u7b97\uff0c\u5e76\u80fd\u5728\u4e0d\u540c\u786c\u4ef6\u5e73\u53f0\u4e0a\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2511.09400", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09400", "abs": "https://arxiv.org/abs/2511.09400", "authors": ["Philip Sosnin", "Matthew Wicker", "Josh Collyer", "Calvin Tsay"], "title": "Abstract Gradient Training: A Unified Certification Framework for Data Poisoning, Unlearning, and Differential Privacy", "comment": null, "summary": "The impact of inference-time data perturbation (e.g., adversarial attacks) has been extensively studied in machine learning, leading to well-established certification techniques for adversarial robustness. In contrast, certifying models against training data perturbations remains a relatively under-explored area. These perturbations can arise in three critical contexts: adversarial data poisoning, where an adversary manipulates training samples to corrupt model performance; machine unlearning, which requires certifying model behavior under the removal of specific training data; and differential privacy, where guarantees must be given with respect to substituting individual data points. This work introduces Abstract Gradient Training (AGT), a unified framework for certifying robustness of a given model and training procedure to training data perturbations, including bounded perturbations, the removal of data points, and the addition of new samples. By bounding the reachable set of parameters, i.e., establishing provable parameter-space bounds, AGT provides a formal approach to analyzing the behavior of models trained via first-order optimization methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u62bd\u8c61\u68af\u5ea6\u8bad\u7ec3\uff08AGT\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u8ba4\u8bc1\u6a21\u578b\u5bf9\u8bad\u7ec3\u6570\u636e\u6270\u52a8\u7684\u9c81\u68d2\u6027\uff0c\u5305\u62ec\u6709\u754c\u6270\u52a8\u3001\u6570\u636e\u70b9\u79fb\u9664\u548c\u65b0\u6837\u672c\u6dfb\u52a0\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u63a8\u7406\u65f6\u6570\u636e\u6270\u52a8\u7684\u8ba4\u8bc1\uff0c\u800c\u5bf9\u8bad\u7ec3\u6570\u636e\u6270\u52a8\u7684\u8ba4\u8bc1\u7814\u7a76\u76f8\u5bf9\u4e0d\u8db3\uff0c\u8fd9\u4e9b\u6270\u52a8\u5728\u5bf9\u6297\u6027\u6570\u636e\u6295\u6bd2\u3001\u673a\u5668\u9057\u5fd8\u548c\u5dee\u5206\u9690\u79c1\u7b49\u5173\u952e\u573a\u666f\u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u901a\u8fc7\u8fb9\u754c\u53ef\u8fbe\u53c2\u6570\u96c6\uff0c\u5373\u5efa\u7acb\u53ef\u8bc1\u660e\u7684\u53c2\u6570\u7a7a\u95f4\u8fb9\u754c\uff0cAGT\u4e3a\u5206\u6790\u901a\u8fc7\u4e00\u9636\u4f18\u5316\u65b9\u6cd5\u8bad\u7ec3\u7684\u6a21\u578b\u884c\u4e3a\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u65b9\u6cd5\u3002", "result": "AGT\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u80fd\u591f\u8ba4\u8bc1\u7ed9\u5b9a\u6a21\u578b\u548c\u8bad\u7ec3\u7a0b\u5e8f\u5bf9\u8bad\u7ec3\u6570\u636e\u6270\u52a8\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u62bd\u8c61\u68af\u5ea6\u8bad\u7ec3\u6846\u67b6\u4e3a\u8bad\u7ec3\u6570\u636e\u6270\u52a8\u7684\u9c81\u68d2\u6027\u8ba4\u8bc1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2511.09477", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09477", "abs": "https://arxiv.org/abs/2511.09477", "authors": ["Andrew Hamara", "Greg Hamerly", "Pablo Rivas", "Andrew C. Freeman"], "title": "Latent Planning via Embedding Arithmetic: A Contrastive Approach to Strategic Reasoning", "comment": null, "summary": "Planning in high-dimensional decision spaces is increasingly being studied through the lens of learned representations. Rather than training policies or value heads, we investigate whether planning can be carried out directly in an evaluation-aligned embedding space. We introduce SOLIS, which learns such a space using supervised contrastive learning. In this representation, outcome similarity is captured by proximity, and a single global advantage vector orients the space from losing to winning regions. Candidate actions are then ranked according to their alignment with this direction, reducing planning to vector operations in latent space. We demonstrate this approach in chess, where SOLIS uses only a shallow search guided by the learned embedding to reach competitive strength under constrained conditions. More broadly, our results suggest that evaluation-aligned latent planning offers a lightweight alternative to traditional dynamics models or policy learning.", "AI": {"tldr": "SOLIS\u901a\u8fc7\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u6784\u5efa\u8bc4\u4f30\u5bf9\u9f50\u7684\u5d4c\u5165\u7a7a\u95f4\uff0c\u5728\u8be5\u7a7a\u95f4\u4e2d\u7ed3\u679c\u76f8\u4f3c\u6027\u7531\u8ddd\u79bb\u8868\u793a\uff0c\u5168\u5c40\u4f18\u52bf\u5411\u91cf\u4ece\u8f93\u5230\u8d62\u533a\u57df\u5b9a\u5411\u7a7a\u95f4\u3002\u5019\u9009\u52a8\u4f5c\u6839\u636e\u4e0e\u8be5\u65b9\u5411\u7684\u5bf9\u9f50\u5ea6\u8fdb\u884c\u6392\u5e8f\uff0c\u5c06\u89c4\u5212\u7b80\u5316\u4e3a\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u5411\u91cf\u64cd\u4f5c\u3002", "motivation": "\u7814\u7a76\u662f\u5426\u53ef\u4ee5\u76f4\u63a5\u5728\u8bc4\u4f30\u5bf9\u9f50\u7684\u5d4c\u5165\u7a7a\u95f4\u4e2d\u8fdb\u884c\u89c4\u5212\uff0c\u800c\u4e0d\u662f\u8bad\u7ec3\u7b56\u7565\u6216\u4ef7\u503c\u5934\uff0c\u4e3a\u9ad8\u7ef4\u51b3\u7b56\u7a7a\u95f4\u89c4\u5212\u63d0\u4f9b\u8f7b\u91cf\u7ea7\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u6784\u5efa\u8bc4\u4f30\u5bf9\u9f50\u5d4c\u5165\u7a7a\u95f4\uff0c\u5176\u4e2d\u7ed3\u679c\u76f8\u4f3c\u6027\u7531\u90bb\u8fd1\u5ea6\u6355\u83b7\uff0c\u5355\u4e2a\u5168\u5c40\u4f18\u52bf\u5411\u91cf\u4ece\u8f93\u5230\u8d62\u533a\u57df\u5b9a\u5411\u7a7a\u95f4\u3002\u5019\u9009\u52a8\u4f5c\u6839\u636e\u4e0e\u8be5\u65b9\u5411\u7684\u5bf9\u9f50\u5ea6\u8fdb\u884c\u6392\u5e8f\u3002", "result": "\u5728\u8c61\u68cb\u4e2d\uff0cSOLIS\u4ec5\u4f7f\u7528\u6d45\u5c42\u641c\u7d22\u548c\u5b66\u4e60\u7684\u5d4c\u5165\u6307\u5bfc\u5c31\u80fd\u5728\u53d7\u9650\u6761\u4ef6\u4e0b\u8fbe\u5230\u7ade\u4e89\u6027\u5f3a\u5ea6\u3002", "conclusion": "\u8bc4\u4f30\u5bf9\u9f50\u7684\u6f5c\u5728\u89c4\u5212\u4e3a\u4f20\u7edf\u52a8\u6001\u6a21\u578b\u6216\u7b56\u7565\u5b66\u4e60\u63d0\u4f9b\u4e86\u8f7b\u91cf\u7ea7\u66ff\u4ee3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u76f4\u63a5\u8fdb\u884c\u89c4\u5212\u7684\u6709\u6548\u6027\u3002"}}
