{"id": "2511.07459", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07459", "abs": "https://arxiv.org/abs/2511.07459", "authors": ["Ashutosh Agarwal"], "title": "Optimizing Classification of Infrequent Labels by Reducing Variability in Label Distribution", "comment": "Accepted and presented at 6th International Conference on Emerging research in electronics, computer science and technology ( ICERECT)", "summary": "This paper presents a novel solution, LEVER, designed to address the challenges posed by underperforming infrequent categories in Extreme Classification (XC) tasks. Infrequent categories, often characterized by sparse samples, suffer from high label inconsistency, which undermines classification performance. LEVER mitigates this problem by adopting a robust Siamese-style architecture, leveraging knowledge transfer to reduce label inconsistency and enhance the performance of One-vs-All classifiers. Comprehensive testing across multiple XC datasets reveals substantial improvements in the handling of infrequent categories, setting a new benchmark for the field. Additionally, the paper introduces two newly created multi-intent datasets, offering essential resources for future XC research.", "AI": {"tldr": "LEVER\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7Siamese\u98ce\u683c\u67b6\u6784\u548c\u77e5\u8bc6\u8f6c\u79fb\u6765\u6539\u5584\u6781\u7aef\u5206\u7c7b\u4efb\u52a1\u4e2d\u4f4e\u9891\u7c7b\u522b\u7684\u6027\u80fd\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u6807\u7b7e\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\u3002", "motivation": "\u6781\u7aef\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u4f4e\u9891\u7c7b\u522b\u7531\u4e8e\u6837\u672c\u7a00\u758f\u5bfc\u81f4\u6807\u7b7e\u4e0d\u4e00\u81f4\u6027\u9ad8\uff0c\u4e25\u91cd\u5f71\u54cd\u5206\u7c7b\u6027\u80fd\uff0c\u9700\u8981\u4e13\u95e8\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91c7\u7528\u9c81\u68d2\u7684Siamese\u98ce\u683c\u67b6\u6784\uff0c\u5229\u7528\u77e5\u8bc6\u8f6c\u79fb\u6280\u672f\u6765\u964d\u4f4e\u6807\u7b7e\u4e0d\u4e00\u81f4\u6027\uff0c\u5e76\u589e\u5f3aOne-vs-All\u5206\u7c7b\u5668\u7684\u6027\u80fd\u3002", "result": "\u5728\u591a\u4e2a\u6781\u7aef\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u6d4b\u8bd5\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u5904\u7406\u4f4e\u9891\u7c7b\u522b\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u4e3a\u8be5\u9886\u57df\u8bbe\u7acb\u4e86\u65b0\u7684\u57fa\u51c6\u3002", "conclusion": "LEVER\u6709\u6548\u89e3\u51b3\u4e86\u6781\u7aef\u5206\u7c7b\u4e2d\u4f4e\u9891\u7c7b\u522b\u7684\u6027\u80fd\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u4e24\u4e2a\u65b0\u521b\u5efa\u7684\u591a\u610f\u56fe\u6570\u636e\u96c6\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\u3002"}}
{"id": "2511.07470", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07470", "abs": "https://arxiv.org/abs/2511.07470", "authors": ["Steven Atkinson"], "title": "Slimmable NAM: Neural Amp Models with adjustable runtime computational cost", "comment": "2 pages, 2 figures. Accepted to NeurIPS 2025 workshop on AI for Music", "summary": "This work demonstrates \"slimmable Neural Amp Models\", whose size and computational cost can be changed without additional training and with negligible computational overhead, enabling musicians to easily trade off between the accuracy and compute of the models they are using. The method's performance is quantified against commonly-used baselines, and a real-time demonstration of the model in an audio effect plug-in is developed.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u53ef\u8c03\u6574\u5927\u5c0f\u7684\u795e\u7ecf\u653e\u5927\u5668\u6a21\u578b\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u6539\u53d8\u6a21\u578b\u5927\u5c0f\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u8ba9\u97f3\u4e50\u5bb6\u80fd\u591f\u5728\u6a21\u578b\u7cbe\u5ea6\u548c\u8ba1\u7b97\u8d44\u6e90\u4e4b\u95f4\u7075\u6d3b\u6743\u8861\u3002", "motivation": "\u8ba9\u97f3\u4e50\u5bb6\u80fd\u591f\u6839\u636e\u5b9e\u9645\u9700\u6c42\u5728\u6a21\u578b\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u8fdb\u884c\u7075\u6d3b\u6743\u8861\uff0c\u65e0\u9700\u4e3a\u4e0d\u540c\u89c4\u6a21\u7684\u6a21\u578b\u8fdb\u884c\u989d\u5916\u8bad\u7ec3\u3002", "method": "\u5f00\u53d1\u53ef\u8c03\u6574\u5927\u5c0f\u7684\u795e\u7ecf\u653e\u5927\u5668\u6a21\u578b\u67b6\u6784\uff0c\u652f\u6301\u5728\u63a8\u7406\u65f6\u52a8\u6001\u8c03\u6574\u6a21\u578b\u5927\u5c0f\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u5ffd\u7565\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u4e0e\u5e38\u7528\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\u91cf\u5316\u4e86\u6027\u80fd\u8868\u73b0\uff0c\u5e76\u5f00\u53d1\u4e86\u5b9e\u65f6\u97f3\u9891\u6548\u679c\u63d2\u4ef6\u7684\u5b9e\u9645\u6f14\u793a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u5373\u53ef\u8c03\u6574\u6a21\u578b\u89c4\u6a21\u7684\u76ee\u6807\uff0c\u4e3a\u97f3\u4e50\u5e94\u7528\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u7cbe\u5ea6-\u8ba1\u7b97\u6743\u8861\u65b9\u6848\u3002"}}
{"id": "2511.07683", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.07683", "abs": "https://arxiv.org/abs/2511.07683", "authors": ["Marko Fidanovski", "Iv\u00e1n Alexander Morales Sandoval", "Kuranage Roche Rayan Ranasinghe", "Giuseppe Thadeu Freitas de Abreu", "Emil Bj\u00f6rnson", "Bruno Clerckx"], "title": "Fractional Programming and Manifold Optimization for Reciprocal BD-RIS Scattering Matrix Design", "comment": null, "summary": "We investigate the problem of maximizing the sum-rate performance of a beyond-diagonal reconfigurable intelligent surface (BD-RIS)-aided multi-user (MU)-multiple-input single-output (MISO) system using fractional programming (FP) techniques. More specifically, we leverage the Lagrangian Dual Transform (LDT) and Quadratic Transform (QT) to derive an equivalent objective function which is then solved iteratively via a manifold optimization framework. It is shown that these techniques reduce the complexity of the optimization problem for the scattering matrix solution, while also providing notable performance gains compared to state-of-the-art (SotA) methods under the same system conditions. Simulation results confirm the effectiveness of the proposed method in improving sum-rate performance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4f7f\u7528\u5206\u6570\u89c4\u5212\u6280\u672f\u6700\u5927\u5316\u8d85\u5bf9\u89d2\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u8f85\u52a9\u591a\u7528\u6237\u591a\u8f93\u5165\u5355\u8f93\u51fa\u7cfb\u7edf\u7684\u548c\u901f\u7387\u6027\u80fd\u95ee\u9898\u3002", "motivation": "\u63d0\u9ad8BD-RIS\u8f85\u52a9MU-MISO\u7cfb\u7edf\u7684\u548c\u901f\u7387\u6027\u80fd\uff0c\u901a\u8fc7\u66f4\u6709\u6548\u7684\u4f18\u5316\u65b9\u6cd5\u964d\u4f4e\u590d\u6742\u5ea6\u5e76\u8d85\u8d8a\u73b0\u6709\u6280\u672f\u6c34\u5e73\u3002", "method": "\u5229\u7528\u62c9\u683c\u6717\u65e5\u5bf9\u5076\u53d8\u6362\u548c\u4e8c\u6b21\u53d8\u6362\u63a8\u5bfc\u7b49\u6548\u76ee\u6807\u51fd\u6570\uff0c\u7136\u540e\u901a\u8fc7\u6d41\u5f62\u4f18\u5316\u6846\u67b6\u8fdb\u884c\u8fed\u4ee3\u6c42\u89e3\u3002", "result": "\u8fd9\u4e9b\u6280\u672f\u964d\u4f4e\u4e86\u6563\u5c04\u77e9\u9635\u4f18\u5316\u95ee\u9898\u7684\u590d\u6742\u5ea6\uff0c\u5e76\u5728\u76f8\u540c\u7cfb\u7edf\u6761\u4ef6\u4e0b\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u4f9b\u4e86\u663e\u8457\u7684\u6027\u80fd\u589e\u76ca\u3002", "conclusion": "\u4eff\u771f\u7ed3\u679c\u8bc1\u5b9e\u4e86\u6240\u63d0\u65b9\u6cd5\u5728\u6539\u5584\u548c\u901f\u7387\u6027\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.07483", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07483", "abs": "https://arxiv.org/abs/2511.07483", "authors": ["Qianxi He", "Qingyu Ren", "Shanzhe Lei", "Xuhong Wang", "Yingchun Wang"], "title": "Beyond Correctness: Confidence-Aware Reward Modeling for Enhancing Large Language Model Reasoning", "comment": null, "summary": "Recent advancements in large language models (LLMs) have shifted the post-training paradigm from traditional instruction tuning and human preference alignment toward reinforcement learning (RL) focused on reasoning capabilities. However, numerous technical reports indicate that purely rule-based reward RL frequently results in poor-quality reasoning chains or inconsistencies between reasoning processes and final answers, particularly when the base model is of smaller scale. During the RL exploration process, models might employ low-quality reasoning chains due to the lack of knowledge, occasionally producing correct answers randomly and receiving rewards based on established rule-based judges. This constrains the potential for resource-limited organizations to conduct direct reinforcement learning training on smaller-scale models. We propose a novel confidence-based reward model tailored for enhancing STEM reasoning capabilities. Unlike conventional approaches, our model penalizes not only incorrect answers but also low-confidence correct responses, thereby promoting more robust and logically consistent reasoning. We validate the effectiveness of our approach through static evaluations, Best-of-N inference tests, and PPO-based RL training. Our method outperforms several state-of-the-art open-source reward models across diverse STEM benchmarks. We release our codes and model in https://github.com/qianxiHe147/C2RM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u5956\u52b1\u6a21\u578b\uff0c\u4e13\u95e8\u7528\u4e8e\u589e\u5f3aSTEM\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u60e9\u7f5a\u4f4e\u7f6e\u4fe1\u5ea6\u7684\u6b63\u786e\u56de\u7b54\u6765\u4fc3\u8fdb\u66f4\u7a33\u5065\u548c\u903b\u8f91\u4e00\u81f4\u7684\u63a8\u7406\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\u673a\u5236\u5728\u63a8\u7406\u80fd\u529b\u8bad\u7ec3\u4e2d\u7ecf\u5e38\u5bfc\u81f4\u63a8\u7406\u94fe\u8d28\u91cf\u5dee\u6216\u63a8\u7406\u8fc7\u7a0b\u4e0e\u6700\u7ec8\u7b54\u6848\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u8f83\u5c0f\u89c4\u6a21\u7684\u6a21\u578b\u3002\u8fd9\u9650\u5236\u4e86\u8d44\u6e90\u6709\u9650\u7684\u7ec4\u7ec7\u5728\u5c0f\u89c4\u6a21\u6a21\u578b\u4e0a\u8fdb\u884c\u76f4\u63a5\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u5956\u52b1\u6a21\u578b\uff0c\u4e0d\u4ec5\u60e9\u7f5a\u9519\u8bef\u7b54\u6848\uff0c\u8fd8\u60e9\u7f5a\u4f4e\u7f6e\u4fe1\u5ea6\u7684\u6b63\u786e\u56de\u7b54\u3002\u901a\u8fc7\u9759\u6001\u8bc4\u4f30\u3001Best-of-N\u63a8\u7406\u6d4b\u8bd5\u548c\u57fa\u4e8ePPO\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6765\u9a8c\u8bc1\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u4e2aSTEM\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u51e0\u79cd\u6700\u5148\u8fdb\u7684\u5f00\u6e90\u5956\u52b1\u6a21\u578b\u3002", "conclusion": "\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u5956\u52b1\u6a21\u578b\u80fd\u591f\u6709\u6548\u63d0\u5347STEM\u63a8\u7406\u80fd\u529b\uff0c\u4fc3\u8fdb\u66f4\u7a33\u5065\u548c\u903b\u8f91\u4e00\u81f4\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u4e3a\u5c0f\u89c4\u6a21\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2511.07472", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.07472", "abs": "https://arxiv.org/abs/2511.07472", "authors": ["Mehmet Can Yavuz"], "title": "Multivariate Variational Autoencoder", "comment": null, "summary": "We present the Multivariate Variational Autoencoder (MVAE), a VAE variant that preserves Gaussian tractability while lifting the diagonal posterior restriction. MVAE factorizes each posterior covariance, where a \\emph{global} coupling matrix $\\mathbf{C}$ induces dataset-wide latent correlations and \\emph{per-sample} diagonal scales modulate local uncertainty. This yields a full-covariance family with analytic KL and an efficient reparameterization via $\\mathbf{L}=\\mathbf{C}\\mathrm{diag}(\\boldsymbol\u03c3)$. Across Larochelle-style MNIST variants, Fashion-MNIST, CIFAR-10, and CIFAR-100, MVAE consistently matches or improves reconstruction (MSE~$\\downarrow$) and delivers robust gains in calibration (NLL/Brier/ECE~$\\downarrow$) and unsupervised structure (NMI/ARI~$\\uparrow$) relative to diagonal-covariance VAEs with matched capacity, especially at mid-range latent sizes. Latent-plane visualizations further indicate smoother, more coherent factor traversals and sharper local detail. We release a fully reproducible implementation with training/evaluation scripts and sweep utilities to facilitate fair comparison and reuse.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u591a\u5143\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08MVAE\uff09\uff0c\u4e00\u79cd\u4fdd\u7559\u9ad8\u65af\u53ef\u5904\u7406\u6027\u540c\u65f6\u89e3\u9664\u5bf9\u89d2\u540e\u9a8c\u9650\u5236\u7684VAE\u53d8\u4f53\uff0c\u901a\u8fc7\u5168\u5c40\u8026\u5408\u77e9\u9635\u548c\u6bcf\u6837\u672c\u5bf9\u89d2\u5c3a\u5ea6\u5b9e\u73b0\u5168\u534f\u65b9\u5dee\u5efa\u6a21\u3002", "motivation": "\u4f20\u7edfVAE\u4f7f\u7528\u5bf9\u89d2\u534f\u65b9\u5dee\u540e\u9a8c\u9650\u5236\u4e86\u5efa\u6a21\u80fd\u529b\uff0cMVAE\u65e8\u5728\u4fdd\u6301\u9ad8\u65af\u53ef\u5904\u7406\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u66f4\u7075\u6d3b\u7684\u5168\u534f\u65b9\u5dee\u5efa\u6a21\u3002", "method": "MVAE\u5c06\u6bcf\u4e2a\u540e\u9a8c\u534f\u65b9\u5dee\u5206\u89e3\u4e3a\u5168\u5c40\u8026\u5408\u77e9\u9635C\uff08\u8bf1\u5bfc\u6570\u636e\u96c6\u8303\u56f4\u7684\u6f5c\u5728\u76f8\u5173\u6027\uff09\u548c\u6bcf\u6837\u672c\u5bf9\u89d2\u5c3a\u5ea6\uff08\u8c03\u5236\u5c40\u90e8\u4e0d\u786e\u5b9a\u6027\uff09\uff0c\u901a\u8fc7L=Cdiag(\u03c3)\u5b9e\u73b0\u9ad8\u6548\u91cd\u53c2\u6570\u5316\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cMVAE\u5728\u91cd\u5efa\u8bef\u5dee\u3001\u6821\u51c6\u6307\u6807\u548c\u65e0\u76d1\u7763\u7ed3\u6784\u53d1\u73b0\u65b9\u9762\u5747\u4f18\u4e8e\u5bf9\u89d2\u534f\u65b9\u5deeVAE\uff0c\u7279\u522b\u662f\u5728\u4e2d\u7b49\u6f5c\u5728\u7ef4\u5ea6\u4e0b\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "MVAE\u63d0\u4f9b\u4e86\u4e00\u79cd\u5728\u4fdd\u6301\u9ad8\u65af\u53ef\u5904\u7406\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u5168\u534f\u65b9\u5dee\u5efa\u6a21\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u8bc4\u4f30\u7ef4\u5ea6\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u5bf9\u89d2\u534f\u65b9\u5deeVAE\u3002"}}
{"id": "2511.07481", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07481", "abs": "https://arxiv.org/abs/2511.07481", "authors": ["Reem Al-Saidi", "Erman Ayday", "Ziad Kobti"], "title": "Comparing Reconstruction Attacks on Pretrained Versus Full Fine-tuned Large Language Model Embeddings on Homo Sapiens Splice Sites Genomic Data", "comment": null, "summary": "This study investigates embedding reconstruction attacks in large language models (LLMs) applied to genomic sequences, with a specific focus on how fine-tuning affects vulnerability to these attacks. Building upon Pan et al.'s seminal work demonstrating that embeddings from pretrained language models can leak sensitive information, we conduct a comprehensive analysis using the HS3D genomic dataset to determine whether task-specific optimization strengthens or weakens privacy protections. Our research extends Pan et al.'s work in three significant dimensions. First, we apply their reconstruction attack pipeline to pretrained and fine-tuned model embeddings, addressing a critical gap in their methodology that did not specify embedding types. Second, we implement specialized tokenization mechanisms tailored specifically for DNA sequences, enhancing the model's ability to process genomic data, as these models are pretrained on natural language and not DNA. Third, we perform a detailed comparative analysis examining position-specific, nucleotide-type, and privacy changes between pretrained and fine-tuned embeddings. We assess embeddings vulnerabilities across different types and dimensions, providing deeper insights into how task adaptation shifts privacy risks throughout genomic sequences. Our findings show a clear distinction in reconstruction vulnerability between pretrained and fine-tuned embeddings. Notably, fine-tuning strengthens resistance to reconstruction attacks in multiple architectures -- XLNet (+19.8\\%), GPT-2 (+9.8\\%), and BERT (+7.8\\%) -- pointing to task-specific optimization as a potential privacy enhancement mechanism. These results highlight the need for advanced protective mechanisms for language models processing sensitive genomic data, while highlighting fine-tuning as a potential privacy-enhancing technique worth further exploration.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u5e94\u7528\u4e8e\u57fa\u56e0\u7ec4\u5e8f\u5217\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5d4c\u5165\u91cd\u5efa\u653b\u51fb\u7684\u95ee\u9898\uff0c\u7279\u522b\u5173\u6ce8\u5fae\u8c03\u5982\u4f55\u5f71\u54cd\u5bf9\u8fd9\u4e9b\u653b\u51fb\u7684\u8106\u5f31\u6027\u3002\u7814\u7a76\u53d1\u73b0\u5fae\u8c03\u53ef\u4ee5\u589e\u5f3a\u6a21\u578b\u5bf9\u91cd\u5efa\u653b\u51fb\u7684\u62b5\u6297\u529b\uff0c\u7279\u522b\u662f\u5728XLNet\u3001GPT-2\u548cBERT\u7b49\u67b6\u6784\u4e2d\u3002", "motivation": "\u57fa\u4e8ePan\u7b49\u4eba\u7684\u5f00\u521b\u6027\u5de5\u4f5c\uff0c\u8be5\u7814\u7a76\u65e8\u5728\u786e\u5b9a\u4efb\u52a1\u7279\u5b9a\u7684\u4f18\u5316\u662f\u589e\u5f3a\u8fd8\u662f\u524a\u5f31\u9690\u79c1\u4fdd\u62a4\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u654f\u611f\u7684\u57fa\u56e0\u7ec4\u6570\u636e\u65f6\u3002", "method": "\u7814\u7a76\u6269\u5c55\u4e86Pan\u7b49\u4eba\u7684\u5de5\u4f5c\uff0c\u5728\u4e09\u4e2a\u91cd\u8981\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u4e86\u6539\u8fdb\uff1a\u5c06\u91cd\u5efa\u653b\u51fb\u7ba1\u9053\u5e94\u7528\u4e8e\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u6a21\u578b\u5d4c\u5165\uff1b\u4e3aDNA\u5e8f\u5217\u5b9e\u73b0\u4e13\u95e8\u7684\u6807\u8bb0\u5316\u673a\u5236\uff1b\u8fdb\u884c\u8be6\u7ec6\u7684\u6bd4\u8f83\u5206\u6790\uff0c\u68c0\u67e5\u4f4d\u7f6e\u7279\u5b9a\u3001\u6838\u82f7\u9178\u7c7b\u578b\u548c\u9690\u79c1\u53d8\u5316\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u5d4c\u5165\u5728\u91cd\u5efa\u8106\u5f31\u6027\u65b9\u9762\u5b58\u5728\u660e\u663e\u533a\u522b\u3002\u5fae\u8c03\u589e\u5f3a\u4e86\u591a\u79cd\u67b6\u6784\u5bf9\u91cd\u5efa\u653b\u51fb\u7684\u62b5\u6297\u529b\uff1aXLNet (+19.8%)\u3001GPT-2 (+9.8%) \u548c BERT (+7.8%)\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u5f3a\u8c03\u4e86\u4e3a\u5904\u7406\u654f\u611f\u57fa\u56e0\u7ec4\u6570\u636e\u7684\u8bed\u8a00\u6a21\u578b\u5f00\u53d1\u9ad8\u7ea7\u4fdd\u62a4\u673a\u5236\u7684\u5fc5\u8981\u6027\uff0c\u540c\u65f6\u6307\u51fa\u5fae\u8c03\u4f5c\u4e3a\u4e00\u79cd\u6f5c\u5728\u7684\u9690\u79c1\u589e\u5f3a\u6280\u672f\u503c\u5f97\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002"}}
{"id": "2511.07482", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.07482", "abs": "https://arxiv.org/abs/2511.07482", "authors": ["Dev Patel", "Gabrielle Gervacio", "Diekola Raimi", "Kevin Zhu", "Ryan Lagasse", "Gabriel Grand", "Ashwinee Panda", "Maheep Chaudhary"], "title": "Alignment-Constrained Dynamic Pruning for LLMs: Identifying and Preserving Alignment-Critical Circuits", "comment": null, "summary": "Large Language Models require substantial computational resources for inference, posing deployment challenges. While dynamic pruning offers superior efficiency over static methods through adaptive circuit selection, it exacerbates alignment degradation by retaining only input-dependent safety-critical circuit preservation across diverse inputs. As a result, addressing these heightened alignment vulnerabilities remains critical. We introduce Alignment-Aware Probe Pruning (AAPP), a dynamic structured pruning method that adaptively preserves alignment-relevant circuits during inference, building upon Probe Pruning. Experiments on LLaMA 2-7B, Qwen2.5-14B-Instruct, and Gemma-3-12B-IT show AAPP improves refusal rates by 50\\% at matched compute, enabling efficient yet safety-preserving LLM deployment.", "AI": {"tldr": "AAPP\u662f\u4e00\u79cd\u52a8\u6001\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u4fdd\u7559\u5bf9\u9f50\u76f8\u5173\u7535\u8def\u6765\u63d0\u9ad8LLM\u63a8\u7406\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u5b89\u5168\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\uff0c\u52a8\u6001\u526a\u679d\u867d\u7136\u6bd4\u9759\u6001\u65b9\u6cd5\u66f4\u9ad8\u6548\uff0c\u4f46\u4f1a\u52a0\u5267\u5bf9\u9f50\u9000\u5316\u95ee\u9898\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u5bf9\u9f50\u6f0f\u6d1e\u3002", "method": "\u57fa\u4e8eProbe Pruning\uff0c\u63d0\u51fa\u5bf9\u9f50\u611f\u77e5\u63a2\u9488\u526a\u679d(AAPP)\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u81ea\u9002\u5e94\u4fdd\u7559\u5bf9\u9f50\u76f8\u5173\u7535\u8def\u3002", "result": "\u5728LLaMA 2-7B\u3001Qwen2.5-14B-Instruct\u548cGemma-3-12B-IT\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cAAPP\u5728\u76f8\u540c\u8ba1\u7b97\u91cf\u4e0b\u5c06\u62d2\u7edd\u7387\u63d0\u9ad8\u4e8650%\u3002", "conclusion": "AAPP\u80fd\u591f\u5b9e\u73b0\u9ad8\u6548\u4e14\u4fdd\u6301\u5b89\u5168\u6027\u7684LLM\u90e8\u7f72\u3002"}}
{"id": "2511.07669", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07669", "abs": "https://arxiv.org/abs/2511.07669", "authors": ["Alejandro R. Jadad"], "title": "Making LLMs Reliable When It Matters Most: A Five-Layer Architecture for High-Stakes Decisions", "comment": "24 pages, 1 figure, 2 tables", "summary": "Current large language models (LLMs) excel in verifiable domains where outputs can be checked before action but prove less reliable for high-stakes strategic decisions with uncertain outcomes. This gap, driven by mutually reinforcing cognitive biases in both humans and artificial intelligence (AI) systems, threatens the defensibility of valuations and sustainability of investments in the sector.\n  This report describes a framework emerging from systematic qualitative assessment across 7 frontier-grade LLMs and 3 market-facing venture vignettes under time pressure. Detailed prompting specifying decision partnership and explicitly instructing avoidance of sycophancy, confabulation, solution drift, and nihilism achieved initial partnership state but failed to maintain it under operational pressure. Sustaining protective partnership state required an emergent 7-stage calibration sequence, built upon a 4-stage initialization process, within a 5-layer protection architecture enabling bias self-monitoring, human-AI adversarial challenge, partnership state verification, performance degradation detection, and stakeholder protection.\n  Three discoveries resulted: partnership state is achievable through ordered calibration but requires emergent maintenance protocols; reliability degrades when architectural drift and context exhaustion align; and dissolution discipline prevents costly pursuit of fundamentally wrong directions. Cross-model validation revealed systematic performance differences across LLM architectures.\n  This approach demonstrates that human-AI teams can achieve cognitive partnership capable of preventing avoidable regret in high-stakes decisions, addressing return-on-investment expectations that depend on AI systems supporting consequential decision-making without introducing preventable cognitive traps when verification arrives too late.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u901a\u8fc77\u9636\u6bb5\u6821\u51c6\u5e8f\u5217\u548c5\u5c42\u4fdd\u62a4\u67b6\u6784\uff0c\u4f7f\u4eba\u7c7b-AI\u56e2\u961f\u5728\u9ad8\u98ce\u9669\u6218\u7565\u51b3\u7b56\u4e2d\u5b9e\u73b0\u8ba4\u77e5\u4f19\u4f34\u5173\u7cfb\uff0c\u907f\u514d\u53ef\u9884\u9632\u7684\u8ba4\u77e5\u9677\u9631\u548c\u9057\u61be\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u53ef\u9a8c\u8bc1\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5177\u6709\u4e0d\u786e\u5b9a\u7ed3\u679c\u7684\u9ad8\u98ce\u9669\u6218\u7565\u51b3\u7b56\u4e2d\u53ef\u9760\u6027\u4e0d\u8db3\uff0c\u8fd9\u5a01\u80c1\u5230\u4f30\u503c\u8fa9\u62a4\u548c\u6295\u8d44\u53ef\u6301\u7eed\u6027\u3002", "method": "\u901a\u8fc7\u5bf97\u4e2a\u524d\u6cbf\u7ea7LLM\u548c3\u4e2a\u5e02\u573a\u98ce\u9669\u6848\u4f8b\u8fdb\u884c\u7cfb\u7edf\u5b9a\u6027\u8bc4\u4f30\uff0c\u5f00\u53d1\u4e86\u5305\u542b7\u9636\u6bb5\u6821\u51c6\u5e8f\u5217\u30014\u9636\u6bb5\u521d\u59cb\u5316\u8fc7\u7a0b\u548c5\u5c42\u4fdd\u62a4\u67b6\u6784\u7684\u6846\u67b6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a\u4f19\u4f34\u5173\u7cfb\u72b6\u6001\u53ef\u901a\u8fc7\u6709\u5e8f\u6821\u51c6\u5b9e\u73b0\u4f46\u9700\u8981\u65b0\u5174\u7ef4\u62a4\u534f\u8bae\uff1b\u5f53\u67b6\u6784\u6f02\u79fb\u548c\u4e0a\u4e0b\u6587\u8017\u5c3d\u540c\u65f6\u53d1\u751f\u65f6\u53ef\u9760\u6027\u4f1a\u4e0b\u964d\uff1b\u89e3\u6563\u7eaa\u5f8b\u53ef\u9632\u6b62\u8ffd\u6c42\u6839\u672c\u9519\u8bef\u65b9\u5411\u3002", "conclusion": "\u4eba\u7c7b-AI\u56e2\u961f\u53ef\u4ee5\u5b9e\u73b0\u8ba4\u77e5\u4f19\u4f34\u5173\u7cfb\uff0c\u5728\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u9884\u9632\u53ef\u907f\u514d\u7684\u9057\u61be\uff0c\u6ee1\u8db3\u4f9d\u8d56AI\u7cfb\u7edf\u652f\u6301\u5173\u952e\u51b3\u7b56\u800c\u4e0d\u5f15\u5165\u53ef\u9884\u9632\u8ba4\u77e5\u9677\u9631\u7684\u6295\u8d44\u56de\u62a5\u671f\u671b\u3002"}}
{"id": "2511.07485", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.07485", "abs": "https://arxiv.org/abs/2511.07485", "authors": ["Sushant Mehta"], "title": "When Are Learning Biases Equivalent? A Unifying Framework for Fairness, Robustness, and Distribution Shift", "comment": null, "summary": "Machine learning systems exhibit diverse failure modes: unfairness toward protected groups, brittleness to spurious correlations, poor performance on minority sub-populations, which are typically studied in isolation by distinct research communities. We propose a unifying theoretical framework that characterizes when different bias mechanisms produce quantitatively equivalent effects on model performance. By formalizing biases as violations of conditional independence through information-theoretic measures, we prove formal equivalence conditions relating spurious correlations, subpopulation shift, class imbalance, and fairness violations. Our theory predicts that a spurious correlation of strength $\u03b1$ produces equivalent worst-group accuracy degradation as a sub-population imbalance ratio $r \\approx (1+\u03b1)/(1-\u03b1)$ under feature overlap assumptions. Empirical validation in six datasets and three architectures confirms that predicted equivalences hold within the accuracy of the worst group 3\\%, enabling the principled transfer of debiasing methods across problem domains. This work bridges the literature on fairness, robustness, and distribution shifts under a common perspective.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u4e0d\u540c\u504f\u5dee\u673a\u5236\uff08\u5982\u865a\u5047\u76f8\u5173\u6027\u3001\u5b50\u7fa4\u4f53\u504f\u79fb\u3001\u7c7b\u522b\u4e0d\u5e73\u8861\u548c\u516c\u5e73\u6027\u8fdd\u89c4\uff09\u5728\u6a21\u578b\u6027\u80fd\u4e0a\u4f1a\u4ea7\u751f\u5b9a\u91cf\u7b49\u6548\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u4fe1\u606f\u8bba\u65b9\u6cd5\u5c06\u504f\u5dee\u5f62\u5f0f\u5316\u4e3a\u6761\u4ef6\u72ec\u7acb\u6027\u7684\u8fdd\u53cd\uff0c\u5efa\u7acb\u4e86\u8fd9\u4e9b\u504f\u5dee\u673a\u5236\u4e4b\u95f4\u7684\u7b49\u4ef7\u5173\u7cfb\uff0c\u5e76\u8fdb\u884c\u4e86\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5b58\u5728\u591a\u79cd\u5931\u8d25\u6a21\u5f0f\uff0c\u5982\u5bf9\u53d7\u4fdd\u62a4\u7fa4\u4f53\u7684\u4e0d\u516c\u5e73\u6027\u3001\u5bf9\u865a\u5047\u76f8\u5173\u6027\u7684\u8106\u5f31\u6027\u3001\u5728\u5c11\u6570\u5b50\u7fa4\u4f53\u4e0a\u7684\u6027\u80fd\u5dee\u7b49\uff0c\u8fd9\u4e9b\u95ee\u9898\u901a\u5e38\u7531\u4e0d\u540c\u7684\u7814\u7a76\u793e\u533a\u5b64\u7acb\u7814\u7a76\u3002\u4f5c\u8005\u5e0c\u671b\u5efa\u7acb\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u6765\u7406\u89e3\u8fd9\u4e9b\u504f\u5dee\u673a\u5236\u4e4b\u95f4\u7684\u5185\u5728\u8054\u7cfb\u3002", "method": "\u901a\u8fc7\u4fe1\u606f\u8bba\u5ea6\u91cf\u5c06\u504f\u5dee\u5f62\u5f0f\u5316\u4e3a\u6761\u4ef6\u72ec\u7acb\u6027\u7684\u8fdd\u53cd\uff0c\u5efa\u7acb\u4e86\u4e0d\u540c\u504f\u5dee\u673a\u5236\u4e4b\u95f4\u7684\u6b63\u5f0f\u7b49\u4ef7\u6761\u4ef6\u3002\u7406\u8bba\u9884\u6d4b\u4e86\u865a\u5047\u76f8\u5173\u6027\u5f3a\u5ea6\u4e0e\u5b50\u7fa4\u4f53\u4e0d\u5e73\u8861\u6bd4\u7387\u4e4b\u95f4\u7684\u5b9a\u91cf\u5173\u7cfb\uff0c\u5e76\u5728\u516d\u4e2a\u6570\u636e\u96c6\u548c\u4e09\u79cd\u67b6\u6784\u4e0a\u8fdb\u884c\u4e86\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "result": "\u5b9e\u8bc1\u9a8c\u8bc1\u8868\u660e\uff0c\u9884\u6d4b\u7684\u7b49\u4ef7\u5173\u7cfb\u5728\u6700\u5dee\u7fa4\u4f53\u51c6\u786e\u5ea63%\u7684\u8303\u56f4\u5185\u6210\u7acb\u3002\u865a\u5047\u76f8\u5173\u6027\u5f3a\u5ea6\u03b1\u4e0e\u5b50\u7fa4\u4f53\u4e0d\u5e73\u8861\u6bd4\u7387r\u2248(1+\u03b1)/(1-\u03b1)\u4e4b\u95f4\u5b58\u5728\u5b9a\u91cf\u7b49\u4ef7\u5173\u7cfb\uff0c\u8fd9\u5141\u8bb8\u5728\u4e0d\u540c\u95ee\u9898\u9886\u57df\u95f4\u6709\u539f\u5219\u5730\u8f6c\u79fb\u53bb\u504f\u5dee\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5728\u516c\u5e73\u6027\u3001\u9c81\u68d2\u6027\u548c\u5206\u5e03\u504f\u79fb\u7684\u6587\u732e\u4e4b\u95f4\u5efa\u7acb\u4e86\u6865\u6881\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5171\u540c\u7684\u89c6\u89d2\u6765\u7406\u89e3\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5404\u79cd\u504f\u5dee\u673a\u5236\u3002"}}
{"id": "2511.07500", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07500", "abs": "https://arxiv.org/abs/2511.07500", "authors": ["Marco Roccetti"], "title": "Methodological Precedence in Health Tech: Why ML/Big Data Analysis Must Follow Basic Epidemiological Consistency. A Case Study", "comment": "2 Tables; ML/Big data paper on medical data", "summary": "The integration of advanced analytical tools, including Machine Learning (ML) and massive data processing, has revolutionized health research, promising unprecedented accuracy in diagnosis and risk prediction. However, the rigor of these complex methods is fundamentally dependent on the quality and integrity of the underlying datasets and the validity of their statistical design. We propose an emblematic case where advanced analysis (ML/Big Data) must necessarily be subsequent to the verification of basic methodological coherence. This study highlights a crucial cautionary principle: sophisticated analyses amplify, rather than correct, severe methodological flaws rooted in basic design choices, leading to misleading or contradictory findings. By applying simple, standard descriptive statistical methods and established national epidemiological benchmarks to a recently published cohort study on vaccine outcomes and psychiatric events, we expose multiple, statistically irreconcilable paradoxes. These paradoxes, including an implausible risk reduction for a chronic disorder in a high-risk group and contradictory incidence rate comparisons, definitively invalidate the reported hazard ratios (HRs). We demonstrate that the observed effects are mathematical artifacts stemming from an uncorrected selection bias in the cohort construction. This analysis serves as a robust reminder that even the most complex health studies must first pass the test of basic epidemiological consistency before any conclusion drawn from subsequent advanced ML or statistical modeling can be considered valid or publishable. We conclude that robust methods, such as Propensity Score Matching, are essential for achieving valid causal inference from administrative data in the absence of randomization", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u4e00\u4e2a\u75ab\u82d7\u4e0e\u7cbe\u795e\u4e8b\u4ef6\u5173\u7cfb\u7684\u961f\u5217\u7814\u7a76\u6848\u4f8b\uff0c\u8bc1\u660e\u5373\u4f7f\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u548c\u5927\u6570\u636e\u7b49\u5148\u8fdb\u5206\u6790\u65b9\u6cd5\uff0c\u5982\u679c\u57fa\u7840\u7814\u7a76\u8bbe\u8ba1\u5b58\u5728\u4e25\u91cd\u65b9\u6cd5\u5b66\u7f3a\u9677\uff0c\u590d\u6742\u5206\u6790\u53cd\u800c\u4f1a\u653e\u5927\u8fd9\u4e9b\u9519\u8bef\uff0c\u5bfc\u81f4\u8bef\u5bfc\u6027\u7ed3\u8bba\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u548c\u6d77\u91cf\u6570\u636e\u5904\u7406\u5728\u5065\u5eb7\u7814\u7a76\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u7814\u7a76\u8005\u9700\u8981\u8b66\u60d5\u8fd9\u4e9b\u590d\u6742\u65b9\u6cd5\u5bf9\u57fa\u7840\u65b9\u6cd5\u5b66\u4e25\u8c28\u6027\u7684\u4f9d\u8d56\u3002\u672c\u6587\u65e8\u5728\u5f3a\u8c03\uff0c\u5728\u5e94\u7528\u5148\u8fdb\u5206\u6790\u4e4b\u524d\uff0c\u5fc5\u987b\u9996\u5148\u9a8c\u8bc1\u57fa\u7840\u65b9\u6cd5\u5b66\u7684\u4e00\u81f4\u6027\u3002", "method": "\u901a\u8fc7\u5bf9\u4e00\u9879\u5df2\u53d1\u8868\u7684\u75ab\u82d7\u7ed3\u679c\u4e0e\u7cbe\u795e\u4e8b\u4ef6\u961f\u5217\u7814\u7a76\uff0c\u5e94\u7528\u6807\u51c6\u63cf\u8ff0\u6027\u7edf\u8ba1\u65b9\u6cd5\u548c\u56fd\u5bb6\u6d41\u884c\u75c5\u5b66\u57fa\u51c6\uff0c\u8bc6\u522b\u51fa\u7edf\u8ba1\u4e0a\u4e0d\u53ef\u8c03\u548c\u7684\u77db\u76fe\uff0c\u63ed\u793a\u7814\u7a76\u8bbe\u8ba1\u4e2d\u7684\u9009\u62e9\u504f\u501a\u95ee\u9898\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8be5\u961f\u5217\u7814\u7a76\u5b58\u5728\u591a\u4e2a\u7edf\u8ba1\u6096\u8bba\uff0c\u5305\u62ec\u9ad8\u98ce\u9669\u4eba\u7fa4\u4e2d\u6162\u6027\u75be\u75c5\u98ce\u9669\u964d\u4f4e\u7684\u4e0d\u53ef\u4fe1\u7ed3\u679c\u3001\u77db\u76fe\u7684\u53d1\u75c5\u7387\u6bd4\u8f83\u7b49\uff0c\u8bc1\u660e\u62a5\u544a\u7684\u98ce\u9669\u6bd4\u662f\u6570\u5b66\u4f2a\u8c61\uff0c\u6e90\u4e8e\u961f\u5217\u6784\u5efa\u4e2d\u672a\u6821\u6b63\u7684\u9009\u62e9\u504f\u501a\u3002", "conclusion": "\u590d\u6742\u5065\u5eb7\u7814\u7a76\u5728\u5e94\u7528\u673a\u5668\u5b66\u4e60\u6216\u7edf\u8ba1\u5efa\u6a21\u4e4b\u524d\uff0c\u5fc5\u987b\u9996\u5148\u901a\u8fc7\u57fa\u7840\u6d41\u884c\u75c5\u5b66\u4e00\u81f4\u6027\u68c0\u9a8c\u3002\u5bf9\u4e8e\u975e\u968f\u673a\u5316\u7684\u884c\u653f\u6570\u636e\uff0c\u503e\u5411\u8bc4\u5206\u5339\u914d\u7b49\u7a33\u5065\u65b9\u6cd5\u662f\u5b9e\u73b0\u6709\u6548\u56e0\u679c\u63a8\u65ad\u7684\u5173\u952e\u3002"}}
{"id": "2511.08125", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.08125", "abs": "https://arxiv.org/abs/2511.08125", "authors": ["Askin Altinoklu", "Leila Musavian"], "title": "DMA-aided MU-MISO Systems for Power Splitting SWIPT via Lorentzian-Constrained Holography", "comment": "Submitted to IEEE ICC 2026", "summary": "This paper presents an optimal power splitting and beamforming design for co-located simultaneous wireless information and power transfer (SWIPT) users in Dynamic Metasurface Antenna (DMA)-aided multiuser multiple-input single-output (MISO) systems. The objective is to minimize transmit power while meeting users signal-to-interference-plus-noise ratio (SINR) and energy harvesting (EH) requirements. The problem is solved via an alternating optimization framework based on semidefinite programming (SDP), where metasurface tunability follows Lorentzian-constrained holography (LCH). In contrast to traditional beamforming architectures, DMA-assisted architectures reduce the need for RF chains and phase shifters but require optimization under the Lorentzian constraint limiting the amplitude and phase optimizations. Hence, the proposed method integrates several LCH schemes, including the recently proposed adaptive-radius LCH (ARLCH), and evaluates nonlinear EH models and circuit noise effects. Simulation results show that the proposed design significantly reduces transmit power compared with baseline methods, highlighting the efficiency of ARLCH and optimal power splitting in DMA-assisted SWIPT systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8eDMA\u8f85\u52a9\u591a\u7528\u6237MISO\u7cfb\u7edf\u4e2dSWIPT\u7528\u6237\u7684\u6700\u4f18\u529f\u7387\u5206\u914d\u548c\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\uff0c\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\u6846\u67b6\u6700\u5c0f\u5316\u53d1\u5c04\u529f\u7387\uff0c\u540c\u65f6\u6ee1\u8db3\u7528\u6237\u7684SINR\u548c\u80fd\u91cf\u6536\u96c6\u8981\u6c42\u3002", "motivation": "\u4f20\u7edf\u6ce2\u675f\u6210\u5f62\u67b6\u6784\u9700\u8981\u5927\u91cfRF\u94fe\u548c\u79fb\u76f8\u5668\uff0c\u800cDMA\u8f85\u52a9\u67b6\u6784\u80fd\u51cf\u5c11\u8fd9\u4e9b\u9700\u6c42\uff0c\u4f46\u9700\u8981\u5728\u6d1b\u4f26\u5179\u7ea6\u675f\u4e0b\u8fdb\u884c\u4f18\u5316\uff0c\u9650\u5236\u4e86\u5e45\u5ea6\u548c\u76f8\u4f4d\u4f18\u5316\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u534a\u5b9a\u89c4\u5212\u7684\u4ea4\u66ff\u4f18\u5316\u6846\u67b6\uff0c\u96c6\u6210\u591a\u79cd\u6d1b\u4f26\u5179\u7ea6\u675f\u5168\u606f\u65b9\u6848\uff08\u5305\u62ec\u81ea\u9002\u5e94\u534a\u5f84LCH\uff09\uff0c\u5e76\u8bc4\u4f30\u975e\u7ebf\u6027EH\u6a21\u578b\u548c\u7535\u8def\u566a\u58f0\u6548\u5e94\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u8bbe\u8ba1\u663e\u8457\u964d\u4f4e\u4e86\u53d1\u5c04\u529f\u7387\uff0c\u7a81\u51fa\u4e86ARLCH\u548c\u6700\u4f18\u529f\u7387\u5206\u914d\u5728DMA\u8f85\u52a9SWIPT\u7cfb\u7edf\u4e2d\u7684\u6548\u7387\u3002", "conclusion": "DMA\u8f85\u52a9\u67b6\u6784\u7ed3\u5408ARLCH\u65b9\u6848\u548c\u6700\u4f18\u529f\u7387\u5206\u914d\u7b56\u7565\uff0c\u80fd\u591f\u6709\u6548\u964d\u4f4e\u7cfb\u7edf\u53d1\u5c04\u529f\u7387\uff0c\u63d0\u9ad8SWIPT\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2511.07629", "categories": ["cs.LG", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.07629", "abs": "https://arxiv.org/abs/2511.07629", "authors": ["Yue Jin", "Giovanni Montana"], "title": "Partial Action Replacement: Tackling Distribution Shift in Offline MARL", "comment": "Accepted by AAAI 2026", "summary": "Offline multi-agent reinforcement learning (MARL) is severely hampered by the challenge of evaluating out-of-distribution (OOD) joint actions. Our core finding is that when the behavior policy is factorized - a common scenario where agents act fully or partially independently during data collection - a strategy of partial action replacement (PAR) can significantly mitigate this challenge. PAR updates a single or part of agents' actions while the others remain fixed to the behavioral data, reducing distribution shift compared to full joint-action updates. Based on this insight, we develop Soft-Partial Conservative Q-Learning (SPaCQL), using PAR to mitigate OOD issue and dynamically weighting different PAR strategies based on the uncertainty of value estimation. We provide a rigorous theoretical foundation for this approach, proving that under factorized behavior policies, the induced distribution shift scales linearly with the number of deviating agents rather than exponentially with the joint-action space. This yields a provably tighter value error bound for this important class of offline MARL problems. Our theoretical results also indicate that SPaCQL adaptively addresses distribution shift using uncertainty-informed weights. Our empirical results demonstrate SPaCQL enables more effective policy learning, and manifest its remarkable superiority over baseline algorithms when the offline dataset exhibits the independence structure.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSPaCQL\u7684\u79bb\u7ebf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u90e8\u5206\u52a8\u4f5c\u66ff\u6362\u7b56\u7565\u7f13\u89e3\u5206\u5e03\u5916\u8054\u5408\u52a8\u4f5c\u8bc4\u4f30\u95ee\u9898\uff0c\u5728\u56e0\u5b50\u5316\u884c\u4e3a\u7b56\u7565\u4e0b\u663e\u8457\u964d\u4f4e\u5206\u5e03\u504f\u79fb\u3002", "motivation": "\u79bb\u7ebf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u9762\u4e34\u5206\u5e03\u5916\u8054\u5408\u52a8\u4f5c\u8bc4\u4f30\u7684\u4e25\u91cd\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u884c\u4e3a\u7b56\u7565\u56e0\u5b50\u5316\u7684\u5e38\u89c1\u573a\u666f\u4e0b\u3002", "method": "\u5f00\u53d1\u4e86Soft-Partial Conservative Q-Learning\u65b9\u6cd5\uff0c\u4f7f\u7528\u90e8\u5206\u52a8\u4f5c\u66ff\u6362\u7b56\u7565\u7f13\u89e3OOD\u95ee\u9898\uff0c\u5e76\u6839\u636e\u4ef7\u503c\u4f30\u8ba1\u7684\u4e0d\u786e\u5b9a\u6027\u52a8\u6001\u52a0\u6743\u4e0d\u540c\u7684PAR\u7b56\u7565\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u5728\u56e0\u5b50\u5316\u884c\u4e3a\u7b56\u7565\u4e0b\uff0c\u5206\u5e03\u504f\u79fb\u4e0e\u504f\u79bb\u667a\u80fd\u4f53\u6570\u91cf\u5448\u7ebf\u6027\u5173\u7cfb\u800c\u975e\u6307\u6570\u5173\u7cfb\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aSPaCQL\u5728\u5177\u6709\u72ec\u7acb\u6027\u7ed3\u6784\u7684\u79bb\u7ebf\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u7b97\u6cd5\u3002", "conclusion": "SPaCQL\u65b9\u6cd5\u901a\u8fc7\u90e8\u5206\u52a8\u4f5c\u66ff\u6362\u548c\u4e0d\u786e\u5b9a\u6027\u52a0\u6743\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u79bb\u7ebfMARL\u4e2d\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u5728\u56e0\u5b50\u5316\u884c\u4e3a\u7b56\u7565\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2511.08474", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.08474", "abs": "https://arxiv.org/abs/2511.08474", "authors": ["Jialiang Zhu", "Hamza Haif", "Abdelali Arous", "Huseyin Arslan", "Arman Farhang"], "title": "Waveform-domain NOMA: An Enabler for ISAC in Uplink Transmission", "comment": null, "summary": "According to the recent 3GPP decisions on 6G air interface, orthogonal frequency-division multiplexing (OFDM)-based waveforms are the primary candidates for future integrated sensing and communication (ISAC) systems. In this paper, we consider a monostatic sensing scenario in which OFDM is used for the downlink and its reflected echo signal is used for sensing. OFDM and discrete Fourier transform-spread OFDM (DFT-s-OFDM) are the options for uplink transmission. When OFDM is used in the uplink, the power difference between this signal and the echo signal leads to a power-domain non-orthogonal multiple access (PD-NOMA) scenario. In contrast, adopting DFT-s-OFDM as uplink signal enables a waveform-domain NOMA(WD-NOMA). Affine frequency-division multiplexing (AFDM) and orthogonal time frequency space (OTFS) have been proven to be DFT-s-OFDM based waveforms. This work focuses on such a WD-NOMA system, where AFDM or OTFS is used as uplink waveform and OFDM is employed for downlink transmission and sensing. We show that the OFDM signal exhibits additive white Gaussian noise (AWGN)-like behavior in the affine domain, allowing it to be modeled as white noise in uplink symbol detection. To enable accurate data detection performance, an AFDM frame design and a noise power estimation (NPE) method are developed. Furthermore, a two-dimensional orthogonal matching pursuit (2D-OMP) algorithm is applied for sensing by iteratively identifying delay-Doppler components of each target. Simulation results demonstrate that the WD-NOMA ISAC system, employing either AFDM or OTFS, outperforms the PD-NOMA ISAC system that uses only the OFDM waveform in terms of bit error rate (BER) performance. Furthermore, the proposed NPE method yields additional improvements in BER.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57286G\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u4e2d\uff0c\u4f7f\u7528AFDM\u6216OTFS\u4f5c\u4e3a\u4e0a\u884c\u6ce2\u5f62\u3001OFDM\u7528\u4e8e\u4e0b\u884c\u4f20\u8f93\u548c\u611f\u77e5\u7684\u6ce2\u5f62\u57df\u975e\u6b63\u4ea4\u591a\u5740\u7cfb\u7edf\uff0c\u76f8\u6bd4\u529f\u7387\u57dfNOMA\u7cfb\u7edf\u5177\u6709\u66f4\u597d\u7684\u8bef\u7801\u7387\u6027\u80fd\u3002", "motivation": "\u6839\u636e3GPP\u5bf96G\u7a7a\u53e3\u7684\u51b3\u7b56\uff0cOFDM\u6ce2\u5f62\u662f\u672a\u6765\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u7684\u4e3b\u8981\u5019\u9009\u65b9\u6848\u3002\u5f53OFDM\u7528\u4e8e\u4e0b\u884c\u4f20\u8f93\u548c\u611f\u77e5\uff0c\u800c\u4e0d\u540c\u6ce2\u5f62\u7528\u4e8e\u4e0a\u884c\u65f6\uff0c\u4f1a\u4ea7\u751f\u529f\u7387\u57df\u6216\u6ce2\u5f62\u57df\u7684\u975e\u6b63\u4ea4\u591a\u5740\u573a\u666f\u3002", "method": "\u91c7\u7528AFDM\u6216OTFS\u4f5c\u4e3a\u4e0a\u884c\u6ce2\u5f62\uff0cOFDM\u7528\u4e8e\u4e0b\u884c\u4f20\u8f93\u548c\u611f\u77e5\u3002\u5f00\u53d1\u4e86AFDM\u5e27\u8bbe\u8ba1\u548c\u566a\u58f0\u529f\u7387\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u5e94\u7528\u4e8c\u7ef4\u6b63\u4ea4\u5339\u914d\u8ffd\u8e2a\u7b97\u6cd5\u8fdb\u884c\u611f\u77e5\uff0c\u8fed\u4ee3\u8bc6\u522b\u6bcf\u4e2a\u76ee\u6807\u7684\u65f6\u5ef6-\u591a\u666e\u52d2\u5206\u91cf\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528AFDM\u6216OTFS\u7684WD-NOMA ISAC\u7cfb\u7edf\u5728\u8bef\u7801\u7387\u6027\u80fd\u4e0a\u4f18\u4e8e\u4ec5\u4f7f\u7528OFDM\u6ce2\u5f62\u7684PD-NOMA\u7cfb\u7edf\u3002\u63d0\u51fa\u7684\u566a\u58f0\u529f\u7387\u4f30\u8ba1\u65b9\u6cd5\u8fdb\u4e00\u6b65\u6539\u5584\u4e86\u8bef\u7801\u7387\u6027\u80fd\u3002", "conclusion": "\u6ce2\u5f62\u57dfNOMA ISAC\u7cfb\u7edf\u5728\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u5e94\u7528\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0cAFDM\u548cOTFS\u4f5c\u4e3a\u4e0a\u884c\u6ce2\u5f62\u80fd\u591f\u6709\u6548\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2511.08504", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.08504", "abs": "https://arxiv.org/abs/2511.08504", "authors": ["Kailong Wang", "Athina Petropulu"], "title": "Low Overhead Channel Estimation in MIMO OTFS Wireless Communication Systems", "comment": null, "summary": "Orthogonal Time Frequency Space (OTFS) modulation has recently garnered attention due to its robustness in high-mobility wireless communication environments. In OTFS, the data symbols are mapped to the Doppler-Delay (DD) domain. In this paper, we address bandwidth-efficient estimation of channel state information (CSI) for MIMO OTFS systems. Existing channel estimation techniques either require non-overlapped DD-domain pilots and associated guard regions across multiple antennas, sacrificing significant communication rate as the number of transmit antennas increases, or sophisticated algorithms to handle overlapped pilots, escalating the cost and complexity of receivers. We introduce a novel pilot-aided channel estimation method that enjoys low overhead while achieving high performance. Our approach embeds pilots within each OTFS burst in the Time-Frequency (TF) domain. We propose a novel use of TF and DD guard bins, aiming to preserve waveform orthogonality on the pilot bins and DD data integrity, respectively. The receiver first obtains low-complexity coarse estimates of the channel parameters. Leveraging the orthogonality, a virtual array (VA) is constructed. This enables the formulation of a sparse signal recovery (SSR) problem, in which the coarse estimates are used to build a low-dimensional dictionary matrix. The SSR solution yields high-resolution estimates of channel parameters. Simulation results show that the proposed approach achieves good performance with only a small number of pilots and guard bins. Furthermore, the required overhead is independent of the number of transmit antennas, ensuring good scalability of the proposed method for large MIMO arrays. The proposed approach considers practical rectangular transmit pulse-shaping and receiver matched filtering, and also accounts for fractional Doppler effects.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8eMIMO OTFS\u7cfb\u7edf\u7684\u4f4e\u5f00\u9500\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u65f6\u9891\u57df\u5d4c\u5165\u5bfc\u9891\u5e76\u4f7f\u7528\u865a\u62df\u9635\u5217\u6784\u5efa\u7a00\u758f\u4fe1\u53f7\u6062\u590d\u95ee\u9898\uff0c\u5b9e\u73b0\u9ad8\u6027\u80fd\u4fe1\u9053\u53c2\u6570\u4f30\u8ba1\u3002", "motivation": "\u73b0\u6709OTFS\u4fe1\u9053\u4f30\u8ba1\u6280\u672f\u8981\u4e48\u9700\u8981\u975e\u91cd\u53e0\u7684DD\u57df\u5bfc\u9891\u548c\u9632\u62a4\u533a\u57df\u5bfc\u81f4\u901a\u4fe1\u901f\u7387\u4e0b\u964d\uff0c\u8981\u4e48\u9700\u8981\u590d\u6742\u7b97\u6cd5\u5904\u7406\u91cd\u53e0\u5bfc\u9891\u589e\u52a0\u63a5\u6536\u673a\u6210\u672c\u548c\u590d\u6742\u5ea6\u3002", "method": "\u5728\u65f6\u9891\u57df\u5d4c\u5165\u5bfc\u9891\uff0c\u4f7f\u7528TF\u548cDD\u9632\u62a4\u5355\u5143\u4fdd\u6301\u6ce2\u5f62\u6b63\u4ea4\u6027\u548c\u6570\u636e\u5b8c\u6574\u6027\uff0c\u901a\u8fc7\u6784\u5efa\u865a\u62df\u9635\u5217\u548c\u7a00\u758f\u4fe1\u53f7\u6062\u590d\u95ee\u9898\u83b7\u5f97\u9ad8\u5206\u8fa8\u7387\u4fe1\u9053\u53c2\u6570\u4f30\u8ba1\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u4ec5\u9700\u5c11\u91cf\u5bfc\u9891\u548c\u9632\u62a4\u5355\u5143\u5373\u53ef\u83b7\u5f97\u826f\u597d\u6027\u80fd\uff0c\u6240\u9700\u5f00\u9500\u4e0e\u53d1\u5c04\u5929\u7ebf\u6570\u91cf\u65e0\u5173\uff0c\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8003\u8651\u4e86\u5b9e\u9645\u77e9\u5f62\u53d1\u5c04\u8109\u51b2\u6210\u5f62\u548c\u63a5\u6536\u673a\u5339\u914d\u6ee4\u6ce2\uff0c\u540c\u65f6\u8003\u8651\u4e86\u5206\u6570\u591a\u666e\u52d2\u6548\u5e94\uff0c\u4e3a\u5927\u89c4\u6a21MIMO\u9635\u5217\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4fe1\u9053\u4f30\u8ba1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.07895", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07895", "abs": "https://arxiv.org/abs/2511.07895", "authors": ["Ha-Na Jo", "Jung-Sun Lee", "Eunyeong Ko"], "title": "Toward Robust EEG-based Intention Decoding during Misarticulated Speech in Aphasia", "comment": null, "summary": "Aphasia severely limits verbal communication due to impaired language production, often leading to frequent misarticulations during speech attempts. Despite growing interest in brain-computer interface technologies, relatively little attention has been paid to developing EEG-based communication support systems tailored for aphasic patients. To address this gap, we recruited a single participant with expressive aphasia and conducted an Korean-based automatic speech task. EEG signals were recorded during task performance, and each trial was labeled as either correct or incorrect depending on whether the intended word was successfully spoken. Spectral analysis revealed distinct neural activation patterns between the two trial types: misarticulated trials exhibited excessive delta power across widespread channels and increased theta-alpha activity in frontal regions. Building upon these findings, we developed a soft multitask learning framework with maximum mean discrepancy regularization that focus on delta features to jointly optimize class discrimination while aligning the EEG feature distributions of correct and misarticulated trials. The proposed model achieved 58.6 % accuracy for correct and 45.5 % for misarticulated trials-outperforming the baseline by over 45 % on the latter-demonstrating robust intention decoding even under articulation errors. These results highlight the feasibility of EEG-based assistive systems capable of supporting real-world, imperfect speech conditions in aphasia patients.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9488\u5bf9\u5931\u8bed\u75c7\u60a3\u8005\u5f00\u53d1\u4e86\u57fa\u4e8eEEG\u7684\u901a\u4fe1\u652f\u6301\u7cfb\u7edf\uff0c\u901a\u8fc7\u5206\u6790\u6b63\u786e\u548c\u9519\u8bef\u53d1\u97f3\u8bd5\u9a8c\u7684\u795e\u7ecf\u6d3b\u52a8\u5dee\u5f02\uff0c\u6784\u5efa\u4e86\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\u6765\u89e3\u7801\u60a3\u8005\u610f\u56fe\uff0c\u5373\u4f7f\u5728\u53d1\u97f3\u9519\u8bef\u65f6\u4e5f\u80fd\u6709\u6548\u8bc6\u522b\u3002", "motivation": "\u5931\u8bed\u75c7\u4e25\u91cd\u5f71\u54cd\u8bed\u8a00\u8868\u8fbe\u80fd\u529b\uff0c\u5bfc\u81f4\u9891\u7e41\u53d1\u97f3\u9519\u8bef\uff0c\u4f46\u76ee\u524d\u9488\u5bf9\u5931\u8bed\u75c7\u60a3\u8005\u7684EEG\u901a\u4fe1\u652f\u6301\u7cfb\u7edf\u7814\u7a76\u8f83\u5c11\u3002\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u80fd\u591f\u9002\u5e94\u5b9e\u9645\u4e0d\u5b8c\u7f8e\u53d1\u97f3\u6761\u4ef6\u7684\u8f85\u52a9\u7cfb\u7edf\u3002", "method": "\u62db\u52df\u4e00\u540d\u8868\u8fbe\u6027\u5931\u8bed\u75c7\u60a3\u8005\u8fdb\u884c\u97e9\u8bed\u81ea\u52a8\u8bed\u97f3\u4efb\u52a1\uff0c\u8bb0\u5f55EEG\u4fe1\u53f7\u5e76\u6839\u636e\u53d1\u97f3\u6b63\u786e\u6027\u6807\u8bb0\u8bd5\u9a8c\u3002\u4f7f\u7528\u9891\u8c31\u5206\u6790\u8bc6\u522b\u795e\u7ecf\u6d3b\u52a8\u6a21\u5f0f\u5dee\u5f02\uff0c\u5f00\u53d1\u57fa\u4e8e\u6700\u5927\u5747\u503c\u5dee\u5f02\u6b63\u5219\u5316\u7684\u8f6f\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\uff0c\u91cd\u70b9\u5173\u6ce8delta\u7279\u5f81\u3002", "result": "\u6b63\u786e\u8bd5\u9a8c\u51c6\u786e\u738758.6%\uff0c\u9519\u8bef\u53d1\u97f3\u8bd5\u9a8c\u51c6\u786e\u738745.5%\uff0c\u540e\u8005\u6bd4\u57fa\u7ebf\u63d0\u9ad8\u8d85\u8fc745%\u3002\u9891\u8c31\u5206\u6790\u663e\u793a\u9519\u8bef\u53d1\u97f3\u8bd5\u9a8c\u5728\u5e7f\u6cdb\u901a\u9053\u4e0a\u8868\u73b0\u51fa\u8fc7\u5ea6\u7684delta\u529f\u7387\uff0c\u524d\u989d\u533a\u57dftheta-alpha\u6d3b\u52a8\u589e\u52a0\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u57fa\u4e8eEEG\u7684\u8f85\u52a9\u7cfb\u7edf\u5728\u5931\u8bed\u75c7\u60a3\u8005\u5b9e\u9645\u4e0d\u5b8c\u7f8e\u53d1\u97f3\u6761\u4ef6\u4e0b\u7684\u53ef\u884c\u6027\uff0c\u80fd\u591f\u7a33\u5065\u5730\u89e3\u7801\u610f\u56fe\uff0c\u5373\u4f7f\u5728\u53d1\u97f3\u9519\u8bef\u65f6\u4e5f\u80fd\u6709\u6548\u5de5\u4f5c\u3002"}}
{"id": "2511.07896", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.07896", "abs": "https://arxiv.org/abs/2511.07896", "authors": ["Dengcan Liu", "Jiahao Li", "Zheren Fu", "Yi Tu", "Jiajun Li", "Zhendong Mao", "Yongdong Zhang"], "title": "SparseRM: A Lightweight Preference Modeling with Sparse Autoencoder", "comment": "15pages,11figures,AAAI-26", "summary": "Reward models (RMs) are a core component in the post-training of large language models (LLMs), serving as proxies for human preference evaluation and guiding model alignment. However, training reliable RMs under limited resources remains challenging due to the reliance on large-scale preference annotations and the high cost of fine-tuning LLMs. To address this, we propose SparseRM, which leverages Sparse Autoencoder (SAE) to extract preference-relevant information encoded in model representations, enabling the construction of a lightweight and interpretable reward model. SparseRM first employs SAE to decompose LLM representations into interpretable directions that capture preference-relevant features. The representations are then projected onto these directions to compute alignment scores, which quantify the strength of each preference feature in the representations. A simple reward head aggregates these scores to predict preference scores. Experiments on three preference modeling tasks show that SparseRM achieves superior performance over most mainstream RMs while using less than 1% of trainable parameters. Moreover, it integrates seamlessly into downstream alignment pipelines, highlighting its potential for efficient alignment.", "AI": {"tldr": "SparseRM\u5229\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\u4ece\u5927\u8bed\u8a00\u6a21\u578b\u8868\u793a\u4e2d\u63d0\u53d6\u504f\u597d\u76f8\u5173\u7279\u5f81\uff0c\u6784\u5efa\u8f7b\u91cf\u7ea7\u3001\u53ef\u89e3\u91ca\u7684\u5956\u52b1\u6a21\u578b\uff0c\u5728\u4ec5\u4f7f\u7528\u4e0d\u52301%\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u4f18\u4e8e\u4e3b\u6d41\u5956\u52b1\u6a21\u578b\u3002", "motivation": "\u89e3\u51b3\u5728\u6709\u9650\u8d44\u6e90\u4e0b\u8bad\u7ec3\u53ef\u9760\u5956\u52b1\u6a21\u578b\u7684\u6311\u6218\uff0c\u56e0\u4e3a\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u5927\u89c4\u6a21\u504f\u597d\u6807\u6ce8\u548c\u6602\u8d35\u7684LLM\u5fae\u8c03\u6210\u672c\u3002", "method": "\u4f7f\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5206\u89e3LLM\u8868\u793a\u4e3a\u53ef\u89e3\u91ca\u7684\u504f\u597d\u76f8\u5173\u7279\u5f81\u65b9\u5411\uff0c\u901a\u8fc7\u6295\u5f71\u8ba1\u7b97\u5bf9\u9f50\u5206\u6570\uff0c\u7136\u540e\u7528\u7b80\u5355\u5956\u52b1\u5934\u805a\u5408\u8fd9\u4e9b\u5206\u6570\u9884\u6d4b\u504f\u597d\u5f97\u5206\u3002", "result": "\u5728\u4e09\u4e2a\u504f\u597d\u5efa\u6a21\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSparseRM\u5728\u4ec5\u4f7f\u7528\u4e0d\u52301%\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\uff0c\u6027\u80fd\u4f18\u4e8e\u5927\u591a\u6570\u4e3b\u6d41\u5956\u52b1\u6a21\u578b\u3002", "conclusion": "SparseRM\u80fd\u591f\u65e0\u7f1d\u96c6\u6210\u5230\u4e0b\u6e38\u5bf9\u9f50\u6d41\u7a0b\u4e2d\uff0c\u5c55\u793a\u4e86\u5176\u5728\u9ad8\u6548\u5bf9\u9f50\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.07649", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07649", "abs": "https://arxiv.org/abs/2511.07649", "authors": ["Pengfei Hu", "Ming Fan", "Xiaoxue Han", "Chang Lu", "Wei Zhang", "Hyun Kang", "Yue Ning", "Dan Lu"], "title": "Adaptive Graph Learning with Transformer for Multi-Reservoir Inflow Prediction", "comment": "ICDM 2025 DMESS Workshop", "summary": "Reservoir inflow prediction is crucial for water resource management, yet existing approaches mainly focus on single-reservoir models that ignore spatial dependencies among interconnected reservoirs. We introduce AdaTrip as an adaptive, time-varying graph learning framework for multi-reservoir inflow forecasting. AdaTrip constructs dynamic graphs where reservoirs are nodes with directed edges reflecting hydrological connections, employing attention mechanisms to automatically identify crucial spatial and temporal dependencies. Evaluation on thirty reservoirs in the Upper Colorado River Basin demonstrates superiority over existing baselines, with improved performance for reservoirs with limited records through parameter sharing. Additionally, AdaTrip provides interpretable attention maps at edge and time-step levels, offering insights into hydrological controls to support operational decision-making. Our code is available at https://github.com/humphreyhuu/AdaTrip.", "AI": {"tldr": "AdaTrip\u662f\u4e00\u4e2a\u81ea\u9002\u5e94\u65f6\u53d8\u56fe\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u6c34\u5e93\u5165\u6d41\u9884\u6d4b\uff0c\u901a\u8fc7\u52a8\u6001\u56fe\u7ed3\u6784\u548c\u6ce8\u610f\u529b\u673a\u5236\u6355\u6349\u6c34\u5e93\u95f4\u7684\u65f6\u7a7a\u4f9d\u8d56\u5173\u7cfb\uff0c\u5728\u79d1\u7f57\u62c9\u591a\u6cb3\u4e0a\u6e38\u6d41\u57df30\u4e2a\u6c34\u5e93\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6c34\u5e93\u5165\u6d41\u9884\u6d4b\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5355\u4e00\u6c34\u5e93\u6a21\u578b\uff0c\u5ffd\u7565\u4e86\u76f8\u4e92\u8fde\u63a5\u6c34\u5e93\u4e4b\u95f4\u7684\u7a7a\u95f4\u4f9d\u8d56\u6027\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6355\u6349\u6c34\u5e93\u95f4\u65f6\u7a7a\u4f9d\u8d56\u5173\u7cfb\u7684\u591a\u6c34\u5e93\u9884\u6d4b\u6846\u67b6\u3002", "method": "AdaTrip\u6784\u5efa\u52a8\u6001\u56fe\u7ed3\u6784\uff0c\u5c06\u6c34\u5e93\u4f5c\u4e3a\u8282\u70b9\uff0c\u6709\u5411\u8fb9\u53cd\u6620\u6c34\u6587\u8fde\u63a5\uff0c\u4f7f\u7528\u6ce8\u610f\u529b\u673a\u5236\u81ea\u52a8\u8bc6\u522b\u5173\u952e\u7684\u65f6\u7a7a\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u53c2\u6570\u5171\u4eab\u63d0\u5347\u6570\u636e\u6709\u9650\u6c34\u5e93\u7684\u9884\u6d4b\u6027\u80fd\u3002", "result": "\u5728\u79d1\u7f57\u62c9\u591a\u6cb3\u4e0a\u6e38\u6d41\u57df30\u4e2a\u6c34\u5e93\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cAdaTrip\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5bf9\u8bb0\u5f55\u6709\u9650\u7684\u6c34\u5e93\u901a\u8fc7\u53c2\u6570\u5171\u4eab\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u6ce8\u610f\u529b\u56fe\u8c31\u3002", "conclusion": "AdaTrip\u4e3a\u591a\u6c34\u5e93\u5165\u6d41\u9884\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u81ea\u9002\u5e94\u56fe\u5b66\u4e60\u6846\u67b6\uff0c\u4e0d\u4ec5\u80fd\u51c6\u786e\u9884\u6d4b\uff0c\u8fd8\u80fd\u63d0\u4f9b\u5bf9\u6c34\u6587\u63a7\u5236\u56e0\u7d20\u7684\u53ef\u89e3\u91ca\u6d1e\u5bdf\uff0c\u652f\u6301\u8fd0\u8425\u51b3\u7b56\u3002"}}
{"id": "2511.07657", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07657", "abs": "https://arxiv.org/abs/2511.07657", "authors": ["Veera V S Bhargav Nunna", "Shinae Kang", "Zheyuan Zhou", "Virginia Wang", "Sucharitha Boinapally", "Michael Foley"], "title": "CAE: Character-Level Autoencoder for Non-Semantic Relational Data Grouping", "comment": null, "summary": "Enterprise relational databases increasingly contain vast amounts of non-semantic data - IP addresses, product identifiers, encoded keys, and timestamps - that challenge traditional semantic analysis. This paper introduces a novel Character-Level Autoencoder (CAE) approach that automatically identifies and groups semantically identical columns in non-semantic relational datasets by detecting column similarities based on data patterns and structures. Unlike conventional Natural Language Processing (NLP) models that struggle with limitations in semantic interpretability and out-of-vocabulary tokens, our approach operates at the character level with fixed dictionary constraints, enabling scalable processing of large-scale data lakes and warehouses. The CAE architecture encodes text representations of non-semantic relational table columns and extracts high-dimensional feature embeddings for data grouping. By maintaining a fixed dictionary size, our method significantly reduces both memory requirements and training time, enabling efficient processing of large-scale industrial data environments. Experimental evaluation demonstrates substantial performance gains: our CAE approach achieved 80.95% accuracy in top 5 column matching tasks across relational datasets, substantially outperforming traditional NLP approaches such as Bag of Words (47.62%). These results demonstrate its effectiveness for identifying and clustering identical columns in relational datasets. This work bridges the gap between theoretical advances in character-level neural architectures and practical enterprise data management challenges, providing an automated solution for schema understanding and data profiling of non-semantic industrial datasets at scale.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5b57\u7b26\u7ea7\u81ea\u7f16\u7801\u5668(CAE)\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u8bc6\u522b\u548c\u5206\u7ec4\u975e\u8bed\u4e49\u5173\u7cfb\u6570\u636e\u96c6\u4e2d\u7684\u8bed\u4e49\u76f8\u540c\u5217\uff0c\u901a\u8fc7\u68c0\u6d4b\u6570\u636e\u6a21\u5f0f\u548c\u7ed3\u6784\u7684\u5217\u76f8\u4f3c\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edfNLP\u65b9\u6cd5\u3002", "motivation": "\u4f01\u4e1a\u5173\u7cfb\u6570\u636e\u5e93\u5305\u542b\u5927\u91cf\u975e\u8bed\u4e49\u6570\u636e\uff08IP\u5730\u5740\u3001\u4ea7\u54c1\u6807\u8bc6\u7b26\u3001\u7f16\u7801\u952e\u548c\u65f6\u95f4\u6233\uff09\uff0c\u8fd9\u4e9b\u6570\u636e\u6311\u6218\u4e86\u4f20\u7edf\u7684\u8bed\u4e49\u5206\u6790\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u5904\u7406\u975e\u8bed\u4e49\u5173\u7cfb\u6570\u636e\u96c6\u7684\u5217\u76f8\u4f3c\u6027\u68c0\u6d4b\u3002", "method": "\u91c7\u7528\u5b57\u7b26\u7ea7\u81ea\u7f16\u7801\u5668(CAE)\u67b6\u6784\uff0c\u5728\u5b57\u7b26\u7ea7\u522b\u64cd\u4f5c\u5e76\u4fdd\u6301\u56fa\u5b9a\u5b57\u5178\u7ea6\u675f\uff0c\u7f16\u7801\u975e\u8bed\u4e49\u5173\u7cfb\u8868\u5217\u7684\u6587\u672c\u8868\u793a\uff0c\u63d0\u53d6\u9ad8\u7ef4\u7279\u5f81\u5d4c\u5165\u8fdb\u884c\u6570\u636e\u5206\u7ec4\uff0c\u663e\u8457\u964d\u4f4e\u5185\u5b58\u9700\u6c42\u548c\u8bad\u7ec3\u65f6\u95f4\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0cCAE\u65b9\u6cd5\u5728\u5173\u7cfb\u6570\u636e\u96c6\u7684\u524d5\u5217\u5339\u914d\u4efb\u52a1\u4e2d\u8fbe\u523080.95%\u7684\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edfNLP\u65b9\u6cd5\u5982\u8bcd\u888b\u6a21\u578b(47.62%)\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5f25\u5408\u4e86\u5b57\u7b26\u7ea7\u795e\u7ecf\u67b6\u6784\u7684\u7406\u8bba\u8fdb\u5c55\u4e0e\u4f01\u4e1a\u6570\u636e\u7ba1\u7406\u5b9e\u8df5\u6311\u6218\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u975e\u8bed\u4e49\u5de5\u4e1a\u6570\u636e\u96c6\u7684\u5927\u89c4\u6a21\u6a21\u5f0f\u7406\u89e3\u548c\u6570\u636e\u5256\u6790\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.07912", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07912", "abs": "https://arxiv.org/abs/2511.07912", "authors": ["Jun-Young Kim", "Young-Seok Kweon", "Gi-Hwan Shin", "Seong-Whan Lee"], "title": "Neurophysiological Characteristics of Adaptive Reasoning for Creative Problem-Solving Strategy", "comment": "4 pages, 4 figures, 1 table,", "summary": "Adaptive reasoning enables humans to flexibly adjust inference strategies when environmental rules or contexts change, yet its underlying neural dynamics remain unclear. This study investigated the neurophysiological mechanisms of adaptive reasoning using a card-sorting paradigm combined with electroencephalography and compared human performance with that of a multimodal large language model. Stimulus- and feedback-locked analyses revealed coordinated delta-theta-alpha dynamics: early delta-theta activity reflected exploratory monitoring and rule inference, whereas occipital alpha engagement indicated confirmatory stabilization of attention after successful rule identification. In contrast, the multimodal large language model exhibited only short-term feedback-driven adjustments without hierarchical rule abstraction or genuine adaptive reasoning. These findings identify the neural signatures of human adaptive reasoning and highlight the need for brain-inspired artificial intelligence that incorporates oscillatory feedback coordination for true context-sensitive adaptation.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u8111\u7535\u56fe\u548c\u5361\u7247\u5206\u7c7b\u4efb\u52a1\u63a2\u7d22\u4eba\u7c7b\u9002\u5e94\u6027\u63a8\u7406\u7684\u795e\u7ecf\u673a\u5236\uff0c\u53d1\u73b0\u4eba\u7c7b\u5728\u89c4\u5219\u53d8\u5316\u65f6\u8868\u73b0\u51fa\u534f\u8c03\u7684delta-theta-alpha\u632f\u8361\u52a8\u6001\uff0c\u800c\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4ec5\u80fd\u8fdb\u884c\u77ed\u671f\u53cd\u9988\u9a71\u52a8\u8c03\u6574\uff0c\u7f3a\u4e4f\u771f\u6b63\u7684\u9002\u5e94\u6027\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u9002\u5e94\u6027\u63a8\u7406\u4f7f\u4eba\u7c7b\u80fd\u591f\u5728\u73af\u5883\u89c4\u5219\u6216\u60c5\u5883\u53d8\u5316\u65f6\u7075\u6d3b\u8c03\u6574\u63a8\u7406\u7b56\u7565\uff0c\u4f46\u5176\u6f5c\u5728\u7684\u795e\u7ecf\u52a8\u529b\u5b66\u673a\u5236\u5c1a\u4e0d\u6e05\u695a\u3002\u672c\u7814\u7a76\u65e8\u5728\u63ed\u793a\u9002\u5e94\u6027\u63a8\u7406\u7684\u795e\u7ecf\u751f\u7406\u673a\u5236\uff0c\u5e76\u4e0e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u8fdb\u884c\u6bd4\u8f83\u3002", "method": "\u4f7f\u7528\u5361\u7247\u5206\u7c7b\u8303\u5f0f\u7ed3\u5408\u8111\u7535\u56fe\u6280\u672f\uff0c\u5206\u6790\u523a\u6fc0\u9501\u5b9a\u548c\u53cd\u9988\u9501\u5b9a\u7684\u795e\u7ecf\u6d3b\u52a8\uff0c\u5e76\u4e0e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u8868\u73b0\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u53d1\u73b0\u4eba\u7c7b\u5728\u9002\u5e94\u6027\u63a8\u7406\u4e2d\u8868\u73b0\u51fa\u534f\u8c03\u7684delta-theta-alpha\u52a8\u6001\uff1a\u65e9\u671fdelta-theta\u6d3b\u52a8\u53cd\u6620\u63a2\u7d22\u6027\u76d1\u6d4b\u548c\u89c4\u5219\u63a8\u65ad\uff0c\u800c\u6795\u53f6alpha\u53c2\u4e0e\u8868\u660e\u6210\u529f\u89c4\u5219\u8bc6\u522b\u540e\u7684\u6ce8\u610f\u529b\u786e\u8ba4\u7a33\u5b9a\u5316\u3002\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4ec5\u8868\u73b0\u51fa\u77ed\u671f\u53cd\u9988\u9a71\u52a8\u8c03\u6574\uff0c\u7f3a\u4e4f\u5c42\u6b21\u89c4\u5219\u62bd\u8c61\u6216\u771f\u6b63\u7684\u9002\u5e94\u6027\u63a8\u7406\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u8bc6\u522b\u4e86\u4eba\u7c7b\u9002\u5e94\u6027\u63a8\u7406\u7684\u795e\u7ecf\u7279\u5f81\uff0c\u5e76\u5f3a\u8c03\u4e86\u9700\u8981\u5f00\u53d1\u5305\u542b\u632f\u8361\u53cd\u9988\u534f\u8c03\u7684\u8111\u542f\u53d1\u4eba\u5de5\u667a\u80fd\uff0c\u4ee5\u5b9e\u73b0\u771f\u6b63\u7684\u4e0a\u4e0b\u6587\u654f\u611f\u9002\u5e94\u3002"}}
{"id": "2511.07700", "categories": ["cs.LG", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.07700", "abs": "https://arxiv.org/abs/2511.07700", "authors": ["Brandon Dominique", "Prudence Lam", "Nicholas Kurtansky", "Jochen Weber", "Kivanc Kose", "Veronica Rotemberg", "Jennifer Dy"], "title": "On the Role of Calibration in Benchmarking Algorithmic Fairness for Skin Cancer Detection", "comment": "19 pages, 4 figures. Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) https://melba-journal.org/2025:027", "summary": "Artificial Intelligence (AI) models have demonstrated expert-level performance in melanoma detection, yet their clinical adoption is hindered by performance disparities across demographic subgroups such as gender, race, and age. Previous efforts to benchmark the performance of AI models have primarily focused on assessing model performance using group fairness metrics that rely on the Area Under the Receiver Operating Characteristic curve (AUROC), which does not provide insights into a model's ability to provide accurate estimates. In line with clinical assessments, this paper addresses this gap by incorporating calibration as a complementary benchmarking metric to AUROC-based fairness metrics. Calibration evaluates the alignment between predicted probabilities and observed event rates, offering deeper insights into subgroup biases. We assess the performance of the leading skin cancer detection algorithm of the ISIC 2020 Challenge on the ISIC 2020 Challenge dataset and the PROVE-AI dataset, and compare it with the second and third place models, focusing on subgroups defined by sex, race (Fitzpatrick Skin Tone), and age. Our findings reveal that while existing models enhance discriminative accuracy, they often over-diagnose risk and exhibit calibration issues when applied to new datasets. This study underscores the necessity for comprehensive model auditing strategies and extensive metadata collection to achieve equitable AI-driven healthcare solutions. All code is publicly available at https://github.com/bdominique/testing_strong_calibration.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6307\u51faAI\u6a21\u578b\u5728\u9ed1\u8272\u7d20\u7624\u68c0\u6d4b\u4e2d\u5b58\u5728\u8de8\u4eba\u53e3\u4e9a\u7ec4\uff08\u6027\u522b\u3001\u79cd\u65cf\u3001\u5e74\u9f84\uff09\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u63d0\u51fa\u5c06\u6821\u51c6\u4f5c\u4e3aAUROC\u516c\u5e73\u6027\u6307\u6807\u7684\u8865\u5145\u57fa\u51c6\u6307\u6807\uff0c\u8bc4\u4f30\u4e86ISIC 2020\u6311\u6218\u8d5b\u9886\u5148\u6a21\u578b\u5728\u65b0\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u5b58\u5728\u8fc7\u5ea6\u8bca\u65ad\u98ce\u9669\u548c\u6821\u51c6\u95ee\u9898\u3002", "motivation": "AI\u6a21\u578b\u5728\u9ed1\u8272\u7d20\u7624\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u4e13\u5bb6\u7ea7\u6027\u80fd\uff0c\u4f46\u4e34\u5e8a\u91c7\u7528\u53d7\u5230\u8de8\u4eba\u53e3\u4e9a\u7ec4\u6027\u80fd\u5dee\u5f02\u7684\u963b\u788d\u3002\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u4f9d\u8d56AUROC\u7fa4\u4f53\u516c\u5e73\u6027\u6307\u6807\uff0c\u65e0\u6cd5\u63d0\u4f9b\u6a21\u578b\u51c6\u786e\u4f30\u8ba1\u80fd\u529b\u7684\u4fe1\u606f\u3002", "method": "\u5c06\u6821\u51c6\u4f5c\u4e3aAUROC\u516c\u5e73\u6027\u6307\u6807\u7684\u8865\u5145\u57fa\u51c6\u6307\u6807\uff0c\u8bc4\u4f30ISIC 2020\u6311\u6218\u8d5b\u9886\u5148\u6a21\u578b\u5728ISIC 2020\u6311\u6218\u8d5b\u6570\u636e\u96c6\u548cPROVE-AI\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u91cd\u70b9\u5173\u6ce8\u6027\u522b\u3001\u79cd\u65cf\uff08Fitzpatrick\u76ae\u80a4\u7c7b\u578b\uff09\u548c\u5e74\u9f84\u5b9a\u4e49\u7684\u4e9a\u7ec4\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u63d0\u9ad8\u4e86\u5224\u522b\u51c6\u786e\u6027\uff0c\u4f46\u5728\u5e94\u7528\u4e8e\u65b0\u6570\u636e\u96c6\u65f6\u7ecf\u5e38\u8fc7\u5ea6\u8bca\u65ad\u98ce\u9669\u5e76\u8868\u73b0\u51fa\u6821\u51c6\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5b9e\u73b0\u516c\u5e73AI\u9a71\u52a8\u533b\u7597\u89e3\u51b3\u65b9\u6848\u9700\u8981\u5168\u9762\u7684\u6a21\u578b\u5ba1\u8ba1\u7b56\u7565\u548c\u5e7f\u6cdb\u7684\u5143\u6570\u636e\u6536\u96c6\u3002"}}
{"id": "2511.07936", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07936", "abs": "https://arxiv.org/abs/2511.07936", "authors": ["Ji-Ha Park", "Heon-Gyu Kwak", "Gi-Hwan Shin", "Yoo-In Jeon", "Sun-Min Park", "Ji-Yeon Hwang", "Seong-Whan Lee"], "title": "Toward Practical BCI: A Real-time Wireless Imagined Speech EEG Decoding System", "comment": "4 pages, 2 figures, 1 table, Name of Conference: International Conference on Brain-Computer Interface", "summary": "Brain-computer interface (BCI) research, while promising, has largely been confined to static and fixed environments, limiting real-world applicability. To move towards practical BCI, we introduce a real-time wireless imagined speech electroencephalogram (EEG) decoding system designed for flexibility and everyday use. Our framework focuses on practicality, demonstrating extensibility beyond wired EEG devices to portable, wireless hardware. A user identification module recognizes the operator and provides a personalized, user-specific service. To achieve seamless, real-time operation, we utilize the lab streaming layer to manage the continuous streaming of live EEG signals to the personalized decoder. This end-to-end pipeline enables a functional real-time application capable of classifying user commands from imagined speech EEG signals, achieving an overall 4-class accuracy of 62.00 % on a wired device and 46.67 % on a portable wireless headset. This paper demonstrates a significant step towards truly practical and accessible BCI technology, establishing a clear direction for future research in robust, practical, and personalized neural interfaces.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5b9e\u65f6\u65e0\u7ebf\u60f3\u8c61\u8bed\u97f3\u8111\u7535\u56fe\u89e3\u7801\u7cfb\u7edf\uff0c\u65e8\u5728\u5b9e\u73b0\u7075\u6d3b\u548c\u65e5\u5e38\u4f7f\u7528\u7684\u8111\u673a\u63a5\u53e3\u6280\u672f\uff0c\u5728\u6709\u9650\u73af\u5883\u4e0b\u53d6\u5f97\u4e864\u7c7b\u5206\u7c7b62.00%\u548c46.67%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u4f20\u7edf\u8111\u673a\u63a5\u53e3\u7814\u7a76\u4e3b\u8981\u5c40\u9650\u4e8e\u9759\u6001\u548c\u56fa\u5b9a\u73af\u5883\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u4e3a\u4e86\u63a8\u8fdb\u5b9e\u7528\u8111\u673a\u63a5\u53e3\u6280\u672f\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5728\u65e5\u5e38\u73af\u5883\u4e2d\u4f7f\u7528\u7684\u7075\u6d3b\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u5b9e\u65f6\u65e0\u7ebf\u60f3\u8c61\u8bed\u97f3\u8111\u7535\u56fe\u89e3\u7801\u7cfb\u7edf\uff0c\u4f7f\u7528\u5b9e\u9a8c\u5ba4\u6d41\u5c42\u7ba1\u7406\u8fde\u7eed\u5b9e\u65f6\u8111\u7535\u4fe1\u53f7\u6d41\uff0c\u96c6\u6210\u7528\u6237\u8bc6\u522b\u6a21\u5757\u63d0\u4f9b\u4e2a\u6027\u5316\u670d\u52a1\uff0c\u5e76\u6269\u5c55\u5230\u4fbf\u643a\u65e0\u7ebf\u786c\u4ef6\u8bbe\u5907\u3002", "result": "\u8be5\u7cfb\u7edf\u5728\u6709\u7ebf\u8bbe\u5907\u4e0a\u5b9e\u73b0\u4e864\u7c7b\u5206\u7c7b62.00%\u7684\u51c6\u786e\u7387\uff0c\u5728\u4fbf\u643a\u65e0\u7ebf\u5934\u6234\u8bbe\u5907\u4e0a\u8fbe\u523046.67%\u7684\u51c6\u786e\u7387\uff0c\u80fd\u591f\u5b9e\u65f6\u5206\u7c7b\u7528\u6237\u547d\u4ee4\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u5411\u771f\u6b63\u5b9e\u7528\u548c\u53ef\u8bbf\u95ee\u7684\u8111\u673a\u63a5\u53e3\u6280\u672f\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\uff0c\u4e3a\u672a\u6765\u7a33\u5065\u3001\u5b9e\u7528\u548c\u4e2a\u6027\u5316\u795e\u7ecf\u63a5\u53e3\u7814\u7a76\u786e\u7acb\u4e86\u660e\u786e\u65b9\u5411\u3002"}}
{"id": "2511.07943", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.07943", "abs": "https://arxiv.org/abs/2511.07943", "authors": ["Jun Xu", "Xinkai Du", "Yu Ao", "Peilong Zhao", "Yang Li", "Ling Zhong", "Lin Yuan", "Zhongpu Bo", "Xiaorui Wang", "Mengshu Sun", "Zhengke Gui", "Dalong Zhang", "Zhaoyang Wang", "Qiwei Wang", "Yangyang Hou", "Zhiying Yin", "Haofen Wang", "Huajun Chen", "Lei Liang", "Jun Zhou"], "title": "Thinker: Training LLMs in Hierarchical Thinking for Deep Search via Multi-Turn Interaction", "comment": "Accepted to AAAI 2026. Extended version with full Appendix", "summary": "Efficient retrieval of external knowledge bases and web pages is crucial for enhancing the reasoning abilities of LLMs. Previous works on training LLMs to leverage external retrievers for solving complex problems have predominantly employed end-to-end reinforcement learning. However, these approaches neglect supervision over the reasoning process, making it difficult to guarantee logical coherence and rigor. To address these limitations, we propose Thinker, a hierarchical thinking model for deep search through multi-turn interaction, making the reasoning process supervisable and verifiable. It decomposes complex problems into independently solvable sub-problems, each dually represented in both natural language and an equivalent logical function to support knowledge base and web searches. Concurrently, dependencies between sub-problems are passed as parameters via these logical functions, enhancing the logical coherence of the problem-solving process. To avoid unnecessary external searches, we perform knowledge boundary determination to check if a sub-problem is within the LLM's intrinsic knowledge, allowing it to answer directly. Experimental results indicate that with as few as several hundred training samples, the performance of Thinker is competitive with established baselines. Furthermore, when scaled to the full training set, Thinker significantly outperforms these methods across various datasets and model sizes. The source code is available at https://github.com/OpenSPG/KAG-Thinker.", "AI": {"tldr": "\u63d0\u51fa\u4e86Thinker\u6a21\u578b\uff0c\u901a\u8fc7\u591a\u8f6e\u4ea4\u4e92\u8fdb\u884c\u6df1\u5ea6\u641c\u7d22\uff0c\u5c06\u590d\u6742\u95ee\u9898\u5206\u89e3\u4e3a\u53ef\u72ec\u7acb\u89e3\u51b3\u7684\u5b50\u95ee\u9898\uff0c\u5e76\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u548c\u903b\u8f91\u51fd\u6570\u53cc\u91cd\u8868\u793a\u6765\u652f\u6301\u77e5\u8bc6\u5e93\u548c\u7f51\u9875\u641c\u7d22\uff0c\u540c\u65f6\u901a\u8fc7\u903b\u8f91\u51fd\u6570\u4f20\u9012\u5b50\u95ee\u9898\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u4ee5\u589e\u5f3a\u903b\u8f91\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f7f\u7528\u7aef\u5230\u7aef\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3LLMs\u5229\u7528\u5916\u90e8\u68c0\u7d22\u5668\u89e3\u51b3\u590d\u6742\u95ee\u9898\uff0c\u4f46\u5ffd\u89c6\u4e86\u63a8\u7406\u8fc7\u7a0b\u7684\u76d1\u7763\uff0c\u96be\u4ee5\u4fdd\u8bc1\u903b\u8f91\u4e00\u81f4\u6027\u548c\u4e25\u8c28\u6027\u3002", "method": "\u63d0\u51faThinker\u5206\u5c42\u601d\u7ef4\u6a21\u578b\uff0c\u5c06\u590d\u6742\u95ee\u9898\u5206\u89e3\u4e3a\u5b50\u95ee\u9898\uff0c\u6bcf\u4e2a\u5b50\u95ee\u9898\u7528\u81ea\u7136\u8bed\u8a00\u548c\u903b\u8f91\u51fd\u6570\u53cc\u91cd\u8868\u793a\uff0c\u901a\u8fc7\u903b\u8f91\u51fd\u6570\u4f20\u9012\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u8fdb\u884c\u77e5\u8bc6\u8fb9\u754c\u786e\u5b9a\u4ee5\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u5916\u90e8\u641c\u7d22\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4ec5\u7528\u6570\u767e\u4e2a\u8bad\u7ec3\u6837\u672c\uff0cThinker\u7684\u6027\u80fd\u5c31\u4e0e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u76f8\u5f53\uff1b\u5f53\u6269\u5c55\u5230\u5b8c\u6574\u8bad\u7ec3\u96c6\u65f6\uff0cThinker\u5728\u5404\u79cd\u6570\u636e\u96c6\u548c\u6a21\u578b\u5927\u5c0f\u4e0a\u663e\u8457\u4f18\u4e8e\u8fd9\u4e9b\u65b9\u6cd5\u3002", "conclusion": "Thinker\u901a\u8fc7\u5206\u5c42\u601d\u7ef4\u548c\u591a\u8f6e\u4ea4\u4e92\u4f7f\u63a8\u7406\u8fc7\u7a0b\u53ef\u76d1\u7763\u548c\u53ef\u9a8c\u8bc1\uff0c\u6709\u6548\u63d0\u5347\u4e86LLMs\u5229\u7528\u5916\u90e8\u77e5\u8bc6\u89e3\u51b3\u590d\u6742\u95ee\u9898\u7684\u80fd\u529b\u3002"}}
{"id": "2511.07724", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07724", "abs": "https://arxiv.org/abs/2511.07724", "authors": ["Piotr Szwed", "Pawe\u0142 Skrzynski", "Jaros\u0142aw W\u0105s"], "title": "A Ranking-Based Optimization Algorithm for the Vehicle Relocation Problem in Car Sharing Services", "comment": null, "summary": "The paper addresses the Vehicle Relocation Problem in free-floating car-sharing services by presenting a solution focused on strategies for repositioning vehicles and transferring personnel with the use of scooters. Our method begins by dividing the service area into zones that group regions with similar temporal patterns of vehicle presence and service demand, allowing the application of discrete optimization methods. In the next stage, we propose a fast ranking-based algorithm that makes its decisions on the basis of the number of cars available in each zone, the projected probability density of demand, and estimated trip durations. The experiments were carried out on the basis of real-world data originating from a major car-sharing service operator in Poland. The results of this algorithm are evaluated against scenarios without optimization that constitute a baseline and compared with the results of an exact algorithm to solve the Mixed Integer Programming (MIP) model. As performance metrics, the total travel time was used. Under identical conditions (number of vehicles, staff, and demand distribution), the average improvements with respect to the baseline of our algorithm and MIP solver were equal to 8.44\\% and 19.6\\% correspondingly. However, it should be noted that the MIP model also mimicked decisions on trip selection, which are excluded by current services business rules. The analysis of results suggests that, depending on the size of the workforce, the application of the proposed solution allows for improving performance metrics by roughly 3%-10%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u81ea\u7531\u6d6e\u52a8\u6c7d\u8f66\u5171\u4eab\u670d\u52a1\u4e2d\u8f66\u8f86\u91cd\u65b0\u5b9a\u4f4d\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u4f7f\u7528\u6ed1\u677f\u8f66\u91cd\u65b0\u5b9a\u4f4d\u8f66\u8f86\u548c\u8f6c\u79fb\u4eba\u5458\u3002\u8be5\u65b9\u6cd5\u5c06\u670d\u52a1\u533a\u57df\u5212\u5206\u4e3a\u5177\u6709\u76f8\u4f3c\u8f66\u8f86\u5b58\u5728\u548c\u670d\u52a1\u9700\u6c42\u65f6\u95f4\u6a21\u5f0f\u7684\u533a\u57df\uff0c\u5e76\u91c7\u7528\u57fa\u4e8e\u6392\u540d\u7684\u5feb\u901f\u7b97\u6cd5\u8fdb\u884c\u51b3\u7b56\u3002", "motivation": "\u89e3\u51b3\u81ea\u7531\u6d6e\u52a8\u6c7d\u8f66\u5171\u4eab\u670d\u52a1\u4e2d\u7684\u8f66\u8f86\u91cd\u65b0\u5b9a\u4f4d\u95ee\u9898\uff0c\u63d0\u9ad8\u670d\u52a1\u6548\u7387\uff0c\u51cf\u5c11\u603b\u65c5\u884c\u65f6\u95f4\u3002", "method": "1. \u5c06\u670d\u52a1\u533a\u57df\u5212\u5206\u4e3a\u5177\u6709\u76f8\u4f3c\u65f6\u95f4\u6a21\u5f0f\u7684\u533a\u57df\uff1b2. \u63d0\u51fa\u57fa\u4e8e\u6392\u540d\u7684\u5feb\u901f\u7b97\u6cd5\uff0c\u8003\u8651\u6bcf\u4e2a\u533a\u57df\u7684\u53ef\u7528\u8f66\u8f86\u6570\u91cf\u3001\u9700\u6c42\u6982\u7387\u5bc6\u5ea6\u548c\u9884\u8ba1\u884c\u7a0b\u6301\u7eed\u65f6\u95f4\uff1b3. \u4f7f\u7528\u771f\u5b9e\u4e16\u754c\u6570\u636e\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u4e0e\u65e0\u4f18\u5316\u57fa\u7ebf\u76f8\u6bd4\uff0c\u63d0\u51fa\u7684\u7b97\u6cd5\u5e73\u5747\u6539\u8fdb8.44%\uff0cMIP\u6c42\u89e3\u5668\u6539\u8fdb19.6%\u3002\u6839\u636e\u5de5\u4f5c\u4eba\u5458\u89c4\u6a21\uff0c\u6027\u80fd\u6307\u6807\u53ef\u63d0\u9ad8\u7ea63%-10%\u3002", "conclusion": "\u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\u80fd\u6709\u6548\u6539\u5584\u8f66\u8f86\u91cd\u65b0\u5b9a\u4f4d\u6027\u80fd\uff0c\u4f46MIP\u6a21\u578b\u5305\u542b\u5f53\u524d\u4e1a\u52a1\u89c4\u5219\u6392\u9664\u7684\u884c\u7a0b\u9009\u62e9\u51b3\u7b56\uff0c\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8003\u8651\u8fd9\u4e00\u5dee\u5f02\u3002"}}
{"id": "2511.07730", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.07730", "abs": "https://arxiv.org/abs/2511.07730", "authors": ["Bill Chunyuan Zheng", "Vivek Myers", "Benjamin Eysenbach", "Sergey Levine"], "title": "Multistep Quasimetric Learning for Scalable Goal-conditioned Reinforcement Learning", "comment": null, "summary": "Learning how to reach goals in an environment is a longstanding challenge in AI, yet reasoning over long horizons remains a challenge for modern methods. The key question is how to estimate the temporal distance between pairs of observations. While temporal difference methods leverage local updates to provide optimality guarantees, they often perform worse than Monte Carlo methods that perform global updates (e.g., with multi-step returns), which lack such guarantees. We show how these approaches can be integrated into a practical GCRL method that fits a quasimetric distance using a multistep Monte-Carlo return. We show our method outperforms existing GCRL methods on long-horizon simulated tasks with up to 4000 steps, even with visual observations. We also demonstrate that our method can enable stitching in the real-world robotic manipulation domain (Bridge setup). Our approach is the first end-to-end GCRL method that enables multistep stitching in this real-world manipulation domain from an unlabeled offline dataset of visual observations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5c40\u90e8\u66f4\u65b0\u548c\u5168\u5c40\u66f4\u65b0\u7684\u76ee\u6807\u6761\u4ef6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u6b65\u8499\u7279\u5361\u6d1b\u56de\u62a5\u62df\u5408\u51c6\u5ea6\u91cf\u8ddd\u79bb\uff0c\u5728\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5728\u771f\u5b9e\u673a\u5668\u4eba\u64cd\u4f5c\u9886\u57df\u5b9e\u73b0\u591a\u6b65\u62fc\u63a5\u3002", "motivation": "\u89e3\u51b3AI\u4e2d\u957f\u65f6\u7a0b\u76ee\u6807\u8fbe\u6210\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5982\u4f55\u51c6\u786e\u4f30\u8ba1\u89c2\u6d4b\u5bf9\u4e4b\u95f4\u7684\u65f6\u95f4\u8ddd\u79bb\uff0c\u6574\u5408\u5177\u6709\u6700\u4f18\u6027\u4fdd\u8bc1\u7684\u5c40\u90e8\u66f4\u65b0\u65b9\u6cd5\u548c\u6027\u80fd\u66f4\u597d\u7684\u5168\u5c40\u66f4\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5b9e\u7528\u7684GCRL\u65b9\u6cd5\uff0c\u4f7f\u7528\u591a\u6b65\u8499\u7279\u5361\u6d1b\u56de\u62a5\u62df\u5408\u51c6\u5ea6\u91cf\u8ddd\u79bb\uff0c\u5c06\u65f6\u95f4\u5dee\u5206\u65b9\u6cd5\u548c\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u7684\u4f18\u52bf\u7ed3\u5408\u8d77\u6765\u3002", "result": "\u5728\u957f\u8fbe4000\u6b65\u7684\u957f\u65f6\u7a0b\u6a21\u62df\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709GCRL\u65b9\u6cd5\uff0c\u5373\u4f7f\u4f7f\u7528\u89c6\u89c9\u89c2\u6d4b\uff1b\u5728\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u64cd\u4f5c\u9886\u57df\uff08Bridge\u8bbe\u7f6e\uff09\u5b9e\u73b0\u4e86\u591a\u6b65\u62fc\u63a5\uff0c\u662f\u9996\u4e2a\u5728\u8be5\u9886\u57df\u4ece\u65e0\u6807\u7b7e\u79bb\u7ebf\u89c6\u89c9\u89c2\u6d4b\u6570\u636e\u96c6\u5b9e\u73b0\u7aef\u5230\u7aef\u591a\u6b65\u62fc\u63a5\u7684GCRL\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u6574\u5408\u4e86\u5c40\u90e8\u548c\u5168\u5c40\u66f4\u65b0\u7684\u4f18\u52bf\uff0c\u5728\u957f\u65f6\u7a0b\u4efb\u52a1\u548c\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u8868\u73b0\u51fa\u5353\u8d8a\u6027\u80fd\uff0c\u4e3aGCRL\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.07980", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07980", "abs": "https://arxiv.org/abs/2511.07980", "authors": ["Zheng Chenghong", "Zongyin Deng", "Liu Cheng", "Xiong Simin", "Di Deshi", "Li Guanyao"], "title": "Capturing Complex Spatial-Temporal Dependencies in Traffic Forecasting: A Self-Attention Approach", "comment": "5 pages", "summary": "We study the problem of traffic forecasting, aiming to predict the inflow and outflow of a region in the subsequent time slot. The problem is complex due to the intricate spatial and temporal interdependence among regions. Prior works study the spatial and temporal dependency in a decouple manner, failing to capture their joint effect. In this work, we propose ST-SAM, a novel and efficient Spatial-Temporal Self-Attention Model for traffic forecasting. ST-SAM uses a region embedding layer to learn time-specific embedding from traffic data for regions. Then, it employs a spatial-temporal dependency learning module based on self-attention mechanism to capture the joint spatial-temporal dependency for both nearby and faraway regions. ST-SAM entirely relies on self-attention to capture both local and global spatial-temporal correlations, which make it effective and efficient. Extensive experiments on two real world datasets show that ST-SAM is substantially more accurate and efficient than the state-of-the-art approaches (with an average improvement of up to 15% on RMSE, 17% on MAPE, and 32 times on training time in our experiments).", "AI": {"tldr": "\u63d0\u51faST-SAM\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u673a\u5236\u8054\u5408\u5b66\u4e60\u65f6\u7a7a\u4f9d\u8d56\u5173\u7cfb\uff0c\u7528\u4e8e\u4ea4\u901a\u6d41\u91cf\u9884\u6d4b\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u90fd\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c06\u7a7a\u95f4\u548c\u65f6\u95f4\u4f9d\u8d56\u6027\u5206\u5f00\u7814\u7a76\uff0c\u65e0\u6cd5\u6355\u6349\u5b83\u4eec\u7684\u8054\u5408\u6548\u5e94\uff0c\u5bfc\u81f4\u4ea4\u901a\u9884\u6d4b\u6548\u679c\u53d7\u9650\u3002", "method": "\u4f7f\u7528\u533a\u57df\u5d4c\u5165\u5c42\u5b66\u4e60\u65f6\u95f4\u7279\u5b9a\u5d4c\u5165\uff0c\u7136\u540e\u57fa\u4e8e\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u7a7a\u95f4-\u65f6\u95f4\u4f9d\u8d56\u5b66\u4e60\u6a21\u5757\u6765\u6355\u83b7\u9644\u8fd1\u548c\u8fdc\u5904\u533a\u57df\u7684\u8054\u5408\u65f6\u7a7a\u4f9d\u8d56\u3002", "result": "\u5728\u4e24\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cST-SAM\u5728RMSE\u4e0a\u5e73\u5747\u63d0\u534715%\uff0cMAPE\u63d0\u534717%\uff0c\u8bad\u7ec3\u65f6\u95f4\u5feb32\u500d\u3002", "conclusion": "ST-SAM\u5b8c\u5168\u4f9d\u8d56\u81ea\u6ce8\u610f\u529b\u673a\u5236\u6355\u83b7\u5c40\u90e8\u548c\u5168\u5c40\u65f6\u7a7a\u76f8\u5173\u6027\uff0c\u4f7f\u5176\u5728\u4ea4\u901a\u9884\u6d4b\u4efb\u52a1\u4e2d\u65e2\u6709\u6548\u53c8\u9ad8\u6548\u3002"}}
{"id": "2511.07767", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07767", "abs": "https://arxiv.org/abs/2511.07767", "authors": ["Yuen-Man Pun", "Matthew Buchholz", "Robert M. Gower"], "title": "Schedulers for Schedule-free: Theoretically inspired hyperparameters", "comment": null, "summary": "The recently proposed schedule-free method has been shown to achieve strong performance when hyperparameter tuning is limited. The current theory for schedule-free only supports a constant learning rate, where-as the implementation used in practice uses a warm-up schedule. We show how to extend the last-iterate convergence theory of schedule-free to allow for any scheduler, and how the averaging parameter has to be updated as a function of the learning rate. We then perform experiments showing how our convergence theory has some predictive power with regards to practical executions on deep neural networks, despite that this theory relies on assuming convexity. When applied to the warmup-stable-decay (wsd) schedule, our theory shows the optimal convergence rate of $\\mathcal{O}(1/\\sqrt{T})$. We then use convexity to design a new adaptive Polyak learning rate schedule for schedule-free. We prove an optimal anytime last-iterate convergence for our new Polyak schedule, and show that it performs well compared to a number of baselines on a black-box model distillation task.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86schedule-free\u65b9\u6cd5\u7684\u6536\u655b\u7406\u8bba\uff0c\u652f\u6301\u4efb\u610f\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u81ea\u9002\u5e94Polyak\u5b66\u4e60\u7387\u8c03\u5ea6\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e2d\u90fd\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684schedule-free\u7406\u8bba\u53ea\u652f\u6301\u6052\u5b9a\u5b66\u4e60\u7387\uff0c\u4f46\u5b9e\u9645\u5b9e\u73b0\u4f7f\u7528\u4e86warm-up\u8c03\u5ea6\u3002\u9700\u8981\u6269\u5c55\u7406\u8bba\u4ee5\u652f\u6301\u4efb\u610f\u8c03\u5ea6\u5668\uff0c\u5e76\u6539\u8fdb\u5b9e\u9645\u6027\u80fd\u3002", "method": "\u6269\u5c55schedule-free\u7684\u6536\u655b\u7406\u8bba\u4ee5\u5141\u8bb8\u4efb\u610f\u5b66\u4e60\u7387\u8c03\u5ea6\uff0c\u66f4\u65b0\u5e73\u5747\u53c2\u6570\u4f5c\u4e3a\u5b66\u4e60\u7387\u7684\u51fd\u6570\uff0c\u5e76\u57fa\u4e8e\u51f8\u6027\u8bbe\u8ba1\u65b0\u7684\u81ea\u9002\u5e94Polyak\u5b66\u4e60\u7387\u8c03\u5ea6\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e86\u5728wsd\u8c03\u5ea6\u4e0b\u8fbe\u5230O(1/\u221aT)\u7684\u6700\u4f18\u6536\u655b\u7387\uff0c\u65b0Polyak\u8c03\u5ea6\u5728\u6a21\u578b\u84b8\u998f\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u591a\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u6269\u5c55\u7684schedule-free\u7406\u8bba\u5177\u6709\u5b9e\u9645\u9884\u6d4b\u80fd\u529b\uff0c\u65b0\u63d0\u51fa\u7684\u81ea\u9002\u5e94Polyak\u8c03\u5ea6\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e2d\u5747\u8868\u73b0\u51fa\u6700\u4f18\u6027\u80fd\u3002"}}
{"id": "2511.07988", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07988", "abs": "https://arxiv.org/abs/2511.07988", "authors": ["Nico Policzer", "Cameron Braunstein", "Mariya Toneva"], "title": "The One Where They Brain-Tune for Social Cognition: Multi-Modal Brain-Tuning on Friends", "comment": "20 pages, 7 figures. Appearing at the NeurIPS 2025 Workshop on Interpreting Cognition in Deep Learning Models", "summary": "Recent studies on audio models show brain-tuning - fine-tuning models to better predict corresponding fMRI activity - improves brain alignment and increases performance on downstream semantic and audio tasks. We extend this approach to a multimodal audio-video model to enhance social cognition, targeting the Superior Temporal Sulcus (STS), a key region for social processing, while subjects watch Friends. We find significant increases in brain alignment to the STS and an adjacent ROI, as well as improvements to a social cognition task related to the training data - sarcasm detection in sitcoms. In summary, our study extends brain-tuning to the multi-modal domain, demonstrating improvements to a downstream task after tuning to a relevant functional region.", "AI": {"tldr": "\u672c\u7814\u7a76\u5c06\u8111\u8c03\u8c10\u65b9\u6cd5\u6269\u5c55\u5230\u591a\u6a21\u6001\u97f3\u9891-\u89c6\u9891\u6a21\u578b\uff0c\u901a\u8fc7\u9488\u5bf9\u793e\u4ea4\u5904\u7406\u5173\u952e\u533a\u57dfSTS\u8fdb\u884c\u5fae\u8c03\uff0c\u63d0\u9ad8\u4e86\u8111\u5bf9\u9f50\u6027\u5e76\u6539\u5584\u4e86\u793e\u4ea4\u8ba4\u77e5\u4efb\u52a1\uff08\u60c5\u666f\u559c\u5267\u4e2d\u7684\u8bbd\u523a\u68c0\u6d4b\uff09\u6027\u80fd\u3002", "motivation": "\u6269\u5c55\u8111\u8c03\u8c10\u65b9\u6cd5\u5230\u591a\u6a21\u6001\u9886\u57df\uff0c\u901a\u8fc7\u589e\u5f3a\u6a21\u578b\u4e0e\u5927\u8111\u793e\u4ea4\u5904\u7406\u533a\u57df\u7684\u5bf9\u9f50\u6027\u6765\u6539\u5584\u793e\u4ea4\u8ba4\u77e5\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u591a\u6a21\u6001\u97f3\u9891-\u89c6\u9891\u6a21\u578b\uff0c\u9488\u5bf9\u793e\u4ea4\u5904\u7406\u5173\u952e\u533a\u57dfSTS\u8fdb\u884c\u8111\u8c03\u8c10\uff0c\u8ba9\u6a21\u578b\u66f4\u597d\u5730\u9884\u6d4b\u89c2\u770b\u300a\u8001\u53cb\u8bb0\u300b\u65f6\u7684fMRI\u6d3b\u52a8\u3002", "result": "\u663e\u8457\u63d0\u9ad8\u4e86\u4e0eSTS\u53ca\u90bb\u8fd1ROI\u7684\u8111\u5bf9\u9f50\u6027\uff0c\u5e76\u5728\u4e0e\u8bad\u7ec3\u6570\u636e\u76f8\u5173\u7684\u793e\u4ea4\u8ba4\u77e5\u4efb\u52a1\uff08\u60c5\u666f\u559c\u5267\u8bbd\u523a\u68c0\u6d4b\uff09\u4e0a\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u6210\u529f\u5c06\u8111\u8c03\u8c10\u6269\u5c55\u5230\u591a\u6a21\u6001\u9886\u57df\uff0c\u8bc1\u660e\u901a\u8fc7\u8c03\u8c10\u76f8\u5173\u529f\u80fd\u533a\u57df\u53ef\u4ee5\u6539\u5584\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002"}}
{"id": "2511.07809", "categories": ["cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.07809", "abs": "https://arxiv.org/abs/2511.07809", "authors": ["Sara Kangaslahti", "Danny Ebanks", "Jean Kossaifi", "Anqi Liu", "R. Michael Alvarez", "Animashree Anandkumar"], "title": "Analyzing Political Text at Scale with Online Tensor LDA", "comment": "64 pages, 11 figures", "summary": "This paper proposes a topic modeling method that scales linearly to billions of documents. We make three core contributions: i) we present a topic modeling method, Tensor Latent Dirichlet Allocation (TLDA), that has identifiable and recoverable parameter guarantees and sample complexity guarantees for large data; ii) we show that this method is computationally and memory efficient (achieving speeds over 3-4x those of prior parallelized Latent Dirichlet Allocation (LDA) methods), and that it scales linearly to text datasets with over a billion documents; iii) we provide an open-source, GPU-based implementation, of this method. This scaling enables previously prohibitive analyses, and we perform two real-world, large-scale new studies of interest to political scientists: we provide the first thorough analysis of the evolution of the #MeToo movement through the lens of over two years of Twitter conversation and a detailed study of social media conversations about election fraud in the 2020 presidential election. Thus this method provides social scientists with the ability to study very large corpora at scale and to answer important theoretically-relevant questions about salient issues in near real-time.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u5230\u6570\u5341\u4ebf\u6587\u6863\u7684\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5TLDA\uff0c\u5177\u6709\u7ebf\u6027\u6269\u5c55\u6027\u3001\u8ba1\u7b97\u6548\u7387\u9ad8\uff08\u6bd4\u73b0\u6709\u5e76\u884cLDA\u65b9\u6cd5\u5feb3-4\u500d\uff09\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u6e90GPU\u5b9e\u73b0\u3002", "motivation": "\u73b0\u6709\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u8d85\u5927\u89c4\u6a21\u6587\u672c\u6570\u636e\uff0c\u9650\u5236\u4e86\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u5bf9\u6d77\u91cf\u8bed\u6599\u7684\u5206\u6790\u80fd\u529b\u3002", "method": "\u63d0\u51faTensor Latent Dirichlet Allocation (TLDA)\u65b9\u6cd5\uff0c\u5177\u6709\u53ef\u8bc6\u522b\u548c\u53ef\u6062\u590d\u53c2\u6570\u4fdd\u8bc1\uff0c\u4ee5\u53ca\u5927\u6570\u636e\u7684\u6837\u672c\u590d\u6742\u5ea6\u4fdd\u8bc1\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5305\u542b\u8d85\u8fc710\u4ebf\u6587\u6863\u7684\u6587\u672c\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u7ebf\u6027\u6269\u5c55\uff0c\u5e76\u6210\u529f\u5e94\u7528\u4e8e#MeToo\u8fd0\u52a8\u6f14\u5316\u548c2020\u5e74\u603b\u7edf\u9009\u4e3e\u6b3a\u8bc8\u793e\u4ea4\u5a92\u4f53\u5bf9\u8bdd\u7684\u5927\u89c4\u6a21\u5206\u6790\u3002", "conclusion": "TLDA\u65b9\u6cd5\u4e3a\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u8005\u63d0\u4f9b\u4e86\u7814\u7a76\u8d85\u5927\u89c4\u6a21\u8bed\u6599\u5e93\u7684\u80fd\u529b\uff0c\u80fd\u591f\u8fd1\u4e4e\u5b9e\u65f6\u5730\u5206\u6790\u91cd\u8981\u7406\u8bba\u76f8\u5173\u95ee\u9898\u3002"}}
{"id": "2511.07824", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07824", "abs": "https://arxiv.org/abs/2511.07824", "authors": ["Zhiyao Zhang", "Zhuqing Liu", "Xin Zhang", "Wen-Yen Chen", "Jiyan Yang", "Jia Liu"], "title": "Multi-Objective Bilevel Learning", "comment": null, "summary": "As machine learning (ML) applications grow increasingly complex in recent years, modern ML frameworks often need to address multiple potentially conflicting objectives with coupled decision variables across different layers. This creates a compelling need for multi-objective bilevel learning (MOBL). So far, however, the field of MOBL remains in its infancy and many important problems remain under-explored. This motivates us to fill this gap and systematically investigate the theoretical and algorithmic foundation of MOBL. Specifically, we consider MOBL problems with multiple conflicting objectives guided by preferences at the upper-level subproblem, where part of the inputs depend on the optimal solution of the lower-level subproblem. Our goal is to develop efficient MOBL optimization algorithms to (1) identify a preference-guided Pareto-stationary solution with low oracle complexity; and (2) enable systematic Pareto front exploration. To this end, we propose a unifying algorithmic framework called weighted-Chebyshev multi-hyper-gradient-descent (WC-MHGD) for both deterministic and stochastic settings with finite-time Pareto-stationarity convergence rate guarantees, which not only implies low oracle complexity but also induces systematic Pareto front exploration. We further conduct extensive experiments to confirm our theoretical results.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u76ee\u6807\u53cc\u5c42\u5b66\u4e60\uff08MOBL\uff09\u7b97\u6cd5\u6846\u67b6WC-MHGD\uff0c\u7528\u4e8e\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u4e2d\u591a\u4e2a\u51b2\u7a81\u76ee\u6807\u7684\u4f18\u5316\u95ee\u9898\uff0c\u5177\u6709\u4f4eoracle\u590d\u6742\u5ea6\u548c\u7cfb\u7edf\u5316Pareto\u524d\u6cbf\u63a2\u7d22\u80fd\u529b\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u5e94\u7528\u65e5\u76ca\u590d\u6742\uff0c\u73b0\u4ee3ML\u6846\u67b6\u9700\u8981\u5904\u7406\u591a\u4e2a\u53ef\u80fd\u51b2\u7a81\u7684\u76ee\u6807\u548c\u4e0d\u540c\u5c42\u95f4\u7684\u8026\u5408\u51b3\u7b56\u53d8\u91cf\uff0c\u8fd9\u4ea7\u751f\u4e86\u5bf9\u591a\u76ee\u6807\u53cc\u5c42\u5b66\u4e60\u7684\u8feb\u5207\u9700\u6c42\u3002\u4f46\u76ee\u524dMOBL\u9886\u57df\u4ecd\u5904\u4e8e\u8d77\u6b65\u9636\u6bb5\uff0c\u8bb8\u591a\u91cd\u8981\u95ee\u9898\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u4e86\u52a0\u6743Chebyshev\u591a\u8d85\u68af\u5ea6\u4e0b\u964d\uff08WC-MHGD\uff09\u7b97\u6cd5\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u786e\u5b9a\u6027\u548c\u968f\u673a\u8bbe\u7f6e\uff0c\u901a\u8fc7\u504f\u597d\u5f15\u5bfc\u8bc6\u522bPareto\u7a33\u6001\u89e3\uff0c\u5e76\u5b9e\u73b0\u7cfb\u7edf\u5316\u7684Pareto\u524d\u6cbf\u63a2\u7d22\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660eWC-MHGD\u5177\u6709\u6709\u9650\u65f6\u95f4Pareto\u7a33\u6001\u6536\u655b\u7387\u4fdd\u8bc1\uff0c\u4e0d\u4ec5\u610f\u5473\u7740\u4f4eoracle\u590d\u6742\u5ea6\uff0c\u8fd8\u80fd\u8bf1\u5bfc\u7cfb\u7edf\u5316\u7684Pareto\u524d\u6cbf\u63a2\u7d22\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\u3002", "conclusion": "WC-MHGD\u4e3a\u591a\u76ee\u6807\u53cc\u5c42\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u7406\u8bba\u7b97\u6cd5\u6846\u67b6\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u4e3a\u590d\u6742ML\u5e94\u7528\u4e2d\u7684\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u7cfb\u7edf\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.07995", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07995", "abs": "https://arxiv.org/abs/2511.07995", "authors": ["Jinbo Li", "Witold Pedrycz", "Iqbal Jamal"], "title": "Multivariate Time series Anomaly Detection:A Framework of Hidden Markov Models", "comment": "25 pages, 8 figures, 6 tables", "summary": "In this study, we develop an approach to multivariate time series anomaly detection focused on the transformation of multivariate time series to univariate time series. Several transformation techniques involving Fuzzy C-Means (FCM) clustering and fuzzy integral are studied. In the sequel, a Hidden Markov Model (HMM), one of the commonly encountered statistical methods, is engaged here to detect anomalies in multivariate time series. We construct HMM-based anomaly detectors and in this context compare several transformation methods. A suite of experimental studies along with some comparative analysis is reported.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u5355\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u7ed3\u5408FCM\u805a\u7c7b\u3001\u6a21\u7cca\u79ef\u5206\u548c\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\u3002", "motivation": "\u9488\u5bf9\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u7684\u590d\u6742\u6027\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u964d\u7ef4\u8f6c\u6362\u6280\u672f\u7b80\u5316\u95ee\u9898\uff0c\u63d0\u9ad8\u68c0\u6d4b\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528FCM\u805a\u7c7b\u548c\u6a21\u7cca\u79ef\u5206\u5c06\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u5355\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\uff0c\u7136\u540e\u5e94\u7528\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u6784\u5efa\u5f02\u5e38\u68c0\u6d4b\u5668\uff0c\u5e76\u6bd4\u8f83\u4e0d\u540c\u8f6c\u6362\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "result": "\u901a\u8fc7\u4e00\u7cfb\u5217\u5b9e\u9a8c\u7814\u7a76\u548c\u5bf9\u6bd4\u5206\u6790\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u6bd4\u8f83\u4e86\u4e0d\u540c\u8f6c\u6362\u6280\u672f\u5728\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\u3002", "conclusion": "\u57fa\u4e8e\u591a\u5143\u5230\u5355\u53d8\u91cf\u8f6c\u6362\u7684\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u65b9\u6cd5\u5728\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4e3a\u590d\u6742\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.07843", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07843", "abs": "https://arxiv.org/abs/2511.07843", "authors": ["Jay Chooi", "Kevin Cong", "Russell Li", "Lillian Sun"], "title": "DP-AdamW: Investigating Decoupled Weight Decay and Bias Correction in Private Deep Learning", "comment": "19 pages, 5 appendices; presented at ICML 2025 DIG-BUGS Workshop", "summary": "As deep learning methods increasingly utilize sensitive data on a widespread scale, differential privacy (DP) offers formal guarantees to protect against information leakage during model training. A significant challenge remains in implementing DP optimizers that retain strong performance while preserving privacy. Recent advances introduced ever more efficient optimizers, with AdamW being a popular choice for training deep learning models because of strong empirical performance. We study \\emph{DP-AdamW} and introduce \\emph{DP-AdamW-BC}, a differentially private variant of the AdamW optimizer with DP bias correction for the second moment estimator. We start by showing theoretical results for privacy and convergence guarantees of DP-AdamW and DP-AdamW-BC. Then, we empirically analyze the behavior of both optimizers across multiple privacy budgets ($\u03b5= 1, 3, 7$). We find that DP-AdamW outperforms existing state-of-the-art differentially private optimizers like DP-SGD, DP-Adam, and DP-AdamBC, scoring over 15\\% higher on text classification, up to 5\\% higher on image classification, and consistently 1\\% higher on graph node classification. Moreover, we empirically show that incorporating bias correction in DP-AdamW (DP-AdamW-BC) consistently decreases accuracy, in contrast to the improvement of DP-AdamBC improvement over DP-Adam.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5dee\u5206\u9690\u79c1AdamW\u4f18\u5316\u5668\uff08DP-AdamW\uff09\u53ca\u5176\u5e26\u504f\u7f6e\u6821\u6b63\u7684\u7248\u672c\uff08DP-AdamW-BC\uff09\uff0c\u5728\u591a\u4e2a\u9690\u79c1\u9884\u7b97\u4e0b\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u53d1\u73b0DP-AdamW\u5728\u6587\u672c\u5206\u7c7b\u3001\u56fe\u50cf\u5206\u7c7b\u548c\u56fe\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709DP\u4f18\u5316\u5668\u3002", "motivation": "\u968f\u7740\u6df1\u5ea6\u5b66\u4e60\u5e7f\u6cdb\u4f7f\u7528\u654f\u611f\u6570\u636e\uff0c\u5dee\u5206\u9690\u79c1\u63d0\u4f9b\u6b63\u5f0f\u4fdd\u62a4\u4ee5\u9632\u6b62\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u4fe1\u606f\u6cc4\u9732\u3002\u73b0\u6709\u6311\u6218\u5728\u4e8e\u5b9e\u73b0\u65e2\u4fdd\u6301\u5f3a\u6027\u80fd\u53c8\u4fdd\u62a4\u9690\u79c1\u7684DP\u4f18\u5316\u5668\uff0c\u800cAdamW\u56e0\u5176\u5f3a\u5927\u7ecf\u9a8c\u6027\u80fd\u6210\u4e3a\u6d41\u884c\u9009\u62e9\u3002", "method": "\u63d0\u51fa\u4e86DP-AdamW\u53ca\u5176\u5e26\u504f\u7f6e\u6821\u6b63\u7684\u7248\u672cDP-AdamW-BC\uff0c\u63d0\u4f9b\u4e86\u9690\u79c1\u548c\u6536\u655b\u4fdd\u8bc1\u7684\u7406\u8bba\u7ed3\u679c\uff0c\u5e76\u5728\u591a\u4e2a\u9690\u79c1\u9884\u7b97\uff08\u03b5=1,3,7\uff09\u4e0b\u5bf9\u4e24\u79cd\u4f18\u5316\u5668\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\u3002", "result": "DP-AdamW\u5728\u6587\u672c\u5206\u7c7b\u4e0a\u6bd4\u73b0\u6709DP\u4f18\u5316\u5668\u9ad8\u51fa15%\u4ee5\u4e0a\uff0c\u56fe\u50cf\u5206\u7c7b\u9ad8\u51fa5%\uff0c\u56fe\u8282\u70b9\u5206\u7c7b\u4e00\u81f4\u9ad8\u51fa1%\u3002\u4f46DP-AdamW-BC\u7684\u504f\u7f6e\u6821\u6b63\u53cd\u800c\u964d\u4f4e\u4e86\u51c6\u786e\u7387\uff0c\u4e0eDP-AdamBC\u6539\u5584DP-Adam\u7684\u60c5\u51b5\u76f8\u53cd\u3002", "conclusion": "DP-AdamW\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u663e\u8457\u4f18\u4e8e\u73b0\u6709DP\u4f18\u5316\u5668\uff0c\u4f46\u504f\u7f6e\u6821\u6b63\u5728\u8be5\u8bbe\u7f6e\u4e0b\u672a\u80fd\u5e26\u6765\u6027\u80fd\u63d0\u5347\uff0c\u53cd\u800c\u964d\u4f4e\u4e86\u51c6\u786e\u6027\u3002"}}
{"id": "2511.08052", "categories": ["cs.AI", "cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.08052", "abs": "https://arxiv.org/abs/2511.08052", "authors": ["Po-Chung Hsieh", "Chin-Po Chen", "Jeng-Lin Li", "Ming-Ching Chang"], "title": "Dual-Process Scaffold Reasoning for Enhancing LLM Code Debugging", "comment": "5 pages, 2 figures", "summary": "Recent LLMs have demonstrated sophisticated problem-solving capabilities on various benchmarks through advanced reasoning algorithms. However, the key research question of identifying reasoning steps that balance complexity and computational efficiency remains unsolved. Recent research has increasingly drawn upon psychological theories to explore strategies for optimizing cognitive pathways. The LLM's final outputs and intermediate steps are regarded as System 1 and System 2, respectively. However, an in-depth exploration of the System 2 reasoning is still lacking. Therefore, we propose a novel psychologically backed Scaffold Reasoning framework for code debugging, which encompasses the Scaffold Stream, Analytic Stream, and Integration Stream. The construction of reference code within the Scaffold Stream is integrated with the buggy code analysis results produced by the Analytic Stream through the Integration Stream. Our framework achieves an 88.91% pass rate and an average inference time of 5.36 seconds per-problem on DebugBench, outperforming other reasoning approaches across various LLMs in both reasoning accuracy and efficiency. Further analyses elucidate the advantages and limitations of various cognitive pathways across varying problem difficulties and bug types. Our findings also corroborate the alignment of the proposed Scaffold Reasoning framework with human cognitive processes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5fc3\u7406\u5b66\u7406\u8bba\u7684Scaffold Reasoning\u6846\u67b6\u7528\u4e8e\u4ee3\u7801\u8c03\u8bd5\uff0c\u901a\u8fc7\u4e09\u4e2a\u6d41\uff08Scaffold\u6d41\u3001\u5206\u6790\u6d41\u548c\u96c6\u6210\u6d41\uff09\u6765\u4f18\u5316LLM\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u5728DebugBench\u4e0a\u8fbe\u5230\u4e8688.91%\u7684\u901a\u8fc7\u7387\u548c5.36\u79d2\u7684\u5e73\u5747\u63a8\u7406\u65f6\u95f4\u3002", "motivation": "\u5f53\u524dLLM\u867d\u7136\u5177\u5907\u590d\u6742\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u4f46\u5982\u4f55\u5728\u63a8\u7406\u6b65\u9aa4\u7684\u590d\u6742\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u627e\u5230\u5e73\u8861\u4ecd\u662f\u4e00\u4e2a\u672a\u89e3\u51b3\u7684\u95ee\u9898\u3002\u7f3a\u4e4f\u5bf9System 2\u63a8\u7406\u7684\u6df1\u5165\u63a2\u7d22\uff0c\u9700\u8981\u57fa\u4e8e\u5fc3\u7406\u5b66\u7406\u8bba\u4f18\u5316\u8ba4\u77e5\u8def\u5f84\u3002", "method": "\u63d0\u51faScaffold Reasoning\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u6d41\uff1aScaffold\u6d41\u6784\u5efa\u53c2\u8003\u4ee3\u7801\uff0c\u5206\u6790\u6d41\u5206\u6790\u9519\u8bef\u4ee3\u7801\uff0c\u96c6\u6210\u6d41\u5c06\u4e24\u8005\u6574\u5408\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u5fc3\u7406\u5b66\u7406\u8bba\uff0c\u4f18\u5316LLM\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u5728DebugBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6846\u67b6\u8fbe\u5230\u4e8688.91%\u7684\u901a\u8fc7\u7387\uff0c\u5e73\u5747\u6bcf\u4e2a\u95ee\u9898\u7684\u63a8\u7406\u65f6\u95f4\u4e3a5.36\u79d2\uff0c\u5728\u63a8\u7406\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u5176\u4ed6\u63a8\u7406\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\u5bf9\u9f50\uff0c\u5728\u4e0d\u540c\u95ee\u9898\u96be\u5ea6\u548c\u9519\u8bef\u7c7b\u578b\u4e0b\u5c55\u73b0\u4e86\u5404\u79cd\u8ba4\u77e5\u8def\u5f84\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u4e3aLLM\u63a8\u7406\u4f18\u5316\u63d0\u4f9b\u4e86\u5fc3\u7406\u5b66\u57fa\u7840\u3002"}}
{"id": "2511.07904", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07904", "abs": "https://arxiv.org/abs/2511.07904", "authors": ["Zhao Yu", "Xiuping Wu", "Liangjun Ke"], "title": "Test-driven Reinforcement Learning", "comment": "AAAI 2026 oral", "summary": "Reinforcement learning (RL) has been recognized as a powerful tool for robot control tasks. RL typically employs reward functions to define task objectives and guide agent learning. However, since the reward function serves the dual purpose of defining the optimal goal and guiding learning, it is challenging to design the reward function manually, which often results in a suboptimal task representation. To tackle the reward design challenge in RL, inspired by the satisficing theory, we propose a Test-driven Reinforcement Learning (TdRL) framework. In the TdRL framework, multiple test functions are used to represent the task objective rather than a single reward function. Test functions can be categorized as pass-fail tests and indicative tests, each dedicated to defining the optimal objective and guiding the learning process, respectively, thereby making defining tasks easier. Building upon such a task definition, we first prove that if a trajectory return function assigns higher returns to trajectories closer to the optimal trajectory set, maximum entropy policy optimization based on this return function will yield a policy that is closer to the optimal policy set. Then, we introduce a lexicographic heuristic approach to compare the relative distance relationship between trajectories and the optimal trajectory set for learning the trajectory return function. Furthermore, we develop an algorithm implementation of TdRL. Experimental results on the DeepMind Control Suite benchmark demonstrate that TdRL matches or outperforms handcrafted reward methods in policy training, with greater design simplicity and inherent support for multi-objective optimization. We argue that TdRL offers a novel perspective for representing task objectives, which could be helpful in addressing the reward design challenges in RL applications.", "AI": {"tldr": "\u63d0\u51fa\u6d4b\u8bd5\u9a71\u52a8\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u591a\u4e2a\u6d4b\u8bd5\u51fd\u6570\u66ff\u4ee3\u5355\u4e00\u5956\u52b1\u51fd\u6570\u6765\u5b9a\u4e49\u4efb\u52a1\u76ee\u6807\uff0c\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u5956\u52b1\u51fd\u6570\u8bbe\u8ba1\u56f0\u96be\u7684\u95ee\u9898\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5956\u52b1\u51fd\u6570\u65e2\u8981\u5b9a\u4e49\u6700\u4f18\u76ee\u6807\u53c8\u8981\u6307\u5bfc\u5b66\u4e60\u8fc7\u7a0b\uff0c\u624b\u52a8\u8bbe\u8ba1\u56f0\u96be\u4e14\u5bb9\u6613\u5bfc\u81f4\u6b21\u4f18\u4efb\u52a1\u8868\u793a\u3002\u53d7\u6ee1\u610f\u7406\u8bba\u542f\u53d1\uff0c\u5e0c\u671b\u627e\u5230\u66f4\u7b80\u5355\u7684\u4efb\u52a1\u5b9a\u4e49\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u901a\u8fc7-\u5931\u8d25\u6d4b\u8bd5\u548c\u6307\u793a\u6027\u6d4b\u8bd5\u4e24\u7c7b\u6d4b\u8bd5\u51fd\u6570\u5206\u522b\u5b9a\u4e49\u6700\u4f18\u76ee\u6807\u548c\u6307\u5bfc\u5b66\u4e60\u8fc7\u7a0b\uff1b\u63d0\u51fa\u57fa\u4e8e\u8f68\u8ff9\u8fd4\u56de\u51fd\u6570\u7684\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u8bcd\u5178\u5e8f\u542f\u53d1\u5f0f\u65b9\u6cd5\u5b66\u4e60\u8f68\u8ff9\u8fd4\u56de\u51fd\u6570\u3002", "result": "\u5728DeepMind Control Suite\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTdRL\u65b9\u6cd5\u5728\u7b56\u7565\u8bad\u7ec3\u4e0a\u8fbe\u5230\u6216\u4f18\u4e8e\u624b\u5de5\u8bbe\u8ba1\u5956\u52b1\u7684\u65b9\u6cd5\uff0c\u4e14\u5177\u6709\u66f4\u5927\u7684\u8bbe\u8ba1\u7b80\u5355\u6027\u548c\u5bf9\u591a\u76ee\u6807\u4f18\u5316\u7684\u5185\u5728\u652f\u6301\u3002", "conclusion": "TdRL\u4e3a\u8868\u793a\u4efb\u52a1\u76ee\u6807\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u6709\u52a9\u4e8e\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e2d\u7684\u5956\u52b1\u8bbe\u8ba1\u6311\u6218\u3002"}}
{"id": "2511.08082", "categories": ["cs.AI", "cs.LG", "econ.GN"], "pdf": "https://arxiv.org/pdf/2511.08082", "abs": "https://arxiv.org/abs/2511.08082", "authors": ["Stella C. Dong"], "title": "Prudential Reliability of Large Language Models in Reinsurance: Governance, Assurance, and Capital Efficiency", "comment": "48 pages, 9 figures, 5 tables. Submitted to the Journal of Risk and Insurance (JRI), November 2025", "summary": "This paper develops a prudential framework for assessing the reliability of large language models (LLMs) in reinsurance. A five-pillar architecture--governance, data lineage, assurance, resilience, and regulatory alignment--translates supervisory expectations from Solvency II, SR 11-7, and guidance from EIOPA (2025), NAIC (2023), and IAIS (2024) into measurable lifecycle controls. The framework is implemented through the Reinsurance AI Reliability and Assurance Benchmark (RAIRAB), which evaluates whether governance-embedded LLMs meet prudential standards for grounding, transparency, and accountability. Across six task families, retrieval-grounded configurations achieved higher grounding accuracy (0.90), reduced hallucination and interpretive drift by roughly 40%, and nearly doubled transparency. These mechanisms lower informational frictions in risk transfer and capital allocation, showing that existing prudential doctrines already accommodate reliable AI when governance is explicit, data are traceable, and assurance is verifiable.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u8bc4\u4f30\u518d\u4fdd\u9669\u4e2d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u9760\u6027\u7684\u5ba1\u614e\u6846\u67b6\uff0c\u901a\u8fc7\u4e94\u652f\u67f1\u67b6\u6784\u5c06\u76d1\u7ba1\u671f\u671b\u8f6c\u5316\u4e3a\u53ef\u8861\u91cf\u7684\u751f\u547d\u5468\u671f\u63a7\u5236\uff0c\u5e76\u5728RAIRAB\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u518d\u4fdd\u9669\u9886\u57df\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u5ba1\u614e\u6846\u67b6\u6765\u8bc4\u4f30\u5176\u53ef\u9760\u6027\uff0c\u786e\u4fdd\u7b26\u5408\u73b0\u6709\u76d1\u7ba1\u6807\u51c6\u5982Solvency II\u3001SR 11-7\u7b49\u7684\u8981\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e94\u652f\u67f1\u67b6\u6784\uff08\u6cbb\u7406\u3001\u6570\u636e\u6eaf\u6e90\u3001\u4fdd\u8bc1\u3001\u97e7\u6027\u548c\u76d1\u7ba1\u5bf9\u9f50\uff09\uff0c\u5e76\u5c06\u5176\u5b9e\u73b0\u4e3a\u518d\u4fdd\u9669AI\u53ef\u9760\u6027\u548c\u4fdd\u8bc1\u57fa\u51c6(RAIRAB)\uff0c\u901a\u8fc7\u68c0\u7d22\u63a5\u5730\u914d\u7f6e\u5728\u516d\u4e2a\u4efb\u52a1\u7cfb\u5217\u4e2d\u8bc4\u4f30LLM\u7684\u63a5\u5730\u51c6\u786e\u6027\u3001\u5e7b\u89c9\u51cf\u5c11\u548c\u900f\u660e\u5ea6\u63d0\u5347\u3002", "result": "\u68c0\u7d22\u63a5\u5730\u914d\u7f6e\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u63a5\u5730\u51c6\u786e\u6027(0.90)\uff0c\u5e7b\u89c9\u548c\u89e3\u91ca\u6f02\u79fb\u51cf\u5c11\u4e86\u7ea640%\uff0c\u900f\u660e\u5ea6\u51e0\u4e4e\u7ffb\u500d\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u98ce\u9669\u8f6c\u79fb\u548c\u8d44\u672c\u914d\u7f6e\u4e2d\u7684\u4fe1\u606f\u6469\u64e6\u3002", "conclusion": "\u73b0\u6709\u5ba1\u614e\u539f\u5219\u5df2\u7ecf\u80fd\u591f\u5bb9\u7eb3\u53ef\u9760\u7684AI\uff0c\u524d\u63d0\u662f\u6cbb\u7406\u660e\u786e\u3001\u6570\u636e\u53ef\u8ffd\u6eaf\u4e14\u4fdd\u8bc1\u53ef\u9a8c\u8bc1\uff0c\u8be5\u6846\u67b6\u4e3a\u518d\u4fdd\u9669\u9886\u57df\u7684AI\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u76d1\u7ba1\u5408\u89c4\u8def\u5f84\u3002"}}
{"id": "2511.08091", "categories": ["cs.AI", "cs.CC"], "pdf": "https://arxiv.org/pdf/2511.08091", "abs": "https://arxiv.org/abs/2511.08091", "authors": ["Robert Ganian", "Marlene Gr\u00fcndel", "Simon Wietheger"], "title": "Gateways to Tractability for Satisfiability in Pearl's Causal Hierarchy", "comment": null, "summary": "Pearl's Causal Hierarchy (PCH) is a central framework for reasoning about probabilistic, interventional, and counterfactual statements, yet the satisfiability problem for PCH formulas is computationally intractable in almost all classical settings. We revisit this challenge through the lens of parameterized complexity and identify the first gateways to tractability. Our results include fixed-parameter and XP-algorithms for satisfiability in key probabilistic and counterfactual fragments, using parameters such as primal treewidth and the number of variables, together with matching hardness results that map the limits of tractability. Technically, we depart from the dynamic programming paradigm typically employed for treewidth-based algorithms and instead exploit structural characterizations of well-formed causal models, providing a new algorithmic toolkit for causal reasoning.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u53c2\u6570\u5316\u590d\u6742\u6027\u7406\u8bba\u91cd\u65b0\u5ba1\u89c6Pearl\u56e0\u679c\u5c42\u6b21(PCH)\u7684\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\uff0c\u53d1\u73b0\u4e86\u9996\u4e2a\u53ef\u5904\u7406\u6027\u8def\u5f84\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u539f\u59cb\u6811\u5bbd\u548c\u53d8\u91cf\u6570\u91cf\u7684\u56fa\u5b9a\u53c2\u6570\u548cXP\u7b97\u6cd5\uff0c\u5e76\u5efa\u7acb\u4e86\u5339\u914d\u7684\u786c\u5ea6\u7ed3\u679c\u6765\u754c\u5b9a\u53ef\u5904\u7406\u6027\u8fb9\u754c\u3002", "motivation": "Pearl\u56e0\u679c\u5c42\u6b21(PCH)\u662f\u63a8\u7406\u6982\u7387\u3001\u5e72\u9884\u548c\u53cd\u4e8b\u5b9e\u9648\u8ff0\u7684\u6838\u5fc3\u6846\u67b6\uff0c\u4f46\u5176\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u5728\u51e0\u4e4e\u6240\u6709\u7ecf\u5178\u8bbe\u7f6e\u4e2d\u90fd\u662f\u8ba1\u7b97\u96be\u89e3\u7684\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u53c2\u6570\u5316\u590d\u6742\u6027\u7406\u8bba\u6765\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u91c7\u7528\u53c2\u6570\u5316\u590d\u6742\u6027\u65b9\u6cd5\uff0c\u4f7f\u7528\u539f\u59cb\u6811\u5bbd\u548c\u53d8\u91cf\u6570\u91cf\u4f5c\u4e3a\u53c2\u6570\uff0c\u5f00\u53d1\u4e86\u56fa\u5b9a\u53c2\u6570\u548cXP\u7b97\u6cd5\u3002\u6280\u672f\u4e0a\u7a81\u7834\u4e86\u5178\u578b\u7684\u6811\u5bbd\u52a8\u6001\u89c4\u5212\u8303\u5f0f\uff0c\u5229\u7528\u7ed3\u6784\u826f\u597d\u7684\u56e0\u679c\u6a21\u578b\u7684\u7279\u5f81\u5316\uff0c\u4e3a\u56e0\u679c\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u7b97\u6cd5\u5de5\u5177\u5305\u3002", "result": "\u4e3a\u5173\u952e\u7684\u6982\u7387\u548c\u53cd\u4e8b\u5b9e\u7247\u6bb5\u63d0\u4f9b\u4e86\u53ef\u6ee1\u8db3\u6027\u7684\u56fa\u5b9a\u53c2\u6570\u548cXP\u7b97\u6cd5\uff0c\u5e76\u5efa\u7acb\u4e86\u5339\u914d\u7684\u786c\u5ea6\u7ed3\u679c\uff0c\u7cbe\u786e\u523b\u753b\u4e86\u53ef\u5904\u7406\u6027\u7684\u8fb9\u754c\u3002", "conclusion": "\u901a\u8fc7\u53c2\u6570\u5316\u590d\u6742\u6027\u7406\u8bba\u6210\u529f\u8bc6\u522b\u4e86PCH\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u7684\u9996\u4e2a\u53ef\u5904\u7406\u6027\u8def\u5f84\uff0c\u4e3a\u56e0\u679c\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u7b97\u6cd5\u5de5\u5177\u5305\uff0c\u5e76\u660e\u786e\u4e86\u53ef\u5904\u7406\u6027\u7684\u7406\u8bba\u8fb9\u754c\u3002"}}
{"id": "2511.07971", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07971", "abs": "https://arxiv.org/abs/2511.07971", "authors": ["Hyunseok Seung", "Jaewoo Lee", "Hyunsuk Ko"], "title": "Low-Rank Curvature for Zeroth-Order Optimization in LLM Fine-Tuning", "comment": "Accepted to the AAAI Conference on Artificial Intelligence (AAAI-2026)", "summary": "We introduce LOREN, a curvature-aware zeroth-order (ZO) optimization method for fine-tuning large language models (LLMs). Existing ZO methods, which estimate gradients via finite differences using random perturbations, often suffer from high variance and suboptimal search directions. Our approach addresses these challenges by: (i) reformulating the problem of gradient preconditioning as that of adaptively estimating an anisotropic perturbation distribution for gradient estimation, (ii) capturing curvature through a low-rank block diagonal preconditioner using the framework of natural evolution strategies, and (iii) applying a REINFORCE leave-one-out (RLOO) gradient estimator to reduce variance. Experiments on standard LLM benchmarks show that our method outperforms state-of-the-art ZO methods by achieving higher accuracy and faster convergence, while cutting peak memory usage by up to 27.3% compared with MeZO-Adam.", "AI": {"tldr": "LOREN\u662f\u4e00\u79cd\u66f2\u7387\u611f\u77e5\u7684\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u4f30\u8ba1\u5404\u5411\u5f02\u6027\u6270\u52a8\u5206\u5e03\u3001\u4f4e\u79e9\u5757\u5bf9\u89d2\u9884\u5904\u7406\u5668\u548cREINFORCE\u7559\u4e00\u6cd5\u68af\u5ea6\u4f30\u8ba1\u5668\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u96f6\u9636\u65b9\u6cd5\u4f7f\u7528\u968f\u673a\u6270\u52a8\u901a\u8fc7\u6709\u9650\u5dee\u5206\u4f30\u8ba1\u68af\u5ea6\uff0c\u5b58\u5728\u9ad8\u65b9\u5dee\u548c\u6b21\u4f18\u641c\u7d22\u65b9\u5411\u7684\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u68af\u5ea6\u4f30\u8ba1\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "LOREN\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u89e3\u51b3\u6311\u6218\uff1a(i)\u5c06\u68af\u5ea6\u9884\u6761\u4ef6\u95ee\u9898\u91cd\u65b0\u8868\u8ff0\u4e3a\u81ea\u9002\u5e94\u4f30\u8ba1\u5404\u5411\u5f02\u6027\u6270\u52a8\u5206\u5e03\uff1b(ii)\u4f7f\u7528\u81ea\u7136\u8fdb\u5316\u7b56\u7565\u6846\u67b6\u901a\u8fc7\u4f4e\u79e9\u5757\u5bf9\u89d2\u9884\u5904\u7406\u5668\u6355\u83b7\u66f2\u7387\uff1b(iii)\u5e94\u7528REINFORCE\u7559\u4e00\u6cd5\u68af\u5ea6\u4f30\u8ba1\u5668\u51cf\u5c11\u65b9\u5dee\u3002", "result": "\u5728\u6807\u51c6LLM\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLOREN\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u96f6\u9636\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\uff0c\u540c\u65f6\u4e0eMeZO-Adam\u76f8\u6bd4\uff0c\u5cf0\u503c\u5185\u5b58\u4f7f\u7528\u91cf\u51cf\u5c11\u4e86\u9ad8\u8fbe27.3%\u3002", "conclusion": "LOREN\u901a\u8fc7\u66f2\u7387\u611f\u77e5\u7684\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\uff0c\u5728\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u5185\u5b58\u4f7f\u7528\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u6a21\u578b\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.08191", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08191", "abs": "https://arxiv.org/abs/2511.08191", "authors": ["Ruihan Zhang", "Jun Sun", "Ee-Peng Lim", "Peixin Zhang"], "title": "Towards Provably Unlearnable Examples via Bayes Error Optimisation", "comment": null, "summary": "The recent success of machine learning models, especially large-scale classifiers and language models, relies heavily on training with massive data. These data are often collected from online sources. This raises serious concerns about the protection of user data, as individuals may not have given consent for their data to be used in training. To address this concern, recent studies introduce the concept of unlearnable examples, i.e., data instances that appear natural but are intentionally altered to prevent models from effectively learning from them. While existing methods demonstrate empirical effectiveness, they typically rely on heuristic trials and lack formal guarantees. Besides, when unlearnable examples are mixed with clean data, as is often the case in practice, their unlearnability disappears. In this work, we propose a novel approach to constructing unlearnable examples by systematically maximising the Bayes error, a measurement of irreducible classification error. We develop an optimisation-based approach and provide an efficient solution using projected gradient ascent. Our method provably increases the Bayes error and remains effective when the unlearning examples are mixed with clean samples. Experimental results across multiple datasets and model architectures are consistent with our theoretical analysis and show that our approach can restrict data learnability, effectively in practice.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6700\u5927\u5316\u8d1d\u53f6\u65af\u8bef\u5dee\u7684\u65b0\u65b9\u6cd5\u6765\u6784\u5efa\u4e0d\u53ef\u5b66\u4e60\u6837\u672c\uff0c\u8fd9\u4e9b\u6837\u672c\u770b\u8d77\u6765\u81ea\u7136\u4f46\u80fd\u963b\u6b62\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4ece\u4e2d\u6709\u6548\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1\u548c\u5728\u6df7\u5408\u5e72\u51c0\u6570\u636e\u65f6\u5931\u6548\u7684\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4f9d\u8d56\u5927\u89c4\u6a21\u6570\u636e\u8bad\u7ec3\uff0c\u7528\u6237\u6570\u636e\u4fdd\u62a4\u6210\u4e3a\u91cd\u8981\u95ee\u9898\u3002\u73b0\u6709\u4e0d\u53ef\u5b66\u4e60\u6837\u672c\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u8bd5\u9a8c\u4e14\u7f3a\u4e4f\u7406\u8bba\u4fdd\u8bc1\uff0c\u5728\u6df7\u5408\u5e72\u51c0\u6570\u636e\u65f6\u6548\u679c\u6d88\u5931\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6700\u5927\u5316\u8d1d\u53f6\u65af\u8bef\u5dee\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u4f7f\u7528\u6295\u5f71\u68af\u5ea6\u4e0a\u5347\u8fdb\u884c\u9ad8\u6548\u6c42\u89e3\uff0c\u7cfb\u7edf\u6027\u5730\u589e\u52a0\u5206\u7c7b\u7684\u4e0d\u53ef\u7ea6\u8bef\u5dee\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u9650\u5236\u6570\u636e\u53ef\u5b66\u4e60\u6027\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u67b6\u6784\u4e0a\u4fdd\u6301\u6709\u6548\u6027\uff0c\u5373\u4f7f\u4e0e\u5e72\u51c0\u6837\u672c\u6df7\u5408\u65f6\u4ecd\u80fd\u53d1\u6325\u4f5c\u7528\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u7684\u4e0d\u53ef\u5b66\u4e60\u6837\u672c\u6784\u5efa\u65b9\u6848\uff0c\u80fd\u6709\u6548\u4fdd\u62a4\u7528\u6237\u6570\u636e\u9690\u79c1\uff0c\u5728\u6df7\u5408\u6570\u636e\u573a\u666f\u4e0b\u4ecd\u4fdd\u6301\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.08035", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08035", "abs": "https://arxiv.org/abs/2511.08035", "authors": ["Xinyu Wang", "Jinxiao Du", "Yiyang Peng", "Wei Ma"], "title": "From Sequential to Recursive: Enhancing Decision-Focused Learning with Bidirectional Feedback", "comment": "16 pages, 5 figures", "summary": "Decision-focused learning (DFL) has emerged as a powerful end-to-end alternative to conventional predict-then-optimize (PTO) pipelines by directly optimizing predictive models through downstream decision losses. Existing DFL frameworks are limited by their strictly sequential structure, referred to as sequential DFL (S-DFL). However, S-DFL fails to capture the bidirectional feedback between prediction and optimization in complex interaction scenarios. In view of this, we first time propose recursive decision-focused learning (R-DFL), a novel framework that introduces bidirectional feedback between downstream optimization and upstream prediction. We further extend two distinct differentiation methods: explicit unrolling via automatic differentiation and implicit differentiation based on fixed-point methods, to facilitate efficient gradient propagation in R-DFL. We rigorously prove that both methods achieve comparable gradient accuracy, with the implicit method offering superior computational efficiency. Extensive experiments on both synthetic and real-world datasets, including the newsvendor problem and the bipartite matching problem, demonstrate that R-DFL not only substantially enhances the final decision quality over sequential baselines but also exhibits robust adaptability across diverse scenarios in closed-loop decision-making problems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9012\u5f52\u51b3\u7b56\u805a\u7126\u5b66\u4e60\uff08R-DFL\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u4e0b\u6e38\u4f18\u5316\u548c\u4e0a\u6e38\u9884\u6d4b\u4e4b\u95f4\u5f15\u5165\u53cc\u5411\u53cd\u9988\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u987a\u5e8f\u51b3\u7b56\u805a\u7126\u5b66\u4e60\uff08S-DFL\uff09\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709DFL\u6846\u67b6\u53d7\u9650\u4e8e\u4e25\u683c\u7684\u987a\u5e8f\u7ed3\u6784\uff08S-DFL\uff09\uff0c\u65e0\u6cd5\u6355\u6349\u590d\u6742\u4ea4\u4e92\u573a\u666f\u4e2d\u9884\u6d4b\u4e0e\u4f18\u5316\u4e4b\u95f4\u7684\u53cc\u5411\u53cd\u9988\u3002", "method": "\u63d0\u51fa\u4e86R-DFL\u6846\u67b6\uff0c\u5e76\u6269\u5c55\u4e86\u4e24\u79cd\u5fae\u5206\u65b9\u6cd5\uff1a\u57fa\u4e8e\u81ea\u52a8\u5fae\u5206\u7684\u663e\u5f0f\u5c55\u5f00\u548c\u57fa\u4e8e\u5b9a\u70b9\u65b9\u6cd5\u7684\u9690\u5f0f\u5fae\u5206\uff0c\u4ee5\u4fc3\u8fdbR-DFL\u4e2d\u7684\u9ad8\u6548\u68af\u5ea6\u4f20\u64ad\u3002", "result": "\u5728\u62a5\u7ae5\u95ee\u9898\u548c\u4e8c\u5206\u5339\u914d\u95ee\u9898\u7b49\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cR-DFL\u663e\u8457\u63d0\u9ad8\u4e86\u6700\u7ec8\u51b3\u7b56\u8d28\u91cf\uff0c\u5e76\u5728\u95ed\u73af\u51b3\u7b56\u95ee\u9898\u4e2d\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u8de8\u573a\u666f\u9002\u5e94\u6027\u3002", "conclusion": "R-DFL\u4e0d\u4ec5\u8d85\u8d8a\u4e86\u987a\u5e8f\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8fd8\u8bc1\u660e\u4e86\u5728\u590d\u6742\u51b3\u7b56\u573a\u666f\u4e2d\u53cc\u5411\u53cd\u9988\u673a\u5236\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.08077", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08077", "abs": "https://arxiv.org/abs/2511.08077", "authors": ["Jinbo Li", "Peng Liu", "Long Chen", "Witold Pedrycz", "Weiping Ding"], "title": "An Integrated Fusion Framework for Ensemble Learning Leveraging Gradient Boosting and Fuzzy Rule-Based Models", "comment": "15 pages, 6 figures. IEEE Transactions on Artificial Intelligence (2024)", "summary": "The integration of different learning paradigms has long been a focus of machine learning research, aimed at overcoming the inherent limitations of individual methods. Fuzzy rule-based models excel in interpretability and have seen widespread application across diverse fields. However, they face challenges such as complex design specifications and scalability issues with large datasets. The fusion of different techniques and strategies, particularly Gradient Boosting, with Fuzzy Rule-Based Models offers a robust solution to these challenges. This paper proposes an Integrated Fusion Framework that merges the strengths of both paradigms to enhance model performance and interpretability. At each iteration, a Fuzzy Rule-Based Model is constructed and controlled by a dynamic factor to optimize its contribution to the overall ensemble. This control factor serves multiple purposes: it prevents model dominance, encourages diversity, acts as a regularization parameter, and provides a mechanism for dynamic tuning based on model performance, thus mitigating the risk of overfitting. Additionally, the framework incorporates a sample-based correction mechanism that allows for adaptive adjustments based on feedback from a validation set. Experimental results substantiate the efficacy of the presented gradient boosting framework for fuzzy rule-based models, demonstrating performance enhancement, especially in terms of mitigating overfitting and complexity typically associated with many rules. By leveraging an optimal factor to govern the contribution of each model, the framework improves performance, maintains interpretability, and simplifies the maintenance and update of the models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u878d\u5408\u6846\u67b6\uff0c\u5c06\u6a21\u7cca\u89c4\u5219\u6a21\u578b\u4e0e\u68af\u5ea6\u63d0\u5347\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u52a8\u6001\u63a7\u5236\u56e0\u5b50\u548c\u6837\u672c\u6821\u6b63\u673a\u5236\u6765\u63d0\u5347\u6027\u80fd\u3001\u9632\u6b62\u8fc7\u62df\u5408\u5e76\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6a21\u7cca\u89c4\u5219\u6a21\u578b\u5177\u6709\u826f\u597d\u7684\u53ef\u89e3\u91ca\u6027\u4f46\u9762\u4e34\u8bbe\u8ba1\u590d\u6742\u548c\u5927\u6570\u636e\u96c6\u6269\u5c55\u6027\u95ee\u9898\u3002\u878d\u5408\u68af\u5ea6\u63d0\u5347\u6280\u672f\u53ef\u4ee5\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u7ed3\u5408\u4e24\u79cd\u8303\u5f0f\u7684\u4f18\u52bf\u3002", "method": "\u63d0\u51fa\u96c6\u6210\u878d\u5408\u6846\u67b6\uff0c\u5728\u6bcf\u6b21\u8fed\u4ee3\u4e2d\u6784\u5efa\u6a21\u7cca\u89c4\u5219\u6a21\u578b\uff0c\u901a\u8fc7\u52a8\u6001\u63a7\u5236\u56e0\u5b50\u4f18\u5316\u5176\u5728\u6574\u4f53\u96c6\u6210\u4e2d\u7684\u8d21\u732e\uff0c\u5e76\u5305\u542b\u57fa\u4e8e\u6837\u672c\u7684\u6821\u6b63\u673a\u5236\u8fdb\u884c\u81ea\u9002\u5e94\u8c03\u6574\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u51cf\u8f7b\u8fc7\u62df\u5408\u548c\u89c4\u5219\u590d\u6742\u6027\u65b9\u9762\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u63a7\u5236\u56e0\u5b50\u6765\u7ba1\u7406\u6bcf\u4e2a\u6a21\u578b\u7684\u8d21\u732e\uff0c\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\u3001\u53ef\u89e3\u91ca\u6027\u4fdd\u6301\u4ee5\u53ca\u6a21\u578b\u7ef4\u62a4\u548c\u66f4\u65b0\u7684\u7b80\u5316\u3002"}}
{"id": "2511.08086", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.08086", "abs": "https://arxiv.org/abs/2511.08086", "authors": ["Muthukumar Pandaram", "Jakob Hollenstein", "David Drexel", "Samuele Tosatto", "Antonio Rodr\u00edguez-S\u00e1nchez", "Justus Piater"], "title": "Dynamic Sparsity: Challenging Common Sparsity Assumptions for Learning World Models in Robotic Reinforcement Learning Benchmarks", "comment": null, "summary": "The use of learned dynamics models, also known as world models, can improve the sample efficiency of reinforcement learning. Recent work suggests that the underlying causal graphs of such dynamics models are sparsely connected, with each of the future state variables depending only on a small subset of the current state variables, and that learning may therefore benefit from sparsity priors. Similarly, temporal sparsity, i.e. sparsely and abruptly changing local dynamics, has also been proposed as a useful inductive bias.\n  In this work, we critically examine these assumptions by analyzing ground-truth dynamics from a set of robotic reinforcement learning environments in the MuJoCo Playground benchmark suite, aiming to determine whether the proposed notions of state and temporal sparsity actually tend to hold in typical reinforcement learning tasks.\n  We study (i) whether the causal graphs of environment dynamics are sparse, (ii) whether such sparsity is state-dependent, and (iii) whether local system dynamics change sparsely.\n  Our results indicate that global sparsity is rare, but instead the tasks show local, state-dependent sparsity in their dynamics and this sparsity exhibits distinct structures, appearing in temporally localized clusters (e.g., during contact events) and affecting specific subsets of state dimensions. These findings challenge common sparsity prior assumptions in dynamics learning, emphasizing the need for grounded inductive biases that reflect the state-dependent sparsity structure of real-world dynamics.", "AI": {"tldr": "\u672c\u6587\u6279\u5224\u6027\u5730\u68c0\u9a8c\u4e86\u5f3a\u5316\u5b66\u4e60\u4e2d\u52a8\u6001\u6a21\u578b\u7684\u7a00\u758f\u6027\u5047\u8bbe\uff0c\u901a\u8fc7\u5206\u6790MuJoCo Playground\u57fa\u51c6\u5957\u4ef6\u4e2d\u7684\u771f\u5b9e\u52a8\u6001\uff0c\u53d1\u73b0\u5168\u5c40\u7a00\u758f\u6027\u5f88\u5c11\u89c1\uff0c\u4f46\u5b58\u5728\u5c40\u90e8\u3001\u72b6\u6001\u4f9d\u8d56\u7684\u7a00\u758f\u6027\uff0c\u4e14\u8fd9\u79cd\u7a00\u758f\u6027\u5448\u73b0\u7279\u5b9a\u7684\u65f6\u95f4\u805a\u7c7b\u6a21\u5f0f\u3002", "motivation": "\u68c0\u9a8c\u5f3a\u5316\u5b66\u4e60\u4e2d\u52a8\u6001\u6a21\u578b\u7684\u4e24\u4e2a\u5e38\u89c1\u5047\u8bbe\uff1a\u56e0\u679c\u56fe\u7a00\u758f\u6027\u548c\u65f6\u95f4\u7a00\u758f\u6027\u662f\u5426\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\u6210\u7acb\uff0c\u4e3a\u5b66\u4e60\u52a8\u6001\u6a21\u578b\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u5f52\u7eb3\u504f\u7f6e\u3002", "method": "\u5206\u6790MuJoCo Playground\u57fa\u51c6\u5957\u4ef6\u4e2d\u673a\u5668\u4eba\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u7684\u771f\u5b9e\u52a8\u6001\uff0c\u7814\u7a76\u4e09\u4e2a\u95ee\u9898\uff1a(i)\u73af\u5883\u52a8\u6001\u7684\u56e0\u679c\u56fe\u662f\u5426\u7a00\u758f\uff0c(ii)\u8fd9\u79cd\u7a00\u758f\u6027\u662f\u5426\u72b6\u6001\u4f9d\u8d56\uff0c(iii)\u5c40\u90e8\u7cfb\u7edf\u52a8\u6001\u662f\u5426\u7a00\u758f\u53d8\u5316\u3002", "result": "\u5168\u5c40\u7a00\u758f\u6027\u5f88\u5c11\u89c1\uff0c\u4f46\u4efb\u52a1\u5728\u5176\u52a8\u6001\u4e2d\u8868\u73b0\u51fa\u5c40\u90e8\u3001\u72b6\u6001\u4f9d\u8d56\u7684\u7a00\u758f\u6027\uff0c\u8fd9\u79cd\u7a00\u758f\u6027\u5448\u73b0\u7279\u5b9a\u7684\u7ed3\u6784\uff0c\u51fa\u73b0\u5728\u65f6\u95f4\u5c40\u90e8\u5316\u7684\u805a\u7c7b\u4e2d\uff08\u5982\u63a5\u89e6\u4e8b\u4ef6\u671f\u95f4\uff09\u5e76\u5f71\u54cd\u7279\u5b9a\u7684\u72b6\u6001\u7ef4\u5ea6\u5b50\u96c6\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u6311\u6218\u4e86\u52a8\u6001\u5b66\u4e60\u4e2d\u5e38\u89c1\u7684\u7a00\u758f\u6027\u5148\u9a8c\u5047\u8bbe\uff0c\u5f3a\u8c03\u9700\u8981\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u52a8\u6001\u72b6\u6001\u4f9d\u8d56\u7a00\u758f\u6027\u7ed3\u6784\u7684\u63a5\u5730\u5f52\u7eb3\u504f\u7f6e\u3002"}}
{"id": "2511.08120", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08120", "abs": "https://arxiv.org/abs/2511.08120", "authors": ["Jorge Paz-Ruza", "Jo\u00e3o Gama", "Amparo Alonso-Betanzos", "Bertha Guijarro-Berdi\u00f1as"], "title": "A robust methodology for long-term sustainability evaluation of Machine Learning models", "comment": null, "summary": "Sustainability and efficiency have become essential considerations in the development and deployment of Artificial Intelligence systems, yet existing regulatory and reporting practices lack standardized, model-agnostic evaluation protocols. Current assessments often measure only short-term experimental resource usage and disproportionately emphasize batch learning settings, failing to reflect real-world, long-term AI lifecycles. In this work, we propose a comprehensive evaluation protocol for assessing the long-term sustainability of ML models, applicable to both batch and streaming learning scenarios. Through experiments on diverse classification tasks using a range of model types, we demonstrate that traditional static train-test evaluations do not reliably capture sustainability under evolving data and repeated model updates. Our results show that long-term sustainability varies significantly across models, and in many cases, higher environmental cost yields little performance benefit.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u8bc4\u4f30\u673a\u5668\u5b66\u4e60\u6a21\u578b\u957f\u671f\u53ef\u6301\u7eed\u6027\u7684\u7efc\u5408\u534f\u8bae\uff0c\u9002\u7528\u4e8e\u6279\u5904\u7406\u548c\u6d41\u5f0f\u5b66\u4e60\u573a\u666f\uff0c\u53d1\u73b0\u4f20\u7edf\u9759\u6001\u8bc4\u4f30\u65e0\u6cd5\u53ef\u9760\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u957f\u671fAI\u751f\u547d\u5468\u671f\u4e2d\u7684\u53ef\u6301\u7eed\u6027\u3002", "motivation": "\u73b0\u6709AI\u7cfb\u7edf\u76d1\u7ba1\u548c\u62a5\u544a\u5b9e\u8df5\u7f3a\u4e4f\u6807\u51c6\u5316\u3001\u6a21\u578b\u65e0\u5173\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u5f53\u524d\u8bc4\u4f30\u4ec5\u6d4b\u91cf\u77ed\u671f\u5b9e\u9a8c\u8d44\u6e90\u4f7f\u7528\uff0c\u8fc7\u5ea6\u5f3a\u8c03\u6279\u5b66\u4e60\u8bbe\u7f6e\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u957f\u671fAI\u751f\u547d\u5468\u671f\u3002", "method": "\u63d0\u51fa\u7efc\u5408\u8bc4\u4f30\u534f\u8bae\uff0c\u9002\u7528\u4e8e\u6279\u5904\u7406\u548c\u6d41\u5f0f\u5b66\u4e60\u573a\u666f\uff0c\u901a\u8fc7\u591a\u6837\u5316\u5206\u7c7b\u4efb\u52a1\u548c\u591a\u79cd\u6a21\u578b\u7c7b\u578b\u7684\u5b9e\u9a8c\u6765\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u4f20\u7edf\u9759\u6001\u8bad\u7ec3-\u6d4b\u8bd5\u8bc4\u4f30\u65e0\u6cd5\u53ef\u9760\u6355\u6349\u6570\u636e\u6f14\u53d8\u548c\u91cd\u590d\u6a21\u578b\u66f4\u65b0\u4e0b\u7684\u53ef\u6301\u7eed\u6027\uff0c\u957f\u671f\u53ef\u6301\u7eed\u6027\u5728\u4e0d\u540c\u6a21\u578b\u95f4\u5dee\u5f02\u663e\u8457\uff0c\u4e14\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\u66f4\u9ad8\u7684\u73af\u5883\u6210\u672c\u5e26\u6765\u7684\u6027\u80fd\u6536\u76ca\u5f88\u5c0f\u3002", "conclusion": "\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u6807\u51c6\u6765\u51c6\u786e\u8861\u91cfAI\u7cfb\u7edf\u7684\u957f\u671f\u53ef\u6301\u7eed\u6027\uff0c\u5f53\u524d\u8bc4\u4f30\u65b9\u6cd5\u4e0d\u8db3\u4ee5\u53cd\u6620\u771f\u5b9e\u90e8\u7f72\u73af\u5883\u4e2d\u7684\u8d44\u6e90\u6d88\u8017\u548c\u6548\u7387\u3002"}}
{"id": "2511.08409", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08409", "abs": "https://arxiv.org/abs/2511.08409", "authors": ["Junxian Li", "Xinyue Xu", "Sai Ma", "Sichao Li"], "title": "FaithAct: Faithfulness Planning and Acting in MLLMs", "comment": null, "summary": "Unfaithfulness remains a persistent challenge for large language models (LLMs), which often produce plausible yet ungrounded reasoning chains that diverge from perceptual evidence or final conclusions. We distinguish between behavioral faithfulness (alignment between reasoning and output) and perceptual faithfulness (alignment between reasoning and input), and introduce FaithEval for quantifying step-level and chain-level faithfulness by evaluating whether each claimed object is visually supported by the image. Building on these insights, we propose FaithAct, a faithfulness-first planning and acting framework that enforces evidential grounding at every reasoning step. Experiments across multiple reasoning benchmarks demonstrate that FaithAct improves perceptual faithfulness by up to 26% without degrading task accuracy compared to prompt-based and tool-augmented baselines. Our analysis shows that treating faithfulness as a guiding principle not only mitigates hallucination but also leads to more stable reasoning trajectories. This work thereby establishes a unified framework for both evaluating and enforcing faithfulness in multimodal reasoning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86FaithEval\u8bc4\u4f30\u6846\u67b6\u548cFaithAct\u89c4\u5212\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u6a21\u6001\u63a8\u7406\u4e2d\u7684\u4e0d\u5fe0\u5b9e\u95ee\u9898\uff0c\u901a\u8fc7\u5f3a\u5236\u6bcf\u4e2a\u63a8\u7406\u6b65\u9aa4\u7684\u8bc1\u636e\u57fa\u7840\u6765\u63d0\u9ad8\u611f\u77e5\u5fe0\u5b9e\u5ea6\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u63a8\u7406\u4e2d\u7ecf\u5e38\u4ea7\u751f\u770b\u4f3c\u5408\u7406\u4f46\u7f3a\u4e4f\u4f9d\u636e\u7684\u63a8\u7406\u94fe\uff0c\u8fd9\u4e9b\u63a8\u7406\u94fe\u53ef\u80fd\u4e0e\u611f\u77e5\u8bc1\u636e\u6216\u6700\u7ec8\u7ed3\u8bba\u4e0d\u7b26\uff0c\u5b58\u5728\u884c\u4e3a\u5fe0\u5b9e\u5ea6\u548c\u611f\u77e5\u5fe0\u5b9e\u5ea6\u7684\u95ee\u9898\u3002", "method": "\u533a\u5206\u884c\u4e3a\u5fe0\u5b9e\u5ea6\u548c\u611f\u77e5\u5fe0\u5b9e\u5ea6\uff0c\u5f15\u5165FaithEval\u91cf\u5316\u6b65\u9aa4\u7ea7\u548c\u94fe\u7ea7\u5fe0\u5b9e\u5ea6\uff0c\u63d0\u51faFaithAct\u6846\u67b6\u5728\u6bcf\u4e00\u6b65\u63a8\u7406\u4e2d\u5f3a\u5236\u8bc1\u636e\u57fa\u7840\u3002", "result": "\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFaithAct\u76f8\u6bd4\u57fa\u4e8e\u63d0\u793a\u548c\u5de5\u5177\u589e\u5f3a\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5c06\u611f\u77e5\u5fe0\u5b9e\u5ea6\u63d0\u9ad8\u4e8626%\uff0c\u4e14\u4e0d\u964d\u4f4e\u4efb\u52a1\u51c6\u786e\u6027\u3002", "conclusion": "\u5c06\u5fe0\u5b9e\u5ea6\u4f5c\u4e3a\u6307\u5bfc\u539f\u5219\u4e0d\u4ec5\u80fd\u51cf\u8f7b\u5e7b\u89c9\u95ee\u9898\uff0c\u8fd8\u80fd\u4ea7\u751f\u66f4\u7a33\u5b9a\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u4e3a\u591a\u6a21\u6001\u63a8\u7406\u4e2d\u7684\u5fe0\u5b9e\u5ea6\u8bc4\u4f30\u548c\u6267\u884c\u5efa\u7acb\u4e86\u7edf\u4e00\u6846\u67b6\u3002"}}
{"id": "2511.08439", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08439", "abs": "https://arxiv.org/abs/2511.08439", "authors": ["Alireza Abbaspour", "Tejaskumar Balgonda Patil", "B Ravi Kiran", "Russel Mohr", "Senthil Yogamani"], "title": "Dataset Safety in Autonomous Driving: Requirements, Risks, and Assurance", "comment": null, "summary": "Dataset integrity is fundamental to the safety and reliability of AI systems, especially in autonomous driving. This paper presents a structured framework for developing safe datasets aligned with ISO/PAS 8800 guidelines. Using AI-based perception systems as the primary use case, it introduces the AI Data Flywheel and the dataset lifecycle, covering data collection, annotation, curation, and maintenance. The framework incorporates rigorous safety analyses to identify hazards and mitigate risks caused by dataset insufficiencies. It also defines processes for establishing dataset safety requirements and proposes verification and validation strategies to ensure compliance with safety standards. In addition to outlining best practices, the paper reviews recent research and emerging trends in dataset safety and autonomous vehicle development, providing insights into current challenges and future directions. By integrating these perspectives, the paper aims to advance robust, safety-assured AI systems for autonomous driving applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eISO/PAS 8800\u6307\u5357\u7684\u7ed3\u6784\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u5f00\u53d1\u5b89\u5168\u7684\u81ea\u52a8\u9a7e\u9a76\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u6570\u636e\u6536\u96c6\u3001\u6807\u6ce8\u3001\u7ba1\u7406\u548c\u7ef4\u62a4\u7684\u5168\u751f\u547d\u5468\u671f\uff0c\u5e76\u6574\u5408\u4e86\u4e25\u683c\u7684\u5b89\u5168\u5206\u6790\u6765\u8bc6\u522b\u548c\u51cf\u8f7b\u6570\u636e\u96c6\u4e0d\u8db3\u5e26\u6765\u7684\u98ce\u9669\u3002", "motivation": "\u6570\u636e\u96c6\u5b8c\u6574\u6027\u5bf9AI\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u81ea\u52a8\u9a7e\u9a76\u9886\u57df\u3002\u5f53\u524d\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684\u6570\u636e\u96c6\u5b89\u5168\u5f00\u53d1\u6846\u67b6\uff0c\u9700\u8981\u786e\u4fdd\u6570\u636e\u96c6\u7b26\u5408\u5b89\u5168\u6807\u51c6\u5e76\u80fd\u591f\u652f\u6491\u53ef\u9760\u7684AI\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u4e86AI\u6570\u636e\u98de\u8f6e\u548c\u6570\u636e\u96c6\u751f\u547d\u5468\u671f\u6846\u67b6\uff0c\u5305\u62ec\u6570\u636e\u6536\u96c6\u3001\u6807\u6ce8\u3001\u7ba1\u7406\u548c\u7ef4\u62a4\u7b49\u9636\u6bb5\u3002\u6574\u5408\u4e86\u4e25\u683c\u7684\u5b89\u5168\u5206\u6790\u6765\u8bc6\u522b\u5371\u9669\u6e90\u548c\u98ce\u9669\uff0c\u5b9a\u4e49\u4e86\u6570\u636e\u96c6\u5b89\u5168\u8981\u6c42\u7684\u5efa\u7acb\u8fc7\u7a0b\uff0c\u5e76\u63d0\u51fa\u4e86\u9a8c\u8bc1\u548c\u9a8c\u8bc1\u7b56\u7565\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u6570\u636e\u96c6\u5b89\u5168\u6846\u67b6\uff0c\u80fd\u591f\u8bc6\u522b\u548c\u51cf\u8f7b\u6570\u636e\u96c6\u4e0d\u8db3\u5e26\u6765\u7684\u98ce\u9669\uff0c\u786e\u4fdd\u6570\u636e\u96c6\u7b26\u5408ISO/PAS 8800\u5b89\u5168\u6807\u51c6\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76AI\u7cfb\u7edf\u63d0\u4f9b\u5b89\u5168\u4fdd\u8bc1\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u6570\u636e\u96c6\u5b89\u5168\u6846\u67b6\u3001\u5b89\u5168\u5206\u6790\u548c\u9a8c\u8bc1\u7b56\u7565\uff0c\u672c\u6587\u65e8\u5728\u63a8\u8fdb\u81ea\u52a8\u9a7e\u9a76\u5e94\u7528\u4e2d\u7a33\u5065\u3001\u5b89\u5168\u4fdd\u8bc1\u7684AI\u7cfb\u7edf\u53d1\u5c55\uff0c\u4e3a\u5f53\u524d\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u63d0\u4f9b\u89c1\u89e3\u3002"}}
{"id": "2511.08548", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08548", "abs": "https://arxiv.org/abs/2511.08548", "authors": ["Shubhra Mishra", "Yuka Machino", "Gabriel Poesia", "Albert Jiang", "Joy Hsu", "Adrian Weller", "Challenger Mishra", "David Broman", "Joshua B. Tenenbaum", "Mateja Jamnik", "Cedegao E. Zhang", "Katherine M. Collins"], "title": "A Matter of Interest: Understanding Interestingness of Math Problems in Humans and Language Models", "comment": "Published at the Math-AI Workshop, NeurIPS 2025", "summary": "The evolution of mathematics has been guided in part by interestingness. From researchers choosing which problems to tackle next, to students deciding which ones to engage with, people's choices are often guided by judgments about how interesting or challenging problems are likely to be. As AI systems, such as LLMs, increasingly participate in mathematics with people -- whether for advanced research or education -- it becomes important to understand how well their judgments align with human ones. Our work examines this alignment through two empirical studies of human and LLM assessment of mathematical interestingness and difficulty, spanning a range of mathematical experience. We study two groups: participants from a crowdsourcing platform and International Math Olympiad competitors. We show that while many LLMs appear to broadly agree with human notions of interestingness, they mostly do not capture the distribution observed in human judgments. Moreover, most LLMs only somewhat align with why humans find certain math problems interesting, showing weak correlation with human-selected interestingness rationales. Together, our findings highlight both the promises and limitations of current LLMs in capturing human interestingness judgments for mathematical AI thought partnerships.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u4e24\u9879\u5b9e\u8bc1\u7814\u7a76\u63a2\u8ba8\u4e86\u4eba\u7c7b\u4e0eLLM\u5728\u6570\u5b66\u8da3\u5473\u6027\u548c\u96be\u5ea6\u8bc4\u4f30\u4e0a\u7684\u4e00\u81f4\u6027\uff0c\u53d1\u73b0LLM\u867d\u7136\u5927\u81f4\u8ba4\u540c\u4eba\u7c7b\u7684\u8da3\u5473\u6027\u6982\u5ff5\uff0c\u4f46\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u4eba\u7c7b\u5224\u65ad\u7684\u5206\u5e03\u7279\u5f81\uff0c\u4e14\u4e0e\u4eba\u7c7b\u9009\u62e9\u8da3\u5473\u6027\u7406\u7531\u7684\u76f8\u5173\u6027\u8f83\u5f31\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\uff08\u5982LLM\uff09\u8d8a\u6765\u8d8a\u591a\u5730\u53c2\u4e0e\u6570\u5b66\u7814\u7a76\u548c\u6559\u80b2\uff0c\u7406\u89e3\u5b83\u4eec\u4e0e\u4eba\u7c7b\u5728\u6570\u5b66\u95ee\u9898\u8da3\u5473\u6027\u548c\u96be\u5ea6\u5224\u65ad\u4e0a\u7684\u4e00\u81f4\u6027\u53d8\u5f97\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u4e24\u9879\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u522b\u5bf9\u4f17\u5305\u5e73\u53f0\u53c2\u4e0e\u8005\u548c\u56fd\u9645\u6570\u5b66\u5965\u6797\u5339\u514b\u7ade\u8d5b\u9009\u624b\u8fdb\u884c\u8c03\u67e5\uff0c\u6bd4\u8f83\u4eba\u7c7b\u4e0e\u591a\u79cdLLM\u5bf9\u6570\u5b66\u95ee\u9898\u8da3\u5473\u6027\u548c\u96be\u5ea6\u7684\u8bc4\u4f30\u3002", "result": "LLM\u5728\u8da3\u5473\u6027\u5224\u65ad\u4e0a\u5927\u81f4\u4e0e\u4eba\u7c7b\u4e00\u81f4\uff0c\u4f46\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u4eba\u7c7b\u5224\u65ad\u7684\u5206\u5e03\u6a21\u5f0f\uff1b\u5927\u591a\u6570LLM\u4e0e\u4eba\u7c7b\u9009\u62e9\u8da3\u5473\u6027\u7406\u7531\u7684\u76f8\u5173\u6027\u8f83\u5f31\u3002", "conclusion": "\u5f53\u524dLLM\u5728\u6355\u6349\u4eba\u7c7b\u6570\u5b66\u8da3\u5473\u6027\u5224\u65ad\u65b9\u9762\u65e2\u6709\u6f5c\u529b\u4e5f\u6709\u5c40\u9650\uff0c\u5bf9\u4e8e\u6570\u5b66AI\u601d\u7ef4\u4f19\u4f34\u5173\u7cfb\u7684\u53d1\u5c55\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.08243", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08243", "abs": "https://arxiv.org/abs/2511.08243", "authors": ["Xianshuai Shi", "Jianfeng Zhu", "Leibo Liu"], "title": "A Unified Geometric Field Theory Framework for Transformers: From Manifold Embeddings to Kernel Modulation", "comment": null, "summary": "The Transformer architecture has achieved tremendous success in natural language processing, computer vision, and scientific computing through its self-attention mechanism. However, its core components-positional encoding and attention mechanisms-have lacked a unified physical or mathematical interpretation. This paper proposes a structural theoretical framework that integrates positional encoding, kernel integral operators, and attention mechanisms for in-depth theoretical investigation. We map discrete positions (such as text token indices and image pixel coordinates) to spatial functions on continuous manifolds, enabling a field-theoretic interpretation of Transformer layers as kernel-modulated operators acting over embedded manifolds.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5c06Transformer\u4e2d\u7684\u4f4d\u7f6e\u7f16\u7801\u3001\u6838\u79ef\u5206\u7b97\u5b50\u548c\u6ce8\u610f\u529b\u673a\u5236\u6574\u5408\u8d77\u6765\u8fdb\u884c\u7406\u8bba\u7814\u7a76\u3002", "motivation": "Transformer\u67b6\u6784\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u79d1\u5b66\u8ba1\u7b97\u4e2d\u53d6\u5f97\u4e86\u5de8\u5927\u6210\u529f\uff0c\u4f46\u5176\u6838\u5fc3\u7ec4\u4ef6\uff08\u4f4d\u7f6e\u7f16\u7801\u548c\u6ce8\u610f\u529b\u673a\u5236\uff09\u7f3a\u4e4f\u7edf\u4e00\u7684\u7269\u7406\u6216\u6570\u5b66\u89e3\u91ca\u3002", "method": "\u5c06\u79bb\u6563\u4f4d\u7f6e\u6620\u5c04\u5230\u8fde\u7eed\u6d41\u5f62\u4e0a\u7684\u7a7a\u95f4\u51fd\u6570\uff0c\u5c06Transformer\u5c42\u89e3\u91ca\u4e3a\u5728\u5d4c\u5165\u6d41\u5f62\u4e0a\u4f5c\u7528\u7684\u6838\u8c03\u5236\u7b97\u5b50\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u573a\u8bba\u89e3\u91ca\u6846\u67b6\uff0c\u4e3aTransformer\u67b6\u6784\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u6570\u5b66\u57fa\u7840\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7406\u89e3Transformer\u7684\u6838\u5fc3\u7ec4\u4ef6\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89c6\u89d2\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8Transformer\u67b6\u6784\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2404.19477", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2404.19477", "abs": "https://arxiv.org/abs/2404.19477", "authors": ["Kaiwen Yu", "Renhe Fan", "Gang Wu", "Zhijin Qin"], "title": "Hybrid Bit and Semantic Communications", "comment": null, "summary": "Semantic communication technology is regarded as a method surpassing the Shannon limit of bit transmission, capable of effectively enhancing transmission efficiency. However, current approaches that directly map content to transmission symbols are challenging to deploy in practice, imposing significant limitations on the development of semantic communication. To address this challenge, we propose a hybrid bit and semantic communication system, named HybridBSC, in which encoded semantic information is inserted into bit information for transmission via conventional digital communication systems utilizing same spectrum resources. The system can be easily deployed using existing communication architecture to achieve bit and semantic information transmission. Particularly, we design a semantic insertion and extraction scheme to implement this strategy. Furthermore, we conduct experimental validation based on the pluto-based software defined radio (SDR) platform in a real wireless channel, demonstrating that the proposed strategy can simultaneously transmit semantic and bit information.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHybridBSC\u7684\u6df7\u5408\u6bd4\u7279\u548c\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\uff0c\u901a\u8fc7\u5728\u4f20\u7edf\u6570\u5b57\u901a\u4fe1\u7cfb\u7edf\u4e2d\u5c06\u7f16\u7801\u7684\u8bed\u4e49\u4fe1\u606f\u63d2\u5165\u6bd4\u7279\u4fe1\u606f\u8fdb\u884c\u4f20\u8f93\uff0c\u5b9e\u73b0\u4e86\u8bed\u4e49\u548c\u6bd4\u7279\u4fe1\u606f\u7684\u5e76\u884c\u4f20\u8f93\u3002", "motivation": "\u5f53\u524d\u76f4\u63a5\u5c06\u5185\u5bb9\u6620\u5c04\u5230\u4f20\u8f93\u7b26\u53f7\u7684\u8bed\u4e49\u901a\u4fe1\u65b9\u6cd5\u96be\u4ee5\u5b9e\u9645\u90e8\u7f72\uff0c\u9650\u5236\u4e86\u8bed\u4e49\u901a\u4fe1\u7684\u53d1\u5c55\u3002", "method": "\u8bbe\u8ba1\u4e86\u8bed\u4e49\u63d2\u5165\u548c\u63d0\u53d6\u65b9\u6848\uff0c\u5728\u4f20\u7edf\u6570\u5b57\u901a\u4fe1\u7cfb\u7edf\u4e2d\u5229\u7528\u76f8\u540c\u9891\u8c31\u8d44\u6e90\u5c06\u7f16\u7801\u7684\u8bed\u4e49\u4fe1\u606f\u63d2\u5165\u6bd4\u7279\u4fe1\u606f\u8fdb\u884c\u4f20\u8f93\u3002", "result": "\u57fa\u4e8ePluto\u8f6f\u4ef6\u5b9a\u4e49\u65e0\u7ebf\u7535\u5e73\u53f0\u5728\u771f\u5b9e\u65e0\u7ebf\u4fe1\u9053\u4e2d\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u7b56\u7565\u80fd\u591f\u540c\u65f6\u4f20\u8f93\u8bed\u4e49\u548c\u6bd4\u7279\u4fe1\u606f\u3002", "conclusion": "HybridBSC\u7cfb\u7edf\u53ef\u4ee5\u5229\u7528\u73b0\u6709\u901a\u4fe1\u67b6\u6784\u8f7b\u677e\u90e8\u7f72\uff0c\u5b9e\u73b0\u6bd4\u7279\u548c\u8bed\u4e49\u4fe1\u606f\u7684\u4f20\u8f93\u3002"}}
{"id": "2511.08281", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08281", "abs": "https://arxiv.org/abs/2511.08281", "authors": ["Yi Cai", "Thibaud Ardoin", "Mayank Gulati", "Gerhard Wunder"], "title": "Rethinking Explanation Evaluation under the Retraining Scheme", "comment": null, "summary": "Feature attribution has gained prominence as a tool for explaining model decisions, yet evaluating explanation quality remains challenging due to the absence of ground-truth explanations. To circumvent this, explanation-guided input manipulation has emerged as an indirect evaluation strategy, measuring explanation effectiveness through the impact of input modifications on model outcomes during inference. Despite the widespread use, a major concern with inference-based schemes is the distribution shift caused by such manipulations, which undermines the reliability of their assessments. The retraining-based scheme ROAR overcomes this issue by adapting the model to the altered data distribution. However, its evaluation results often contradict the theoretical foundations of widely accepted explainers. This work investigates this misalignment between empirical observations and theoretical expectations. In particular, we identify the sign issue as a key factor responsible for residual information that ultimately distorts retraining-based evaluation. Based on the analysis, we show that a straightforward reframing of the evaluation process can effectively resolve the identified issue. Building on the existing framework, we further propose novel variants that jointly structure a comprehensive perspective on explanation evaluation. These variants largely improve evaluation efficiency over the standard retraining protocol, thereby enhancing practical applicability for explainer selection and benchmarking. Following our proposed schemes, empirical results across various data scales provide deeper insights into the performance of carefully selected explainers, revealing open challenges and future directions in explainability research.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u91cd\u8bad\u7ec3\u7684\u5f52\u56e0\u65b9\u6cd5\u8bc4\u4f30\u65b9\u6848ROAR\u4e2d\u7406\u8bba\u4e0e\u5b9e\u8bc1\u7ed3\u679c\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u8bc6\u522b\u51fa\u7b26\u53f7\u95ee\u9898\u662f\u5bfc\u81f4\u8bc4\u4f30\u5931\u771f\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\u6765\u63d0\u9ad8\u8bc4\u4f30\u6548\u7387\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u63a8\u7406\u7684\u5f52\u56e0\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u800c\u57fa\u4e8e\u91cd\u8bad\u7ec3\u7684ROAR\u65b9\u6848\u867d\u7136\u89e3\u51b3\u4e86\u5206\u5e03\u504f\u79fb\uff0c\u4f46\u5176\u8bc4\u4f30\u7ed3\u679c\u4e0e\u7406\u8bba\u9884\u671f\u5b58\u5728\u77db\u76fe\uff0c\u9700\u8981\u6df1\u5165\u5206\u6790\u8fd9\u79cd\u4e0d\u4e00\u81f4\u7684\u539f\u56e0\u3002", "method": "\u8bc6\u522b\u4e86\u7b26\u53f7\u95ee\u9898\u4f5c\u4e3a\u5173\u952e\u56e0\u7d20\uff0c\u63d0\u51fa\u4e86\u7b80\u5355\u7684\u8bc4\u4f30\u8fc7\u7a0b\u91cd\u6784\u65b9\u6848\uff0c\u5e76\u57fa\u4e8e\u73b0\u6709\u6846\u67b6\u5f00\u53d1\u4e86\u65b0\u7684\u53d8\u4f53\uff0c\u5171\u540c\u6784\u5efa\u4e86\u5168\u9762\u7684\u5f52\u56e0\u8bc4\u4f30\u89c6\u89d2\u3002", "result": "\u63d0\u51fa\u7684\u6539\u8fdb\u65b9\u6848\u663e\u8457\u63d0\u9ad8\u4e86\u8bc4\u4f30\u6548\u7387\uff0c\u5728\u4e0d\u540c\u6570\u636e\u89c4\u6a21\u4e0b\u7684\u5b9e\u8bc1\u7ed3\u679c\u4e3a\u7cbe\u5fc3\u9009\u62e9\u7684\u5f52\u56e0\u65b9\u6cd5\u63d0\u4f9b\u4e86\u66f4\u6df1\u5165\u7684\u6027\u80fd\u6d1e\u5bdf\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u53ef\u89e3\u91ca\u6027\u7814\u7a76\u4e2d\u5b58\u5728\u7684\u5f00\u653e\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\uff0c\u63d0\u51fa\u7684\u8bc4\u4f30\u65b9\u6848\u589e\u5f3a\u4e86\u5f52\u56e0\u65b9\u6cd5\u9009\u62e9\u548c\u57fa\u51c6\u6d4b\u8bd5\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2511.08371", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08371", "abs": "https://arxiv.org/abs/2511.08371", "authors": ["Soham Basu", "Frank Hutter", "Danny Stoll"], "title": "Multi-objective Hyperparameter Optimization in the Age of Deep Learning", "comment": null, "summary": "While Deep Learning (DL) experts often have prior knowledge about which hyperparameter settings yield strong performance, only few Hyperparameter Optimization (HPO) algorithms can leverage such prior knowledge and none incorporate priors over multiple objectives. As DL practitioners often need to optimize not just one but many objectives, this is a blind spot in the algorithmic landscape of HPO. To address this shortcoming, we introduce PriMO, the first HPO algorithm that can integrate multi-objective user beliefs. We show PriMO achieves state-of-the-art performance across 8 DL benchmarks in the multi-objective and single-objective setting, clearly positioning itself as the new go-to HPO algorithm for DL practitioners.", "AI": {"tldr": "PriMO\u662f\u9996\u4e2a\u80fd\u591f\u6574\u5408\u591a\u76ee\u6807\u7528\u6237\u4fe1\u5ff5\u7684\u8d85\u53c2\u6570\u4f18\u5316\u7b97\u6cd5\uff0c\u57288\u4e2a\u6df1\u5ea6\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u6210\u4e3a\u6df1\u5ea6\u5b66\u4e60\u4ece\u4e1a\u8005\u7684\u9996\u9009HPO\u7b97\u6cd5\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u4e13\u5bb6\u901a\u5e38\u5177\u6709\u5173\u4e8e\u54ea\u4e9b\u8d85\u53c2\u6570\u8bbe\u7f6e\u80fd\u83b7\u5f97\u5f3a\u6027\u80fd\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u4f46\u73b0\u6709\u7684HPO\u7b97\u6cd5\u5f88\u5c11\u80fd\u5229\u7528\u8fd9\u79cd\u5148\u9a8c\u77e5\u8bc6\uff0c\u4e14\u6ca1\u6709\u7b97\u6cd5\u80fd\u6574\u5408\u591a\u76ee\u6807\u7684\u5148\u9a8c\u77e5\u8bc6\u3002", "method": "\u63d0\u51fa\u4e86PriMO\u7b97\u6cd5\uff0c\u8fd9\u662f\u9996\u4e2a\u80fd\u591f\u6574\u5408\u591a\u76ee\u6807\u7528\u6237\u4fe1\u5ff5\u7684HPO\u7b97\u6cd5\u3002", "result": "\u57288\u4e2a\u6df1\u5ea6\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPriMO\u5728\u591a\u76ee\u6807\u548c\u5355\u76ee\u6807\u8bbe\u7f6e\u4e0b\u90fd\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "PriMO\u660e\u786e\u5730\u5c06\u81ea\u5df1\u5b9a\u4f4d\u4e3a\u6df1\u5ea6\u5b66\u4e60\u4ece\u4e1a\u8005\u7684\u65b0\u9996\u9009HPO\u7b97\u6cd5\u3002"}}
{"id": "2511.08396", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.08396", "abs": "https://arxiv.org/abs/2511.08396", "authors": ["Zhiwei Zhang", "Xinyi Du", "Xuanchi Guo", "Weihao Wang", "Wenjuan Han"], "title": "EMAformer: Enhancing Transformer through Embedding Armor for Time Series Forecasting", "comment": "14 pages, 9 figures, 6 tables, accepted by AAAI2026", "summary": "Multivariate time series forecasting is crucial across a wide range of domains. While presenting notable progress for the Transformer architecture, iTransformer still lags behind the latest MLP-based models. We attribute this performance gap to unstable inter-channel relationships. To bridge this gap, we propose EMAformer, a simple yet effective model that enhances the Transformer with an auxiliary embedding suite, akin to armor that reinforces its ability. By introducing three key inductive biases, i.e., \\textit{global stability}, \\textit{phase sensitivity}, and \\textit{cross-axis specificity}, EMAformer unlocks the further potential of the Transformer architecture, achieving state-of-the-art performance on 12 real-world benchmarks and reducing forecasting errors by an average of 2.73\\% in MSE and 5.15\\% in MAE. This significantly advances the practical applicability of Transformer-based approaches for multivariate time series forecasting. The code is available on https://github.com/PlanckChang/EMAformer.", "AI": {"tldr": "EMAformer\u662f\u4e00\u79cd\u589e\u5f3aTransformer\u67b6\u6784\u7684\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u5f15\u5165\u5168\u5c40\u7a33\u5b9a\u6027\u3001\u76f8\u4f4d\u654f\u611f\u6027\u548c\u8de8\u8f74\u7279\u5f02\u6027\u4e09\u4e2a\u5173\u952e\u5f52\u7eb3\u504f\u7f6e\uff0c\u572812\u4e2a\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1Transformer\u67b6\u6784\u5728\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5176\u6027\u80fd\u4ecd\u843d\u540e\u4e8e\u6700\u65b0\u7684\u57fa\u4e8eMLP\u7684\u6a21\u578b\uff0c\u4f5c\u8005\u5c06\u8fd9\u79cd\u6027\u80fd\u5dee\u8ddd\u5f52\u56e0\u4e8e\u4e0d\u7a33\u5b9a\u7684\u901a\u9053\u95f4\u5173\u7cfb\u3002", "method": "\u63d0\u51faEMAformer\u6a21\u578b\uff0c\u901a\u8fc7\u8f85\u52a9\u5d4c\u5165\u5957\u4ef6\u589e\u5f3aTransformer\uff0c\u5f15\u5165\u4e09\u4e2a\u5173\u952e\u5f52\u7eb3\u504f\u7f6e\uff1a\u5168\u5c40\u7a33\u5b9a\u6027\u3001\u76f8\u4f4d\u654f\u611f\u6027\u548c\u8de8\u8f74\u7279\u5f02\u6027\u3002", "result": "\u572812\u4e2a\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0cMSE\u5e73\u5747\u51cf\u5c112.73%\uff0cMAE\u5e73\u5747\u51cf\u5c115.15%\u3002", "conclusion": "EMAformer\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8eTransformer\u7684\u65b9\u6cd5\u5728\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u5b9e\u9645\u9002\u7528\u6027\u3002"}}
{"id": "2511.08399", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.08399", "abs": "https://arxiv.org/abs/2511.08399", "authors": ["Hua Ye", "Hang Ding", "Siyuan Chen", "Yiyang Jiang", "Changyuan Zhang", "Xuan Zhang"], "title": "Aligning by Misaligning: Boundary-aware Curriculum Learning for Multimodal Alignment", "comment": "24 pages, 6 figures, 5 tables. Submitted to NeurIPS 2025", "summary": "Most multimodal models treat every negative pair alike, ignoring the ambiguous negatives that differ from the positive by only a small detail. We propose Boundary-Aware Curriculum with Local Attention (BACL), a lightweight add-on that turns these borderline cases into a curriculum signal. A Boundary-aware Negative Sampler gradually raises difficulty, while a Contrastive Local Attention loss highlights where the mismatch occurs. The two modules are fully differentiable and work with any off-the-shelf dual encoder. Theory predicts a fast O(1/n) error rate; practice shows up to +32% R@1 over CLIP and new SOTA on four large-scale benchmarks, all without extra labels.", "AI": {"tldr": "BACL\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u591a\u6a21\u6001\u6a21\u578b\u589e\u5f3a\u6a21\u5757\uff0c\u901a\u8fc7\u8fb9\u754c\u611f\u77e5\u8d1f\u91c7\u6837\u548c\u5bf9\u6bd4\u5c40\u90e8\u6ce8\u610f\u529b\u635f\u5931\uff0c\u5c06\u6a21\u7cca\u7684\u8d1f\u6837\u672c\u8f6c\u5316\u4e3a\u8bfe\u7a0b\u5b66\u4e60\u4fe1\u53f7\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u5bf9\u6240\u6709\u8d1f\u6837\u672c\u4e00\u89c6\u540c\u4ec1\uff0c\u5ffd\u7565\u4e86\u4e0e\u6b63\u6837\u672c\u4ec5\u5b58\u5728\u7ec6\u5fae\u5dee\u5f02\u7684\u6a21\u7cca\u8d1f\u6837\u672c\uff0c\u8fd9\u4e9b\u8fb9\u754c\u60c5\u51b5\u8574\u542b\u7740\u91cd\u8981\u7684\u5b66\u4e60\u4fe1\u53f7\u3002", "method": "\u63d0\u51fa\u8fb9\u754c\u611f\u77e5\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6cd5\uff0c\u5305\u542b\u8fb9\u754c\u611f\u77e5\u8d1f\u91c7\u6837\u5668\uff08\u9010\u6b65\u589e\u52a0\u96be\u5ea6\uff09\u548c\u5bf9\u6bd4\u5c40\u90e8\u6ce8\u610f\u529b\u635f\u5931\uff08\u5b9a\u4f4d\u4e0d\u5339\u914d\u533a\u57df\uff09\uff0c\u8fd9\u4e24\u4e2a\u6a21\u5757\u5b8c\u5168\u53ef\u5fae\u5206\u4e14\u53ef\u4e0e\u4efb\u4f55\u73b0\u6210\u7684\u53cc\u7f16\u7801\u5668\u914d\u5408\u4f7f\u7528\u3002", "result": "\u7406\u8bba\u9884\u6d4b\u8bef\u5dee\u7387\u4e3aO(1/n)\uff1b\u5b9e\u9a8c\u663e\u793a\u5728\u56db\u4e2a\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4CLIP\u63d0\u5347\u9ad8\u8fbe32%\u7684R@1\uff0c\u8fbe\u5230\u65b0\u7684SOTA\u6c34\u5e73\uff0c\u4e14\u65e0\u9700\u989d\u5916\u6807\u7b7e\u3002", "conclusion": "BACL\u901a\u8fc7\u6709\u6548\u5229\u7528\u8fb9\u754c\u8d1f\u6837\u672c\u4f5c\u4e3a\u8bfe\u7a0b\u5b66\u4e60\u4fe1\u53f7\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u6a21\u578b\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u8fb9\u754c\u60c5\u51b5\u5728\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.07891", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07891", "abs": "https://arxiv.org/abs/2511.07891", "authors": ["Yeon-Woo Choi", "Hye-Bin Shin", "Dan Li"], "title": "Toward Adaptive BCIs: Enhancing Decoding Stability via User State-Aware EEG Filtering", "comment": "4 pages, 3 figures, conference", "summary": "Brain-computer interfaces (BCIs) often suffer from limited robustness and poor long-term adaptability. Model performance rapidly degrades when user attention fluctuates, brain states shift over time, or irregular artifacts appear during interaction. To mitigate these issues, we introduce a user state-aware electroencephalogram (EEG) filtering framework that refines neural representations before decoding user intentions. The proposed method continuously estimates the user's cognitive state (e.g., focus or distraction) from EEG features and filters unreliable segments by applying adaptive weighting based on the estimated attention level. This filtering stage suppresses noisy or out-of-focus epochs, thereby reducing distributional drift and improving the consistency of subsequent decoding. Experiments on multiple EEG datasets that emulate real BCI scenarios demonstrate that the proposed state-aware filtering enhances classification accuracy and stability across different user states and sessions compared with conventional preprocessing pipelines. These findings highlight that leveraging brain-derived state information--even without additional user labels--can substantially improve the reliability of practical EEG-based BCIs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u6237\u72b6\u6001\u611f\u77e5\u7684EEG\u8fc7\u6ee4\u6846\u67b6\uff0c\u901a\u8fc7\u4f30\u8ba1\u7528\u6237\u7684\u8ba4\u77e5\u72b6\u6001\u6765\u8fc7\u6ee4\u4e0d\u53ef\u9760\u7684EEG\u7247\u6bb5\uff0c\u4ece\u800c\u63d0\u9ad8\u8111\u673a\u63a5\u53e3\u7684\u9c81\u68d2\u6027\u548c\u957f\u671f\u9002\u5e94\u6027\u3002", "motivation": "\u8111\u673a\u63a5\u53e3\u5728\u7528\u6237\u6ce8\u610f\u529b\u6ce2\u52a8\u3001\u5927\u8111\u72b6\u6001\u968f\u65f6\u95f4\u53d8\u5316\u6216\u5b58\u5728\u4e0d\u89c4\u5219\u4f2a\u5f71\u65f6\u6027\u80fd\u4f1a\u8fc5\u901f\u4e0b\u964d\uff0c\u9700\u8981\u63d0\u9ad8\u5176\u9c81\u68d2\u6027\u548c\u957f\u671f\u9002\u5e94\u6027\u3002", "method": "\u5f15\u5165\u7528\u6237\u72b6\u6001\u611f\u77e5\u7684EEG\u8fc7\u6ee4\u6846\u67b6\uff0c\u901a\u8fc7EEG\u7279\u5f81\u8fde\u7eed\u4f30\u8ba1\u7528\u6237\u7684\u8ba4\u77e5\u72b6\u6001\uff0c\u5e76\u57fa\u4e8e\u4f30\u8ba1\u7684\u6ce8\u610f\u529b\u6c34\u5e73\u5e94\u7528\u81ea\u9002\u5e94\u52a0\u6743\u6765\u8fc7\u6ee4\u4e0d\u53ef\u9760\u7247\u6bb5\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u62df\u771f\u5b9eBCI\u573a\u666f\u7684EEG\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u7684\u9884\u5904\u7406\u6d41\u7a0b\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u72b6\u6001\u611f\u77e5\u8fc7\u6ee4\u63d0\u9ad8\u4e86\u5206\u7c7b\u51c6\u786e\u6027\u548c\u7a33\u5b9a\u6027\u3002", "conclusion": "\u5229\u7528\u5927\u8111\u884d\u751f\u7684\u72b6\u6001\u4fe1\u606f\uff08\u5373\u4f7f\u6ca1\u6709\u989d\u5916\u7684\u7528\u6237\u6807\u7b7e\uff09\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u57fa\u4e8eEEG\u7684\u5b9e\u7528\u8111\u673a\u63a5\u53e3\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2511.08470", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08470", "abs": "https://arxiv.org/abs/2511.08470", "authors": ["Peng Yu", "Yike Chen", "Chao Xu", "Albert Bifet", "Jesse Read"], "title": "Binary Split Categorical feature with Mean Absolute Error Criteria in CART", "comment": null, "summary": "In the context of the Classification and Regression Trees (CART) algorithm, the efficient splitting of categorical features using standard criteria like GINI and Entropy is well-established. However, using the Mean Absolute Error (MAE) criterion for categorical features has traditionally relied on various numerical encoding methods. This paper demonstrates that unsupervised numerical encoding methods are not viable for the MAE criteria. Furthermore, we present a novel and efficient splitting algorithm that addresses the challenges of handling categorical features with the MAE criterion. Our findings underscore the limitations of existing approaches and offer a promising solution to enhance the handling of categorical data in CART algorithms.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u65e0\u76d1\u7763\u6570\u503c\u7f16\u7801\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8eMAE\u51c6\u5219\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9ad8\u6548\u5206\u88c2\u7b97\u6cd5\u6765\u5904\u7406CART\u7b97\u6cd5\u4e2d\u5206\u7c7b\u7279\u5f81\u4e0eMAE\u51c6\u5219\u7684\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u4e0a\u4f7f\u7528MAE\u51c6\u5219\u5904\u7406\u5206\u7c7b\u7279\u5f81\u65f6\u4f9d\u8d56\u5404\u79cd\u6570\u503c\u7f16\u7801\u65b9\u6cd5\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u9ad8\u6548\u7684\u5206\u88c2\u7b97\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9CART\u7b97\u6cd5\u4e2d\u5206\u7c7b\u7279\u5f81\u4e0eMAE\u51c6\u5219\u7684\u6311\u6218\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u65e0\u76d1\u7763\u6570\u503c\u7f16\u7801\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8eMAE\u51c6\u5219\uff0c\u65b0\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "conclusion": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u5206\u7c7b\u7279\u5f81\u4e0eMAE\u51c6\u5219\u65f6\u5b58\u5728\u5c40\u9650\uff0c\u65b0\u7b97\u6cd5\u4e3a\u589e\u5f3aCART\u7b97\u6cd5\u4e2d\u5206\u7c7b\u6570\u636e\u5904\u7406\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.08552", "categories": ["cs.LG", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.08552", "abs": "https://arxiv.org/abs/2511.08552", "authors": ["Ivan Butakov", "Alexander Semenenko", "Alexey Frolov", "Ivan Oseledets"], "title": "FMMI: Flow Matching Mutual Information Estimation", "comment": "11 pages", "summary": "We introduce a novel Mutual Information (MI) estimator that fundamentally reframes the discriminative approach. Instead of training a classifier to discriminate between joint and marginal distributions, we learn a normalizing flow that transforms one into the other. This technique produces a computationally efficient and precise MI estimate that scales well to high dimensions and across a wide range of ground-truth MI values.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e92\u4fe1\u606f\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u4f7f\u7528\u5f52\u4e00\u5316\u6d41\u5c06\u4e00\u4e2a\u5206\u5e03\u8f6c\u6362\u4e3a\u53e6\u4e00\u4e2a\u5206\u5e03\uff0c\u800c\u4e0d\u662f\u8bad\u7ec3\u5206\u7c7b\u5668\u6765\u533a\u5206\u8054\u5408\u5206\u5e03\u548c\u8fb9\u7f18\u5206\u5e03\u3002", "motivation": "\u4f20\u7edf\u7684\u4e92\u4fe1\u606f\u4f30\u8ba1\u65b9\u6cd5\u4f7f\u7528\u5206\u7c7b\u5668\u6765\u533a\u5206\u8054\u5408\u5206\u5e03\u548c\u8fb9\u7f18\u5206\u5e03\uff0c\u5b58\u5728\u8ba1\u7b97\u6548\u7387\u4f4e\u548c\u5728\u9ad8\u7ef4\u60c5\u51b5\u4e0b\u6027\u80fd\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u5b66\u4e60\u4e00\u4e2a\u5f52\u4e00\u5316\u6d41\uff0c\u5c06\u8054\u5408\u5206\u5e03\u8f6c\u6362\u4e3a\u8fb9\u7f18\u5206\u5e03\uff0c\u4ece\u800c\u76f4\u63a5\u4f30\u8ba1\u4e92\u4fe1\u606f\u3002", "result": "\u8be5\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u9ad8\u3001\u4f30\u8ba1\u7cbe\u5ea6\u597d\uff0c\u80fd\u591f\u5f88\u597d\u5730\u6269\u5c55\u5230\u9ad8\u7ef4\u60c5\u51b5\uff0c\u5e76\u5728\u5e7f\u6cdb\u7684\u771f\u5b9e\u4e92\u4fe1\u606f\u503c\u8303\u56f4\u5185\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u901a\u8fc7\u91cd\u65b0\u6784\u5efa\u4e92\u4fe1\u606f\u4f30\u8ba1\u95ee\u9898\uff0c\u4f7f\u7528\u5f52\u4e00\u5316\u6d41\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u7cbe\u786e\u7684\u4e92\u4fe1\u606f\u4f30\u8ba1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.08567", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.08567", "abs": "https://arxiv.org/abs/2511.08567", "authors": ["Hanqing Zhu", "Zhenyu Zhang", "Hanxian Huang", "DiJia Su", "Zechun Liu", "Jiawei Zhao", "Igor Fedorov", "Hamed Pirsiavash", "Zhizhou Sha", "Jinwon Lee", "David Z. Pan", "Zhangyang Wang", "Yuandong Tian", "Kai Sheng Tai"], "title": "The Path Not Taken: RLVR Provably Learns Off the Principals", "comment": "Preliminary version accepted as a spotlight in NeurIPS 2025 Workshop on Efficient Reasoning", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) reliably improves the reasoning performance of large language models, yet it appears to modify only a small fraction of parameters. We revisit this paradox and show that sparsity is a surface artifact of a model-conditioned optimization bias: for a fixed pretrained model, updates consistently localize to preferred parameter regions, highly consistent across runs and largely invariant to datasets and RL recipes. We mechanistically explain these dynamics with a Three-Gate Theory: Gate I (KL Anchor) imposes a KL-constrained update; Gate II (Model Geometry) steers the step off principal directions into low-curvature, spectrum-preserving subspaces; and Gate III (Precision) hides micro-updates in non-preferred regions, making the off-principal bias appear as sparsity. We then validate this theory and, for the first time, provide a parameter-level characterization of RLVR's learning dynamics: RLVR learns off principal directions in weight space, achieving gains via minimal spectral drift, reduced principal-subspace rotation, and off-principal update alignment. In contrast, SFT targets principal weights, distorts the spectrum, and even lags RLVR.\n  Together, these results provide the first parameter-space account of RLVR's training dynamics, revealing clear regularities in how parameters evolve. Crucially, we show that RL operates in a distinct optimization regime from SFT, so directly adapting SFT-era parameter-efficient fine-tuning (PEFT) methods can be flawed, as evidenced by our case studies on advanced sparse fine-tuning and LoRA variants. We hope this work charts a path toward a white-box understanding of RLVR and the design of geometry-aware, RLVR-native learning algorithms, rather than repurposed SFT-era heuristics.", "AI": {"tldr": "RLVR\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u8868\u73b0\u51fa\u53c2\u6570\u7a00\u758f\u6027\uff0c\u4f46\u8fd9\u5b9e\u9645\u4e0a\u662f\u6a21\u578b\u6761\u4ef6\u4f18\u5316\u504f\u5dee\u7684\u8868\u9762\u73b0\u8c61\u3002\u7814\u7a76\u53d1\u73b0RLVR\u5728\u6743\u91cd\u7a7a\u95f4\u4e2d\u6cbf\u975e\u4e3b\u65b9\u5411\u5b66\u4e60\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u8c31\u6f02\u79fb\u548c\u51cf\u5c11\u4e3b\u7a7a\u95f4\u65cb\u8f6c\u6765\u83b7\u5f97\u6027\u80fd\u63d0\u5347\uff0c\u800cSFT\u5219\u9488\u5bf9\u4e3b\u6743\u91cd\u5e76\u626d\u66f2\u8c31\u7ed3\u6784\u3002", "motivation": "\u89e3\u51b3RLVR\u4e2d\u770b\u4f3c\u53c2\u6570\u7a00\u758f\u4f46\u5b9e\u9645\u4e0a\u5b58\u5728\u7cfb\u7edf\u6027\u4f18\u5316\u504f\u5dee\u7684\u6096\u8bba\uff0c\u63ed\u793aRLVR\u4e0eSFT\u5728\u4f18\u5316\u673a\u5236\u4e0a\u7684\u6839\u672c\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u4e09\u95f8\u95e8\u7406\u8bba\uff1a\u95f8\u95e8I\uff08KL\u951a\uff09\u65bd\u52a0KL\u7ea6\u675f\u66f4\u65b0\uff1b\u95f8\u95e8II\uff08\u6a21\u578b\u51e0\u4f55\uff09\u5c06\u6b65\u957f\u5f15\u5bfc\u81f3\u4f4e\u66f2\u7387\u3001\u4fdd\u8c31\u5b50\u7a7a\u95f4\uff1b\u95f8\u95e8III\uff08\u7cbe\u5ea6\uff09\u5728\u975e\u504f\u597d\u533a\u57df\u9690\u85cf\u5fae\u66f4\u65b0\u3002\u901a\u8fc7\u53c2\u6570\u7ea7\u5206\u6790\u9a8c\u8bc1\u7406\u8bba\u3002", "result": "\u9996\u6b21\u63d0\u4f9b\u4e86RLVR\u5b66\u4e60\u52a8\u6001\u7684\u53c2\u6570\u7ea7\u8868\u5f81\uff1aRLVR\u5728\u6743\u91cd\u7a7a\u95f4\u7684\u975e\u4e3b\u65b9\u5411\u5b66\u4e60\uff0c\u5b9e\u73b0\u6700\u5c0f\u8c31\u6f02\u79fb\u3001\u51cf\u5c11\u4e3b\u7a7a\u95f4\u65cb\u8f6c\u548c\u79bb\u4e3b\u66f4\u65b0\u5bf9\u9f50\u3002\u76f8\u6bd4SFT\uff0cRLVR\u5728\u4fdd\u6301\u8c31\u7ed3\u6784\u65b9\u9762\u66f4\u4f18\u3002", "conclusion": "RLVR\u4e0eSFT\u5904\u4e8e\u4e0d\u540c\u7684\u4f18\u5316\u673a\u5236\uff0c\u76f4\u63a5\u9002\u914dSFT\u65f6\u4ee3\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u5b58\u5728\u7f3a\u9677\u3002\u7814\u7a76\u4e3a\u7406\u89e3RLVR\u63d0\u4f9b\u4e86\u767d\u76d2\u89c6\u89d2\uff0c\u5e76\u4e3a\u8bbe\u8ba1\u51e0\u4f55\u611f\u77e5\u7684RLVR\u539f\u751f\u5b66\u4e60\u7b97\u6cd5\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2511.07504", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07504", "abs": "https://arxiv.org/abs/2511.07504", "authors": ["Raymond Zhang", "H\u00e9di Hadiji", "Richard Combes"], "title": "Tractable Instances of Bilinear Maximization: Implementing LinUCB on Ellipsoids", "comment": "27 pages, 8 figures, 4 algos", "summary": "We consider the maximization of $x^\\top \u03b8$ over $(x,\u03b8) \\in \\mathcal{X} \\times \u0398$, with $\\mathcal{X} \\subset \\mathbb{R}^d$ convex and $\u0398\\subset \\mathbb{R}^d$ an ellipsoid. This problem is fundamental in linear bandits, as the learner must solve it at every time step using optimistic algorithms. We first show that for some sets $\\mathcal{X}$ e.g. $\\ell_p$ balls with $p>2$, no efficient algorithms exist unless $\\mathcal{P} = \\mathcal{NP}$. We then provide two novel algorithms solving this problem efficiently when $\\mathcal{X}$ is a centered ellipsoid. Our findings provide the first known method to implement optimistic algorithms for linear bandits in high dimensions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u51f8\u96c6X\u548c\u692d\u7403\u96c6\u0398\u4e0a\u6700\u5927\u5316x\u22a4\u03b8\u7684\u95ee\u9898\uff0c\u8fd9\u662f\u7ebf\u6027bandits\u4e2d\u7684\u57fa\u672c\u95ee\u9898\u3002\u4f5c\u8005\u9996\u5148\u8bc1\u660e\u5bf9\u4e8e\u67d0\u4e9b\u96c6\u5408\uff08\u5982\u2113p\u7403\uff0cp>2\uff09\uff0c\u9664\u975eP=NP\uff0c\u5426\u5219\u4e0d\u5b58\u5728\u9ad8\u6548\u7b97\u6cd5\u3002\u7136\u540e\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u7b97\u6cd5\uff0c\u5f53X\u662f\u4e2d\u5fc3\u692d\u7403\u65f6\u80fd\u9ad8\u6548\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "motivation": "\u7ebf\u6027bandits\u4e2d\u7684\u4e50\u89c2\u7b97\u6cd5\u9700\u8981\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u89e3\u51b3\u6700\u5927\u5316x\u22a4\u03b8\u7684\u95ee\u9898\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u9ad8\u7ef4\u60c5\u51b5\u4e0b\u6548\u7387\u4f4e\u4e0b\u6216\u65e0\u6cd5\u5b9e\u73b0\u3002", "method": "\u9996\u5148\u8bc1\u660e\u4e86\u67d0\u4e9b\u96c6\u5408\u4e0b\u8be5\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff08\u9664\u975eP=NP\u65e0\u9ad8\u6548\u7b97\u6cd5\uff09\uff0c\u7136\u540e\u63d0\u51fa\u4e86\u4e24\u79cd\u4e13\u95e8\u9488\u5bf9\u4e2d\u5fc3\u692d\u7403\u96c6X\u7684\u65b0\u7b97\u6cd5\u3002", "result": "\u63d0\u4f9b\u4e86\u9996\u4e2a\u5df2\u77e5\u7684\u65b9\u6cd5\u6765\u5b9e\u73b0\u9ad8\u7ef4\u7ebf\u6027bandits\u4e2d\u7684\u4e50\u89c2\u7b97\u6cd5\uff0c\u5f53X\u662f\u4e2d\u5fc3\u692d\u7403\u65f6\u80fd\u9ad8\u6548\u6c42\u89e3\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u9ad8\u7ef4\u7ebf\u6027bandits\u4e2d\u7684\u4e50\u89c2\u7b97\u6cd5\u5b9e\u73b0\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u65b9\u6cd5\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u91cd\u8981\u7a7a\u767d\u3002"}}
{"id": "2511.07831", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07831", "abs": "https://arxiv.org/abs/2511.07831", "authors": ["Zewu Zheng", "Yuanyuan Lin"], "title": "Distributionally Robust Online Markov Game with Linear Function Approximation", "comment": "To be published in the Proceedings of AAAI 2026", "summary": "The sim-to-real gap, where agents trained in a simulator face significant performance degradation during testing, is a fundamental challenge in reinforcement learning. Extansive works adopt the framework of distributionally robust RL, to learn a policy that acts robustly under worst case environment shift. Within this framework, our objective is to devise algorithms that are sample efficient with interactive data collection and large state spaces. By assuming d-rectangularity of environment dynamic shift, we identify a fundamental hardness result for learning in online Markov game, and address it by adopting minimum value assumption. Then, a novel least square value iteration type algorithm, DR-CCE-LSI, with exploration bonus devised specifically for multiple agents, is proposed to find an \\episilon-approximate robust Coarse Correlated Equilibrium(CCE). To obtain sample efficient learning, we find that: when the feature mapping function satisfies certain properties, our algorithm, DR-CCE-LSI, is able to achieve \u03b5-approximate CCE with a regret bound of O{dHmin{H,1/min{\u03c3_i}}\\sqrt{K}}, where K is the number of interacting episodes, H is the horizon length, d is the feature dimension, and \\simga_i represents the uncertainty level of player i. Our work introduces the first sample-efficient algorithm for this setting, matches the best result so far in single agent setting, and achieves minimax optimalsample complexity in terms of the feature dimension d. Meanwhile, we also conduct simulation study to validate the efficacy of our algorithm in learning a robust equilibrium.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDR-CCE-LSI\u7684\u6837\u672c\u9ad8\u6548\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684sim-to-real\u5dee\u8ddd\u95ee\u9898\uff0c\u80fd\u591f\u5728\u73af\u5883\u52a8\u6001\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\u627e\u5230\u03b5-\u8fd1\u4f3c\u9c81\u68d2\u7c97\u76f8\u5173\u5747\u8861\u3002", "motivation": "\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2dsim-to-real\u5dee\u8ddd\u95ee\u9898\uff0c\u5373\u667a\u80fd\u4f53\u5728\u6a21\u62df\u5668\u4e2d\u8bad\u7ec3\u540e\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u6027\u80fd\u663e\u8457\u4e0b\u964d\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u591a\u667a\u80fd\u4f53\u8bbe\u7f6e\u4e0b\u5b66\u4e60\u9c81\u68d2\u7b56\u7565\u3002", "method": "\u91c7\u7528\u5206\u5e03\u9c81\u68d2RL\u6846\u67b6\uff0c\u5047\u8bbe\u73af\u5883\u52a8\u6001\u53d8\u5316\u6ee1\u8db3d-\u77e9\u5f62\u6027\uff0c\u63d0\u51faDR-CCE-LSI\u7b97\u6cd5\u2014\u2014\u4e00\u79cd\u5e26\u6709\u63a2\u7d22\u5956\u52b1\u7684\u6700\u5c0f\u4e8c\u4e58\u503c\u8fed\u4ee3\u7b97\u6cd5\uff0c\u4e13\u95e8\u4e3a\u591a\u667a\u80fd\u4f53\u8bbe\u8ba1\u3002", "result": "\u5f53\u7279\u5f81\u6620\u5c04\u51fd\u6570\u6ee1\u8db3\u7279\u5b9a\u6027\u8d28\u65f6\uff0cDR-CCE-LSI\u7b97\u6cd5\u80fd\u591f\u4ee5O{dHmin{H,1/min{\u03c3_i}}\u221aK}\u7684\u9057\u61be\u754c\u5b9e\u73b0\u03b5-\u8fd1\u4f3c\u7c97\u76f8\u5173\u5747\u8861\uff0c\u5728\u7279\u5f81\u7ef4\u5ea6d\u4e0a\u8fbe\u5230\u6781\u5c0f\u6781\u5927\u6700\u4f18\u6837\u672c\u590d\u6742\u5ea6\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u5728\u8be5\u8bbe\u7f6e\u4e0b\u7684\u6837\u672c\u9ad8\u6548\u7b97\u6cd5\uff0c\u5728\u5355\u667a\u80fd\u4f53\u8bbe\u7f6e\u4e0b\u5339\u914d\u4e86\u6700\u4f73\u7ed3\u679c\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u7814\u7a76\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u5728\u9c81\u68d2\u5747\u8861\u5b66\u4e60\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
