<div id=toc></div>

# Table of Contents

- [stat.AP](#stat.AP) [Total: 1]
- [cs.LG](#cs.LG) [Total: 32]
- [cs.AI](#cs.AI) [Total: 7]
- [eess.SP](#eess.SP) [Total: 3]


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [1] [Representing caregiver burden in observational studies: Development of the Caregiver Burden Index (CareBI) using NSOC](https://arxiv.org/abs/2510.21630)
*Forough Mahpouya,Sabrina Casucci,Suzanne Sullivan,Christopher Barrick*

Main category: stat.AP

TL;DR: 本研究开发了Caregiver Burden Index (CareBI)，这是一个用于观察性研究的新型照护者负担评估工具，能够全面衡量客观、主观和人际关系三个维度的负担。


<details>
  <summary>Details</summary>
Motivation: 现有照护者负担评估工具与观察性数据集不兼容，在健康服务研究中代表性不足，需要开发适用于定量模型和观察性研究的标准化工具。

Method: 采用多步骤开发验证流程，包括识别NSOC调查项目、探索性和验证性因子分析、分数估计、解释和外部验证，使用NSOC第12轮数据。

Result: CareBI成功表征了照护者负担的三个维度，与Zarit Burden Interview保持一致，能够有效区分低、中、高负担照护者，并指导资源分配策略。

Conclusion: CareBI为将照护者指标纳入健康运营、预测建模和公共政策框架提供了可复制的工具，展示了运筹学和工业工程方法在老年照护心理社会测量中的应用潜力。

Abstract: Informal caregiving often carries a significant emotional, physical, and
financial toll, yet caregiver burden is often underrepresented in healthcare
research and methods. Existing caregiver burden instruments, while valuable in
clinical research, often lack compatibility with observational datasets
regularly used in health services research and planning. This study introduces
the Caregiver Burden Index (CareBI) developed for the National Study of
Caregiving (NSOC), that can be used to represent caregiver burden in
quantitative models and observational research studies. CareBI was developed
and validated using a multistep process that included the identification and
preparation of individual NSOC survey items, exploratory and confirmatory
factor analysis, score estimation, interpretation, and external validation. The
study used data from round 12 of the NSOC. CareBI represents three domains of
burden: objective, subjective, and interpersonal, providing a comprehensive
view of both the positive and negative aspects of caregiving. It also aligns
with the Zarit Burden Interview, a widely used tool for prospectively assessing
caregiver burden. Construct validity was assessed by comparing CareBI's
relationship with caregiver and care recipient outcomes, as well as sensitivity
to known burden-related risk and mitigation factors. Early findings affirm the
scale's utility in categorizing low-, moderate-, and high-burden caregivers and
guiding resource-oriented strategies. CareBI represents a reproducible tool for
embedding caregiver metrics into health operations, predictive modeling, and
public policy frameworks, and provides a template for applying operations
research and industrial engineering methods to psychosocial measurement
challenges in aging and long-term care.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [Incentivizing Consistent, Effective and Scalable Reasoning Capability in Audio LLMs via Reasoning Process Rewards](https://arxiv.org/abs/2510.20867)
*Jiajun Fan,Roger Ren,Jingyuan Li,Rahul Pandey,Prashanth Gurunath Shivakumar,Ivan Bulyko,Ankur Gandhe,Ge Liu,Yile Gu*

Main category: cs.LG

TL;DR: CESAR通过在线强化学习框架解决音频大语言模型中的推理逆缩放问题，通过奖励推理过程而非结果验证，在MMAU Test-mini上达到SOTA性能，接近人类水平的MMSU推理任务表现。


<details>
  <summary>Details</summary>
Motivation: 音频大语言模型中的推理作用被广泛忽视，引入推理过程往往在推理时降低而非提升性能，这种现象被称为测试时逆缩放，即更长的推理链会产生更差的结果。

Method: 引入CESAR框架，采用在线强化学习，使用Group Relative Policy Optimization和多方面奖励套件，激励正确性、格式、一致性、结构化分析模式、因果推理、领域知识整合和校准推理深度。

Result: 解决了测试时逆缩放问题，在MMAU Test-mini上达到最先进结果，显著优于Gemini 2.5 Pro和GPT-4o Audio，在MMSU推理任务上接近人类水平表现。

Conclusion: CESAR为音频大语言模型开发稳健且可扩展的推理建立了原则性方法，增强的推理创造了协同效应，同时改善了多模态推理和感知能力。

Abstract: The role of reasoning in Audio Large Language Models remains widely
underexplored, as introducing a reasoning process often degrades rather than
improves performance during inference, a phenomenon we term test-time inverse
scaling, where longer reasoning chains yield progressively worse results. We
demonstrate that this stems not from fundamental limitations of reasoning
itself, but from inadequate training: models without proper guidance for the
reasoning process produce hallucinatory, inconsistent reasoning that
accumulates errors over longer chains. To address these challenges, we
introduce CESAR (Consistent, Effective, and Scalable Audio Reasoners), shifting
from outcome verification to rewarding the reasoning process. Our online
reinforcement learning framework employs Group Relative Policy Optimization
with a multi-faceted reward suite that incentivizes not only correctness and
format but also consistency, structured analytical patterns, causal reasoning,
domain-knowledge integration, and calibrated reasoning depth. CESAR resolves
test-time inverse scaling, transforming reasoning from detriments into gains
while revealing model-specific ``reasoning sweet spots", where performance
peaks during test-time scaling. We achieve state-of-the-art results on MMAU
Test-mini, substantially outperforming Gemini 2.5 Pro and GPT-4o Audio, and
near-human-level performance on MMSU reasoning tasks. Through AI-as-judge
evaluations and qualitative comparisons, we provide both quantitative and
qualitative validation of our improved reasoning quality. Importantly, enhanced
reasoning creates synergistic effects, simultaneously improving multimodal
reasoning and perception capabilities. Overall, CESAR establishes a principled
method for developing robust and scalable reasoning in Audio LLMs.

</details>


### [3] [CC-GRMAS: A Multi-Agent Graph Neural System for Spatiotemporal Landslide Risk Assessment in High Mountain Asia](https://arxiv.org/abs/2510.20875)
*Mihir Panchal,Ying-Jung Chen,Surya Parkash*

Main category: cs.LG

TL;DR: CC-GRMAS是一个利用卫星观测和环境信号提高滑坡预测准确性的框架，通过三个相互关联的智能体（预测、规划、执行）实现实时态势感知、响应规划和干预。


<details>
  <summary>Details</summary>
Motivation: 滑坡是日益严重的气候诱发灾害，特别是在高亚洲山区，尽管卫星和时序数据获取增加，但及时检测和灾害响应仍然不发达且分散。

Method: 采用多智能体协调框架，整合卫星观测和环境信号，通过预测、规划和执行三个智能体的协作来增强滑坡预测准确性。

Result: 该框架提供了可扩展的主动解决方案，能够实现实时态势感知、响应规划和干预，提高气候韧性灾害准备能力。

Conclusion: CC-GRMAS通过整合本地环境因素和操作化多智能体协调，为脆弱山区地形提供了可扩展和主动的气候韧性灾害准备解决方案。

Abstract: Landslides are a growing climate induced hazard with severe environmental and
human consequences, particularly in high mountain Asia. Despite increasing
access to satellite and temporal datasets, timely detection and disaster
response remain underdeveloped and fragmented. This work introduces CC-GRMAS, a
framework leveraging a series of satellite observations and environmental
signals to enhance the accuracy of landslide forecasting. The system is
structured around three interlinked agents Prediction, Planning, and Execution,
which collaboratively enable real time situational awareness, response
planning, and intervention. By incorporating local environmental factors and
operationalizing multi agent coordination, this approach offers a scalable and
proactive solution for climate resilient disaster preparedness across
vulnerable mountainous terrains.

</details>


### [4] [Safety Assessment in Reinforcement Learning via Model Predictive Control](https://arxiv.org/abs/2510.20955)
*Jeff Pflueger,Michael Everett*

Main category: cs.LG

TL;DR: 提出一种基于可逆性的模型自由强化学习方法，通过模型预测路径积分控制检查学习策略的安全性，无需显式动态模型或安全约束知识即可防止训练过程中的安全问题。


<details>
  <summary>Details</summary>
Motivation: 模型自由强化学习方法缺乏形式化安全保证，现有方法通常需要详细的安全规范知识。许多难以明确规范的安全问题最好通过不变性来表征，因此利用可逆性来预防训练过程中的安全问题。

Method: 使用模型预测路径积分控制来检查学习策略提出的动作在训练过程中的安全性。该方法只需要查询黑盒动态的能力，而不需要动态或安全约束的显式知识。

Result: 实验结果表明，所提出的算法在所有不安全动作之前成功中止，同时与允许违反安全性的基线PPO方法相比，仍能实现相当的训练进展。

Conclusion: 基于可逆性的方法能够有效防止训练过程中的安全问题，仅需查询黑盒动态即可实现安全保证，在保持训练效率的同时确保安全性。

Abstract: Model-free reinforcement learning approaches are promising for control but
typically lack formal safety guarantees. Existing methods to shield or
otherwise provide these guarantees often rely on detailed knowledge of the
safety specifications. Instead, this work's insight is that many
difficult-to-specify safety issues are best characterized by invariance.
Accordingly, we propose to leverage reversibility as a method for preventing
these safety issues throughout the training process. Our method uses
model-predictive path integral control to check the safety of an action
proposed by a learned policy throughout training. A key advantage of this
approach is that it only requires the ability to query the black-box dynamics,
not explicit knowledge of the dynamics or safety constraints. Experimental
results demonstrate that the proposed algorithm successfully aborts before all
unsafe actions, while still achieving comparable training progress to a
baseline PPO approach that is allowed to violate safety.

</details>


### [5] [Reducing the Probability of Undesirable Outputs in Language Models Using Probabilistic Inference](https://arxiv.org/abs/2510.21184)
*Stephen Zhao,Aidan Li,Rob Brekelmans,Roger Grosse*

Main category: cs.LG

TL;DR: RePULSe是一种新的强化学习训练方法，通过增加额外损失函数来减少不良输出的概率，同时保持平均奖励性能。


<details>
  <summary>Details</summary>
Motivation: 标准强化学习方法优化平均奖励，但减少不良输出概率的方法通常会牺牲平均性能。需要改进这种权衡关系。

Method: 在标准RL损失基础上增加额外损失，使用学习到的建议来引导采样低奖励输出，然后降低这些输出的概率。

Result: 实验表明RePULSe在期望奖励与不良输出概率之间提供了更好的权衡，并且比标准RL对齐方法和替代方案更具对抗鲁棒性。

Conclusion: RePULSe方法能够有效改善语言模型对齐中的权衡问题，在保持良好平均性能的同时减少不良输出的概率。

Abstract: Reinforcement learning (RL) has become a predominant technique to align
language models (LMs) with human preferences or promote outputs which are
deemed to be desirable by a given reward function. Standard RL approaches
optimize average reward, while methods explicitly focused on reducing the
probability of undesired outputs typically come at a cost to average-case
performance. To improve this tradeoff, we introduce RePULSe, a new training
method that augments the standard RL loss with an additional loss that uses
learned proposals to guide sampling low-reward outputs, and then reduces those
outputs' probability. We run experiments demonstrating that RePULSe produces a
better tradeoff of expected reward versus the probability of undesired outputs
and is more adversarially robust, compared to standard RL alignment approaches
and alternatives.

</details>


### [6] [Towards Scalable Oversight with Collaborative Multi-Agent Debate in Error Detection](https://arxiv.org/abs/2510.20963)
*Yongqiang Chen,Gang Niu,James Cheng,Bo Han,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 本文提出了一种新的协作式多智能体辩论协议ColMAD，将多智能体辩论重新定义为非零和博弈，以解决传统竞争性辩论中的辩论黑客问题，显著提升了大型语言模型错误检测的性能。


<details>
  <summary>Details</summary>
Motivation: 传统多智能体辩论协议将辩论视为零和博弈，导致辩论者倾向于误导法官而非寻求真相，出现辩论黑客现象，反而引入更多错误并表现不如单智能体方法。

Method: 提出协作式多智能体辩论协议ColMAD，鼓励多个智能体以支持性方式相互批评，从而相互补充缺失的观点，使法官智能体能够基于更全面的证据做出更有信息量的结论。

Result: 实验表明，ColMAD在错误检测任务上显著优于先前竞争性多智能体辩论方法19%，并相比单智能体方法带来了非平凡的改进。

Conclusion: 协作式多智能体辩论协议能够有效缓解辩论黑客问题，通过将辩论重新定义为非零和博弈，显著提升了大型语言模型错误检测的准确性和可靠性。

Abstract: Accurate detection of errors in large language models (LLM) responses is
central to the success of scalable oversight, or providing effective
supervision to superhuman intelligence. Yet, self-diagnosis is often unreliable
on complex tasks unless aided by reliable external feedback. Multi-agent debate
(MAD) seems to be a natural alternative to external feedback: multiple LLMs
provide complementary perspectives and cross-checks for error detection.
However, prior MAD protocols frame debate as a zero-sum game, where the
debaters compete to win the game instead of seeking the truth. Consequently, it
leads to debate hacking: debaters tend to mislead the judge by misinterpreting
the task or presenting overconfident claims, which introduce more mistakes and
underperform single-agent methods. To mitigate the issue, we introduce a new
collaborative MAD protocol, termed ColMAD, that reframes MAD as a non-zero sum
game. Specifically, ColMAD encourages multiple agents to criticize each other
in a supportive way, such that they can complement the missing points of each
other. Therefore, the judge agent can make a more informative conclusion based
on more comprehensive evidence. Empirically, we show that ColMAD significantly
outperforms previous competitive MAD by 19% and brings non-trivial improvements
over single-agent methods in error detection.

</details>


### [7] [A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization](https://arxiv.org/abs/2510.21314)
*Xuan Tang,Jichu Li,Difan Zou*

Main category: cs.LG

TL;DR: 本文提出了首个分析自适应优化器在浮点量化下的收敛理论框架，证明了Adam和Muon在低精度训练中仍能保持接近全精度的收敛速率，条件是尾数长度随迭代次数对数增长。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型的快速发展使得低精度训练对于减少内存、提高效率以及支持更大模型和数据集变得至关重要。然而，现有的自适应优化器收敛理论假设所有组件都是精确的，忽略了硬件感知量化，因此无法解释为什么低精度训练仍然有效。

Method: 引入首个理论框架来分析自适应优化器（包括Adam和Muon）在梯度、权重和优化器状态（如动量估计）的浮点量化下的收敛性。在标准随机梯度假设下，推导了平滑非凸目标上的收敛速率，明确表征了不同组件的量化误差如何影响收敛。

Result: 证明了两种算法在尾数长度仅随迭代次数对数增长的情况下，都能保持接近其全精度对应物的收敛速率。分析还显示，Adam对权重和第二矩量化高度敏感，而Muon需要更弱的误差控制，因此可能更鲁棒。

Conclusion: 这些结果缩小了低精度训练方法的经验成功与理论理解之间的差距。在合成和真实数据上的数值实验证实了理论分析。

Abstract: The rapid scaling of large language models (LLMs) has made low-precision
training essential for reducing memory, improving efficiency, and enabling
larger models and datasets. Existing convergence theories for adaptive
optimizers, however, assume all components are exact and neglect hardware-aware
quantization, leaving open the question of why low-precision training remains
effective. We introduce the first theoretical framework for analyzing the
convergence of adaptive optimizers, including Adam and Muon, under
floating-point quantization of gradients, weights, and optimizer states (e.g.,
moment estimates). Within this framework, we derive convergence rates on smooth
non-convex objectives under standard stochastic gradient assumptions,
explicitly characterizing how quantization errors from different components
affect convergence. We show that both algorithms retain rates close to their
full-precision counterparts provided mantissa length scales only
logarithmically with the number of iterations. Our analysis further reveals
that Adam is highly sensitive to weights and second-moment quantization due to
its reliance on $\beta_2 \to 1$, while Muon requires weaker error control and
is thus potentially more robust. These results narrow the gap between empirical
success and theoretical understanding of low-precision training methods.
Numerical experiments on synthetic and real-world data corroborate our theory.

</details>


### [8] [On the accuracy of implicit neural representations for cardiovascular anatomies and hemodynamic fields](https://arxiv.org/abs/2510.20970)
*Jubilee Lee,Daniele E. Schiavazzi*

Main category: cs.LG

TL;DR: 该论文评估了隐式神经表示(INRs)在血流动力学场压缩和心血管解剖表示中的性能，通过多种策略缓解谱偏差，在主动脉血流场中实现了约230倍的压缩比，解剖误差低于1.6mm。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示作为强大的知识表示框架，在特定领域应用中的准确性尚未充分了解，需要评估其在血流动力学场压缩和心血管解剖表示中的性能。

Method: 研究了多种缓解谱偏差的策略，包括专用激活函数、固定和可训练位置编码、非线性核的线性组合，在空间和时间变化的主主动脉血流场及48个胸腔主动脉解剖结构上进行测试。

Result: 在主动脉血流场中实现了约230倍的压缩比，压力最大绝对误差为1 mmHg，速度误差为5-10 cm/s；解剖结构平均和最大绝对误差分别低于0.5mm和1.6mm。SIREN、MFN-Gabor和MHE架构表现最佳。

Conclusion: 隐式神经表示在血流动力学场压缩和心血管解剖表示中表现出色，能够实现高压缩比和低误差，为医学图像和模拟数据的有效表示提供了有前景的解决方案。

Abstract: Implicit neural representations (INRs, also known as neural fields) have
recently emerged as a powerful framework for knowledge representation,
synthesis, and compression. By encoding fields as continuous functions within
the weights and biases of deep neural networks-rather than relying on voxel- or
mesh-based structured or unstructured representations-INRs offer both
resolution independence and high memory efficiency. However, their accuracy in
domain-specific applications remains insufficiently understood. In this work,
we assess the performance of state-of-the-art INRs for compressing hemodynamic
fields derived from numerical simulations and for representing cardiovascular
anatomies via signed distance functions. We investigate several strategies to
mitigate spectral bias, including specialized activation functions, both fixed
and trainable positional encoding, and linear combinations of nonlinear
kernels. On realistic, space- and time-varying hemodynamic fields in the
thoracic aorta, INRs achieved remarkable compression ratios of up to
approximately 230, with maximum absolute errors of 1 mmHg for pressure and 5-10
cm/s for velocity, without extensive hyperparameter tuning. Across 48 thoracic
aortic anatomies, the average and maximum absolute anatomical discrepancies
were below 0.5 mm and 1.6 mm, respectively. Overall, the SIREN, MFN-Gabor, and
MHE architectures demonstrated the best performance. Source code and data is
available at https://github.com/desResLab/nrf.

</details>


### [9] [Benchmarking Catastrophic Forgetting Mitigation Methods in Federated Time Series Forecasting](https://arxiv.org/abs/2510.21491)
*Khaled Hallak,Oudom Kem*

Main category: cs.LG

TL;DR: 提出了首个针对联邦持续时间序列预测中灾难性遗忘问题的基准框架，在12个分散客户端上系统评估了多种缓解策略，为联邦时间序列预测系统的持续学习提供了重要工具和见解。


<details>
  <summary>Details</summary>
Motivation: 灾难性遗忘在持续学习中是一个持续挑战，特别是在具有非独立同分布时间序列数据的联邦学习环境中。现有研究主要集中在视觉领域的分类任务，而物联网和边缘应用中普遍存在的基于回归的预测设置尚未得到充分探索。

Method: 使用北京多站点空气质量数据集，在12个分散客户端上系统评估了多种灾难性遗忘缓解策略，包括回放、弹性权重巩固、无遗忘学习和突触智能等方法。

Result: 建立了首个针对联邦持续时间序列预测中灾难性遗忘的基准，并对最先进方法进行了全面的比较分析。

Conclusion: 这项工作为推进联邦时间序列预测系统中的持续学习提供了必要的工具和见解，包括新的基准框架、比较分析结果和可复现的开源框架。

Abstract: Catastrophic forgetting (CF) poses a persistent challenge in continual
learning (CL), especially within federated learning (FL) environments
characterized by non-i.i.d. time series data. While existing research has
largely focused on classification tasks in vision domains, the regression-based
forecasting setting prevalent in IoT and edge applications remains
underexplored. In this paper, we present the first benchmarking framework
tailored to investigate CF in federated continual time series forecasting.
Using the Beijing Multi-site Air Quality dataset across 12 decentralized
clients, we systematically evaluate several CF mitigation strategies, including
Replay, Elastic Weight Consolidation, Learning without Forgetting, and Synaptic
Intelligence. Key contributions include: (i) introducing a new benchmark for CF
in time series FL, (ii) conducting a comprehensive comparative analysis of
state-of-the-art methods, and (iii) releasing a reproducible open-source
framework. This work provides essential tools and insights for advancing
continual learning in federated time-series forecasting systems.

</details>


### [10] [GPU Memory Requirement Prediction for Deep Learning Task Based on Bidirectional Gated Recurrent Unit Optimization Transformer](https://arxiv.org/abs/2510.20985)
*Chao Wang,Zhizhao Wen,Ruoxin Zhang,Puyang Xu,Yifan Jiang*

Main category: cs.LG

TL;DR: 本文提出了一种集成双向门控循环单元(BiGRU)来优化Transformer架构的深度学习模型，用于提高GPU内存需求预测的准确性。实验表明该模型在MSE、RMSE、MAE和R2等指标上均优于决策树、随机森林、Adaboost和XGBoost等传统机器学习方法。


<details>
  <summary>Details</summary>
Motivation: 为满足深度学习任务中对GPU内存资源准确预测的迫切需求，解决传统机器学习方法在内存需求预测精度上的不足。

Method: 创新性地提出将双向门控循环单元(BiGRU)集成到Transformer架构中，构建BiGRU Transformer优化模型，并与四种基准机器学习模型进行对比实验。

Result: BiGRU Transformer模型在所有对比模型中取得了最低的MSE和RMSE值，在MAE和R2指标上也表现优异，预测性能全面超越基准机器学习方法。

Conclusion: 基于BiGRU优化的Transformer模型能够高效准确地完成深度学习任务中的GPU内存需求预测，相比传统机器学习方法显著提升了预测精度，为优化深度学习任务资源调度和管理提供了技术支持和理论依据。

Abstract: In response to the increasingly critical demand for accurate prediction of
GPU memory resources in deep learning tasks, this paper deeply analyzes the
current research status and innovatively proposes a deep learning model that
integrates bidirectional gated recurrent units (BiGRU) to optimize the
Transformer architecture, aiming to improve the accuracy of memory demand
prediction. To verify the effectiveness of the model, a carefully designed
comparative experiment was conducted, selecting four representative basic
machine learning models: decision tree, random forest, Adaboost, and XGBoost as
benchmarks. The detailed experimental results show that the BiGRU Transformer
optimization model proposed in this paper exhibits significant advantages in
key evaluation indicators: in terms of mean square error (MSE) and root mean
square error (RMSE), the model achieves the lowest value among all comparison
models, and its predicted results have the smallest deviation from the actual
values; In terms of mean absolute error (MAE) and coefficient of determination
(R2) indicators, the model also performs well and the results are balanced and
stable, with comprehensive predictive performance far exceeding the benchmark
machine learning methods compared. In summary, the Transformer model based on
bidirectional gated recurrent unit optimization successfully constructed in
this study can efficiently and accurately complete GPU memory demand prediction
tasks in deep learning tasks, and its prediction accuracy has been
significantly improved compared to traditional machine learning methods. This
research provides strong technical support and reliable theoretical basis for
optimizing resource scheduling and management of deep learning tasks, and
improving the utilization efficiency of computing clusters.

</details>


### [11] [Few-Shot Knowledge Distillation of LLMs With Counterfactual Explanations](https://arxiv.org/abs/2510.21631)
*Faisal Hamman,Pasan Dissanayake,Yanjun Fu,Sanghamitra Dutta*

Main category: cs.LG

TL;DR: 提出了一种名为CoD的反事实解释增强蒸馏方法，用于解决小样本任务感知知识蒸馏中的数据不足问题，通过利用反事实解释来精确映射教师模型的决策边界。


<details>
  <summary>Details</summary>
Motivation: 现有任务感知蒸馏方法需要大量数据，但在实际场景中数据可能稀缺或获取成本高昂。

Method: CoD策略通过系统性地注入反事实解释（CFEs）来进行小样本任务感知知识蒸馏，利用能够以最小扰动翻转教师模型预测的输入来精确映射决策边界。

Result: 在多个数据集和LLM上的实验表明，CoD在小样本场景（低至8-512个样本）中优于标准蒸馏方法，仅使用基线方法一半的原始样本及其对应的CFEs仍能提升性能。

Conclusion: CoD方法通过反事实解释有效解决了小样本知识蒸馏中的数据稀缺问题，提供了统计和几何理论保证，证明了CFEs在改善参数估计和决策边界模仿方面的有效性。

Abstract: Knowledge distillation is a promising approach to transfer capabilities from
complex teacher models to smaller, resource-efficient student models that can
be deployed easily, particularly in task-aware scenarios. However, existing
methods of task-aware distillation typically require substantial quantities of
data which may be unavailable or expensive to obtain in many practical
scenarios. In this paper, we address this challenge by introducing a novel
strategy called Counterfactual-explanation-infused Distillation CoD for
few-shot task-aware knowledge distillation by systematically infusing
counterfactual explanations. Counterfactual explanations (CFEs) refer to inputs
that can flip the output prediction of the teacher model with minimum
perturbation. Our strategy CoD leverages these CFEs to precisely map the
teacher's decision boundary with significantly fewer samples. We provide
theoretical guarantees for motivating the role of CFEs in distillation, from
both statistical and geometric perspectives. We mathematically show that CFEs
can improve parameter estimation by providing more informative examples near
the teacher's decision boundary. We also derive geometric insights on how CFEs
effectively act as knowledge probes, helping the students mimic the teacher's
decision boundaries more effectively than standard data. We perform experiments
across various datasets and LLMs to show that CoD outperforms standard
distillation approaches in few-shot regimes (as low as 8-512 samples). Notably,
CoD only uses half of the original samples used by the baselines, paired with
their corresponding CFEs and still improves performance.

</details>


### [12] [More Than Memory Savings: Zeroth-Order Optimization Mitigates Forgetting in Continual Learning](https://arxiv.org/abs/2510.21019)
*Wanhao Yu,Zheng Wang,Shuteng Niu,Sen Lin,Li Yang*

Main category: cs.LG

TL;DR: 本文研究了零阶优化在持续学习中的应用，发现它能通过产生更平坦的损失景观来减少遗忘，但会牺牲可塑性。作者提出ZO-FC方法，结合零阶优化的稳定性和一阶优化的适应性，实现了内存高效的持续学习。


<details>
  <summary>Details</summary>
Motivation: 探索零阶优化作为解决持续学习中可塑性-稳定性-效率三难问题的新方法，特别是在梯度计算昂贵或不切实际的场景下。

Method: 通过理论分析和实证研究评估零阶优化在持续学习中的应用，并提出ZO-FC方法：对单个基于适配器的PEFT模块应用零阶优化，同时使用一阶优化更新分类器。

Result: 零阶优化自然产生更平坦的损失景观，减少遗忘，但会损害可塑性，特别是在训练预算受限时。ZO-FC方法在稳定性和可塑性之间取得了有效平衡。

Conclusion: ZO-FC提供了一种实用且内存高效的持续学习解决方案，特别适用于设备端部署场景，成功平衡了稳定性和可塑性需求。

Abstract: Zeroth-order (ZO) optimization has gained attention as a memory-efficient
alternative to first-order (FO) methods, particularly in settings where
gradient computation is expensive or even impractical. Beyond its memory
efficiency, in this work, we investigate ZO optimization for continual learning
(CL) as a novel approach to address the plasticity-stability-efficiency
trilemma. Through theoretical analysis and empirical evidence, we show that ZO
optimization naturally leads to flatter loss landscapes, which in turn reduce
forgetting in CL. However, this stability comes at a cost of plasticity: due to
its imprecise gradient estimates and slower convergence, ZO optimization tends
to be less effective than FO in acquiring new task-specific knowledge,
particularly under constrained training budgets. To better understand this
trade-off, we conduct a holistic evaluation of ZO optimization applied to
various existing CL methods. Our findings reveal that ZO optimization enhances
stability but often undermines plasticity, particularly when used with
learnable classifiers. Motivated by this insight, we propose ZO-FC, a simple
but effective approach that applies ZO optimization to a single adapter-based
PEFT module with FO optimized classifier. This design leverages the stability
benefits of ZO while preserving the adaptability of FO updates with negligible
memory overhead. Experiments demonstrate that ZO-FC achieves an effective
balance between stability and plasticity, offering a practical and
memory-efficient solution for on-device CL.

</details>


### [13] [Elementary, My Dear Watson: Non-Invasive Neural Keyword Spotting in the LibriBrain Dataset](https://arxiv.org/abs/2510.21038)
*Gereon Elvers,Gilad Landau,Oiwi Parker Jones*

Main category: cs.LG

TL;DR: 该论文提出了关键词检测作为脑机接口的实用中间任务，使用LibriBrain语料库提供标准化基准，采用AUPRC和FA/h作为评估指标，并发布了参考模型和工具库。


<details>
  <summary>Details</summary>
Motivation: 当前脑机接口基准主要针对简单的语音检测和音素分类任务，而实际应用如脑到文本转换仍难以实现。作者希望找到一种既实用又保护隐私的中间任务来推动脑机接口发展。

Method: 使用52小时的LibriBrain语料库，提供标准化的训练/验证/测试分割，采用针对极端类别不平衡的评估协议，使用AUPRC和FA/h作为评估指标，开发了基于1-D Conv/ResNet的紧凑基线模型，结合焦点损失和top-k池化。

Result: 参考模型在保留会话上实现了约13倍于置换基线的AUPRC，证明了任务的可行性。探索性分析显示：性能随训练时间对数线性提升，词频和词长等词级因素系统地调节检测能力。

Conclusion: 关键词检测是脑机接口的一个可行且实用的中间任务，提出的基准和工具为社区提供了标准化评估框架，为脑到文本转换等应用铺平了道路。

Abstract: Non-invasive brain-computer interfaces (BCIs) are beginning to benefit from
large, public benchmarks. However, current benchmarks target relatively simple,
foundational tasks like Speech Detection and Phoneme Classification, while
application-ready results on tasks like Brain-to-Text remain elusive. We
propose Keyword Spotting (KWS) as a practically applicable, privacy-aware
intermediate task. Using the deep 52-hour, within-subject LibriBrain corpus, we
provide standardized train/validation/test splits for reproducible
benchmarking, and adopt an evaluation protocol tailored to extreme class
imbalance. Concretely, we use area under the precision-recall curve (AUPRC) as
a robust evaluation metric, complemented by false alarms per hour (FA/h) at
fixed recall to capture user-facing trade-offs. To simplify deployment and
further experimentation within the research community, we are releasing an
updated version of the pnpl library with word-level dataloaders and Colab-ready
tutorials. As an initial reference model, we present a compact 1-D Conv/ResNet
baseline with focal loss and top-k pooling that is trainable on a single
consumer-class GPU. The reference model achieves approximately 13x the
permutation baseline AUPRC on held-out sessions, demonstrating the viability of
the task. Exploratory analyses reveal: (i) predictable within-subject scaling -
performance improves log-linearly with more training hours - and (ii) the
existence of word-level factors (frequency and duration) that systematically
modulate detectability.

</details>


### [14] [On the Sample Complexity of Differentially Private Policy Optimization](https://arxiv.org/abs/2510.21060)
*Yi He,Xingyu Zhou*

Main category: cs.LG

TL;DR: 该论文首次对差分隐私策略优化的样本复杂度进行理论研究，为策略梯度、自然策略梯度等广泛使用的策略优化算法在隐私约束下的性能提供了理论分析框架。


<details>
  <summary>Details</summary>
Motivation: 随着策略优化在敏感领域（如机器人、医疗、大语言模型训练）的广泛应用，隐私保护问题日益突出，需要从理论上研究差分隐私策略优化的样本复杂度。

Method: 首先形式化了适合策略优化的差分隐私定义，解决了在线学习动态和隐私单元定义的固有挑战，然后通过统一框架系统分析了PG、NPG等算法在DP约束下的样本复杂度。

Result: 理论结果表明隐私成本通常表现为样本复杂度的低阶项，同时揭示了私有策略优化设置中的一些微妙但重要的观察。

Conclusion: 研究为隐私保护策略优化算法提供了有价值的实践见解，证明了在适当设计下，隐私保护可以在不显著增加样本复杂度的情况下实现。

Abstract: Policy optimization (PO) is a cornerstone of modern reinforcement learning
(RL), with diverse applications spanning robotics, healthcare, and large
language model training. The increasing deployment of PO in sensitive domains,
however, raises significant privacy concerns. In this paper, we initiate a
theoretical study of differentially private policy optimization, focusing
explicitly on its sample complexity. We first formalize an appropriate
definition of differential privacy (DP) tailored to PO, addressing the inherent
challenges arising from on-policy learning dynamics and the subtlety involved
in defining the unit of privacy. We then systematically analyze the sample
complexity of widely-used PO algorithms, including policy gradient (PG),
natural policy gradient (NPG) and more, under DP constraints and various
settings, via a unified framework. Our theoretical results demonstrate that
privacy costs can often manifest as lower-order terms in the sample complexity,
while also highlighting subtle yet important observations in private PO
settings. These offer valuable practical insights for privacy-preserving PO
algorithms.

</details>


### [15] [The Virtues of Brevity: Avoid Overthinking in Parallel Test-Time Reasoning](https://arxiv.org/abs/2510.21067)
*Raul Cavalcante Dinardi,Bruno Yamamoto,Anna Helena Reali Costa,Artur Jordao*

Main category: cs.LG

TL;DR: 研究发现选择最短答案的简单启发式方法在提升LLM推理性能方面与复杂方法相当，同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有并行测试时计算方法需要复杂评分，增加了计算成本和复杂性，需要寻找更简单有效的策略。

Method: 采用选择最短答案的简单启发式方法，基于模型在简洁自信的常规模式和冗长过度思考模式之间切换的假设。

Result: 该方法在两个具有挑战性的基准测试中与自一致性等复杂方法表现相当，同时显著减少计算开销。

Conclusion: 最短答案启发式方法提供了对自一致性的帕累托改进，适用于输出相等性定义不明确的任务，是一种简单有效的替代方案。

Abstract: Reasoning models represent a significant advance in LLM capabilities,
particularly for complex reasoning tasks such as mathematics and coding.
Previous studies confirm that parallel test-time compute-sampling multiple
solutions and selecting the best one-can further enhance the predictive
performance of LLMs. However, strategies in this area often require complex
scoring, thus increasing computational cost and complexity. In this work, we
demonstrate that the simple and counterintuitive heuristic of selecting the
shortest solution is highly effective. We posit that the observed effectiveness
stems from models operating in two distinct regimes: a concise, confident
conventional regime and a verbose overthinking regime characterized by
uncertainty, and we show evidence of a critical point where the overthinking
regime begins to be significant. By selecting the shortest answer, the
heuristic preferentially samples from the conventional regime. We confirm that
this approach is competitive with more complex methods such as self-consistency
across two challenging benchmarks while significantly reducing computational
overhead. The shortest-answer heuristic provides a Pareto improvement over
self-consistency and applies even to tasks where output equality is not well
defined.

</details>


### [16] [DictPFL: Efficient and Private Federated Learning on Encrypted Gradients](https://arxiv.org/abs/2510.21086)
*Jiaqi Xue,Mayank Kumar,Yuzhang Shang,Shangqian Gao,Rui Ning,Mengxin Zheng,Xiaoqian Jiang,Qian Lou*

Main category: cs.LG

TL;DR: DictPFL是一个实用的联邦学习框架，通过分解模型权重为静态字典和可更新查找表，仅加密传输部分参数，在保证全梯度保护的同时显著降低计算和通信开销。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的梯度共享存在隐私泄露风险，而全同态加密虽然能保护隐私但计算和通信开销巨大。现有方法要么完全加密导致高成本，要么部分加密存在安全漏洞。

Method: 提出DePE模块将模型权重分解为静态字典和可更新查找表，仅加密后者进行聚合；PrME模块通过加密感知剪枝最小化加密参数数量。

Result: 相比完全加密的联邦学习，DictPFL减少通信成本402-748倍，加速训练28-65倍；相比选择性加密方法，减少开销51-155倍，加速4-19倍。

Conclusion: DictPFL首次证明基于同态加密的私有联邦学习在实际部署中是可行的，其运行时间仅比明文联邦学习慢2倍以内。

Abstract: Federated Learning (FL) enables collaborative model training across
institutions without sharing raw data. However, gradient sharing still risks
privacy leakage, such as gradient inversion attacks. Homomorphic Encryption
(HE) can secure aggregation but often incurs prohibitive computational and
communication overhead. Existing HE-based FL methods sit at two extremes:
encrypting all gradients for full privacy at high cost, or partially encrypting
gradients to save resources while exposing vulnerabilities. We present DictPFL,
a practical framework that achieves full gradient protection with minimal
overhead. DictPFL encrypts every transmitted gradient while keeping
non-transmitted parameters local, preserving privacy without heavy computation.
It introduces two key modules: Decompose-for-Partial-Encrypt (DePE), which
decomposes model weights into a static dictionary and an updatable lookup
table, only the latter is encrypted and aggregated, while the static dictionary
remains local and requires neither sharing nor encryption; and
Prune-for-Minimum-Encrypt (PrME), which applies encryption-aware pruning to
minimize encrypted parameters via consistent, history-guided masks. Experiments
show that DictPFL reduces communication cost by 402-748$\times$ and accelerates
training by 28-65$\times$ compared to fully encrypted FL, while outperforming
state-of-the-art selective encryption methods by 51-155$\times$ in overhead and
4-19$\times$ in speed. Remarkably, DictPFL's runtime is within 2$\times$ of
plaintext FL, demonstrating for the first time, that HE-based private federated
learning is practical for real-world deployment. The code is publicly available
at https://github.com/UCF-ML-Research/DictPFL.

</details>


### [17] [Distributionally Robust Feature Selection](https://arxiv.org/abs/2510.21113)
*Maitreyi Swaroop,Tamar Krishnamurti,Bryan Wilder*

Main category: cs.LG

TL;DR: 提出一种特征选择方法，在特征收集成本高的场景下，选择有限特征以训练能在多个子群体上同时表现良好的模型。


<details>
  <summary>Details</summary>
Motivation: 在特征收集成本高昂的设定中（如添加调查问题或物理传感器），需要选择有限特征来构建适用于不同群体的高质量下游模型。

Method: 将问题建模为传统变量选择的连续松弛，使用加噪机制，无需通过模型训练过程进行反向传播。通过优化贝叶斯最优预测器的方差，开发模型无关的框架来平衡跨群体下游预测的整体性能。

Result: 在合成数据集和真实世界数据上的实验验证了该方法的有效性。

Conclusion: 该方法能够有效选择有限特征，使训练出的模型在多个子群体上同时表现良好，适用于特征收集成本高的应用场景。

Abstract: We study the problem of selecting limited features to observe such that
models trained on them can perform well simultaneously across multiple
subpopulations. This problem has applications in settings where collecting each
feature is costly, e.g. requiring adding survey questions or physical sensors,
and we must be able to use the selected features to create high-quality
downstream models for different populations. Our method frames the problem as a
continuous relaxation of traditional variable selection using a noising
mechanism, without requiring backpropagation through model training processes.
By optimizing over the variance of a Bayes-optimal predictor, we develop a
model-agnostic framework that balances overall performance of downstream
prediction across populations. We validate our approach through experiments on
both synthetic datasets and real-world data.

</details>


### [18] [PLAN: Proactive Low-Rank Allocation for Continual Learning](https://arxiv.org/abs/2510.21188)
*Xiequn Wang,Zhan Zhuang,Yu Zhang*

Main category: cs.LG

TL;DR: PLAN是一个持续学习框架，通过扩展LoRA来管理任务特定子空间分配，使用正交基向量和基于扰动的策略最小化与已学参数的冲突，从而在基础模型中实现高效且干扰感知的微调。


<details>
  <summary>Details</summary>
Motivation: 持续学习要求模型在不断适应新任务的同时不忘记过去的知识。现有方法在大型预训练模型的持续学习中面临效率低下和干扰问题。

Method: PLAN扩展了LoRA，引入任务特定的正交基向量，通过基于扰动的策略优化这些向量以最小化冲突，并采用选择机制识别干扰敏感性最小的基向量。

Result: 在标准持续学习基准测试中，PLAN持续优于现有方法，为基础模型的持续学习建立了新的最先进水平。

Conclusion: PLAN框架通过主动管理任务特定子空间分配，在保持对过去知识的同时高效适应新任务，为持续学习提供了有效的解决方案。

Abstract: Continual learning (CL) requires models to continuously adapt to new tasks
without forgetting past knowledge. In this work, we propose
\underline{P}roactive \underline{L}ow-rank \underline{A}llocatio\underline{N}
(PLAN), a framework that extends Low-Rank Adaptation (LoRA) to enable efficient
and interference-aware fine-tuning of large pre-trained models in CL settings.
PLAN proactively manages the allocation of task-specific subspaces by
introducing orthogonal basis vectors for each task and optimizing them through
a perturbation-based strategy that minimizes conflicts with previously learned
parameters. Furthermore, PLAN incorporates a novel selection mechanism that
identifies and assigns basis vectors with minimal sensitivity to interference,
reducing the risk of degrading past knowledge while maintaining efficient
adaptation to new tasks. Empirical results on standard CL benchmarks
demonstrate that PLAN consistently outperforms existing methods, establishing a
new state-of-the-art for continual learning with foundation models.

</details>


### [19] [Online AUC Optimization Based on Second-order Surrogate Loss](https://arxiv.org/abs/2510.21202)
*JunRu Luo,Difei Cheng,Bo Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种基于二阶统计量的替代损失函数来优化AUC，解决了传统方法中非凸不连续损失和内存成本高的问题，在在线学习中实现了更紧的遗憾界。


<details>
  <summary>Details</summary>
Motivation: AUC是分类任务中的重要性能指标，特别是在类别不平衡场景下。但优化AUC面临两个主要挑战：成对0/1损失的非凸不连续性导致优化困难，以及实例级存储的高内存成本在大规模应用中造成瓶颈。

Method: 提出了基于成对铰链损失的新型二阶替代损失，开发了高效的在线算法。与传统方法不同，该方法直接使用训练数据的一阶和二阶统计量构建替代损失函数来替代整个聚合的成对损失。

Result: 理论分析表明，现有在线AUC优化算法通常达到O(√T)遗憾界，而本文方法达到了更紧的O(ln T)界。通过核方法扩展到非线性设置，在多个基准数据集上的实验证明了所提方法的优越效率和效果。

Conclusion: 提出的二阶替代损失函数为在线AUC优化提供了一种高效有效的解决方案，显著改善了优化性能和计算效率。

Abstract: The Area Under the Curve (AUC) is an important performance metric for
classification tasks, particularly in class-imbalanced scenarios. However,
minimizing the AUC presents significant challenges due to the non-convex and
discontinuous nature of pairwise 0/1 losses, which are difficult to optimize,
as well as the substantial memory cost of instance-wise storage, which creates
bottlenecks in large-scale applications. To overcome these challenges, we
propose a novel second-order surrogate loss based on the pairwise hinge loss,
and develop an efficient online algorithm. Unlike conventional approaches that
approximate each individual pairwise 0/1 loss term with an instance-wise
surrogate function, our approach introduces a new paradigm that directly
substitutes the entire aggregated pairwise loss with a surrogate loss function
constructed from the first- and second-order statistics of the training data.
Theoretically, while existing online AUC optimization algorithms typically
achieve an $\mathcal{O}(\sqrt{T})$ regret bound, our method attains a tighter
$\mathcal{O}(\ln T)$ bound. Furthermore, we extend the proposed framework to
nonlinear settings through a kernel-based formulation. Extensive experiments on
multiple benchmark datasets demonstrate the superior efficiency and
effectiveness of the proposed second-order surrogate loss in optimizing online
AUC performance.

</details>


### [20] [Model Merging with Functional Dual Anchors](https://arxiv.org/abs/2510.21223)
*Kexuan Shi,Yandong Wen,Weiyang Liu*

Main category: cs.LG

TL;DR: 提出Functional Dual Anchors (FDAs)框架，通过建模输入表示空间而非参数空间来改进模型合并，使用合成输入来对齐任务向量，捕获任务特定的功能偏移。


<details>
  <summary>Details</summary>
Motivation: 现有模型合并方法在参数空间操作，受到参数不一致性的限制，需要更有效的方法来整合多个微调检查点的知识。

Method: 提出FDA框架，使用合成输入（双锚点）来诱导与任务向量对齐的梯度，捕获任务特定的功能偏移，并提供原则性初始化方案。

Result: 综合实验证明FDAs在模型合并中的有效性，且与参数空间模型合并方法互补。

Conclusion: FDA框架通过建模输入表示空间，为模型合并提供了更稳健和灵活的方法，弥合了联合多任务训练和后验合并之间的差距。

Abstract: Model merging is an efficient post-training strategy for integrating
knowledge from multiple finetuned checkpoints of a shared foundation model.
Existing methods operate in the parameter space, combining task vectors to
mitigate conflicts, but remain constrained by parameter inconsistencies. We
propose Functional Dual Anchors (FDAs), a framework that instead models the
input-representation space. FDAs are synthetic inputs whose induced gradients
align with task vectors, capturing task-specific functional shifts relative to
the pretrained model. This perspective bridges joint multi-task training and
post-hoc merging, offering both robustness and flexibility. We further
introduce a principled initialization scheme and show that FDAs are
complementary to parameter-space model merging. Comprehensive experiments
demonstrate the effectiveness of FDAs in model merging.

</details>


### [21] [Unified Implementations of Recurrent Neural Networks in Multiple Deep Learning Frameworks](https://arxiv.org/abs/2510.21252)
*Francesco Martinuzzi*

Main category: cs.LG

TL;DR: 本文介绍了三个开源库（torchrecurrent、RecurrentLayers.jl、LuxRecurrentLayers.jl），用于集中实现和测试多种RNN变体，解决当前缺乏统一测试平台的问题。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏统一的测试库，重新实现各种RNN架构耗时且容易出错，限制了可重复性和探索性研究。

Method: 开发了Julia和Python中的三个开源库，提供一致的框架来构建和扩展RNN模型，内置定制和实验机制。

Result: 成功创建了集中化的RNN实现库，所有包都在MIT许可下在GitHub上积极维护。

Conclusion: 这些库为研究人员提供了便捷的工具来测试和比较不同的RNN变体，促进了序列建模研究的可重复性和创新。

Abstract: Recurrent neural networks (RNNs) are a cornerstone of sequence modeling
across various scientific and industrial applications. Owing to their
versatility, numerous RNN variants have been proposed over the past decade,
aiming to improve the modeling of long-term dependencies and to address
challenges such as vanishing and exploding gradients. However, no central
library is available to test these variations, and reimplementing diverse
architectures can be time-consuming and error-prone, limiting reproducibility
and exploration. Here, we introduce three open-source libraries in Julia and
Python that centralize numerous recurrent cell implementations and higher-level
recurrent architectures. torchrecurrent, RecurrentLayers.jl, and
LuxRecurrentLayers.jl offer a consistent framework for constructing and
extending RNN models, providing built-in mechanisms for customization and
experimentation. All packages are available under the MIT license and actively
maintained on GitHub.

</details>


### [22] [Assessing the Real-World Utility of Explainable AI for Arousal Diagnostics: An Application-Grounded User Study](https://arxiv.org/abs/2510.21389)
*Stefan Kraft,Andreas Theissler,Vera Wienhausen-Wilke,Gjergji Kasneci,Hendrik Lensch*

Main category: cs.LG

TL;DR: 本研究通过用户实验评估了不同类型和时机的AI辅助对睡眠医学专家评分表现的影响，发现透明AI辅助作为质量控制步骤能显著提升性能，同时获得用户高度接受。


<details>
  <summary>Details</summary>
Motivation: AI系统在生物医学信号解释方面已能匹敌甚至超越人类专家，但临床实践中需要让医生知道何时以及为何信任AI建议，因此研究如何有效整合AI到临床工作流程中。

Method: 对8名专业睡眠医学从业者进行应用型用户研究，在三种条件下评分多导睡眠图数据：手动评分、黑盒AI辅助、透明白盒AI辅助，辅助时机分为开始阶段或事后质量控制。

Result: AI辅助和人类-AI团队评分均显著优于无辅助专家，透明AI辅助作为质量控制步骤比黑盒辅助提升约30%的事件级性能，质量控制时机进一步改善计数结果。

Conclusion: 策略性时机的透明AI辅助能有效平衡准确性和临床效率，为可信AI集成和用户接受提供了有前景的途径。

Abstract: Artificial intelligence (AI) systems increasingly match or surpass human
experts in biomedical signal interpretation. However, their effective
integration into clinical practice requires more than high predictive accuracy.
Clinicians must discern \textit{when} and \textit{why} to trust algorithmic
recommendations. This work presents an application-grounded user study with
eight professional sleep medicine practitioners, who score nocturnal arousal
events in polysomnographic data under three conditions: (i) manual scoring,
(ii) black-box (BB) AI assistance, and (iii) transparent white-box (WB) AI
assistance. Assistance is provided either from the \textit{start} of scoring or
as a post-hoc quality-control (\textit{QC}) review. We systematically evaluate
how the type and timing of assistance influence event-level and clinically most
relevant count-based performance, time requirements, and user experience. When
evaluated against the clinical standard used to train the AI, both AI and
human-AI teams significantly outperform unaided experts, with collaboration
also reducing inter-rater variability. Notably, transparent AI assistance
applied as a targeted QC step yields median event-level performance
improvements of approximately 30\% over black-box assistance, and QC timing
further enhances count-based outcomes. While WB and QC approaches increase the
time required for scoring, start-time assistance is faster and preferred by
most participants. Participants overwhelmingly favor transparency, with seven
out of eight expressing willingness to adopt the system with minor or no
modifications. In summary, strategically timed transparent AI assistance
effectively balances accuracy and clinical efficiency, providing a promising
pathway toward trustworthy AI integration and user acceptance in clinical
workflows.

</details>


### [23] [Relieving the Over-Aggregating Effect in Graph Transformers](https://arxiv.org/abs/2510.21267)
*Junshu Sun,Wanxing Chang,Chenxue Yang,Qingming Huang,Shuhui Wang*

Main category: cs.LG

TL;DR: 论文提出Wideformer方法解决图注意力中的过度聚合问题，通过并行处理和信息引导来防止关键信息丢失。


<details>
  <summary>Details</summary>
Motivation: 图注意力在全局交互学习中面临过度聚合问题，当大量消息聚合到单个节点时会导致关键信息被稀释和丢失。

Method: 提出Wideformer插件方法，将节点聚合划分为并行过程，并通过排序和加权引导模型关注信息丰富的子集。

Result: 评估显示Wideformer能有效缓解过度聚合，使骨干方法能够专注于信息丰富的消息，性能优于基线方法。

Conclusion: Wideformer通过限制每次聚合的输入量和优先处理信息丰富的消息，成功解决了图注意力中的过度聚合问题，提升了模型性能。

Abstract: Graph attention has demonstrated superior performance in graph learning
tasks. However, learning from global interactions can be challenging due to the
large number of nodes. In this paper, we discover a new phenomenon termed
over-aggregating. Over-aggregating arises when a large volume of messages is
aggregated into a single node with less discrimination, leading to the dilution
of the key messages and potential information loss. To address this, we propose
Wideformer, a plug-and-play method for graph attention. Wideformer divides the
aggregation of all nodes into parallel processes and guides the model to focus
on specific subsets of these processes. The division can limit the input volume
per aggregation, avoiding message dilution and reducing information loss. The
guiding step sorts and weights the aggregation outputs, prioritizing the
informative messages. Evaluations show that Wideformer can effectively mitigate
over-aggregating. As a result, the backbone methods can focus on the
informative messages, achieving superior performance compared to baseline
methods.

</details>


### [24] [DreamerV3-XP: Optimizing exploration through uncertainty estimation](https://arxiv.org/abs/2510.21418)
*Lukas Bierling,Davide Pasero,Jan-Henrik Bertrand,Kiki Van Gerwen*

Main category: cs.LG

TL;DR: DreamerV3-XP是DreamerV3的扩展版本，通过优先回放缓冲器和基于分歧的内在奖励机制改进探索和学习效率。


<details>
  <summary>Details</summary>
Motivation: 改进DreamerV3的探索能力和学习效率，特别是在稀疏奖励环境中。

Method: 使用优先回放缓冲器（根据回报、重建损失和价值误差对轨迹评分）和基于世界模型集合预测环境奖励分歧的内在奖励。

Result: 在Atari100k和DeepMind Control Visual Benchmark任务子集上验证，确认了原始DreamerV3结果，并显示学习速度更快、动态模型损失更低，尤其在稀疏奖励设置中。

Conclusion: DreamerV3-XP通过提出的扩展机制有效提升了探索和学习效率，特别是在具有挑战性的稀疏奖励环境中。

Abstract: We introduce DreamerV3-XP, an extension of DreamerV3 that improves
exploration and learning efficiency. This includes (i) a prioritized replay
buffer, scoring trajectories by return, reconstruction loss, and value error
and (ii) an intrinsic reward based on disagreement over predicted environment
rewards from an ensemble of world models. DreamerV3-XP is evaluated on a subset
of Atari100k and DeepMind Control Visual Benchmark tasks, confirming the
original DreamerV3 results and showing that our extensions lead to faster
learning and lower dynamics model loss, particularly in sparse-reward settings.

</details>


### [25] [DEEDEE: Fast and Scalable Out-of-Distribution Dynamics Detection](https://arxiv.org/abs/2510.21638)
*Tala Aljaafari,Varun Kanade,Philip Torr,Christian Schroeder de Witt*

Main category: cs.LG

TL;DR: DEEDEE是一种用于强化学习时间序列的OOD检测器，使用两种统计量（episodewise均值和RBF核相似度）来捕捉全局和局部偏差，在保持高精度的同时大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 在安全关键环境中部署强化学习受到分布偏移脆弱性的限制，需要开发高效的OOD检测方法。

Method: 提出DEEDEE检测器，仅使用episodewise均值和RBF核相似度两种统计量，捕捉训练摘要的全局和局部偏差。

Result: DEEDEE在标准RL OOD测试套件中匹配或超越现有检测器，计算量减少600倍，平均准确率提升5%。

Conclusion: 结果表明，多样异常类型通常通过少量低阶统计量在RL轨迹中留下印记，为复杂环境中的OOD检测提供了紧凑基础。

Abstract: Deploying reinforcement learning (RL) in safety-critical settings is
constrained by brittleness under distribution shift. We study
out-of-distribution (OOD) detection for RL time series and introduce DEEDEE, a
two-statistic detector that revisits representation-heavy pipelines with a
minimal alternative. DEEDEE uses only an episodewise mean and an RBF kernel
similarity to a training summary, capturing complementary global and local
deviations. Despite its simplicity, DEEDEE matches or surpasses contemporary
detectors across standard RL OOD suites, delivering a 600-fold reduction in
compute (FLOPs / wall-time) and an average 5% absolute accuracy gain over
strong baselines. Conceptually, our results indicate that diverse anomaly types
often imprint on RL trajectories through a small set of low-order statistics,
suggesting a compact foundation for OOD detection in complex environments.

</details>


### [26] [An Evidence-Based Post-Hoc Adjustment Framework for Anomaly Detection Under Data Contamination](https://arxiv.org/abs/2510.21296)
*Sukanya Patra,Souhaib Ben Taieb*

Main category: cs.LG

TL;DR: EPHAD是一个测试时自适应框架，用于处理训练数据被异常污染的无监督异常检测问题，通过结合预训练模型和经典异常检测方法在测试时更新模型输出。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的数据集往往包含未被检测到或错误标记的异常，导致无监督异常检测方法性能显著下降。现有解决方案需要访问训练流程、数据或已知异常比例，限制了实际应用。

Method: 提出EPHAD框架，在测试时更新在污染数据集上训练的异常检测模型的输出，整合预训练模型（如CLIP）、经典异常检测方法（如潜在异常因子）或领域特定知识提供的证据。

Result: 在8个视觉异常检测数据集、26个表格异常检测数据集和1个真实工业异常检测数据集上进行了全面实验验证，并通过消融研究分析超参数影响和对不同污染水平的鲁棒性。

Conclusion: EPHAD在不同异常检测模型和证据对中展现出多功能性和鲁棒性，为解决训练数据污染问题提供了有效解决方案。

Abstract: Unsupervised anomaly detection (AD) methods typically assume clean training
data, yet real-world datasets often contain undetected or mislabeled anomalies,
leading to significant performance degradation. Existing solutions require
access to the training pipelines, data or prior knowledge of the proportions of
anomalies in the data, limiting their real-world applicability. To address this
challenge, we propose EPHAD, a simple yet effective test-time adaptation
framework that updates the outputs of AD models trained on contaminated
datasets using evidence gathered at test time. Our approach integrates the
prior knowledge captured by the AD model trained on contaminated datasets with
evidence derived from multimodal foundation models like Contrastive
Language-Image Pre-training (CLIP), classical AD methods like the Latent
Outlier Factor or domain-specific knowledge. We illustrate the intuition behind
EPHAD using a synthetic toy example and validate its effectiveness through
comprehensive experiments across eight visual AD datasets, twenty-six tabular
AD datasets, and a real-world industrial AD dataset. Additionally, we conduct
an ablation study to analyse hyperparameter influence and robustness to varying
contamination levels, demonstrating the versatility and robustness of EPHAD
across diverse AD models and evidence pairs. To ensure reproducibility, our
code is publicly available at https://github.com/sukanyapatra1997/EPHAD.

</details>


### [27] [Data as a Lever: A Neighbouring Datasets Perspective on Predictive Multiplicity](https://arxiv.org/abs/2510.21303)
*Prakhar Ganesh,Hsiang Hsu,Golnoosh Farnadi*

Main category: cs.LG

TL;DR: 论文研究了数据对模型多重性的影响，发现相邻数据集（仅相差一个数据点）中类间分布重叠度越高，多重性反而越低。基于此，作者提出了多任务感知的主动学习数据获取策略和数据插补技术。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注建模选择对多重性的影响，而忽视了数据的关键作用。本文旨在通过相邻数据集框架，分析单个数据点差异对多重性的影响。

Method: 引入相邻数据集框架，分析单个数据点差异对多重性的影响；通过严格的数学证明验证发现；将框架扩展到主动学习和数据插补两个实际领域。

Result: 发现相邻数据集中类间分布重叠度越高，多重性越低，这与传统预期相反；提出了多任务感知的主动学习数据获取策略和多任务感知的数据插补技术。

Conclusion: 数据在塑造多重性方面起着关键作用，通过理解数据层面的多重性，可以开发出更有效的多任务感知算法，提升模型性能和可靠性。

Abstract: Multiplicity -- the existence of distinct models with comparable performance
-- has received growing attention in recent years. While prior work has largely
emphasized modelling choices, the critical role of data in shaping multiplicity
has been comparatively overlooked. In this work, we introduce a neighbouring
datasets framework to examine the most granular case: the impact of a
single-data-point difference on multiplicity. Our analysis yields a seemingly
counterintuitive finding: neighbouring datasets with greater inter-class
distribution overlap exhibit lower multiplicity. This reversal of conventional
expectations arises from a shared Rashomon parameter, and we substantiate it
with rigorous proofs.
  Building on this foundation, we extend our framework to two practical
domains: active learning and data imputation. For each, we establish natural
extensions of the neighbouring datasets perspective, conduct the first
systematic study of multiplicity in existing algorithms, and finally, propose
novel multiplicity-aware methods, namely, multiplicity-aware data acquisition
strategies for active learning and multiplicity-aware data imputation
techniques.

</details>


### [28] [Leverage Unlearning to Sanitize LLMs](https://arxiv.org/abs/2510.21322)
*Antoine Boutet,Lucas Magnana*

Main category: cs.LG

TL;DR: SANI是一种语言模型去记忆化方法，通过擦除和修复两个阶段来移除模型对敏感信息的记忆，无需昂贵的额外微调。


<details>
  <summary>Details</summary>
Motivation: 预训练大语言模型在特定任务微调时会记忆敏感数据，存在隐私泄露风险，需要一种无需重新微调的去记忆化方法。

Method: 采用擦除和修复两阶段：1）重置模型最后层的特定神经元以破坏细粒度信息记忆；2）避免记忆敏感信息的微调。

Result: 仅需少量额外训练周期即可显著减少模型对敏感信息的复现，有效移除直接和间接标识符的记忆。

Conclusion: SANI为医院等行业提供了一种实用的模型净化方法，可在共享模型前有效保护敏感信息。

Abstract: Pre-trained large language models (LLMs) are becoming useful for various
tasks. To improve their performance on certain tasks, it is necessary to
fine-tune them on specific data corpora (e.g., medical reports, business data).
These specialized data corpora may contain sensitive data (e.g., personal or
confidential data) that will be memorized by the model and likely to be
regurgitated during its subsequent use. This memorization of sensitive
information by the model poses a significant privacy or confidentiality issue.
To remove this memorization and sanitize the model without requiring costly
additional fine-tuning on a secured data corpus, we propose SANI. SANI is an
unlearning approach to sanitize language models. It relies on both an erasure
and repair phases that 1) reset certain neurons in the last layers of the model
to disrupt the memorization of fine-grained information, and then 2) fine-tune
the model while avoiding memorizing sensitive information. We comprehensively
evaluate SANI to sanitize both a model fine-tuned and specialized with medical
data by removing directly and indirectly identifiers from the memorization of
the model, and a standard pre-trained model by removing specific terms defined
as confidential information from the model. Results show that with only few
additional epochs of unlearning, the model is sanitized and the number of
regurgitations is drastically reduced. This approach can be particularly useful
for hospitals or other industries that have already spent significant resources
training models on large datasets and wish to sanitize them before sharing.

</details>


### [29] [Cost-Sensitive Freeze-thaw Bayesian Optimization for Efficient Hyperparameter Tuning](https://arxiv.org/abs/2510.21379)
*Dong Bok Lee,Aoxuan Silvia Zhang,Byungjoo Kim,Junhyeon Park,Steven Adriaensen,Juho Lee,Sung Ju Hwang,Hae Beom Lee*

Main category: cs.LG

TL;DR: 本文提出了一种基于冻结-解冻贝叶斯优化的成本敏感超参数优化方法，通过引入效用函数、新的采集函数和停止准则，在性能和计算成本之间实现更好的权衡。


<details>
  <summary>Details</summary>
Motivation: 针对用户希望在预期性能改进不令人满意时提前停止超参数优化过程的需求，解决成本敏感的超参数优化问题。

Method: 在冻结-解冻框架中引入效用函数，结合新的采集函数和停止准则，动态选择最有潜力的配置继续训练，并自动在最大效用附近停止优化过程。同时通过迁移学习提高样本效率。

Result: 在已建立的多保真度超参数优化基准测试中，该算法优于所有考虑的先前冻结-解冻贝叶斯优化和迁移贝叶斯优化基线，在成本和性能之间实现了显著更好的权衡。

Conclusion: 提出的成本敏感超参数优化方法能够有效平衡计算成本和模型性能，在冻结-解冻贝叶斯优化框架下取得了优越的性能。

Abstract: In this paper, we address the problem of \emph{cost-sensitive} hyperparameter
optimization (HPO) built upon freeze-thaw Bayesian optimization (BO).
Specifically, we assume a scenario where users want to early-stop the HPO
process when the expected performance improvement is not satisfactory with
respect to the additional computational cost. Motivated by this scenario, we
introduce \emph{utility} in the freeze-thaw framework, a function describing
the trade-off between the cost and performance that can be estimated from the
user's preference data. This utility function, combined with our novel
acquisition function and stopping criterion, allows us to dynamically continue
training the configuration that we expect to maximally improve the utility in
the future, and also automatically stop the HPO process around the maximum
utility. Further, we improve the sample efficiency of existing freeze-thaw
methods with transfer learning to develop a specialized surrogate model for the
cost-sensitive HPO problem. We validate our algorithm on established
multi-fidelity HPO benchmarks and show that it outperforms all the previous
freeze-thaw BO and transfer-BO baselines we consider, while achieving a
significantly better trade-off between the cost and performance. Our code is
publicly available at https://github.com/db-Lee/CFBO.

</details>


### [30] [Towards Explainable Personalized Recommendations by Learning from Users' Photos](https://arxiv.org/abs/2510.21455)
*Jorge Díez,Pablo Pérez-Núñez,Oscar Luaces,Beatriz Remeseiro,Antonio Bahamonde*

Main category: cs.LG

TL;DR: 该论文提出将个性化解释作为推荐本身来学习，通过预测用户会为物品拍摄什么照片来生成有说服力的解释，从而提高推荐系统的可靠性。


<details>
  <summary>Details</summary>
Motivation: 解释复杂系统（如推荐系统）的输出对用户和公司都至关重要。用户上传的照片可能强化或证明他们对物品的评价，因此预测用户会拍摄什么照片可以生成最能说服用户的解释。

Method: 提出一个形式化框架来估计给定（用户，照片）对的作者概率。使用从TripAdvisor收集的包含餐厅评论（带照片）的数据集进行验证。

Result: 通过预测用户可能拍摄的照片，推荐系统可以提供更具说服力的解释，同时公司可以了解客户关注的产品特点分布。

Conclusion: 将个性化解释作为推荐学习的方法能够提高推荐系统的可靠性，并为公司提供关于客户偏好的生动知识。

Abstract: Explaining the output of a complex system, such as a Recommender System (RS),
is becoming of utmost importance for both users and companies. In this paper we
explore the idea that personalized explanations can be learned as
recommendation themselves. There are plenty of online services where users can
upload some photos, in addition to rating items. We assume that users take
these photos to reinforce or justify their opinions about the items. For this
reason we try to predict what photo a user would take of an item, because that
image is the argument that can best convince her of the qualities of the item.
In this sense, an RS can explain its results and, therefore, increase its
reliability. Furthermore, once we have a model to predict attractive images for
users, we can estimate their distribution. Thus, the companies acquire a vivid
knowledge about the aspects that the clients highlight of their products. The
paper includes a formal framework that estimates the authorship probability for
a given pair (user, photo). To illustrate the proposal, we use data gathered
from TripAdvisor containing the reviews (with photos) of restaurants in six
cities of different sizes.

</details>


### [31] [Uniform Convergence Beyond Glivenko-Cantelli](https://arxiv.org/abs/2510.21506)
*Tanmay Devale,Pramith Devulapalli,Steve Hanneke*

Main category: cs.LG

TL;DR: 本文扩展了Vapnik和Chervonenkis的经典框架，引入了Uniform Mean Estimability（UME-learnability）概念，研究分布集合在任意估计器下是否允许均匀均值估计。证明了均值向量可分性是UME-learnability的充分条件但非必要条件，并解决了Cohen等人提出的关于可数并集可学习性的猜想。


<details>
  <summary>Details</summary>
Motivation: 传统Vapnik-Chervonenkis理论专注于经验均值估计器的均匀收敛性（P-Glivenko-Cantelli），本文旨在超越这一限制，研究在任意估计器下分布集合是否允许均匀均值估计。

Method: 在由分布集合的均值向量构成的空间上工作，研究均值向量的可分性与UME-learnability的关系，并通过构造非可分但UME-learnable的分布集合来证明可分性非必要条件。

Result: 1）均值向量可分性是UME-learnability的充分条件；2）可分性非必要条件，存在非可分但UME-learnable的分布集合；3）UME-learnable集合的可数并集也是UME-learnable。

Conclusion: 本文建立了Uniform Mean Estimability的理论框架，揭示了均值估计的均匀可学习性条件，解决了相关猜想，为分布集合的均值估计理论提供了新的视角和工具。

Abstract: We characterize conditions under which collections of distributions on
$\{0,1\}^\mathbb{N}$ admit uniform estimation of their mean. Prior work from
Vapnik and Chervonenkis (1971) has focused on uniform convergence using the
empirical mean estimator, leading to the principle known as $P-$
Glivenko-Cantelli. We extend this framework by moving beyond the empirical mean
estimator and introducing Uniform Mean Estimability, also called $UME-$
learnability, which captures when a collection permits uniform mean estimation
by any arbitrary estimator. We work on the space created by the mean vectors of
the collection of distributions. For each distribution, the mean vector records
the expected value in each coordinate. We show that separability of the mean
vectors is a sufficient condition for $UME-$ learnability. However, we show
that separability of the mean vectors is not necessary for $UME-$ learnability
by constructing a collection of distributions whose mean vectors are
non-separable yet $UME-$ learnable using techniques fundamentally different
from those used in our separability-based analysis. Finally, we establish that
countable unions of $UME-$ learnable collections are also $UME-$ learnable,
solving a conjecture posed in Cohen et al. (2025).

</details>


### [32] [Probe-based Fine-tuning for Reducing Toxicity](https://arxiv.org/abs/2510.21531)
*Jan Wehner,Mario Fritz*

Main category: cs.LG

TL;DR: 该论文探讨了使用探针作为训练信号时面临的Goodhart定律问题，提出了基于监督微调和直接偏好优化的两种方法，发现在偏好学习目标下探针检测能力得到保持，且重新训练探针比使用探针集成更有效。


<details>
  <summary>Details</summary>
Motivation: 探针可以检测模型内部的不良行为，如欺骗或偏见，这些从输出中难以识别。但将探针作为训练目标时可能面临Goodhart定律问题，即监控指标失去可靠性。

Method: 提出了两种基于探针的训练方法：监督微调和直接偏好优化。在毒性减少测试平台上进行实验，评估训练后探针准确率下降程度。尝试了三种保持探针准确性的策略：训练对抗探针集成、保留未用于训练的探针、训练后重新训练新探针。

Result: 探针基于的偏好优化意外地比基于分类器的方法更好地保持了探针检测能力；探针多样性提供的实际益处有限，重新训练探针可以恢复高检测准确率。

Conclusion: 基于探针的训练对于某些对齐方法是可行的，当重新训练可行时，探针集成基本上是不必要的。

Abstract: Probes trained on model activations can detect undesirable behaviors like
deception or biases that are difficult to identify from outputs alone. This
makes them useful detectors to identify misbehavior. Furthermore, they are also
valuable training signals, since they not only reward outputs, but also good
internal processes for arriving at that output. However, training against
interpretability tools raises a fundamental concern: when a monitor becomes a
training target, it may cease to be reliable (Goodhart's Law). We propose two
methods for training against probes based on Supervised Fine-tuning and Direct
Preference Optimization. We conduct an initial exploration of these methods in
a testbed for reducing toxicity and evaluate the amount by which probe accuracy
drops when training against them. To retain the accuracy of probe-detectors
after training, we attempt (1) to train against an ensemble of probes, (2)
retain held-out probes that aren't used for training, and (3) retrain new
probes after training.
  First, probe-based preference optimization unexpectedly preserves probe
detectability better than classifier-based methods, suggesting the preference
learning objective incentivizes maintaining rather than obfuscating relevant
representations. Second, probe diversity provides minimal practical benefit -
simply retraining probes after optimization recovers high detection accuracy.
Our findings suggest probe-based training can be viable for certain alignment
methods, though probe ensembles are largely unnecessary when retraining is
feasible.

</details>


### [33] [Excision Score: Evaluating Edits with Surgical Precision](https://arxiv.org/abs/2510.21537)
*Nikolai Gruzinov,Ksenia Sycheva,Earl T. Barr,Alex Bezzubov*

Main category: cs.LG

TL;DR: 本文提出了修订相似性问题，并指出传统相似性度量方法（如BLEU）因过度关注共享内容而无法准确评估文档修订。作者提出了一种新的静态度量方法——切除分数（ES），通过移除共享内容后比较差异区域来更好地与人类判断对齐。


<details>
  <summary>Details</summary>
Motivation: 现有文档修订评估方法（如BLEU）存在根本缺陷，其得分被共享内容主导，导致在人类认为差异很大的修订之间仍报告高相似性。需要一种能更好反映人类判断的修订相似性度量方法。

Method: 提出切除分数（ES）方法：使用最长公共子序列（LCS）移除现有文档与修订版本之间的共享内容，然后仅比较剩余的差异区域。通过近似方法将标准立方LCS计算加速到二次复杂度。

Result: 在代码编辑评估中，ES显著优于现有方法。在HumanEvalFix数据集上，与最接近的竞争者SARI相比，ES的皮尔逊相关性提高了12%，比标准方法（如BLEU）提高了>21%。当增加共享上下文时，ES相对于SARI的改进增加到20%，相对于标准方法超过30%。

Conclusion: ES方法通过关注修订中的实际变化而非共享内容，能够更准确地评估文档修订质量，特别是在代码编辑任务中表现优异，为机器学习评估问题提供了更好的解决方案。

Abstract: Many tasks revolve around editing a document, whether code or text. We
formulate the revision similarity problem to unify a wide range of machine
learning evaluation problems whose goal is to assess a revision to an existing
document. We observe that revisions usually change only a small portion of an
existing document, so the existing document and its immediate revisions share a
majority of their content. We formulate five adequacy criteria for revision
similarity measures, designed to align them with human judgement. We show that
popular pairwise measures, like BLEU, fail to meet these criteria, because
their scores are dominated by the shared content. They report high similarity
between two revisions when humans would assess them as quite different. This is
a fundamental flaw we address. We propose a novel static measure, Excision
Score (ES), which computes longest common subsequence (LCS) to remove content
shared by an existing document with the ground truth and predicted revisions,
before comparing only the remaining divergent regions. This is analogous to a
surgeon creating a sterile field to focus on the work area. We use
approximation to speed the standard cubic LCS computation to quadratic. In
code-editing evaluation, where static measures are often used as a cheap proxy
for passing tests, we demonstrate that ES surpasses existing measures. When
aligned with test execution on HumanEvalFix, ES improves over its nearest
competitor, SARI, by 12% Pearson correlation and by >21% over standard measures
like BLEU. The key criterion is invariance to shared context; when we perturb
HumanEvalFix with increased shared context, ES' improvement over SARI increases
to 20% and >30% over standard measures. ES also handles other corner cases that
other measures do not, such as correctly aligning moved code blocks, and
appropriately rewarding matching insertions or deletions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [34] [Fuzzy numbers revisited: operations on extensional fuzzy numbers](https://arxiv.org/abs/2510.20861)
*Krzysztof Siminski*

Main category: cs.AI

TL;DR: 本文提出了一种新的模糊数表示方法——外延模糊数，以解决传统模糊数运算中的计算复杂性和结果特征不一致问题，并定义了相应的运算和关系运算符。


<details>
  <summary>Details</summary>
Motivation: 传统模糊数运算存在计算复杂度高、运算结果可能不保持原特征（如两个三角模糊数相乘结果不是三角模糊数）、模糊扩散等问题，限制了模糊数的应用范围。

Method: 采用外延模糊数作为新的模糊数表示方法，定义了外延模糊数的运算（加法、减法、乘法、除法）和关系运算符（等于、大于、大于等于、小于、小于等于）。

Result: 提出的方法通过多个应用示例进行了说明，并提供了C++实现代码，可从GitHub公共仓库获取。

Conclusion: 外延模糊数方法能够有效解决传统模糊数运算中的问题，为模糊数的应用提供了新的可能性。

Abstract: Fuzzy numbers are commonly represented with fuzzy sets. Their objective is to
better represent imprecise data. However, operations on fuzzy numbers are not
as straightforward as maths on crisp numbers. Commonly, the Zadeh's extension
rule is applied to elaborate a result. This can produce two problems: (1) high
computational complexity and (2) for some fuzzy sets and some operations the
results is not a fuzzy set with the same features (eg. multiplication of two
triangular fuzzy sets does not produce a triangular fuzzy set). One more
problem is the fuzzy spread -- fuzziness of the result increases with the
number of operations. These facts can severely limit the application field of
fuzzy numbers. In this paper we would like to revisite this problem with a
different kind of fuzzy numbers -- extensional fuzzy numbers. The paper defines
operations on extensional fuzzy numbers and relational operators (=, >, >=, <,
<=) for them. The proposed approach is illustrated with several applicational
examples. The C++ implementation is available from a public GitHub repository.

</details>


### [35] [Epistemic Deference to AI](https://arxiv.org/abs/2510.21043)
*Benjamin Lange*

Main category: cs.AI

TL;DR: 本文探讨何时应该优先采用AI输出而非人类专家判断，提出了人工智能认知权威（AEA）概念和AI优先主义观点，但指出其存在诸多问题，最终发展出基于全证据的AI遵从观。


<details>
  <summary>Details</summary>
Motivation: 研究AI系统何时应该被视为认知权威，以及在什么情况下应该优先采用AI输出而非人类判断，解决AI与人类认知权威之间的冲突问题。

Method: 基于社会认识论理论，分析AI优先主义的经典反对意见，并发展出基于全证据的AI遵从观，将AI输出作为贡献性理由而非完全替代人类独立认知考虑。

Result: 提出了三种关键优势：缓解专业知识萎缩、为人机有意义的监督和控制提供认识论基础、解释AI在可靠性条件未满足时的合理不信任。

Conclusion: 基于全证据的AI遵从观提供了一种原则性方法来确定何时AI遵从是合理的，特别是在需要严格可靠性的高风险环境中。

Abstract: When should we defer to AI outputs over human expert judgment? Drawing on
recent work in social epistemology, I motivate the idea that some AI systems
qualify as Artificial Epistemic Authorities (AEAs) due to their demonstrated
reliability and epistemic superiority. I then introduce AI Preemptionism, the
view that AEA outputs should replace rather than supplement a user's
independent epistemic reasons. I show that classic objections to preemptionism
- such as uncritical deference, epistemic entrenchment, and unhinging epistemic
bases - apply in amplified form to AEAs, given their opacity, self-reinforcing
authority, and lack of epistemic failure markers. Against this, I develop a
more promising alternative: a total evidence view of AI deference. According to
this view, AEA outputs should function as contributory reasons rather than
outright replacements for a user's independent epistemic considerations. This
approach has three key advantages: (i) it mitigates expertise atrophy by
keeping human users engaged, (ii) it provides an epistemic case for meaningful
human oversight and control, and (iii) it explains the justified mistrust of AI
when reliability conditions are unmet. While demanding in practice, this
account offers a principled way to determine when AI deference is justified,
particularly in high-stakes contexts requiring rigorous reliability.

</details>


### [36] [MedAlign: A Synergistic Framework of Multimodal Preference Optimization and Federated Meta-Cognitive Reasoning](https://arxiv.org/abs/2510.21093)
*Siyong Chen,Jinbo Wen,Jiawen Kang,Tenghui Huang,Xumin Huang,Yuanjia Su,Hudan Pan,Zishao Zhong,Dusit Niyato,Shengli Xie,Dong In Kim*

Main category: cs.AI

TL;DR: MedAlign是一个针对医学视觉问答的新型框架，通过多模态直接偏好优化、检索感知专家混合架构和联邦治理机制，解决大型视觉语言模型在临床服务中的幻觉、固定推理深度效率低下和多机构协作困难等挑战。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在智能医疗领域具有巨大潜力，但面临三个关键挑战：幻觉回答倾向、固定推理深度效率低下以及多机构协作困难。

Method: 1. 多模态直接偏好优化目标，将偏好学习与视觉上下文显式对齐；2. 检索感知专家混合架构，利用图像和文本相似性将查询路由到专业化的上下文增强LVLM专家；3. 联邦治理机制，基于mDPO在临床数据集上微调的专家通过本地元认知不确定性估计器执行迭代链式思维推理。

Result: 在三个代表性Med-VQA数据集上的广泛实验表明，MedAlign实现了最先进的性能，比强检索增强基线在F1分数上提高了11.85%，同时与固定深度CoT方法相比平均推理长度减少了51.60%。

Conclusion: MedAlign框架有效解决了LVLM在医学视觉问答中的关键挑战，实现了更高的准确性和推理效率，为智能医疗领域的实际部署提供了可行方案。

Abstract: Recently, large models have shown significant potential for smart healthcare.
However, the deployment of Large Vision-Language Models (LVLMs) for clinical
services is currently hindered by three critical challenges: a tendency to
hallucinate answers not grounded in visual evidence, the inefficiency of
fixed-depth reasoning, and the difficulty of multi-institutional collaboration.
To address these challenges, in this paper, we develop MedAlign, a novel
framework to ensure visually accurate LVLM responses for Medical Visual
Question Answering (Med-VQA). Specifically, we first propose a multimodal
Direct Preference Optimization (mDPO) objective to explicitly align preference
learning with visual context. We then design a Retrieval-Aware
Mixture-of-Experts (RA-MoE) architecture that utilizes image and text
similarity to route queries to a specialized and context-augmented LVLM (i.e.,
an expert), thereby mitigating hallucinations in LVLMs. To achieve adaptive
reasoning and facilitate multi-institutional collaboration, we propose a
federated governance mechanism, where the selected expert, fine-tuned on
clinical datasets based on mDPO, locally performs iterative Chain-of-Thought
(CoT) reasoning via the local meta-cognitive uncertainty estimator. Extensive
experiments on three representative Med-VQA datasets demonstrate that MedAlign
achieves state-of-the-art performance, outperforming strong retrieval-augmented
baselines by up to $11.85\%$ in F1-score, and simultaneously reducing the
average reasoning length by $51.60\%$ compared with fixed-depth CoT approaches.

</details>


### [37] [Out-of-Distribution Detection for Safety Assurance of AI and Autonomous Systems](https://arxiv.org/abs/2510.21254)
*Victoria J. Hodge,Colin Paterson,Ibrahim Habli*

Main category: cs.AI

TL;DR: 本文对自主系统中OOD（分布外）检测技术进行了全面综述，重点分析了其在安全关键领域安全保证中的应用，探讨了OOD检测在整个机器学习开发生命周期中的使用方法和注意事项。


<details>
  <summary>Details</summary>
Motivation: 随着AI自主系统能力的扩展，特别是在安全关键领域，如何严格证明其安全性成为重要挑战。OOD检测作为处理系统生命周期中新颖和不确定情况的关键技术，受到研究界和工程界的广泛关注。

Method: 采用系统性文献综述方法，首先定义相关概念，分析OOD产生原因，探讨自主系统安全保证和OOD检测面临的挑战因素，识别可用于整个ML开发生命周期的技术范围。

Result: 识别了一系列可在ML开发生命周期不同阶段使用的OOD检测技术，并提出了这些技术在支持安全保证论证中的具体应用场景，同时指出了系统工程师在集成OOD检测时需要注意的注意事项。

Conclusion: 概述了自主系统安全开发和运营面临的挑战及未来研究方向，强调了OOD检测在确保自主系统安全运行中的重要性。

Abstract: The operational capabilities and application domains of AI-enabled autonomous
systems have expanded significantly in recent years due to advances in robotics
and machine learning (ML). Demonstrating the safety of autonomous systems
rigorously is critical for their responsible adoption but it is challenging as
it requires robust methodologies that can handle novel and uncertain situations
throughout the system lifecycle, including detecting out-of-distribution (OoD)
data. Thus, OOD detection is receiving increased attention from the research,
development and safety engineering communities. This comprehensive review
analyses OOD detection techniques within the context of safety assurance for
autonomous systems, in particular in safety-critical domains. We begin by
defining the relevant concepts, investigating what causes OOD and exploring the
factors which make the safety assurance of autonomous systems and OOD detection
challenging. Our review identifies a range of techniques which can be used
throughout the ML development lifecycle and we suggest areas within the
lifecycle in which they may be used to support safety assurance arguments. We
discuss a number of caveats that system and safety engineers must be aware of
when integrating OOD detection into system lifecycles. We conclude by outlining
the challenges and future work necessary for the safe development and operation
of autonomous systems across a range of domains and applications.

</details>


### [38] [Investigating Scale Independent UCT Exploration Factor Strategies](https://arxiv.org/abs/2510.21275)
*Robin Schmöcker,Christoph Schnell,Alexander Dockhorn*

Main category: cs.AI

TL;DR: 本文评估了多种UCT算法中自适应选择探索常数λ的策略，推荐使用新提出的λ=2σ方法，其中σ是搜索树中所有状态-动作对Q值的经验标准差。


<details>
  <summary>Details</summary>
Motivation: UCT算法对游戏奖励尺度不鲁棒，传统方法在稀疏奖励游戏中表现良好，但在具有密集奖励和手动设定奖励尺度的游戏中，Q值会跨越不同数量级，导致性能问题。

Method: 评估了文献中提出的λ策略以及五种新策略，包括选择λ作为Q值经验标准差的函数等方法。

Result: 新提出的λ=2σ策略在广泛任务中优于现有λ策略，无论是使用单一参数值还是优化所有可用参数时的峰值性能。

Conclusion: 推荐使用λ=2σ作为UCT算法的探索常数选择策略，该方法对游戏奖励尺度具有鲁棒性且性能优越。

Abstract: The Upper Confidence Bounds For Trees (UCT) algorithm is not agnostic to the
reward scale of the game it is applied to. For zero-sum games with the sparse
rewards of $\{-1,0,1\}$ at the end of the game, this is not a problem, but many
games often feature dense rewards with hand-picked reward scales, causing a
node's Q-value to span different magnitudes across different games. In this
paper, we evaluate various strategies for adaptively choosing the UCT
exploration constant $\lambda$, called $\lambda$-strategies, that are agnostic
to the game's reward scale. These $\lambda$-strategies include those proposed
in the literature as well as five new strategies. Given our experimental
results, we recommend using one of our newly suggested $\lambda$-strategies,
which is to choose $\lambda$ as $2 \cdot \sigma$ where $\sigma$ is the
empirical standard deviation of all state-action pairs' Q-values of the search
tree. This method outperforms existing $\lambda$-strategies across a wide range
of tasks both in terms of a single parameter value and the peak performances
obtained by optimizing all available parameters.

</details>


### [39] [Understanding AI Trustworthiness: A Scoping Review of AIES & FAccT Articles](https://arxiv.org/abs/2510.21293)
*Siddharth Mehrotra,Jin Huang,Xuelong Fu,Roel Dobbe,Clara I. Sánchez,Maarten de Rijke*

Main category: cs.AI

TL;DR: 这篇论文通过范围综述分析了AIES和FAccT会议中关于可信AI的研究现状，发现当前研究过于侧重技术属性而忽视社会技术维度，提出了结合技术严谨性与社会文化因素的跨学科方法。


<details>
  <summary>Details</summary>
Motivation: 当前可信AI研究主要采用技术中心方法，过度关注可靠性、鲁棒性和公平性等技术属性，而忽视了理解真实世界环境中AI可信度所需的社会技术维度。

Method: 对AIES和FAccT会议论文集进行范围综述，系统分析可信度在不同研究领域中的定义、操作化和应用方式，重点关注概念化方法、测量方法、验证技术、应用领域和基础价值观。

Result: 研究发现虽然透明度、问责制和鲁棒性等技术属性的定义取得了显著进展，但当前研究往往过度强调技术精度而牺牲社会伦理考量。AI系统的社会技术性质仍较少被探索，可信度成为由有权定义者塑造的争议性概念。

Conclusion: 结合技术严谨性与社会、文化和制度考量的跨学科方法对于推进可信AI至关重要。作者为AI伦理社区提出了可操作措施，以采用真正解决AI系统与社会复杂互动的整体框架，最终促进惠及所有利益相关者的负责任技术发展。

Abstract: Background: Trustworthy AI serves as a foundational pillar for two major AI
ethics conferences: AIES and FAccT. However, current research often adopts
techno-centric approaches, focusing primarily on technical attributes such as
reliability, robustness, and fairness, while overlooking the sociotechnical
dimensions critical to understanding AI trustworthiness in real-world contexts.
  Objectives: This scoping review aims to examine how the AIES and FAccT
communities conceptualize, measure, and validate AI trustworthiness,
identifying major gaps and opportunities for advancing a holistic understanding
of trustworthy AI systems.
  Methods: We conduct a scoping review of AIES and FAccT conference proceedings
to date, systematically analyzing how trustworthiness is defined,
operationalized, and applied across different research domains. Our analysis
focuses on conceptualization approaches, measurement methods, verification and
validation techniques, application areas, and underlying values.
  Results: While significant progress has been made in defining technical
attributes such as transparency, accountability, and robustness, our findings
reveal critical gaps. Current research often predominantly emphasizes technical
precision at the expense of social and ethical considerations. The
sociotechnical nature of AI systems remains less explored and trustworthiness
emerges as a contested concept shaped by those with the power to define it.
  Conclusions: An interdisciplinary approach combining technical rigor with
social, cultural, and institutional considerations is essential for advancing
trustworthy AI. We propose actionable measures for the AI ethics community to
adopt holistic frameworks that genuinely address the complex interplay between
AI systems and society, ultimately promoting responsible technological
development that benefits all stakeholders.

</details>


### [40] [A Multimodal Benchmark for Framing of Oil & Gas Advertising and Potential Greenwashing Detection](https://arxiv.org/abs/2510.21679)
*Gaku Morio,Harri Rowlands,Dominik Stammbach,Christopher D. Manning,Peter Henderson*

Main category: cs.AI

TL;DR: 提出了一个用于评估视觉语言模型的专家标注视频广告基准数据集，用于分析能源公司公关活动中的框架类型，特别是检测绿色创新等环境信息。


<details>
  <summary>Details</summary>
Motivation: 企业公关活动存在言行不一的问题（如石油公司的'漂绿'行为），需要大规模理解框架及其变化来揭示公关活动的目标和性质。

Method: 构建了一个从Facebook和YouTube获取的专家标注视频广告数据集，包含13种框架类型，涵盖50多家公司和20个国家，专门用于视觉语言模型评估。

Result: 基线实验显示GPT-4.1能检测环境信息达到79% F1分数，但最佳模型在识别绿色创新框架方面仅达到46% F1分数，表明仍有改进空间。

Conclusion: 该数据集有助于能源领域战略沟通的多模态分析研究，同时揭示了视觉语言模型需要解决的挑战，如隐式框架、不同长度视频处理和隐含文化背景。

Abstract: Companies spend large amounts of money on public relations campaigns to
project a positive brand image. However, sometimes there is a mismatch between
what they say and what they do. Oil & gas companies, for example, are accused
of "greenwashing" with imagery of climate-friendly initiatives. Understanding
the framing, and changes in framing, at scale can help better understand the
goals and nature of public relations campaigns. To address this, we introduce a
benchmark dataset of expert-annotated video ads obtained from Facebook and
YouTube. The dataset provides annotations for 13 framing types for more than 50
companies or advocacy groups across 20 countries. Our dataset is especially
designed for the evaluation of vision-language models (VLMs), distinguishing it
from past text-only framing datasets. Baseline experiments show some promising
results, while leaving room for improvement for future work: GPT-4.1 can detect
environmental messages with 79% F1 score, while our best model only achieves
46% F1 score on identifying framing around green innovation. We also identify
challenges that VLMs must address, such as implicit framing, handling videos of
various lengths, or implicit cultural backgrounds. Our dataset contributes to
research in multimodal analysis of strategic communication in the energy
sector.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [41] [A Multiscale Approach for Enhancing Weak Signal Detection](https://arxiv.org/abs/2510.20828)
*Dixon Vimalajeewa,Ursula U. Muller,Brani Vidakovic*

Main category: eess.SP

TL;DR: 本研究提出了一种双阈值检测系统，通过结合两个单阈值检测器来增强弱信号检测能力，并在原始数据域和多尺度域进行评估，相比传统单阈值方法显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统随机共振技术主要基于单阈值检测器，局限于时间无关信号，且需要大量噪声来检测弱信号，这会扭曲复杂信号特征。为解决这些限制，本研究探索多阈值系统和在多尺度应用中应用随机共振。

Method: 提出双阈值检测系统，集成两个单阈值检测器；在原始数据域和多尺度域（使用小波变换）进行评估；使用模拟和真实世界信号进行测试，并与现有方法进行比较。

Result: 在原始数据域中，双阈值检测器相比传统单阈值方法显著改善了弱信号检测；在频域中性能进一步提升，需要更低的噪声水平且优于现有检测系统。

Conclusion: 本研究通过引入稳健的弱信号识别方法推进了基于随机共振的检测方法学，在多个学科中具有潜在应用价值。

Abstract: Stochastic resonance (SR), a phenomenon originally introduced in climate
modeling, enhances signal detection by leveraging optimal noise levels within
non-linear systems. Traditional SR techniques, mainly based on single-threshold
detectors, are limited to signals whose behavior does not depend on time. Often
large amounts of noise are needed to detect weak signals, which can distort
complex signal characteristics. To address these limitations, this study
explores multi-threshold systems and the application of SR in multiscale
applications using wavelet transforms. In the multiscale domain signals can be
analyzed at different levels of resolution to better understand the underlying
dynamics.
  We propose a double-threshold detection system that integrates two
single-threshold detectors to enhance weak signal detection. We evaluate it
both in the original data domain and in the multiscale domain using simulated
and real-world signals and compare its performance with existing methods.
  Experimental results demonstrate that, in the original data domain, the
proposed double-threshold detector significantly improves weak signal detection
compared to conventional single-threshold approaches. Its performance is
further improved in the frequency domain, requiring lower noise levels while
outperforming existing detection systems. This study advances SR-based
detection methodologies by introducing a robust approach to weak signal
identification, with potential applications in various disciplines.

</details>


### [42] [Track-to-Track Association for Collective Perception based on Stochastic Optimization](https://arxiv.org/abs/2510.21278)
*Laura M. Wolf,Vincent Albert Wolff,Simon Steuernagel,Kolja Thormann,Marcus Baum*

Main category: eess.SP

TL;DR: 提出基于随机优化的轨迹关联算法，用于智能车辆集体感知中的多传感器融合，通过多维似然函数和多个关联假设处理模糊场景。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶中多传感器融合的轨迹关联问题，克服现有方法计算复杂度高或基于启发式的局限性。

Method: 使用随机优化方法，构建包含轨迹数量和空间分布的多维似然函数，并计算多个关联假设。

Result: 在蒙特卡洛模拟和实际集体感知场景中验证了算法的有效性，能够在模糊设置下计算高似然关联。

Conclusion: 提出的随机优化方法为集体感知中的轨迹关联问题提供了有效的解决方案，能够处理复杂场景中的关联模糊性。

Abstract: Collective perception is a key aspect for autonomous driving in smart cities
as it aims to combine the local environment models of multiple intelligent
vehicles in order to overcome sensor limitations. A crucial part of
multi-sensor fusion is track-to-track association. Previous works often suffer
from high computational complexity or are based on heuristics. We propose an
association algorithms based on stochastic optimization, which leverages a
multidimensional likelihood incorporating the number of tracks and their
spatial distribution and furthermore computes several association hypotheses.
We demonstrate the effectiveness of our approach in Monte Carlo simulations and
a realistic collective perception scenario computing high-likelihood
associations in ambiguous settings.

</details>


### [43] [On Irradiance Distributions for Weakly Turbulent FSO Links: Log-Normal vs. Gamma-Gamma](https://arxiv.org/abs/2510.21509)
*Carmen Álvarez Roa,Yunus Can Gültekin,Vincent van Vliet,Menno van den Hout,Chigo Okonkwo,Alex Alvarado*

Main category: eess.SP

TL;DR: 实验研究表明，对数正态分布无法准确描述弱湍流条件下的辐照度波动，而Gamma-Gamma模型表现更优。


<details>
  <summary>Details</summary>
Motivation: 弱湍流通常使用对数正态分布进行建模，但该模型在描述辐照度波动方面存在不足，需要寻找更准确的统计模型。

Method: 通过实验研究，比较对数正态分布和Gamma-Gamma模型在弱湍流条件下对辐照度波动的拟合效果。

Result: 实验结果显示对数正态分布无法捕捉弱湍流状态下的辐照度波动，而Gamma-Gamma模型能够更准确地描述这些波动。

Conclusion: 在弱湍流条件下，Gamma-Gamma模型比传统的对数正态分布更适合用于描述辐照度波动特性。

Abstract: Weak turbulence is commonly modeled using the log-normal distribution. Our
experimental results show that this distribution fails to capture irradiance
fluctuations in this regime. The Gamma-Gamma model is shown to be more
accurate.

</details>
