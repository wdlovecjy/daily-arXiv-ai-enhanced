<div id=toc></div>

# Table of Contents

- [stat.ML](#stat.ML) [Total: 4]
- [cs.LG](#cs.LG) [Total: 28]
- [cs.AI](#cs.AI) [Total: 10]
- [stat.AP](#stat.AP) [Total: 3]
- [eess.SP](#eess.SP) [Total: 4]


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [1] [The Tree-SNE Tree Exists](https://arxiv.org/abs/2510.15014)
*Jack Kendrick*

Main category: stat.ML

TL;DR: 论文提出tree-SNE方法，通过在t-SNE中引入额外的尺度参数来解决高维数据聚类中的尺度问题，生成(2+1)维嵌入，使聚类结果能够根据任务需求在不同尺度下连续变化。


<details>
  <summary>Details</summary>
Motivation: 解决非线性降维方法（如t-SNE、UMAP）在处理高维数据时面临的尺度问题——即如何根据具体任务需求选择适当的聚类尺度，例如在MNIST数据集中是区分不同数字还是区分同一数字的不同书写方式。

Method: 基于Robinson & Pierce-Hoffman的思想，利用t-SNE中的尺度对称性，将传统的2维嵌入扩展为(2+1)维嵌入，其中额外参数控制尺度，形成t-SNE树（tree-SNE）。

Result: 证明了对于除零测集外的所有初始条件，最优嵌入随尺度参数连续变化，即tree-SNE树存在。该方法可扩展到其他吸引-排斥方法，并在多个示例中得到验证。

Conclusion: tree-SNE提供了一种解决聚类尺度问题的有效方法，通过引入尺度参数实现了聚类结果在不同分辨率下的连续变化，增强了数据可视化和分析的灵活性。

Abstract: The clustering and visualisation of high-dimensional data is a ubiquitous
task in modern data science. Popular techniques include nonlinear
dimensionality reduction methods like t-SNE or UMAP. These methods face the
`scale-problem' of clustering: when dealing with the MNIST dataset, do we want
to distinguish different digits or do we want to distinguish different ways of
writing the digits? The answer is task dependent and depends on scale. We
revisit an idea of Robinson & Pierce-Hoffman that exploits an underlying
scaling symmetry in t-SNE to replace 2-dimensional with (2+1)-dimensional
embeddings where the additional parameter accounts for scale. This gives rise
to the t-SNE tree (short: tree-SNE). We prove that the optimal embedding
depends continuously on the scaling parameter for all initial conditions
outside a set of measure 0: the tree-SNE tree exists. This idea conceivably
extends to other attraction-repulsion methods and is illustrated on several
examples.

</details>


### [2] [Information Theory in Open-world Machine Learning Foundations, Frameworks, and Future Direction](https://arxiv.org/abs/2510.15422)
*Lin Wang*

Main category: stat.ML

TL;DR: 本文综述了信息论方法在开放世界机器学习中的应用，重点探讨了熵、互信息和KL散度等核心概念如何为开放世界条件下的知识获取、不确定性抑制和风险控制提供数学语言。


<details>
  <summary>Details</summary>
Motivation: 开放世界机器学习领域缺乏统一的理论基础来量化不确定性、表征信息传递和解释动态非平稳环境中的学习适应性。

Method: 通过信息论方法，将近期研究综合为三个主要研究方向：信息论开放集识别、信息驱动的新颖性发现和信息保留的持续学习。

Result: 建立了信息论与可证明学习框架之间的理论联系，包括PAC贝叶斯边界、开放空间风险理论和因果信息流，为可证明和可信赖的开放世界智能建立路径。

Conclusion: 识别了关键开放问题和未来研究方向，如信息风险量化、动态互信息边界开发、多模态信息融合以及信息论与因果推理和世界模型学习的整合。

Abstract: Open world Machine Learning (OWML) aims to develop intelligent systems
capable of recognizing known categories, rejecting unknown samples, and
continually learning from novel information. Despite significant progress in
open set recognition, novelty detection, and continual learning, the field
still lacks a unified theoretical foundation that can quantify uncertainty,
characterize information transfer, and explain learning adaptability in
dynamic, nonstationary environments. This paper presents a comprehensive review
of information theoretic approaches in open world machine learning, emphasizing
how core concepts such as entropy, mutual information, and Kullback Leibler
divergence provide a mathematical language for describing knowledge
acquisition, uncertainty suppression, and risk control under open world
conditions. We synthesize recent studies into three major research axes:
information theoretic open set recognition enabling safe rejection of unknowns,
information driven novelty discovery guiding new concept formation, and
information retentive continual learning ensuring stable long term adaptation.
Furthermore, we discuss theoretical connections between information theory and
provable learning frameworks, including PAC Bayes bounds, open-space risk
theory, and causal information flow, to establish a pathway toward provable and
trustworthy open world intelligence. Finally, the review identifies key open
problems and future research directions, such as the quantification of
information risk, development of dynamic mutual information bounds, multimodal
information fusion, and integration of information theory with causal reasoning
and world model learning.

</details>


### [3] [Disentanglement of Sources in a Multi-Stream Variational Autoencoder](https://arxiv.org/abs/2510.15669)
*Veranika Boukun,Jörg Lücke*

Main category: stat.ML

TL;DR: 本文提出了一种多流变分自编码器（MS-VAE），使用离散隐变量来组合单个源的VAE表示，通过线性组合模型实现源分离，并在手写数字叠加和说话人日志任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统VAE通常使用单一连续隐空间学习解耦表示，本文探索使用离散隐变量来组合多个源的VAE表示，特别适用于声学数据等场景。

Method: 提出多流变分自编码器（MS-VAE），基于显式的源组合模型（线性组合），推导了其推理和学习方程，并在手写数字叠加和说话人日志任务上进行数值实验。

Result: 实验显示MS-VAE能够清晰分离叠加的手写数字，在说话人日志任务中表现出特别低的说话人漏检率，且在不同监督程度和训练数据量下都表现出灵活性。

Conclusion: MS-VAE是一种领域无关的方法，能够有效分离多个源，在源分离任务中表现出优越性能，特别是在说话人日志任务中显著降低了漏检率。

Abstract: Variational autoencoders (VAEs) are a leading approach to address the problem
of learning disentangled representations. Typically a single VAE is used and
disentangled representations are sought in its continuous latent space. Here we
explore a different approach by using discrete latents to combine
VAE-representations of individual sources. The combination is done based on an
explicit model for source combination, and we here use a linear combination
model which is well suited, e.g., for acoustic data. We formally define such a
multi-stream VAE (MS-VAE) approach, derive its inference and learning
equations, and we numerically investigate its principled functionality. The
MS-VAE is domain-agnostic, and we here explore its ability to separate sources
into different streams using superimposed hand-written digits, and mixed
acoustic sources in a speaker diarization task. We observe a clear separation
of digits, and on speaker diarization we observe an especially low rate of
missed speakers. Numerical experiments further highlight the flexibility of the
approach across varying amounts of supervision and training data.

</details>


### [4] [Error analysis of a compositional score-based algorithm for simulation-based inference](https://arxiv.org/abs/2510.15817)
*Camille Touron,Gabriel V. Cardoso,Julyan Arbel,Pedro L. C. Rodrigues*

Main category: stat.ML

TL;DR: 本文研究了基于扩散的模拟推理中组合评分方法的误差累积问题，为GAUSS算法建立了误差上界，并通过高斯示例验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 在基于模拟的推理中，如何有效组合多个观测数据来改进参数推断是一个核心问题。虽然扩散方法通过构建组合评分来解决这个问题，但随着观测数量增加，个体误差累积可能显著降低采样质量，这一重要理论问题尚未被探索。

Method: 研究GAUSS算法产生的组合评分，建立其均方误差的上界，该上界与个体评分误差和观测数量相关，并在高斯示例中推导所有解析表达式。

Result: 建立了组合评分均方误差的上界，表明误差随观测数量增加而累积，但在高斯示例中验证了理论结果的正确性。

Conclusion: 本文首次系统分析了组合评分方法中的误差累积问题，为基于扩散的模拟推理方法提供了重要的理论保证，有助于理解多观测数据组合对参数推断质量的影响。

Abstract: Simulation-based inference (SBI) has become a widely used framework in
applied sciences for estimating the parameters of stochastic models that best
explain experimental observations. A central question in this setting is how to
effectively combine multiple observations in order to improve parameter
inference and obtain sharper posterior distributions. Recent advances in
score-based diffusion methods address this problem by constructing a
compositional score, obtained by aggregating individual posterior scores within
the diffusion process. While it is natural to suspect that the accumulation of
individual errors may significantly degrade sampling quality as the number of
observations grows, this important theoretical issue has so far remained
unexplored. In this paper, we study the compositional score produced by the
GAUSS algorithm of Linhart et al. (2024) and establish an upper bound on its
mean squared error in terms of both the individual score errors and the number
of observations. We illustrate our theoretical findings on a Gaussian example,
where all analytical expressions can be derived in a closed form.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [TangledFeatures: Robust Feature Selection in Highly Correlated Spaces](https://arxiv.org/abs/2510.15005)
*Allen Daniel Sunny*

Main category: cs.LG

TL;DR: 提出了TangledFeatures框架，用于在相关特征空间中进行特征选择，通过识别纠缠预测因子组中的代表性特征来减少冗余，同时保留解释能力。


<details>
  <summary>Details</summary>
Motivation: 传统特征选择方法主要关注预测准确性，但在存在相关预测因子的情况下性能会下降，因此需要一种能够处理相关特征空间的方法。

Method: 引入TangledFeatures框架，从纠缠的预测因子组中识别代表性特征，减少冗余同时保持解释力。

Result: 在Alanine Dipeptide数据集上应用该框架预测主链扭转角，所选特征对应于结构上有意义的原子内距离，能够解释这些角度的变化。

Conclusion: TangledFeatures提供了一种比传统选择技术更可解释和稳定的分析基础，可直接应用于下游模型。

Abstract: Feature selection is a fundamental step in model development, shaping both
predictive performance and interpretability. Yet, most widely used methods
focus on predictive accuracy, and their performance degrades in the presence of
correlated predictors. To address this gap, we introduce TangledFeatures, a
framework for feature selection in correlated feature spaces. It identifies
representative features from groups of entangled predictors, reducing
redundancy while retaining explanatory power. The resulting feature subset can
be directly applied in downstream models, offering a more interpretable and
stable basis for analysis compared to traditional selection techniques. We
demonstrate the effectiveness of TangledFeatures on Alanine Dipeptide, applying
it to the prediction of backbone torsional angles and show that the selected
features correspond to structurally meaningful intra-atomic distances that
explain variation in these angles.

</details>


### [6] [ES-C51: Expected Sarsa Based C51 Distributional Reinforcement Learning Algorithm](https://arxiv.org/abs/2510.15006)
*Rijul Tandon,Peter Vamplew,Cameron Foale*

Main category: cs.LG

TL;DR: 本研究提出了一种改进的C51算法（ES-C51），用Expected Sarsa更新替代贪婪Q学习更新，通过softmax计算结合所有可能动作的信息，在动作具有相似期望奖励时减少不稳定性，从而学习到更高性能的策略。


<details>
  <summary>Details</summary>
Motivation: 传统基于价值的强化学习算法只估计每个动作的期望奖励，而分布强化学习（DRL）估计可能奖励的整个概率分布。C51是离散动作空间中流行的DRL算法，但使用贪婪Bellman更新可能导致在多个动作具有相似期望奖励但不同分布时学习不稳定。

Method: 提出ES-C51算法，将C51的贪婪Q学习更新替换为Expected Sarsa更新，使用softmax计算结合所有可能动作的信息，而不是依赖单个最佳动作。同时将标准C51的探索策略从ε-greedy改为softmax作为公平比较基准（QL-C51）。

Result: 在Gym的经典控制环境和Atari-10游戏上评估，结果表明ES-C51在多个环境中优于QL-C51。

Conclusion: 使用Expected Sarsa更新替代贪婪Q学习更新可以有效减少分布强化学习中的不稳定性，特别是在动作具有相似期望奖励的情况下，能够学习到更高性能的策略。

Abstract: In most value-based reinforcement learning (RL) algorithms, the agent
estimates only the expected reward for each action and selects the action with
the highest reward. In contrast, Distributional Reinforcement Learning (DRL)
estimates the entire probability distribution of possible rewards, providing
richer information about uncertainty and variability. C51 is a popular DRL
algorithm for discrete action spaces. It uses a Q-learning approach, where the
distribution is learned using a greedy Bellman update. However, this can cause
problems if multiple actions at a state have similar expected reward but with
different distributions, as the algorithm may not learn a stable distribution.
This study presents a modified version of C51 (ES-C51) that replaces the greedy
Q-learning update with an Expected Sarsa update, which uses a softmax
calculation to combine information from all possible actions at a state rather
than relying on a single best action. This reduces instability when actions
have similar expected rewards and allows the agent to learn higher-performing
policies. This approach is evaluated on classic control environments from Gym,
and Atari-10 games. For a fair comparison, we modify the standard C51's
exploration strategy from e-greedy to softmax, which we refer to as QL-C51 (Q-
Learning based C51). The results demonstrate that ES-C51 outperforms QL-C51
across many environments.

</details>


### [7] [Hybrid Autoencoder-Based Framework for Early Fault Detection in Wind Turbines](https://arxiv.org/abs/2510.15010)
*Rekha R Nair,Tina Babu,Alavikunhu Panthakkan,Balamurugan Balusamy,Wathiq Mansoor*

Main category: cs.LG

TL;DR: 提出了一种基于集成深度学习的无监督异常检测框架，用于风力涡轮机早期故障检测，结合VAE、LSTM自编码器和Transformer架构，在真实SCADA数据上实现AUC-ROC 0.947和48小时提前故障检测。


<details>
  <summary>Details</summary>
Motivation: 风力涡轮机可靠性对可再生能源部门至关重要，早期故障检测能显著减少停机时间和维护成本。

Method: 集成变分自编码器、LSTM自编码器和Transformer架构，结合特征工程提取时域、统计和频域指标，通过集成评分和自适应阈值进行无监督异常检测。

Result: 在包含89年真实涡轮机数据的CARE数据集上评估，AUC-ROC达到0.947，能够提前48小时检测到故障。

Conclusion: 该方法通过预测性维护显著减少涡轮机故障，提高大规模风能部署的运营效率，具有重要社会价值。

Abstract: Wind turbine reliability is critical to the growing renewable energy sector,
where early fault detection significantly reduces downtime and maintenance
costs. This paper introduces a novel ensemble-based deep learning framework for
unsupervised anomaly detection in wind turbines. The method integrates
Variational Autoencoders (VAE), LSTM Autoencoders, and Transformer
architectures, each capturing different temporal and contextual patterns from
high-dimensional SCADA data. A unique feature engineering pipeline extracts
temporal, statistical, and frequency-domain indicators, which are then
processed by the deep models. Ensemble scoring combines model predictions,
followed by adaptive thresholding to detect operational anomalies without
requiring labeled fault data. Evaluated on the CARE dataset containing 89 years
of real-world turbine data across three wind farms, the proposed method
achieves an AUC-ROC of 0.947 and early fault detection up to 48 hours prior to
failure. This approach offers significant societal value by enabling predictive
maintenance, reducing turbine failures, and enhancing operational efficiency in
large-scale wind energy deployments.

</details>


### [8] [Learn to Change the World: Multi-level Reinforcement Learning with Model-Changing Actions](https://arxiv.org/abs/2510.15056)
*Ziqing Lu,Babak Hassibi,Lifeng Lai,Weiyu Xu*

Main category: cs.LG

TL;DR: 本文提出了一种多层级可配置时变马尔可夫决策过程（MCTVMDP），其中智能体不仅可以通过原始动作与环境交互，还能通过上层模型改变动作主动修改环境动态模型本身。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习假设环境是给定或固定的，而本文考虑智能体能够主动修改环境模型，通过重新配置底层转移过程来增加奖励。

Method: 引入MCTVMDP框架，包含上层MDP用于配置模型改变动作，下层MDP具有可通过上层动作配置的非平稳转移函数。智能体需要联合优化上层配置策略和下层原始动作策略。

Result: 提出了一个能够同时处理环境配置和策略优化的统一框架，使智能体能够主动改变环境动态来最大化长期奖励。

Conclusion: MCTVMDP为智能体提供了超越被动适应的能力，通过主动修改环境模型来实现更好的性能表现。

Abstract: Reinforcement learning usually assumes a given or sometimes even fixed
environment in which an agent seeks an optimal policy to maximize its long-term
discounted reward. In contrast, we consider agents that are not limited to
passive adaptations: they instead have model-changing actions that actively
modify the RL model of world dynamics itself. Reconfiguring the underlying
transition processes can potentially increase the agents' rewards. Motivated by
this setting, we introduce the multi-layer configurable time-varying Markov
decision process (MCTVMDP). In an MCTVMDP, the lower-level MDP has a
non-stationary transition function that is configurable through upper-level
model-changing actions. The agent's objective consists of two parts: Optimize
the configuration policies in the upper-level MDP and optimize the primitive
action policies in the lower-level MDP to jointly improve its expected
long-term reward.

</details>


### [9] [A Simple Method for PMF Estimation on Large Supports](https://arxiv.org/abs/2510.15132)
*Alex Shtoff*

Main category: cs.LG

TL;DR: 提出一种基于图拉普拉斯算子的非参数概率质量函数估计方法，通过数据依赖的低通滤波处理多模态和重尾分布，计算可靠且适合大规模自动化分析。


<details>
  <summary>Details</summary>
Motivation: 针对大型离散支撑集上多模态和重尾概率质量函数的非参数估计问题，传统方法在处理这类复杂分布时存在局限性。

Method: 将经验PMF视为线图上的信号，构建对称三对角算子（路径图拉普拉斯加上基于经验PMF的对角矩阵），计算最小特征值对应的特征向量，将经验PMF投影到低维子空间，最后进行裁剪和重归一化处理。

Result: 在合成和真实重尾数据上，该方法能保持粗粒度结构同时抑制采样噪声，在目标场景下优于logspline和高斯KDE基线方法，计算可靠且内存效率高。

Conclusion: 该方法实现简洁，对样本量稳健，因其可靠性和速度适合自动化流程和大规模探索性分析，但存在已知的失效模式（如突然的不连续性）。

Abstract: We study nonparametric estimation of a probability mass function (PMF) on a
large discrete support, where the PMF is multi-modal and heavy-tailed. The core
idea is to treat the empirical PMF as a signal on a line graph and apply a
data-dependent low-pass filter. Concretely, we form a symmetric tri-diagonal
operator, the path graph Laplacian perturbed with a diagonal matrix built from
the empirical PMF, then compute the eigenvectors, corresponding to the smallest
feq eigenvalues. Projecting the empirical PMF onto this low dimensional
subspace produces a smooth, multi-modal estimate that preserves coarse
structure while suppressing noise. A light post-processing step of clipping and
re-normalizing yields a valid PMF.
  Because we compute the eigenpairs of a symmetric tridiagonal matrix, the
computation is reliable and runs time and memory proportional to the support
times the dimension of the desired low-dimensional supspace. We also provide a
practical, data-driven rule for selecting the dimension based on an
orthogonal-series risk estimate, so the method "just works" with minimal
tuning. On synthetic and real heavy-tailed examples, the approach preserves
coarse structure while suppressing sampling noise, compares favorably to
logspline and Gaussian-KDE baselines in the intended regimes. However, it has
known failure modes (e.g., abrupt discontinuities). The method is short to
implement, robust across sample sizes, and suitable for automated pipelines and
exploratory analysis at scale because of its reliability and speed.

</details>


### [10] [Online Correlation Clustering: Simultaneously Optimizing All $\ell_p$-norms](https://arxiv.org/abs/2510.15076)
*Sami Davies,Benjamin Moseley,Heather Newman*

Main category: cs.LG

TL;DR: 该论文提出了首个在线样本模型下的相关聚类算法，能够同时近似所有ℓp范数目标，解决了离线环境中ℓ1范数（最小化总分歧）和ℓ∞范数（确保节点公平性）之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于离线环境中可以同时近似所有ℓp范数的发现，但需要验证这种强大保证是否能在在线设置中实现。同时，作者证明了在标准随机顺序在线模型中，ℓ∞范数存在根本性分离，需要采用不同的超越最坏情况模型。

Method: 提出了一种在线样本模型（AOS）算法，给定输入的一小部分常数比例作为样本，生成单一聚类。该算法能够同时处理所有ℓp范数目标，在样本模型下实现多目标近似。

Result: 算法在AOS模型中：对所有ℓp范数高概率达到O(log⁴n)竞争比；对ℓ∞范数高概率达到O(logn)竞争比；对ℓ1范数期望达到O(1)竞争比。同时证明了在标准RO模型中ℓ∞范数至少需要Ω(n¹/³)竞争比。

Conclusion: 成功将离线环境中的"全范数"保证迁移到在线世界，证明了在线样本模型的必要性，并为ℓ1和ℓ∞范数提供了接近紧的竞争比下界。

Abstract: The $\ell_p$-norm objectives for correlation clustering present a fundamental
trade-off between minimizing total disagreements (the $\ell_1$-norm) and
ensuring fairness to individual nodes (the $\ell_\infty$-norm). Surprisingly,
in the offline setting it is possible to simultaneously approximate all
$\ell_p$-norms with a single clustering. Can this powerful guarantee be
achieved in an online setting? This paper provides the first affirmative
answer. We present a single algorithm for the online-with-a-sample (AOS) model
that, given a small constant fraction of the input as a sample, produces one
clustering that is simultaneously $O(\log^4 n)$-competitive for all
$\ell_p$-norms with high probability, $O(\log n)$-competitive for the
$\ell_\infty$-norm with high probability, and $O(1)$-competitive for the
$\ell_1$-norm in expectation. This work successfully translates the offline
"all-norms" guarantee to the online world.
  Our setting is motivated by a new hardness result that demonstrates a
fundamental separation between these objectives in the standard random-order
(RO) online model. Namely, while the $\ell_1$-norm is trivially
$O(1)$-approximable in the RO model, we prove that any algorithm in the RO
model for the fairness-promoting $\ell_\infty$-norm must have a competitive
ratio of at least $\Omega(n^{1/3})$. This highlights the necessity of a
different beyond-worst-case model. We complement our algorithm with lower
bounds, showing our competitive ratios for the $\ell_1$- and $\ell_\infty$-
norms are nearly tight in the AOS model.

</details>


### [11] [Robust Layerwise Scaling Rules by Proper Weight Decay Tuning](https://arxiv.org/abs/2510.15262)
*Zhiyuan Fan,Yifeng Liu,Qingyue Zhao,Angela Yuan,Quanquan Gu*

Main category: cs.LG

TL;DR: 本文提出了一种针对AdamW优化器的权重衰减缩放规则，解决了在尺度不变架构中μP方法在训练稳态阶段失效的问题，实现了学习率和权重衰减在不同宽度模型间的零样本迁移。


<details>
  <summary>Details</summary>
Motivation: 现代尺度不变架构的训练会快速进入优化器主导的稳态阶段，归一化层导致反向尺度敏感性，使得有效学习率变得宽度依赖，从而破坏了μP方法的迁移效果。

Method: 通过分析矩阵参数奇异值谱的缩放规律，结合μP学习率规则，推导出经验性的权重衰减缩放规则λ₂∝√d，同时保持向量类参数的学习率不变且权重衰减为0。

Result: 在LLaMA风格Transformer和最小合成设置中验证了该规则的有效性，实现了学习率和权重衰减在不同宽度模型间的零样本迁移，消除了每个宽度都需要进行超参数搜索的需求。

Conclusion: 该方法将μP扩展到近初始化阶段之外，通过显式控制优化器设置的稳态尺度，为AdamW下的宽度鲁棒超参数迁移提供了实用方案。

Abstract: Empirical scaling laws prescribe how to allocate parameters, data, and
compute, while maximal-update parameterization ($\mu$P) enables learning-rate
transfer across widths by equalizing early-time update magnitudes. However, in
modern scale-invariant architectures, training quickly enters an
optimizer-governed steady state where normalization layers create backward
scale sensitivity and the effective learning rate becomes width dependent,
degrading $\mu$P transfer. We address this by introducing a weight-decay
scaling rule for AdamW that preserves sublayer gain across widths. Empirically,
the singular-value spectrum of each matrix parameter scales in norm as
$\sqrt{\eta/\lambda}$ with an approximately invariant shape; under width
scaling $d$, we observe that the top singular value scales approximately as
$\sqrt{\eta/\lambda}\cdot d^{0.75}$. Combining this observation with the $\mu$P
learning-rate rule $\eta_2\propto d^{-1}$ for matrix-like parameters implies an
empirical weight-decay scaling rule $\lambda_2\propto \sqrt{d}$ that
approximately keeps sublayer gains width invariant. Together with vector-like
parameters trained at $\eta_1=\Theta_d(1)$ and $\lambda_1=0$, this yields
\emph{zero-shot} transfer of both learning rate and weight decay from proxy to
target widths, removing per-width sweeps. We validate the rule on LLaMA-style
Transformers and in a minimal synthetic setting, and we provide a simple
diagnostic, matching top singular values, to check sublayer-gain invariance.
Our results extend $\mu$P beyond the near-init regime by explicitly controlling
steady-state scales set by the optimizer, offering a practical recipe for
width-robust hyperparameter transfer under AdamW.

</details>


### [12] [Adversary-Free Counterfactual Prediction via Information-Regularized Representations](https://arxiv.org/abs/2510.15479)
*Shiqin Tang,Rong Feng,Shuxin Zhuang,Hongzong Li,Youzhi Zhang*

Main category: cs.LG

TL;DR: 提出一种基于信息论的因果推断方法，通过最小化表示与处理变量之间的互信息来消除分配偏差，无需对抗训练，在静态和动态场景中均表现良好。


<details>
  <summary>Details</summary>
Motivation: 解决因果推断中的分配偏差问题，传统对抗训练方法存在不稳定性和调参负担，需要一种数学基础扎实且训练稳定的替代方案。

Method: 从连接反事实-事实风险差距与互信息的理论边界出发，学习一个预测结果的随机表示Z，同时最小化I(Z;T)。推导出可处理的变分目标，将信息项与监督解码器耦合，形成稳定训练准则。

Result: 在受控数值模拟和真实临床数据集上评估，与最新的平衡、重加权和对抗基线方法相比，在似然度、反事实误差和政策评估指标上表现优越。

Conclusion: 该方法在避免对抗训练不稳定性和调参负担的同时，实现了良好的因果推断性能，为处理分配偏差提供了理论扎实且实用的解决方案。

Abstract: We study counterfactual prediction under assignment bias and propose a
mathematically grounded, information-theoretic approach that removes
treatment-covariate dependence without adversarial training. Starting from a
bound that links the counterfactual-factual risk gap to mutual information, we
learn a stochastic representation Z that is predictive of outcomes while
minimizing I(Z; T). We derive a tractable variational objective that
upper-bounds the information term and couples it with a supervised decoder,
yielding a stable, provably motivated training criterion. The framework extends
naturally to dynamic settings by applying the information penalty to sequential
representations at each decision time. We evaluate the method on controlled
numerical simulations and a real-world clinical dataset, comparing against
recent state-of-the-art balancing, reweighting, and adversarial baselines.
Across metrics of likelihood, counterfactual error, and policy evaluation, our
approach performs favorably while avoiding the training instabilities and
tuning burden of adversarial schemes.

</details>


### [13] [Theoretical Refinement of CLIP by Utilizing Linear Structure of Optimal Similarity](https://arxiv.org/abs/2510.15508)
*Naoki Yoshida,Satoshi Hayakawa,Yuhta Takida,Toshimitsu Uesaka,Hiromi Wakaki,Yuki Mitsufuji*

Main category: cs.LG

TL;DR: 提出KME-CLIP方法，通过再生核希尔伯特空间的内积来改进多模态对比预训练中的相似度计算机制，更好地利用点互信息的线性结构。


<details>
  <summary>Details</summary>
Motivation: 现有CLIP及其变体未能充分利用点互信息(PMI)的线性结构，而理论研究表明跨模态的最优相似度度量应对应PMI。

Method: 在再生核希尔伯特空间中使用内积来近似PMI，理论上证明可以任意精度逼近PMI。

Result: 在多个检索和分类任务中，KME-CLIP整体优于标准CLIP方法。

Conclusion: 通过利用PMI的线性结构，KME-CLIP在多模态对比预训练中实现了更好的性能表现。

Abstract: In this study, we propose an enhancement to the similarity computation
mechanism in multi-modal contrastive pretraining frameworks such as CLIP. Prior
theoretical research has demonstrated that the optimal similarity metrics
between paired modalities should correspond to the pointwise mutual information
(PMI) between the two modalities. However, the current implementations of CLIP
and its variants fail to fully utilize the underlying linear structure of PMI.
We therefore propose KME-CLIP, which leverages this structure through the inner
product in a reproducing kernel Hilbert space. We theoretically prove that our
method can approximate PMI with arbitrary accuracy and empirically demonstrate
that our approach overall outperforms the standard CLIP formulation across
several retrieval and classification tasks.

</details>


### [14] [Policy Transfer Ensures Fast Learning for Continuous-Time LQR with Entropy Regularization](https://arxiv.org/abs/2510.15165)
*Xin Guo,Zijiu Lyu*

Main category: cs.LG

TL;DR: 本文研究了连续时间线性二次调节器（LQR）中的策略迁移学习，证明了在相关LQR任务间迁移最优策略的有效性，并提出了一种具有全局线性和局部超线性收敛的新算法。


<details>
  <summary>Details</summary>
Motivation: 强化学习在复杂任务上从头训练效率低下，而迁移学习在大语言模型中已证明有效。本文旨在将迁移学习应用于连续时间强化学习，提高训练效率。

Method: 采用策略迁移方法，使用源任务的最优策略初始化目标任务学习。在连续时间LQR框架下进行理论分析，并开发新的策略学习算法。

Result: 首次证明了连续时间RL中策略迁移的理论有效性：一个LQR的最优策略可作为相关LQR的近最优初始化，同时保持原算法的收敛速度。新算法实现了全局线性和局部超线性收敛。

Conclusion: 研究填补了连续时间RL中迁移学习的理论空白，证明了策略迁移的理论保证和算法优势，并将相关工作从离散时间扩展到连续时间设置。

Abstract: Reinforcement Learning (RL) enables agents to learn optimal decision-making
strategies through interaction with an environment, yet training from scratch
on complex tasks can be highly inefficient. Transfer learning (TL), widely
successful in large language models (LLMs), offers a promising direction for
enhancing RL efficiency by leveraging pre-trained models.
  This paper investigates policy transfer, a TL approach that initializes
learning in a target RL task using a policy from a related source task, in the
context of continuous-time linear quadratic regulators (LQRs) with entropy
regularization. We provide the first theoretical proof of policy transfer for
continuous-time RL, proving that a policy optimal for one LQR serves as a
near-optimal initialization for closely related LQRs, while preserving the
original algorithm's convergence rate. Furthermore, we introduce a novel policy
learning algorithm for continuous-time LQRs that achieves global linear and
local super-linear convergence. Our results demonstrate both theoretical
guarantees and algorithmic benefits of transfer learning in continuous-time RL,
addressing a gap in existing literature and extending prior work from discrete
to continuous time settings.
  As a byproduct of our analysis, we derive the stability of a class of
continuous-time score-based diffusion models via their connection with LQRs.

</details>


### [15] [Learning Correlated Reward Models: Statistical Barriers and Opportunities](https://arxiv.org/abs/2510.15839)
*Yeshwanth Cherapanamjeri,Constantinos Daskalakis,Gabriele Farina,Sobhan Mohammadpour*

Main category: cs.LG

TL;DR: 本文研究了学习相关probit模型的统计和计算挑战，发现传统的成对偏好数据无法学习相关性信息，而三选一偏好数据能够有效克服这一限制，并提出了高效的估计算法。


<details>
  <summary>Details</summary>
Motivation: 随机效用模型在人类反馈强化学习中发挥关键作用，但许多技术依赖于无关选项独立性假设，这限制了人类偏好的精细建模。本文旨在研究避免该假设的相关probit模型的学习挑战。

Method: 首先分析成对偏好数据在学习相关性信息方面的根本不足，然后证明三选一偏好数据能够克服这些限制，并开发了统计和计算高效的估计算法。

Result: 理论分析表明三选一偏好数据能够提供学习相关性信息的能力，提出的估计算法具有近最优性能。在多个真实数据集上的验证显示该方法能够改善人类偏好的个性化建模。

Conclusion: 高阶偏好数据在学习相关效用方面具有显著优势，能够实现更精细的人类偏好建模，为个性化偏好建模提供了新的理论和方法基础。

Abstract: Random Utility Models (RUMs) are a classical framework for modeling user
preferences and play a key role in reward modeling for Reinforcement Learning
from Human Feedback (RLHF). However, a crucial shortcoming of many of these
techniques is the Independence of Irrelevant Alternatives (IIA) assumption,
which collapses \emph{all} human preferences to a universal underlying utility
function, yielding a coarse approximation of the range of human preferences. On
the other hand, statistical and computational guarantees for models avoiding
this assumption are scarce. In this paper, we investigate the statistical and
computational challenges of learning a \emph{correlated} probit model, a
fundamental RUM that avoids the IIA assumption. First, we establish that the
classical data collection paradigm of pairwise preference data is
\emph{fundamentally insufficient} to learn correlational information,
explaining the lack of statistical and computational guarantees in this
setting. Next, we demonstrate that \emph{best-of-three} preference data
provably overcomes these shortcomings, and devise a statistically and
computationally efficient estimator with near-optimal performance. These
results highlight the benefits of higher-order preference data in learning
correlated utilities, allowing for more fine-grained modeling of human
preferences. Finally, we validate these theoretical guarantees on several
real-world datasets, demonstrating improved personalization of human
preferences.

</details>


### [16] [ReasonIF: Large Reasoning Models Fail to Follow Instructions During Reasoning](https://arxiv.org/abs/2510.15211)
*Yongchan Kwon,Shang Zhu,Federico Bianchi,Kaitlyn Zhou,James Zou*

Main category: cs.LG

TL;DR: 论文提出ReasonIF基准来评估大型推理模型在推理过程中遵循用户指令的能力，发现现有模型指令遵循率低于25%，并探索了多轮推理和指令微调两种改进方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要评估模型主要回答的指令遵循性，但推理过程中的指令遵循对模型可控性、透明性和减少不良行为同样重要。

Method: 引入ReasonIF基准，包含六类指令提示，评估多种开源大型推理模型，并探索多轮推理和推理指令微调两种改进策略。

Result: 现有模型推理指令遵循率普遍低于25%，任务难度增加时表现更差；推理指令微调将GPT-OSS-20B的指令遵循得分从0.11提升到0.27。

Conclusion: 大型推理模型在推理过程中的指令遵循能力存在显著不足，需要进一步改进以确保可靠性和安全性。

Abstract: The ability of large language models (LLMs) to follow user instructions is
central to their reliability, safety, and usefulness. While prior studies
assess instruction adherence in the model's main responses, we argue that it is
also critical for large reasoning models (LRMs) to follow user instructions
throughout their reasoning process. Reasoning instruction following makes LRMs
more controllable and transparent, while reducing risks of undesirable
shortcuts, hallucinations, or reward hacking within reasoning traces. To
evaluate this dimension, we introduce ReasonIF, a systematic benchmark for
assessing reasoning instruction following. ReasonIF includes six categories of
instruction prompts, spanning multilingual reasoning, formatting and length
control. Across many open-source LRMs including GPT-OSS, Qwen3, and
DeepSeek-R1, we find substantial failures in reasoning instruction adherence:
the highest instruction following score (IFS) remains below 0.25, meaning that
fewer than $25\%$ of reasoning traces comply with the given instructions.
Notably, as task difficulty increases, reasoning instruction following degrades
further. We also explore two strategies to enhance reasoning instruction
fidelity. (1) multi-turn reasoning and (2) Reasoning Instruction Finetuning
(RIF) using synthetic data. RIF improves the IFS of $GPT-OSS-20B$ from 0.11 to
0.27, indicating measurable progress but leaving ample room for improvement.

</details>


### [17] [Soundness-Aware Level: A Microscopic Signature that Predicts LLM Reasoning Potential](https://arxiv.org/abs/2510.15216)
*Xuansheng Wu,Xiaoman Pan,Wenlin Yao,Jianshu Chen*

Main category: cs.LG

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Reinforcement learning with verifiable rewards (RLVR) can elicit strong
reasoning in large language models (LLMs), while their performance after RLVR
varies dramatically across different base models. This raises a fundamental
question: what microscopic property of pre-trained models leads to this
variation? To investigate, we formalize reasoning as chains of Horn clauses
("if-then" rules) built from features extracted from the LLM's latent space via
cross-layer sparse autoencoders (SAEs). We estimate the transition
probabilities between its features, and further categorize each rule by its
semantic soundness level (e.g., strict, plausible, noisy) with an LLM. Our key
discovery is that high-potential models are inherently soundness-aware: their
internal probability distributions systematically shift across rules' soundness
levels, becoming highly distinct for "strict" versus "noisy" rules. In
contrast, weaker models are soundness-agnostic, collapsing to one distribution
regardless of soundness levels. To quantify this, we introduce the
Soundness-Aware Level (SAL), a microscopic metric using the Jensen-Shannon
Divergence to measure the separation between these distributions. We show that
SAL's predictions of post-RLVR reasoning performance follow a precise empirical
law (R^2=0.87) across diverse model families (Qwen, Mistral, Llama, DeepSeek)
and scales (0.5B-14B). This reveals that a model's reasoning potential is tied
to its intrinsic, pre-trained ability to distinguish sound knowledge from
unsound ones. These findings underscore the critical role of model pre-training
in shaping reasoning and offer a practical metric grounded in the model's
internal mechanisms for selecting/designing stronger base models.

</details>


### [18] [Reflections from Research Roundtables at the Conference on Health, Inference, and Learning (CHIL) 2025](https://arxiv.org/abs/2510.15217)
*Emily Alsentzer,Marie-Laure Charpignon,Bill Chen,Niharika D'Souza,Jason Fries,Yixing Jiang,Aparajita Kashyap,Chanwoo Kim,Simon Lee,Aishwarya Mandyam,Ashery Christopher Mbilinyi,Nikita Mehandru,Nitish Nagesh,Brighton Nuwagira,Emma Pierson,Arvind Pillai,Akane Sano,Tanveer Syeda-Mahmood,Shashank Yadav,Elias Adhanom,Muhammad Umar Afza,Amelia Archer,Suhana Bedi,Vasiliki Bikia,Trenton Chang,George H. Chen,Winston Chen,Erica Chiang,Edward Choi,Octavia Ciora,Paz Dozie-Nnamah,Shaza Elsharief,Matthew Engelhard,Ali Eshragh,Jean Feng,Josh Fessel,Scott Fleming,Kei Sen Fong,Thomas Frost,Soham Gadgil,Judy Gichoya,Leeor Hershkovich,Sujeong Im,Bhavya Jain,Vincent Jeanselme,Furong Jia,Qixuan,Jin,Yuxuan Jin,Daniel Kapash,Geetika Kapoor,Behdokht Kiafar,Matthias Kleiner,Stefan Kraft,Annika Kumar,Daeun Kyung,Zhongyuan Liang,Joanna Lin,Qianchu,Liu,Chang Liu,Hongzhou Luan,Chris Lunt,Leopoldo Julían Lechuga López,Matthew B. A. McDermott,Shahriar Noroozizadeh,Connor O'Brien,YongKyung Oh,Mixail Ota,Stephen Pfohl,Meagan Pi,Tanmoy Sarkar Pias,Emma Rocheteau,Avishaan Sethi,Toru Shirakawa,Anita Silver,Neha Simha,Kamile Stankeviciute,Max Sunog,Peter Szolovits,Shengpu Tang,Jialu Tang,Aaron Tierney,John Valdovinos,Byron Wallace,Will Ke Wang,Peter Washington,Jeremy Weiss,Daniel Wolfe,Emily Wong,Hye Sun Yun,Xiaoman Zhang,Xiao Yu Cindy Zhang,Hayoung Jeong,Kaveri A. Thakoor*

Main category: cs.LG

TL;DR: CHIL 2025会议举办了8个研究圆桌会议，聚焦机器学习与医疗交叉领域的关键主题，包括可解释性、公平性、因果推断等，旨在促进协作对话和集体创新。


<details>
  <summary>Details</summary>
Motivation: 为了在机器学习和医疗保健的交叉领域催化协作性小群体对话，讨论关键及时的主题，促进开放交流、知识好奇心和包容性参与。

Method: 通过由资深和初级主席团队主持的研究圆桌会议，强调对关键挑战的严格讨论、新兴机会的探索以及集体构思可操作方向。

Result: 成功举办了8个圆桌会议，涉及19位主席，覆盖了可解释性、不确定性、因果性、领域适应、基础模型、小医疗数据学习、多模态方法和可扩展转化医疗解决方案等主题。

Conclusion: 研究圆桌会议为医疗机器学习领域提供了有效的协作平台，促进了关键挑战的深入讨论和集体创新，推动了该领域的可操作发展方向。

Abstract: The 6th Annual Conference on Health, Inference, and Learning (CHIL 2025),
hosted by the Association for Health Learning and Inference (AHLI), was held in
person on June 25-27, 2025, at the University of California, Berkeley, in
Berkeley, California, USA. As part of this year's program, we hosted Research
Roundtables to catalyze collaborative, small-group dialogue around critical,
timely topics at the intersection of machine learning and healthcare. Each
roundtable was moderated by a team of senior and junior chairs who fostered
open exchange, intellectual curiosity, and inclusive engagement. The sessions
emphasized rigorous discussion of key challenges, exploration of emerging
opportunities, and collective ideation toward actionable directions in the
field. In total, eight roundtables were held by 19 roundtable chairs on topics
of "Explainability, Interpretability, and Transparency," "Uncertainty, Bias,
and Fairness," "Causality," "Domain Adaptation," "Foundation Models," "Learning
from Small Medical Data," "Multimodal Methods," and "Scalable, Translational
Healthcare Solutions."

</details>


### [19] [Integrating Product Coefficients for Improved 3D LiDAR Data Classification (Part II)](https://arxiv.org/abs/2510.15219)
*Patricia Medina,Rasika Karkare*

Main category: cs.LG

TL;DR: 本研究扩展了先前关于使用乘积系数增强3D LiDAR点云分类的工作，通过结合自编码器表示和KNN分类器，相比PCA基线和早期框架获得了一致的性能提升。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过结合乘积系数与自编码器表示来进一步提升LiDAR点云分类性能，并研究不同层级乘积系数对分类效果的影响。

Method: 将乘积系数与自编码器表示相结合，使用KNN分类器进行分类，并逐级添加乘积系数来研究其对分类性能的影响。

Result: 实验结果表明，结合乘积系数与自编码器表示相比PCA基线和早期框架获得了更好的性能，且更丰富的系数集合能系统性地提高类别可分性和整体准确率。

Conclusion: 分层乘积系数特征与自编码器的结合对于推动LiDAR分类性能具有重要价值，更丰富的系数集合能带来更好的分类效果。

Abstract: This work extends our previous study on enhancing 3D LiDAR point-cloud
classification with product coefficients
\cite{medina2025integratingproductcoefficientsimproved}, measure-theoretic
descriptors that complement the original spatial Lidar features. Here, we show
that combining product coefficients with an autoencoder representation and a
KNN classifier delivers consistent performance gains over both PCA-based
baselines and our earlier framework. We also investigate the effect of adding
product coefficients level by level, revealing a clear trend: richer sets of
coefficients systematically improve class separability and overall accuracy.
The results highlight the value of combining hierarchical product-coefficient
features with autoencoders to push LiDAR classification performance further.

</details>


### [20] [FinTrust: A Comprehensive Benchmark of Trustworthiness Evaluation in Finance Domain](https://arxiv.org/abs/2510.15232)
*Tiansheng Hu,Tongyan Hu,Liuyang Bai,Yilun Zhao,Arman Cohan,Chen Zhao*

Main category: cs.LG

TL;DR: FinTrust是一个专门用于评估金融领域LLM可信度的综合基准，涵盖多种对齐问题，并对11个LLM进行了评估。


<details>
  <summary>Details</summary>
Motivation: 由于金融领域的高风险和高利害特性，在真实金融应用中部署LLM仍然具有挑战性，需要专门的可信度评估基准。

Method: 设计FinTrust基准，基于实际情境构建广泛的对齐问题，并为每个可信度维度提供细粒度任务，评估11个LLM的表现。

Result: 专有模型如o4-mini在大多数任务（如安全性）中表现更好，而开源模型如DeepSeek-V3在特定领域（如行业级公平性）具有优势；所有LLM在信托对齐和披露等挑战性任务上表现不佳。

Conclusion: FinTrust可以作为金融领域LLM可信度评估的有价值基准，当前LLM在法律意识方面仍存在显著差距。

Abstract: Recent LLMs have demonstrated promising ability in solving finance related
problems. However, applying LLMs in real-world finance application remains
challenging due to its high risk and high stakes property. This paper
introduces FinTrust, a comprehensive benchmark specifically designed for
evaluating the trustworthiness of LLMs in finance applications. Our benchmark
focuses on a wide range of alignment issues based on practical context and
features fine-grained tasks for each dimension of trustworthiness evaluation.
We assess eleven LLMs on FinTrust and find that proprietary models like o4-mini
outperforms in most tasks such as safety while open-source models like
DeepSeek-V3 have advantage in specific areas like industry-level fairness. For
challenging task like fiduciary alignment and disclosure, all LLMs fall short,
showing a significant gap in legal awareness. We believe that FinTrust can be a
valuable benchmark for LLMs' trustworthiness evaluation in finance domain.

</details>


### [21] [Expediting Reinforcement Learning by Incorporating Knowledge About Temporal Causality in the Environment](https://arxiv.org/abs/2510.15456)
*Jan Corazza,Hadi Partovi Aria,Daniel Neider,Zhe Xu*

Main category: cs.LG

TL;DR: 本文提出了一种将时序逻辑因果图集成到概率奖励机中的新方法，以解决强化学习在稀疏奖励任务中的学习困难，加速策略学习并促进任务规范在不同环境间的迁移。


<details>
  <summary>Details</summary>
Motivation: 强化学习算法在处理奖励反馈稀疏且依赖于环境中复杂事件序列的任务时存在困难。概率奖励机虽然能捕捉奖励信号中的时间依赖性，但难以手动修改和设计，这阻碍了利用高层因果知识和在不同因果结构领域间迁移奖励形式化方法。

Method: 提出将时序逻辑因果图形式化的因果信息集成到奖励形式化中的方法，通过结合概率奖励机和因果图来构建更有效的奖励结构。

Result: 提供了关于方法收敛到最优策略的理论结果，并通过实证研究证明了该方法的优势。

Conclusion: 所提出的方法能够有效加速策略学习，并促进任务规范在不同环境间的迁移，为解决稀疏奖励强化学习问题提供了新的解决方案。

Abstract: Reinforcement learning (RL) algorithms struggle with learning optimal
policies for tasks where reward feedback is sparse and depends on a complex
sequence of events in the environment. Probabilistic reward machines (PRMs) are
finite-state formalisms that can capture temporal dependencies in the reward
signal, along with nondeterministic task outcomes. While special RL algorithms
can exploit this finite-state structure to expedite learning, PRMs remain
difficult to modify and design by hand. This hinders the already difficult
tasks of utilizing high-level causal knowledge about the environment, and
transferring the reward formalism into a new domain with a different causal
structure. This paper proposes a novel method to incorporate causal information
in the form of Temporal Logic-based Causal Diagrams into the reward formalism,
thereby expediting policy learning and aiding the transfer of task
specifications to new environments. Furthermore, we provide a theoretical
result about convergence to optimal policy for our method, and demonstrate its
strengths empirically.

</details>


### [22] [Spatiotemporal Transformers for Predicting Avian Disease Risk from Migration Trajectories](https://arxiv.org/abs/2510.15254)
*Dingya Feng,Dingyuan Xue*

Main category: cs.LG

TL;DR: 本研究提出基于Transformer的框架，利用候鸟迁徙轨迹预测终点疾病风险，整合GPS追踪、疫情记录和地理空间数据，在测试集上取得高精度预测性能。


<details>
  <summary>Details</summary>
Motivation: 准确预测禽类疾病暴发对野生动物保护和公共卫生至关重要，需要开发能够捕捉候鸟迁徙模式与疾病传播关系的预测模型。

Method: 集成多源数据集（Movebank GPS追踪数据、WOAH疫情记录、GADM和Natural Earth地理空间数据），使用H3分层地理空间编码处理原始坐标，基于Transformer架构学习鸟群移动序列的时空依赖性来估计终点疾病风险。

Result: 在测试集上表现出色：准确率0.9821，ROC曲线下面积0.9803，平均精度0.9299，F1分数0.8836（最优阈值下）。

Conclusion: Transformer架构在禽类疾病监测早期预警系统中具有巨大潜力，能够支持及时的干预和预防策略。

Abstract: Accurate forecasting of avian disease outbreaks is critical for wildlife
conservation and public health. This study presents a Transformer-based
framework for predicting the disease risk at the terminal locations of
migratory bird trajectories. We integrate multi-source datasets, including GPS
tracking data from Movebank, outbreak records from the World Organisation for
Animal Health (WOAH), and geospatial context from GADM and Natural Earth. The
raw coordinates are processed using H3 hierarchical geospatial encoding to
capture spatial patterns. The model learns spatiotemporal dependencies from
bird movement sequences to estimate endpoint disease risk. Evaluation on a
held-out test set demonstrates strong predictive performance, achieving an
accuracy of 0.9821, area under the ROC curve (AUC) of 0.9803, average precision
(AP) of 0.9299, and an F1-score of 0.8836 at the optimal threshold. These
results highlight the potential of Transformer architectures to support
early-warning systems for avian disease surveillance, enabling timely
intervention and prevention strategies.

</details>


### [23] [Language Models are Injective and Hence Invertible](https://arxiv.org/abs/2510.15511)
*Giorgos Nikolaou,Tommaso Mencattini,Donato Crisostomi,Andrea Santilli,Yannis Panagakis,Emanuele Rodola'*

Main category: cs.LG

TL;DR: 本文证明Transformer语言模型在将离散输入序列映射为连续表示时是单射的，因此是无损的，并提出了首个能精确从隐藏激活重建输入文本的算法SipIt。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为Transformer组件如非线性激活和归一化本质上是非单射的，可能导致不同输入映射到相同输出，阻碍从模型表示中精确恢复输入。本文挑战这一观点。

Method: 首先数学证明Transformer语言模型在初始化和训练过程中保持单射性；其次在六个最先进语言模型上进行数十亿次碰撞测试；最后提出SipIt算法，该算法能证明且高效地从隐藏激活重建精确输入文本。

Result: 数学证明和实证测试均确认Transformer语言模型是单射的，未观察到任何碰撞；SipIt算法在实践中实现了精确可逆性，并具有线性时间保证。

Conclusion: 单射性是语言模型的基本且可利用的属性，对透明度、可解释性和安全部署具有直接意义。

Abstract: Transformer components such as non-linear activations and normalization are
inherently non-injective, suggesting that different inputs could map to the
same output and prevent exact recovery of the input from a model's
representations. In this paper, we challenge this view. First, we prove
mathematically that transformer language models mapping discrete input
sequences to their corresponding sequence of continuous representations are
injective and therefore lossless, a property established at initialization and
preserved during training. Second, we confirm this result empirically through
billions of collision tests on six state-of-the-art language models, and
observe no collisions. Third, we operationalize injectivity: we introduce
SipIt, the first algorithm that provably and efficiently reconstructs the exact
input text from hidden activations, establishing linear-time guarantees and
demonstrating exact invertibility in practice. Overall, our work establishes
injectivity as a fundamental and exploitable property of language models, with
direct implications for transparency, interpretability, and safe deployment.

</details>


### [24] [CQD-SHAP: Explainable Complex Query Answering via Shapley Values](https://arxiv.org/abs/2510.15623)
*Parsa Abbasi,Stefan Heindorf*

Main category: cs.LG

TL;DR: CQD-SHAP是一个基于Shapley值的可解释性框架，用于分析复杂查询回答中各个查询部分对特定答案排名的贡献，解决了现有神经符号方法缺乏查询部分重要性解释的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的复杂查询回答方法多为黑盒模型，缺乏用户信任。虽然神经符号方法如CQD具有一定的可解释性，能够追踪中间结果，但无法解释查询中不同部分的重要性。

Method: 基于合作博弈论中的Shapley值，提出CQD-SHAP框架，计算每个查询部分对特定答案排名的贡献，满足所有基本Shapley公理。

Result: 通过必要性和充分性解释的自动化评估，以及与多种基线的比较，表明该方法对大多数查询类型都有效。

Conclusion: CQD-SHAP能够解释神经预测器从不完整知识图谱中推断新知识的价值，相比仅依赖知识图谱中现有事实的符号方法具有更好的可解释性。

Abstract: Complex query answering (CQA) goes beyond the well-studied link prediction
task by addressing more sophisticated queries that require multi-hop reasoning
over incomplete knowledge graphs (KGs). Research on neural and neurosymbolic
CQA methods is still an emerging field. Almost all of these methods can be
regarded as black-box models, which may raise concerns about user trust.
Although neurosymbolic approaches like CQD are slightly more interpretable,
allowing intermediate results to be tracked, the importance of different parts
of the query remains unexplained. In this paper, we propose CQD-SHAP, a novel
framework that computes the contribution of each query part to the ranking of a
specific answer. This contribution explains the value of leveraging a neural
predictor that can infer new knowledge from an incomplete KG, rather than a
symbolic approach relying solely on existing facts in the KG. CQD-SHAP is
formulated based on Shapley values from cooperative game theory and satisfies
all the fundamental Shapley axioms. Automated evaluation of these explanations
in terms of necessary and sufficient explanations, and comparisons with various
baselines, shows the effectiveness of this approach for most query types.

</details>


### [25] [ProSh: Probabilistic Shielding for Model-free Reinforcement Learning](https://arxiv.org/abs/2510.15720)
*Edwin Hamel-De le Court,Gaspard Ohlmann,Francesco Belardinelli*

Main category: cs.LG

TL;DR: ProSh是一种无模型的安全强化学习算法，通过风险预算增强状态空间，使用学习到的成本评论器对策略分布施加保护罩，确保所有采样动作在期望上保持安全。


<details>
  <summary>Details</summary>
Motivation: 强化学习系统的安全性是主要关注点，需要开发既能最优执行又能提供正式安全保证的系统。

Method: 引入概率保护罩通过风险增强（ProSh），在约束MDP状态空间中增加风险预算，使用学习到的成本评论器对策略分布施加保护罩。

Result: 在确定性环境中保持最优性，提供仅依赖于备份评论器准确度的成本期望紧上界，实验显示在训练期间也能保证安全性。

Conclusion: ProSh能够在训练期间提供安全保证，同时保持最优性能，适用于无模型的安全强化学习场景。

Abstract: Safety is a major concern in reinforcement learning (RL): we aim at
developing RL systems that not only perform optimally, but are also safe to
deploy by providing formal guarantees about their safety. To this end, we
introduce Probabilistic Shielding via Risk Augmentation (ProSh), a model-free
algorithm for safe reinforcement learning under cost constraints. ProSh
augments the Constrained MDP state space with a risk budget and enforces safety
by applying a shield to the agent's policy distribution using a learned cost
critic. The shield ensures that all sampled actions remain safe in expectation.
We also show that optimality is preserved when the environment is
deterministic. Since ProSh is model-free, safety during training depends on the
knowledge we have acquired about the environment. We provide a tight
upper-bound on the cost in expectation, depending only on the backup-critic
accuracy, that is always satisfied during training. Under mild, practically
achievable assumptions, ProSh guarantees safety even at training time, as shown
in the experiments.

</details>


### [26] [Iterative Refinement of Flow Policies in Probability Space for Online Reinforcement Learning](https://arxiv.org/abs/2510.15388)
*Mingyang Sun,Pengxiang Ding,Weinan Zhang,Donglin Wang*

Main category: cs.LG

TL;DR: SWFP框架通过将流匹配推理过程离散化为固定步长的欧拉格式，将其与最优传输的变分JKO原理对齐，实现了预训练流模型的高效稳定微调。


<details>
  <summary>Details</summary>
Motivation: 行为克隆中的流/扩散策略虽然擅长从演示中学习复杂技能，但对分布偏移很脆弱，且标准RL方法由于迭代推理过程和现有解决方案的局限性而难以微调这些模型。

Method: SWFP将全局流分解为一系列邻近分布之间的小增量变换序列，每个步骤对应一个JKO更新，通过熵正则化确保策略变化保持在先前迭代附近，实现稳定的在线适应。

Result: 实验表明SWFP在多种机器人控制基准测试中展现出增强的稳定性、效率和优越的适应性能。

Conclusion: SWFP框架通过分解为小流块级联，提供了更简单/更快的子模型训练、降低的计算/内存成本以及基于Wasserstein信任区域的可证明稳定性。

Abstract: While behavior cloning with flow/diffusion policies excels at learning
complex skills from demonstrations, it remains vulnerable to distributional
shift, and standard RL methods struggle to fine-tune these models due to their
iterative inference process and the limitations of existing workarounds. In
this work, we introduce the Stepwise Flow Policy (SWFP) framework, founded on
the key insight that discretizing the flow matching inference process via a
fixed-step Euler scheme inherently aligns it with the variational
Jordan-Kinderlehrer-Otto (JKO) principle from optimal transport. SWFP
decomposes the global flow into a sequence of small, incremental
transformations between proximate distributions. Each step corresponds to a JKO
update, regularizing policy changes to stay near the previous iterate and
ensuring stable online adaptation with entropic regularization. This
decomposition yields an efficient algorithm that fine-tunes pre-trained flows
via a cascade of small flow blocks, offering significant advantages:
simpler/faster training of sub-models, reduced computational/memory costs, and
provable stability grounded in Wasserstein trust regions. Comprehensive
experiments demonstrate SWFP's enhanced stability, efficiency, and superior
adaptation performance across diverse robotic control benchmarks.

</details>


### [27] [SNOO: Step-K Nesterov Outer Optimizer - The Surprising Effectiveness of Nesterov Momentum Applied to Pseudo-Gradients](https://arxiv.org/abs/2510.15830)
*Dominik Kallusky,Vinay Rao,Vishal Nandavanam,Hao-Jun Michael Shi*

Main category: cs.LG

TL;DR: 论文提出SNOO优化器，通过将Nesterov动量应用于伪梯度，在非分布式设置中实现了1.5-2.5倍的计算效率提升，且改进效果随模型规模增大而增强。


<details>
  <summary>Details</summary>
Motivation: 研究发现DiLoCo优化器在非分布式设置中表现出色的原因主要是其对伪梯度应用了Nesterov动量，这启发了开发更高效的优化技术。

Method: 提出Step-K Nesterov Outer Optimizer (SNOO)，这是一个Lookahead变体，在快速权重上执行多个内部优化器步骤生成伪梯度轨迹，然后对伪梯度应用Nesterov动量来更新慢速权重。

Result: SNOO在非分布式设置中实现了1.5-2.5倍的计算因子增益，训练FLOPs规模可达1e23，且改进效果随模型规模增大而增强。

Conclusion: SNOO因其最小的计算和内存开销以及与模型分片的兼容性，成为适用于包括AdamW和Muon在内的各种内部优化器的实用增强方法。

Abstract: The rapid development of large language models (LLMs) has driven the demand
for more efficient optimization techniques. Among these, the Lookahead family
of optimizers employs a two-loop framework, maintaining fast and slow sets of
model weights. Multiple inner optimizer steps on the fast weights produce a
trajectory - the pseudo-gradient - that is used to update the slow weights.
DiLoCo, a notable example originally designed for distributed training, applies
Nesterov momentum to the averaged pseudo-gradient from multiple workers,
claiming to even outperform AdamW in a non-distributed setup. In this paper, we
empirically show that DiLoCo's surprising effectiveness stems primarily from
applying Nesterov momentum to the pseudo-gradient, which improves training in a
non-distributed setting. We call this Lookahead variant the Step-$K$ Nesterov
Outer Optimizer (SNOO). We demonstrate that SNOO achieves compute factor gains
of 1.5 - 2.5$\times$ in a non-distributed setting up to a scale of 1e23
training FLOPs, with improvements that increase with model size. Because of its
minimal compute and memory overhead and compatibility with model sharding, SNOO
is a practical enhancement for a variety of inner optimizers, including AdamW
and Muon.

</details>


### [28] [Online Kernel Dynamic Mode Decomposition for Streaming Time Series Forecasting with Adaptive Windowing](https://arxiv.org/abs/2510.15404)
*Christopher Salazar,Krithika Manohar,Ashis G. Banerjee*

Main category: cs.LG

TL;DR: WORK-DMD是一种用于流数据实时预测的新方法，结合随机傅里叶特征和在线动态模式分解，通过显式特征映射捕获非线性动态，同时保持固定计算成本和竞争性预测精度。


<details>
  <summary>Details</summary>
Motivation: 解决流数据实时预测中的关键挑战：处理非平稳动态、在严格计算限制下运行、快速适应而不发生灾难性遗忘。现有方法在准确性、适应性和效率之间存在权衡。

Method: 结合随机傅里叶特征与在线动态模式分解，使用Sherman-Morrison更新在滚动窗口内实现连续适应，仅需当前数据，无需大量历史数据存储或长时间训练。

Result: 在多个领域的基准数据集上，WORK-DMD比几种最先进的在线预测方法获得更高准确性，仅需单次数据遍历，在短期预测中表现尤为出色。

Conclusion: 将核评估与自适应矩阵更新相结合，以最小数据需求实现强预测性能，为流预测应用提供了深度学习的实用替代方案。

Abstract: Real-time forecasting from streaming data poses critical challenges: handling
non-stationary dynamics, operating under strict computational limits, and
adapting rapidly without catastrophic forgetting. However, many existing
approaches face trade-offs between accuracy, adaptability, and efficiency,
particularly when deployed in constrained computing environments. We introduce
WORK-DMD (Windowed Online Random Kernel Dynamic Mode Decomposition), a method
that combines Random Fourier Features with online Dynamic Mode Decomposition to
capture nonlinear dynamics through explicit feature mapping, while preserving
fixed computational cost and competitive predictive accuracy across evolving
data. WORK-DMD employs Sherman-Morrison updates within rolling windows,
enabling continuous adaptation to evolving dynamics from only current data,
eliminating the need for lengthy training or large storage requirements for
historical data. Experiments on benchmark datasets across several domains show
that WORK-DMD achieves higher accuracy than several state-of-the-art online
forecasting methods, while requiring only a single pass through the data and
demonstrating particularly strong performance in short-term forecasting. Our
results show that combining kernel evaluations with adaptive matrix updates
achieves strong predictive performance with minimal data requirements. This
sample efficiency offers a practical alternative to deep learning for streaming
forecasting applications.

</details>


### [29] [ParaFormer: Shallow Parallel Transformers with Progressive Approximation](https://arxiv.org/abs/2510.15425)
*Wei Wang,Xiao-Yong Wei,Qing Li*

Main category: cs.LG

TL;DR: ParaFormer是一种浅层Transformer架构，通过并行分支结构实现真正的结构和计算并行化，解决了深度模型训练时间长、推理延迟高的问题，在性能和效率上都优于标准Transformer。


<details>
  <summary>Details</summary>
Motivation: 解决深度Transformer模型带来的训练时间长、推理延迟高以及在资源受限设备上不可行的问题，挑战'越深越好'的传统观念。

Method: 将标准Transformer建模为闭式函数逼近器，通过理论分析发现性能依赖于层间协作而非深度本身。ParaFormer通过将层组织成并行分支，算法性地强制层间协作，实现渐进逼近。

Result: ParaFormer在实验中优于标准Transformer如ViT，支持高达15.07倍的模型压缩，并促进自适应持续学习的模型扩展。在多GPU部署中比FairScale等并行解决方案快3.30倍。

Conclusion: 基于通用逼近定理的闭式Transformer公式不仅解释了'深度信念'，还为设计高效Transformer架构开辟了新途径。

Abstract: The widespread 'deeper is better' philosophy has driven the creation of
architectures like ResNet and Transformer, which achieve high performance by
stacking numerous layers. However, increasing model depth comes with challenges
such as longer training times, higher inference latency, and impracticality on
resource-constrained devices. To address these issues, we propose ParaFormer, a
shallow Transformer architecture designed for true parallelism in both
structure and computation. By formulating standard Transformers as function
approximators in closed-form, our theoretical analysis shows that their
performance relies on inter-layer collaboration for progressive approximation,
rather than depth itself. While deep Transformers enforce this collaboration
through sequential designs, we demonstrate that such collaboration is not
inherently tied to sequential structures. ParaFormer removes the sequential
constraint by organizing layers into parallel branches, enforcing inter-layer
collaboration algorithmically. Specifically, we implement progressive
approximation, ensuring that each new branch further reduces the loss from
preceding branches, enabling faster convergence. Extensive experiments validate
ParaFormer's effectiveness, outperforming standard Transformers like ViT.
Moreover, ParaFormer supports up to 15.07x model compression and facilitates
model expansion for adaptive continuous learning. Experimental results on
multi-GPU deployment demonstrate that ParaFormer is 3.30x faster than widely
used parallelism solutions such as FairScale. These advancements stem from our
closed-form formulation of Transformers based on the Universal Approximation
Theorem, which not only explains the ``depth belief'' but also opens new
avenues for designing efficient Transformer architectures. Source code:
https://(open-upon-acceptance)

</details>


### [30] [An Empirical Study on MC Dropout--Based Uncertainty--Error Correlation in 2D Brain Tumor Segmentation](https://arxiv.org/abs/2510.15541)
*Saumya B*

Main category: cs.LG

TL;DR: 本研究评估了MC Dropout方法在脑肿瘤MRI分割中识别边界误差的有效性，发现其不确定性估计与分割误差的相关性较弱，特别是在边界区域几乎无相关性。


<details>
  <summary>Details</summary>
Motivation: 尽管MC Dropout被广泛用于模型不确定性估计，但其在识别分割误差（特别是肿瘤边界附近）方面的有效性尚不明确，这对于医学图像分割的诊断和治疗规划至关重要。

Method: 使用U-Net在四种数据增强设置（无增强、水平翻转、旋转、缩放）下进行2D脑肿瘤MRI分割，通过50次随机前向传播计算MC Dropout不确定性，并使用Pearson和Spearman系数分析不确定性与像素级误差的相关性。

Result: 结果显示全局相关性较弱（r≈0.30-0.38），边界相关性可忽略不计（|r|<0.05）。虽然不同增强设置间的差异具有统计显著性（p<0.001），但缺乏实际相关性。

Conclusion: MC Dropout不确定性在边界误差定位方面提供的线索有限，强调了在医学图像分割中需要替代或混合不确定性估计方法。

Abstract: Accurate brain tumor segmentation from MRI is vital for diagnosis and
treatment planning. Although Monte Carlo (MC) Dropout is widely used to
estimate model uncertainty, its effectiveness in identifying segmentation
errors -- especially near tumor boundaries -- remains unclear. This study
empirically examines the relationship between MC Dropout--based uncertainty and
segmentation error in 2D brain tumor MRI segmentation using a U-Net trained
under four augmentation settings: none, horizontal flip, rotation, and scaling.
Uncertainty was computed from 50 stochastic forward passes and correlated with
pixel-wise errors using Pearson and Spearman coefficients. Results show weak
global correlations ($r \approx 0.30$--$0.38$) and negligible boundary
correlations ($|r| < 0.05$). Although differences across augmentations were
statistically significant ($p < 0.001$), they lacked practical relevance. These
findings suggest that MC Dropout uncertainty provides limited cues for boundary
error localization, underscoring the need for alternative or hybrid uncertainty
estimation methods in medical image segmentation.

</details>


### [31] [Fast and Compact Tsetlin Machine Inference on CPUs Using Instruction-Level Optimization](https://arxiv.org/abs/2510.15653)
*Yefan Zeng,Shengyu Duan,Rishad Shafik,Alex Yakovlev*

Main category: cs.LG

TL;DR: 本文提出了一种高效的Tsetlin机器软件实现，通过位运算、提前退出机制和文字重排序策略，在ARM处理器上实现高达96.71%的推理时间减少。


<details>
  <summary>Details</summary>
Motivation: Tsetlin机器在资源受限设备上提供高速推理，其逻辑驱动操作适合在现代CPU架构上并行执行，这激发了对其高效软件实现的研究。

Method: 利用指令级位运算进行紧凑模型表示和加速处理；引入提前退出机制避免不必要计算；提出文字重排序策略最大化提前退出可能性；在训练后、推理前阶段通过统计分析应用该策略。

Result: 使用gem5模拟器和ARM处理器的实验结果显示，优化实现相比传统基于整数的TM实现减少了高达96.71%的推理时间，同时保持相当的代码密度。

Conclusion: 通过位运算、提前退出和文字重排序的组合优化，显著提升了Tsetlin机器的推理效率，使其更适合在资源受限设备上部署。

Abstract: The Tsetlin Machine (TM) offers high-speed inference on resource-constrained
devices such as CPUs. Its logic-driven operations naturally lend themselves to
parallel execution on modern CPU architectures. Motivated by this, we propose
an efficient software implementation of the TM by leveraging instruction-level
bitwise operations for compact model representation and accelerated processing.
To further improve inference speed, we introduce an early exit mechanism, which
exploits the TM's AND-based clause evaluation to avoid unnecessary
computations. Building upon this, we propose a literal Reorder strategy
designed to maximize the likelihood of early exits. This strategy is applied
during a post-training, pre-inference stage through statistical analysis of all
literals and the corresponding actions of their associated Tsetlin Automata
(TA), introducing negligible runtime overhead. Experimental results using the
gem5 simulator with an ARM processor show that our optimized implementation
reduces inference time by up to 96.71% compared to the conventional
integer-based TM implementations while maintaining comparable code density.

</details>


### [32] [Poultry Farm Intelligence: An Integrated Multi-Sensor AI Platform for Enhanced Welfare and Productivity](https://arxiv.org/abs/2510.15757)
*Pieris Panagi,Savvas Karatsiolis,Kyriacos Mosphilis,Nicholas Hadjisavvas,Andreas Kamilaris,Nicolas Nicolaou,Efstathios Stavrakis,Vassilis Vassiliades*

Main category: cs.LG

TL;DR: PoultryFI是一个面向中小型家禽养殖场的低成本AI平台，集成了摄像头布局优化、视听监控、分析预警、实时鸡蛋计数、生产预测和推荐系统六大模块，通过边缘计算实现全自动化监测和决策支持。


<details>
  <summary>Details</summary>
Motivation: 中小型家禽养殖场缺乏经济实惠的集成化监控工具，依赖人工检查难以满足生产效率、动物福利和环保要求，需要开发低成本、智能化的解决方案。

Method: 采用进化算法优化摄像头布局实现全覆盖，通过同步视频、音频和饲喂数据的视听监控提取福利指标，使用边缘视觉模型进行实时鸡蛋计数，结合天气预报进行生产预测和操作建议。

Result: 现场试验显示在树莓派5上实现100%鸡蛋计数准确率，具备稳健的异常检测能力和可靠的短期预测性能。

Conclusion: PoultryFI填补了孤立试点工具与可扩展农场智能系统之间的空白，帮助生产者主动保障动物福利和盈利能力。

Abstract: Poultry farming faces increasing pressure to meet productivity targets while
ensuring animal welfare and environmental compliance. Yet many small and
medium-sized farms lack affordable, integrated tools for continuous monitoring
and decision-making, relying instead on manual, reactive inspections. This
paper presents Poultry Farm Intelligence (PoultryFI) - a modular,
cost-effective platform that integrates six AI-powered modules: Camera
Placement Optimizer, Audio-Visual Monitoring, Analytics & Alerting, Real-Time
Egg Counting, Production & Profitability Forecasting, and a Recommendation
Module.
  Camera layouts are first optimized offline using evolutionary algorithms for
full poultry house coverage with minimal hardware. The Audio-Visual Monitoring
module extracts welfare indicators from synchronized video, audio, and feeding
data. Analytics & Alerting produces daily summaries and real-time
notifications, while Real-Time Egg Counting uses an edge vision model to
automate production tracking. Forecasting models predict egg yield and feed
consumption up to 10 days in advance, and the Recommendation Module integrates
forecasts with weather data to guide environmental and operational adjustments.
  This is among the first systems to combine low-cost sensing, edge analytics,
and prescriptive AI to continuously monitor flocks, predict production, and
optimize performance. Field trials demonstrate 100% egg-count accuracy on
Raspberry Pi 5, robust anomaly detection, and reliable short-term forecasting.
PoultryFI bridges the gap between isolated pilot tools and scalable, farm-wide
intelligence, empowering producers to proactively safeguard welfare and
profitability.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [33] [OpenEstimate: Evaluating LLMs on Reasoning Under Uncertainty with Real-World Data](https://arxiv.org/abs/2510.15096)
*Alana Renda,Jillian Ross,Michael Cafarella,Jacob Andreas*

Main category: cs.AI

TL;DR: OpenEstimate是一个用于评估语言模型在不确定性下进行数值估计任务的多领域基准测试，发现前沿语言模型生成的先验概率通常不准确且过于自信。


<details>
  <summary>Details</summary>
Motivation: 现实世界中语言模型需要在信息不完整的情况下进行不确定性推理，但现有评估主要关注有明确答案的问题，缺乏对不确定性推理能力的评估。

Method: 引入OpenEstimate基准测试，评估语言模型在需要综合大量背景信息并以概率先验形式表达预测的数值估计任务上的表现，评估其准确性和校准度。

Result: 在六个前沿语言模型上的测试显示，模型生成的先验概率通常不准确且过于自信。性能在不同不确定性引导方式下略有改善，但在采样策略、推理努力或提示设计方面的变化影响不大。

Conclusion: OpenEstimate为前沿语言模型提供了一个具有挑战性的评估平台，可用于开发在概率估计和不确定性推理方面表现更好的模型。

Abstract: Real-world settings where language models (LMs) are deployed -- in domains
spanning healthcare, finance, and other forms of knowledge work -- require
models to grapple with incomplete information and reason under uncertainty. Yet
most LM evaluations focus on problems with well-defined answers and success
criteria. This gap exists in part because natural problems involving
uncertainty are difficult to construct: given that LMs have access to most of
the same knowledge as humans, it is non-trivial to design questions for which
LMs will struggle to produce correct answers, but which humans can answer
reliably. As a result, LM performance on reasoning under uncertainty remains
poorly characterized. To address this gap, we introduce OpenEstimate, an
extensible, multi-domain benchmark for evaluating LMs on numerical estimation
tasks that require models to synthesize significant amounts of background
information and express predictions as probabilistic priors. We assess these
priors for accuracy and calibration, quantifying their usefulness relative to
samples from the true distribution of interest. Across six frontier LMs, we
find that LM-elicited priors are often inaccurate and overconfident.
Performance improves modestly depending on how uncertainty is elicited from the
model, but is largely unaffected by changes in sampling strategy, reasoning
effort, or prompt design. The OpenEstimate benchmark thus offers a challenging
evaluation for frontier LMs and a platform for developing models that are
better at probabilistic estimation and reasoning under uncertainty.

</details>


### [34] [Towards Error Centric Intelligence I, Beyond Observational Learning](https://arxiv.org/abs/2510.15128)
*Marcus A. Thomas*

Main category: cs.AI

TL;DR: 该论文认为AGI进展受理论限制而非数据或规模限制，挑战了柏拉图表示假说，提出因果力学框架，强调假设空间变化作为首要操作，通过结构原则使错误发现和修正变得可行。


<details>
  <summary>Details</summary>
Motivation: 当前AGI发展面临理论瓶颈，观测等价世界在干预下可能产生分歧，仅靠观测充分性无法保证干预能力，需要从观测学习转向错误中心化方法。

Method: 提出因果力学框架，将假设空间变化作为首要操作，引入局部性和自主性原则、独立因果机制、组合自主性原则等结构原则，并提供可操作的诊断方法。

Result: 构建了一个能够将不可达错误转化为可达错误并进行修正的系统框架，为AGI发展提供了新的理论方向。

Conclusion: AGI进展的关键在于理论突破而非数据扩展，因果力学框架通过系统化的错误发现和修正机制，为解决AGI的理论限制提供了可行的路径。

Abstract: We argue that progress toward AGI is theory limited rather than data or scale
limited. Building on the critical rationalism of Popper and Deutsch, we
challenge the Platonic Representation Hypothesis. Observationally equivalent
worlds can diverge under interventions, so observational adequacy alone cannot
guarantee interventional competence. We begin by laying foundations,
definitions of knowledge, learning, intelligence, counterfactual competence and
AGI, and then analyze the limits of observational learning that motivate an
error centric shift. We recast the problem as three questions about how
explicit and implicit errors evolve under an agent's actions, which errors are
unreachable within a fixed hypothesis space, and how conjecture and criticism
expand that space. From these questions we propose Causal Mechanics, a
mechanisms first program in which hypothesis space change is a first class
operation and probabilistic structure is used when useful rather than presumed.
We advance structural principles that make error discovery and correction
tractable, including a differential Locality and Autonomy Principle for modular
interventions, a gauge invariant form of Independent Causal Mechanisms for
separability, and the Compositional Autonomy Principle for analogy
preservation, together with actionable diagnostics. The aim is a scaffold for
systems that can convert unreachable errors into reachable ones and correct
them.

</details>


### [35] [HugAgent: Evaluating LLMs in Simulating Human-Like Individual Reasoning on Open-Ended Tasks](https://arxiv.org/abs/2510.15144)
*Chance Jiajie Li,Zhenze Mo,Yuhan Tang,Ao Qu,Jiayi Wu,Kaiya Ivy Zhao,Yulu Gan,Jie Fan,Jiangbo Yu,Hang Jiang,Paul Pu Liang,Jinhua Zhao,Luis Alberto Alonso Pastor,Kent Larson*

Main category: cs.AI

TL;DR: HugAgent是一个用于评估AI模型从群体推理适应到个体推理的基准测试，包含合成和人类双轨设计，旨在让机器推理更贴近人类个体思维。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型主要反映群体共识，缺乏对个体推理风格和信念轨迹的捕捉，需要开发能模拟个体人类推理的AI系统。

Method: 采用双轨设计：合成轨道用于规模化和系统压力测试，人类轨道提供生态有效的出声推理数据，通过部分历史观点证据预测个体在全新场景中的推理和信念更新。

Result: 实验显示最先进的大语言模型在个体适应方面仍存在持续差距，HugAgent成为首个可扩展的基准测试。

Conclusion: HugAgent为机器推理与人类个体思维的对齐提供了首个可扩展的评估框架，推动了更人性化AI推理的发展。

Abstract: Simulating human reasoning in open-ended tasks has been a long-standing
aspiration in AI and cognitive science. While large language models now
approximate human responses at scale, they remain tuned to population-level
consensus, often erasing the individuality of reasoning styles and belief
trajectories. To advance the vision of more human-like reasoning in machines,
we introduce HugAgent (Human-Grounded Agent Benchmark), a benchmark for
average-to-individual reasoning adaptation. The task is to predict how a
specific person would reason and update their beliefs in novel scenarios, given
partial evidence of their past views. HugAgent adopts a dual-track design: a
synthetic track for scale and systematic stress tests, and a human track for
ecologically valid, "out-loud" reasoning data. This design enables scalable,
reproducible evaluation of intra-agent fidelity: whether models can capture not
just what people believe, but how their reasoning evolves. Experiments with
state-of-the-art LLMs reveal persistent adaptation gaps, positioning HugAgent
as the first extensible benchmark for aligning machine reasoning with the
individuality of human thought. Our benchmark and chatbot are open-sourced as
HugAgent (https://anonymous.4open.science/r/HugAgent) and TraceYourThinking
(https://anonymous.4open.science/r/trace-your-thinking).

</details>


### [36] [WELD: A Large-Scale Longitudinal Dataset of Emotional Dynamics for Ubiquitous Affective Computing](https://arxiv.org/abs/2510.15221)
*Xiao Sun*

Main category: cs.AI

TL;DR: 提出了一个包含733,651个面部表情记录的大规模纵向工作场所情感数据集，涵盖38名员工30.5个月的数据，包含情绪概率和元数据，验证了已知心理模式并展示了高预测性能。


<details>
  <summary>Details</summary>
Motivation: 解决真实工作场所环境中情感识别面临的挑战，特别是缺乏大规模、自然环境下收集的纵向数据集的问题。

Method: 收集38名员工在30.5个月内的面部表情数据，使用深度学习进行情感识别，计算32个扩展情感指标，并进行技术验证和基线实验。

Result: 数据集成功复制了已知心理模式（周末效应：+192%效价改善，p<0.001），员工流失预测AUC=1.0，情感分类准确率91.2%，效价预测R²=0.84。

Conclusion: 这是目前公开可用的最大、最长的纵向工作场所情感数据集，为情感识别、情感动态建模、情感传染等研究提供了重要资源。

Abstract: Automated emotion recognition in real-world workplace settings remains a
challenging problem in affective computing due to the scarcity of large-scale,
longitudinal datasets collected in naturalistic environments. We present a
novel dataset comprising 733,651 facial expression records from 38 employees
collected over 30.5 months (November 2021 to May 2024) in an authentic office
environment. Each record contains seven emotion probabilities (neutral, happy,
sad, surprised, fear, disgusted, angry) derived from deep learning-based facial
expression recognition, along with comprehensive metadata including job roles,
employment outcomes, and personality traits. The dataset uniquely spans the
COVID-19 pandemic period, capturing emotional responses to major societal
events including the Shanghai lockdown and policy changes. We provide 32
extended emotional metrics computed using established affective science
methods, including valence, arousal, volatility, predictability, inertia, and
emotional contagion strength. Technical validation demonstrates high data
quality through successful replication of known psychological patterns (weekend
effect: +192% valence improvement, p < 0.001; diurnal rhythm validated) and
perfect predictive validity for employee turnover (AUC=1.0). Baseline
experiments using Random Forest and LSTM models achieve 91.2% accuracy for
emotion classification and R2 = 0.84 for valence prediction. This is the
largest and longest longitudinal workplace emotion dataset publicly available,
enabling research in emotion recognition, affective dynamics modeling,
emotional contagion, turnover prediction, and emotion-aware system design.

</details>


### [37] [Towards Flash Thinking via Decoupled Advantage Policy Optimization](https://arxiv.org/abs/2510.15374)
*Zezhong Tan,Hang Gao,Xinhong Ma,Feng Zhang,Ziqiang Dong*

Main category: cs.AI

TL;DR: DEPO是一个新的强化学习框架，旨在减少大型推理模型中的低效推理，通过解耦优势算法、难度感知长度惩罚和优势剪裁方法，显著缩短响应长度39%同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习算法虽然提高了模型准确性，但存在响应过长和过度思考问题，导致推理延迟和计算消耗增加，特别是对于简单任务。

Method: DEPO框架包含三个核心组件：创新的优势解耦算法减少低效token；难度感知长度惩罚降低整体响应长度；优势剪裁方法防止策略优化偏差。

Result: 在DeepSeek-Distill-Qwen-7B和1.5B模型上，DEPO实现了序列长度减少39%，减少了低效token中的过度推理路径，同时在整体准确性上优于基础模型。

Conclusion: DEPO有效解决了大型推理模型中的低效推理问题，在保持准确性的同时显著减少了响应长度和计算消耗。

Abstract: Recent Large Reasoning Models (LRMs) have achieved remarkable performance in
solving complex problems via supervised fine-tuning (SFT) and reinforcement
learning (RL). Although existing RL algorithms significantly enhance model
accuracy, they still suffer from excessively lengthy responses and overthinking
issues, resulting in increased inference latency and computational consumption,
especially for simple tasks that require minimal reasoning. To address this, we
propose a novel RL framework, DEPO, to reduce inefficient reasoning for models.
Our method mainly consists of three core components: (1) an innovative
advantage decoupled algorithm to guide model reduction of inefficient tokens;
(2) a difficulty-aware length penalty to lower the overall length of model
responses; (3) an advantage clipping method to prevent bias in policy
optimization. In our experiments, applied to DeepSeek-Distill-Qwen-7B and
DeepSeek-Distill-Qwen-1.5B as base models, DEPO achieves a significant
reduction in sequence length by 39% and reduces excessive reasoning paths in
inefficient tokens, while outperforming the base model in overall accuracy.

</details>


### [38] [Adaptive Minds: Empowering Agents with LoRA-as-Tools](https://arxiv.org/abs/2510.15416)
*Pavan C Shekar,Ashwanth Krishnan*

Main category: cs.AI

TL;DR: Adaptive Minds是一个将LoRA适配器作为领域专用工具的智能体系统，让基础LLM作为语义路由器动态选择最相关的LoRA工具，实现按需切换领域专家。


<details>
  <summary>Details</summary>
Motivation: 旨在解决单一微调模型或基于规则路由的局限性，通过结合多智能体编排的灵活性和参数高效微调的高效性，提供准确的专业化响应同时保持对话能力。

Method: 使用基础LLM作为语义路由器分析每个查询，动态选择最相关的LoRA工具；基于LangGraph构建工作流管理，支持API和Web接口。

Result: 系统能够无缝在不同领域专家之间切换，提供准确的专业化响应，同时保持对话能力；系统完全开源，提供可扩展和可扩展的领域自适应AI助手基础。

Conclusion: Adaptive Minds通过将LoRA适配器作为工具的动态选择机制，成功实现了灵活高效的领域自适应AI助手，为构建可扩展的智能系统提供了有效解决方案。

Abstract: We present Adaptive Minds, an agentic system that treats LoRA adapters as
domain-specific tools. Instead of relying on a single fine-tuned model or rigid
rule-based routing, our approach empowers the base LLM itself to act as a
semantic router analyzing each query and dynamically selecting the most
relevant LoRA tool. This enables the agent to seamlessly switch between
different domain experts on demand. By combining the flexibility of multi-agent
orchestration with the efficiency of parameter-efficient fine-tuning, Adaptive
Minds delivers accurate, specialized responses while preserving conversational
ability. The system is built with LangGraph for workflow management, supports
both API and web interfaces, and is fully open source, providing a scalable and
extensible foundation for domain-adaptive AI assistance.

</details>


### [39] [Context-aware deep learning using individualized prior information reduces false positives in disease risk prediction and longitudinal health assessment](https://arxiv.org/abs/2510.15591)
*Lavanya Umapathy,Patricia M Johnson,Tarun Dutt,Angela Tong,Madhur Nayan,Hersh Chandarana,Daniel K Sodickson*

Main category: cs.AI

TL;DR: 开发了一个整合患者历史就诊信息的机器学习框架，通过结合当前和既往的医学数据来改进前列腺癌风险预测，显著降低了假阳性率。


<details>
  <summary>Details</summary>
Motivation: 医学中的时间背景信息对于评估患者健康状况随时间变化至关重要，特别是在既往就诊次数有限且频率不固定的情况下，需要整合多样化的历史背景信息来改善健康监测。

Method: 模型首先使用最近一次就诊的医学数据估计疾病初始风险，然后通过消化既往收集的影像学和/或临床生物标志物信息来完善评估。

Result: 整合历史背景信息将假阳性转化为真阴性，总体特异性提高同时保持高敏感性。整合最多三次既往影像检查信息时，假阳性率从51%降至33%，加入既往临床数据后进一步降至24%。预测五年内前列腺癌风险时，假阳性率从64%降至9%。

Conclusion: 随时间收集的信息提供了相关背景，可增强医学风险预测的特异性。对于广泛进展性疾病，通过背景信息充分降低假阳性率可为扩展纵向健康监测项目提供途径，从而实现早期检测和改善健康结果。

Abstract: Temporal context in medicine is valuable in assessing key changes in patient
health over time. We developed a machine learning framework to integrate
diverse context from prior visits to improve health monitoring, especially when
prior visits are limited and their frequency is variable. Our model first
estimates initial risk of disease using medical data from the most recent
patient visit, then refines this assessment using information digested from
previously collected imaging and/or clinical biomarkers. We applied our
framework to prostate cancer (PCa) risk prediction using data from a large
population (28,342 patients, 39,013 magnetic resonance imaging scans, 68,931
blood tests) collected over nearly a decade. For predictions of the risk of
clinically significant PCa at the time of the visit, integrating prior context
directly converted false positives to true negatives, increasing overall
specificity while preserving high sensitivity. False positive rates were
reduced progressively from 51% to 33% when integrating information from up to
three prior imaging examinations, as compared to using data from a single
visit, and were further reduced to 24% when also including additional context
from prior clinical data. For predicting the risk of PCa within five years of
the visit, incorporating prior context reduced false positive rates still
further (64% to 9%). Our findings show that information collected over time
provides relevant context to enhance the specificity of medical risk
prediction. For a wide range of progressive conditions, sufficient reduction of
false positive rates using context could offer a pathway to expand longitudinal
health monitoring programs to large populations with comparatively low baseline
risk of disease, leading to earlier detection and improved health outcomes.

</details>


### [40] [Build Your Personalized Research Group: A Multiagent Framework for Continual and Interactive Science Automation](https://arxiv.org/abs/2510.15624)
*Ed Li,Junyu Ren,Xintian Pan,Cat Yan,Chuanhao Li,Dirk Bergemann,Zhuoran Yang*

Main category: cs.AI

TL;DR: 提出了一个名为freephdlabor的开源多智能体框架，通过动态工作流和模块化架构实现科学发现的自动化，解决了现有系统工作流程僵化和上下文管理不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有科学发现自动化系统存在两个根本限制：僵化的预编程工作流程无法适应中间发现，以及不充分的上下文管理阻碍了长期研究。

Method: 采用完全动态工作流（由实时智能体推理决定）、模块化架构（允许用户修改、添加或移除智能体）、自动上下文压缩、基于工作空间的通信、跨会话内存持久化和非阻塞人工干预机制。

Result: 该框架将自动化研究从孤立的单次尝试转变为持续的研究程序，能够系统性地建立在先前探索基础上并整合人类反馈。

Conclusion: 通过提供构建可定制合作科学家系统的架构原则和实际实现，这项工作旨在促进自动化研究在科学领域的更广泛采用，使从业者能够部署交互式多智能体系统来自主进行端到端研究。

Abstract: The automation of scientific discovery represents a critical milestone in
Artificial Intelligence (AI) research. However, existing agentic systems for
science suffer from two fundamental limitations: rigid, pre-programmed
workflows that cannot adapt to intermediate findings, and inadequate context
management that hinders long-horizon research. We present
\texttt{freephdlabor}, an open-source multiagent framework featuring
\textit{fully dynamic workflows} determined by real-time agent reasoning and a
\coloremph{\textit{modular architecture}} enabling seamless customization --
users can modify, add, or remove agents to address domain-specific
requirements. The framework provides comprehensive infrastructure including
\textit{automatic context compaction}, \textit{workspace-based communication}
to prevent information degradation, \textit{memory persistence} across
sessions, and \textit{non-blocking human intervention} mechanisms. These
features collectively transform automated research from isolated, single-run
attempts into \textit{continual research programs} that build systematically on
prior explorations and incorporate human feedback. By providing both the
architectural principles and practical implementation for building customizable
co-scientist systems, this work aims to facilitate broader adoption of
automated research across scientific domains, enabling practitioners to deploy
interactive multiagent systems that autonomously conduct end-to-end research --
from ideation through experimentation to publication-ready manuscripts.

</details>


### [41] [Invoice Information Extraction: Methods and Performance Evaluation](https://arxiv.org/abs/2510.15727)
*Sai Yashwant,Anurag Dubey,Praneeth Paikray,Gantala Thulsiram*

Main category: cs.AI

TL;DR: 本文提出了从发票文档中提取结构化信息的方法，并建立了一套评估指标来衡量提取数据与标注真实值的准确性。


<details>
  <summary>Details</summary>
Motivation: 需要标准化评估发票信息提取方法，比较不同提取技术的性能，并识别各字段提取的优缺点。

Method: 使用Docling和LlamaCloud服务对扫描或数字发票进行预处理，识别并提取关键字段如发票号码、日期、总金额和供应商详情。

Result: 建立了包含字段级精度、一致性检查失败和精确匹配准确率的稳健评估框架。

Conclusion: 提出的评估指标为比较不同提取方法提供了标准化方式，并能突出显示字段特定性能的强弱项。

Abstract: This paper presents methods for extracting structured information from
invoice documents and proposes a set of evaluation metrics (EM) to assess the
accuracy of the extracted data against annotated ground truth. The approach
involves pre-processing scanned or digital invoices, applying Docling and
LlamaCloud Services to identify and extract key fields such as invoice number,
date, total amount, and vendor details. To ensure the reliability of the
extraction process, we establish a robust evaluation framework comprising
field-level precision, consistency check failures, and exact match accuracy.
The proposed metrics provide a standardized way to compare different extraction
methods and highlight strengths and weaknesses in field-specific performance.

</details>


### [42] [Towards Relaxed Multimodal Inputs for Gait-based Parkinson's Disease Assessment](https://arxiv.org/abs/2510.15748)
*Minlin Zeng,Zhipeng Zhou,Yang Qiu,Zhiqi Shen*

Main category: cs.AI

TL;DR: 提出了首个将多模态学习建模为多目标优化问题的帕金森病评估系统TRIP，解决了传统多模态方法在训练时需要同步所有模态、推理时依赖所有模态的限制，并处理了模态崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 传统多模态方法存在两个主要限制：(1)训练时需要同步所有模态，(2)推理时依赖所有模态，这阻碍了实际应用。

Method: 将多模态学习建模为多目标优化问题，引入基于边界的类别重平衡策略来缓解模态内不平衡问题。

Result: 在三个公共数据集上的实验表明，TRIP在异步设置下比最佳基线分别提升16.48、6.89和11.55个百分点，在同步设置下分别提升4.86和2.30个百分点。

Conclusion: TRIP框架在帕金森病评估中实现了最先进的性能，具有出色的有效性和适应性。

Abstract: Parkinson's disease assessment has garnered growing interest in recent years,
particularly with the advent of sensor data and machine learning techniques.
Among these, multimodal approaches have demonstrated strong performance by
effectively integrating complementary information from various data sources.
However, two major limitations hinder their practical application: (1) the need
to synchronize all modalities during training, and (2) the dependence on all
modalities during inference. To address these issues, we propose the first
Parkinson's assessment system that formulates multimodal learning as a
multi-objective optimization (MOO) problem. This not only allows for more
flexible modality requirements during both training and inference, but also
handles modality collapse issue during multimodal information fusion. In
addition, to mitigate the imbalance within individual modalities, we introduce
a margin-based class rebalancing strategy to enhance category learning. We
conduct extensive experiments on three public datasets under both synchronous
and asynchronous settings. The results show that our framework-Towards Relaxed
InPuts (TRIP)-achieves state-of-the-art performance, outperforming the best
baselines by 16.48, 6.89, and 11.55 percentage points in the asynchronous
setting, and by 4.86 and 2.30 percentage points in the synchronous setting,
highlighting its effectiveness and adaptability.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [43] [Data-driven Calibration Sample Selection and Forecast Combination in Electricity Price Forecasting: An Application of the ARHNN Method](https://arxiv.org/abs/2510.15011)
*Tomasz Serafin,Weronika Nitka*

Main category: stat.AP

TL;DR: 本文提出了一种结合校准样本选择和预测组合的ARHNN方法，在电力价格预测中显著提升准确性，并开发了两种简化版本以降低计算成本，在电池储能交易案例中验证了其商业价值。


<details>
  <summary>Details</summary>
Motivation: 校准样本选择和预测组合是两种简单但强大的预测工具，但在电力价格预测领域尚未充分探索。本文旨在将这些方法应用于电力市场预测，提高预测准确性。

Method: 使用自回归混合最近邻（ARHNN）方法，结合校准样本选择和预测组合技术，应用于德国、西班牙和新英格兰电力市场的长期时间序列数据。

Result: ARHNN方法在预测准确性上比流行文献基准高出10%，提出的两种简化版本大幅降低计算时间而仅轻微损失准确性。在电池储能交易案例中，基于预测的策略可实现理论最大利润的80%。

Conclusion: ARHNN方法及其简化版本在电力价格预测中表现出色，具有实际商业应用价值，特别是在能源交易策略中能显著提升盈利能力。

Abstract: Calibration sample selection and forecast combination are two simple yet
powerful tools used in forecasting. They can be combined with a variety of
models to significantly improve prediction accuracy, at the same time offering
easy implementation and low computational complexity. While their effectiveness
has been repeatedly confirmed in prior scientific literature, the topic is
still underexplored in the field of electricity price forecasting. In this
research article we apply the Autoregressive Hybrid Nearest Neighbors (ARHNN)
method to three long-term time series describing the German, Spanish and New
England electricity markets. We show that it outperforms popular literature
benchmarks in terms of forecast accuracy by up to 10%. We also propose two
simplified variants of the method, granting a vast decrease in computation time
with only minor loss of prediction accuracy. Finally, we compare the forecasts'
performance in a battery storage system trading case study. We find that using
a forecast-driven strategy can achieve up to 80% of theoretical maximum profits
while trading, demonstrating business value in practical applications.

</details>


### [44] [Residual Kriging for Regional-Scale Canopy Height Mapping: Insights into GEDI-Induced Anisotropies and Sparse Sampling](https://arxiv.org/abs/2510.15572)
*Kamel Lahssini,Guerric le Maire,Nicolas Baghdadi,Ibrahim Fayad*

Main category: stat.AP

TL;DR: 本研究比较了基于U-Net深度学习模型(CHNET)和随机森林算法(RFH)的冠层高度估算，发现GEDI激光雷达数据的采集参数会引入空间不一致性。通过残差克里金空间插值技术处理空间自相关性，显著提高了两种模型的精度，特别是RFH模型。


<details>
  <summary>Details</summary>
Motivation: 在全球气候变化背景下，准确量化地上生物量至关重要。冠层高度与地上生物量相关，可以利用多源空间数据和GEDI测量通过机器学习模型进行制图。

Method: 使用GEDI激光雷达数据训练U-Net深度学习模型(CHNET)和随机森林算法(RFH)，输入包括光学、雷达和环境数据。通过残差克里金空间插值技术处理空间自相关性，特别关注GEDI功率束和轨道方位角方向。

Result: 添加残差克里金校正后，CHNET和RFH的性能均得到改善，RFH的改进更为显著。校正效果集中在GEDI采样点周围，可用GEDI信息的密度是空间插值有效性的重要因素。

Conclusion: 随机森林模型结合空间插值可以达到与单独使用U-Net模型相当的性能，表明简单模型结合适当的空间处理方法可以取得良好效果。

Abstract: Quantifying aboveground biomass (AGB) is essential in the context of global
climate change. Canopy height, which is related to AGB, can be mapped using
machine learning models trained with multi-source spatial data and GEDI
measurements. In this study, a comparative analysis of canopy height estimates
derived from two models is presented: a U-Net deep learning model (CHNET) and a
Random Forest algorithm (RFH). Both models were trained using GEDI lidar data
and utilized multi-source inputs, including optical, radar, and environmental
data. While CHNET can leverage its convolutional architecture to account for
spatial correlations, we observed that it does not fully incorporate all the
spatial autocorrelation present in GEDI canopy height measurements. By
conducting a spatial analysis of the models' residuals, we also identified that
GEDI data acquisition parameters, particularly the variability in laser beam
energy combined with the azimuthal directions of the observation tracks,
introduce spatial inconsistencies in the measurements in the form of periodic
patterns. To address these anisotropies, we considered exclusively GEDI power
beams, and we conducted our spatial autocorrelation analysis in the GEDI track
azimuthal direction. Next, we employed the residual kriging (RK) spatial
interpolation technique to account for the spatial autocorrelation of canopy
heights and improve the accuracies of CHNET and RFH estimates. Adding RK
corrections improved the performance of both CHNET and RFH, with more
substantial gains observed for RFH. The corrections appeared to be localized
around the GEDI sample points and the density of usable GEDI information is
therefore an important factor in the effectiveness of spatial interpolation.
Furthermore, our findings reveal that a Random Forest model combined with
spatial interpolation can deliver performance comparable to that of a U-Net
model alone.

</details>


### [45] [Temporal Functional Factor Analysis of Brain Connectivity](https://arxiv.org/abs/2510.15580)
*Kyle Stanley,Nicole Lazar,Matthew Reimherr*

Main category: stat.AP

TL;DR: 提出了一种基于因子分析的功能磁共振成像功能连接分析方法，通过矩阵补全技术过滤短程空间依赖，使用分布式算法处理大规模协方差矩阵，并利用功能回归利用时间动态，为功能连接研究提供了全面且可扩展的方法。


<details>
  <summary>Details</summary>
Motivation: 功能磁共振成像中的功能连接分析通常是探索性的，但传统因子分析在应用时面临三个问题：目标子空间捕获短程空间依赖、需要分解大规模空间协方差矩阵、忽视数据中的时间依赖关系。

Method: 在功能数据分析框架下开发因子模型，使用矩阵补全技术过滤短程空间依赖，采用分布式算法分解大规模协方差矩阵，利用功能回归利用时间动态。

Result: 该方法能够有效处理功能磁共振成像数据中的空间和时间依赖关系，为功能连接研究提供了可扩展的解决方案。

Conclusion: 所提出的方法结合了矩阵补全、分布式计算和功能回归技术，为功能连接分析提供了一个全面且可扩展的框架，克服了传统因子分析在功能磁共振成像应用中的局限性。

Abstract: Many analyses of functional magnetic resonance imaging (fMRI) examine
functional connectivity (FC), or the statistical dependencies among distant
brain regions. These analyses are typically exploratory, guiding future
confirmatory research. In this work, we present an approach based on factor
analysis (FA) that is well-suited to studying FC. FA is appealing in this
context because its flexible model assumptions permit a guided investigation of
its target subspace consistent with the exploratory role of connectivity
analyses. However, applying FA to fMRI data poses three problems: (1) its
target subspace captures short-range spatial dependencies that should be
treated as noise, (2) it requires factorization of a massive spatial
covariance, and (3) it overlooks temporal dependencies in the data. To address
these limitations, we develop a factor model within the framework of functional
data analysis--a field which views certain data as arising from smooth
underlying curves. The proposed approach (1) uses matrix completion techniques
to filter short-range spatial dependencies out of its target subspace, (2)
employs a distributed algorithm for factorizing large-scale covariance
matrices, and (3) leverages functional regression to exploit temporal dynamics.
Together, these innovations yield a comprehensive and scalable method for
studying FC.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [46] [A Structured Family of Grassmannian Constellations via Geodesic Mapping for MIMO Noncoherent Communications](https://arxiv.org/abs/2510.15070)
*Álvaro Pendás-Recondo,Enrique Pendás-Recondo*

Main category: eess.SP

TL;DR: 提出了一种基于Grassmann流形测地线的新型结构化星座设计，用于MIMO非相干通信，具有单天线激活特性，降低硬件复杂度和功耗，在有限频谱效率下达到与最先进设计相当的误码性能。


<details>
  <summary>Details</summary>
Motivation: 针对MIMO非相干通信系统，在缺乏信道状态信息的情况下，设计能够降低硬件复杂度、功耗和检测计算复杂度的结构化星座方案。

Method: 基于Grassmann流形的测地曲线构建星座设计，利用流形的几何结构，确保每个时隙只有一个发射天线激活。

Result: 星座大小限制在4M²点，频谱效率0.25-1 bps/Hz，误码性能与最先进非结构化设计相当，ML检测器计算复杂度降低M倍，支持简单有效的比特标记。

Conclusion: 该结构化星座设计在保持良好误码性能的同时，显著降低了硬件复杂度、功耗和检测计算复杂度，为MIMO非相干通信提供了一种实用的解决方案。

Abstract: This work presents a novel structured family of Grassmannian constellations
for multiple-input multiple-output (MIMO) noncoherent communications over
Rayleigh block-fading channels, where neither the transmitter nor the receiver
has channel state information (CSI). The proposed constellation design is built
upon the geodesic curves of the Grassmann manifold, thereby exploiting its
underlying geometric structure. The resulting solution is limited in spectral
efficiency (with a maximum constellation size of $4M^2$ points, where $M$ is
the number of transmit antennas), targeting a rate in the range of $0.25$-$1$
bps/Hz. However, all space-time matrices resulting from this design exhibit the
remarkable property of having a single nonzero entry per row, meaning that only
one transmit antenna is active per time slot. This property significantly
reduces hardware complexity and implementation cost, while also lowering power
consumption, as only a single power amplifier is required for transmission.
Furthermore, within the constellation size limits, the proposed design achieves
error performance comparable to state-of-the-art optimization-based
unstructured designs, as validated through symbol error rate (SER) numerical
results. It also enables simple yet effective bit labeling, confirmed by
comparisons of bit error rate (BER) and SER, and reduces the computational
complexity of the maximum-likelihood (ML) detector for Grassmannian
constellations by a factor of $M$.

</details>


### [47] [Multidimensional Physiology-Inspired Enhanced Vital Sign Monitoring Using MIMO mmWave Bio-radar](https://arxiv.org/abs/2510.15278)
*Heyao Zhu,Yimeng Zhao,Zirui Zhang,Huansheng Yi,Chenbin Gao,Canhua Xu,Jianqi Wang,Fugui Qi*

Main category: eess.SP

TL;DR: 本文提出了一种基于多维生理特征的MIMO生物雷达生命体征增强检测方法，通过两阶段融合策略解决传统等权重多通道信号融合效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 随着人口老龄化加剧和慢性病负担增加，生命体征监测需求日益迫切。当前基于等权重的毫米波雷达阵列系统在多通道信号融合方面效率低下。

Method: 采用两阶段融合策略：第一阶段基于生理特征的单通道信号增强检测，构建胸壁多散射点模型，选择有效距离单元并使用相位对齐MRC增强信噪比；第二阶段基于器官辐射空间分布特征的多通道融合，首次引入心肺器官空间辐射特性作为理论基础，进行通道筛选和加权融合。

Result: 实验结果证明了器官辐射空间分布特征的存在，并从距离和状态两个方面分析了算法的影响。

Conclusion: 该方法有效克服了传统等权重多通道融合的局限性，提高了生命体征检测的效率和准确性。

Abstract: With the intensiffcation of population aging and increasing burden of chronic
diseases, the demand for vital signs monitoring is becoming increasingly
urgent. A key challenge facing current non-contact detection technologies using
millimeter wave (mmWave) radar is the low efffciency of multi-channel signal
fusion in array radar systems based on equal weighting. To address this
challenge, this paper proposes a vital sign enhancement detection method for
multiple input and multiple output (MIMO) bio-radar, driven by multidimensional
physiological characteristics, which overcomes traditional limitations through
a two-stage fusion strategy. Stage 1: Enhanced Vital Sign Detection Using
Single-Channel Signals Based on Physiological Characteristics. First, a chest
wall multi-scattering point model is constructed. For single channel
time-distance two-dimensional echo signals, effective range bins are selected
based on the respiratory/cardiac physiological frequency band energy ratio, and
the signal-to-noise ratio (SNR) of respiration/heart signals is enhanced using
phase-aligned maximal ratio combining (MRC). Stage 2: Multi-Channel Fusion
Based on Organ Radiation Spatial Distribution Characteristics. The spatial
radiation characteristics of cardiopulmonary organs are introduced for the
ffrst time as the theoretical foundation for SNR-based channel screening,
channel attribute identiffcation, and multi-channel weighted fusion. Then, we
propose a template matching method to extract respiratory rate (RR) and heart
rate (HR) by adopting physical models of respiration and cardiac activities.
The experimental results demonstrate the existence of the spatial distribution
characteristics of organ radiation. In addition, we analyzed the impact of
distance and state on the algorithm from these two aspects.

</details>


### [48] [Pseudo-Random TDM-MIMO FMCW Based Millimeter-Wave Sensing and Communication Integration for UAV Swarm](https://arxiv.org/abs/2510.15575)
*Yi Tao,Zhen Gao,Zhuoran Li,Ziwei Wan,Tuan Li,Chunli Zhu,Lei Chen,Guanghui Wen,Dezhi Zheng,Dusit Niyato*

Main category: eess.SP

TL;DR: 本文提出了一种基于伪随机时分复用MIMO毫米波调频连续波的无人机集群集成感知与通信方案，通过新型ISAC啁啾波形、伪随机天线选择和压缩感知算法，同时实现数据解调和感知参数估计。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信(ISAC)能够共享硬件和频谱资源，提高无人机集群系统的整体性能、灵活性和效率，促进无人机间的协同操作。

Method: 提出新型ISAC啁啾波形在延迟域和复振幅中调制数据；采用伪随机天线选择和压缩感知算法解决TDM-MIMO挑战；使用啁啾分多址方案实现无干扰多天线传输；提出基于通信和感知融合的动态迭代计算方案。

Result: 仿真结果表明该方案能在无人机动态飞行场景下实现ISAC，在通信和感知性能上优于毫米波-LoRadar，但感知性能略低于传统FMCW，在城市杂波建模下仍保持良好鲁棒性。

Conclusion: 所提方案成功实现了无人机集群的集成感知与通信，在动态场景下表现出良好的性能和鲁棒性。

Abstract: The integrated sensing and communications (ISAC) can achieve the sharing of
hardware and spectrum resources, enabling efficient data transmission and
environmental sensing. This fusion is particularly important for unmanned
aerial vehicle (UAV) swarms, as it enhances the overall performance,
flexibility, and efficiency of such systems. To facilitate the collaborative
operations among UAVs, this paper proposes an ISAC solution based on the
pseudo-random time-division multiplexing (TDM)-multiple input multiple output
(MIMO) millimeter-wave (mmWave) frequency modulated continuous wave (FMCW).
Specifically, a novel ISAC chirp waveform is proposed to modulate data in both
the delay domain and complex amplitude, while also possessing high-precision
sensing capabilities. To address challenges in the TDM-MIMO, we utilize the
pseudo-random antenna selection and compressed sensing algorithms, ensuring
that the maximum unambiguous velocity is not compromised. Moreover, by
employing a chirp-division multiple access scheme, we propose an
interference-free multiple antenna transmission scheme to achieve dynamic
allocation of time-frequency resources and multi-user transmission. Finally, we
propose a communication and sensing fusion-based dynamic iterative computation
scheme, simultaneously achieving data demodulation and sensing parameter
estimation. Simulation results show that the proposed scheme can achieve ISAC
under the dynamic flight scenarios of UAVs. Meanwhile, the scheme outperforms
the mmWave-LoRadar in communication and sensing performance, yet its sensing
performance is slightly lower than that of the traditional FMCW. Under the
urban clutter modeling, the scheme still maintains favorable robustness despite
a certain degree of performance degradation.

</details>


### [49] [RIS-assisted Atomic MIMO Receiver](https://arxiv.org/abs/2510.15763)
*Qihao Peng,Jiuyu Liu,Qu Luo,Yi Ma,Pei Xiao,Maged Elkashlan,George K. Karagiannidis*

Main category: eess.SP

TL;DR: 提出了一种基于可重构智能表面(RIS)的低复杂度原子MIMO接收器架构，通过PAM调制和RIS辅助来对齐信号相位，降低检测复杂度和接收器复杂度，并使用Adam梯度下降算法解决非凸优化问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统MIMO接收器相位模糊和复杂度高的问题，通过引入RIS和PAM调制来有效对齐信号相位，从而降低接收器的复杂度。

Method: 采用RIS辅助的原子MIMO接收器架构，结合PAM调制对齐信号相位，将非凸优化问题重构为Frobenius范数最小化问题，并使用Adam梯度下降算法进行高效求解。

Result: 该方法有效缓解了相位模糊问题，显著降低了信号检测复杂度和整体接收器复杂度。

Conclusion: 提出的RIS辅助原子MIMO接收器架构是一种有效的低复杂度解决方案，能够通过相位对齐和优化算法实现高性能的信号接收。

Abstract: In this paper, we propose a novel and low-complexity atomic multiple-input
multiple-output (MIMO) receiver architecture assisted by a reconfigurable
intelligent surface (RIS). By introducing RIS and utilizing pulse amplitude
modulation (PAM), the phase of the transmitted signal is effectively aligned
with that of the local oscillator (LO), thereby mitigating phase ambiguity and
substantially reducing both signal detection complexity and overall receiver
complexity.To tackle the resulting non-convex optimization problem, we
reformulate it into a tractable form by minimizing the Frobenius norm of an
equivalent matrix, which is efficiently solved using an Adam-based gradient
descent algorithm.

</details>
