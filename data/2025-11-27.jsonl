{"id": "2511.20888", "categories": ["stat.ML", "cs.CC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20888", "abs": "https://arxiv.org/abs/2511.20888", "authors": ["Arthur Jacot"], "title": "Deep Learning as a Convex Paradigm of Computation: Minimizing Circuit Size with ResNets", "comment": null, "summary": "This paper argues that DNNs implement a computational Occam's razor -- finding the `simplest' algorithm that fits the data -- and that this could explain their incredible and wide-ranging success over more traditional statistical methods. We start with the discovery that the set of real-valued function $f$ that can be $ε$-approximated with a binary circuit of size at most $cε^{-γ}$ becomes convex in the `Harder than Monte Carlo' (HTMC) regime, when $γ>2$, allowing for the definition of a HTMC norm on functions. In parallel one can define a complexity measure on the parameters of a ResNets (a weighted $\\ell_1$ norm of the parameters), which induce a `ResNet norm' on functions. The HTMC and ResNet norms can then be related by an almost matching sandwich bound. Thus minimizing this ResNet norm is equivalent to finding a circuit that fits the data with an almost minimal number of nodes (within a power of 2 of being optimal). ResNets thus appear as an alternative model for computation of real functions, better adapted to the HTMC regime and its convexity."}
{"id": "2511.21115", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21115", "abs": "https://arxiv.org/abs/2511.21115", "authors": ["Lechen Feng", "Haoran Li", "Lucky Li", "Xingqiu Zhao"], "title": "Nonconvex Penalized LAD Estimation in Partial Linear Models with DNNs: Asymptotic Analysis and Proximal Algorithms", "comment": null, "summary": "This paper investigates the partial linear model by Least Absolute Deviation (LAD) regression. We parameterize the nonparametric term using Deep Neural Networks (DNNs) and formulate a penalized LAD problem for estimation. Specifically, our model exhibits the following challenges. First, the regularization term can be nonconvex and nonsmooth, necessitating the introduction of infinite dimensional variational analysis and nonsmooth analysis into the asymptotic normality discussion. Second, our network must expand (in width, sparsity level and depth) as more samples are observed, thereby introducing additional difficulties for theoretical analysis. Third, the oracle of the proposed estimator is itself defined through a ultra high-dimensional, nonconvex, and discontinuous optimization problem, which already entails substantial computational and theoretical challenges. Under such the challenges, we establish the consistency, convergence rate, and asymptotic normality of the estimator. Furthermore, we analyze the oracle problem itself and its continuous relaxation. We study the convergence of a proximal subgradient method for both formulations, highlighting their structural differences lead to distinct computational subproblems along the iterations. In particular, the relaxed formulation admits significantly cheaper proximal updates, reflecting an inherent trade-off between statistical accuracy and computational tractability."}
{"id": "2511.20696", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20696", "abs": "https://arxiv.org/abs/2511.20696", "authors": ["Dan Li", "Hye-Bin Shin", "Yeon-Woo Choi"], "title": "Prototype-Guided Non-Exemplar Continual Learning for Cross-subject EEG Decoding", "comment": "4 pages, 2 figures, 14th IEEE International Winter Conference on Brain-Computer Interface Conference 2026", "summary": "Due to the significant variability in electroencephalogram (EEG) signals across individuals, knowledge acquired from previous subjects is often overwritten as new subjects are introduced in continual EEG decoding task. Current works mainly rely on storing the historical data of seen subjects as a replay buffer to prevent forgetting. However, privacy concerns or memory constraints make keeping such data impractical. Instead, we propose a Prototype-guided Non-Exemplar Continual Learning (ProNECL)framework that preserves prior knowledge without accessing any historical EEG samples. ProNECL constructs class-level prototypes to summarize discriminative representations from each subject and incrementally aligns new feature spaces with the global prototype memory through cross-subject feature alignment and knowledge distillation. Validated on the BCI Competition IV 2a and 2b datasets, our framework effectively balances knowledge retention and adaptability, achieving superior performance in cross-subject continual EEG decoding tasks."}
{"id": "2511.20671", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.20671", "abs": "https://arxiv.org/abs/2511.20671", "authors": ["Zhaoxin Chang", "Shuguang Xiao", "Fusang Zhang", "Xujun Ma", "Badii Jouaber", "Qingfeng Zhang", "Daqing Zhang"], "title": "WiRainbow: Single-Antenna Direction-Aware Wi-Fi Sensing via Dispersion Effect", "comment": null, "summary": "Recently, Wi-Fi signals have emerged as a powerful tool for contactless sensing. During the sensing process, obtaining target direction information can provide valuable contextual insights for various applications. Existing direction estimation methods typically rely on antenna arrays, which are costly and complex to deploy in real-world scenarios. In this paper, we present WiRainbow, a novel approach that enables single-antenna-based direction awareness for Wi-Fi sensing by leveraging the dispersion effect of frequency-scanning antennas (FSAs), which can naturally steer Wi-Fi subcarriers toward distinct angles during signal transmission. To address key challenges in antenna design and signal processing, we propose a coupled-resonator-based antenna architecture that significantly expands the narrow Field-of-View inherent in conventional FSAs, improving sensing coverage. Additionally, we develop a sensing signal-to-noise-ratio-based signal processing framework that reliably estimates target direction in multipath-rich environments. We prototype WiRainbow and evaluate its performance through benchmark experiments and real-world case studies, demonstrating its ability to achieve accurate, robust, and cost-effective direction awareness for diverse Wi-Fi sensing applications."}
{"id": "2511.20679", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20679", "abs": "https://arxiv.org/abs/2511.20679", "authors": ["Melika Ayoughi", "Pascal Mettes", "Paul Groth"], "title": "Minimizing Hyperbolic Embedding Distortion with LLM-Guided Hierarchy Restructuring", "comment": null, "summary": "Hyperbolic geometry is an effective geometry for embedding hierarchical data structures. Hyperbolic learning has therefore become increasingly prominent in machine learning applications where data is hierarchically organized or governed by hierarchical semantics, ranging from recommendation systems to computer vision. The quality of hyperbolic embeddings is tightly coupled to the structure of the input hierarchy, which is often derived from knowledge graphs or ontologies. Recent work has uncovered that for an optimal hyperbolic embedding, a high branching factor and single inheritance are key, while embedding algorithms are robust to imbalance and hierarchy size. To assist knowledge engineers in reorganizing hierarchical knowledge, this paper investigates whether Large Language Models (LLMs) have the ability to automatically restructure hierarchies to meet these criteria. We propose a prompt-based approach to transform existing hierarchies using LLMs, guided by known desiderata for hyperbolic embeddings. Experiments on 16 diverse hierarchies show that LLM-restructured hierarchies consistently yield higher-quality hyperbolic embeddings across several standard embedding quality metrics. Moreover, we show how LLM-guided hierarchy restructuring enables explainable reorganizations, providing justifications to knowledge engineers."}
{"id": "2511.21223", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21223", "abs": "https://arxiv.org/abs/2511.21223", "authors": ["Jasraj Singh", "Shelvia Wongso", "Jeremie Houssineau", "Badr-Eddine Chérief-Abdellatif"], "title": "Maxitive Donsker-Varadhan Formulation for Possibilistic Variational Inference", "comment": null, "summary": "Variational inference (VI) is a cornerstone of modern Bayesian learning, enabling approximate inference in complex models that would otherwise be intractable. However, its formulation depends on expectations and divergences defined through high-dimensional integrals, often rendering analytical treatment impossible and necessitating heavy reliance on approximate learning and inference techniques. Possibility theory, an imprecise probability framework, allows to directly model epistemic uncertainty instead of leveraging subjective probabilities. While this framework provides robustness and interpretability under sparse or imprecise information, adapting VI to the possibilistic setting requires rethinking core concepts such as entropy and divergence, which presuppose additivity. In this work, we develop a principled formulation of possibilistic variational inference and apply it to a special class of exponential-family functions, highlighting parallels with their probabilistic counterparts and revealing the distinctive mathematical structures of possibility theory."}
{"id": "2511.21526", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.21526", "abs": "https://arxiv.org/abs/2511.21526", "authors": ["Alexandra Carpentier", "Christophe Giraud", "Nicolas Verzelen"], "title": "Phase Transition for Stochastic Block Model with more than $\\sqrt{n}$ Communities (II)", "comment": null, "summary": "A fundamental theoretical question in network analysis is to determine under which conditions community recovery is possible in polynomial time in the Stochastic Block Model (SBM). When the number $K$ of communities remains smaller than $\\sqrt{n}$ --where $n$ denotes the number of nodes--, non-trivial community recovery is possible in polynomial time above, and only above, the Kesten--Stigum (KS) threshold, originally postulated using arguments from statistical physics.\n  When $K \\geq \\sqrt{n}$, Chin, Mossel, Sohn, and Wein recently proved that, in the \\emph{sparse regime}, community recovery in polynomial time is achievable below the KS threshold by counting non-backtracking paths. This finding led them to postulate a new threshold for the many-communities regime $K \\geq \\sqrt{n}$. Subsequently, Carpentier, Giraud, and Verzelen established the failure of low-degree polynomials below this new threshold across all density regimes, and demonstrated successful recovery above the threshold in certain moderately sparse settings. While these results provide strong evidence that, in the many community setting, the computational barrier lies at the threshold proposed in~Chin et al., the question of achieving recovery above this threshold still remains open in most density regimes.\n  The present work is a follow-up to~Carpentier et al., in which we prove Conjecture~1.4 stated therein by: \\\\ 1- Constructing a family of motifs satisfying specific structural properties; and\\\\ 2- Proving that community recovery is possible above the proposed threshold by counting such motifs.\\\\ Our results complete the picture of the computational barrier for community recovery in the SBM with $K \\geq \\sqrt{n}$ communities. They also indicate that, in moderately sparse regimes, the optimal algorithms appear to be fundamentally different from spectral methods."}
{"id": "2511.20702", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20702", "abs": "https://arxiv.org/abs/2511.20702", "authors": ["Chinmay Tripurwar", "Utkarsh Maurya", "Dishant"], "title": "Post-Pruning Accuracy Recovery via Data-Free Knowledge Distillation", "comment": null, "summary": "Model pruning is a widely adopted technique to reduce the computational complexity and memory footprint of Deep Neural Networks (DNNs). However, global unstructured pruning often leads to significant degradation in accuracy, typically necessitating fine-tuning on the original training dataset to recover performance. In privacy-sensitive domains such as healthcare or finance, access to the original training data is often restricted post-deployment due to regulations (e.g., GDPR, HIPAA). This paper proposes a Data-Free Knowledge Distillation framework to bridge the gap between model compression and data privacy. We utilize DeepInversion to synthesize privacy-preserving ``dream'' images from the pre-trained teacher model by inverting Batch Normalization (BN) statistics. These synthetic images serve as a transfer set to distill knowledge from the original teacher to the pruned student network. Experimental results on CIFAR-10 across various architectures (ResNet, MobileNet, VGG) demonstrate that our method significantly recovers accuracy lost during pruning without accessing a single real data point."}
{"id": "2511.20936", "categories": ["eess.SP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.20936", "abs": "https://arxiv.org/abs/2511.20936", "authors": ["Ayoob Salari", "Kai Wu", "Khawaja Fahad Masood", "Y. Jay Guo", "J. Andrew Zhang"], "title": "Wavelet-Guided Water-Level Estimation for ISAC", "comment": null, "summary": "Real-time water-level monitoring across many locations is vital for flood response, infrastructure management, and environmental forecasting. Yet many sensing methods rely on fixed instruments - acoustic, radar, camera, or pressure probes - that are costly to install and maintain and are vulnerable during extreme events. We propose a passive, low-cost water-level tracking scheme that uses only LTE downlink power metrics reported by commodity receivers. The method extracts per-antenna RSRP, RSSI, and RSRQ, applies a continuous wavelet transform (CWT) to the RSRP to isolate the semidiurnal tide component, and forms a summed-coefficient signature that simultaneously marks high/low tide (tide-turn times) and tracks the tide-rate (flow speed) over time. These wavelet features guide a lightweight neural network that learns water-level changes over time from a short training segment. Beyond a single serving base station, we also show a multi-base-station cooperative mode: independent CWTs are computed per carrier and fused by a robust median to produce one tide-band feature that improves stability and resilience to local disturbances. Experiments over a 420 m river path under line-of-sight conditions achieve root-mean-square and mean-absolute errors of 0.8 cm and 0.5 cm, respectively. Under a non-line-of-sight setting with vegetation and vessel traffic, the same model transfers successfully after brief fine-tuning, reaching 1.7 cm RMSE and 0.8 cm MAE. Unlike CSI-based methods, the approach needs no array calibration and runs on standard hardware, making wide deployment practical. When signals from multiple base stations are available, fusion further improves robustness."}
{"id": "2511.20811", "categories": ["cs.LG", "cs.AI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.20811", "abs": "https://arxiv.org/abs/2511.20811", "authors": ["Aaron O. Feldman", "D. Isaiah Harp", "Joseph Duncan", "Mac Schwager"], "title": "Conformal Safety Monitoring for Flight Testing: A Case Study in Data-Driven Safety Learning", "comment": "ICRA 2025 Workshop on Robot safety under uncertainty from intangible specifications", "summary": "We develop a data-driven approach for runtime safety monitoring in flight testing, where pilots perform maneuvers on aircraft with uncertain parameters. Because safety violations can arise unexpectedly as a result of these uncertainties, pilots need clear, preemptive criteria to abort the maneuver in advance of safety violation. To solve this problem, we use offline stochastic trajectory simulation to learn a calibrated statistical model of the short-term safety risk facing pilots. We use flight testing as a motivating example for data-driven learning/monitoring of safety due to its inherent safety risk, uncertainty, and human-interaction. However, our approach consists of three broadly-applicable components: a model to predict future state from recent observations, a nearest neighbor model to classify the safety of the predicted state, and classifier calibration via conformal prediction. We evaluate our method on a flight dynamics model with uncertain parameters, demonstrating its ability to reliably identify unsafe scenarios, match theoretical guarantees, and outperform baseline approaches in preemptive classification of risk."}
{"id": "2511.20694", "categories": ["cs.AI", "astro-ph.SR", "cs.LG", "physics.space-ph"], "pdf": "https://arxiv.org/pdf/2511.20694", "abs": "https://arxiv.org/abs/2511.20694", "authors": ["Kevin Lee", "Russell Spiewak", "James Walsh"], "title": "Reasoning With a Star: A Heliophysics Dataset and Benchmark for Agentic Scientific Reasoning", "comment": "Accepted at NeurIPS 2025 Machine Learning and the Physical Sciences (ML4PS) Workshop. Dataset: https://huggingface.co/datasets/SpaceML/ReasoningWithAStar", "summary": "Scientific reasoning through Large Language Models in heliophysics involves more than just recalling facts: it requires incorporating physical assumptions, maintaining consistent units, and providing clear scientific formats through coordinated approaches. To address these challenges, we present Reasoning With a Star, a newly contributed heliophysics dataset applicable to reasoning; we also provide an initial benchmarking approach. Our data are constructed from National Aeronautics and Space Administration & University Corporation for Atmospheric Research Living With a Star summer school problem sets and compiled into a readily consumable question-and-answer structure with question contexts, reasoning steps, expected answer type, ground-truth targets, format hints, and metadata. A programmatic grader checks the predictions using unit-aware numerical tolerance, symbolic equivalence, and schema validation. We benchmark a single-shot baseline and four multi-agent patterns, finding that decomposing workflows through systems engineering principles outperforms direct prompting on problems requiring deductive reasoning rather than pure inductive recall."}
{"id": "2511.20713", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20713", "abs": "https://arxiv.org/abs/2511.20713", "authors": ["Minhui Zhang", "Prahar Ijner", "Yoav Wald", "Elliot Creager"], "title": "Active Slice Discovery in Large Language Models", "comment": "Accepted for presentation at NeurIPS 2025 - Reliable ML Workshop", "summary": "Large Language Models (LLMs) often exhibit systematic errors on specific subsets of data, known as error slices. For instance, a slice can correspond to a certain demographic, where a model does poorly in identifying toxic comments regarding that demographic. Identifying error slices is crucial to understanding and improving models, but it is also challenging. An appealing approach to reduce the amount of manual annotation required is to actively group errors that are likely to belong to the same slice, while using limited access to an annotator to verify whether the chosen samples share the same pattern of model mistake. In this paper, we formalize this approach as Active Slice Discovery and explore it empirically on a problem of discovering human-defined slices in toxicity classification. We examine the efficacy of active slice discovery under different choices of feature representations and active learning algorithms. On several slices, we find that uncertainty-based active learning algorithms are most effective, achieving competitive accuracy using 2-10% of the available slice membership information, while significantly outperforming baselines."}
{"id": "2511.21133", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.21133", "abs": "https://arxiv.org/abs/2511.21133", "authors": ["Xi Zhang", "Miguel Bernal", "Wei-Ning Lee"], "title": "2D Sparse Array Design via Reweighted L1 Second Order Cone Programming for 3D Ultrasound Imaging", "comment": null, "summary": "Two-dimensional (2D) fully-addressed arrays can conveniently realize three-dimensional (3D) ultrasound imaging while fully controlled such arrays usually demands thousands of independent channels, which is costly. Sparse array technique using stochastic optimization methods is one of promising techniques to reduce channel counts while due to the stochastic nature of these methods, the optimized results are usually unstable. In this work, we introduce a sparse array design approach that formulates the synthesis problem of sparse arrays as second-order cone programming (SOCP) and a re-weighted L1 technique is implemented to sequentially optimize the SOCP. Based on this method, an on-grid quasi-flatten side-lobe (Q-Flats) 2D sparse array with side-lobe level (SLL) no more than -21.26 dB and 252 activated elements is designed, which aims to achieve as high contrast performance as possible under the limits of resolution and maximum number of independent channels (i.e., 256). The imaging performance of the Q-Flats array was compared with those of a corresponding dense array (Dense), a Fermat spiral array (Spiral) and a spatially 50%-Tukey tapered spiral array (Spiral-Taper) using Field II simulations in a multi-angle steered diverging wave transmission scheme. It was demonstrated that the Dense achieved the best resolution and contrast and the Spiral-Taper the worst. The Q-Flats showed better resolution (about 3%) but slightly worse contrast than the Spiral. All the results indicate the re-weighted L1 SOCP method is a promising and flexible method for seeking trade-offs among resolution, contrast, and number of activated elements."}
{"id": "2511.21274", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21274", "abs": "https://arxiv.org/abs/2511.21274", "authors": ["Junhui Rao", "Yi Liu", "Jichen Zhang", "Zhaoyang Ming", "Tianrui Qiao", "Yujie Zhang", "Chi Yuk Chiu", "Hua Wang", "Ross Murch"], "title": "Multiport Analytical Pixel Electromagnetic Simulator (MAPES) for AI-assisted RFIC and Microwave Circuit Design", "comment": null, "summary": "This paper proposes a novel analytical framework, termed the Multiport Analytical Pixel Electromagnetic Simulator (MAPES). MAPES enables efficient and accurate prediction of the electromagnetic (EM) performance of arbitrary pixel-based microwave (MW) and RFIC structures. Inspired by the Integrated Internal Multiport Method (IMPM), MAPES extends the concept to the pixel presence/absence domain used in AI-assisted EM design. By introducing virtual pixels and diagonal virtual pixels and inserting virtual ports at critical positions, MAPES captures all horizontal, vertical, and diagonal electromagnetic couplings within a single multiport impedance matrix. Only a small set of full-wave simulations (typically about 1% of the datasets required by AI-assisted EM simulators) is needed to construct this matrix. Subsequently, any arbitrary pixel configuration can be evaluated analytically using a closed-form multiport relation without additional full-wave calculations. The proposed approach eliminates data-driven overfitting and ensures accurate results across all design variations. Comprehensive examples for single- and double-layer CMOS processes (180 nm and 65 nm) and PCBs confirm that MAPES achieves high prediction accuracy with 600- 2000x speed improvement compared to CST simulations. Owing to its efficiency, scalability and reliability, MAPES provides a practical and versatile tool for AI-assisted MW circuit and RFIC design across diverse fabrication technologies."}
{"id": "2511.20893", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.20893", "abs": "https://arxiv.org/abs/2511.20893", "authors": ["Aodong Li", "Abishek Sankararaman", "Balakrishnan Narayanaswamy"], "title": "Probabilistic Hash Embeddings for Online Learning of Categorical Features", "comment": "AAAI 2026 Oral", "summary": "We study streaming data with categorical features where the vocabulary of categorical feature values is changing and can even grow unboundedly over time. Feature hashing is commonly used as a pre-processing step to map these categorical values into a feature space of fixed size before learning their embeddings. While these methods have been developed and evaluated for offline or batch settings, in this paper we consider online settings. We show that deterministic embeddings are sensitive to the arrival order of categories and suffer from forgetting in online learning, leading to performance deterioration. To mitigate this issue, we propose a probabilistic hash embedding (PHE) model that treats hash embeddings as stochastic and applies Bayesian online learning to learn incrementally from data. Based on the structure of PHE, we derive a scalable inference algorithm to learn model parameters and infer/update the posteriors of hash embeddings and other latent variables. Our algorithm (i) can handle an evolving vocabulary of categorical items, (ii) is adaptive to new items without forgetting old items, (iii) is implementable with a bounded set of parameters that does not grow with the number of distinct observed values on the stream, and (iv) is invariant to the item arrival order. Experiments in classification, sequence modeling, and recommendation systems in online learning setups demonstrate the superior performance of PHE while maintaining high memory efficiency (consumes as low as 2~4 memory of a one-hot embedding table). Supplementary materials are at https://github.com/aodongli/probabilistic-hash-embeddings"}
{"id": "2511.20725", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20725", "abs": "https://arxiv.org/abs/2511.20725", "authors": ["Deng Fucheng", "Wang Wanjie", "Gong Ao", "Wang Xiaoqi", "Wang Fan"], "title": "Gradient Descent Algorithm Survey", "comment": null, "summary": "Focusing on the practical configuration needs of optimization algorithms in deep learning, this article concentrates on five major algorithms: SGD, Mini-batch SGD, Momentum, Adam, and Lion. It systematically analyzes the core advantages, limitations, and key practical recommendations of each algorithm. The research aims to gain an in-depth understanding of these algorithms and provide a standardized reference for the reasonable selection, parameter tuning, and performance improvement of optimization algorithms in both academic research and engineering practice, helping to solve optimization challenges in different scales of models and various training scenarios."}
{"id": "2511.20927", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.20927", "abs": "https://arxiv.org/abs/2511.20927", "authors": ["Vitoria Barin-Pacela", "Kartik Ahuja", "Simon Lacoste-Julien", "Pascal Vincent"], "title": "Operationalizing Quantized Disentanglement", "comment": null, "summary": "Recent theoretical work established the unsupervised identifiability of quantized factors under any diffeomorphism. The theory assumes that quantization thresholds correspond to axis-aligned discontinuities in the probability density of the latent factors. By constraining a learned map to have a density with axis-aligned discontinuities, we can recover the quantization of the factors. However, translating this high-level principle into an effective practical criterion remains challenging, especially under nonlinear maps. Here, we develop a criterion for unsupervised disentanglement by encouraging axis-aligned discontinuities. Discontinuities manifest as sharp changes in the estimated density of factors and form what we call cliffs. Following the definition of independent discontinuities from the theory, we encourage the location of the cliffs along a factor to be independent of the values of the other factors. We show that our method, Cliff, outperforms the baselines on all disentanglement benchmarks, demonstrating its effectiveness in unsupervised disentanglement."}
{"id": "2511.21345", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.21345", "abs": "https://arxiv.org/abs/2511.21345", "authors": ["Chin-Hung Chen", "Yan Wu", "Wim van Houtum", "Alex Alvarado"], "title": "Blind Turbo Demodulation for Differentially Encoded OFDM with 2D Trellis Decomposition", "comment": "preprint", "summary": "Digital Audio Broadcasting (DAB)-like systems employ differentially encoded (DE) phase-shift keying (PSK) for transmission. While turbo-DE-PSK receivers offer substantial performance gains through iterative decoding by making the DE-PSK an inner code, they rely on accurate channel estimation without pilots, which is a key challenge in DAB-like scenarios. This paper develops a fully blind turbo-DE-PSK scheme that jointly estimates channel phase, channel gain, and noise variance directly from the received signal. The design leverages a two-dimensional (2D) trellis decomposition for blind phase estimation, complemented by power-based estimators for channel gain and noise variance. We provide a comprehensive system assessment across practical system parameters, including inner code length, phase quantization, and 2D block size. Simulation results show that the blind 2D turbo demodulator approaches the performance of receivers with perfect channel knowledge and remains robust under realistic transmission conditions."}
{"id": "2511.20936", "categories": ["eess.SP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.20936", "abs": "https://arxiv.org/abs/2511.20936", "authors": ["Ayoob Salari", "Kai Wu", "Khawaja Fahad Masood", "Y. Jay Guo", "J. Andrew Zhang"], "title": "Wavelet-Guided Water-Level Estimation for ISAC", "comment": null, "summary": "Real-time water-level monitoring across many locations is vital for flood response, infrastructure management, and environmental forecasting. Yet many sensing methods rely on fixed instruments - acoustic, radar, camera, or pressure probes - that are costly to install and maintain and are vulnerable during extreme events. We propose a passive, low-cost water-level tracking scheme that uses only LTE downlink power metrics reported by commodity receivers. The method extracts per-antenna RSRP, RSSI, and RSRQ, applies a continuous wavelet transform (CWT) to the RSRP to isolate the semidiurnal tide component, and forms a summed-coefficient signature that simultaneously marks high/low tide (tide-turn times) and tracks the tide-rate (flow speed) over time. These wavelet features guide a lightweight neural network that learns water-level changes over time from a short training segment. Beyond a single serving base station, we also show a multi-base-station cooperative mode: independent CWTs are computed per carrier and fused by a robust median to produce one tide-band feature that improves stability and resilience to local disturbances. Experiments over a 420 m river path under line-of-sight conditions achieve root-mean-square and mean-absolute errors of 0.8 cm and 0.5 cm, respectively. Under a non-line-of-sight setting with vegetation and vessel traffic, the same model transfers successfully after brief fine-tuning, reaching 1.7 cm RMSE and 0.8 cm MAE. Unlike CSI-based methods, the approach needs no array calibration and runs on standard hardware, making wide deployment practical. When signals from multiple base stations are available, fusion further improves robustness."}
{"id": "2511.20779", "categories": ["cs.LG", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.20779", "abs": "https://arxiv.org/abs/2511.20779", "authors": ["Thomas Norrenbrock", "Timo Kaiser", "Sovan Biswas", "Neslihan Kose", "Ramesh Manuvinakurike", "Bodo Rosenhahn"], "title": "CHiQPM: Calibrated Hierarchical Interpretable Image Classification", "comment": "Accepted to NeurIPS 2025", "summary": "Globally interpretable models are a promising approach for trustworthy AI in safety-critical domains. Alongside global explanations, detailed local explanations are a crucial complement to effectively support human experts during inference. This work proposes the Calibrated Hierarchical QPM (CHiQPM) which offers uniquely comprehensive global and local interpretability, paving the way for human-AI complementarity. CHiQPM achieves superior global interpretability by contrastively explaining the majority of classes and offers novel hierarchical explanations that are more similar to how humans reason and can be traversed to offer a built-in interpretable Conformal prediction (CP) method. Our comprehensive evaluation shows that CHiQPM achieves state-of-the-art accuracy as a point predictor, maintaining 99% accuracy of non-interpretable models. This demonstrates a substantial improvement, where interpretability is incorporated without sacrificing overall accuracy. Furthermore, its calibrated set prediction is competitively efficient to other CP methods, while providing interpretable predictions of coherent sets along its hierarchical explanation."}
{"id": "2511.21434", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.21434", "abs": "https://arxiv.org/abs/2511.21434", "authors": ["Fabrizio André Farfán Prado", "William César Pérez Campos", "Steisy Anahi Carreño Tacuri", "Favio David Cabrera Alva", "Harold Jacobed Carhuas Lizarbe"], "title": "Design Of A Communication System To Send Text Using Lora At 400 MHz", "comment": null, "summary": "This work describes the design and implementation of a low-power wireless communication system for transmitting text using ESP32 modules and the LoRa DXLR01. The proposal arises as a solution to connectivity and energy-efficiency problems commonly found in rural areas and certain urban environments where Wi-Fi or mobile networks are unavailable or operate with limitations. To address this, LoRa technology known for its long-range capability and low power consumption is integrated with an ESP32 responsible for capturing, processing, and sending messages.\n  The LoRa DXLR01 module, which operates in the 433 MHz band, is configured with parameters aimed at maximising both transmission range and efficient energy usage. Messages are sent using Chirp Spread Spectrum (CSS) modulation, improving signal penetration in obstructed areas and reducing the likelihood of errors. On the receiving end, the ESP32 interprets the data and displays it on an LCD screen. Additionally, the received information is sent to the ThingSpeak platform, allowing remote storage and visualisation without relying on conventional network infrastructure.\n  Tests conducted in a controlled environment show an average latency of 3.2 seconds for text transmission. It was also verified that the system can be used in applications such as remote monitoring, infrastructure management, and access control."}
{"id": "2511.20934", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20934", "abs": "https://arxiv.org/abs/2511.20934", "authors": ["Biagio La Rosa", "Leilani H. Gilpin"], "title": "Guaranteed Optimal Compositional Explanations for Neurons", "comment": "41 pages, 10 figures", "summary": "While neurons are the basic units of deep neural networks, it is still unclear what they learn and if their knowledge is aligned with that of humans. Compositional explanations aim to answer this question by describing the spatial alignment between neuron activations and concepts through logical rules. These logical descriptions are typically computed via a search over all possible concept combinations. Since computing the spatial alignment over the entire state space is computationally infeasible, the literature commonly adopts beam search to restrict the space. However, beam search cannot provide any theoretical guarantees of optimality, and it remains unclear how close current explanations are to the true optimum. In this theoretical paper, we address this gap by introducing the first framework for computing guaranteed optimal compositional explanations. Specifically, we propose: (i) a decomposition that identifies the factors influencing the spatial alignment, (ii) a heuristic to estimate the alignment at any stage of the search, and (iii) the first algorithm that can compute optimal compositional explanations within a feasible time. Using this framework, we analyze the differences between optimal and non-optimal explanations in the most popular settings for compositional explanations, the computer vision domain and Convolutional Neural Networks. In these settings, we demonstrate that 10-40 percent of explanations obtained with beam search are suboptimal when overlapping concepts are involved. Finally, we evaluate a beam-search variant guided by our proposed decomposition and heuristic, showing that it matches or improves runtime over prior methods while offering greater flexibility in hyperparameters and computational resources."}
{"id": "2511.21050", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.21050", "abs": "https://arxiv.org/abs/2511.21050", "authors": ["Dongkyu Derek Cho", "Huan Song", "Arijit Ghosh Chowdhury", "Haotian An", "Yawei Wang", "Rohit Thekkanal", "Negin Sokhandan", "Sharlina Keshava", "Hannah Marlowe"], "title": "Breaking the Safety-Capability Tradeoff: Reinforcement Learning with Verifiable Rewards Maintains Safety Guardrails in LLMs", "comment": "AAAI-26 Workshop on Post-AI Formal Methods", "summary": "Fine-tuning large language models (LLMs) for downstream tasks typically exhibit a fundamental safety-capability tradeoff, where improving task performance degrades safety alignment even on benign datasets. This degradation persists across standard approaches including supervised finetuning (SFT) and reinforcement learning from human feedback (RLHF). While reinforcement learning with verifiable rewards (RLVR) has emerged as a promising alternative that optimizes models on objectively measurable tasks, its safety implications remain unexplored. We present the first comprehensive theoretical and empirical analysis of safety properties in RLVR. Theoretically, we derive upper bounds on safety drift under KL-constrained optimization and prove conditions under which safety degradation is eliminated. Empirically, we conduct extensive experiments across five adversarial safety benchmarks, demonstrating that RLVR can simultaneously enhance reasoning capabilities while maintaining or improving safety guardrails. Our comprehensive ablation studies examine the effects of optimization algorithms, model scale, and task domains. Our findings challenge the prevailing assumption of an inevitable safety capability trade-off, and establish that a specific training methodology can achieve both objectives simultaneously, providing insights for the safe deployment of reasoning-capable LLMs."}
{"id": "2511.20937", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20937", "abs": "https://arxiv.org/abs/2511.20937", "authors": ["Qineng Wang", "Wenlong Huang", "Yu Zhou", "Hang Yin", "Tianwei Bao", "Jianwen Lyu", "Weiyu Liu", "Ruohan Zhang", "Jiajun Wu", "Li Fei-Fei", "Manling Li"], "title": "ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction", "comment": "Preprint version", "summary": "Embodied cognition argues that intelligence arises from sensorimotor interaction rather than passive observation. It raises an intriguing question: do modern vision-language models (VLMs), trained largely in a disembodied manner, exhibit signs of embodied cognition? We introduce ENACT, a benchmark that casts evaluation of embodied cognition as world modeling from egocentric interaction in a visual question answering (VQA) format. Framed as a partially observable Markov decision process (POMDP) whose actions are scene graph changes, ENACT comprises two complementary sequence reordering tasks: forward world modeling (reorder shuffled observations given actions) and inverse world modeling (reorder shuffled actions given observations). While conceptually simple, solving these tasks implicitly demands capabilities central to embodied cognition-affordance recognition, action-effect reasoning, embodied awareness, and interactive, long-horizon memory from partially observable egocentric input, while avoiding low-level image synthesis that could confound the evaluation. We provide a scalable pipeline that synthesizes QA pairs from robotics simulation (BEHAVIOR) and evaluates models on 8,972 QA pairs spanning long-horizon home-scale activities. Experiments reveal a performance gap between frontier VLMs and humans that widens with interaction horizon. Models consistently perform better on the inverse task than the forward one and exhibit anthropocentric biases, including a preference for right-handed actions and degradation when camera intrinsics or viewpoints deviate from human vision. Website at https://enact-embodied-cognition.github.io/."}
{"id": "2511.20811", "categories": ["cs.LG", "cs.AI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.20811", "abs": "https://arxiv.org/abs/2511.20811", "authors": ["Aaron O. Feldman", "D. Isaiah Harp", "Joseph Duncan", "Mac Schwager"], "title": "Conformal Safety Monitoring for Flight Testing: A Case Study in Data-Driven Safety Learning", "comment": "ICRA 2025 Workshop on Robot safety under uncertainty from intangible specifications", "summary": "We develop a data-driven approach for runtime safety monitoring in flight testing, where pilots perform maneuvers on aircraft with uncertain parameters. Because safety violations can arise unexpectedly as a result of these uncertainties, pilots need clear, preemptive criteria to abort the maneuver in advance of safety violation. To solve this problem, we use offline stochastic trajectory simulation to learn a calibrated statistical model of the short-term safety risk facing pilots. We use flight testing as a motivating example for data-driven learning/monitoring of safety due to its inherent safety risk, uncertainty, and human-interaction. However, our approach consists of three broadly-applicable components: a model to predict future state from recent observations, a nearest neighbor model to classify the safety of the predicted state, and classifier calibration via conformal prediction. We evaluate our method on a flight dynamics model with uncertain parameters, demonstrating its ability to reliably identify unsafe scenarios, match theoretical guarantees, and outperform baseline approaches in preemptive classification of risk."}
{"id": "2511.20826", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20826", "abs": "https://arxiv.org/abs/2511.20826", "authors": ["Nicholas Pellegrino", "David Szczecina", "Paul W. Fieguth"], "title": "Effects of Initialization Biases on Deep Neural Network Training Dynamics", "comment": "5 pages, 2 figures, submitted to the 11th Annual Conference on Vision and Intelligent Systems", "summary": "Untrained large neural networks, just after random initialization, tend to favour a small subset of classes, assigning high predicted probabilities to these few classes and approximately zero probability to all others. This bias, termed Initial Guessing Bias, affects the early training dynamics, when the model is fitting to the coarse structure of the data. The choice of loss function against which to train the model has a large impact on how these early dynamics play out. Two recent loss functions, Blurry and Piecewise-zero loss, were designed for robustness to label errors but can become unable to steer the direction of training when exposed to this initial bias. Results indicate that the choice of loss function has a dramatic effect on the early phase training of networks, and highlights the need for careful consideration of how Initial Guessing Bias may interact with various components of the training scheme."}
{"id": "2511.20830", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20830", "abs": "https://arxiv.org/abs/2511.20830", "authors": ["Reza Mansouri", "Dustin Kempton", "Pete Riley", "Rafal Angryk"], "title": "Autoregressive Surrogate Modeling of the Solar Wind with Spherical Fourier Neural Operator", "comment": "IEEE Conference on Data Mining (ICDM 2025)", "summary": "The solar wind, a continuous outflow of charged particles from the Sun's corona, shapes the heliosphere and impacts space systems near Earth. Accurate prediction of features such as high-speed streams and coronal mass ejections is critical for space weather forecasting, but traditional three-dimensional magnetohydrodynamic (MHD) models are computationally expensive, limiting rapid exploration of boundary condition uncertainties. We introduce the first autoregressive machine learning surrogate for steady-state solar wind radial velocity using the Spherical Fourier Neural Operator (SFNO). By predicting a limited radial range and iteratively propagating the solution outward, the model improves accuracy in distant regions compared to a single-step approach. Compared with the numerical HUX surrogate, SFNO demonstrates superior or comparable performance while providing a flexible, trainable, and data-driven alternative, establishing a novel methodology for high-fidelity solar wind modeling. The source code and additional visual results are available at https://github.com/rezmansouri/solarwind-sfno-velocity-autoregressive."}
{"id": "2511.21260", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21260", "abs": "https://arxiv.org/abs/2511.21260", "authors": ["Joseph Y. Halpern", "Rafael Pass"], "title": "Causality Without Causal Models", "comment": "In Proceedings TARK 2025, arXiv:2511.20540", "summary": "Perhaps the most prominent current definition of (actual) causality is due to Halpern and Pearl.  It is defined using causal models (also known as structural equations models).  We abstract the definition, extracting its key features, so that it can be applied to any other model where counterfactuals are defined. By abstracting the definition, we gain a number of benefits. Not only can we apply the definition in a wider range of models, including ones that allow, for example, backtracking, but we can apply the definition to determine if A is a cause of B  even if A and B are formulas involving disjunctions, negations, beliefs, and nested counterfactuals (none of which can be handled by the Halpern-Pearl definition). Moreover, we can extend the ideas to getting an abstract definition of explanation that can be applied beyond causal models. Finally, we gain a deeper understanding of features of the definition  even in causal models."}
{"id": "2511.20873", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20873", "abs": "https://arxiv.org/abs/2511.20873", "authors": ["Elahe Kooshafar"], "title": "Representation Integrity in Temporal Graph Learning Methods", "comment": "70 pages", "summary": "Real-world systems ranging from airline routes to cryptocurrency transfers are naturally modelled as dynamic graphs whose topology changes over time. Conventional benchmarks judge dynamic-graph learners by a handful of task-specific scores, yet seldom ask whether the embeddings themselves remain a truthful, interpretable reflection of the evolving network. We formalize this requirement as representation integrity and derive a family of indexes that measure how closely embedding changes follow graph changes. Three synthetic scenarios, Gradual Merge, Abrupt Move, and Periodic Re-wiring, are used to screen forty-two candidate indexes. Based on which we recommend one index that passes all of our theoretical and empirical tests. In particular, this validated metric consistently ranks the provably stable UASE and IPP models highest. We then use this index to do a comparative study on representation integrity of common dynamic graph learning models. This study exposes the scenario-specific strengths of neural methods, and shows a strong positive rank correlation with one-step link-prediction AUC. The proposed integrity framework, therefore, offers a task-agnostic and interpretable evaluation tool for dynamic-graph representation quality, providing more explicit guidance for model selection and future architecture design."}
{"id": "2511.21417", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.21417", "abs": "https://arxiv.org/abs/2511.21417", "authors": ["Mia Müßig", "Jan Johannsen"], "title": "New Hybrid Heuristics for Pseudo-Boolean Propagation", "comment": null, "summary": "In pseudo-boolean solving the currently most successful unit propagation strategy is a hybrid mode combining the watched literal scheme with the counting method. This short paper introduces new heuristics for this hybrid decision, which are able to drastically outperform the current method in the RoundingSAT solver."}
{"id": "2511.20893", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.20893", "abs": "https://arxiv.org/abs/2511.20893", "authors": ["Aodong Li", "Abishek Sankararaman", "Balakrishnan Narayanaswamy"], "title": "Probabilistic Hash Embeddings for Online Learning of Categorical Features", "comment": "AAAI 2026 Oral", "summary": "We study streaming data with categorical features where the vocabulary of categorical feature values is changing and can even grow unboundedly over time. Feature hashing is commonly used as a pre-processing step to map these categorical values into a feature space of fixed size before learning their embeddings. While these methods have been developed and evaluated for offline or batch settings, in this paper we consider online settings. We show that deterministic embeddings are sensitive to the arrival order of categories and suffer from forgetting in online learning, leading to performance deterioration. To mitigate this issue, we propose a probabilistic hash embedding (PHE) model that treats hash embeddings as stochastic and applies Bayesian online learning to learn incrementally from data. Based on the structure of PHE, we derive a scalable inference algorithm to learn model parameters and infer/update the posteriors of hash embeddings and other latent variables. Our algorithm (i) can handle an evolving vocabulary of categorical items, (ii) is adaptive to new items without forgetting old items, (iii) is implementable with a bounded set of parameters that does not grow with the number of distinct observed values on the stream, and (iv) is invariant to the item arrival order. Experiments in classification, sequence modeling, and recommendation systems in online learning setups demonstrate the superior performance of PHE while maintaining high memory efficiency (consumes as low as 2~4 memory of a one-hot embedding table). Supplementary materials are at https://github.com/aodongli/probabilistic-hash-embeddings"}
{"id": "2511.21444", "categories": ["cs.AI", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2511.21444", "abs": "https://arxiv.org/abs/2511.21444", "authors": ["Zhe Jiang", "Jiong Wang", "Xiaoyu Yue", "Zijie Guo", "Wenlong Zhang", "Fenghua Ling", "Wanli Ouyang", "Lei Bai"], "title": "EWE: An Agentic Framework for Extreme Weather Analysis", "comment": null, "summary": "Extreme weather events pose escalating risks to global society, underscoring the urgent need to unravel their underlying physical mechanisms. Yet the prevailing expert-driven, labor-intensive diagnostic paradigm has created a critical analytical bottleneck, stalling scientific progress. While AI for Earth Science has achieved notable advances in prediction, the equally essential challenge of automated diagnostic reasoning remains largely unexplored. We present the Extreme Weather Expert (EWE), the first intelligent agent framework dedicated to this task. EWE emulates expert workflows through knowledge-guided planning, closed-loop reasoning, and a domain-tailored meteorological toolkit. It autonomously produces and interprets multimodal visualizations from raw meteorological data, enabling comprehensive diagnostic analyses. To catalyze progress, we introduce the first benchmark for this emerging field, comprising a curated dataset of 103 high-impact events and a novel step-wise evaluation metric. EWE marks a step toward automated scientific discovery and offers the potential to democratize expertise and intellectual resources, particularly for developing nations vulnerable to extreme weather."}
{"id": "2511.20913", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20913", "abs": "https://arxiv.org/abs/2511.20913", "authors": ["Yingchuan Sun", "Shengpu Tang"], "title": "Exploring Time-Step Size in Reinforcement Learning for Sepsis Treatment", "comment": null, "summary": "Existing studies on reinforcement learning (RL) for sepsis management have mostly followed an established problem setup, in which patient data are aggregated into 4-hour time steps. Although concerns have been raised regarding the coarseness of this time-step size, which might distort patient dynamics and lead to suboptimal treatment policies, the extent to which this is a problem in practice remains unexplored. In this work, we conducted empirical experiments for a controlled comparison of four time-step sizes ($Δt\\!=\\!1,2,4,8$ h) on this domain, following an identical offline RL pipeline. To enable a fair comparison across time-step sizes, we designed action re-mapping methods that allow for evaluation of policies on datasets with different time-step sizes, and conducted cross-$Δt$ model selections under two policy learning setups. Our goal was to quantify how time-step size influences state representation learning, behavior cloning, policy training, and off-policy evaluation. Our results show that performance trends across $Δt$ vary as learning setups change, while policies learned at finer time-step sizes ($Δt = 1$ h and $2$ h) using a static behavior policy achieve the overall best performance and stability. Our work highlights time-step size as a core design choice in offline RL for healthcare and provides evidence supporting alternatives beyond the conventional 4-hour setup."}
{"id": "2511.21460", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21460", "abs": "https://arxiv.org/abs/2511.21460", "authors": ["Junjian Wang", "Lidan Zhao", "Xi Sheryl Zhang"], "title": "MADRA: Multi-Agent Debate for Risk-Aware Embodied Planning", "comment": null, "summary": "Ensuring the safety of embodied AI agents during task planning is critical for real-world deployment, especially in household environments where dangerous instructions pose significant risks. Existing methods often suffer from either high computational costs due to preference alignment training or over-rejection when using single-agent safety prompts. To address these limitations, we propose MADRA, a training-free Multi-Agent Debate Risk Assessment framework that leverages collective reasoning to enhance safety awareness without sacrificing task performance. MADRA employs multiple LLM-based agents to debate the safety of a given instruction, guided by a critical evaluator that scores responses based on logical soundness, risk identification, evidence quality, and clarity. Through iterative deliberation and consensus voting, MADRA significantly reduces false rejections while maintaining high sensitivity to dangerous tasks. Additionally, we introduce a hierarchical cognitive collaborative planning framework that integrates safety, memory, planning, and self-evolution mechanisms to improve task success rates through continuous learning. We also contribute SafeAware-VH, a benchmark dataset for safety-aware task planning in VirtualHome, containing 800 annotated instructions. Extensive experiments on AI2-THOR and VirtualHome demonstrate that our approach achieves over 90% rejection of unsafe tasks while ensuring that safe-task rejection is low, outperforming existing methods in both safety and execution efficiency. Our work provides a scalable, model-agnostic solution for building trustworthy embodied agents."}
{"id": "2511.20927", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.20927", "abs": "https://arxiv.org/abs/2511.20927", "authors": ["Vitoria Barin-Pacela", "Kartik Ahuja", "Simon Lacoste-Julien", "Pascal Vincent"], "title": "Operationalizing Quantized Disentanglement", "comment": null, "summary": "Recent theoretical work established the unsupervised identifiability of quantized factors under any diffeomorphism. The theory assumes that quantization thresholds correspond to axis-aligned discontinuities in the probability density of the latent factors. By constraining a learned map to have a density with axis-aligned discontinuities, we can recover the quantization of the factors. However, translating this high-level principle into an effective practical criterion remains challenging, especially under nonlinear maps. Here, we develop a criterion for unsupervised disentanglement by encouraging axis-aligned discontinuities. Discontinuities manifest as sharp changes in the estimated density of factors and form what we call cliffs. Following the definition of independent discontinuities from the theory, we encourage the location of the cliffs along a factor to be independent of the values of the other factors. We show that our method, Cliff, outperforms the baselines on all disentanglement benchmarks, demonstrating its effectiveness in unsupervised disentanglement."}
{"id": "2511.21522", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21522", "abs": "https://arxiv.org/abs/2511.21522", "authors": ["Yanxing Huang", "Zihan Tang", "Zejin Lin", "Peng Li", "Yang Liu"], "title": "Pessimistic Verification for Open Ended Math Questions", "comment": null, "summary": "The key limitation of the verification performance lies in the ability of error detection. With this intuition we designed several variants of pessimistic verification, which are simple workflows that could significantly improve the verification of open-ended math questions. In pessimistic verification we construct multiple parallel verifications for the same proof, and the proof is deemed incorrect if any one of them reports an error. This simple technique significantly improves the performance across many math verification benchmarks without incurring substantial computational resources. Its token efficiency even surpassed extended long-CoT in test-time scaling. Our case studies further indicate that the majority of false negatives in stronger models are actually caused by annotation errors in the original dataset, so our method's performance is in fact underestimated. Self-verification for mathematical problems can effectively improve the reliability and performance of language model outputs, and it also plays a critical role in enabling long-horizon mathematical tasks. We believe that research on pessimistic verification will help enhance the mathematical capabilities of language models across a wide range of tasks."}
{"id": "2511.20992", "categories": ["cs.LG", "cs.CR", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20992", "abs": "https://arxiv.org/abs/2511.20992", "authors": ["Akansha Kalra", "Soumil Datta", "Ethan Gilmore", "Duc La", "Guanhong Tao", "Daniel S. Brown"], "title": "Dataset Poisoning Attacks on Behavioral Cloning Policies", "comment": "Accepted at EAI SmartSP 2025", "summary": "Behavior Cloning (BC) is a popular framework for training sequential decision policies from expert demonstrations via supervised learning. As these policies are increasingly being deployed in the real world, their robustness and potential vulnerabilities are an important concern. In this work, we perform the first analysis of the efficacy of clean-label backdoor attacks on BC policies. Our backdoor attacks poison a dataset of demonstrations by injecting a visual trigger to create a spurious correlation that can be exploited at test time. We evaluate how policy vulnerability scales with the fraction of poisoned data, the strength of the trigger, and the trigger type. We also introduce a novel entropy-based test-time trigger attack that substantially degrades policy performance by identifying critical states where test-time triggering of the backdoor is expected to be most effective at degrading performance. We empirically demonstrate that BC policies trained on even minimally poisoned datasets exhibit deceptively high, near-baseline task performance despite being highly vulnerable to backdoor trigger attacks during deployment. Our results underscore the urgent need for more research into the robustness of BC policies, particularly as large-scale datasets are increasingly used to train policies for real-world cyber-physical systems. Videos and code are available at https://sites.google.com/view/dataset-poisoning-in-bc."}
{"id": "2511.21570", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.21570", "abs": "https://arxiv.org/abs/2511.21570", "authors": ["Maria Perez-Ortiz"], "title": "From Prediction to Foresight: The Role of AI in Designing Responsible Futures", "comment": "Accessible at https://projecteuclid.org/journals/journal-of-artificial-intelligence-for-sustainable-development/volume-1/issue-1/From-Prediction-to-Foresight--The-Role-of-AI-in/10.69828/4d4kja.full", "summary": "In an era marked by rapid technological advancements and complex global challenges, responsible foresight has emerged as an essential framework for policymakers aiming to navigate future uncertainties and shape the future. Responsible foresight entails the ethical anticipation of emerging opportunities and risks, with a focus on fostering proactive, sustainable, and accountable future design. This paper coins the term \"responsible computational foresight\", examining the role of human-centric artificial intelligence and computational modeling in advancing responsible foresight, establishing a set of foundational principles for this new field and presenting a suite of AI-driven foresight tools currently shaping it. AI, particularly in conjunction with simulations and scenario analysis, enhances policymakers' ability to address uncertainty, evaluate risks, and devise strategies geared toward sustainable, resilient futures. However, responsible foresight extends beyond mere technical forecasting; it demands a nuanced understanding of the interdependencies within social, environmental, economic and political systems, alongside a commitment to ethical, long-term decision-making that supports human intelligence. We argue that AI will play a role as a supportive tool in responsible, human-centered foresight, complementing rather than substituting policymaker judgment to enable the proactive shaping of resilient and ethically sound futures. This paper advocates for the thoughtful integration of AI into foresight practices to empower policymakers and communities as they confront the grand challenges of the 21st century."}
{"id": "2511.21011", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21011", "abs": "https://arxiv.org/abs/2511.21011", "authors": ["Sid Bharthulwar", "Stone Tao", "Hao Su"], "title": "Staggered Environment Resets Improve Massively Parallel On-Policy Reinforcement Learning", "comment": null, "summary": "Massively parallel GPU simulation environments have accelerated reinforcement learning (RL) research by enabling fast data collection for on-policy RL algorithms like Proximal Policy Optimization (PPO). To maximize throughput, it is common to use short rollouts per policy update, increasing the update-to-data (UTD) ra- tio. However, we find that, in this setting, standard synchronous resets introduce harmful nonstationarity, skewing the learning signal and destabilizing training. We introduce staggered resets, a simple yet effective technique where environments are initialized and reset at varied points within the task horizon. This yields training batches with greater temporal diversity, reducing the nonstationarity induced by synchronized rollouts. We characterize dimensions along which RL environments can benefit significantly from staggered resets through illustrative toy environ- ments. We then apply this technique to challenging high-dimensional robotics environments, achieving significantly higher sample efficiency, faster wall-clock convergence, and stronger final performance. Finally, this technique scales better with more parallel environments compared to naive synchronized rollouts."}
{"id": "2511.20696", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20696", "abs": "https://arxiv.org/abs/2511.20696", "authors": ["Dan Li", "Hye-Bin Shin", "Yeon-Woo Choi"], "title": "Prototype-Guided Non-Exemplar Continual Learning for Cross-subject EEG Decoding", "comment": "4 pages, 2 figures, 14th IEEE International Winter Conference on Brain-Computer Interface Conference 2026", "summary": "Due to the significant variability in electroencephalogram (EEG) signals across individuals, knowledge acquired from previous subjects is often overwritten as new subjects are introduced in continual EEG decoding task. Current works mainly rely on storing the historical data of seen subjects as a replay buffer to prevent forgetting. However, privacy concerns or memory constraints make keeping such data impractical. Instead, we propose a Prototype-guided Non-Exemplar Continual Learning (ProNECL)framework that preserves prior knowledge without accessing any historical EEG samples. ProNECL constructs class-level prototypes to summarize discriminative representations from each subject and incrementally aligns new feature spaces with the global prototype memory through cross-subject feature alignment and knowledge distillation. Validated on the BCI Competition IV 2a and 2b datasets, our framework effectively balances knowledge retention and adaptability, achieving superior performance in cross-subject continual EEG decoding tasks."}
{"id": "2511.21016", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.21016", "abs": "https://arxiv.org/abs/2511.21016", "authors": ["Liangzu Peng", "Aditya Chattopadhyay", "Luca Zancato", "Elvis Nunez", "Wei Xia", "Stefano Soatto"], "title": "Gated KalmaNet: A Fading Memory Layer Through Test-Time Ridge Regression", "comment": "30 pages, 10 figures", "summary": "As efficient alternatives to softmax Attention, linear state-space models (SSMs) achieve constant memory and linear compute, but maintain only a lossy, fading summary of the past, often leading to inferior performance in recall oriented tasks. We propose Gated KalmaNet (GKA), a layer that reduces this gap by accounting for the full past when predicting the next token, while maintaining SSM-style efficiency. GKA achieves this by solving an online ridge regression problem at test time, with constant memory and linear compute cost in the sequence length. Drawing inspiration from the Kalman Filter, we iteratively solve the online ridge regression problem. However, a critical insight is that standard Kalman filter equations are numerically unstable in low-precision environments (like bfloat16) and difficult to parallelize in modern hardware. We address both challenges through two key innovations: (1) an adaptive regularization strategy with input-dependent gating that controls the condition number of the ridge regression, ensuring numerical stability while balancing memory retention. And (2) the use of Chebyshev Iteration instead of other conventional iterative solvers, which we demonstrate to be more stable in low-precision settings. To further improve scalability, we develop a hardware-aware chunk-wise implementation of Chebyshev Iteration along with custom kernels for backpropagating through our adaptive regularization and gating mechanisms. Empirically, GKA shows strong language understanding capabilites on short-context tasks outperforming existing SSM layers (like Mamba2, GLA and Gated DeltaNet). On long-context, GKA excels at real-world RAG and LongQA tasks up to 128k tokens, achieving more than $10$% relative improvement over other fading memory baselines."}
{"id": "2511.20702", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20702", "abs": "https://arxiv.org/abs/2511.20702", "authors": ["Chinmay Tripurwar", "Utkarsh Maurya", "Dishant"], "title": "Post-Pruning Accuracy Recovery via Data-Free Knowledge Distillation", "comment": null, "summary": "Model pruning is a widely adopted technique to reduce the computational complexity and memory footprint of Deep Neural Networks (DNNs). However, global unstructured pruning often leads to significant degradation in accuracy, typically necessitating fine-tuning on the original training dataset to recover performance. In privacy-sensitive domains such as healthcare or finance, access to the original training data is often restricted post-deployment due to regulations (e.g., GDPR, HIPAA). This paper proposes a Data-Free Knowledge Distillation framework to bridge the gap between model compression and data privacy. We utilize DeepInversion to synthesize privacy-preserving ``dream'' images from the pre-trained teacher model by inverting Batch Normalization (BN) statistics. These synthetic images serve as a transfer set to distill knowledge from the original teacher to the pruned student network. Experimental results on CIFAR-10 across various architectures (ResNet, MobileNet, VGG) demonstrate that our method significantly recovers accuracy lost during pruning without accessing a single real data point."}
{"id": "2511.21034", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21034", "abs": "https://arxiv.org/abs/2511.21034", "authors": ["Mahdi Saki", "Justin Lipman"], "title": "Prediction of Herd Life in Dairy Cows Using Multi-Head Attention Transformers", "comment": null, "summary": "Dairy farmers should decide to keep or cull a cow based on an objective assessment of her likely performance in the herd. For this purpose, farmers need to identify more resilient cows, which can cope better with farm conditions and complete more lactations. This decision-making process is inherently complex, with significant environmental and economic implications. In this study, we develop an AI-driven model to predict cow longevity using historical multivariate time-series data recorded from birth. Leveraging advanced AI techniques, specifically Multi-Head Attention Transformers, we analysed approximately 780,000 records from 19,000 unique cows across 7 farms in Australia. The results demonstrate that our model achieves an overall determination coefficient of 83% in predicting herd life across the studied farms, highlighting its potential for practical application in dairy herd management."}
{"id": "2511.20713", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20713", "abs": "https://arxiv.org/abs/2511.20713", "authors": ["Minhui Zhang", "Prahar Ijner", "Yoav Wald", "Elliot Creager"], "title": "Active Slice Discovery in Large Language Models", "comment": "Accepted for presentation at NeurIPS 2025 - Reliable ML Workshop", "summary": "Large Language Models (LLMs) often exhibit systematic errors on specific subsets of data, known as error slices. For instance, a slice can correspond to a certain demographic, where a model does poorly in identifying toxic comments regarding that demographic. Identifying error slices is crucial to understanding and improving models, but it is also challenging. An appealing approach to reduce the amount of manual annotation required is to actively group errors that are likely to belong to the same slice, while using limited access to an annotator to verify whether the chosen samples share the same pattern of model mistake. In this paper, we formalize this approach as Active Slice Discovery and explore it empirically on a problem of discovering human-defined slices in toxicity classification. We examine the efficacy of active slice discovery under different choices of feature representations and active learning algorithms. On several slices, we find that uncertainty-based active learning algorithms are most effective, achieving competitive accuracy using 2-10% of the available slice membership information, while significantly outperforming baselines."}
{"id": "2511.20725", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20725", "abs": "https://arxiv.org/abs/2511.20725", "authors": ["Deng Fucheng", "Wang Wanjie", "Gong Ao", "Wang Xiaoqi", "Wang Fan"], "title": "Gradient Descent Algorithm Survey", "comment": null, "summary": "Focusing on the practical configuration needs of optimization algorithms in deep learning, this article concentrates on five major algorithms: SGD, Mini-batch SGD, Momentum, Adam, and Lion. It systematically analyzes the core advantages, limitations, and key practical recommendations of each algorithm. The research aims to gain an in-depth understanding of these algorithms and provide a standardized reference for the reasonable selection, parameter tuning, and performance improvement of optimization algorithms in both academic research and engineering practice, helping to solve optimization challenges in different scales of models and various training scenarios."}
{"id": "2511.21050", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.21050", "abs": "https://arxiv.org/abs/2511.21050", "authors": ["Dongkyu Derek Cho", "Huan Song", "Arijit Ghosh Chowdhury", "Haotian An", "Yawei Wang", "Rohit Thekkanal", "Negin Sokhandan", "Sharlina Keshava", "Hannah Marlowe"], "title": "Breaking the Safety-Capability Tradeoff: Reinforcement Learning with Verifiable Rewards Maintains Safety Guardrails in LLMs", "comment": "AAAI-26 Workshop on Post-AI Formal Methods", "summary": "Fine-tuning large language models (LLMs) for downstream tasks typically exhibit a fundamental safety-capability tradeoff, where improving task performance degrades safety alignment even on benign datasets. This degradation persists across standard approaches including supervised finetuning (SFT) and reinforcement learning from human feedback (RLHF). While reinforcement learning with verifiable rewards (RLVR) has emerged as a promising alternative that optimizes models on objectively measurable tasks, its safety implications remain unexplored. We present the first comprehensive theoretical and empirical analysis of safety properties in RLVR. Theoretically, we derive upper bounds on safety drift under KL-constrained optimization and prove conditions under which safety degradation is eliminated. Empirically, we conduct extensive experiments across five adversarial safety benchmarks, demonstrating that RLVR can simultaneously enhance reasoning capabilities while maintaining or improving safety guardrails. Our comprehensive ablation studies examine the effects of optimization algorithms, model scale, and task domains. Our findings challenge the prevailing assumption of an inevitable safety capability trade-off, and establish that a specific training methodology can achieve both objectives simultaneously, providing insights for the safe deployment of reasoning-capable LLMs."}
{"id": "2511.20811", "categories": ["cs.LG", "cs.AI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.20811", "abs": "https://arxiv.org/abs/2511.20811", "authors": ["Aaron O. Feldman", "D. Isaiah Harp", "Joseph Duncan", "Mac Schwager"], "title": "Conformal Safety Monitoring for Flight Testing: A Case Study in Data-Driven Safety Learning", "comment": "ICRA 2025 Workshop on Robot safety under uncertainty from intangible specifications", "summary": "We develop a data-driven approach for runtime safety monitoring in flight testing, where pilots perform maneuvers on aircraft with uncertain parameters. Because safety violations can arise unexpectedly as a result of these uncertainties, pilots need clear, preemptive criteria to abort the maneuver in advance of safety violation. To solve this problem, we use offline stochastic trajectory simulation to learn a calibrated statistical model of the short-term safety risk facing pilots. We use flight testing as a motivating example for data-driven learning/monitoring of safety due to its inherent safety risk, uncertainty, and human-interaction. However, our approach consists of three broadly-applicable components: a model to predict future state from recent observations, a nearest neighbor model to classify the safety of the predicted state, and classifier calibration via conformal prediction. We evaluate our method on a flight dynamics model with uncertain parameters, demonstrating its ability to reliably identify unsafe scenarios, match theoretical guarantees, and outperform baseline approaches in preemptive classification of risk."}
{"id": "2511.21076", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21076", "abs": "https://arxiv.org/abs/2511.21076", "authors": ["Aaditya L. Kachhadiya"], "title": "Deceptron: Learned Local Inverses for Fast and Stable Physics Inversion", "comment": "10 pages, 11 main figures. Accepted for poster presentation at the NeurIPS 2025 Machine Learning and the Physical Sciences Workshop", "summary": "Inverse problems in the physical sciences are often ill-conditioned in input space, making progress step-size sensitive. We propose the Deceptron, a lightweight bidirectional module that learns a local inverse of a differentiable forward surrogate. Training combines a supervised fit, forward-reverse consistency, a lightweight spectral penalty, a soft bias tie, and a Jacobian Composition Penalty (JCP) that encourages $J_g(f(x))\\,J_f(x)\\!\\approx\\!I$ via JVP/VJP probes. At solve time, D-IPG (Deceptron Inverse-Preconditioned Gradient) takes a descent step in output space, pulls it back through $g$, and projects under the same backtracking and stopping rules as baselines. On Heat-1D initial-condition recovery and a Damped Oscillator inverse problem, D-IPG reaches a fixed normalized tolerance with $\\sim$20$\\times$ fewer iterations on Heat and $\\sim$2-3$\\times$ fewer on Oscillator than projected gradient, competitive in iterations and cost with Gauss-Newton. Diagnostics show JCP reduces a measured composition error and tracks iteration gains. We also preview a single-scale 2D instantiation, DeceptronNet (v0), that learns few-step corrections under a strict fairness protocol and exhibits notably fast convergence."}
{"id": "2511.21089", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21089", "abs": "https://arxiv.org/abs/2511.21089", "authors": ["Ivan Novikov"], "title": "MLPMoE: Zero-Shot Architectural Metamorphosis of Dense LLM MLPs into Static Mixture-of-Experts", "comment": null, "summary": "Large Language Models (LLMs) are predominantly deployed as dense transformers, where every parameter in every feed-forward block is activated for every token. While architecturally simple, this is computationally inefficient, since inference costs scale linearly with parameter count. Recent upcycling methods such as MoEfication, CMoE, ToMoE, and MoORE reveal that much of the useful computation lives in sparse, semi-modular substructures inside dense feed-forward networks, but these approaches typically rely on clustering, activation profiling, singular value decomposition, or custom routing that requires calibration data. This paper introduces MLPMoE (MLP Mixture-of-Experts), a training-free, deterministic transformation that restructures the dense MLP in transformer blocks into a static, high-cardinality mixture of experts. The transformation uses simple tensor slicing and summation, reinterpreting the algebra of tensor parallelism as a topological conversion rather than a distributed training pattern. We further introduce Fractal Fade (differential branch sparsity) and Compensated Pruning (variance-preserving branch reduction) as lightweight mechanisms for structured sparsity. On Qwen2.5-0.5B-Instruct and DeepSeek-R1-Distill-Llama-8B, the zero-shot MLPMoE transform changes a proxy perplexity metric by less than 0.05 percent while keeping the parameter count effectively constant. On the 8B model, differential sparsity removes about 20 percent of MLP parameters while keeping perplexity within about 2 percent of the dense baseline. The method operates entirely post hoc on existing checkpoints and does not require gradients, calibration sets, or router training. Code is available at https://gist.github.com/iwallarm/fc2ef1eddf226ca7814f9e5e2ae9bad1"}
{"id": "2511.21092", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21092", "abs": "https://arxiv.org/abs/2511.21092", "authors": ["Seunghun Baek", "Jaejin Lee", "Jaeyoon Sim", "Minjae Jeong", "Won Hwa Kim"], "title": "MNM : Multi-level Neuroimaging Meta-analysis with Hyperbolic Brain-Text Representations", "comment": "MICCAI 2025 (Provisional Accept; top ~9%)", "summary": "Various neuroimaging studies suffer from small sample size problem which often limit their reliability. Meta-analysis addresses this challenge by aggregating findings from different studies to identify consistent patterns of brain activity. However, traditional approaches based on keyword retrieval or linear mappings often overlook the rich hierarchical structure in the brain. In this work, we propose a novel framework that leverages hyperbolic geometry to bridge the gap between neuroscience literature and brain activation maps. By embedding text from research articles and corresponding brain images into a shared hyperbolic space via the Lorentz model, our method captures both semantic similarity and hierarchical organization inherent in neuroimaging data. In the hyperbolic space, our method performs multi-level neuroimaging meta-analysis (MNM) by 1) aligning brain and text embeddings for semantic correspondence, 2) guiding hierarchy between text and brain activations, and 3) preserving the hierarchical relationships within brain activation patterns. Experimental results demonstrate that our model outperforms baselines, offering a robust and interpretable paradigm of multi-level neuroimaging meta-analysis via hyperbolic brain-text representation."}
{"id": "2511.20913", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20913", "abs": "https://arxiv.org/abs/2511.20913", "authors": ["Yingchuan Sun", "Shengpu Tang"], "title": "Exploring Time-Step Size in Reinforcement Learning for Sepsis Treatment", "comment": null, "summary": "Existing studies on reinforcement learning (RL) for sepsis management have mostly followed an established problem setup, in which patient data are aggregated into 4-hour time steps. Although concerns have been raised regarding the coarseness of this time-step size, which might distort patient dynamics and lead to suboptimal treatment policies, the extent to which this is a problem in practice remains unexplored. In this work, we conducted empirical experiments for a controlled comparison of four time-step sizes ($Δt\\!=\\!1,2,4,8$ h) on this domain, following an identical offline RL pipeline. To enable a fair comparison across time-step sizes, we designed action re-mapping methods that allow for evaluation of policies on datasets with different time-step sizes, and conducted cross-$Δt$ model selections under two policy learning setups. Our goal was to quantify how time-step size influences state representation learning, behavior cloning, policy training, and off-policy evaluation. Our results show that performance trends across $Δt$ vary as learning setups change, while policies learned at finer time-step sizes ($Δt = 1$ h and $2$ h) using a static behavior policy achieve the overall best performance and stability. Our work highlights time-step size as a core design choice in offline RL for healthcare and provides evidence supporting alternatives beyond the conventional 4-hour setup."}
{"id": "2511.21109", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21109", "abs": "https://arxiv.org/abs/2511.21109", "authors": ["Mudi Jiang", "Jiahui Zhou", "Xinying Liu", "Zengyou He", "Zhikui Chen"], "title": "Interpretable Fair Clustering", "comment": null, "summary": "Fair clustering has gained increasing attention in recent years, especially in applications involving socially sensitive attributes. However, existing fair clustering methods often lack interpretability, limiting their applicability in high-stakes scenarios where understanding the rationale behind clustering decisions is essential. In this work, we address this limitation by proposing an interpretable and fair clustering framework, which integrates fairness constraints into the structure of decision trees. Our approach constructs interpretable decision trees that partition the data while ensuring fair treatment across protected groups. To further enhance the practicality of our framework, we also introduce a variant that requires no fairness hyperparameter tuning, achieved through post-pruning a tree constructed without fairness constraints. Extensive experiments on both real-world and synthetic datasets demonstrate that our method not only delivers competitive clustering performance and improved fairness, but also offers additional advantages such as interpretability and the ability to handle multiple sensitive attributes. These strengths enable our method to perform robustly under complex fairness constraints, opening new possibilities for equitable and transparent clustering."}
{"id": "2511.21050", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.21050", "abs": "https://arxiv.org/abs/2511.21050", "authors": ["Dongkyu Derek Cho", "Huan Song", "Arijit Ghosh Chowdhury", "Haotian An", "Yawei Wang", "Rohit Thekkanal", "Negin Sokhandan", "Sharlina Keshava", "Hannah Marlowe"], "title": "Breaking the Safety-Capability Tradeoff: Reinforcement Learning with Verifiable Rewards Maintains Safety Guardrails in LLMs", "comment": "AAAI-26 Workshop on Post-AI Formal Methods", "summary": "Fine-tuning large language models (LLMs) for downstream tasks typically exhibit a fundamental safety-capability tradeoff, where improving task performance degrades safety alignment even on benign datasets. This degradation persists across standard approaches including supervised finetuning (SFT) and reinforcement learning from human feedback (RLHF). While reinforcement learning with verifiable rewards (RLVR) has emerged as a promising alternative that optimizes models on objectively measurable tasks, its safety implications remain unexplored. We present the first comprehensive theoretical and empirical analysis of safety properties in RLVR. Theoretically, we derive upper bounds on safety drift under KL-constrained optimization and prove conditions under which safety degradation is eliminated. Empirically, we conduct extensive experiments across five adversarial safety benchmarks, demonstrating that RLVR can simultaneously enhance reasoning capabilities while maintaining or improving safety guardrails. Our comprehensive ablation studies examine the effects of optimization algorithms, model scale, and task domains. Our findings challenge the prevailing assumption of an inevitable safety capability trade-off, and establish that a specific training methodology can achieve both objectives simultaneously, providing insights for the safe deployment of reasoning-capable LLMs."}
{"id": "2511.21118", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21118", "abs": "https://arxiv.org/abs/2511.21118", "authors": ["Pius Onobhayedo", "Paul Osemudiame Oamen"], "title": "Trustless Federated Learning at Edge-Scale: A Compositional Architecture for Decentralized, Verifiable, and Incentive-Aligned Coordination", "comment": null, "summary": "Artificial intelligence is retracing the Internet's path from centralized provision to distributed creation. Initially, resource-intensive computation concentrates within institutions capable of training and serving large models.Eventually, as federated learning matures, billions of edge devices holding sensitive data will be able to collectively improve models without surrendering raw information, enabling both contribution and consumption at scale. This democratic vision remains unrealized due to certain compositional gaps; aggregators handle updates without accountability, economic mechanisms are lacking and even when present remain vulnerable to gaming, coordination serializes state modifications limiting scalability, and governance permits retroactive manipulation. This work addresses these gaps by leveraging cryptographic receipts to prove aggregation correctness, geometric novelty measurement to prevent incentive gaming, parallel object ownership to achieve linear scalability, and time-locked policies to check retroactive manipulation."}
{"id": "2511.21089", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21089", "abs": "https://arxiv.org/abs/2511.21089", "authors": ["Ivan Novikov"], "title": "MLPMoE: Zero-Shot Architectural Metamorphosis of Dense LLM MLPs into Static Mixture-of-Experts", "comment": null, "summary": "Large Language Models (LLMs) are predominantly deployed as dense transformers, where every parameter in every feed-forward block is activated for every token. While architecturally simple, this is computationally inefficient, since inference costs scale linearly with parameter count. Recent upcycling methods such as MoEfication, CMoE, ToMoE, and MoORE reveal that much of the useful computation lives in sparse, semi-modular substructures inside dense feed-forward networks, but these approaches typically rely on clustering, activation profiling, singular value decomposition, or custom routing that requires calibration data. This paper introduces MLPMoE (MLP Mixture-of-Experts), a training-free, deterministic transformation that restructures the dense MLP in transformer blocks into a static, high-cardinality mixture of experts. The transformation uses simple tensor slicing and summation, reinterpreting the algebra of tensor parallelism as a topological conversion rather than a distributed training pattern. We further introduce Fractal Fade (differential branch sparsity) and Compensated Pruning (variance-preserving branch reduction) as lightweight mechanisms for structured sparsity. On Qwen2.5-0.5B-Instruct and DeepSeek-R1-Distill-Llama-8B, the zero-shot MLPMoE transform changes a proxy perplexity metric by less than 0.05 percent while keeping the parameter count effectively constant. On the 8B model, differential sparsity removes about 20 percent of MLP parameters while keeping perplexity within about 2 percent of the dense baseline. The method operates entirely post hoc on existing checkpoints and does not require gradients, calibration sets, or router training. Code is available at https://gist.github.com/iwallarm/fc2ef1eddf226ca7814f9e5e2ae9bad1"}
{"id": "2511.21092", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21092", "abs": "https://arxiv.org/abs/2511.21092", "authors": ["Seunghun Baek", "Jaejin Lee", "Jaeyoon Sim", "Minjae Jeong", "Won Hwa Kim"], "title": "MNM : Multi-level Neuroimaging Meta-analysis with Hyperbolic Brain-Text Representations", "comment": "MICCAI 2025 (Provisional Accept; top ~9%)", "summary": "Various neuroimaging studies suffer from small sample size problem which often limit their reliability. Meta-analysis addresses this challenge by aggregating findings from different studies to identify consistent patterns of brain activity. However, traditional approaches based on keyword retrieval or linear mappings often overlook the rich hierarchical structure in the brain. In this work, we propose a novel framework that leverages hyperbolic geometry to bridge the gap between neuroscience literature and brain activation maps. By embedding text from research articles and corresponding brain images into a shared hyperbolic space via the Lorentz model, our method captures both semantic similarity and hierarchical organization inherent in neuroimaging data. In the hyperbolic space, our method performs multi-level neuroimaging meta-analysis (MNM) by 1) aligning brain and text embeddings for semantic correspondence, 2) guiding hierarchy between text and brain activations, and 3) preserving the hierarchical relationships within brain activation patterns. Experimental results demonstrate that our model outperforms baselines, offering a robust and interpretable paradigm of multi-level neuroimaging meta-analysis via hyperbolic brain-text representation."}
{"id": "2511.21363", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21363", "abs": "https://arxiv.org/abs/2511.21363", "authors": ["Kevin Iselborn", "David Dembinsky", "Adriano Lucieri", "Andreas Dengel"], "title": "The Directed Prediction Change - Efficient and Trustworthy Fidelity Assessment for Local Feature Attribution Methods", "comment": "13 pages, 10 figures, 5 tables, accepted at AAAI SECURE-AI4H workshop", "summary": "The utility of an explanation method critically depends on its fidelity to the underlying machine learning model. Especially in high-stakes medical settings, clinicians and regulators require explanations that faithfully reflect the model's decision process. Existing fidelity metrics such as Infidelity rely on Monte Carlo approximation, which demands numerous model evaluations and introduces uncertainty due to random sampling. This work proposes a novel metric for evaluating the fidelity of local feature attribution methods by modifying the existing Prediction Change (PC) metric within the Guided Perturbation Experiment. By incorporating the direction of both perturbation and attribution, the proposed Directed Prediction Change (DPC) metric achieves an almost tenfold speedup and eliminates randomness, resulting in a deterministic and trustworthy evaluation procedure that measures the same property as local Infidelity. DPC is evaluated on two datasets (skin lesion images and financial tabular data), two black-box models, seven explanation algorithms, and a wide range of hyperparameters. Across $4\\,744$ distinct explanations, the results demonstrate that DPC, together with PC, enables a holistic and computationally efficient evaluation of both baseline-oriented and local feature attribution methods, while providing deterministic and reproducible outcomes."}
{"id": "2511.21354", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21354", "abs": "https://arxiv.org/abs/2511.21354", "authors": ["Umberto Michelucci", "Francesca Venturini"], "title": "Best Practices for Machine Learning Experimentation in Scientific Applications", "comment": null, "summary": "Machine learning (ML) is increasingly adopted in scientific research, yet the quality and reliability of results often depend on how experiments are designed and documented. Poor baselines, inconsistent preprocessing, or insufficient validation can lead to misleading conclusions about model performance. This paper presents a practical and structured guide for conducting ML experiments in scientific applications, focussing on reproducibility, fair comparison, and transparent reporting. We outline a step-by-step workflow, from dataset preparation to model selection and evaluation, and propose metrics that account for overfitting and instability across validation folds, including the Logarithmic Overfitting Ratio (LOR) and the Composite Overfitting Score (COS). Through recommended practices and example reporting formats, this work aims to support researchers in establishing robust baselines and drawing valid evidence-based insights from ML models applied to scientific problems."}
{"id": "2511.21378", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21378", "abs": "https://arxiv.org/abs/2511.21378", "authors": ["Jungi Lee", "Jungkwon Kim", "Chi Zhang", "Kwangsun Yoo", "Seok-Joo Byun"], "title": "Anomaly Detection with Adaptive and Aggressive Rejection for Contaminated Training Data", "comment": null, "summary": "Handling contaminated data poses a critical challenge in anomaly detection, as traditional models assume training on purely normal data. Conventional methods mitigate contamination by relying on fixed contamination ratios, but discrepancies between assumed and actual ratios can severely degrade performance, especially in noisy environments where normal and abnormal data distributions overlap. To address these limitations, we propose Adaptive and Aggressive Rejection (AAR), a novel method that dynamically excludes anomalies using a modified z-score and Gaussian mixture model-based thresholds. AAR effectively balances the trade-off between preserving normal data and excluding anomalies by integrating hard and soft rejection strategies. Extensive experiments on two image datasets and thirty tabular datasets demonstrate that AAR outperforms the state-of-the-art method by 0.041 AUROC. By providing a scalable and reliable solution, AAR enhances robustness against contaminated datasets, paving the way for broader real-world applications in domains such as security and healthcare."}
{"id": "2511.21408", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.21408", "abs": "https://arxiv.org/abs/2511.21408", "authors": ["Frederico Wieser", "Martin Benfeghoul", "Haitham Bou Ammar", "Jun Wang", "Zafeirios Fountas"], "title": "Subjective Depth and Timescale Transformers: Learning Where and When to Compute", "comment": null, "summary": "The rigid, uniform allocation of computation in standard Transformer (TF) architectures can limit their efficiency and scalability, particularly for large-scale models and long sequences. Addressing this, we introduce Subjective Depth Transformers (SDT) and Subjective Timescale Transformers (STT), two distinct architectures that leverage Bayesian surprise signals to dynamically route computation, learning where and when to compute within decoder-only TFs. SDT augments a decoder-only stack with alternating Decision and Dynamic layers: a Decision layer computes a full block 'posterior' and a lightweight 'prior,' while a Dynamic layer employs fixed-capacity Top-K routing based on Bayesian surprise (Expected and Unexpected Change), maintaining a static compute graph. STT extends this conditional computation to the temporal domain: a transition network predicts residual updates, forming a temporal 'change hypothesis' that informs a router to dynamically execute or bypass TF blocks for each token, managing KV-cache contributions. Both architectures exhibit the predicted shift from novelty to prediction driven gating over training, suggesting alignment with surprise based principles. While operating at reduced capacity, they offer preliminary insights into the compute-accuracy trade-offs of conditional computation. The proposed architectures establish a flexible framework for efficiency, reducing self-attention computation by 75% and KV-cache requirements by 50% within each compute skipping layer, setting a pathway for more efficient models."}
{"id": "2511.21363", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21363", "abs": "https://arxiv.org/abs/2511.21363", "authors": ["Kevin Iselborn", "David Dembinsky", "Adriano Lucieri", "Andreas Dengel"], "title": "The Directed Prediction Change - Efficient and Trustworthy Fidelity Assessment for Local Feature Attribution Methods", "comment": "13 pages, 10 figures, 5 tables, accepted at AAAI SECURE-AI4H workshop", "summary": "The utility of an explanation method critically depends on its fidelity to the underlying machine learning model. Especially in high-stakes medical settings, clinicians and regulators require explanations that faithfully reflect the model's decision process. Existing fidelity metrics such as Infidelity rely on Monte Carlo approximation, which demands numerous model evaluations and introduces uncertainty due to random sampling. This work proposes a novel metric for evaluating the fidelity of local feature attribution methods by modifying the existing Prediction Change (PC) metric within the Guided Perturbation Experiment. By incorporating the direction of both perturbation and attribution, the proposed Directed Prediction Change (DPC) metric achieves an almost tenfold speedup and eliminates randomness, resulting in a deterministic and trustworthy evaluation procedure that measures the same property as local Infidelity. DPC is evaluated on two datasets (skin lesion images and financial tabular data), two black-box models, seven explanation algorithms, and a wide range of hyperparameters. Across $4\\,744$ distinct explanations, the results demonstrate that DPC, together with PC, enables a holistic and computationally efficient evaluation of both baseline-oriented and local feature attribution methods, while providing deterministic and reproducible outcomes."}
{"id": "2511.21514", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21514", "abs": "https://arxiv.org/abs/2511.21514", "authors": ["Matīss Kalnāre", "Sofoklis Kitharidis", "Thomas Bäck", "Niki van Stein"], "title": "Mechanistic Interpretability for Transformer-based Time Series Classification", "comment": null, "summary": "Transformer-based models have become state-of-the-art tools in various machine learning tasks, including time series classification, yet their complexity makes understanding their internal decision-making challenging. Existing explainability methods often focus on input-output attributions, leaving the internal mechanisms largely opaque. This paper addresses this gap by adapting various Mechanistic Interpretability techniques; activation patching, attention saliency, and sparse autoencoders, from NLP to transformer architectures designed explicitly for time series classification. We systematically probe the internal causal roles of individual attention heads and timesteps, revealing causal structures within these models. Through experimentation on a benchmark time series dataset, we construct causal graphs illustrating how information propagates internally, highlighting key attention heads and temporal positions driving correct classifications. Additionally, we demonstrate the potential of sparse autoencoders for uncovering interpretable latent features. Our findings provide both methodological contributions to transformer interpretability and novel insights into the functional mechanics underlying transformer performance in time series classification tasks."}
{"id": "2511.21364", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.21364", "abs": "https://arxiv.org/abs/2511.21364", "authors": ["Ariful Islam", "Md Rifat Hossen", "Md. Mahmudul Arif", "Abdullah Al Noman", "Md Arifur Rahman"], "title": "BanglaMM-Disaster: A Multimodal Transformer-Based Deep Learning Framework for Multiclass Disaster Classification in Bangla", "comment": "Presented at the 2025 IEEE International Conference on Signal Processing, Information, Communication and Systems (SPICSCON), November 21-22, 2025, University of Rajshahi, Bangladesh. 6 pages, 9 disaster classes, multimodal dataset with 5,037 samples", "summary": "Natural disasters remain a major challenge for Bangladesh, so real-time monitoring and quick response systems are essential. In this study, we present BanglaMM-Disaster, an end-to-end deep learning-based multimodal framework for disaster classification in Bangla, using both textual and visual data from social media. We constructed a new dataset of 5,037 Bangla social media posts, each consisting of a caption and a corresponding image, annotated into one of nine disaster-related categories. The proposed model integrates transformer-based text encoders, including BanglaBERT, mBERT, and XLM-RoBERTa, with CNN backbones such as ResNet50, DenseNet169, and MobileNetV2, to process the two modalities. Using early fusion, the best model achieves 83.76% accuracy. This surpasses the best text-only baseline by 3.84% and the image-only baseline by 16.91%. Our analysis also shows reduced misclassification across all classes, with noticeable improvements for ambiguous examples. This work fills a key gap in Bangla multimodal disaster analysis and demonstrates the benefits of combining multiple data types for real-time disaster response in low-resource settings."}
{"id": "2511.21531", "categories": ["cs.LG", "cs.AI", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21531", "abs": "https://arxiv.org/abs/2511.21531", "authors": ["Jin Pin", "Krasowski Hanna", "Vanneaux Elena"], "title": "Predictive Safety Shield for Dyna-Q Reinforcement Learning", "comment": null, "summary": "Obtaining safety guarantees for reinforcement learning is a major challenge to achieve applicability for real-world tasks. Safety shields extend standard reinforcement learning and achieve hard safety guarantees. However, existing safety shields commonly use random sampling of safe actions or a fixed fallback controller, therefore disregarding future performance implications of different safe actions. In this work, we propose a predictive safety shield for model-based reinforcement learning agents in discrete space. Our safety shield updates the Q-function locally based on safe predictions, which originate from a safe simulation of the environment model. This shielding approach improves performance while maintaining hard safety guarantees. Our experiments on gridworld environments demonstrate that even short prediction horizons can be sufficient to identify the optimal path. We observe that our approach is robust to distribution shifts, e.g., between simulation and reality, without requiring additional training."}
{"id": "2511.21377", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21377", "abs": "https://arxiv.org/abs/2511.21377", "authors": ["Ben Anson", "Laurence Aitchison"], "title": "Controlling changes to attention logits", "comment": null, "summary": "Stability of neural network weights is critical when training transformer models. The query and key weights are particularly problematic, as they tend to grow large without any intervention. Applying normalization to queries and keys, known as `QK norm', fixes stability issues in practice, but is not always applicable. For example, QK norm is not compatible with Multi Latent Attention (MLA) because QK norm requires full materialization of queries and keys during inference, which is not done in MLA. In this paper we suggest that controlling the changes to logits is important for stability. We show that these changes are controllable by assigning parameter-dependent learning rates to the query and key weights. We find that our cheap intervention allows us to increase the base learning rate of the network, outperform other methods in the MLA setting, and achieve performance competitive with QK norm when using Multi-head Attention."}
{"id": "2511.21378", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21378", "abs": "https://arxiv.org/abs/2511.21378", "authors": ["Jungi Lee", "Jungkwon Kim", "Chi Zhang", "Kwangsun Yoo", "Seok-Joo Byun"], "title": "Anomaly Detection with Adaptive and Aggressive Rejection for Contaminated Training Data", "comment": null, "summary": "Handling contaminated data poses a critical challenge in anomaly detection, as traditional models assume training on purely normal data. Conventional methods mitigate contamination by relying on fixed contamination ratios, but discrepancies between assumed and actual ratios can severely degrade performance, especially in noisy environments where normal and abnormal data distributions overlap. To address these limitations, we propose Adaptive and Aggressive Rejection (AAR), a novel method that dynamically excludes anomalies using a modified z-score and Gaussian mixture model-based thresholds. AAR effectively balances the trade-off between preserving normal data and excluding anomalies by integrating hard and soft rejection strategies. Extensive experiments on two image datasets and thirty tabular datasets demonstrate that AAR outperforms the state-of-the-art method by 0.041 AUROC. By providing a scalable and reliable solution, AAR enhances robustness against contaminated datasets, paving the way for broader real-world applications in domains such as security and healthcare."}
{"id": "2511.21408", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.21408", "abs": "https://arxiv.org/abs/2511.21408", "authors": ["Frederico Wieser", "Martin Benfeghoul", "Haitham Bou Ammar", "Jun Wang", "Zafeirios Fountas"], "title": "Subjective Depth and Timescale Transformers: Learning Where and When to Compute", "comment": null, "summary": "The rigid, uniform allocation of computation in standard Transformer (TF) architectures can limit their efficiency and scalability, particularly for large-scale models and long sequences. Addressing this, we introduce Subjective Depth Transformers (SDT) and Subjective Timescale Transformers (STT), two distinct architectures that leverage Bayesian surprise signals to dynamically route computation, learning where and when to compute within decoder-only TFs. SDT augments a decoder-only stack with alternating Decision and Dynamic layers: a Decision layer computes a full block 'posterior' and a lightweight 'prior,' while a Dynamic layer employs fixed-capacity Top-K routing based on Bayesian surprise (Expected and Unexpected Change), maintaining a static compute graph. STT extends this conditional computation to the temporal domain: a transition network predicts residual updates, forming a temporal 'change hypothesis' that informs a router to dynamically execute or bypass TF blocks for each token, managing KV-cache contributions. Both architectures exhibit the predicted shift from novelty to prediction driven gating over training, suggesting alignment with surprise based principles. While operating at reduced capacity, they offer preliminary insights into the compute-accuracy trade-offs of conditional computation. The proposed architectures establish a flexible framework for efficiency, reducing self-attention computation by 75% and KV-cache requirements by 50% within each compute skipping layer, setting a pathway for more efficient models."}
{"id": "2511.21466", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.21466", "abs": "https://arxiv.org/abs/2511.21466", "authors": ["William De Deyn", "Michael Herty", "Giovanni Samaey"], "title": "Mean-Field Limits for Two-Layer Neural Networks Trained with Consensus-Based Optimization", "comment": null, "summary": "We study two-layer neural networks and train these with a particle-based method called consensus-based optimization (CBO). We compare the performance of CBO against Adam on two test cases and demonstrate how a hybrid approach, combining CBO with Adam, provides faster convergence than CBO. In the context of multi-task learning, we recast CBO into a formulation that offers less memory overhead. The CBO method allows for a mean-field limit formulation, which we couple with the mean-field limit of the neural network. To this end, we first reformulate CBO within the optimal transport framework. Finally, in the limit of infinitely many particles, we define the corresponding dynamics on the Wasserstein-over-Wasserstein space and show that the variance decreases monotonically."}
{"id": "2511.21500", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21500", "abs": "https://arxiv.org/abs/2511.21500", "authors": ["Qian Hong", "Cheng Bian", "Xiao Zhou", "Xiaoyu Li", "Yelei Li", "Zijing Zeng"], "title": "Lost in Time? A Meta-Learning Framework for Time-Shift-Tolerant Physiological Signal Transformation", "comment": "The 40th Annual AAAI Conference on Artificial Intelligence (AAAI 26)", "summary": "Translating non-invasive signals such as photoplethysmography (PPG) and ballistocardiography (BCG) into clinically meaningful signals like arterial blood pressure (ABP) is vital for continuous, low-cost healthcare monitoring. However, temporal misalignment in multimodal signal transformation impairs transformation accuracy, especially in capturing critical features like ABP peaks. Conventional synchronization methods often rely on strong similarity assumptions or manual tuning, while existing Learning with Noisy Labels (LNL) approaches are ineffective under time-shifted supervision, either discarding excessive data or failing to correct label shifts. To address this challenge, we propose ShiftSyncNet, a meta-learning-based bi-level optimization framework that automatically mitigates performance degradation due to time misalignment. It comprises a transformation network (TransNet) and a time-shift correction network (SyncNet), where SyncNet learns time offsets between training pairs and applies Fourier phase shifts to align supervision signals. Experiments on one real-world industrial dataset and two public datasets show that ShiftSyncNet outperforms strong baselines by 9.4%, 6.0%, and 12.8%, respectively. The results highlight its effectiveness in correcting time shifts, improving label quality, and enhancing transformation accuracy across diverse misalignment scenarios, pointing toward a unified direction for addressing temporal inconsistencies in multimodal physiological transformation."}
{"id": "2511.21513", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21513", "abs": "https://arxiv.org/abs/2511.21513", "authors": ["Wanli Zhong", "Haibo Feng", "Zirui Zhou", "Hanyang Peng", "Shiqi Yu"], "title": "IntAttention: A Fully Integer Attention Pipeline for Efficient Edge Inference", "comment": null, "summary": "Deploying Transformer models on edge devices is limited by latency and energy budgets. While INT8 quantization effectively accelerates the primary matrix multiplications, it exposes the softmax as the dominant bottleneck. This stage incurs a costly dequantize-softmax-requantize detour, which can account for up to 65% of total attention latency and disrupts the end-to-end integer dataflow critical for edge hardware efficiency. To address this limitation, we present IntAttention, the first fully integer, plug-and-play attention pipeline without retraining. At the core of our approach lies IndexSoftmax, a hardware-friendly operator that replaces floating-point exponentials entirely within the integer domain. IntAttention integrates sparsity-aware clipping, a 32-entry lookup-table approximation, and direct integer normalization, thereby eliminating all datatype conversion overhead. We evaluate IntAttention and demonstrate consistent and substantial gains. Our method achieves up to 3.7x speedup and 61% energy reduction over FP16 baselines and 2.0x faster than conventional INT8 attention pipelines on Armv8 CPUs. These gains are achieved with high-fidelity accuracy comparable to baselines across diverse language and vision models, enabling practical and efficient Transformer inference on commodity edge devices. Code will be released in later version of this work."}
{"id": "2511.21514", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21514", "abs": "https://arxiv.org/abs/2511.21514", "authors": ["Matīss Kalnāre", "Sofoklis Kitharidis", "Thomas Bäck", "Niki van Stein"], "title": "Mechanistic Interpretability for Transformer-based Time Series Classification", "comment": null, "summary": "Transformer-based models have become state-of-the-art tools in various machine learning tasks, including time series classification, yet their complexity makes understanding their internal decision-making challenging. Existing explainability methods often focus on input-output attributions, leaving the internal mechanisms largely opaque. This paper addresses this gap by adapting various Mechanistic Interpretability techniques; activation patching, attention saliency, and sparse autoencoders, from NLP to transformer architectures designed explicitly for time series classification. We systematically probe the internal causal roles of individual attention heads and timesteps, revealing causal structures within these models. Through experimentation on a benchmark time series dataset, we construct causal graphs illustrating how information propagates internally, highlighting key attention heads and temporal positions driving correct classifications. Additionally, we demonstrate the potential of sparse autoencoders for uncovering interpretable latent features. Our findings provide both methodological contributions to transformer interpretability and novel insights into the functional mechanics underlying transformer performance in time series classification tasks."}
{"id": "2511.21531", "categories": ["cs.LG", "cs.AI", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21531", "abs": "https://arxiv.org/abs/2511.21531", "authors": ["Jin Pin", "Krasowski Hanna", "Vanneaux Elena"], "title": "Predictive Safety Shield for Dyna-Q Reinforcement Learning", "comment": null, "summary": "Obtaining safety guarantees for reinforcement learning is a major challenge to achieve applicability for real-world tasks. Safety shields extend standard reinforcement learning and achieve hard safety guarantees. However, existing safety shields commonly use random sampling of safe actions or a fixed fallback controller, therefore disregarding future performance implications of different safe actions. In this work, we propose a predictive safety shield for model-based reinforcement learning agents in discrete space. Our safety shield updates the Q-function locally based on safe predictions, which originate from a safe simulation of the environment model. This shielding approach improves performance while maintaining hard safety guarantees. Our experiments on gridworld environments demonstrate that even short prediction horizons can be sufficient to identify the optimal path. We observe that our approach is robust to distribution shifts, e.g., between simulation and reality, without requiring additional training."}
{"id": "2511.21560", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21560", "abs": "https://arxiv.org/abs/2511.21560", "authors": ["Jack Geary", "Boyan Gao", "Henry Gouk"], "title": "Computing Strategic Responses to Non-Linear Classifiers", "comment": null, "summary": "We consider the problem of strategic classification, where the act of deploying a classifier leads to strategic behaviour that induces a distribution shift on subsequent observations. Current approaches to learning classifiers in strategic settings are focused primarily on the linear setting, but in many cases non-linear classifiers are more suitable. A central limitation to progress for non-linear classifiers arises from the inability to compute best responses in these settings. We present a novel method for computing the best response by optimising the Lagrangian dual of the Agents' objective. We demonstrate that our method reproduces best responses in linear settings, identifying key weaknesses in existing approaches. We present further results demonstrating our method can be straight-forwardly applied to non-linear classifier settings, where it is useful for both evaluation and training."}
{"id": "2511.21566", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21566", "abs": "https://arxiv.org/abs/2511.21566", "authors": ["Ali Amirahmadi", "Gökçe Geylan", "Leonardo De Maria", "Farzaneh Etminani", "Mattias Ohlsson", "Alessandro Tibo"], "title": "A decoupled alignment kernel for peptide membrane permeability predictions", "comment": "submitted to Journal of Cheminformatics", "summary": "Cyclic peptides are promising modalities for targeting intracellular sites; however, cell-membrane permeability remains a key bottleneck, exacerbated by limited public data and the need for well-calibrated uncertainty. Instead of relying on data-eager complex deep learning architecture, we propose a monomer-aware decoupled global alignment kernel (MD-GAK), which couples chemically meaningful residue-residue similarity with sequence alignment while decoupling local matches from gap penalties. MD-GAK is a relatively simple kernel. To further demonstrate the robustness of our framework, we also introduce a variant, PMD-GAK, which incorporates a triangular positional prior. As we will show in the experimental section, PMD-GAK can offer additional advantages over MD-GAK, particularly in reducing calibration errors. Since our focus is on uncertainty estimation, we use Gaussian Processes as the predictive model, as both MD-GAK and PMD-GAK can be directly applied within this framework. We demonstrate the effectiveness of our methods through an extensive set of experiments, comparing our fully reproducible approach against state-of-the-art models, and show that it outperforms them across all metrics."}
{"id": "2511.21581", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21581", "abs": "https://arxiv.org/abs/2511.21581", "authors": ["Alex Ning", "Yen-Ling Kuo", "Gabe Gomes"], "title": "Learning When to Stop: Adaptive Latent Reasoning via Reinforcement Learning", "comment": "13 pages, 6 figures", "summary": "Latent reasoning represents a new development in Transformer language models that has shown potential in compressing reasoning lengths compared to chain-of-thought reasoning. By directly passing the information-rich previous final latent state into the next sequence, latent reasoning removes the restriction to human language tokens as the medium for reasoning. We develop adaptive-length latent reasoning models and introduce a post-SFT reinforcement-learning methodology to optimize latent reasoning length by minimizing reasoning length while maintaining accuracy. This, in turn, further reduces compute usage and raises the bar on the compressive capabilities of latent reasoning models. Experiments on the Llama 3.2 1B model and the GSM8K-Aug dataset show a $52\\%$ drop in total reasoning length with no penalty to accuracy. In future work, we plan to extend to additional models and datasets, analyze relationships between training coefficients, experiment with architecture variations, and continue our knowledge distillation for latent reasoning SFT efforts. We make our code and pretrained weights available at https://github.com/apning/adaptive-latent-reasoning."}
{"id": "2511.21590", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21590", "abs": "https://arxiv.org/abs/2511.21590", "authors": ["Muhammad Siddique", "Sohaib Zafar"], "title": "An AI-Enabled Hybrid Cyber-Physical Framework for Adaptive Control in Smart Grids", "comment": "16 pages, 11 figures, IEEEaccess journal", "summary": "Smart grids are a fusion of classical power infrastructure and advanced communication networks and smart control, to create a cyber-physical environment that is more efficient and flexible than ever before. This integration causes vulnerabilities that can undermine grid stability as well as reliability. Digital forensics is a fundamental concept of learning and identifying, detecting, and mitigating such security incidents. This paper presents an all-in-one machine learning-based digital forensic framework of smart grid systems deployed on the Cloud. The framework combines the data acquisition at the sensor-level, authenticated communication, scalable cloud storage and automated forensic analytics. The model uses supervised and unsupervised learning algorithms - such as Random Forest, Support Vector Machine, Gradient Boosted Trees and deep neural architectures for anomaly detection, event reconstruction and intrusion analysis in real time. After several simulation and experimental studies on real-time smart-meter data streams, the proposed framework is shown to be very accurate, scalable and resilient to cyber-attacks including data tampering, false-data injection and coordinated control-loop manipulation. The results indicate that cloud services are the best backbone for big-data-driven forensic workflows, which allows energy utilities to achieve a fast situational awareness and intelligent incident response."}
{"id": "2511.20679", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20679", "abs": "https://arxiv.org/abs/2511.20679", "authors": ["Melika Ayoughi", "Pascal Mettes", "Paul Groth"], "title": "Minimizing Hyperbolic Embedding Distortion with LLM-Guided Hierarchy Restructuring", "comment": null, "summary": "Hyperbolic geometry is an effective geometry for embedding hierarchical data structures. Hyperbolic learning has therefore become increasingly prominent in machine learning applications where data is hierarchically organized or governed by hierarchical semantics, ranging from recommendation systems to computer vision. The quality of hyperbolic embeddings is tightly coupled to the structure of the input hierarchy, which is often derived from knowledge graphs or ontologies. Recent work has uncovered that for an optimal hyperbolic embedding, a high branching factor and single inheritance are key, while embedding algorithms are robust to imbalance and hierarchy size. To assist knowledge engineers in reorganizing hierarchical knowledge, this paper investigates whether Large Language Models (LLMs) have the ability to automatically restructure hierarchies to meet these criteria. We propose a prompt-based approach to transform existing hierarchies using LLMs, guided by known desiderata for hyperbolic embeddings. Experiments on 16 diverse hierarchies show that LLM-restructured hierarchies consistently yield higher-quality hyperbolic embeddings across several standard embedding quality metrics. Moreover, we show how LLM-guided hierarchy restructuring enables explainable reorganizations, providing justifications to knowledge engineers."}
{"id": "2511.20694", "categories": ["cs.AI", "astro-ph.SR", "cs.LG", "physics.space-ph"], "pdf": "https://arxiv.org/pdf/2511.20694", "abs": "https://arxiv.org/abs/2511.20694", "authors": ["Kevin Lee", "Russell Spiewak", "James Walsh"], "title": "Reasoning With a Star: A Heliophysics Dataset and Benchmark for Agentic Scientific Reasoning", "comment": "Accepted at NeurIPS 2025 Machine Learning and the Physical Sciences (ML4PS) Workshop. Dataset: https://huggingface.co/datasets/SpaceML/ReasoningWithAStar", "summary": "Scientific reasoning through Large Language Models in heliophysics involves more than just recalling facts: it requires incorporating physical assumptions, maintaining consistent units, and providing clear scientific formats through coordinated approaches. To address these challenges, we present Reasoning With a Star, a newly contributed heliophysics dataset applicable to reasoning; we also provide an initial benchmarking approach. Our data are constructed from National Aeronautics and Space Administration & University Corporation for Atmospheric Research Living With a Star summer school problem sets and compiled into a readily consumable question-and-answer structure with question contexts, reasoning steps, expected answer type, ground-truth targets, format hints, and metadata. A programmatic grader checks the predictions using unit-aware numerical tolerance, symbolic equivalence, and schema validation. We benchmark a single-shot baseline and four multi-agent patterns, finding that decomposing workflows through systems engineering principles outperforms direct prompting on problems requiring deductive reasoning rather than pure inductive recall."}
{"id": "2511.20888", "categories": ["stat.ML", "cs.CC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20888", "abs": "https://arxiv.org/abs/2511.20888", "authors": ["Arthur Jacot"], "title": "Deep Learning as a Convex Paradigm of Computation: Minimizing Circuit Size with ResNets", "comment": null, "summary": "This paper argues that DNNs implement a computational Occam's razor -- finding the `simplest' algorithm that fits the data -- and that this could explain their incredible and wide-ranging success over more traditional statistical methods. We start with the discovery that the set of real-valued function $f$ that can be $ε$-approximated with a binary circuit of size at most $cε^{-γ}$ becomes convex in the `Harder than Monte Carlo' (HTMC) regime, when $γ>2$, allowing for the definition of a HTMC norm on functions. In parallel one can define a complexity measure on the parameters of a ResNets (a weighted $\\ell_1$ norm of the parameters), which induce a `ResNet norm' on functions. The HTMC and ResNet norms can then be related by an almost matching sandwich bound. Thus minimizing this ResNet norm is equivalent to finding a circuit that fits the data with an almost minimal number of nodes (within a power of 2 of being optimal). ResNets thus appear as an alternative model for computation of real functions, better adapted to the HTMC regime and its convexity."}
{"id": "2511.20934", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20934", "abs": "https://arxiv.org/abs/2511.20934", "authors": ["Biagio La Rosa", "Leilani H. Gilpin"], "title": "Guaranteed Optimal Compositional Explanations for Neurons", "comment": "41 pages, 10 figures", "summary": "While neurons are the basic units of deep neural networks, it is still unclear what they learn and if their knowledge is aligned with that of humans. Compositional explanations aim to answer this question by describing the spatial alignment between neuron activations and concepts through logical rules. These logical descriptions are typically computed via a search over all possible concept combinations. Since computing the spatial alignment over the entire state space is computationally infeasible, the literature commonly adopts beam search to restrict the space. However, beam search cannot provide any theoretical guarantees of optimality, and it remains unclear how close current explanations are to the true optimum. In this theoretical paper, we address this gap by introducing the first framework for computing guaranteed optimal compositional explanations. Specifically, we propose: (i) a decomposition that identifies the factors influencing the spatial alignment, (ii) a heuristic to estimate the alignment at any stage of the search, and (iii) the first algorithm that can compute optimal compositional explanations within a feasible time. Using this framework, we analyze the differences between optimal and non-optimal explanations in the most popular settings for compositional explanations, the computer vision domain and Convolutional Neural Networks. In these settings, we demonstrate that 10-40 percent of explanations obtained with beam search are suboptimal when overlapping concepts are involved. Finally, we evaluate a beam-search variant guided by our proposed decomposition and heuristic, showing that it matches or improves runtime over prior methods while offering greater flexibility in hyperparameters and computational resources."}
{"id": "2511.21115", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21115", "abs": "https://arxiv.org/abs/2511.21115", "authors": ["Lechen Feng", "Haoran Li", "Lucky Li", "Xingqiu Zhao"], "title": "Nonconvex Penalized LAD Estimation in Partial Linear Models with DNNs: Asymptotic Analysis and Proximal Algorithms", "comment": null, "summary": "This paper investigates the partial linear model by Least Absolute Deviation (LAD) regression. We parameterize the nonparametric term using Deep Neural Networks (DNNs) and formulate a penalized LAD problem for estimation. Specifically, our model exhibits the following challenges. First, the regularization term can be nonconvex and nonsmooth, necessitating the introduction of infinite dimensional variational analysis and nonsmooth analysis into the asymptotic normality discussion. Second, our network must expand (in width, sparsity level and depth) as more samples are observed, thereby introducing additional difficulties for theoretical analysis. Third, the oracle of the proposed estimator is itself defined through a ultra high-dimensional, nonconvex, and discontinuous optimization problem, which already entails substantial computational and theoretical challenges. Under such the challenges, we establish the consistency, convergence rate, and asymptotic normality of the estimator. Furthermore, we analyze the oracle problem itself and its continuous relaxation. We study the convergence of a proximal subgradient method for both formulations, highlighting their structural differences lead to distinct computational subproblems along the iterations. In particular, the relaxed formulation admits significantly cheaper proximal updates, reflecting an inherent trade-off between statistical accuracy and computational tractability."}
{"id": "2511.21223", "categories": ["stat.ML", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21223", "abs": "https://arxiv.org/abs/2511.21223", "authors": ["Jasraj Singh", "Shelvia Wongso", "Jeremie Houssineau", "Badr-Eddine Chérief-Abdellatif"], "title": "Maxitive Donsker-Varadhan Formulation for Possibilistic Variational Inference", "comment": null, "summary": "Variational inference (VI) is a cornerstone of modern Bayesian learning, enabling approximate inference in complex models that would otherwise be intractable. However, its formulation depends on expectations and divergences defined through high-dimensional integrals, often rendering analytical treatment impossible and necessitating heavy reliance on approximate learning and inference techniques. Possibility theory, an imprecise probability framework, allows to directly model epistemic uncertainty instead of leveraging subjective probabilities. While this framework provides robustness and interpretability under sparse or imprecise information, adapting VI to the possibilistic setting requires rethinking core concepts such as entropy and divergence, which presuppose additivity. In this work, we develop a principled formulation of possibilistic variational inference and apply it to a special class of exponential-family functions, highlighting parallels with their probabilistic counterparts and revealing the distinctive mathematical structures of possibility theory."}
{"id": "2511.21526", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.21526", "abs": "https://arxiv.org/abs/2511.21526", "authors": ["Alexandra Carpentier", "Christophe Giraud", "Nicolas Verzelen"], "title": "Phase Transition for Stochastic Block Model with more than $\\sqrt{n}$ Communities (II)", "comment": null, "summary": "A fundamental theoretical question in network analysis is to determine under which conditions community recovery is possible in polynomial time in the Stochastic Block Model (SBM). When the number $K$ of communities remains smaller than $\\sqrt{n}$ --where $n$ denotes the number of nodes--, non-trivial community recovery is possible in polynomial time above, and only above, the Kesten--Stigum (KS) threshold, originally postulated using arguments from statistical physics.\n  When $K \\geq \\sqrt{n}$, Chin, Mossel, Sohn, and Wein recently proved that, in the \\emph{sparse regime}, community recovery in polynomial time is achievable below the KS threshold by counting non-backtracking paths. This finding led them to postulate a new threshold for the many-communities regime $K \\geq \\sqrt{n}$. Subsequently, Carpentier, Giraud, and Verzelen established the failure of low-degree polynomials below this new threshold across all density regimes, and demonstrated successful recovery above the threshold in certain moderately sparse settings. While these results provide strong evidence that, in the many community setting, the computational barrier lies at the threshold proposed in~Chin et al., the question of achieving recovery above this threshold still remains open in most density regimes.\n  The present work is a follow-up to~Carpentier et al., in which we prove Conjecture~1.4 stated therein by: \\\\ 1- Constructing a family of motifs satisfying specific structural properties; and\\\\ 2- Proving that community recovery is possible above the proposed threshold by counting such motifs.\\\\ Our results complete the picture of the computational barrier for community recovery in the SBM with $K \\geq \\sqrt{n}$ communities. They also indicate that, in moderately sparse regimes, the optimal algorithms appear to be fundamentally different from spectral methods."}
