<div id=toc></div>

# Table of Contents

- [cs.LG](#cs.LG) [Total: 30]
- [cs.AI](#cs.AI) [Total: 8]
- [stat.AP](#stat.AP) [Total: 2]
- [eess.SP](#eess.SP) [Total: 9]
- [stat.ML](#stat.ML) [Total: 2]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [The Eigenvalues Entropy as a Classifier Evaluation Measure](https://arxiv.org/abs/2511.01904)
*Doulaye Dembélé*

Main category: cs.LG

TL;DR: 本文提出使用特征值熵作为评估分类器性能的新指标，特别适用于类别不平衡的数据集。该指标与常用的评估指标（如灵敏度、特异性、AUC和基尼指数）存在数学关系，并能估计混淆矩阵以处理类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有评估指标在类别不平衡数据集上准确性不足，需要开发更有效的评估方法来比较不同分类方法的性能。

Method: 使用特征值熵作为评估指标，建立特征值与常用评估指标之间的数学关系，并提出估计混淆矩阵的方法来处理类别不平衡问题。

Result: 通过多个数据示例验证，所提出的特征值熵评估指标在性能上优于文献中的标准评估指标。

Conclusion: 特征值熵是一种有效的分类器评估指标，特别适用于类别不平衡情况，能够提供更准确的性能评估。

Abstract: Classification is a machine learning method used in many practical
applications: text mining, handwritten character recognition, face recognition,
pattern classification, scene labeling, computer vision, natural langage
processing. A classifier prediction results and training set information are
often used to get a contingency table which is used to quantify the method
quality through an evaluation measure. Such measure, typically a numerical
value, allows to choose a suitable method among several. Many evaluation
measures available in the literature are less accurate for a dataset with
imbalanced classes. In this paper, the eigenvalues entropy is used as an
evaluation measure for a binary or a multi-class problem. For a binary problem,
relations are given between the eigenvalues and some commonly used measures,
the sensitivity, the specificity, the area under the operating receiver
characteristic curve and the Gini index. A by-product result of this paper is
an estimate of the confusion matrix to deal with the curse of the imbalanced
classes. Various data examples are used to show the better performance of the
proposed evaluation measure over the gold standard measures available in the
literature.

</details>


### [2] [Reducing normalizing flow complexity for MCMC preconditioning](https://arxiv.org/abs/2511.02345)
*David Nabergoj,Erik Štrumbelj*

Main category: cs.LG

TL;DR: 该论文提出了一种因子化预处理架构，通过结合线性组件和条件归一化流来降低归一化流复杂度，提高对目标几何形状的适应性。


<details>
  <summary>Details</summary>
Motivation: 现有非线性预处理方法使用过参数化的归一化流，这会降低采样效率和拟合质量，且现有方法无法根据目标分布自适应调整架构。

Method: 提出因子化预处理架构，使用线性预处理器处理近似高斯分布的维度，条件归一化流处理复杂维度，基于预热样本估计分布特性。

Result: 在复杂合成分布上获得更好的尾部样本，在稀疏逻辑回归后验上表现一致更好，在弱似然和强漏斗几何的分层贝叶斯模型后验上获得更高的有效样本量。

Conclusion: 该方法特别适用于数据有限的分层贝叶斯模型分析，可为神经MCMC设计的理论和软件进展提供参考。

Abstract: Preconditioning is a key component of MCMC algorithms that improves sampling
efficiency by facilitating exploration of geometrically complex target
distributions through an invertible map. While linear preconditioners are often
sufficient for moderately complex target distributions, recent work has
explored nonlinear preconditioning with invertible neural networks as
components of normalizing flows (NFs). However, empirical and theoretical
studies show that overparameterized NF preconditioners can degrade sampling
efficiency and fit quality. Moreover, existing NF-based approaches do not adapt
their architectures to the target distribution. Related work outside of MCMC
similarly finds that suitably parameterized NFs can achieve comparable or
superior performance with substantially less training time or data. We propose
a factorized preconditioning architecture that reduces NF complexity by
combining a linear component with a conditional NF, improving adaptability to
target geometry. The linear preconditioner is applied to dimensions that are
approximately Gaussian, as estimated from warmup samples, while the conditional
NF models more complex dimensions. Our method yields significantly better tail
samples on two complex synthetic distributions and consistently better
performance on a sparse logistic regression posterior across varying likelihood
and prior strengths. It also achieves higher effective sample sizes on
hierarchical Bayesian model posteriors with weak likelihoods and strong funnel
geometries. This approach is particularly relevant for hierarchical Bayesian
model analyses with limited data and could inform current theoretical and
software strides in neural MCMC design.

</details>


### [3] [ConMeZO: Adaptive Descent-Direction Sampling for Gradient-Free Finetuning of Large Language Models](https://arxiv.org/abs/2511.02757)
*Lejs Deen Behric,Liang Zhang,Bingcong Li,Kiran Koshy Thekumparampil*

Main category: cs.LG

TL;DR: ConMeZO是一种新颖的零阶优化器，通过自适应方向采样加速收敛，在微调大型语言模型时比MeZO快2倍，同时保持零阶方法的内存优势。


<details>
  <summary>Details</summary>
Motivation: 零阶优化（MeZO）在微调大型语言模型时具有内存优势，但由于在高维参数空间中搜索下降方向，收敛速度缓慢。

Method: ConMeZO通过将采样限制在以动量估计为中心的圆锥内，而不是均匀随机采样方向，将搜索集中在真实梯度更可能存在的方向上。

Result: ConMeZO在理论上达到与MeZO相同的最坏情况收敛率，在自然语言任务上微调LLMs时，比MeZO快2倍。

Conclusion: ConMeZO在保持零阶方法低内存占用的同时，显著加速了收敛速度，为大型语言模型的高效微调提供了有效解决方案。

Abstract: Zeroth-order or derivative-free optimization (MeZO) is an attractive strategy
for finetuning large language models (LLMs) because it eliminates the memory
overhead of backpropagation. However, it converges slowly due to the inherent
curse of dimensionality when searching for descent directions in the
high-dimensional parameter space of billion-scale LLMs. We propose ConMeZO, a
novel zeroth-order optimizer that accelerates convergence by adaptive
directional sampling. Instead of drawing the direction uniformly at random,
ConMeZO restricts the sampling to a cone centered around a momentum estimate.
This concentrates the search in directions where the true gradient is more
likely to lie and thus reduces the effect of high dimensions. We prove that
ConMeZO achieves the same worst-case convergence rate as MeZO. Empirically,
when finetuning LLMs on natural language tasks, ConMeZO is up to 2X faster than
MeZO while retaining the low-memory footprint of zeroth-order methods.

</details>


### [4] [COFAP: A Universal Framework for COFs Adsorption Prediction through Designed Multi-Modal Extraction and Cross-Modal Synergy](https://arxiv.org/abs/2511.01946)
*Zihan Li,Mingyang Wan,Mingyu Gao,Zhongshan Chen,Xiangke Wang,Feifan Zhang*

Main category: cs.LG

TL;DR: 提出了COFAP框架，通过深度学习提取多模态结构化学特征，使用跨模态注意力机制融合特征，无需传统气体相关特征即可实现COFs吸附性能的高效预测。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习预测器依赖特定气体相关特征，这些特征计算耗时且限制可扩展性，导致筛选COFs最优结构效率低下且劳动密集。

Method: 开发COFAP框架，通过深度学习提取多模态结构化学特征，使用跨模态注意力机制融合互补特征，无需Henry系数或吸附热等传统特征。

Result: 在hypoCOFs数据集上超越先前方法，达到新的SOTA性能；发现高性能分离COFs集中在狭窄的孔径和表面积范围内；开发了权重可调优先排序方案。

Conclusion: COFAP具有卓越的效率和准确性，可直接应用于晶体多孔材料的高通量筛选，为研究人员提供灵活的应用特定候选COFs排序。

Abstract: Covalent organic frameworks (COFs) are promising adsorbents for gas
adsorption and separation, while identifying the optimal structures among their
vast design space requires efficient high-throughput screening. Conventional
machine-learning predictors rely heavily on specific gas-related features.
However, these features are time-consuming and limit scalability, leading to
inefficiency and labor-intensive processes. Herein, a universal COFs adsorption
prediction framework (COFAP) is proposed, which can extract multi-modal
structural and chemical features through deep learning, and fuse these
complementary features via cross-modal attention mechanism. Without Henry
coefficients or adsorption heat, COFAP sets a new SOTA by outperforming
previous approaches on hypoCOFs dataset. Based on COFAP, we also found that
high-performing COFs for separation concentrate within a narrow range of pore
size and surface area. A weight-adjustable prioritization scheme is also
developed to enable flexible, application-specific ranking of candidate COFs
for researchers. Superior efficiency and accuracy render COFAP directly
deployable in crystalline porous materials.

</details>


### [5] [EchoLSTM: A Self-Reflective Recurrent Network for Stabilizing Long-Range Memory](https://arxiv.org/abs/2511.01950)
*Prasanth K K,Shubham Sharma*

Main category: cs.LG

TL;DR: 提出输出条件门控新架构，通过基于过去推理调节内部记忆门实现自反思维，结合注意力机制形成EchoLSTM模型，在长序列依赖任务中显著优于标准LSTM，且参数效率高于Transformer


<details>
  <summary>Details</summary>
Motivation: 标准RNN和LSTM难以建模长距离依赖关系，特别是在包含噪声或误导信息的序列中，需要更稳健的记忆系统

Method: 提出输出条件门控架构原则，使模型能够基于自身过去推理进行自反思维调节内部记忆门，形成稳定反馈循环增强记忆保持，最终模型EchoLSTM结合注意力机制

Result: 在Distractor Signal Task上达到69.0%准确率，比标准LSTM基线提高33个百分点；在ListOps基准上达到69.8%性能，与Transformer的71.8%相当，但参数效率高5倍以上

Conclusion: 自反思维机制使模型具有更稳健的记忆系统，输出条件门控是处理长序列依赖的有效方法

Abstract: Standard Recurrent Neural Networks, including LSTMs, struggle to model
long-range dependencies, particularly in sequences containing noisy or
misleading information. We propose a new architectural principle,
Output-Conditioned Gating, which enables a model to perform self-reflection by
modulating its internal memory gates based on its own past inferences. This
creates a stabilizing feedback loop that enhances memory retention. Our final
model, the EchoLSTM, integrates this principle with an attention mechanism. We
evaluate the EchoLSTM on a series of challenging benchmarks. On a
custom-designed Distractor Signal Task, the EchoLSTM achieves 69.0% accuracy,
decisively outperforming a standard LSTM baseline by 33 percentage points.
Furthermore, on the standard ListOps benchmark, the EchoLSTM achieves
performance competitive with a modern Transformer model, 69.8% vs. 71.8%, while
being over 5 times more parameter-efficient. A final Trigger Sensitivity Test
provides qualitative evidence that our model's self-reflective mechanism leads
to a fundamentally more robust memory system.

</details>


### [6] [A Dual-Use Framework for Clinical Gait Analysis: Attention-Based Sensor Optimization and Automated Dataset Auditing](https://arxiv.org/abs/2511.02047)
*Hamidreza Sadeghsalehi*

Main category: cs.LG

TL;DR: 提出了一种多流注意力深度学习框架，既能优化传感器配置，又能自动审计数据质量。在步态分析数据中发现严重的侧向性偏差问题。


<details>
  <summary>Details</summary>
Motivation: 可穿戴传感器和AI在客观步态分析中很重要，但模型容易受到隐藏数据集偏差的影响，且任务特定的传感器优化仍具挑战性。

Method: 使用多流注意力深度学习框架，结合注意力机制来发现数据集偏差并优化传感器配置。

Result: 模型注意力机制定量发现了严重的数据集混淆问题，例如在OA和CVA筛查任务中，超过70%的注意力分配给右脚，而左脚几乎被忽略（<0.1%），这反映了公共数据集中严重的侧向性偏差。

Conclusion: 该工作的主要贡献是方法学上的，证明可解释框架可以自动审计数据集完整性。作为次要发现，模型提出了新颖的数据驱动传感器协同作用，为未来优化协议提供假设。

Abstract: Objective gait analysis using wearable sensors and AI is critical for
managing neurological and orthopedic conditions. However, models are vulnerable
to hidden dataset biases, and task-specific sensor optimization remains a
challenge. We propose a multi-stream attention-based deep learning framework
that functions as both a sensor optimizer and an automated data auditor.
Applied to the Voisard et al. (2025) multi-cohort gait dataset on four clinical
tasks (PD, OA, CVA screening; PD vs CVA differential), the model's attention
mechanism quantitatively discovered a severe dataset confound. For OA and CVA
screening, tasks where bilateral assessment is clinically essential, the model
assigned more than 70 percent attention to the Right Foot while statistically
ignoring the Left Foot (less than 0.1 percent attention, 95 percent CI
[0.0-0.1]). This was not a clinical finding but a direct reflection of a severe
laterality bias (for example, 15 of 15 right-sided OA) in the public dataset.
The primary contribution of this work is methodological, demonstrating that an
interpretable framework can automatically audit dataset integrity. As a
secondary finding, the model proposes novel, data-driven sensor synergies (for
example, Head plus Foot for PD screening) as hypotheses for future optimized
protocols.

</details>


### [7] [LLM Probing with Contrastive Eigenproblems: Improving Understanding and Applicability of CCS](https://arxiv.org/abs/2511.02089)
*Stefan F. Schouten,Peter Bloem*

Main category: cs.LG

TL;DR: 本文重新审视了对比一致性搜索(CCS)方法，将其重新表述为特征值问题，提供了闭式解和可解释的特征值，并扩展到多变量情况，避免了随机初始化的敏感性问题。


<details>
  <summary>Details</summary>
Motivation: CCS是一种无监督探测方法，用于测试大语言模型是否在其内部激活中表示二元特征。虽然CCS显示出潜力，但其双项目标函数仅被部分理解。本文旨在澄清其机制并扩展其适用性。

Method: 基于相对对比一致性的洞察，将CCS重新表述为特征值问题，获得具有可解释特征值的闭式解，并自然扩展到多变量情况。

Result: 在多个数据集上评估这些方法，发现它们恢复了与CCS相似的性能，同时避免了随机初始化的敏感性问题。

Conclusion: 相对化对比一致性不仅改进了对CCS的理解，还为更广泛的探测和机械可解释性方法开辟了途径。

Abstract: Contrast-Consistent Search (CCS) is an unsupervised probing method able to
test whether large language models represent binary features, such as sentence
truth, in their internal activations. While CCS has shown promise, its two-term
objective has been only partially understood. In this work, we revisit CCS with
the aim of clarifying its mechanisms and extending its applicability. We argue
that what should be optimized for, is relative contrast consistency. Building
on this insight, we reformulate CCS as an eigenproblem, yielding closed-form
solutions with interpretable eigenvalues and natural extensions to multiple
variables. We evaluate these approaches across a range of datasets, finding
that they recover similar performance to CCS, while avoiding problems around
sensitivity to random initialization. Our results suggest that relativizing
contrast consistency not only improves our understanding of CCS but also opens
pathways for broader probing and mechanistic interpretability methods.

</details>


### [8] [Geometric Data Valuation via Leverage Scores](https://arxiv.org/abs/2511.02100)
*Rodrigo Mendoza-Smith*

Main category: cs.LG

TL;DR: 本文提出了一种基于统计杠杆得分的几何替代方法，用于数据估值，解决了Shapley值计算复杂度高的问题，并在主动学习实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: Shapley数据估值虽然提供了原则性的数据重要性评估框架，但由于需要评估所有数据子集的边际效用，计算复杂度高，难以在大规模数据上应用。

Method: 采用统计杠杆得分作为几何替代方法，量化每个数据点在表示空间中的结构影响，通过测量其对数据集跨度扩展和训练问题有效维度的贡献。

Result: 杠杆得分满足Shapley估值的虚拟性、效率和对称性公理，岭杠杆得分具有严格正的边际增益，与经典A-和D-最优设计准则自然连接。训练杠杆采样子集得到的模型参数和预测风险与全数据最优解相差O(ε)。

Conclusion: 基于杠杆得分的数据估值方法不仅计算高效，而且与下游决策质量有严格的理论联系，在主动学习中优于标准基线方法，无需梯度或反向传播。

Abstract: Shapley data valuation provides a principled, axiomatic framework for
assigning importance to individual datapoints, and has gained traction in
dataset curation, pruning, and pricing. However, it is a combinatorial measure
that requires evaluating marginal utility across all subsets of the data,
making it computationally infeasible at scale. We propose a geometric
alternative based on statistical leverage scores, which quantify each
datapoint's structural influence in the representation space by measuring how
much it extends the span of the dataset and contributes to the effective
dimensionality of the training problem. We show that our scores satisfy the
dummy, efficiency, and symmetry axioms of Shapley valuation and that extending
them to \emph{ridge leverage scores} yields strictly positive marginal gains
that connect naturally to classical A- and D-optimal design criteria. We
further show that training on a leverage-sampled subset produces a model whose
parameters and predictive risk are within $O(\varepsilon)$ of the full-data
optimum, thereby providing a rigorous link between data valuation and
downstream decision quality. Finally, we conduct an active learning experiment
in which we empirically demonstrate that ridge-leverage sampling outperforms
standard baselines without requiring access gradients or backward passes.

</details>


### [9] [Measuring the Intrinsic Dimension of Earth Representations](https://arxiv.org/abs/2511.02101)
*Arjun Rao,Marc Rußwurm,Konstantin Klemmer,Esther Rolf*

Main category: cs.LG

TL;DR: 本文首次研究了地理隐式神经表示（INRs）的内在维度，发现其维度在2到10之间，与下游任务性能相关，可作为无监督评估和模型选择的指标。


<details>
  <summary>Details</summary>
Motivation: 地理INRs旨在将地球数据压缩为紧凑的表示，但缺乏对其信息含量和分布的理解，需要量化这些表示的信息容量。

Method: 通过分析内在维度来测量地理INRs的信息含量，研究不同空间分辨率和输入模态对内在维度的影响，并验证其与下游任务性能的相关性。

Result: 地理INRs的内在维度在2到10之间，对空间分辨率和输入模态敏感，且与下游任务性能呈正相关，能捕捉空间伪影。

Conclusion: 内在维度为地理INRs提供了架构无关、无标签的信息含量度量，支持无监督评估、模型选择和预训练设计。

Abstract: Within the context of representation learning for Earth observation,
geographic Implicit Neural Representations (INRs) embed low-dimensional
location inputs (longitude, latitude) into high-dimensional embeddings, through
models trained on geo-referenced satellite, image or text data. Despite the
common aim of geographic INRs to distill Earth's data into compact,
learning-friendly representations, we lack an understanding of how much
information is contained in these Earth representations, and where that
information is concentrated. The intrinsic dimension of a dataset measures the
number of degrees of freedom required to capture its local variability,
regardless of the ambient high-dimensional space in which it is embedded. This
work provides the first study of the intrinsic dimensionality of geographic
INRs. Analyzing INRs with ambient dimension between 256 and 512, we find that
their intrinsic dimensions fall roughly between 2 and 10 and are sensitive to
changing spatial resolution and input modalities during INR pre-training.
Furthermore, we show that the intrinsic dimension of a geographic INR
correlates with downstream task performance and can capture spatial artifacts,
facilitating model evaluation and diagnostics. More broadly, our work offers an
architecture-agnostic, label-free metric of information content that can enable
unsupervised evaluation, model selection, and pre-training design across INRs.

</details>


### [10] [CFL: On the Use of Characteristic Function Loss for Domain Alignment in Machine Learning](https://arxiv.org/abs/2511.02148)
*Abdullah Almansour,Ozan Tonguz*

Main category: cs.LG

TL;DR: 本文提出使用特征函数作为频域方法来衡量高维空间中的分布偏移，为领域自适应提供了一种强大的替代方案。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在现实世界中部署时由于分布偏移问题而表现不佳，特别是在高风险应用中可能导致灾难性后果。传统统计方法存在局限性，需要更有效的分布偏移度量方法。

Method: 使用特征函数作为频域方法来量化高维空间中的分布偏移，为领域自适应提供新的测量工具。

Result: 特征函数方法被证明是衡量分布偏移的强大替代方案，特别适用于高维空间和领域自适应场景。

Conclusion: 特征函数作为一种频域方法，为机器学习中的分布偏移问题提供了有效的解决方案，是传统统计方法的有力替代。

Abstract: Machine Learning (ML) models are extensively used in various applications due
to their significant advantages over traditional learning methods. However, the
developed ML models often underperform when deployed in the real world due to
the well-known distribution shift problem. This problem can lead to a
catastrophic outcomes when these decision-making systems have to operate in
high-risk applications. Many researchers have previously studied this problem
in ML, known as distribution shift problem, using statistical techniques (such
as Kullback-Leibler, Kolmogorov-Smirnov Test, Wasserstein distance, etc.) to
quantify the distribution shift. In this letter, we show that using
Characteristic Function (CF) as a frequency domain approach is a powerful
alternative for measuring the distribution shift in high-dimensional space and
for domain adaptation.

</details>


### [11] [ProtoTSNet: Interpretable Multivariate Time Series Classification With Prototypical Parts](https://arxiv.org/abs/2511.02152)
*Bartłomiej Małkus,Szymon Bobek,Grzegorz J. Nalepa*

Main category: cs.LG

TL;DR: ProtoTSNet是一种用于多变量时间序列数据可解释分类的新方法，通过改进ProtoPNet架构来捕获动态模式并处理特征重要性变化，在UEA档案的30个数据集上表现优于其他可解释方法。


<details>
  <summary>Details</summary>
Motivation: 在工业和医学等关键领域，时间序列数据应用广泛，需要既高精度又可解释的算法，因为这些领域的决策具有重大影响。

Method: 使用改进的卷积编码器，采用分组卷积，可作为自编码器预训练，旨在保留和量化特征重要性，专门解决时间序列分析的独特挑战。

Result: 在UEA档案的30个多变量时间序列数据集上评估，该方法在可解释方法中表现最佳，与非可解释和后处理可解释方法保持竞争力。

Conclusion: ProtoTSNet为领域专家提供了可访问的可解释结果，在保持与不可解释方法竞争力的同时，提供了优于其他可解释方法的性能。

Abstract: Time series data is one of the most popular data modalities in critical
domains such as industry and medicine. The demand for algorithms that not only
exhibit high accuracy but also offer interpretability is crucial in such
fields, as decisions made there bear significant consequences. In this paper,
we present ProtoTSNet, a novel approach to interpretable classification of
multivariate time series data, through substantial enhancements to the
ProtoPNet architecture. Our method is tailored to overcome the unique
challenges of time series analysis, including capturing dynamic patterns and
handling varying feature significance. Central to our innovation is a modified
convolutional encoder utilizing group convolutions, pre-trainable as part of an
autoencoder and designed to preserve and quantify feature importance. We
evaluated our model on 30 multivariate time series datasets from the UEA
archive, comparing our approach with existing explainable methods as well as
non-explainable baselines. Through comprehensive evaluation and ablation
studies, we demonstrate that our approach achieves the best performance among
ante-hoc explainable methods while maintaining competitive performance with
non-explainable and post-hoc explainable approaches, providing interpretable
results accessible to domain experts.

</details>


### [12] [Tackling Incomplete Data in Air Quality Prediction: A Bayesian Deep Learning Framework for Uncertainty Quantification](https://arxiv.org/abs/2511.02175)
*Yuzhuang Pian,Taiyu Wang,Shiqi Zhang,Rui Xu,Yonghong Liu*

Main category: cs.LG

TL;DR: 提出CGLUBNF框架，通过傅里叶特征和图注意力编码器捕捉多尺度空间依赖性和季节性时间动态，使用通道门控学习单元自适应过滤和放大信息特征，贝叶斯推理联合优化预测分布和参数不确定性，在空气质量预测中实现更准确的预测和更尖锐的置信区间。


<details>
  <summary>Details</summary>
Motivation: 空气质量预测对公共卫生警报、暴露评估和排放控制至关重要，但观测数据常因收集和传输问题而存在不同程度的缺失，这些不完整的时空记录会阻碍可靠推断和风险评估，并可能导致过度自信的外推。

Method: 提出端到端框架CGLUBNF，使用傅里叶特征和图注意力编码器捕捉多尺度空间依赖性和季节性时间动态，通道门控学习单元配备可学习激活和门控残差连接，自适应过滤和放大信息特征，贝叶斯推理联合优化预测分布和参数不确定性。

Result: 在两个真实世界数据集上进行了系统评估，涵盖四种典型缺失数据模式，并与五个最先进的基线进行比较。CGLUBNF实现了优越的预测精度和更尖锐的置信区间，在多个预测时间范围内验证了鲁棒性，并分析了外部变量的贡献。

Conclusion: 这项研究为在新兴感知范式（如真实世界车载移动监测）中基于深度学习的时空预测提供了可靠基础，能够处理不完整观测数据。

Abstract: Accurate air quality forecasts are vital for public health alerts, exposure
assessment, and emissions control. In practice, observational data are often
missing in varying proportions and patterns due to collection and transmission
issues. These incomplete spatiotemporal records impede reliable inference and
risk assessment and can lead to overconfident extrapolation. To address these
challenges, we propose an end to end framework, the channel gated learning unit
based spatiotemporal bayesian neural field (CGLUBNF). It uses Fourier features
with a graph attention encoder to capture multiscale spatial dependencies and
seasonal temporal dynamics. A channel gated learning unit, equipped with
learnable activations and gated residual connections, adaptively filters and
amplifies informative features. Bayesian inference jointly optimizes predictive
distributions and parameter uncertainty, producing point estimates and
calibrated prediction intervals. We conduct a systematic evaluation on two real
world datasets, covering four typical missing data patterns and comparing
against five state of the art baselines. CGLUBNF achieves superior prediction
accuracy and sharper confidence intervals. In addition, we further validate
robustness across multiple prediction horizons and analysis the contribution of
extraneous variables. This research lays a foundation for reliable deep
learning based spatio-temporal forecasting with incomplete observations in
emerging sensing paradigms, such as real world vehicle borne mobile monitoring.

</details>


### [13] [OmniField: Conditioned Neural Fields for Robust Multimodal Spatiotemporal Learning](https://arxiv.org/abs/2511.02205)
*Kevin Valencia,Thilina Balasooriya,Xihaier Luo,Shinjae Yoo,David Keetae Park*

Main category: cs.LG

TL;DR: OmniField是一个多模态时空学习框架，通过连续神经场和跨模态交互块处理稀疏、不规则、噪声数据，支持统一的重建、插值、预测和跨模态预测。


<details>
  <summary>Details</summary>
Motivation: 解决真实世界实验数据中模态内测量稀疏、不规则、噪声以及跨模态可用性变化的问题，避免网格化或替代预处理的需求。

Method: 采用连续神经场条件化可用模态，结合多模态交互块架构和迭代跨模态细化，在解码器前对齐信号。

Result: 在广泛评估中，OmniField持续优于八个强大的多模态时空基线方法，在重度模拟传感器噪声下性能仍接近清洁输入水平。

Conclusion: OmniField展示了在多模态时空学习中的卓越性能和鲁棒性，能够有效处理真实世界数据的挑战。

Abstract: Multimodal spatiotemporal learning on real-world experimental data is
constrained by two challenges: within-modality measurements are sparse,
irregular, and noisy (QA/QC artifacts) but cross-modally correlated; the set of
available modalities varies across space and time, shrinking the usable record
unless models can adapt to arbitrary subsets at train and test time. We propose
OmniField, a continuity-aware framework that learns a continuous neural field
conditioned on available modalities and iteratively fuses cross-modal context.
A multimodal crosstalk block architecture paired with iterative cross-modal
refinement aligns signals prior to the decoder, enabling unified
reconstruction, interpolation, forecasting, and cross-modal prediction without
gridding or surrogate preprocessing. Extensive evaluations show that OmniField
consistently outperforms eight strong multimodal spatiotemporal baselines.
Under heavy simulated sensor noise, performance remains close to clean-input
levels, highlighting robustness to corrupted measurements.

</details>


### [14] [FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error](https://arxiv.org/abs/2511.02302)
*Fengjuan Wang,Zhiyi Su,Xingzhu Hu,Cheng Wang,Mou Sun*

Main category: cs.LG

TL;DR: FP8-Flow-MoE是一种用于训练大型MoE模型的FP8训练方案，通过量化一致的FP8中心数据流和融合算子，显著减少了显存使用并提高了训练吞吐量。


<details>
  <summary>Details</summary>
Motivation: 当前MoE模型训练计算和内存需求巨大，现有FP8实现仍依赖BF16数据流和频繁的量化-反量化转换，这些冗余操作削弱了FP8的理论效率。

Method: 提出量化一致的FP8中心数据流，包含缩放感知转置和融合FP8算子，将显式转换操作从12个减少到2个，消除双量化误差。

Result: 在671B参数MoE模型上评估，相比BF16和朴素FP8基线，吞吐量提高21%，每个GPU内存使用减少16.5GB，同时保持稳定收敛。

Conclusion: FP8-Flow-MoE提供了一种即插即用的FP8训练方案，与TransformerEngine和Megatron-LM兼容，即将开源。

Abstract: Training large Mixture-of-Experts (MoE) models remains computationally
prohibitive due to their extreme compute and memory demands. Although
low-precision training promises to accelerate computation and reduce memory
footprint, existing implementations still rely on BF16-dominated dataflows with
frequent quantize-dequantize (Q/DQ) conversions. These redundant casts erode
much of FP8's theoretical efficiency. However, naively removing these casts by
keeping dataflows entirely in FP8 introduces double quantization error: tensors
quantized along different dimensions accumulate inconsistent scaling factors,
degrading numerical stability.
  We propose FP8-Flow-MoE, an FP8 training recipe featuring a
quantization-consistent FP8-centric dataflow with a scaling-aware transpose and
fused FP8 operators that streamline computation and eliminate explicit cast
operations from 12 to 2. Evaluations on a 671B-parameter MoE model demonstrate
up to 21\% higher throughput and 16.5 GB lower memory usage per GPU compared to
BF16 and na\"ive FP8 baselines, while maintaining stable convergence. We
provide a plug-and-play FP8 recipe compatible with TransformerEngine and
Megatron-LM, which will be open-sourced soon.

</details>


### [15] [The Sequential Edge: Inverse-Entropy Voting Beats Parallel Self-Consistency at Matched Compute](https://arxiv.org/abs/2511.02309)
*Aman Sharma,Paras Chopra*

Main category: cs.LG

TL;DR: 本文重新审视语言模型推理的测试时扩展策略，发现在同等计算资源下，顺序扩展（链式迭代精炼）比并行自一致性范式表现更好，在95.6%的配置中准确率提升高达46.7%。


<details>
  <summary>Details</summary>
Motivation: 挑战当前主导的并行自一致性推理范式，探索在同等计算预算下，顺序扩展是否比并行扩展更有效。

Method: 在5个最先进开源模型和3个挑战性推理基准上进行全面评估，比较并行自一致性与顺序扩展策略，并引入基于逆熵加权投票的新方法。

Result: 顺序扩展在95.6%的配置中优于并行自一致性，准确率提升高达46.7%；逆熵加权投票进一步提升了顺序扩展的准确率。

Conclusion: 顺序精炼应成为现代LLM推理的稳健默认策略，这需要对推理时优化方法进行范式转变。

Abstract: We revisit test-time scaling for language model reasoning and ask a
fundamental question: at equal token budget and compute, is it better to run
multiple independent chains in parallel, or to run fewer chains that
iteratively refine through sequential steps? Through comprehensive evaluation
across 5 state-of-the-art open source models and 3 challenging reasoning
benchmarks, we find that sequential scaling where chains explicitly build upon
previous attempts consistently outperforms the dominant parallel
self-consistency paradigm in 95.6% of configurations with gains in accuracy
upto 46.7%. Further, we introduce inverse-entropy weighted voting, a novel
training-free method to further boost the accuracy of sequential scaling. By
weighing answers in proportion to the inverse entropy of their reasoning
chains, we increase our success rate over parallel majority and establish it as
the optimal test-time scaling strategy. Our findings fundamentally challenge
the parallel reasoning orthodoxy that has dominated test-time scaling since
Wang et al.'s self-consistency decoding (Wang et al., 2022), positioning
sequential refinement as the robust default for modern LLM reasoning and
necessitating a paradigm shift in how we approach inference-time optimization.

</details>


### [16] [Human-Machine Ritual: Synergic Performance through Real-Time Motion Recognition](https://arxiv.org/abs/2511.02351)
*Zhuodi Cai,Ziyu Xu,Juan Pampin*

Main category: cs.LG

TL;DR: 提出一种轻量级实时运动识别系统，通过可穿戴IMU传感器数据、MiniRocket时间序列分类和响应式多媒体控制，实现人机协同表演。


<details>
  <summary>Details</summary>
Motivation: 探索一种替代性的人机协作方法，通过将舞者特定动作映射到声音，保留表演身体的表达深度，同时利用机器学习实现专注观察和响应。

Method: 使用可穿戴IMU传感器收集数据，采用MiniRocket时间序列分类算法，结合体感记忆和关联机制将舞蹈动作映射到声音控制。

Result: 系统可靠支持高精度分类（延迟<50毫秒），提供了可复制的框架，可将具备舞蹈理解能力的机器集成到创意、教育和现场表演场景中。

Conclusion: 该人本设计方法成功实现了低延迟、高精度的实时运动识别，为人机协同表演提供了可行的技术框架。

Abstract: We introduce a lightweight, real-time motion recognition system that enables
synergic human-machine performance through wearable IMU sensor data, MiniRocket
time-series classification, and responsive multimedia control. By mapping
dancer-specific movement to sound through somatic memory and association, we
propose an alternative approach to human-machine collaboration, one that
preserves the expressive depth of the performing body while leveraging machine
learning for attentive observation and responsiveness. We demonstrate that this
human-centered design reliably supports high accuracy classification (<50 ms
latency), offering a replicable framework to integrate dance-literate machines
into creative, educational, and live performance contexts.

</details>


### [17] [Accounting for Underspecification in Statistical Claims of Model Superiority](https://arxiv.org/abs/2511.02453)
*Thomas Sanchez,Pedro M. Gordaliza,Meritxell Bach Cuadra*

Main category: cs.LG

TL;DR: 本文扩展了统计框架以考虑机器学习模型中的不确定性，发现即使很小的随机种子变异性也会显著增加支持优越性声明所需的证据，强调了在验证医学成像系统时需要明确建模训练方差。


<details>
  <summary>Details</summary>
Motivation: 机器学习方法在医学成像中应用日益广泛，但许多报告的改进缺乏统计稳健性。现有分析未考虑不确定性——即由于随机初始化或训练动态，获得相似验证分数的模型可能在未见数据上表现不同。

Method: 扩展了最近的统计框架，将不确定性作为额外的方差分量进行建模，通过模拟研究评估随机种子变异性对优越性声明证据要求的影响。

Result: 模拟显示即使适度的种子变异性（约1%）也会显著增加支持优越性声明所需的证据，不确定性进一步加剧了假阳性声明的风险。

Conclusion: 研究结果强调了在验证医学成像系统时明确建模训练方差的必要性，以确保统计稳健性和可靠性。

Abstract: Machine learning methods are increasingly applied in medical imaging, yet
many reported improvements lack statistical robustness: recent works have
highlighted that small but significant performance gains are highly likely to
be false positives. However, these analyses do not take
\emph{underspecification} into account -- the fact that models achieving
similar validation scores may behave differently on unseen data due to random
initialization or training dynamics. Here, we extend a recent statistical
framework modeling false outperformance claims to include underspecification as
an additional variance component. Our simulations demonstrate that even modest
seed variability ($\sim1\%$) substantially increases the evidence required to
support superiority claims. Our findings underscore the need for explicit
modeling of training variance when validating medical imaging systems.

</details>


### [18] [NOWS: Neural Operator Warm Starts for Accelerating Iterative Solvers](https://arxiv.org/abs/2511.02481)
*Mohammad Sadegh Eshaghi,Cosmin Anitescu,Navid Valizadeh,Yizheng Wang,Xiaoying Zhuang,Timon Rabczuk*

Main category: cs.LG

TL;DR: 提出了一种混合策略NOWS，利用学习到的解算子为Krylov方法生成高质量初始猜测，从而加速传统迭代求解器，同时保持数值算法的稳定性和收敛保证。


<details>
  <summary>Details</summary>
Motivation: 高保真PDE模拟在计算上仍然是一个主要瓶颈，而数据驱动的替代方法虽然速度快，但在训练分布之外应用时往往不可靠。

Method: NOWS策略利用学习到的解算子为共轭梯度和GMRES等Krylov方法生成高质量初始猜测，与现有离散化和求解器基础设施无缝集成。

Result: 在基准测试中，学习到的初始化一致减少了迭代次数和端到端运行时间，计算时间最多减少90%。

Conclusion: NOWS通过将神经算子的快速推理与传统求解器的严谨性相结合，为加速高保真PDE模拟提供了一种实用且可信赖的方法。

Abstract: Partial differential equations (PDEs) underpin quantitative descriptions
across the physical sciences and engineering, yet high-fidelity simulation
remains a major computational bottleneck for many-query, real-time, and design
tasks. Data-driven surrogates can be strikingly fast but are often unreliable
when applied outside their training distribution. Here we introduce Neural
Operator Warm Starts (NOWS), a hybrid strategy that harnesses learned solution
operators to accelerate classical iterative solvers by producing high-quality
initial guesses for Krylov methods such as conjugate gradient and GMRES. NOWS
leaves existing discretizations and solver infrastructures intact, integrating
seamlessly with finite-difference, finite-element, isogeometric analysis,
finite volume method, etc. Across our benchmarks, the learned initialization
consistently reduces iteration counts and end-to-end runtime, resulting in a
reduction of the computational time of up to 90 %, while preserving the
stability and convergence guarantees of the underlying numerical algorithms. By
combining the rapid inference of neural operators with the rigor of traditional
solvers, NOWS provides a practical and trustworthy approach to accelerate
high-fidelity PDE simulations.

</details>


### [19] [Adaptive Neighborhood-Constrained Q Learning for Offline Reinforcement Learning](https://arxiv.org/abs/2511.02567)
*Yixiu Mao,Yun Qu,Qi Wang,Xiangyang Ji*

Main category: cs.LG

TL;DR: 提出了一种新的邻域约束方法来解决离线强化学习中的外推误差问题，该方法将贝尔曼目标中的动作选择限制在数据集动作邻域的并集上，并通过双层优化框架实现自适应的邻域约束。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习面临由分布外动作引起的外推误差问题，现有的密度约束、支持约束和样本约束方法各有局限：密度和样本约束过于保守，而支持约束在准确建模行为策略方面存在困难。

Method: 提出邻域约束方法，将贝尔曼目标中的动作选择限制在数据集动作邻域的并集上；使用数据质量作为适应准则设计自适应邻域约束；基于高效的双层优化框架开发ANQ算法。

Result: 理论上证明该约束能在特定条件下限制外推误差和分布偏移，且无需行为策略建模即可近似支持约束；实证表明ANQ在标准离线RL基准上达到最先进性能，在噪声或有限数据场景下表现出强鲁棒性。

Conclusion: 邻域约束方法克服了现有约束方法的局限性，提供了灵活且点式保守的解决方案，ANQ算法在性能和鲁棒性方面表现优异。

Abstract: Offline reinforcement learning (RL) suffers from extrapolation errors induced
by out-of-distribution (OOD) actions. To address this, offline RL algorithms
typically impose constraints on action selection, which can be systematically
categorized into density, support, and sample constraints. However, we show
that each category has inherent limitations: density and sample constraints
tend to be overly conservative in many scenarios, while the support constraint,
though least restrictive, faces challenges in accurately modeling the behavior
policy. To overcome these limitations, we propose a new neighborhood constraint
that restricts action selection in the Bellman target to the union of
neighborhoods of dataset actions. Theoretically, the constraint not only bounds
extrapolation errors and distribution shift under certain conditions, but also
approximates the support constraint without requiring behavior policy modeling.
Moreover, it retains substantial flexibility and enables pointwise conservatism
by adapting the neighborhood radius for each data point. In practice, we employ
data quality as the adaptation criterion and design an adaptive neighborhood
constraint. Building on an efficient bilevel optimization framework, we develop
a simple yet effective algorithm, Adaptive Neighborhood-constrained Q learning
(ANQ), to perform Q learning with target actions satisfying this constraint.
Empirically, ANQ achieves state-of-the-art performance on standard offline RL
benchmarks and exhibits strong robustness in scenarios with noisy or limited
data.

</details>


### [20] [Natural-gas storage modelling by deep reinforcement learning](https://arxiv.org/abs/2511.02646)
*Tiziano Balaconi,Aldo Glielmo,Marco Taboga*

Main category: cs.LG

TL;DR: GasRL是一个结合天然气市场校准模型和深度强化学习存储管理策略的模拟器，用于分析最优库存管理对均衡价格及供需动态的影响。研究发现SAC算法表现最佳，能实现盈利性、市场清算稳健性和价格稳定等多重目标，且其产生的价格动态与实际市场特征高度匹配。模拟器还可用于评估欧盟最低存储阈值政策，发现该政策能增强市场对供应冲击的韧性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在分析天然气市场中存储运营商的最优库存管理策略如何影响市场均衡价格和供需动态，并评估政策干预（如欧盟最低存储阈值）对市场稳定性的影响。

Method: 开发GasRL模拟器，将天然气市场校准模型与深度强化学习（特别是Soft Actor Critic算法）训练的存储运营商策略相结合，测试多种RL算法性能。

Result: SAC算法在GasRL环境中表现最优，成功实现存储运营商的多重目标；SAC策略产生的均衡价格动态与实际市场价格特征高度一致；欧盟最低存储阈值政策能有效增强市场对供应冲击的韧性，减少市场中断风险。

Conclusion: GasRL模拟器为分析天然气市场动态和政策影响提供了有效工具，SAC算法能产生符合实际市场特征的最优存储管理策略，欧盟最低存储阈值政策有助于提升市场稳定性。

Abstract: We introduce GasRL, a simulator that couples a calibrated representation of
the natural gas market with a model of storage-operator policies trained with
deep reinforcement learning (RL). We use it to analyse how optimal stockpile
management affects equilibrium prices and the dynamics of demand and supply. We
test various RL algorithms and find that Soft Actor Critic (SAC) exhibits
superior performance in the GasRL environment: multiple objectives of storage
operators - including profitability, robust market clearing and price
stabilisation - are successfully achieved. Moreover, the equilibrium price
dynamics induced by SAC-derived optimal policies have characteristics, such as
volatility and seasonality, that closely match those of real-world prices.
Remarkably, this adherence to the historical distribution of prices is obtained
without explicitly calibrating the model to price data. We show how the
simulator can be used to assess the effects of EU-mandated minimum storage
thresholds. We find that such thresholds have a positive effect on market
resilience against unanticipated shifts in the distribution of supply shocks.
For example, with unusually large shocks, market disruptions are averted more
often if a threshold is in place.

</details>


### [21] [In Situ Training of Implicit Neural Compressors for Scientific Simulations via Sketch-Based Regularization](https://arxiv.org/abs/2511.02659)
*Cooper Simpson,Stephen Becker,Alireza Doostan*

Main category: cs.LG

TL;DR: 提出一种新颖的在线训练协议，使用完整数据和草图数据的有限内存缓冲区，通过草图数据防止灾难性遗忘，特别针对基于隐式神经表示的神经压缩应用。


<details>
  <summary>Details</summary>
Motivation: 解决在线学习中的灾难性遗忘问题，特别是在隐式神经表示和神经压缩领域，通过草图数据作为正则化器来维持模型性能。

Method: 使用有限内存缓冲区存储完整和草图数据样本，基于Johnson-Lindenstrauss理论将草图作为正则化器，应用于基于隐式神经表示的hypernetworks进行在线神经压缩。

Result: 在复杂仿真数据上（2D/3D、长时间序列、非结构化网格和非笛卡尔几何）展示了高压缩率下的强重建性能，草图方法使在线方案性能接近等效离线方法。

Conclusion: 草图技术能够有效防止在线学习中的灾难性遗忘，使在线训练方案在神经压缩任务中达到与离线方法相当的性能水平。

Abstract: Focusing on implicit neural representations, we present a novel in situ
training protocol that employs limited memory buffers of full and sketched data
samples, where the sketched data are leveraged to prevent catastrophic
forgetting. The theoretical motivation for our use of sketching as a
regularizer is presented via a simple Johnson-Lindenstrauss-informed result.
While our methods may be of wider interest in the field of continual learning,
we specifically target in situ neural compression using implicit neural
representation-based hypernetworks. We evaluate our method on a variety of
complex simulation data in two and three dimensions, over long time horizons,
and across unstructured grids and non-Cartesian geometries. On these tasks, we
show strong reconstruction performance at high compression rates. Most
importantly, we demonstrate that sketching enables the presented in situ scheme
to approximately match the performance of the equivalent offline method.

</details>


### [22] [Rawlsian many-to-one matching with non-linear utility](https://arxiv.org/abs/2511.02533)
*Hortence Nana,Andreas Athanasopoulos,Christos Dimitrakakis*

Main category: cs.LG

TL;DR: 本文研究具有非线性效用函数的大学招生匹配问题，提出基于罗尔斯公平的替代方案来解决经典稳定匹配不存在的问题。


<details>
  <summary>Details</summary>
Motivation: 经典稳定匹配在考虑学生多样性的非线性效用函数下可能不存在，需要新的公平分配方法。

Method: 设计确定性和随机性算法，通过迭代改善最差大学的效用来实现公平分配。

Result: 提出了基于罗尔斯公平原则的解决方案，能够在稳定匹配不可得时提供公平的分配结果。

Conclusion: 当经典稳定匹配不存在时，基于最大化最小效用的罗尔斯公平方法提供了可行的替代方案。

Abstract: We study a many-to-one matching problem, such as the college admission
problem, where each college can admit multiple students. Unlike classical
models, colleges evaluate sets of students through non-linear utility functions
that capture diversity between them. In this setting, we show that classical
stable matchings may fail to exist. To address this, we propose alternative
solution concepts based on Rawlsian fairness, aiming to maximize the minimum
utility across colleges. We design both deterministic and stochastic algorithms
that iteratively improve the outcome of the worst-off college, offering a
practical approach to fair allocation when stability cannot be guaranteed.

</details>


### [23] [Assessing win strength in MLB win prediction models](https://arxiv.org/abs/2511.02815)
*Morgan Allen,Paul Savala*

Main category: cs.LG

TL;DR: 该研究扩展了MLB比赛预测模型，通过训练多种机器学习模型来预测胜队，并分析预测胜率与比分差异的关系，最后探讨了在跑分线投注中的应用效果。


<details>
  <summary>Details</summary>
Motivation: 扩展先前关于MLB比赛预测的研究，通过统一的训练数据集构建全面的机器学习模型，并验证预测胜率与实际比赛优势之间的关系。

Method: 使用统一数据集训练多种机器学习模型，分析预测胜率与比分差异的相关性，并测试模型在跑分线投注决策中的应用。

Result: 大多数机器学习模型确实显示出预测胜率与比赛优势强度之间的关系；适当的投注策略能产生正收益，但简单使用模型进行投注会导致显著损失。

Conclusion: 机器学习模型能有效预测MLB比赛结果并反映比赛优势，但在实际投注应用中需要谨慎的策略设计，不能简单依赖模型预测。

Abstract: In Major League Baseball, strategy and planning are major factors in
determining the outcome of a game. Previous studies have aided this by building
machine learning models for predicting the winning team of any given game. We
extend this work by training a comprehensive set of machine learning models
using a common dataset. In addition, we relate the win probabilities produced
by these models to win strength as measured by score differential. In doing so
we show that the most common machine learning models do indeed demonstrate a
relationship between predicted win probability and the strength of the win.
Finally, we analyze the results of using predicted win probabilities as a
decision making mechanism on run-line betting. We demonstrate positive returns
when utilizing appropriate betting strategies, and show that naive use of
machine learning models for betting lead to significant loses.

</details>


### [24] [Directional-Clamp PPO](https://arxiv.org/abs/2511.02577)
*Gilad Karpel,Ruida Zhou,Shoham Sabach,Mohammad Ghavamzadeh*

Main category: cs.LG

TL;DR: 本文提出了一种改进的PPO算法DClamp-PPO，通过在"错误"方向区域引入额外的惩罚机制，解决了传统PPO算法中重要性比率经常向错误方向移动的问题，从而提升了算法性能。


<details>
  <summary>Details</summary>
Motivation: 传统PPO算法在优化过程中，由于rollout的随机性和策略优化的随机性，重要性比率经常向"错误"方向移动，这是阻碍PPO改进的关键因素，但一直被忽视。

Method: 提出DClamp-PPO算法，在严格"错误"方向区域（优势为正时重要性比率低于1-β，优势为负时重要性比率高于1+β）引入额外的惩罚机制，通过强制执行更陡峭的损失斜率来惩罚这些动作。

Result: 在多个MuJoCo环境中使用不同随机种子的实验表明，DClamp-PPO始终优于PPO及其变体，能更好地避免"错误"方向更新，同时保持重要性比率更接近1。

Conclusion: DClamp-PPO通过关注修改目标函数在"错误"方向区域的行为，有效提升了PPO算法的性能，理论和实证都证明了其优越性。

Abstract: Proximal Policy Optimization (PPO) is widely regarded as one of the most
successful deep reinforcement learning algorithms, known for its robustness and
effectiveness across a range of problems.
  The PPO objective encourages the importance ratio between the current and
behavior policies to move to the "right" direction -- starting from importance
sampling ratios equal to 1, increasing the ratios for actions with positive
advantages and decreasing those with negative advantages. A clipping function
is introduced to prevent over-optimization when updating the importance ratio
in these "right" direction regions. Many PPO variants have been proposed to
extend its success, most of which modify the objective's behavior by altering
the clipping in the "right" direction regions. However, due to randomness in
the rollouts and stochasticity of the policy optimization, we observe that the
ratios frequently move to the "wrong" direction during the PPO optimization.
This is a key factor hindering the improvement of PPO, but it has been largely
overlooked. To address this, we propose the Directional-Clamp PPO algorithm
(DClamp-PPO), which further penalizes the actions going to the strict "wrong"
direction regions, where the advantage is positive (negative) and importance
ratio falls below (above) $1 - \beta$ ($1+\beta$),
  for a tunable parameter $\beta \in (0, 1)$. The penalty is by enforcing a
steeper loss slope, i.e., a clamp, in those regions. We demonstrate that
DClamp-PPO consistently outperforms PPO, as well as its variants, by focusing
on modifying the objective's behavior in the "right" direction, across various
MuJoCo environments, using different random seeds. The proposed method is
shown, both theoretically and empirically, to better avoid "wrong" direction
updates while keeping the importance ratio closer to 1.

</details>


### [25] [Recursively Enumerably Representable Classes and Computable Versions of the Fundamental Theorem of Statistical Learning](https://arxiv.org/abs/2511.02644)
*David Kattermann,Lothar Sebastian Krapp*

Main category: cs.LG

TL;DR: 本文研究了可计算PAC学习，探讨了传统统计学习基本定理在可计算框架下的失效情况，引入了有效VC维度的概念，并分析了可计算PAC学习与递归可枚举可表示类之间的关系。


<details>
  <summary>Details</summary>
Motivation: 传统统计学习基本定理在可计算学习框架下不再成立，需要寻找新的理论框架来刻画可计算PAC学习。

Method: 引入有效VC维度概念，研究可计算PAC学习与递归可枚举可表示类之间的连接关系，分析不同维度之间的关系。

Result: 发现有效VC维度可以取任意高于传统VC维度的值，但对于满足强可计算PAC学习概念的类别，两个维度会重合。同时证明了可计算PAC学习可以通过包含实现相同样本的递归可枚举可表示类来刻画。

Conclusion: 可计算PAC学习可以通过递归可枚举可表示类来表征，满足唯一识别性质的可计算PAC学习类必然是递归可枚举可表示的，且对于递归可枚举可表示类，可以通过考虑非均匀可计算PAC学习来保证不可知学习性。

Abstract: We study computable probably approximately correct (CPAC) learning, where
learners are required to be computable functions. It had been previously
observed that the Fundamental Theorem of Statistical Learning, which
characterizes PAC learnability by finiteness of the Vapnik-Chervonenkis
(VC-)dimension, no longer holds in this framework. Recent works recovered
analogs of the Fundamental Theorem in the computable setting, for instance by
introducing an effective VC-dimension. Guided by this, we investigate the
connection between CPAC learning and recursively enumerable representable (RER)
classes, whose members can be algorithmically listed. Our results show that the
effective VC-dimensions can take arbitrary values above the traditional one,
even for RER classes, which creates a whole family of (non-)examples for
various notions of CPAC learning. Yet the two dimensions coincide for classes
satisfying sufficiently strong notions of CPAC learning. We then observe that
CPAC learnability can also be characterized via containment of RER classes that
realize the same samples. Furthermore, it is shown that CPAC learnable classes
satisfying a unique identification property are necessarily RER. Finally, we
establish that agnostic learnability can be guaranteed for RER classes, by
considering the relaxed notion of nonuniform CPAC learning.

</details>


### [26] [Nesterov-Accelerated Robust Federated Learning Over Byzantine Adversaries](https://arxiv.org/abs/2511.02657)
*Lihan Xu,Yanjie Dong,Gang Wang,Runhao Zeng,Xiaoyi Fan,Xiping Hu*

Main category: cs.LG

TL;DR: 提出了一种抗拜占庭攻击的Nesterov加速联邦学习算法(Byrd-NAFL)，在存在恶意攻击者的情况下实现快速且安全的收敛。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，多个工作节点在中央服务器协调下协作训练共享模型时，面临拜占庭对手的任意恶意行为威胁，需要同时提升通信效率和鲁棒性。

Method: 将Nesterov动量与抗拜占庭聚合规则相结合，在非凸平滑损失函数下实现快速收敛，并对聚合梯度假设进行了放宽。

Result: 建立了Byrd-NAFL的有限时间收敛保证，并通过大量数值实验验证了其在收敛速度、准确性和对多种拜占庭攻击策略的韧性方面的优越性。

Conclusion: Byrd-NAFL算法在联邦学习环境中有效平衡了通信效率与鲁棒性需求，能够抵御各种拜占庭攻击策略，优于现有基准方法。

Abstract: We investigate robust federated learning, where a group of workers
collaboratively train a shared model under the orchestration of a central
server in the presence of Byzantine adversaries capable of arbitrary and
potentially malicious behaviors. To simultaneously enhance communication
efficiency and robustness against such adversaries, we propose a
Byzantine-resilient Nesterov-Accelerated Federated Learning (Byrd-NAFL)
algorithm. Byrd-NAFL seamlessly integrates Nesterov's momentum into the
federated learning process alongside Byzantine-resilient aggregation rules to
achieve fast and safeguarding convergence against gradient corruption. We
establish a finite-time convergence guarantee for Byrd-NAFL under non-convex
and smooth loss functions with relaxed assumption on the aggregated gradients.
Extensive numerical experiments validate the effectiveness of Byrd-NAFL and
demonstrate the superiority over existing benchmarks in terms of convergence
speed, accuracy, and resilience to diverse Byzantine attack strategies.

</details>


### [27] [Does Interpretability of Knowledge Tracing Models Support Teacher Decision Making?](https://arxiv.org/abs/2511.02718)
*Adia Khalid,Alina Deriyeva,Benjamin Paassen*

Main category: cs.LG

TL;DR: 本研究探讨了知识追踪(KT)模型的可解释性是否真正帮助人类教师做出教学决策。通过模拟研究和人类教师实验发现，虽然可解释模型在模拟中能更快达到掌握水平，且教师对其可用性和可信度评价更高，但实际教学中教师使用不同模型时学生达到掌握所需的任务数量差异不大。


<details>
  <summary>Details</summary>
Motivation: 知识追踪模型对教学决策至关重要，虽然通常要求具有可解释性，但之前没有研究验证这种可解释性是否真正帮助人类教师做出更好的教学决策。本研究旨在填补这一空白。

Method: 首先进行模拟研究，比较基于可解释KT模型和非可解释模型的教学决策效果；然后邀请12名人类教师参与实验，让他们基于KT模型提供的信息做出教学决策，并评估模型的可用性和可信度。

Result: 模拟研究显示基于可解释KT模型的决策能更快达到掌握水平；人类教师实验表明教师对可解释KT模型的可用性和可信度评价更高，但实际教学中学生达到掌握所需的任务数量在不同模型间差异不大。

Conclusion: 模型可解释性与教师决策之间的关系并不直接：教师不完全依赖KT模型做决策，需要进一步研究学习者和教师如何实际理解和使用KT模型。

Abstract: Knowledge tracing (KT) models are a crucial basis for pedagogical
decision-making, namely which task to select next for a learner and when to
stop teaching a particular skill. Given the high stakes of pedagogical
decisions, KT models are typically required to be interpretable, in the sense
that they should implement an explicit model of human learning and provide
explicit estimates of learners' abilities. However, to our knowledge, no study
to date has investigated whether the interpretability of KT models actually
helps human teachers to make teaching decisions. We address this gap. First, we
perform a simulation study to show that, indeed, decisions based on
interpretable KT models achieve mastery faster compared to decisions based on a
non-interpretable model. Second, we repeat the study but ask $N=12$ human
teachers to make the teaching decisions based on the information provided by KT
models. As expected, teachers rate interpretable KT models higher in terms of
usability and trustworthiness. However, the number of tasks needed until
mastery hardly differs between KT models. This suggests that the relationship
between model interpretability and teacher decisions is not straightforward:
teachers do not solely rely on KT models to make decisions and further research
is needed to investigate how learners and teachers actually understand and use
KT models.

</details>


### [28] [Calibration improves detection of mislabeled examples](https://arxiv.org/abs/2511.02738)
*Ilies Chibane,Thomas George,Pierre Nodet,Vincent Lemaire*

Main category: cs.LG

TL;DR: 本文研究了校准基础机器学习模型对错误标签检测性能的影响，发现使用校准方法可以提高错误标签实例检测的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实应用中错误标签数据普遍存在，会降低机器学习系统性能。需要有效检测错误标签实例并进行过滤或重新标记。

Method: 训练基础机器学习模型，然后对每个实例进行探测以获得标签可信度分数，重点研究校准该基础模型的影响。

Result: 实证结果表明，使用校准方法能够提高错误标签实例检测的准确性和鲁棒性。

Conclusion: 模型校准为工业应用提供了一种实用有效的错误标签检测解决方案。

Abstract: Mislabeled data is a pervasive issue that undermines the performance of
machine learning systems in real-world applications. An effective approach to
mitigate this problem is to detect mislabeled instances and subject them to
special treatment, such as filtering or relabeling. Automatic mislabeling
detection methods typically rely on training a base machine learning model and
then probing it for each instance to obtain a trust score that each provided
label is genuine or incorrect. The properties of this base model are thus of
paramount importance. In this paper, we investigate the impact of calibrating
this model. Our empirical results show that using calibration methods improves
the accuracy and robustness of mislabeled instance detection, providing a
practical and effective solution for industrial applications.

</details>


### [29] [From Solo to Symphony: Orchestrating Multi-Agent Collaboration with Single-Agent Demos](https://arxiv.org/abs/2511.02762)
*Xun Wang,Zhuoran Li,Yanshan Lin,Hai Zhong,Longbo Huang*

Main category: cs.LG

TL;DR: SoCo框架通过将单智能体知识迁移到协作学习中，利用单智能体演示来提升多智能体强化学习的训练效率和性能。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习从头训练团队效率低下，而现有的离线或可迁移方法仍依赖昂贵的多智能体数据。相比之下，单智能体经验在许多重要场景中更容易获得。

Method: SoCo首先从单智能体演示中预训练共享的单智能体策略，然后通过策略融合机制（包含MoE-like门控选择器和动作编辑器）在多智能体训练期间将其适应于协作。

Result: 在多样化协作任务上的实验表明，SoCo显著提升了骨干算法的训练效率和性能。

Conclusion: 单智能体演示为多智能体数据提供了可扩展且有效的补充，使协作学习更加实用和广泛适用。

Abstract: Training a team of agents from scratch in multi-agent reinforcement learning
(MARL) is highly inefficient, much like asking beginners to play a symphony
together without first practicing solo. Existing methods, such as offline or
transferable MARL, can ease this burden, but they still rely on costly
multi-agent data, which often becomes the bottleneck. In contrast, solo
experiences are far easier to obtain in many important scenarios, e.g.,
collaborative coding, household cooperation, and search-and-rescue. To unlock
their potential, we propose Solo-to-Collaborative RL (SoCo), a framework that
transfers solo knowledge into cooperative learning. SoCo first pretrains a
shared solo policy from solo demonstrations, then adapts it for cooperation
during multi-agent training through a policy fusion mechanism that combines an
MoE-like gating selector and an action editor. Experiments across diverse
cooperative tasks show that SoCo significantly boosts the training efficiency
and performance of backbone algorithms. These results demonstrate that solo
demonstrations provide a scalable and effective complement to multi-agent data,
making cooperative learning more practical and broadly applicable.

</details>


### [30] [Fast, Private, and Protected: Safeguarding Data Privacy and Defending Against Model Poisoning Attacks in Federated Learning](https://arxiv.org/abs/2511.02797)
*Nicolas Riccieri Gardin Assumpcao,Leandro Villas*

Main category: cs.LG

TL;DR: FPP是一种联邦学习保护方法，通过参与者评估、训练恢复和信誉机制来防御恶意攻击，同时保持数据隐私。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在保护数据隐私的同时，难以防范恶意参与者对训练结果的攻击，需要一种既能保护隐私又能防御攻击的解决方案。

Method: FPP采用安全聚合保护数据隐私，通过参与者评估轮次、训练恢复机制和基于信誉的参与控制来防御模型投毒攻击。

Result: 实验表明FPP在恶意参与者存在的情况下仍能快速收敛，收敛速度优于FedAvg、Power-of-Choice、Trimmed Mean和Median等方法。

Conclusion: FPP在保护数据隐私的同时有效防御了联邦学习中的恶意攻击，实现了快速收敛和训练稳定性。

Abstract: Federated Learning (FL) is a distributed training paradigm wherein
participants collaborate to build a global model while ensuring the privacy of
the involved data, which remains stored on participant devices. However,
proposals aiming to ensure such privacy also make it challenging to protect
against potential attackers seeking to compromise the training outcome. In this
context, we present Fast, Private, and Protected (FPP), a novel approach that
aims to safeguard federated training while enabling secure aggregation to
preserve data privacy. This is accomplished by evaluating rounds using
participants' assessments and enabling training recovery after an attack. FPP
also employs a reputation-based mechanism to mitigate the participation of
attackers. We created a dockerized environment to validate the performance of
FPP compared to other approaches in the literature (FedAvg, Power-of-Choice,
and aggregation via Trimmed Mean and Median). Our experiments demonstrate that
FPP achieves a rapid convergence rate and can converge even in the presence of
malicious participants performing model poisoning attacks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [31] [Re-FORC: Adaptive Reward Prediction for Efficient Chain-of-Thought Reasoning](https://arxiv.org/abs/2511.02130)
*Renos Zabounidis,Aditya Golatkar,Michael Kleinman,Alessandro Achille,Wei Xia,Stefano Soatto*

Main category: cs.AI

TL;DR: Re-FORC是一种自适应奖励预测方法，能够根据上下文预测未来奖励期望值，作为未来思考token数量的函数。该方法通过在推理模型上训练轻量级适配器，实现了更长的推理和更大模型带来的改进预测能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决推理过程中计算资源浪费的问题，提高推理效率，同时优化模型和推理长度的选择，实现更好的性能与计算成本平衡。

Method: 在推理模型上训练轻量级适配器，实现自适应奖励预测，能够根据上下文预测未来奖励期望值。

Result: 1) 提前停止无前景的推理链，减少26%计算量同时保持准确性；2) 优化模型和思考长度选择，在相同计算量下实现4%更高准确率，在相同准确率下减少55%计算量；3) 自适应测试时扩展，在高计算模式下提高11%准确率，在低计算模式下提高7%准确率。

Conclusion: Re-FORC允许通过每token成本阈值进行动态推理长度控制，同时预先估计计算时间，为高效推理提供了有效解决方案。

Abstract: We propose Re-FORC, an adaptive reward prediction method that, given a
context, enables prediction of the expected future rewards as a function of the
number of future thinking tokens. Re-FORC trains a lightweight adapter on
reasoning models, demonstrating improved prediction with longer reasoning and
larger models. Re-FORC enables: 1) early stopping of unpromising reasoning
chains, reducing compute by 26% while maintaining accuracy, 2) optimized model
and thinking length selection that achieves 4% higher accuracy at equal compute
and 55% less compute at equal accuracy compared to the largest model, 3)
adaptive test-time scaling, which increases accuracy by 11% in high compute
regime, and 7% in low compute regime. Re-FORC allows dynamic reasoning with
length control via cost-per-token thresholds while estimating computation time
upfront.

</details>


### [32] [Personalized Decision Modeling: Utility Optimization or Textualized-Symbolic Reasoning](https://arxiv.org/abs/2511.02194)
*Yibo Zhao,Yang Zhao,Hongru Du,Hao Frank Yang*

Main category: cs.AI

TL;DR: 本文提出了ATHENA框架，通过结合符号效用建模和语义适应，在疫苗选择和出行方式等高风险决策场景中，比现有模型提升了至少6.5%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 个体决策模型与群体最优预测存在差距，这种差距源于个体决策过程的独特性，包括数值属性（如成本、时间）和语言影响（如个人偏好和约束）。

Method: ATHENA框架包含两个阶段：1）通过LLM增强的符号发现发现稳健的群体级符号效用函数；2）实现个体级语义适应，创建由最优效用指导的个性化语义模板来建模个性化选择。

Result: 在真实世界的出行方式和疫苗选择任务上验证，ATHENA始终优于基于效用的模型、机器学习模型和其他基于LLM的模型，F1分数比最强前沿模型提升了至少6.5%。

Conclusion: 通过有机整合符号效用建模和语义适应，ATHENA为建模以人为中心的决策提供了新方案，消融研究证实两个阶段都至关重要且互补。

Abstract: Decision-making models for individuals, particularly in high-stakes scenarios
like vaccine uptake, often diverge from population optimal predictions. This
gap arises from the uniqueness of the individual decision-making process,
shaped by numerical attributes (e.g., cost, time) and linguistic influences
(e.g., personal preferences and constraints). Developing upon Utility Theory
and leveraging the textual-reasoning capabilities of Large Language Models
(LLMs), this paper proposes an Adaptive Textual-symbolic Human-centric
Reasoning framework (ATHENA) to address the optimal information integration.
ATHENA uniquely integrates two stages: First, it discovers robust, group-level
symbolic utility functions via LLM-augmented symbolic discovery; Second, it
implements individual-level semantic adaptation, creating personalized semantic
templates guided by the optimal utility to model personalized choices.
Validated on real-world travel mode and vaccine choice tasks, ATHENA
consistently outperforms utility-based, machine learning, and other LLM-based
models, lifting F1 score by at least 6.5% over the strongest cutting-edge
models. Further, ablation studies confirm that both stages of ATHENA are
critical and complementary, as removing either clearly degrades overall
predictive performance. By organically integrating symbolic utility modeling
and semantic adaptation, ATHENA provides a new scheme for modeling
human-centric decisions. The project page can be found at
https://yibozh.github.io/Athena.

</details>


### [33] [When Modalities Conflict: How Unimodal Reasoning Uncertainty Governs Preference Dynamics in MLLMs](https://arxiv.org/abs/2511.02243)
*Zhuoran Zhang,Tengyue Wang,Xilin Gong,Yang Shi,Haotian Wang,Di Wang,Lijie Hu*

Main category: cs.AI

TL;DR: 本文提出了一个新的框架，将多模态大语言模型中的模态跟随行为分解为两个基本因素：相对推理不确定性和固有模态偏好，并通过可控数据集验证了相对不确定性增加时跟随概率单调下降的普遍规律。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅使用粗粒度的数据集级统计来测量多模态大语言模型在冲突信息下的模态跟随行为，忽略了模型在单模态推理中的置信度影响。

Method: 构建可控数据集系统性地改变视觉和文本输入的推理难度，使用熵作为细粒度不确定性度量，通过层间预测探测揭示内部机制。

Result: 发现了一个普遍规律：跟随某个模态的概率随着其相对不确定性的增加而单调下降；在平衡点附近，模型会在不同模态间振荡；相对不确定性和固有偏好是模态跟随的两个控制原则。

Conclusion: 建立了相对不确定性和固有偏好作为模态跟随的两个控制原则，为理解多模态大语言模型如何解决冲突信息提供了定量框架和机制性见解。

Abstract: Multimodal large language models (MLLMs) must resolve conflicts when
different modalities provide contradictory information, a process we term
modality following. Prior work measured this behavior only with coarse
dataset-level statistics, overlooking the influence of model's confidence in
unimodal reasoning. In this paper, we introduce a new framework that decomposes
modality following into two fundamental factors: relative reasoning uncertainty
(the case-specific confidence gap between unimodal predictions) and inherent
modality preference( a model's stable bias when uncertainties are balanced). To
validate this framework, we construct a controllable dataset that
systematically varies the reasoning difficulty of visual and textual inputs.
Using entropy as a fine-grained uncertainty metric, we uncover a universal law:
the probability of following a modality decreases monotonically as its relative
uncertainty increases. At the relative difficulty level where the model tends
to follow both modalities with comparable probability what we call the balance
point, a practical indicator of the model's inherent preference. Unlike
traditional macro-level ratios, this measure offers a more principled and less
confounded way to characterize modality bias, disentangling it from unimodal
capabilities and dataset artifacts. Further, by probing layer-wise predictions,
we reveal the internal mechanism of oscillation: in ambiguous regions near the
balance point, models vacillate between modalities across layers, explaining
externally observed indecision. Together, these findings establish relative
uncertainty and inherent preference as the two governing principles of modality
following, offering both a quantitative framework and mechanistic insight into
how MLLMs resolve conflicting information.

</details>


### [34] [Unlocking the Power of Multi-Agent LLM for Reasoning: From Lazy Agents to Deliberation](https://arxiv.org/abs/2511.02303)
*Zhiwei Zhang,Xiaomin Li,Yudi Lin,Hui Liu,Ramraj Chandradevan,Linlin Wu,Minhua Lin,Fali Wang,Xianfeng Tang,Qi He,Suhang Wang*

Main category: cs.AI

TL;DR: 本文分析了多智能体推理中的懒惰行为问题，提出了因果影响力测量方法和可验证奖励机制来缓解该问题，从而充分发挥多智能体框架在复杂推理任务中的潜力。


<details>
  <summary>Details</summary>
Motivation: 在多智能体推理中，存在懒惰行为问题——一个智能体主导而另一个贡献很少，削弱了协作效果，使多智能体设置退化为无效的单智能体。

Method: 1) 理论分析懒惰行为的产生原因；2) 引入稳定高效的因果影响力测量方法；3) 提出可验证奖励机制，允许推理智能体丢弃噪声输出、整合指令并在必要时重新启动推理过程。

Result: 大量实验表明，该框架有效缓解了懒惰智能体行为，释放了多智能体框架在复杂推理任务中的全部潜力。

Conclusion: 通过理论分析和提出的解决方案，成功解决了多智能体推理中的协作问题，为复杂推理任务提供了更有效的多智能体框架。

Abstract: Large Language Models (LLMs) trained with reinforcement learning and
verifiable rewards have achieved strong results on complex reasoning tasks.
Recent work extends this paradigm to a multi-agent setting, where a
meta-thinking agent proposes plans and monitors progress while a reasoning
agent executes subtasks through sequential conversational turns. Despite
promising performance, we identify a critical limitation: lazy agent behavior,
in which one agent dominates while the other contributes little, undermining
collaboration and collapsing the setup to an ineffective single agent. In this
paper, we first provide a theoretical analysis showing why lazy behavior
naturally arises in multi-agent reasoning. We then introduce a stable and
efficient method for measuring causal influence, helping mitigate this issue.
Finally, as collaboration intensifies, the reasoning agent risks getting lost
in multi-turn interactions and trapped by previous noisy responses. To counter
this, we propose a verifiable reward mechanism that encourages deliberation by
allowing the reasoning agent to discard noisy outputs, consolidate
instructions, and restart its reasoning process when necessary. Extensive
experiments demonstrate that our framework alleviates lazy agent behavior and
unlocks the full potential of multi-agent framework for complex reasoning
tasks.

</details>


### [35] [Chronic Kidney Disease Prognosis Prediction Using Transformer](https://arxiv.org/abs/2511.02340)
*Yohan Lee,DongGyun Kang,SeHoon Park,Sa-Yoon Park,Kwangsoo Kim*

Main category: cs.AI

TL;DR: 提出基于Transformer的ProQ-BERT框架，用于预测慢性肾病进展，整合多模态电子健康记录数据，在91,816患者队列中表现优异，ROC-AUC最高达0.995。


<details>
  <summary>Details</summary>
Motivation: 慢性肾病影响全球近10%人口，准确预测疾病进展对于及时干预和资源优化至关重要。

Method: 使用基于Transformer的框架，整合人口统计、临床和实验室数据，采用量化分词处理连续实验室值，使用注意力机制提高可解释性，通过掩码语言建模预训练和二元分类微调。

Result: 在91,816患者队列评估中，模型持续优于CEHR-BERT，短期预测ROC-AUC达0.995，PR-AUC达0.989。

Conclusion: 结果表明Transformer架构和时间设计选择在临床预后建模中的有效性，为个性化慢性肾病护理提供了有前景的方向。

Abstract: Chronic Kidney Disease (CKD) affects nearly 10\% of the global population and
often progresses to end-stage renal failure. Accurate prognosis prediction is
vital for timely interventions and resource optimization. We present a
transformer-based framework for predicting CKD progression using multi-modal
electronic health records (EHR) from the Seoul National University Hospital
OMOP Common Data Model. Our approach (\textbf{ProQ-BERT}) integrates
demographic, clinical, and laboratory data, employing quantization-based
tokenization for continuous lab values and attention mechanisms for
interpretability. The model was pretrained with masked language modeling and
fine-tuned for binary classification tasks predicting progression from stage 3a
to stage 5 across varying follow-up and assessment periods. Evaluated on a
cohort of 91,816 patients, our model consistently outperformed CEHR-BERT,
achieving ROC-AUC up to 0.995 and PR-AUC up to 0.989 for short-term prediction.
These results highlight the effectiveness of transformer architectures and
temporal design choices in clinical prognosis modeling, offering a promising
direction for personalized CKD care.

</details>


### [36] [Fuzzy Soft Set Theory based Expert System for the Risk Assessment in Breast Cancer Patients](https://arxiv.org/abs/2511.02392)
*Muhammad Sheharyar Liaqat*

Main category: cs.AI

TL;DR: 提出了一种基于模糊软集理论的专家系统，使用BMI、胰岛素水平、瘦素水平、脂联素水平和年龄等临床参数来评估乳腺癌风险。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性死亡的主要原因之一，早期诊断对有效治疗和提高生存率至关重要，但由于疾病复杂性和患者风险因素的变异性，及时检测仍然具有挑战性。

Method: 开发了一个基于模糊软集理论的专家系统，整合BMI、胰岛素水平、瘦素水平、脂联素水平和年龄作为输入变量，通过模糊推理规则和软集计算来估计乳腺癌风险。

Result: 该系统使用UCI机器学习存储库的数据集进行开发和验证，能够通过常规血液分析获得参数，提供无创且易于获取的初步评估方法。

Conclusion: 该专家系统旨在帮助医疗专业人员识别高风险患者，并确定是否需要进行进一步的诊断程序（如活检）。

Abstract: Breast cancer remains one of the leading causes of mortality among women
worldwide, with early diagnosis being critical for effective treatment and
improved survival rates. However, timely detection continues to be a challenge
due to the complex nature of the disease and variability in patient risk
factors. This study presents a fuzzy soft set theory-based expert system
designed to assess the risk of breast cancer in patients using measurable
clinical and physiological parameters. The proposed system integrates Body Mass
Index, Insulin Level, Leptin Level, Adiponectin Level, and age as input
variables to estimate breast cancer risk through a set of fuzzy inference rules
and soft set computations. These parameters can be obtained from routine blood
analyses, enabling a non-invasive and accessible method for preliminary
assessment. The dataset used for model development and validation was obtained
from the UCI Machine Learning Repository. The proposed expert system aims to
support healthcare professionals in identifying high-risk patients and
determining the necessity of further diagnostic procedures such as biopsies.

</details>


### [37] [Auditable-choice reframing unlocks RL-based verification for open-ended tasks](https://arxiv.org/abs/2511.02463)
*Mengyu Zhang,Xubo Liu,Siyu Ding,Weichong Yin,Yu Sun,Hua Wu,Wenya Guo,Ying Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种可验证多选择重构（VMR）方法，将强化学习与可验证奖励（RLVR）范式扩展到开放域任务，通过将开放数据重构为可验证的多选择格式来提升大语言模型在无标准答案任务中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法在数学和编程等有标准答案的领域表现出色，但在缺乏标准答案的开放任务（如创意写作和指令遵循）中被视为非推理场景，忽略了推理能力的潜在价值。本文旨在探索推理能力是否能提升开放任务的性能。

Method: 提出可验证多选择重构（VMR）训练策略，将开放数据重构为可验证的多选择格式，从而在缺乏明确标准答案的情况下实现有效训练，使RLVR范式能够应用于开放域任务。

Result: 在多个基准测试上的实验结果表明，该方法能有效提升大语言模型在开放任务上的性能。在八个开放基准测试中，基于VMR的训练相比基线平均提升了5.99分。

Conclusion: VMR方法成功将RLVR范式扩展到开放域，证明了强化推理能力确实能提升大语言模型在开放任务中的表现，为缺乏标准答案的任务提供了有效的训练策略。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated great
potential in enhancing the reasoning capabilities of large language models
(LLMs), achieving remarkable progress in domains such as mathematics and
programming where standard answers are available. However, for open-ended tasks
lacking ground-truth solutions (e.g., creative writing and instruction
following), existing studies typically regard them as non-reasoning scenarios,
thereby overlooking the latent value of reasoning capabilities. This raises a
key question: Can strengthening reasoning improve performance in open-ended
tasks? To address this, we explore the transfer of the RLVR paradigm to the
open domain. Yet, since RLVR fundamentally relies on verifiers that presuppose
the existence of standard answers, it cannot be directly applied to open-ended
tasks. To overcome this challenge, we introduce Verifiable Multiple-Choice
Reformulation (VMR), a novel training strategy that restructures open-ended
data into verifiable multiple-choice formats, enabling effective training even
in the absence of explicit ground truth. Experimental results on multiple
benchmarks validate the effectiveness of our method in improving LLM
performance on open-ended tasks. Notably, across eight open-ended benchmarks,
our VMR-based training delivers an average gain of 5.99 points over the
baseline. Code will be released upon acceptance to facilitate reproducibility.

</details>


### [38] [Optimizing AI Agent Attacks With Synthetic Data](https://arxiv.org/abs/2511.02823)
*Chloe Loughridge,Paul Colognese,Avery Griffin,Tyler Tracy,Jon Kutasov,Joe Benton*

Main category: cs.AI

TL;DR: 本文提出了一种在复杂AI环境中优化攻击策略的方法，通过将攻击能力分解为五个核心技能并分别优化，在数据有限的情况下显著提升了攻击强度。


<details>
  <summary>Details</summary>
Motivation: 随着AI部署变得更加复杂和高风险，准确评估其风险变得至关重要。AI控制框架需要强大的攻击策略，但在复杂智能体环境中，计算约束导致数据不足，这给攻击策略的优化带来了挑战。

Method: 将攻击能力分解为五个组成技能：怀疑建模、攻击选择、计划合成、执行和隐蔽性，并分别优化每个组件。为了解决数据有限的问题，开发了攻击动态的概率模型，在模拟中优化攻击超参数，然后将结果迁移到SHADE-Arena环境中。

Result: 该方法显著提高了攻击强度，将安全分数从基线0.87降低到0.41，表明攻击效果得到了实质性改善。

Conclusion: 通过技能分解和概率建模的方法，可以在数据有限的复杂环境中有效优化攻击策略，为AI风险评估提供了更可靠的工具。

Abstract: As AI deployments become more complex and high-stakes, it becomes
increasingly important to be able to estimate their risk. AI control is one
framework for doing so. However, good control evaluations require eliciting
strong attack policies. This can be challenging in complex agentic environments
where compute constraints leave us data-poor. In this work, we show how to
optimize attack policies in SHADE-Arena, a dataset of diverse realistic control
environments. We do this by decomposing attack capability into five constituent
skills -- suspicion modeling, attack selection, plan synthesis, execution and
subtlety -- and optimizing each component individually. To get around the
constraint of limited data, we develop a probabilistic model of attack
dynamics, optimize our attack hyperparameters using this simulation, and then
show that the results transfer to SHADE-Arena. This results in a substantial
improvement in attack strength, reducing safety score from a baseline of 0.87
to 0.41 using our scaffold.

</details>


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [39] [Wavelet Based Cross Correlations with Applications](https://arxiv.org/abs/2511.02174)
*Jack Kissell,Vijini Lakmini,Brani Vidakovic*

Main category: stat.AP

TL;DR: 本文扩展了基于小波变换的相关性分析理论，详细阐述了小波相关图、偏小波相关性和加性小波相关性，使用Pearson和Kendall定义，并评估了不同小波基下这些相关性的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 小波变换能够将信号分解为对应不同频率/尺度带的系数向量，同时保留时间局部化特性，这使得能够在不同尺度上自适应分析信号，捕捉时间和频谱模式。通过研究两个信号在这些尺度上的相关性变化，可以获得比单一全局相关性度量更细致的理解。

Method: 使用正交和非抽取离散小波变换，扩展了小波相关性理论，包括小波相关图、偏小波相关性和加性小波相关性，采用Pearson和Kendall相关性定义，并通过模拟研究评估不同小波基下的鲁棒性。

Result: 通过模拟研究验证了这些方法的有效性，并在真实世界数据集上进行了应用，展示了小波相关性分析在不同尺度上揭示信号关系的优势。

Conclusion: 小波相关性分析提供了一种多尺度的方法来理解信号之间的关系，比传统的全局相关性度量能够提供更丰富的信息，适用于各种实际应用场景。

Abstract: Wavelet Transforms are a widely used technique for decomposing a signal into
coefficient vectors that correspond to distinct frequency/scale bands while
retaining time localization. This property enables an adaptive analysis of
signals at different scales, capturing both temporal and spectral patterns. By
examining how correlations between two signals vary across these scales, we
obtain a more nuanced understanding of their relationship than what is possible
from a single global correlation measure. In this work, we expand on the theory
of wavelet-based correlations already used in the literature and elaborate on
wavelet correlograms, partial wavelet correlations, and additive wavelet
correlations using the Pearson and Kendall definitions. We use both Orthogonal
and Non-decimated discrete Wavelet Transforms, and assess the robustness of
these correlations under different wavelet bases. Simulation studies are
conducted to illustrate these methods, and we conclude with applications to
real-world datasets.

</details>


### [40] [Identification of Separable OTUs for Multinomial Classification in Compositional Data Analysis](https://arxiv.org/abs/2511.02509)
*R. Alberich,N. A. Cruz,R. Fernández,I. García Mosquera,A. Mir,F. Roselló*

Main category: stat.AP

TL;DR: 提出了一种基于惩罚对数比回归和成对可分离性筛选的多元分类框架，用于处理组成性微生物组数据，通过AUC评估OTU的判别能力，并整合成全局可分离性指数Sk，提供可解释的物种排名和置信区间。


<details>
  <summary>Details</summary>
Motivation: 高通量测序产生组成性数据，挑战标准统计和机器学习方法，需要开发专门处理组成性微生物组数据的稳健框架。

Method: 使用惩罚对数比回归和成对可分离性筛选，通过计算所有成对对数比的AUC值，聚合为全局可分离性指数Sk，并结合协变量调整和不确定性估计。

Result: 在Baxter结直肠腺瘤数据集上验证，一致恢复先前识别的核心物种子集，同时发现考虑人口统计学协变量后新的重要OTU，提高分离指数的精度。

Conclusion: 该方法通过整合对数比建模、协变量调整和不确定性估计，为组成性微生物组数据中的OTU选择提供了稳健且可解释的框架，补充了现有基于排序的方法，增强了生物学意义微生物特征的识别。

Abstract: High-throughput sequencing has transformed microbiome research, but it also
produces inherently compositional data that challenge standard statistical and
machine learning methods. In this work, we propose a multinomial classification
framework for compositional microbiome data based on penalized log-ratio
regression and pairwise separability screening. The method quantifies the
discriminative ability of each OTU through the area under the receiver
operating characteristic curve ($AUC$) for all pairwise log-ratios and
aggregates these values into a global separability index $S_k$, yielding
interpretable rankings of taxa together with confidence intervals. We
illustrate the approach by reanalyzing the Baxter colorectal adenoma dataset
and comparing our results with Greenacre's ordination-based analysis using
Correspondence Analysis and Canonical Correspondence Analysis. Our models
consistently recover a core subset of taxa previously identified as
discriminant, thereby corroborating Greenacre's main findings, while also
revealing additional OTUs that become important once demographic covariates are
taken into account. In particular, adjustment for age, gender, and diabetes
medication improves the precision of the separation index and highlights new,
potentially relevant taxa, suggesting that part of the original signal may have
been influenced by confounding. Overall, the integration of log-ratio modeling,
covariate adjustment, and uncertainty estimation provides a robust and
interpretable framework for OTU selection in compositional microbiome data. The
proposed method complements existing ordination-based approaches by adding a
probabilistic and inferential perspective, strengthening the identification of
biologically meaningful microbial signatures.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [41] [Affordable EEG, Actionable Insights: An Open Dataset and Evaluation Framework for Epilepsy Patient Stratification](https://arxiv.org/abs/2511.01879)
*HM Shadman Tabib,Md. Hasnaen Adil,Ayesha Rahman,Ahmmad Nur Swapnil,Maoyejatun Hasana,Ahmed Hossain Chowdhury,A. B. M. Alim Al Islam*

Main category: eess.SP

TL;DR: NEUROSKY-EPI是首个面向癫痫的单通道消费级EEG开放数据集，结合EmbedCluster患者分层方法，证明了低成本EEG数据在资源受限环境中的实用性。


<details>
  <summary>Details</summary>
Motivation: 全球许多地区难以获取临床多通道EEG数据，需要开发在资源受限环境中可部署的癫痫诊断解决方案。

Method: 提出EmbedCluster患者分层流程：从临床数据训练的EEGNet模型迁移表征，用上下文自编码器嵌入丰富表征，然后基于EEG模式进行无监督聚类。

Result: 结果表明低成本单通道数据能够支持有意义的患者分层。

Conclusion: 通过发布数据集和代码，旨在促进跨学科研究，推进可负担且可操作的基于EEG的癫痫护理。

Abstract: Access to clinical multi-channel EEG remains limited in many regions
worldwide. We present NEUROSKY-EPI, the first open dataset of single-channel,
consumer-grade EEG for epilepsy, collected in a South Asian clinical setting
along with rich contextual metadata. To explore its utility, we introduce
EmbedCluster, a patient-stratification pipeline that transfers representations
from EEGNet models trained on clinical data and enriches them with contextual
autoencoder embeddings, followed by unsupervised clustering of patients based
on EEG patterns. Results show that low-cost, single-channel data can support
meaningful stratification. Beyond algorithmic performance, we emphasize
human-centered concerns such as deployability in resource-constrained
environments, interpretability for non-specialists, and safeguards for privacy,
inclusivity, and bias. By releasing the dataset and code, we aim to catalyze
interdisciplinary research across health technology, human-computer
interaction, and machine learning, advancing the goal of affordable and
actionable EEG-based epilepsy care.

</details>


### [42] [A Comparison of Road Grade Preview Signals from Lidar and Maps](https://arxiv.org/abs/2511.02006)
*Logan Schexnaydre,Aman Poovalappil,Darrell Robinette,Jeremy Bos*

Main category: eess.SP

TL;DR: 该论文提出了一种使用车载激光雷达实时估计道路坡度的方法，通过卡尔曼滤波技术处理里程计和运动不确定性，与基于地图的系统相比具有0.6度标准偏差的精度，为自动驾驶车辆提供独立于地图的坡度测量方案。


<details>
  <summary>Details</summary>
Motivation: 现有控制系统要么依赖车辆行驶时的实时感知（缺乏预览信号），要么完全依赖预设地图数据（可能信息缺失或过时），这两种方法都限制了控制系统的性能。需要一种能够实时测量前方道路坡度的解决方案。

Method: 使用车载激光雷达采集的点云数据，通过累积行驶过程中的点返回来估计路径上每个航点的坡度。坡度定义为给定航点处前后轮轴之间的高度差，采用卡尔曼滤波技术来减轻里程计和运动不确定性对坡度估计的影响。

Result: 与基于GNSS/INS系统创建的地图测量相比，激光雷达估计器产生无偏误差，标准偏差为0.6度，平均范围为52.7米。精度与基于地图的系统相当。

Conclusion: 激光雷达坡度估计系统在无法获取或地图不准确时是有效的道路坡度测量方法，为基于坡度的控制系统任务提供输入信号，使自动驾驶车辆相比现有方法具有更高的冗余性和独立性。

Abstract: Road grade can impact the energy efficiency, safety, and comfort associated
with automated vehicle control systems. Currently, control systems that attempt
to compensate for road grade are designed with one of two assumptions. Either
the grade is only known once the vehicle is driving over the road segment
through proprioception, or complete knowledge of the oncoming road grade is
known from a pre-made map. Both assumptions limit the performance of a control
system, as not having a preview signal prevents proactive grade compensation,
whereas relying only on map data potentially subjects the control system to
missing or outdated information. These limits can be avoided by measuring the
oncoming grade in real-time using on-board lidar sensors. In this work, we use
point returns accumulated during travel to estimate the grade at each waypoint
along a path. The estimated grade is defined as the difference in height
between the front and rear wheelbase at a given waypoint. Kalman filtering
techniques are used to mitigate the effects of odometry and motion uncertainty
on the grade estimates. This estimator's performance is compared to the
measurements of a map created with a GNSS/INS system via a field experiment.
When compared to the map-based system, the lidar-based estimator produces an
unbiased error with a standard deviation of 0.6 degrees at an average range of
52.7 meters. By having similar precision to map-based systems, automotive
lidar-based grade estimation systems are shown to be a valid approach for
measuring road grade when a map is unavailable or inaccurate. In using lidar as
an input signal for grade-based control system tasks, autonomous vehicles
achieve higher redundancy and independence in contrast to existing methods.

</details>


### [43] [A Kullback-Leibler divergence method for input-system-state identification](https://arxiv.org/abs/2511.02426)
*Marios Impraimakis*

Main category: eess.SP

TL;DR: 提出了一种基于Kullback-Leibler散度的新方法，用于在卡尔曼滤波框架中选择最合理的输入-参数-状态估计结果，通过比较先验分布和后验分布的信息增益来解决初始参数集不确定性带来的问题。


<details>
  <summary>Details</summary>
Motivation: 解决系统识别中由于不同初始参数集猜测导致结果不确定性的问题，需要一种方法来选择最合理的估计结果。

Method: 1. 对多个不同初始参数集执行卡尔曼滤波；2. 使用Kullback-Leibler散度同时比较后验分布与先验分布；3. 选择具有最小Kullback-Leibler散度的识别结果作为最合理的结果。

Result: 该方法在线性、非线性和有限信息应用中都能选择性能更好的识别结果，为系统监控提供了一个强大的工具。

Conclusion: 基于Kullback-Leibler散度的方法能够有效解决初始参数不确定性带来的问题，在各种应用场景下都能可靠地选择最合理的系统识别结果。

Abstract: The capability of a novel Kullback-Leibler divergence method is examined
herein within the Kalman filter framework to select the input-parameter-state
estimation execution with the most plausible results. This identification
suffers from the uncertainty related to obtaining different results from
different initial parameter set guesses, and the examined approach uses the
information gained from the data in going from the prior to the posterior
distribution to address the issue. Firstly, the Kalman filter is performed for
a number of different initial parameter sets providing the system
input-parameter-state estimation. Secondly, the resulting posterior
distributions are compared simultaneously to the initial prior distributions
using the Kullback-Leibler divergence. Finally, the identification with the
least Kullback-Leibler divergence is selected as the one with the most
plausible results. Importantly, the method is shown to select the better
performed identification in linear, nonlinear, and limited information
applications, providing a powerful tool for system monitoring.

</details>


### [44] [Adaptive Compressed Integrate-and-Fire Time Encoding Machine](https://arxiv.org/abs/2511.02444)
*Vered Karp,Aseel Omar,Alejandro Cohen*

Main category: eess.SP

TL;DR: 提出了一种结合自适应和压缩技术的ACIF-TEM采样器，通过集成AIF-TEM和CIF-TEM的优势，在降低采样率和比特使用的同时提高信号恢复精度。


<details>
  <summary>Details</summary>
Motivation: 现有IF-TEM采样器存在采样率较高和比特使用效率低的问题，需要结合自适应和压缩技术来优化性能。

Method: 设计ACIF-TEM采样器，集成自适应IF-TEM和压缩IF-TEM，并提出高效的无时钟时间数字转换器架构，将压缩阶段集成到TDC中。

Result: ACIF-TEM在真实音频信号测试中，相比AIF-TEM实现至少3位（共9位）的压缩增益，相比IF-TEM实现60%的压缩，在固定恢复MSE下使用更少比特。

Conclusion: ACIF-TEM采样器通过结合自适应和压缩技术，显著降低了比特使用并提高了信号恢复精度，为高效信号采样提供了有效解决方案。

Abstract: Integrate-and-Fire Time Encoding Machine (IF-TEM) is a power-efficient
asynchronous sampler that converts analog signals into non-uniform time-domain
samples. Adaptive IF-TEM (AIF-TEM) improves this machine by adapting its
process to the characteristics of the input signal, thereby reducing the
sampling rate. Compressed IF-TEM (CIF-TEM) reduces bit usage by performing
analog compression before quantization. In this paper, we introduce a combined
Adaptive Compressed IF-TEM (ACIF-TEM) -- a new sampler that leverages the two
machines, AIF-TEM and CIF-TEM, where each reinforces the effectiveness of the
other. We propose an efficient adaptive clockless time-to-digital converter
(TDC) architecture for the novel sampler that integrates the compression stage
within the TDC, facilitating the realization of the intended integrated system.
\ifconf \else We analyze the total bit usage, and contrast its performance with
that of IF-TEM, AIF-TEM, and CIF-TEM.\fi Via an evaluation study, we
demonstrate that the proposed ACIF-TEM sampler achieves lower Mean Square Error
(MSE) with fewer bits, offering compression gains of at least 3-bit out of
9-bits over AIF-TEM and 60\% compression over IF-TEM, for fixed recovery MSE
with real audio signals.

</details>


### [45] [Before AI Takes Over: Rethinking Nonlinear Signal Processing in Communications](https://arxiv.org/abs/2511.02493)
*Ana Pérez-Neira,Marc Martinez-Gost,Miguel Ángel Lagunas*

Main category: eess.SP

TL;DR: 本文呼吁在AI主导通信领域之前，重新评估传统非线性信号处理方法，强调数据驱动与模型驱动方法之间的张力，并探索经典信号处理与新兴AI方法的共存与整合。


<details>
  <summary>Details</summary>
Motivation: 在AI技术主导通信领域之前，迫切需要反思传统的非线性信号处理方法，重新评估或重新解释已建立的理论和工具，突显数据驱动与模型驱动方法之间的张力。

Method: 通过反思和重新评估传统非线性信号处理理论，探索经典信号处理与新兴AI方法的共存与整合方式。

Result: 提出了在AI时代保留经典信号处理宝贵见解的必要性，并探讨了传统方法与AI方法如何协同工作的可能性。

Conclusion: 需要在AI主导的通信领域发展中，既保留经典信号处理的宝贵见解，又积极探索其与新兴AI方法的整合路径，实现传统与现代方法的和谐共存。

Abstract: There is an urgent reflection on traditional nonlinear signal processing
methods in communications before Artificial Intelligence (AI) dominates the
field. It implies a need to reassess or reinterpret established theories and
tools, highlighting the tension between data-driven and model-based approaches.
This paper calls for preserving valuable insights from classical signal
processing while exploring how they can coexist or integrate with emerging AI
methods.

</details>


### [46] [RIS-Assisted 3D Spherical Splatting for Object Composition Visualization using Detection Transformers](https://arxiv.org/abs/2511.02573)
*Anastasios T. Sotiropoulos,Stavros Tsimpoukis,Dimitrios Tyrovolas,Sotiris Ioannidis,George K. Karagiannidis,Christos K. Liaskos*

Main category: eess.SP

TL;DR: 该论文提出了一种基于可编程无线环境(PWE)的射频框架，使用材料感知球形基元进行三维物体重建。该方法结合RIS支持的场合成与检测变换器(DETR)，直接从提取的RF特征推断空间和材料参数。


<details>
  <summary>Details</summary>
Motivation: 传统光学管道在遮挡或低光照条件下性能下降，而射频传感的电磁波能穿透材料并编码几何和成分信息。然而，不受控制的多径传播限制了重建精度。可编程无线环境通过可重构智能表面实现传播的软件定义操作，提供了可控的照明多样性。

Method: 结合RIS支持的场合成与检测变换器(DETR)，直接从提取的RF特征推断空间和材料参数。使用材料感知球形基元进行三维物体重建。

Result: 仿真结果证实该框架能够近似物体几何形状并以79.35%的总体准确率分类材料成分。

Conclusion: 这是迈向可编程和基于物理的射频三维物体成分可视化的初步步骤。

Abstract: The pursuit of immersive and structurally aware multimedia experiences has
intensified interest in sensing modalities that reconstruct objects beyond the
limits of visible light. Conventional optical pipelines degrade under occlusion
or low illumination, motivating the use of radio-frequency (RF) sensing, whose
electromagnetic waves penetrate materials and encode both geometric and
compositional information. Yet, uncontrolled multipath propagation restricts
reconstruction accuracy. Recent advances in Programmable Wireless Environments
(PWEs) mitigate this limitation by enabling software-defined manipulation of
propagation through Reconfigurable Intelligent Surfaces (RISs), thereby
providing controllable illumination diversity. Building on this capability,
this work introduces a PWE-driven RF framework for three-dimensional object
reconstruction using material-aware spherical primitives. The proposed approach
combines RIS-enabled field synthesis with a Detection Transformer (DETR) that
infers spatial and material parameters directly from extracted RF features.
Simulation results confirm the framework's ability to approximate object
geometries and classify material composition with an overall accuracy of
79.35%, marking an initial step toward programmable and physically grounded
RF-based 3D object composition visualization.

</details>


### [47] [Eye Movement Analysis in Simulated Driving Scenarios](https://arxiv.org/abs/2511.02689)
*Smilja Stokanović,Jaka Sodnik,Nadica Miljković*

Main category: eess.SP

TL;DR: 本研究通过31个眼动参数分析不同驾驶条件下的眼动行为，发现雾天低能见度对注视稳定性和眨眼行为有显著影响，并引入Guzik指数量化注视不对称性。


<details>
  <summary>Details</summary>
Motivation: 研究不同能见度条件下（正常驾驶和雾天驾驶）的眼动行为差异，特别是关注低能见度如何影响驾驶员的视觉注意力和注视稳定性。

Method: 使用眼动追踪技术，在三种条件下（基线、正常驾驶模拟、雾天驾驶模拟）收集数据，分析13个扫视特征、13个BCEA（双变量轮廓椭圆面积）参数和5个眨眼特征。

Result: 基线与驾驶条件间存在显著差异，雾天与正常驾驶相比，BCEA参数（9/13）和眨眼特征（4/5）变化明显，扫视特征变化较小（1/13）。引入的Guzik指数能有效量化注视不对称性。

Conclusion: 结合BCEA、扫视和眨眼参数能全面理解视觉注意力和注视稳定性，Guzik指数为不同能见度条件下的注视不对称性提供了新的分析视角。

Abstract: This study investigates eye movement behaviour during three conditions:
Baseline, Ride (simulated drive under normal visibility), and Fog (simulated
drive under reduced visibility). Eye tracking data are analyzed using 31
parameters, organized into three groups: (1) saccade features, (2) Bivariate
Contour Ellipse Area (BCEA), and (3) blinking features. Specifically, the
analysis includes 13 saccade, 13 BCEA, and 5 blinking variables. Across all
feature groups, numerous statistically significant differences emerge between
Baseline and the driving conditions, particularly between Baseline and Ride or
Fog. Between Ride and Fog, saccade features show minimal changes (one out of
13), whereas BCEA (9 of 13) and blink features (four of 5) exhibit pronounced
differences, highlighting the strong impact of reduced visibility on gaze
stability and blinking behaviour. In addition to conventional measures such as
Mean Squared Error (MSE) and entropy metrics, a new parameter, Guzik's Index
(GI), is introduced to quantify fixation asymmetry along the major axis of the
BCEA. This index utilizes eye tracking data to enhance the understanding of eye
movement dynamics during driving conditions. Separately from GI, other
parameters elicit the largest deviations compared to Ride (e.g., number of
saccades: Cliff's $\delta$ = 0.96, BCEA: Cohen's $\textit{d}$ = 0.89, and
standard deviation of blink duration: Cliff's $\delta$ = 0.80), underscoring
the influence of reduced visibility on visual attention. Overall, these
findings demonstrate that combining BCEA with saccade and blink parameters
provides a comprehensive understanding of visual attention and gaze stability,
while GI offers additional insights into fixation asymmetry under varying
visibility conditions.

</details>


### [48] [An unscented Kalman filter method for real time input-parameter-state estimation](https://arxiv.org/abs/2511.02717)
*Marios Impraimakis,Andrew W. Smyth*

Main category: eess.SP

TL;DR: 本文研究了一种新型无迹卡尔曼滤波器在线性和非线性系统中的输入-参数-状态估计能力，通过两阶段方法在单个时间步内估计未知输入，并证明具有已知零或非零输入的系统可被唯一识别。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够同时估计动态状态、参数和输入的输出专用方法，以提供比传统输出专用参数识别策略更好的系统理解。

Method: 使用新型无迹卡尔曼滤波器，在每个时间步内分两阶段估计未知输入：首先基于预测的动态状态和系统参数估计输入，然后基于测量校正后的状态和参数提供最终估计。

Result: 通过扰动分析证明，具有至少一个零或非零已知输入的系统可能被唯一识别，该方法能够实时联合估计所有动态状态、参数和输入。

Conclusion: 该输出专用方法相比传统策略提供了更好的系统理解能力，实现了动态状态、参数和输入的实时联合估计。

Abstract: The input-parameter-state estimation capabilities of a novel unscented Kalman
filter is examined herein on both linear and nonlinear systems. The unknown
input is estimated in two stages within each time step. Firstly, the predicted
dynamic states and the system parameters provide an estimation of the input.
Secondly, the corrected with measurements states and parameters provide a final
estimation. Importantly, it is demonstrated using the perturbation analysis
that, a system with at least a zero or a non-zero known input can potentially
be uniquely identified. This output-only methodology allows for a better
understanding of the system compared to classical output-only parameter
identification strategies, given that all the dynamic states, the parameters,
and the input are estimated jointly and in real-time.

</details>


### [49] [A Non-Uniform Quantization Framework for Time-Encoding Machines](https://arxiv.org/abs/2511.02728)
*Kaluguri Yashaswini,Anshu Arora,Satish Mulleti*

Main category: eess.SP

TL;DR: 该论文提出了一种针对时间编码机器(TEMs)的非均匀量化方案(NUQ)，相比传统的均匀量化(UQ)和非均匀采样(NUS)，在相同比特预算下显著降低了量化误差，传输成本减半。


<details>
  <summary>Details</summary>
Motivation: 传统的时间编码机器使用均匀量化处理触发间隔，但研究发现这些间隔本质上是非均匀分布的，因此需要设计更适合的非均匀量化方案。

Method: 推导了带限信号类中触发间隔的概率分布，并基于此分布设计了幂律非均匀量化方案。

Result: 仿真表明，在相同比特预算下，NUQ显著优于UQ。与需要量化幅度和时间的NUS相比，TEM-NUQ以一半的传输成本实现了更低的误差。

Conclusion: 研究结果凸显了分布感知量化的优势，确立了TEM-NUQ作为传统UQ和NUS方案的高效替代方案。

Abstract: Time encoding machines (TEMs) provide an event-driven alternative to
classical uniform sampling, enabling power-efficient representations without a
global clock. While prior work analyzed uniform quantization (UQ) of firing
intervals, we show that these intervals are inherently non-uniformly
distributed, motivating the use of non-uniform quantization (NUQ). We derive
the probability distribution of firing intervals for a class of bandlimited
signals and design a power-law-based NUQ scheme tailored to this distribution.
Simulations demonstrate that NUQ significantly outperforms UQ under the same
bit budget. We also compare TEMs with non-uniform sampling (NUS), where both
amplitudes and timings require quantization, and show that TEM--NUQ achieves
lower error at half the transmission cost. These results highlight the
advantages of distribution-aware quantization and establish TEM--NUQ as an
efficient alternative to conventional UQ and NUS schemes.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [50] [A new class of Markov random fields enabling lightweight sampling](https://arxiv.org/abs/2511.02373)
*Jean-Baptiste Courbot,Hugo Gangloff,Bruno Colicchio*

Main category: stat.ML

TL;DR: 提出了一种通过高斯马尔可夫随机场(GMRF)高效采样马尔可夫随机场(MRF)的新方法，相比传统的Gibbs采样，计算效率提升至少35倍，能耗降低至少37倍。


<details>
  <summary>Details</summary>
Motivation: 传统Potts或Ising MRF的采样主要基于Gibbs采样，计算成本高昂，需要寻找更高效的采样方法。

Method: 利用GMRF与MRF的联系，建立从实值GMRF到离散值MRF的映射，通过GMRF的高效采样方法来采样MRF。

Result: 新方法在计算效率上比Gibbs采样快至少35倍，能耗降低至少37倍，同时保持了与经典MRF相似的实证特性。

Conclusion: 通过GMRF映射的方法为MRF采样提供了一种计算高效且节能的替代方案，在保持模型质量的同时显著提升了性能。

Abstract: This work addresses the problem of efficient sampling of Markov random fields
(MRF). The sampling of Potts or Ising MRF is most often based on Gibbs
sampling, and is thus computationally expensive. We consider in this work how
to circumvent this bottleneck through a link with Gaussian Markov Random
fields. The latter can be sampled in several cost-effective ways, and we
introduce a mapping from real-valued GMRF to discrete-valued MRF. The resulting
new class of MRF benefits from a few theoretical properties that validate the
new model. Numerical results show the drastic performance gain in terms of
computational efficiency, as we sample at least 35x faster than Gibbs sampling
using at least 37x less energy, all the while exhibiting empirical properties
close to classical MRFs.

</details>


### [51] [An Adaptive Sampling Framework for Detecting Localized Concept Drift under Label Scarcity](https://arxiv.org/abs/2511.02452)
*Junghee Pyeon,Davide Cacciarelli,Kamran Paynabar*

Main category: stat.ML

TL;DR: 提出一种结合残差探索开发和EWMA监控的自适应采样框架，用于在标签预算约束下高效检测局部概念漂移。


<details>
  <summary>Details</summary>
Motivation: 概念漂移和标签稀缺是动态工业环境中预测模型面临的两个关键挑战，现有漂移检测方法通常假设全局漂移并依赖密集监督，不适用于局部漂移和有限标签的回归任务。

Method: 结合残差探索开发和EWMA监控的自适应采样框架，在标签预算约束下检测局部概念漂移。

Result: 在合成基准测试和电力市场案例研究中，在标签效率和漂移检测准确性方面表现出优越性能。

Conclusion: 该自适应采样框架能有效解决局部概念漂移检测问题，在标签预算受限的情况下具有良好表现。

Abstract: Concept drift and label scarcity are two critical challenges limiting the
robustness of predictive models in dynamic industrial environments. Existing
drift detection methods often assume global shifts and rely on dense
supervision, making them ill-suited for regression tasks with local drifts and
limited labels. This paper proposes an adaptive sampling framework that
combines residual-based exploration and exploitation with EWMA monitoring to
efficiently detect local concept drift under labeling budget constraints.
Empirical results on synthetic benchmarks and a case study on electricity
market demonstrate superior performance in label efficiency and drift detection
accuracy.

</details>
