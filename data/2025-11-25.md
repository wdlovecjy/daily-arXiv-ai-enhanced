<div id=toc></div>

# Table of Contents

- [stat.AP](#stat.AP) [Total: 1]
- [cs.AI](#cs.AI) [Total: 5]
- [eess.SP](#eess.SP) [Total: 3]
- [cs.LG](#cs.LG) [Total: 18]


<div id='stat.AP'></div>

# stat.AP [[Back]](#toc)

### [1] [A spatiotemporal Bayesian hierarchical model of heat-related mortality in Catalonia, Spain (2012--2022): The role of environmental and socioeconomic modifiers](https://arxiv.org/abs/2511.17148)
*David Solano,Marta Solans,Xavier Perafita,Anna Ruiz-Comellas,Marc Saez,Maria A. Barceló*

Main category: stat.AP

TL;DR: 本研究分析了2012-2022年加泰罗尼亚地区极端高温与死亡率的关系，发现极端高温本身与死亡率无独立关联，其影响完全被高臭氧水平混淆，部分被社会经济指标混淆。臭氧浓度≥120 μg/m³显著增加死亡风险，尤其是在85岁以上人群中。收入不平等和老年人口比例较高也增加了脆弱性。


<details>
  <summary>Details</summary>
Motivation: 极端高温是主要的公共健康风险，但其与死亡率的关系可能受到空气污染和社会因素的混淆或调节。本研究旨在量化极端最高温度和热浪对加泰罗尼亚地区每日死亡率的影响，并评估空气污染物和社会经济因素的调节和混淆作用。

Method: 在379个基本卫生区域进行时间序列生态学研究，将西班牙国家统计局的死亡率数据与气象和空气污染数据关联。使用分层贝叶斯时空模型，包含结构和非结构随机效应，以考虑时空依赖性和观察到的社会经济混淆因素。

Result: 共发生730,634例死亡，其中216,989例发生在夏季。极端高温本身与死亡率无独立关联，其影响完全被高臭氧水平混淆，部分被社会经济指标混淆。臭氧浓度≥120 μg/m³显著增加死亡风险，尤其是在≥85岁人群中。收入不平等和老年人口比例较高也增加了脆弱性。

Conclusion: 加泰罗尼亚地区极端高温导致的死亡风险受到臭氧水平和社会因素的强烈影响。适应策略应同时解决复合环境暴露和社会经济脆弱性，以更好地保护老年和弱势人群。

Abstract: Background: Extreme heat is a major public health risk, yet its relationship with mortality may be confounded or modified by air pollution and social determinants. Objectives: We aimed to quantify the effects of extreme maximum temperatures and heatwaves on daily mortality in Catalonia (2012--2022), and to assess the modifying and confounding roles of air pollutants and socioeconomic factors. Methods: We conducted a time--series ecological study across 379 basic health areas (ABS) during summer months. Mortality data from the Spanish National Statistics Institute were linked with meteorological and air pollution data. A hierarchical Bayesian spatiotemporal model, incorporating structured and unstructured random effects, was used to account for spatial and temporal dependencies, as well as observed socioeconomic confounders. Results: In total, 730,634 deaths occurred, with 216,989 in summer. Extreme heat alone was not independently associated with mortality, as its effect was fully confounded by high ozone levels and partly by socioeconomic indicators. Ozone concentrations ($\ge 120 μg/m^3$) significantly increased mortality risk, especially among individuals aged $\ge 85$ years. Greater income inequality and higher proportions of older residents also amplified vulnerability. Conclusion: Mortality risks from extreme heat in Catalonia were strongly influenced by ozone levels and social determinants. Adaptation strategies should address both compound environmental exposures together with socioeconomic vulnerability to better protect older and disadvantaged populations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [2] [DAPS++: Rethinking Diffusion Inverse Problems with Decoupled Posterior Annealing](https://arxiv.org/abs/2511.17038)
*Hao Chen,Renzheng Zhang,Scott S. Howard*

Main category: cs.AI

TL;DR: 本文重新解释了扩散模型在逆问题求解中的作用，提出了DAPS++方法，将扩散阶段和数据驱动细化完全解耦，实现了更高的计算效率和鲁棒的重建性能。


<details>
  <summary>Details</summary>
Motivation: 从贝叶斯角度看，基于分数的扩散通过联合推理解决逆问题，但实际应用中先验提供的指导有限，重建主要由测量一致性项驱动，与扩散动力学基本解耦。需要澄清这种结构并改进方法。

Method: 将扩散重新解释为期望最大化(EM)框架中的初始化阶段，引入DAPS++方法，使似然项更直接地指导推理，同时保持数值稳定性。

Result: DAPS++需要更少的函数评估次数和测量优化步骤，在多种图像恢复任务中实现了高计算效率和鲁棒的重建性能。

Conclusion: 扩散在逆问题求解中的作用可以重新解释为EM框架中的初始化阶段，DAPS++通过解耦扩散和数据驱动细化，提供了更有效的解决方案。

Abstract: From a Bayesian perspective, score-based diffusion solves inverse problems through joint inference, embedding the likelihood with the prior to guide the sampling process. However, this formulation fails to explain its practical behavior: the prior offers limited guidance, while reconstruction is largely driven by the measurement-consistency term, leading to an inference process that is effectively decoupled from the diffusion dynamics. To clarify this structure, we reinterpret the role of diffusion in inverse problem solving as an initialization stage within an expectation--maximization (EM)--style framework, where the diffusion stage and the data-driven refinement are fully decoupled. We introduce \textbf{DAPS++}, which allows the likelihood term to guide inference more directly while maintaining numerical stability and providing insight into why unified diffusion trajectories remain effective in practice. By requiring fewer function evaluations (NFEs) and measurement-optimization steps, \textbf{DAPS++} achieves high computational efficiency and robust reconstruction performance across diverse image restoration tasks.

</details>


### [3] [Cognitive BASIC: An In-Model Interpreted Reasoning Language for LLMs](https://arxiv.org/abs/2511.16837)
*Oliver Kramer*

Main category: cs.AI

TL;DR: Cognitive BASIC是一种基于BASIC风格的提示语言和模型内解释器，将大语言模型推理结构化为显式的逐步执行轨迹，通过编号行和简单命令作为可解释的认知控制层。


<details>
  <summary>Details</summary>
Motivation: 受复古BASIC简单性的启发，重新利用编号行和简单命令作为可解释的认知控制层，使现代LLM能够可靠地模拟这类简短程序，实现模型内部透明的多步推理。

Method: 使用自然语言解释器文件指定命令语义、内存更新和日志行为，通过心理模型解释器提取声明性和程序性知识，检测矛盾并在必要时产生解决方案。

Result: 在三个LLM上对知识提取、冲突检测和推理任务的基准测试显示，所有模型都能执行Cognitive BASIC程序，整体性能强劲但不统一。

Conclusion: Cognitive BASIC提供了一种结构化的方法来组织LLM推理过程，使其更加透明和可解释，为复杂推理任务提供了有效的框架。

Abstract: Cognitive BASIC is a minimal, BASIC-style prompting language and in-model interpreter that structures large language model (LLM) reasoning into explicit, stepwise execution traces. Inspired by the simplicity of retro BASIC, we repurpose numbered lines and simple commands as an interpretable cognitive control layer. Modern LLMs can reliably simulate such short programs, enabling transparent multi-step reasoning inside the model. A natural-language interpreter file specifies command semantics, memory updates, and logging behavior. Our mental-model interpreter extracts declarative and procedural knowledge, detects contradictions, and produces resolutions when necessary. A comparison across three LLMs on a benchmark of knowledge extraction, conflict detection, and reasoning tasks shows that all models can execute Cognitive BASIC programs, with overall strong but not uniform performance.

</details>


### [4] [Fantastic Bugs and Where to Find Them in AI Benchmarks](https://arxiv.org/abs/2511.16842)
*Sang Truong,Yuheng Tu,Michael Hardy,Anka Reuel,Zeyu Tang,Jirayu Burapacheep,Jonathan Perera,Chibuike Uwakwe,Ben Domingue,Nick Haber,Sanmi Koyejo*

Main category: cs.AI

TL;DR: 提出了一个系统性的基准测试修订框架，通过分析响应模式的统计特征来识别可能无效的问题，并引入LLM法官进行初步审查，以高效识别和修正基准测试中的问题。


<details>
  <summary>Details</summary>
Motivation: 基准测试在推动AI进步中至关重要，但无效的基准问题经常破坏其可靠性。手动识别和修正数千个基准问题中的错误既不可行，也是可靠评估的关键瓶颈。

Method: 利用响应模式的统计分析来标记可能无效的问题供专家进一步审查。该方法基于AI评估中常用的核心假设，即平均分足以总结模型性能，这意味着测量实验背后存在单维潜在结构。当项目的统计估计值超出预期范围时，该项目更可能存在问题。

Result: 在九个广泛使用的基准测试中，该方法指导专家审查识别问题问题的精度高达84%。通过引入LLM法官进行初步问题审查，进一步减少了人工工作量。

Conclusion: 这些组件共同提供了一个高效且可扩展的系统性基准测试修订框架，能够有效识别和修正基准测试中的无效问题。

Abstract: Benchmarks are pivotal in driving AI progress, and invalid benchmark questions frequently undermine their reliability. Manually identifying and correcting errors among thousands of benchmark questions is not only infeasible but also a critical bottleneck for reliable evaluation. In this work, we introduce a framework for systematic benchmark revision that leverages statistical analysis of response patterns to flag potentially invalid questions for further expert review. Our approach builds on a core assumption commonly used in AI evaluations that the mean score sufficiently summarizes model performance. This implies a unidimensional latent construct underlying the measurement experiment, yielding expected ranges for various statistics for each item. When empirically estimated values for these statistics fall outside the expected range for an item, the item is more likely to be problematic. Across nine widely used benchmarks, our method guides expert review to identify problematic questions with up to 84\% precision. In addition, we introduce an LLM-judge first pass to review questions, further reducing human effort. Together, these components provide an efficient and scalable framework for systematic benchmark revision.

</details>


### [5] [Budget-Aware Tool-Use Enables Effective Agent Scaling](https://arxiv.org/abs/2511.17006)
*Tengxiao Liu,Zifeng Wang,Jin Miao,I-Hung Hsu,Jun Yan,Jiefeng Chen,Rujun Han,Fangyuan Xu,Yanfei Chen,Ke Jiang,Samira Daruki,Yi Liang,William Yang Wang,Tomas Pfister,Chen-Yu Lee*

Main category: cs.AI

TL;DR: 本文研究了在明确工具调用预算约束下如何有效扩展工具增强智能体的性能，提出了预算跟踪器和BATS框架，使智能体具备预算意识并动态调整策略，从而改善成本-性能的扩展曲线。


<details>
  <summary>Details</summary>
Motivation: 当前工具增强智能体在扩展测试时计算时，单纯增加工具调用预算并不能提升性能，因为智能体缺乏"预算意识"，导致性能很快达到瓶颈。需要研究如何在明确预算约束下有效扩展这类智能体。

Method: 1) 引入预算跟踪器插件，为智能体提供持续的预算意识；2) 开发BATS框架，利用预算意识动态调整规划和验证策略，根据剩余资源决定是深入探索还是转向新路径；3) 制定统一的成本度量标准，综合考虑令牌和工具消耗。

Result: 预算感知方法产生了更有利的扩展曲线，推动了成本-性能的帕累托前沿，提供了对工具增强智能体扩展的更透明和原则性理解。

Conclusion: 预算意识是有效扩展工具增强智能体的关键，本文提出的方法为在预算约束下优化智能体性能提供了系统性的解决方案和实证见解。

Abstract: Scaling test-time computation improves performance across different tasks on large language models (LLMs), which has also been extended to tool-augmented agents. For these agents, scaling involves not only "thinking" in tokens but also "acting" via tool calls. The number of tool calls directly bounds the agent's interaction with the external environment. However, we find that simply granting agents a larger tool-call budget fails to improve performance, as they lack "budget awareness" and quickly hit a performance ceiling. To address this, we study how to scale such agents effectively under explicit tool-call budgets, focusing on web search agents. We first introduce the Budget Tracker, a lightweight plug-in that provides the agent with continuous budget awareness, enabling simple yet effective scaling. We further develop BATS (Budget Aware Test-time Scaling), an advanced framework that leverages this awareness to dynamically adapt its planning and verification strategy, deciding whether to "dig deeper" on a promising lead or "pivot" to new paths based on remaining resources. To analyze cost-performance scaling in a controlled manner, we formalize a unified cost metric that jointly accounts for token and tool consumption. We provide the first systematic study on budget-constrained agents, showing that budget-aware methods produce more favorable scaling curves and push the cost-performance Pareto frontier. Our work offers empirical insights toward a more transparent and principled understanding of scaling in tool-augmented agents.

</details>


### [6] [MIR: Efficient Exploration in Episodic Multi-Agent Reinforcement Learning via Mutual Intrinsic Reward](https://arxiv.org/abs/2511.17165)
*Kesheng Chen,Wenjian Luo,Bang Zhang,Zeping Yin,Zipeng Ye*

Main category: cs.AI

TL;DR: 本文提出MIR（互惠内在奖励）方法，通过激励智能体探索影响队友的行为来解决多智能体强化学习中稀疏奖励问题，在MiniGrid-MA环境中验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中，特别是面对稀疏奖励（如情节奖励）时存在两大挑战：联合动作轨迹的指数级稀疏性，以及现有方法未能充分考虑影响团队状态的联合动作。

Method: 提出MIR方法，激励个体智能体探索能够影响队友的行为，结合原始策略有效促进团队探索，并创建MiniGrid-MA环境进行实验验证。

Result: 在MiniGrid-MA环境中与最先进方法对比，实验结果表明所提方法具有优越性能。

Conclusion: MIR是一种简单有效的增强策略，能够显著改善多智能体强化学习在稀疏奖励场景下的算法性能。

Abstract: Episodic rewards present a significant challenge in reinforcement learning. While intrinsic reward methods have demonstrated effectiveness in single-agent rein-forcement learning scenarios, their application to multi-agent reinforcement learn-ing (MARL) remains problematic. The primary difficulties stem from two fac-tors: (1) the exponential sparsity of joint action trajectories that lead to rewards as the exploration space expands, and (2) existing methods often fail to account for joint actions that can influence team states. To address these challenges, this paper introduces Mutual Intrinsic Reward (MIR), a simple yet effective enhancement strategy for MARL with extremely sparse rewards like episodic rewards. MIR incentivizes individual agents to explore actions that affect their teammates, and when combined with original strategies, effectively stimulates team exploration and improves algorithm performance. For comprehensive experimental valida-tion, we extend the representative single-agent MiniGrid environment to create MiniGrid-MA, a series of MARL environments with sparse rewards. Our evalu-ation compares the proposed method against state-of-the-art approaches in the MiniGrid-MA setting, with experimental results demonstrating superior perfor-mance.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [7] [Movable Intelligent Surface-Enabled Wireless Communications: Static Phase Shifts with Mechanical Reconfigurability](https://arxiv.org/abs/2511.17058)
*Ziyuan Zheng,Qingqing Wu,Wen Chen,Weiren Zhu,Ying Gao*

Main category: eess.SP

TL;DR: 提出了一种新型可移动智能表面（MIS）架构，通过机械滑动预相位的次级超表面层来切换波束模式，解决了现有可重构智能表面（RIS）成本高和静态表面灵活性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有智能表面设计存在两个极端：动态RIS提供精细波束控制但成本高昂（需要密集布线、持续功耗和大量信令开销），而低成本静态表面无需控制线路但仅限于单一波束模式。这种差距使得在准静态环境中（如工业物联网和智慧农业）缺乏经济实用的解决方案。

Method: 提出MIS架构，通过机械滑动预相位的次级超表面层在较大的静态主层上移动来切换波束模式。开发了MIS信号模型，通过二进制选择矩阵描述静态相位元素与动态几何的交互。基于该模型，制定了联合优化静态相位偏移和重叠位置选择（等于波束模式调度）的新优化问题，并提出了基于惩罚方法、块坐标下降和黎曼流形优化的高效算法。

Result: 仿真结果表明，所提出的MIS架构显著缩小了单层静态表面和动态RIS之间的性能差距，为准静态无线应用提供了实用且灵活的解决方案。

Conclusion: MIS架构为需要中等灵活性的准静态无线应用提供了一种经济实用的替代方案，填补了现有智能表面技术的空白。

Abstract: Intelligent surfaces that reshape electromagnetic waves are regarded as disruptive technologies for wireless networks. However, existing designs sit at two costly extremes: dynamic reconfigurable intelligent surfaces (RISs) offer fine beam control but require dense cabling, continuous power consumption, and substantial signaling overhead, whereas low-cost static surfaces require no control lines or electronics but are limited to a single beam pattern. This disparity leaves a practical gap for quasi-static environments, such as industrial Internet-of-things and smart agriculture scenarios, where channels are stable with user demands changing only occasionally or periodically, and neither extreme is sufficiently economical or flexible. To bridge this gap, we propose a novel movable intelligent surface (MIS) architecture, whose beam patterns are switched not by electronic phase tuning but by mechanically sliding a small, pre-phased secondary metasurface layer across a larger, likewise static primary layer. We develop an MIS signal model that characterizes the interaction between static phase elements with dynamic geometry via binary selection matrices. Based on this model, we formulate a new type of optimization problems that jointly design static phase shifts and the overlapping position selection of MS2 (equal to beam pattern scheduling). Efficient algorithms based on the penalty method, block coordinate descent, and Riemannian manifold optimization are proposed to tackle these mixed-integer non-convex problems. Simulation results demonstrate that the proposed MIS architecture substantially narrows the performance gap between single-layer static surfaces and dynamic RISs, providing a practical and flexible solution for quasi-static wireless applications.

</details>


### [8] [Teager-Kaiser Energy Methods For EEG Feature Extraction In Biomedical Applications](https://arxiv.org/abs/2511.17164)
*Ioanna Chourdaki,Kleanthis Avramidis,Christos Garoufis,Athanasia Zlatintsi,Petros Maragos*

Main category: eess.SP

TL;DR: 本文研究了基于Teager-Kaiser能量算子的非线性特征提取方法，用于EEG信号分析，在运动想象、情感识别和癫痫检测三个任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: EEG信号具有非线性、非平稳性和易受噪声影响的特点，提取判别性特征一直是挑战。本文旨在探索TKEO算子对EEG能量动态建模的有效性。

Method: 使用Gabor滤波器组分离标准频带，然后通过能量分离算法将TKEO输出分解为幅度包络和瞬时频率分量，基于此推导出一组能量描述符。

Result: TKEO特征在运动想象和癫痫检测任务中优于基线方法，在情感识别任务中表现相当。

Conclusion: 提出的基于TKEO的流程为提取EEG信号动态提供了一个直观的框架。

Abstract: Electroencephalography (EEG) signals are inherently non-linear, non-stationary, and vulnerable to noise sources, making the extraction of discriminative features a long-standing challenge. In this work, we investigate the non-linear Teager-Kaiser Energy Operator (TKEO) for modeling the underlying energy dynamics of EEG in three representative tasks: motor imagery, emotion recognition, and epilepsy detection. To accommodate the narrowband nature of the operator, we employ Gabor filterbanks to isolate canonical frequency bands, followed by the Energy Separation Algorithm to decompose the TKEO output into amplitude envelope and instantaneous frequency components. We then derive a set of energy descriptors based on this demodulation and compare their classification performance against established signal energy and power spectrum features. TKEO features outperform the respective baselines in motor imagery and epilepsy detection, whereas they perform on par in emotion recognition. Our findings suggest that the proposed TKEO-based pipeline provides an intuitive framework for extracting EEG signal dynamics.

</details>


### [9] [Incorporating Bayesian Transfer Learning into Particle Filter for Dual-Tracking System with Asymmetric Noise Intensities](https://arxiv.org/abs/2511.17440)
*Omar A. Alotaibi,Brian L. Mark,Mohammad Reza Fasihi*

Main category: eess.SP

TL;DR: 提出了一种基于贝叶斯迁移学习的粒子滤波方法，用于处理双传感器系统中测量噪声强度不对称的非线性动态模型跟踪问题，通过加权粒子近似密度来提高主传感器的跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 在双传感器跟踪系统中，当两个传感器的测量噪声强度不对称时，主传感器（噪声强度较高）的跟踪性能会受到影响。需要一种方法来利用源传感器（噪声强度较低）的信息来提升主传感器的跟踪精度。

Method: 使用贝叶斯迁移学习结合粒子滤波，通过加权粒子来近似贝叶斯密度。与孤立粒子滤波以及应用于无迹卡尔曼滤波和容积卡尔曼滤波的迁移学习方法进行比较。

Result: 仿真结果表明，所提出的方法相比孤立粒子滤波和其他迁移学习方法更有效。增加粒子数量能显著提升迁移学习粒子滤波的性能，但会增加计算时间。性能提升与传感器噪声强度差异绝对值近似线性相关。

Conclusion: 贝叶斯迁移学习粒子滤波方法能有效提升双传感器系统中主传感器的跟踪性能，性能提升与传感器噪声差异成正比，但需要权衡粒子数量与计算成本。

Abstract: Using Bayesian transfer learning, we develop a particle filter approach for tracking a nonlinear dynamical model in a dual-tracking system where intensities of measurement noise for both sensors are asymmetric. The densities for Bayesian transfer learning are approximated with the sum of weighted particles to improve the tracking performance of the primary sensor, which experiences a higher noise intensity compared to the source sensor. We present simulation results that validate the effectiveness of the proposed approach compared to an isolated particle filter and transfer learning applied to the unscented Kalman filter and the cubature Kalman filter. Furthermore, increasing the number of particles shows an improvement in the performance of transfer learning applied to the particle filter with a higher rate compared to the isolated particle filter. However, increasing the number of particles raises computational time per step. Moreover, the performance gain from incorporating Bayesian transfer learning is approximately linearly proportional to the absolute difference value between the noise intensities of the sensors in the dual-tracking system.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [10] [DDTime: Dataset Distillation with Spectral Alignment and Information Bottleneck for Time-Series Forecasting](https://arxiv.org/abs/2511.16715)
*Yuqi Li,Kuiye Ding,Chuanguang Yang,Hao Wang,Haoxuan Wang,Huiran Duan,Junming Liu,Yingli Tian*

Main category: cs.LG

TL;DR: DDTime是一个轻量级的时间序列数据集蒸馏框架，通过频域对齐机制和基于信息瓶颈原理的样本间正则化，解决了时间序列预测中的时间偏差和样本多样性不足问题。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测通常需要大规模数据集和大量计算资源，而现有数据集蒸馏方法在时间序列领域面临两个主要挑战：时间偏差（由强自相关性引起）和合成样本多样性不足。

Method: 基于一阶压缩分解构建DDTime框架：1）通过频域对齐机制解决时间偏差问题，确保频谱一致性和时间保真度；2）设计基于信息瓶颈原理的样本间正则化来增强多样性。

Result: 在20个基准数据集和多种预测架构上的实验表明，DDTime始终优于现有蒸馏方法，实现了约30%的相对准确率提升，同时仅引入约2.49%的计算开销。

Conclusion: DDTime提供了一个高效的时间序列数据集蒸馏解决方案，能够显著提升预测准确性同时保持较低计算成本，支持稳定的一阶优化，并与多种压缩范式兼容。

Abstract: Time-series forecasting is fundamental across many domains, yet training accurate models often requires large-scale datasets and substantial computational resources. Dataset distillation offers a promising alternative by synthesizing compact datasets that preserve the learning behavior of full data. However, extending dataset distillation to time-series forecasting is non-trivial due to two fundamental challenges: 1.temporal bias from strong autocorrelation, which leads to distorted value-term alignment between teacher and student models; and 2.insufficient diversity among synthetic samples, arising from the absence of explicit categorical priors to regularize trajectory variety.
  In this work, we propose DDTime, a lightweight and plug-in distillation framework built upon first-order condensation decomposition. To tackle Challenge 1, it revisits value-term alignment through temporal statistics and introduces a frequency-domain alignment mechanism to mitigate autocorrelation-induced bias, ensuring spectral consistency and temporal fidelity. To address Challenge 2, we further design an inter-sample regularization inspired by the information bottleneck principle, which enhances diversity and maximizes information density across synthetic trajectories. The combined objective is theoretically compatible with a wide range of condensation paradigms and supports stable first-order optimization. Extensive experiments on 20 benchmark datasets and diverse forecasting architectures demonstrate that DDTime consistently outperforms existing distillation methods, achieving about 30% relative accuracy gains while introducing about 2.49% computational overhead. All code and distilled datasets will be released.

</details>


### [11] [When Structure Doesn't Help: LLMs Do Not Read Text-Attributed Graphs as Effectively as We Expected](https://arxiv.org/abs/2511.16767)
*Haotian Xu,Yuning You,Tengfei Ma*

Main category: cs.LG

TL;DR: 研究发现，在文本属性图上，仅使用节点文本描述的LLM已能获得强大性能，大多数结构编码策略仅带来边际收益甚至负面影响，表明在强大语言模型时代需要重新思考结构表示方式。


<details>
  <summary>Details</summary>
Motivation: 探索不同图结构编码策略如何影响LLM在文本属性图上的性能，挑战传统图学习中结构必然有益的基本假设。

Method: 通过系统实验比较不同图结构编码策略，包括模板化图模板和使用GNN编码结构信息的方法。

Result: LLM仅利用节点文本描述就能在各项任务中取得强劲表现；大多数结构编码策略仅提供边际收益或产生负面影响；明确的结构先验在强大语言模型参与时往往不必要甚至适得其反。

Conclusion: 这标志着与传统图学习范式的重大背离，突出了在LLM时代需要重新思考结构应如何表示和利用的必要性，为新的语义驱动图学习方法打开了大门。

Abstract: Graphs provide a unified representation of semantic content and relational structure, making them a natural fit for domains such as molecular modeling, citation networks, and social graphs. Meanwhile, large language models (LLMs) have excelled at understanding natural language and integrating cross-modal signals, sparking interest in their potential for graph reasoning. Recent work has explored this by either designing template-based graph templates or using graph neural networks (GNNs) to encode structural information. In this study, we investigate how different strategies for encoding graph structure affect LLM performance on text-attributed graphs. Surprisingly, our systematic experiments reveal that: (i) LLMs leveraging only node textual descriptions already achieve strong performance across tasks; and (ii) most structural encoding strategies offer marginal or even negative gains. We show that explicit structural priors are often unnecessary and, in some cases, counterproductive when powerful language models are involved. This represents a significant departure from traditional graph learning paradigms and highlights the need to rethink how structure should be represented and utilized in the LLM era. Our study is to systematically challenge the foundational assumption that structure is inherently beneficial for LLM-based graph reasoning, opening the door to new, semantics-driven approaches for graph learning.

</details>


### [12] [GCL-OT: Graph Contrastive Learning with Optimal Transport for Heterophilic Text-Attributed Graphs](https://arxiv.org/abs/2511.16778)
*Yating Ren,Yikun Ban,Huobin Tan*

Main category: cs.LG

TL;DR: 本文提出GCL-OT框架，针对文本属性图中的多粒度异质性（完全异质性、部分异质性、潜在同质性）问题，通过最优传输实现结构和文本的灵活双向对齐。


<details>
  <summary>Details</summary>
Motivation: 现有方法在异质性图上表现不佳，主要因为依赖同质性假设和硬优化目标，且将文本嵌入视为静态目标，导致对齐效果不理想。

Method: 提出GCL-OT框架：1) 使用RealSoftMax相似度估计器处理部分异质性；2) 基于提示的过滤器排除完全异质性中的噪声；3) 引入OT引导的软监督挖掘潜在同质性。

Result: 在9个基准测试上的实验表明，GCL-OT持续优于最先进方法，验证了其有效性和鲁棒性。理论分析显示GCL-OT能改善互信息边界和贝叶斯误差保证。

Conclusion: GCL-OT通过最优传输有效解决了文本属性图中的多粒度异质性问题，实现了结构和文本的灵活双向对齐，在异质性图上表现出优越性能。

Abstract: Recently, structure-text contrastive learning has shown promising performance on text-attributed graphs by leveraging the complementary strengths of graph neural networks and language models. However, existing methods typically rely on homophily assumptions in similarity estimation and hard optimization objectives, which limit their applicability to heterophilic graphs. Although existing methods can mitigate heterophily through structural adjustments or neighbor aggregation, they usually treat textual embeddings as static targets, leading to suboptimal alignment. In this work, we identify the multi-granular heterophily in text-attributed graphs, including complete heterophily, partial heterophily, and latent homophily, which makes structure-text alignment particularly challenging due to mixed, noisy, and missing semantic correlations. To achieve flexible and bidirectional alignment, we propose GCL-OT, a novel graph contrastive learning framework with optimal transport, equipped with tailored mechanisms for each type of heterophily. Specifically, for partial heterophily, we design a RealSoftMax-based similarity estimator to emphasize key neighbor-word interactions while easing background noise. For complete heterophily, we introduce a prompt-based filter that adaptively excludes irrelevant noise during optimal transport alignment. Furthermore, we incorporate OT-guided soft supervision to uncover potential neighbors with similar semantics, enhancing the learning of latent homophily. Theoretical analysis shows that GCL-OT can improve the mutual information bound and Bayes error guarantees. Extensive experiments on nine benchmarks show that GCL-OT consistently outperforms state-of-the-art methods, verifying its effectiveness and robustness.

</details>


### [13] [Revisiting Multimodal KV Cache Compression: A Frequency-Domain-Guided Outlier-KV-Aware Approach](https://arxiv.org/abs/2511.16786)
*Yaoxin Yang,Peng Ye,Xudong Tan,Chongjun Tu,Maosen Zhao,Jia Hao,Tao Chen*

Main category: cs.LG

TL;DR: FlashCache是一个基于频域分析和异常KV感知的多模态KV缓存压缩框架，通过识别和保留对推理至关重要的异常KV对，在保持任务性能的同时显著减少KV缓存大小并加速解码。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型存在显著的推理开销，因为多模态KV缓存随视觉输入长度线性增长。现有压缩方法主要依赖注意力分数，与高效注意力内核不兼容且忽略了值向量对注意力输出的贡献。

Method: 1. 从KV矩阵分布角度分析，发现其频域能量主要集中在低频；2. 提出异常KV识别模块，在频域中建模KV矩阵主成分，优先保留显著偏离的KV对；3. 设计动态预算分配模块，自适应确定每层KV缓存大小以保留更多异常KV。

Result: 在多个MLLM和基准测试上，FlashCache优于最先进的多模态KV压缩方法，实现高达1.69倍的解码加速和80%的KV内存使用降低，同时保持任务性能。

Conclusion: FlashCache通过频域引导的异常KV感知压缩框架，有效解决了多模态KV缓存压缩问题，在保持模型性能的同时显著提升了推理效率。

Abstract: Multimodal large language models suffer from substantial inference overhead since multimodal KV Cache grows proportionally with the visual input length. Existing multimodal KV Cache compression methods mostly rely on attention score to reduce cache size, which makes them are incompatible with established efficient attention kernels (e.g., FlashAttention) and ignores the contribution of value vectors to the attention output. In this work, we revisit multimodal KV Cache compression from the perspective of the KV matrices' distribution. First, we observe that frequency-domain energy of multimodal KV matrices is predominantly concentrated in low-frequency and extract this principal energy via a low-pass filter. Further, we find that removing KV pairs that deviate substantially from this principal energy leads to a pronounced performance drop, which we define as Outlier KVs. Considering Outlier KVs are more likely to encode features critical for inference, we propose FlashCache, a frequency-domain-guided, Outlier-KV-aware KV Cache compression framework. First, we introduce an Outlier KV Recognition Module that models the principal component of multimodal KV matrices in the frequency domain and preferentially retains KV pairs that significantly deviate from it. Furthermore, Dynamic Budget Allocation Module is designed to adaptively determine the per-layer KV Cache size to retain more Outlier KVs. Experiments on multiple MLLMs and benchmarks demonstrate that FlashCache outperforms state-of-the-art multimoal KV compression methods, achieving up to 1.69 times faster decoding with 80% lower KV memory usage while maintaining task performance.

</details>


### [14] [Monte Carlo Expected Threat (MOCET) Scoring](https://arxiv.org/abs/2511.16823)
*Joseph Kim,Saahith Potluri*

Main category: cs.LG

TL;DR: 本文介绍了MOCET，一种可解释且双重可扩展的指标，用于量化AI安全级别（ASL-3+）模型在生物安全领域的现实世界风险。


<details>
  <summary>Details</summary>
Motivation: 现有评估指标如LAB-Bench、BioLP-bench和WMDP虽然能可靠评估模型提升和领域知识，但缺乏能更好情境化"现实世界风险"的指标，需要可扩展的开放式指标来跟上LLM的快速发展。

Method: 提出MOCET指标，该指标具有可解释性和双重可扩展性（可自动化和开放式），能够量化现实世界风险。

Result: MOCET能够解决现有评估指标的不足，为LLM的安全案例提供更好的风险评估依据。

Conclusion: MOCET作为一种新型评估指标，填补了AI安全评估中现实世界风险量化和可扩展性方面的空白。

Abstract: Evaluating and measuring AI Safety Level (ASL) threats are crucial for guiding stakeholders to implement safeguards that keep risks within acceptable limits. ASL-3+ models present a unique risk in their ability to uplift novice non-state actors, especially in the realm of biosecurity. Existing evaluation metrics, such as LAB-Bench, BioLP-bench, and WMDP, can reliably assess model uplift and domain knowledge. However, metrics that better contextualize "real-world risks" are needed to inform the safety case for LLMs, along with scalable, open-ended metrics to keep pace with their rapid advancements. To address both gaps, we introduce MOCET, an interpretable and doubly-scalable metric (automatable and open-ended) that can quantify real-world risks.

</details>


### [15] [Analysis of heart failure patient trajectories using sequence modeling](https://arxiv.org/abs/2511.16839)
*Falk Dippela,Yinan Yu,Annika Rosengren,Martin Lindgren,Christina E. Lundberg,Erik Aerts,Martin Adiels,Helen Sjöland*

Main category: cs.LG

TL;DR: 本文系统比较了三种架构（Transformers、Transformers++、Mambas）在瑞典心力衰竭队列中的表现，发现Llama在预测性能、校准和鲁棒性方面最佳，Mambas次之，两者都能用更少参数和训练数据达到优异性能。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer和Mamba架构在临床预测任务中表现出色，但医学领域缺乏系统分析模型性能和效率的方法，需要建立实证分析框架。

Method: 使用瑞典42,820名心衰患者数据，评估六种序列模型在三个一年期预测任务上的表现，包括输入序列修改、架构配置和时间预处理技术的消融实验。

Result: Llama在所有任务中展现出最高的预测区分度、最佳校准和鲁棒性，其次是Mambas。两者在相同模型规模下仅需75%的训练数据即可达到优异性能。

Conclusion: 本研究为临床预测任务提供了首个系统消融研究框架，包括输入标记化、模型配置和时间数据预处理的设计选择，为未来EHR模型开发提供了起点建议。

Abstract: Transformers have defined the state-of-the-art for clinical prediction tasks involving electronic health records (EHRs). The recently introduced Mamba architecture outperformed an advanced Transformer (Transformer++) based on Llama in handling long context lengths, while using fewer model parameters. Despite the impressive performance of these architectures, a systematic approach to empirically analyze model performance and efficiency under various settings is not well established in the medical domain. The performances of six sequence models were investigated across three architecture classes (Transformers, Transformers++, Mambas) in a large Swedish heart failure (HF) cohort (N = 42820), providing a clinically relevant case study. Patient data included diagnoses, vital signs, laboratories, medications and procedures extracted from in-hospital EHRs. The models were evaluated on three one-year prediction tasks: clinical instability (a readmission phenotype) after initial HF hospitalization, mortality after initial HF hospitalization and mortality after latest hospitalization. Ablations account for modifications of the EHR-based input patient sequence, architectural model configurations, and temporal preprocessing techniques for data collection. Llama achieves the highest predictive discrimination, best calibration, and showed robustness across all tasks, followed by Mambas. Both architectures demonstrate efficient representation learning, with tiny configurations surpassing other large-scaled Transformers. At equal model size, Llama and Mambas achieve superior performance using 25% less training data. This paper presents a first ablation study with systematic design choices for input tokenization, model configuration and temporal data preprocessing. Future model development in clinical prediction tasks using EHRs could build upon this study's recommendation as a starting point.

</details>


### [16] [Sex and age determination in European lobsters using AI-Enhanced bioacoustics](https://arxiv.org/abs/2511.16848)
*Feliciano Pedro Francisco Domingos,Isibor Kennedy Ihianle,Omprakash Kaiwartya,Ahmad Lotfi,Nicola Khan,Nicholas Beaudreau,Amaya Albalat,Pedro Machado*

Main category: cs.LG

TL;DR: 本研究利用被动声学监测和人工智能模型，通过欧洲龙虾的生物声学特征（嗡嗡声/甲壳振动）成功分类龙虾的年龄（幼体/成体）和性别（雄/雌）。


<details>
  <summary>Details</summary>
Motivation: 监测水生生物（特别是像龙虾这样的难以观察的物种）具有挑战性。了解龙虾的栖息地、福利、繁殖、性别和年龄对于管理和保护至关重要。

Method: 在苏格兰Johnshaven使用水听器收集数据集，探索深度学习模型（1D-CNN、1D-DCNN）和六种机器学习模型（SVM、k-NN、朴素贝叶斯、随机森林、XGBoost、MLP），使用梅尔频率倒谱系数作为特征。

Result: 年龄分类准确率超过97%（朴素贝叶斯：91.31%），性别分类除朴素贝叶斯外所有模型超过93.23%。

Conclusion: 研究表明监督机器学习和深度学习能够从龙虾声音中提取年龄和性别相关特征，为龙虾保护、检测和管理提供有前景的非侵入性被动声学监测方法。

Abstract: Monitoring aquatic species, especially elusive ones like lobsters, presents challenges. This study focuses on Homarus gammarus (European lobster), a key species for fisheries and aquaculture, and leverages non-invasive Passive Acoustic Monitoring (PAM). Understanding lobster habitats, welfare, reproduction, sex, and age is crucial for management and conservation. While bioacoustic emissions have classified various aquatic species using Artificial Intelligence (AI) models, this research specifically uses H. gammarus bioacoustics (buzzing/carapace vibrations) to classify lobsters by age (juvenile/adult) and sex (male/female).
  The dataset was collected at Johnshaven, Scotland, using hydrophones in concrete tanks. We explored the efficacy of Deep Learning (DL) models (1D-CNN, 1D-DCNN) and six Machine Learning (ML) models (SVM, k-NN, Naive Bayes, Random Forest, XGBoost, MLP). Mel-frequency cepstral coefficients (MFCCs) were used as features.
  For age classification (adult vs. juvenile), most models achieved over 97% accuracy (Naive Bayes: 91.31%). For sex classification, all models except Naive Bayes surpassed 93.23%. These strong results demonstrate the potential of supervised ML and DL to extract age- and sex-related features from lobster sounds. This research offers a promising non-invasive PAM approach for lobster conservation, detection, and management in aquaculture and fisheries, enabling real-world edge computing applications for underwater species.

</details>


### [17] [A Hybrid Computational Intelligence Framework for scRNA-seq Imputation: Integrating scRecover and Random Forests](https://arxiv.org/abs/2511.16923)
*Ali Anaissi,Deshao Liu,Yuanzhe Jia,Weidong Huang,Widad Alyassine,Junaid Akram*

Main category: cs.LG

TL;DR: SCR-MF是一个模块化两阶段工作流，结合了scRecover的dropout检测和missForest的非参数插补，在保持生物学保真度的同时提供稳健的单细胞RNA测序数据插补性能。


<details>
  <summary>Details</summary>
Motivation: 单细胞RNA测序存在普遍的dropout事件，这会掩盖生物信号，需要开发能够稳健处理dropout同时保持生物学保真度的方法。

Method: 采用模块化两阶段工作流：第一阶段使用scRecover进行dropout检测，第二阶段使用missForest进行非参数插补。

Result: 在公共和模拟数据集上，SCR-MF在大多数情况下达到或超过现有插补方法的性能，同时保持生物学保真度和透明度。

Conclusion: SCR-MF在准确性和计算效率之间提供了有竞争力的平衡，适用于中等规模单细胞数据集。

Abstract: Single-cell RNA sequencing (scRNA-seq) enables transcriptomic profiling at cellular resolution but suffers from pervasive dropout events that obscure biological signals. We present SCR-MF, a modular two-stage workflow that combines principled dropout detection using scRecover with robust non-parametric imputation via missForest. Across public and simulated datasets, SCR-MF achieves robust and interpretable performance comparable to or exceeding existing imputation methods in most cases, while preserving biological fidelity and transparency. Runtime analysis demonstrates that SCR-MF provides a competitive balance between accuracy and computational efficiency, making it suitable for mid-scale single-cell datasets.

</details>


### [18] [CroTad: A Contrastive Reinforcement Learning Framework for Online Trajectory Anomaly Detection](https://arxiv.org/abs/2511.16929)
*Rui Xue,Dan He,Fengmei Jin,Chen Zhang,Xiaofang Zhou*

Main category: cs.LG

TL;DR: CroTad是一个基于对比强化学习的在线轨迹异常检测框架，无需阈值设置，能够处理噪声和不规则采样的轨迹数据，在子轨迹和点级别进行细粒度异常检测。


<details>
  <summary>Details</summary>
Motivation: 解决智能交通系统中轨迹异常检测的关键挑战：子轨迹异常检测研究不足、现有方法依赖阈值调节、不规则采样和训练集噪声影响模型性能。

Method: 结合对比学习和强化学习，通过对比学习提取不同行程的正常旅行模式，利用深度强化学习进行在线实时异常评分。

Result: 在两个真实数据集上的广泛实验证明了该框架在各种评估场景下的有效性和鲁棒性。

Conclusion: CroTad框架能够有效解决轨迹异常检测中的关键问题，实现无阈值、鲁棒的在线异常检测。

Abstract: Detecting trajectory anomalies is a vital task in modern Intelligent Transportation Systems (ITS), enabling the identification of unsafe, inefficient, or irregular travel behaviours. While deep learning has emerged as the dominant approach, several key challenges remain unresolved. First, sub-trajectory anomaly detection, capable of pinpointing the precise segments where anomalies occur, remains underexplored compared to whole-trajectory analysis. Second, many existing methods depend on carefully tuned thresholds, limiting their adaptability in real-world applications. Moreover, the irregular sampling of trajectory data and the presence of noise in training sets further degrade model performance, making it difficult to learn reliable representations of normal routes. To address these challenges, we propose a contrastive reinforcement learning framework for online trajectory anomaly detection, CroTad. Our method is threshold-free and robust to noisy, irregularly sampled data. By incorporating contrastive learning, CroTad learns to extract diverse normal travel patterns for different itineraries and effectively distinguish anomalous behaviours at both sub-trajectory and point levels. The detection module leverages deep reinforcement learning to perform online, real-time anomaly scoring, enabling timely and fine-grained identification of abnormal segments. Extensive experiments on two real-world datasets demonstrate the effectiveness and robustness of our framework across various evaluation scenarios.

</details>


### [19] [A novel approach to classification of ECG arrhythmia types with latent ODEs](https://arxiv.org/abs/2511.16933)
*Angelina Yan,Matt L. Sampson,Peter Melchior*

Main category: cs.LG

TL;DR: 提出了一种端到端的心电图分类方法，通过潜在ODE建模连续ECG波形，在不同采样频率下保持高性能，解决了可穿戴设备电池寿命与信号保真度之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统12导联ECG只能短期监测，容易错过间歇性心律失常事件；可穿戴ECG虽然能长期监测，但由于电池限制导致采样频率不规则且较低，形态分析困难。

Method: 训练潜在ODE模型来建模连续ECG波形，从高频单通道信号创建鲁棒特征向量；通过将初始360Hz ECG下采样到90Hz和45Hz，为每个波形构建三个潜在向量；使用梯度提升树对这些向量进行分类，并测试跨频率的鲁棒性。

Result: 在不同采样频率下性能下降最小，360Hz、90Hz和45Hz的宏平均AUC-ROC值分别为0.984、0.978和0.976，表明该方法能够绕过信号保真度与电池寿命之间的权衡。

Conclusion: 该方法使得更小的可穿戴设备成为可能，促进了心脏健康的长期监测。

Abstract: 12-lead ECGs with high sampling frequency are the clinical gold standard for arrhythmia detection, but their short-term, spot-check nature often misses intermittent events. Wearable ECGs enable long-term monitoring but suffer from irregular, lower sampling frequencies due to battery constraints, making morphology analysis challenging. We present an end-to-end classification pipeline to address these issues. We train a latent ODE to model continuous ECG waveforms and create robust feature vectors from high-frequency single-channel signals. We construct three latent vectors per waveform via downsampling the initial 360 Hz ECG to 90 Hz and 45 Hz. We then use a gradient boosted tree to classify these vectors and test robustness across frequencies. Performance shows minimal degradation, with macro-averaged AUC-ROC values of 0.984, 0.978, and 0.976 at 360 Hz, 90 Hz, and 45 Hz, respectively, suggesting a way to sidestep the trade-off between signal fidelity and battery life. This enables smaller wearables, promoting long-term monitoring of cardiac health.

</details>


### [20] [FIRM: Federated In-client Regularized Multi-objective Alignment for Large Language Models](https://arxiv.org/abs/2511.16992)
*Fatemeh,Nourzad,Amirhossein Roknilamouki,Eylem Ekici,Jia,Liu,Ness B. Shroff*

Main category: cs.LG

TL;DR: FIRM是一种联邦多目标对齐算法，通过客户端内正则化解决多目标冲突问题，实现通信效率和客户端分歧漂移缓解。


<details>
  <summary>Details</summary>
Motivation: 大语言模型与人类价值观对齐时面临多目标冲突（如帮助性与无害性），传统联邦多目标优化方法存在严重通信瓶颈，且集中化训练引发数据隐私问题。

Method: 提出FIRM算法，每个客户端本地解决正则化多目标优化问题，通过客户端内正则化直接缓解客户端分歧漂移，仅需传输单组适应参数，无需多梯度传输。

Result: 证明算法收敛到帕累托稳定点，提供有限时间收敛保证。实验显示FIRM带来更平滑的训练动态、减少的客户端分歧漂移和改善的奖励权衡。

Conclusion: FIRM能有效平衡多目标冲突，实现通信高效的联邦多目标对齐，并能根据指定偏好平滑调整目标间的权衡。

Abstract: Aligning Large Language Models (LLMs) with human values often involves balancing multiple, conflicting objectives such as helpfulness and harmlessness. Training these models is computationally intensive, and centralizing the process raises significant data privacy concerns. Federated Learning (FL) offers a compelling alternative, but existing Federated Multi-Objective Optimization (FMOO) methods face severe communication bottlenecks as their reliance on transmitting multiple gradients to a server is unscalable for large models. We introduce FIRM (Federated In-client Regularized Multi-objective alignment), a novel algorithm that achieves both client disagreement drift mitigation and communication efficiency. In FIRM, each client locally solves a regularized multi-objective optimization problem. By directly mitigating client disagreement drift through in-client regularization, our method eliminates the need for the multi-gradient transmissions common in prior works. Consequently, clients need only to transmit a single set of adapted parameters, maintaining high communication efficiency. We prove that our algorithm converges to Pareto-stationary points and, to our knowledge, provide the first finite-time convergence guarantees for this federated multi-objective alignment setting. Empirically, we show that FIRM leads to smoother training dynamics, reduced client disagreement drift, and improved reward trade-offs compared to baselines. We further propose a method to incorporate a preference over the objectives and report empirical Pareto plots, demonstrating that FIRM can smoothly adapt trade-offs between objectives in response to specified preferences.

</details>


### [21] [Geometric-Disentangelment Unlearning](https://arxiv.org/abs/2511.17100)
*Duo Zhou,Yuji Zhang,Tianxin Wei,Ruizhong Qiu,Ke Yang,Xiao Lin,Cheng Qian,Jingrui He,Hanghang Tong,Heng Ji,Huan Zhang*

Main category: cs.LG

TL;DR: 该论文提出了一种基于几何解缠的机器遗忘方法(GU)，通过将遗忘梯度分解为与保留梯度空间正交的分量来避免对保留知识的影响，在理论保证下实现有效遗忘同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有机器遗忘方法在有效遗忘和保留知识之间存在权衡，缺乏对遗忘更新如何影响保留知识的理论分析。需要探索具有理论保证的解决方案来消除副作用。

Method: 从一阶分析出发，提出几何解缠遗忘(GU)方法，将遗忘梯度更新分解为保留梯度空间的切向和法向分量，仅执行法向分量以确保保留损失的一阶不变性。

Result: GU方法在TOFU、MUSE和WMDP三个基准测试中均取得了一致的改进，能够有效缓解现有梯度遗忘方法的副作用。

Conclusion: 几何解缠方法提供了一种理论上有保证的简单解决方案，能够以插件方式增强现有梯度遗忘方法，在实现有效遗忘的同时保护保留知识。

Abstract: Machine unlearning, the removal of a training subset's influence from a deployed model, is critical for privacy preservation and model reliability, yet gradient ascent on forget samples often harms retained knowledge. Existing approaches face a persistent tradeoff between effective forgetting and preservation on the retain set. While previous methods provide useful heuristics, they often lack a formal analysis on how exactly forgetting updates harm retained knowledge, and whether the side effects can be removed with theoretical guarantees. To explore a theoretically sound and simple solution, we start from the first principle on how performance on the retain set is actually affected: a first-order analysis of the local change of the retain loss under small parameter updates during model training. We start from a crisp equivalence: the retain loss is unchanged to first order iff the update direction is orthogonal to the subspace spanned by retain gradients ("retain-invariant"). This identifies the entangled component as the tangential part of forget update within the retain-gradient subspace, and characterizes disentanglement as orthogonality. Guided by this, we propose the Geometric-disentanglement Unlearning (GU) that decomposes any candidate forget gradient update into tangential and normal components to retain space and executes only the normal component. Under a standard trust-region budget, the projected direction aligned with the raw forget gradient is optimal among all first-order retain-invariant moves, and we also derive the optimal projected direction for joint forget-retain updating objectives. Our method is plug-and-play and can be attached to existing gradient-based unlearning procedures to mitigate side effects. GU achieves consistent improvement on various methods across three benchmarks TOFU, MUSE, and WMDP.

</details>


### [22] [Four decades of circumpolar super-resolved satellite land surface temperature data](https://arxiv.org/abs/2511.17134)
*Sonia Dupuis,Nando Metzger,Konrad Schindler,Frank Göttsche,Stefan Wunderle*

Main category: cs.LG

TL;DR: 开发了一个42年泛北极地表温度数据集，通过深度学习超分辨率算法将AVHRR GAC数据从粗分辨率降尺度到1公里，用于改善北极地区多年冻土建模和气候监测。


<details>
  <summary>Details</summary>
Motivation: 北极地区快速变暖，但AVHRR卫星数据的粗空间分辨率限制了其在精细尺度多年冻土动态分析中的应用，需要更高分辨率的长期地表温度数据。

Method: 使用基于深度各向异性扩散模型的超分辨率算法，以MODIS LST数据为训练集，结合高分辨率土地覆盖、数字高程和植被高度图，将AVHRR GAC数据从粗分辨率降尺度到1公里。

Result: 生成了42年泛北极地区每日两次的1公里分辨率地表温度数据集，覆盖整个北极地区四个十年。

Conclusion: 该增强数据集能够改进多年冻土建模、重建近地表气温、评估格陵兰冰盖表面质量平衡，并为MODIS前时代的气候监测提供支持，同时为未来卫星任务提供可适应的框架。

Abstract: Land surface temperature (LST) is an essential climate variable (ECV) crucial for understanding land-atmosphere energy exchange and monitoring climate change, especially in the rapidly warming Arctic. Long-term satellite-based LST records, such as those derived from the Advanced Very High Resolution Radiometer (AVHRR), are essential for detecting climate trends. However, the coarse spatial resolution of AVHRR's global area coverage (GAC) data limit their utility for analyzing fine-scale permafrost dynamics and other surface processes in the Arctic. This paper presents a new 42 years pan-Arctic LST dataset, downscaled from AVHRR GAC to 1 km with a super-resolution algorithm based on a deep anisotropic diffusion model. The model is trained on MODIS LST data, using coarsened inputs and native-resolution outputs, guided by high-resolution land cover, digital elevation, and vegetation height maps. The resulting dataset provides twice-daily, 1 km LST observations for the entire pan-Arctic region over four decades. This enhanced dataset enables improved modelling of permafrost, reconstruction of near-surface air temperature, and assessment of surface mass balance of the Greenland Ice Sheet. Additionally, it supports climate monitoring efforts in the pre-MODIS era and offers a framework adaptable to future satellite missions for thermal infrared observation and climate data record continuity.

</details>


### [23] [Enforcing governing equation constraints in neural PDE solvers via training-free projections](https://arxiv.org/abs/2511.17258)
*Omer Rochman,Gilles Louppe*

Main category: cs.LG

TL;DR: 本文评估了两种无需训练的后处理投影方法，用于减少神经PDE求解器违反约束的问题，包括非线性优化投影和局部线性化投影，在多个代表性PDE上显著降低了约束违反并提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 神经PDE求解器在科学模拟中经常违反控制方程约束，特别是非线性约束和动态PDE中的长程时间依赖性问题，需要有效的后处理方法来确保解的可行性。

Method: 提出了两种无需训练的后处理投影方法：1）非线性优化投影；2）基于局部线性化的投影，使用雅可比-向量和向量-雅可比乘积。

Result: 在多个代表性PDE上的实验表明，两种投影方法都显著减少了约束违反，相比基于物理信息的基线方法提高了准确性。

Conclusion: 所提出的后处理投影方法能够有效处理神经PDE求解器中的约束违反问题，特别是对于非线性约束和动态PDE，为科学模拟提供了实用的解决方案。

Abstract: Neural PDE solvers used for scientific simulation often violate governing equation constraints. While linear constraints can be projected cheaply, many constraints are nonlinear, complicating projection onto the feasible set. Dynamical PDEs are especially difficult because constraints induce long-range dependencies in time. In this work, we evaluate two training-free, post hoc projections of approximate solutions: a nonlinear optimization-based projection, and a local linearization-based projection using Jacobian-vector and vector-Jacobian products. We analyze constraints across representative PDEs and find that both projections substantially reduce violations and improve accuracy over physics-informed baselines.

</details>


### [24] [Self-supervised denoising of raw tomography detector data for improved image reconstruction](https://arxiv.org/abs/2511.17312)
*Israt Jahan Tulin,Sebastian Starke,Dominic Windisch,André Bieberle,Peter Steinbach*

Main category: cs.LG

TL;DR: 本文研究了两种自监督深度学习方法用于超快电子束X射线CT的探测器数据去噪，并与非学习方法进行比较，发现深度学习方法能有效提升信噪比和重建图像质量。


<details>
  <summary>Details</summary>
Motivation: 超快电子束X射线CT由于测量时间短导致数据噪声大，产生重建伪影，限制了图像质量。

Method: 研究并比较了两种自监督深度学习去噪方法和一种非学习去噪方法。

Result: 深度学习方法能够增强探测器数据的信噪比，并在重建图像中带来一致的改进，优于非学习方法。

Conclusion: 自监督深度学习方法在超快电子束X射线CT数据去噪方面具有优势，能有效提升图像质量。

Abstract: Ultrafast electron beam X-ray computed tomography produces noisy data due to short measurement times, causing reconstruction artifacts and limiting overall image quality. To counteract these issues, two self-supervised deep learning methods for denoising of raw detector data were investigated and compared against a non-learning based denoising method. We found that the application of the deep-learning-based methods was able to enhance signal-to-noise ratios in the detector data and also led to consistent improvements of the reconstructed images, outperforming the non-learning based method.

</details>


### [25] [Convergence and stability of Q-learning in Hierarchical Reinforcement Learning](https://arxiv.org/abs/2511.17351)
*Massimiliano Manenti,Andrea Iannelli*

Main category: cs.LG

TL;DR: 本文提出了封建Q学习方案，研究了其耦合更新的收敛性和稳定性条件，通过随机逼近理论和ODE方法证明了收敛性，并将更新收敛点解释为适当定义博弈的均衡点。


<details>
  <summary>Details</summary>
Motivation: 分层强化学习在捕捉决策问题的时间结构和增强持续学习能力方面具有潜力，但理论保证落后于实践，需要提供收敛性和稳定性分析。

Method: 提出封建Q学习方案，利用随机逼近理论和ODE方法分析耦合更新的收敛性和稳定性，将收敛点解释为博弈均衡。

Result: 证明了封建Q学习的收敛性和稳定性定理，实验支持理论预期结果。

Conclusion: 为封建强化学习提供了原则性的收敛性和稳定性分析，为分层强化学习的博弈论方法打开了大门。

Abstract: Hierarchical Reinforcement Learning promises, among other benefits, to efficiently capture and utilize the temporal structure of a decision-making problem and to enhance continual learning capabilities, but theoretical guarantees lag behind practice. In this paper, we propose a Feudal Q-learning scheme and investigate under which conditions its coupled updates converge and are stable. By leveraging the theory of Stochastic Approximation and the ODE method, we present a theorem stating the convergence and stability properties of Feudal Q-learning. This provides a principled convergence and stability analysis tailored to Feudal RL. Moreover, we show that the updates converge to a point that can be interpreted as an equilibrium of a suitably defined game, opening the door to game-theoretic approaches to Hierarchical RL. Lastly, experiments based on the Feudal Q-learning algorithm support the outcomes anticipated by theory.

</details>


### [26] [Towards fully differentiable neural ocean model with Veros](https://arxiv.org/abs/2511.17427)
*Etienne Meunier,Said Ouala,Hugo Frezat,Julien Le Sommer,Ronan Fablet*

Main category: cs.LG

TL;DR: 本文提出了VEROS海洋模型的可微分扩展，使其能够通过自动微分进行梯度计算，并展示了在海洋状态修正和物理参数校准中的应用。


<details>
  <summary>Details</summary>
Motivation: 传统海洋模型缺乏自动微分能力，限制了基于梯度的优化方法在海洋建模中的应用。本文旨在通过使VEROS模型与JAX框架兼容，实现端到端的学习和参数调优。

Method: 对VEROS海洋模型进行关键修改，使其完全兼容JAX自动微分框架，并评估实现结果的数值一致性。

Result: 成功实现了VEROS模型的可微分扩展，并通过两个应用案例验证了其有效性：基于梯度的初始海洋状态修正和直接从模型观测中校准未知物理参数。

Conclusion: 可微分编程能够促进海洋建模中的端到端学习和参数调优，为海洋科学研究提供了新的工具和方法。

Abstract: We present a differentiable extension of the VEROS ocean model, enabling automatic differentiation through its dynamical core. We describe the key modifications required to make the model fully compatible with JAX autodifferentiation framework and evaluate the numerical consistency of the resulting implementation. Two illustrative applications are then demonstrated: (i) the correction of an initial ocean state through gradient-based optimization, and (ii) the calibration of unknown physical parameters directly from model observations. These examples highlight how differentiable programming can facilitate end-to-end learning and parameter tuning in ocean modeling. Our implementation is available online.

</details>


### [27] [Harnessing Data from Clustered LQR Systems: Personalized and Collaborative Policy Optimization](https://arxiv.org/abs/2511.17489)
*Vinay Kanakeri,Shivam Bajaj,Ashwin Verma,Vijay Gupta,Aritra Mitra*

Main category: cs.LG

TL;DR: 提出一种结合聚类和强化学习的新算法，用于多智能体线性二次调节器(LQR)控制，通过同时进行聚类和学习来为每个聚类输出个性化策略，提高样本效率。


<details>
  <summary>Details</summary>
Motivation: 强化学习通常数据需求量大，现有方法试图利用'近似相似'过程的数据来提高样本效率，但由于过程模型未知，识别相似过程具有挑战性。

Method: 结合顺序消除和零阶策略优化的思想，提出同时进行聚类和学习的算法，在多智能体LQR设置中为每个聚类学习个性化控制器。

Result: 在适当的聚类分离条件下，算法能以高概率保证正确聚类，每个聚类的策略次优性差距与聚类大小成反比，且没有额外偏差。

Conclusion: 这是首个揭示聚类如何在数据驱动控制中用于学习个性化策略的工作，既能享受协作带来的统计增益，又不会因包含不相似过程数据而遭受次优性。

Abstract: It is known that reinforcement learning (RL) is data-hungry. To improve sample-efficiency of RL, it has been proposed that the learning algorithm utilize data from 'approximately similar' processes. However, since the process models are unknown, identifying which other processes are similar poses a challenge. In this work, we study this problem in the context of the benchmark Linear Quadratic Regulator (LQR) setting. Specifically, we consider a setting with multiple agents, each corresponding to a copy of a linear process to be controlled. The agents' local processes can be partitioned into clusters based on similarities in dynamics and tasks. Combining ideas from sequential elimination and zeroth-order policy optimization, we propose a new algorithm that performs simultaneous clustering and learning to output a personalized policy (controller) for each cluster. Under a suitable notion of cluster separation that captures differences in closed-loop performance across systems, we prove that our approach guarantees correct clustering with high probability. Furthermore, we show that the sub-optimality gap of the policy learned for each cluster scales inversely with the size of the cluster, with no additional bias, unlike in prior works on collaborative learning-based control. Our work is the first to reveal how clustering can be used in data-driven control to learn personalized policies that enjoy statistical gains from collaboration but do not suffer sub-optimality due to inclusion of data from dissimilar processes. From a distributed implementation perspective, our method is attractive as it incurs only a mild logarithmic communication overhead.

</details>
